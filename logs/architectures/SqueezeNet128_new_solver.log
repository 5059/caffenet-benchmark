I0604 20:56:00.918982   844 caffe.cpp:185] Using GPUs 1
I0604 20:56:02.154641   844 solver.cpp:48] Initializing solver from parameters: 
test_iter: 2000
test_interval: 1000
base_lr: 0.04
display: 40
max_iter: 170000
lr_policy: "poly"
power: 1
momentum: 0.9
weight_decay: 0.0002
snapshot: 1000
snapshot_prefix: "snapshots/squeezenet128_"
solver_mode: GPU
device_id: 1
random_seed: 42
net_param {
  layer {
    name: "data"
    type: "Data"
    top: "data"
    top: "label"
    include {
      phase: TRAIN
    }
    transform_param {
      scale: 0.04
      mirror: true
      crop_size: 128
      mean_value: 104
      mean_value: 117
      mean_value: 124
      force_color: true
    }
    data_param {
      source: "/local/temporary/mishkdmy/imagenet144pxlmdb/ilsvrc12_128_train_lmdb"
      batch_size: 512
      backend: LMDB
    }
  }
  layer {
    name: "data"
    type: "Data"
    top: "data"
    top: "label"
    include {
      phase: TEST
    }
    transform_param {
      scale: 0.04
      mirror: false
      crop_size: 128
      mean_value: 104
      mean_value: 117
      mean_value: 123
      force_color: true
    }
    data_param {
      source: "/local/temporary/mishkdmy/imagenet144pxlmdb/ilsvrc12_128_val_lmdb"
      batch_size: 50
      backend: LMDB
    }
  }
  layer {
    name: "conv1"
    type: "Convolution"
    bottom: "data"
    top: "conv1"
    convolution_param {
      num_output: 96
      kernel_size: 7
      stride: 2
      weight_filler {
        type: "xavier"
      }
    }
  }
  layer {
    name: "relu_conv1"
    type: "ReLU"
    bottom: "conv1"
    top: "conv1"
  }
  layer {
    name: "pool1"
    type: "Pooling"
    bottom: "conv1"
    top: "pool1"
    pooling_param {
      pool: MAX
      kernel_size: 3
      stride: 2
    }
  }
  layer {
    name: "fire2/squeeze1x1"
    type: "Convolution"
    bottom: "pool1"
    top: "fire2/squeeze1x1"
    convolution_param {
      num_output: 16
      kernel_size: 1
      weight_filler {
        type: "xavier"
      }
    }
  }
  layer {
    name: "fire2/relu_squeeze1x1"
    type: "ReLU"
    bottom: "fire2/squeeze1x1"
    top: "fire2/squeeze1x1"
  }
  layer {
    name: "fire2/expand1x1"
    type: "Convolution"
    bottom: "fire2/squeeze1x1"
    top: "fire2/expand1x1"
    convolution_param {
      num_output: 64
      kernel_size: 1
      weight_filler {
        type: "xavier"
      }
    }
  }
  layer {
    name: "fire2/relu_expand1x1"
    type: "ReLU"
    bottom: "fire2/expand1x1"
    top: "fire2/expand1x1"
  }
  layer {
    name: "fire2/expand3x3"
    type: "Convolution"
    bottom: "fire2/squeeze1x1"
    top: "fire2/expand3x3"
    convolution_param {
      num_output: 64
      pad: 1
      kernel_size: 3
      weight_filler {
        type: "xavier"
      }
    }
  }
  layer {
    name: "fire2/relu_expand3x3"
    type: "ReLU"
    bottom: "fire2/expand3x3"
    top: "fire2/expand3x3"
  }
  layer {
    name: "fire2/concat"
    type: "Concat"
    bottom: "fire2/expand1x1"
    bottom: "fire2/expand3x3"
    top: "fire2/concat"
  }
  layer {
    name: "fire3/squeeze1x1"
    type: "Convolution"
    bottom: "fire2/concat"
    top: "fire3/squeeze1x1"
    convolution_param {
      num_output: 16
      kernel_size: 1
      weight_filler {
        type: "xavier"
      }
    }
  }
  layer {
    name: "fire3/relu_squeeze1x1"
    type: "ReLU"
    bottom: "fire3/squeeze1x1"
    top: "fire3/squeeze1x1"
  }
  layer {
    name: "fire3/expand1x1"
    type: "Convolution"
    bottom: "fire3/squeeze1x1"
    top: "fire3/expand1x1"
    convolution_param {
      num_output: 64
      kernel_size: 1
      weight_filler {
        type: "xavier"
      }
    }
  }
  layer {
    name: "fire3/relu_expand1x1"
    type: "ReLU"
    bottom: "fire3/expand1x1"
    top: "fire3/expand1x1"
  }
  layer {
    name: "fire3/expand3x3"
    type: "Convolution"
    bottom: "fire3/squeeze1x1"
    top: "fire3/expand3x3"
    convolution_param {
      num_output: 64
      pad: 1
      kernel_size: 3
      weight_filler {
        type: "xavier"
      }
    }
  }
  layer {
    name: "fire3/relu_expand3x3"
    type: "ReLU"
    bottom: "fire3/expand3x3"
    top: "fire3/expand3x3"
  }
  layer {
    name: "fire3/concat"
    type: "Concat"
    bottom: "fire3/expand1x1"
    bottom: "fire3/expand3x3"
    top: "fire3/concat"
  }
  layer {
    name: "fire4/squeeze1x1"
    type: "Convolution"
    bottom: "fire3/concat"
    top: "fire4/squeeze1x1"
    convolution_param {
      num_output: 32
      kernel_size: 1
      weight_filler {
        type: "xavier"
      }
    }
  }
  layer {
    name: "fire4/relu_squeeze1x1"
    type: "ReLU"
    bottom: "fire4/squeeze1x1"
    top: "fire4/squeeze1x1"
  }
  layer {
    name: "fire4/expand1x1"
    type: "Convolution"
    bottom: "fire4/squeeze1x1"
    top: "fire4/expand1x1"
    convolution_param {
      num_output: 128
      kernel_size: 1
      weight_filler {
        type: "xavier"
      }
    }
  }
  layer {
    name: "fire4/relu_expand1x1"
    type: "ReLU"
    bottom: "fire4/expand1x1"
    top: "fire4/expand1x1"
  }
  layer {
    name: "fire4/expand3x3"
    type: "Convolution"
    bottom: "fire4/squeeze1x1"
    top: "fire4/expand3x3"
    convolution_param {
      num_output: 128
      pad: 1
      kernel_size: 3
      weight_filler {
        type: "xavier"
      }
    }
  }
  layer {
    name: "fire4/relu_expand3x3"
    type: "ReLU"
    bottom: "fire4/expand3x3"
    top: "fire4/expand3x3"
  }
  layer {
    name: "fire4/concat"
    type: "Concat"
    bottom: "fire4/expand1x1"
    bottom: "fire4/expand3x3"
    top: "fire4/concat"
  }
  layer {
    name: "pool4"
    type: "Pooling"
    bottom: "fire4/concat"
    top: "pool4"
    pooling_param {
      pool: MAX
      kernel_size: 3
      stride: 2
    }
  }
  layer {
    name: "fire5/squeeze1x1"
    type: "Convolution"
    bottom: "pool4"
    top: "fire5/squeeze1x1"
    convolution_param {
      num_output: 32
      kernel_size: 1
      weight_filler {
        type: "xavier"
      }
    }
  }
  layer {
    name: "fire5/relu_squeeze1x1"
    type: "ReLU"
    bottom: "fire5/squeeze1x1"
    top: "fire5/squeeze1x1"
  }
  layer {
    name: "fire5/expand1x1"
    type: "Convolution"
    bottom: "fire5/squeeze1x1"
    top: "fire5/expand1x1"
    convolution_param {
      num_output: 128
      kernel_size: 1
      weight_filler {
        type: "xavier"
      }
    }
  }
  layer {
    name: "fire5/relu_expand1x1"
    type: "ReLU"
    bottom: "fire5/expand1x1"
    top: "fire5/expand1x1"
  }
  layer {
    name: "fire5/expand3x3"
    type: "Convolution"
    bottom: "fire5/squeeze1x1"
    top: "fire5/expand3x3"
    convolution_param {
      num_output: 128
      pad: 1
      kernel_size: 3
      weight_filler {
        type: "xavier"
      }
    }
  }
  layer {
    name: "fire5/relu_expand3x3"
    type: "ReLU"
    bottom: "fire5/expand3x3"
    top: "fire5/expand3x3"
  }
  layer {
    name: "fire5/concat"
    type: "Concat"
    bottom: "fire5/expand1x1"
    bottom: "fire5/expand3x3"
    top: "fire5/concat"
  }
  layer {
    name: "fire6/squeeze1x1"
    type: "Convolution"
    bottom: "fire5/concat"
    top: "fire6/squeeze1x1"
    convolution_param {
      num_output: 48
      kernel_size: 1
      weight_filler {
        type: "xavier"
      }
    }
  }
  layer {
    name: "fire6/relu_squeeze1x1"
    type: "ReLU"
    bottom: "fire6/squeeze1x1"
    top: "fire6/squeeze1x1"
  }
  layer {
    name: "fire6/expand1x1"
    type: "Convolution"
    bottom: "fire6/squeeze1x1"
    top: "fire6/expand1x1"
    convolution_param {
      num_output: 192
      kernel_size: 1
      weight_filler {
        type: "xavier"
      }
    }
  }
  layer {
    name: "fire6/relu_expand1x1"
    type: "ReLU"
    bottom: "fire6/expand1x1"
    top: "fire6/expand1x1"
  }
  layer {
    name: "fire6/expand3x3"
    type: "Convolution"
    bottom: "fire6/squeeze1x1"
    top: "fire6/expand3x3"
    convolution_param {
      num_output: 192
      pad: 1
      kernel_size: 3
      weight_filler {
        type: "xavier"
      }
    }
  }
  layer {
    name: "fire6/relu_expand3x3"
    type: "ReLU"
    bottom: "fire6/expand3x3"
    top: "fire6/expand3x3"
  }
  layer {
    name: "fire6/concat"
    type: "Concat"
    bottom: "fire6/expand1x1"
    bottom: "fire6/expand3x3"
    top: "fire6/concat"
  }
  layer {
    name: "fire7/squeeze1x1"
    type: "Convolution"
    bottom: "fire6/concat"
    top: "fire7/squeeze1x1"
    convolution_param {
      num_output: 48
      kernel_size: 1
      weight_filler {
        type: "xavier"
      }
    }
  }
  layer {
    name: "fire7/relu_squeeze1x1"
    type: "ReLU"
    bottom: "fire7/squeeze1x1"
    top: "fire7/squeeze1x1"
  }
  layer {
    name: "fire7/expand1x1"
    type: "Convolution"
    bottom: "fire7/squeeze1x1"
    top: "fire7/expand1x1"
    convolution_param {
      num_output: 192
      kernel_size: 1
      weight_filler {
        type: "xavier"
      }
    }
  }
  layer {
    name: "fire7/relu_expand1x1"
    type: "ReLU"
    bottom: "fire7/expand1x1"
    top: "fire7/expand1x1"
  }
  layer {
    name: "fire7/expand3x3"
    type: "Convolution"
    bottom: "fire7/squeeze1x1"
    top: "fire7/expand3x3"
    convolution_param {
      num_output: 192
      pad: 1
      kernel_size: 3
      weight_filler {
        type: "xavier"
      }
    }
  }
  layer {
    name: "fire7/relu_expand3x3"
    type: "ReLU"
    bottom: "fire7/expand3x3"
    top: "fire7/expand3x3"
  }
  layer {
    name: "fire7/concat"
    type: "Concat"
    bottom: "fire7/expand1x1"
    bottom: "fire7/expand3x3"
    top: "fire7/concat"
  }
  layer {
    name: "fire8/squeeze1x1"
    type: "Convolution"
    bottom: "fire7/concat"
    top: "fire8/squeeze1x1"
    convolution_param {
      num_output: 64
      kernel_size: 1
      weight_filler {
        type: "xavier"
      }
    }
  }
  layer {
    name: "fire8/relu_squeeze1x1"
    type: "ReLU"
    bottom: "fire8/squeeze1x1"
    top: "fire8/squeeze1x1"
  }
  layer {
    name: "fire8/expand1x1"
    type: "Convolution"
    bottom: "fire8/squeeze1x1"
    top: "fire8/expand1x1"
    convolution_param {
      num_output: 256
      kernel_size: 1
      weight_filler {
        type: "xavier"
      }
    }
  }
  layer {
    name: "fire8/relu_expand1x1"
    type: "ReLU"
    bottom: "fire8/expand1x1"
    top: "fire8/expand1x1"
  }
  layer {
    name: "fire8/expand3x3"
    type: "Convolution"
    bottom: "fire8/squeeze1x1"
    top: "fire8/expand3x3"
    convolution_param {
      num_output: 256
      pad: 1
      kernel_size: 3
      weight_filler {
        type: "xavier"
      }
    }
  }
  layer {
    name: "fire8/relu_expand3x3"
    type: "ReLU"
    bottom: "fire8/expand3x3"
    top: "fire8/expand3x3"
  }
  layer {
    name: "fire8/concat"
    type: "Concat"
    bottom: "fire8/expand1x1"
    bottom: "fire8/expand3x3"
    top: "fire8/concat"
  }
  layer {
    name: "pool8"
    type: "Pooling"
    bottom: "fire8/concat"
    top: "pool8"
    pooling_param {
      pool: MAX
      kernel_size: 3
      stride: 2
    }
  }
  layer {
    name: "fire9/squeeze1x1"
    type: "Convolution"
    bottom: "pool8"
    top: "fire9/squeeze1x1"
    convolution_param {
      num_output: 64
      kernel_size: 1
      weight_filler {
        type: "xavier"
      }
    }
  }
  layer {
    name: "fire9/relu_squeeze1x1"
    type: "ReLU"
    bottom: "fire9/squeeze1x1"
    top: "fire9/squeeze1x1"
  }
  layer {
    name: "fire9/expand1x1"
    type: "Convolution"
    bottom: "fire9/squeeze1x1"
    top: "fire9/expand1x1"
    convolution_param {
      num_output: 256
      kernel_size: 1
      weight_filler {
        type: "xavier"
      }
    }
  }
  layer {
    name: "fire9/relu_expand1x1"
    type: "ReLU"
    bottom: "fire9/expand1x1"
    top: "fire9/expand1x1"
  }
  layer {
    name: "fire9/expand3x3"
    type: "Convolution"
    bottom: "fire9/squeeze1x1"
    top: "fire9/expand3x3"
    convolution_param {
      num_output: 256
      pad: 1
      kernel_size: 3
      weight_filler {
        type: "xavier"
      }
    }
  }
  layer {
    name: "fire9/relu_expand3x3"
    type: "ReLU"
    bottom: "fire9/expand3x3"
    top: "fire9/expand3x3"
  }
  layer {
    name: "fire9/concat"
    type: "Concat"
    bottom: "fire9/expand1x1"
    bottom: "fire9/expand3x3"
    top: "fire9/concat"
  }
  layer {
    name: "drop9"
    type: "Dropout"
    bottom: "fire9/concat"
    top: "fire9/concat"
    dropout_param {
      dropout_ratio: 0.5
    }
  }
  layer {
    name: "conv10"
    type: "Convolution"
    bottom: "fire9/concat"
    top: "conv10"
    convolution_param {
      num_output: 1000
      pad: 1
      kernel_size: 1
      weight_filler {
        type: "gaussian"
        mean: 0
        std: 0.01
      }
    }
  }
  layer {
    name: "relu_conv10"
    type: "ReLU"
    bottom: "conv10"
    top: "conv10"
  }
  layer {
    name: "pool10"
    type: "Pooling"
    bottom: "conv10"
    top: "pool10"
    pooling_param {
      pool: AVE
      global_pooling: true
    }
  }
  layer {
    name: "loss"
    type: "SoftmaxWithLoss"
    bottom: "pool10"
    bottom: "label"
    top: "loss"
    include {
      phase: TRAIN
    }
  }
  layer {
    name: "accuracy"
    type: "Accuracy"
    bottom: "pool10"
    bottom: "label"
    top: "accuracy"
    include {
      phase: TEST
    }
  }
  layer {
    name: "accuracy_top5"
    type: "Accuracy"
    bottom: "pool10"
    bottom: "label"
    top: "accuracy_top5"
    include {
      phase: TEST
    }
    accuracy_param {
      top_k: 5
    }
  }
}
test_initialization: false
average_loss: 40
iter_size: 1
I0604 20:56:02.156497   844 solver.cpp:86] Creating training net specified in net_param.
I0604 20:56:02.156726   844 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0604 20:56:02.156770   844 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0604 20:56:02.156774   844 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy_top5
I0604 20:56:02.157274   844 net.cpp:49] Initializing net from parameters: 
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.04
    mirror: true
    crop_size: 128
    mean_value: 104
    mean_value: 117
    mean_value: 124
    force_color: true
  }
  data_param {
    source: "/local/temporary/mishkdmy/imagenet144pxlmdb/ilsvrc12_128_train_lmdb"
    batch_size: 512
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 96
    kernel_size: 7
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu_conv1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fire2/squeeze1x1"
  type: "Convolution"
  bottom: "pool1"
  top: "fire2/squeeze1x1"
  convolution_param {
    num_output: 16
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire2/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire2/squeeze1x1"
  top: "fire2/squeeze1x1"
}
layer {
  name: "fire2/expand1x1"
  type: "Convolution"
  bottom: "fire2/squeeze1x1"
  top: "fire2/expand1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire2/relu_expand1x1"
  type: "ReLU"
  bottom: "fire2/expand1x1"
  top: "fire2/expand1x1"
}
layer {
  name: "fire2/expand3x3"
  type: "Convolution"
  bottom: "fire2/squeeze1x1"
  top: "fire2/expand3x3"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire2/relu_expand3x3"
  type: "ReLU"
  bottom: "fire2/expand3x3"
  top: "fire2/expand3x3"
}
layer {
  name: "fire2/concat"
  type: "Concat"
  bottom: "fire2/expand1x1"
  bottom: "fire2/expand3x3"
  top: "fire2/concat"
}
layer {
  name: "fire3/squeeze1x1"
  type: "Convolution"
  bottom: "fire2/concat"
  top: "fire3/squeeze1x1"
  convolution_param {
    num_output: 16
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire3/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire3/squeeze1x1"
  top: "fire3/squeeze1x1"
}
layer {
  name: "fire3/expand1x1"
  type: "Convolution"
  bottom: "fire3/squeeze1x1"
  top: "fire3/expand1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire3/relu_expand1x1"
  type: "ReLU"
  bottom: "fire3/expand1x1"
  top: "fire3/expand1x1"
}
layer {
  name: "fire3/expand3x3"
  type: "Convolution"
  bottom: "fire3/squeeze1x1"
  top: "fire3/expand3x3"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire3/relu_expand3x3"
  type: "ReLU"
  bottom: "fire3/expand3x3"
  top: "fire3/expand3x3"
}
layer {
  name: "fire3/concat"
  type: "Concat"
  bottom: "fire3/expand1x1"
  bottom: "fire3/expand3x3"
  top: "fire3/concat"
}
layer {
  name: "fire4/squeeze1x1"
  type: "Convolution"
  bottom: "fire3/concat"
  top: "fire4/squeeze1x1"
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire4/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire4/squeeze1x1"
  top: "fire4/squeeze1x1"
}
layer {
  name: "fire4/expand1x1"
  type: "Convolution"
  bottom: "fire4/squeeze1x1"
  top: "fire4/expand1x1"
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire4/relu_expand1x1"
  type: "ReLU"
  bottom: "fire4/expand1x1"
  top: "fire4/expand1x1"
}
layer {
  name: "fire4/expand3x3"
  type: "Convolution"
  bottom: "fire4/squeeze1x1"
  top: "fire4/expand3x3"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire4/relu_expand3x3"
  type: "ReLU"
  bottom: "fire4/expand3x3"
  top: "fire4/expand3x3"
}
layer {
  name: "fire4/concat"
  type: "Concat"
  bottom: "fire4/expand1x1"
  bottom: "fire4/expand3x3"
  top: "fire4/concat"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "fire4/concat"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fire5/squeeze1x1"
  type: "Convolution"
  bottom: "pool4"
  top: "fire5/squeeze1x1"
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire5/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire5/squeeze1x1"
  top: "fire5/squeeze1x1"
}
layer {
  name: "fire5/expand1x1"
  type: "Convolution"
  bottom: "fire5/squeeze1x1"
  top: "fire5/expand1x1"
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire5/relu_expand1x1"
  type: "ReLU"
  bottom: "fire5/expand1x1"
  top: "fire5/expand1x1"
}
layer {
  name: "fire5/expand3x3"
  type: "Convolution"
  bottom: "fire5/squeeze1x1"
  top: "fire5/expand3x3"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire5/relu_expand3x3"
  type: "ReLU"
  bottom: "fire5/expand3x3"
  top: "fire5/expand3x3"
}
layer {
  name: "fire5/concat"
  type: "Concat"
  bottom: "fire5/expand1x1"
  bottom: "fire5/expand3x3"
  top: "fire5/concat"
}
layer {
  name: "fire6/squeeze1x1"
  type: "Convolution"
  bottom: "fire5/concat"
  top: "fire6/squeeze1x1"
  convolution_param {
    num_output: 48
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire6/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire6/squeeze1x1"
  top: "fire6/squeeze1x1"
}
layer {
  name: "fire6/expand1x1"
  type: "Convolution"
  bottom: "fire6/squeeze1x1"
  top: "fire6/expand1x1"
  convolution_param {
    num_output: 192
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire6/relu_expand1x1"
  type: "ReLU"
  bottom: "fire6/expand1x1"
  top: "fire6/expand1x1"
}
layer {
  name: "fire6/expand3x3"
  type: "Convolution"
  bottom: "fire6/squeeze1x1"
  top: "fire6/expand3x3"
  convolution_param {
    num_output: 192
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire6/relu_expand3x3"
  type: "ReLU"
  bottom: "fire6/expand3x3"
  top: "fire6/expand3x3"
}
layer {
  name: "fire6/concat"
  type: "Concat"
  bottom: "fire6/expand1x1"
  bottom: "fire6/expand3x3"
  top: "fire6/concat"
}
layer {
  name: "fire7/squeeze1x1"
  type: "Convolution"
  bottom: "fire6/concat"
  top: "fire7/squeeze1x1"
  convolution_param {
    num_output: 48
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire7/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire7/squeeze1x1"
  top: "fire7/squeeze1x1"
}
layer {
  name: "fire7/expand1x1"
  type: "Convolution"
  bottom: "fire7/squeeze1x1"
  top: "fire7/expand1x1"
  convolution_param {
    num_output: 192
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire7/relu_expand1x1"
  type: "ReLU"
  bottom: "fire7/expand1x1"
  top: "fire7/expand1x1"
}
layer {
  name: "fire7/expand3x3"
  type: "Convolution"
  bottom: "fire7/squeeze1x1"
  top: "fire7/expand3x3"
  convolution_param {
    num_output: 192
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire7/relu_expand3x3"
  type: "ReLU"
  bottom: "fire7/expand3x3"
  top: "fire7/expand3x3"
}
layer {
  name: "fire7/concat"
  type: "Concat"
  bottom: "fire7/expand1x1"
  bottom: "fire7/expand3x3"
  top: "fire7/concat"
}
layer {
  name: "fire8/squeeze1x1"
  type: "Convolution"
  bottom: "fire7/concat"
  top: "fire8/squeeze1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire8/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire8/squeeze1x1"
  top: "fire8/squeeze1x1"
}
layer {
  name: "fire8/expand1x1"
  type: "Convolution"
  bottom: "fire8/squeeze1x1"
  top: "fire8/expand1x1"
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire8/relu_expand1x1"
  type: "ReLU"
  bottom: "fire8/expand1x1"
  top: "fire8/expand1x1"
}
layer {
  name: "fire8/expand3x3"
  type: "Convolution"
  bottom: "fire8/squeeze1x1"
  top: "fire8/expand3x3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire8/relu_expand3x3"
  type: "ReLU"
  bottom: "fire8/expand3x3"
  top: "fire8/expand3x3"
}
layer {
  name: "fire8/concat"
  type: "Concat"
  bottom: "fire8/expand1x1"
  bottom: "fire8/expand3x3"
  top: "fire8/concat"
}
layer {
  name: "pool8"
  type: "Pooling"
  bottom: "fire8/concat"
  top: "pool8"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fire9/squeeze1x1"
  type: "Convolution"
  bottom: "pool8"
  top: "fire9/squeeze1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire9/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire9/squeeze1x1"
  top: "fire9/squeeze1x1"
}
layer {
  name: "fire9/expand1x1"
  type: "Convolution"
  bottom: "fire9/squeeze1x1"
  top: "fire9/expand1x1"
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire9/relu_expand1x1"
  type: "ReLU"
  bottom: "fire9/expand1x1"
  top: "fire9/expand1x1"
}
layer {
  name: "fire9/expand3x3"
  type: "Convolution"
  bottom: "fire9/squeeze1x1"
  top: "fire9/expand3x3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire9/relu_expand3x3"
  type: "ReLU"
  bottom: "fire9/expand3x3"
  top: "fire9/expand3x3"
}
layer {
  name: "fire9/concat"
  type: "Concat"
  bottom: "fire9/expand1x1"
  bottom: "fire9/expand3x3"
  top: "fire9/concat"
}
layer {
  name: "drop9"
  type: "Dropout"
  bottom: "fire9/concat"
  top: "fire9/concat"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "conv10"
  type: "Convolution"
  bottom: "fire9/concat"
  top: "conv10"
  convolution_param {
    num_output: 1000
    pad: 1
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      mean: 0
      std: 0.01
    }
  }
}
layer {
  name: "relu_conv10"
  type: "ReLU"
  bottom: "conv10"
  top: "conv10"
}
layer {
  name: "pool10"
  type: "Pooling"
  bottom: "conv10"
  top: "pool10"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "pool10"
  bottom: "label"
  top: "loss"
  include {
    phase: TRAIN
  }
}
I0604 20:56:02.157644   844 layer_factory.hpp:77] Creating layer data
I0604 20:56:02.158129   844 net.cpp:106] Creating Layer data
I0604 20:56:02.158143   844 net.cpp:411] data -> data
I0604 20:56:02.158172   844 net.cpp:411] data -> label
I0604 20:56:02.159256   873 db_lmdb.cpp:38] Opened lmdb /local/temporary/mishkdmy/imagenet144pxlmdb/ilsvrc12_128_train_lmdb
I0604 20:56:02.217015   844 data_layer.cpp:41] output data size: 512,3,128,128
I0604 20:56:02.425575   844 net.cpp:150] Setting up data
I0604 20:56:02.425609   844 net.cpp:157] Top shape: 512 3 128 128 (25165824)
I0604 20:56:02.425614   844 net.cpp:157] Top shape: 512 (512)
I0604 20:56:02.425617   844 net.cpp:165] Memory required for data: 100665344
I0604 20:56:02.425629   844 layer_factory.hpp:77] Creating layer conv1
I0604 20:56:02.425655   844 net.cpp:106] Creating Layer conv1
I0604 20:56:02.425663   844 net.cpp:454] conv1 <- data
I0604 20:56:02.425693   844 net.cpp:411] conv1 -> conv1
I0604 20:56:02.710000   844 net.cpp:150] Setting up conv1
I0604 20:56:02.710038   844 net.cpp:157] Top shape: 512 96 61 61 (182894592)
I0604 20:56:02.710043   844 net.cpp:165] Memory required for data: 832243712
I0604 20:56:02.710063   844 layer_factory.hpp:77] Creating layer relu_conv1
I0604 20:56:02.710078   844 net.cpp:106] Creating Layer relu_conv1
I0604 20:56:02.710085   844 net.cpp:454] relu_conv1 <- conv1
I0604 20:56:02.710099   844 net.cpp:397] relu_conv1 -> conv1 (in-place)
I0604 20:56:02.711900   844 net.cpp:150] Setting up relu_conv1
I0604 20:56:02.711913   844 net.cpp:157] Top shape: 512 96 61 61 (182894592)
I0604 20:56:02.711917   844 net.cpp:165] Memory required for data: 1563822080
I0604 20:56:02.711921   844 layer_factory.hpp:77] Creating layer pool1
I0604 20:56:02.711930   844 net.cpp:106] Creating Layer pool1
I0604 20:56:02.711935   844 net.cpp:454] pool1 <- conv1
I0604 20:56:02.711941   844 net.cpp:411] pool1 -> pool1
I0604 20:56:02.712004   844 net.cpp:150] Setting up pool1
I0604 20:56:02.712013   844 net.cpp:157] Top shape: 512 96 30 30 (44236800)
I0604 20:56:02.712018   844 net.cpp:165] Memory required for data: 1740769280
I0604 20:56:02.712020   844 layer_factory.hpp:77] Creating layer fire2/squeeze1x1
I0604 20:56:02.712034   844 net.cpp:106] Creating Layer fire2/squeeze1x1
I0604 20:56:02.712039   844 net.cpp:454] fire2/squeeze1x1 <- pool1
I0604 20:56:02.712045   844 net.cpp:411] fire2/squeeze1x1 -> fire2/squeeze1x1
I0604 20:56:02.715596   844 net.cpp:150] Setting up fire2/squeeze1x1
I0604 20:56:02.715617   844 net.cpp:157] Top shape: 512 16 30 30 (7372800)
I0604 20:56:02.715621   844 net.cpp:165] Memory required for data: 1770260480
I0604 20:56:02.715633   844 layer_factory.hpp:77] Creating layer fire2/relu_squeeze1x1
I0604 20:56:02.715641   844 net.cpp:106] Creating Layer fire2/relu_squeeze1x1
I0604 20:56:02.715644   844 net.cpp:454] fire2/relu_squeeze1x1 <- fire2/squeeze1x1
I0604 20:56:02.715651   844 net.cpp:397] fire2/relu_squeeze1x1 -> fire2/squeeze1x1 (in-place)
I0604 20:56:02.716542   844 net.cpp:150] Setting up fire2/relu_squeeze1x1
I0604 20:56:02.716554   844 net.cpp:157] Top shape: 512 16 30 30 (7372800)
I0604 20:56:02.716564   844 net.cpp:165] Memory required for data: 1799751680
I0604 20:56:02.716568   844 layer_factory.hpp:77] Creating layer fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I0604 20:56:02.716576   844 net.cpp:106] Creating Layer fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I0604 20:56:02.716580   844 net.cpp:454] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split <- fire2/squeeze1x1
I0604 20:56:02.716588   844 net.cpp:411] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split -> fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_0
I0604 20:56:02.716595   844 net.cpp:411] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split -> fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_1
I0604 20:56:02.716675   844 net.cpp:150] Setting up fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I0604 20:56:02.716683   844 net.cpp:157] Top shape: 512 16 30 30 (7372800)
I0604 20:56:02.716688   844 net.cpp:157] Top shape: 512 16 30 30 (7372800)
I0604 20:56:02.716692   844 net.cpp:165] Memory required for data: 1858734080
I0604 20:56:02.716696   844 layer_factory.hpp:77] Creating layer fire2/expand1x1
I0604 20:56:02.716706   844 net.cpp:106] Creating Layer fire2/expand1x1
I0604 20:56:02.716711   844 net.cpp:454] fire2/expand1x1 <- fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_0
I0604 20:56:02.716717   844 net.cpp:411] fire2/expand1x1 -> fire2/expand1x1
I0604 20:56:02.719179   844 net.cpp:150] Setting up fire2/expand1x1
I0604 20:56:02.719197   844 net.cpp:157] Top shape: 512 64 30 30 (29491200)
I0604 20:56:02.719204   844 net.cpp:165] Memory required for data: 1976698880
I0604 20:56:02.719218   844 layer_factory.hpp:77] Creating layer fire2/relu_expand1x1
I0604 20:56:02.719229   844 net.cpp:106] Creating Layer fire2/relu_expand1x1
I0604 20:56:02.719233   844 net.cpp:454] fire2/relu_expand1x1 <- fire2/expand1x1
I0604 20:56:02.719238   844 net.cpp:397] fire2/relu_expand1x1 -> fire2/expand1x1 (in-place)
I0604 20:56:02.720451   844 net.cpp:150] Setting up fire2/relu_expand1x1
I0604 20:56:02.720468   844 net.cpp:157] Top shape: 512 64 30 30 (29491200)
I0604 20:56:02.720471   844 net.cpp:165] Memory required for data: 2094663680
I0604 20:56:02.720479   844 layer_factory.hpp:77] Creating layer fire2/expand3x3
I0604 20:56:02.720487   844 net.cpp:106] Creating Layer fire2/expand3x3
I0604 20:56:02.720491   844 net.cpp:454] fire2/expand3x3 <- fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_1
I0604 20:56:02.720502   844 net.cpp:411] fire2/expand3x3 -> fire2/expand3x3
I0604 20:56:02.724951   844 net.cpp:150] Setting up fire2/expand3x3
I0604 20:56:02.724974   844 net.cpp:157] Top shape: 512 64 30 30 (29491200)
I0604 20:56:02.724979   844 net.cpp:165] Memory required for data: 2212628480
I0604 20:56:02.724992   844 layer_factory.hpp:77] Creating layer fire2/relu_expand3x3
I0604 20:56:02.725003   844 net.cpp:106] Creating Layer fire2/relu_expand3x3
I0604 20:56:02.725009   844 net.cpp:454] fire2/relu_expand3x3 <- fire2/expand3x3
I0604 20:56:02.725026   844 net.cpp:397] fire2/relu_expand3x3 -> fire2/expand3x3 (in-place)
I0604 20:56:02.726109   844 net.cpp:150] Setting up fire2/relu_expand3x3
I0604 20:56:02.726125   844 net.cpp:157] Top shape: 512 64 30 30 (29491200)
I0604 20:56:02.726130   844 net.cpp:165] Memory required for data: 2330593280
I0604 20:56:02.726136   844 layer_factory.hpp:77] Creating layer fire2/concat
I0604 20:56:02.726153   844 net.cpp:106] Creating Layer fire2/concat
I0604 20:56:02.726166   844 net.cpp:454] fire2/concat <- fire2/expand1x1
I0604 20:56:02.726174   844 net.cpp:454] fire2/concat <- fire2/expand3x3
I0604 20:56:02.726188   844 net.cpp:411] fire2/concat -> fire2/concat
I0604 20:56:02.726234   844 net.cpp:150] Setting up fire2/concat
I0604 20:56:02.726245   844 net.cpp:157] Top shape: 512 128 30 30 (58982400)
I0604 20:56:02.726250   844 net.cpp:165] Memory required for data: 2566522880
I0604 20:56:02.726258   844 layer_factory.hpp:77] Creating layer fire3/squeeze1x1
I0604 20:56:02.726280   844 net.cpp:106] Creating Layer fire3/squeeze1x1
I0604 20:56:02.726286   844 net.cpp:454] fire3/squeeze1x1 <- fire2/concat
I0604 20:56:02.726297   844 net.cpp:411] fire3/squeeze1x1 -> fire3/squeeze1x1
I0604 20:56:02.730255   844 net.cpp:150] Setting up fire3/squeeze1x1
I0604 20:56:02.730278   844 net.cpp:157] Top shape: 512 16 30 30 (7372800)
I0604 20:56:02.730284   844 net.cpp:165] Memory required for data: 2596014080
I0604 20:56:02.730304   844 layer_factory.hpp:77] Creating layer fire3/relu_squeeze1x1
I0604 20:56:02.730322   844 net.cpp:106] Creating Layer fire3/relu_squeeze1x1
I0604 20:56:02.730330   844 net.cpp:454] fire3/relu_squeeze1x1 <- fire3/squeeze1x1
I0604 20:56:02.730342   844 net.cpp:397] fire3/relu_squeeze1x1 -> fire3/squeeze1x1 (in-place)
I0604 20:56:02.731269   844 net.cpp:150] Setting up fire3/relu_squeeze1x1
I0604 20:56:02.731286   844 net.cpp:157] Top shape: 512 16 30 30 (7372800)
I0604 20:56:02.731292   844 net.cpp:165] Memory required for data: 2625505280
I0604 20:56:02.731298   844 layer_factory.hpp:77] Creating layer fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I0604 20:56:02.731312   844 net.cpp:106] Creating Layer fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I0604 20:56:02.731317   844 net.cpp:454] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split <- fire3/squeeze1x1
I0604 20:56:02.731326   844 net.cpp:411] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split -> fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_0
I0604 20:56:02.731334   844 net.cpp:411] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split -> fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_1
I0604 20:56:02.731387   844 net.cpp:150] Setting up fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I0604 20:56:02.731396   844 net.cpp:157] Top shape: 512 16 30 30 (7372800)
I0604 20:56:02.731401   844 net.cpp:157] Top shape: 512 16 30 30 (7372800)
I0604 20:56:02.731405   844 net.cpp:165] Memory required for data: 2684487680
I0604 20:56:02.731408   844 layer_factory.hpp:77] Creating layer fire3/expand1x1
I0604 20:56:02.731417   844 net.cpp:106] Creating Layer fire3/expand1x1
I0604 20:56:02.731423   844 net.cpp:454] fire3/expand1x1 <- fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_0
I0604 20:56:02.731431   844 net.cpp:411] fire3/expand1x1 -> fire3/expand1x1
I0604 20:56:02.735846   844 net.cpp:150] Setting up fire3/expand1x1
I0604 20:56:02.735859   844 net.cpp:157] Top shape: 512 64 30 30 (29491200)
I0604 20:56:02.735863   844 net.cpp:165] Memory required for data: 2802452480
I0604 20:56:02.735872   844 layer_factory.hpp:77] Creating layer fire3/relu_expand1x1
I0604 20:56:02.735880   844 net.cpp:106] Creating Layer fire3/relu_expand1x1
I0604 20:56:02.735884   844 net.cpp:454] fire3/relu_expand1x1 <- fire3/expand1x1
I0604 20:56:02.735891   844 net.cpp:397] fire3/relu_expand1x1 -> fire3/expand1x1 (in-place)
I0604 20:56:02.736876   844 net.cpp:150] Setting up fire3/relu_expand1x1
I0604 20:56:02.736887   844 net.cpp:157] Top shape: 512 64 30 30 (29491200)
I0604 20:56:02.736891   844 net.cpp:165] Memory required for data: 2920417280
I0604 20:56:02.736894   844 layer_factory.hpp:77] Creating layer fire3/expand3x3
I0604 20:56:02.736902   844 net.cpp:106] Creating Layer fire3/expand3x3
I0604 20:56:02.736907   844 net.cpp:454] fire3/expand3x3 <- fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_1
I0604 20:56:02.736914   844 net.cpp:411] fire3/expand3x3 -> fire3/expand3x3
I0604 20:56:02.740543   844 net.cpp:150] Setting up fire3/expand3x3
I0604 20:56:02.740556   844 net.cpp:157] Top shape: 512 64 30 30 (29491200)
I0604 20:56:02.740559   844 net.cpp:165] Memory required for data: 3038382080
I0604 20:56:02.740567   844 layer_factory.hpp:77] Creating layer fire3/relu_expand3x3
I0604 20:56:02.740576   844 net.cpp:106] Creating Layer fire3/relu_expand3x3
I0604 20:56:02.740579   844 net.cpp:454] fire3/relu_expand3x3 <- fire3/expand3x3
I0604 20:56:02.740586   844 net.cpp:397] fire3/relu_expand3x3 -> fire3/expand3x3 (in-place)
I0604 20:56:02.741480   844 net.cpp:150] Setting up fire3/relu_expand3x3
I0604 20:56:02.741492   844 net.cpp:157] Top shape: 512 64 30 30 (29491200)
I0604 20:56:02.741495   844 net.cpp:165] Memory required for data: 3156346880
I0604 20:56:02.741499   844 layer_factory.hpp:77] Creating layer fire3/concat
I0604 20:56:02.741508   844 net.cpp:106] Creating Layer fire3/concat
I0604 20:56:02.741511   844 net.cpp:454] fire3/concat <- fire3/expand1x1
I0604 20:56:02.741516   844 net.cpp:454] fire3/concat <- fire3/expand3x3
I0604 20:56:02.741521   844 net.cpp:411] fire3/concat -> fire3/concat
I0604 20:56:02.741556   844 net.cpp:150] Setting up fire3/concat
I0604 20:56:02.741564   844 net.cpp:157] Top shape: 512 128 30 30 (58982400)
I0604 20:56:02.741567   844 net.cpp:165] Memory required for data: 3392276480
I0604 20:56:02.741570   844 layer_factory.hpp:77] Creating layer fire4/squeeze1x1
I0604 20:56:02.741595   844 net.cpp:106] Creating Layer fire4/squeeze1x1
I0604 20:56:02.741600   844 net.cpp:454] fire4/squeeze1x1 <- fire3/concat
I0604 20:56:02.741605   844 net.cpp:411] fire4/squeeze1x1 -> fire4/squeeze1x1
I0604 20:56:02.745127   844 net.cpp:150] Setting up fire4/squeeze1x1
I0604 20:56:02.745141   844 net.cpp:157] Top shape: 512 32 30 30 (14745600)
I0604 20:56:02.745144   844 net.cpp:165] Memory required for data: 3451258880
I0604 20:56:02.745156   844 layer_factory.hpp:77] Creating layer fire4/relu_squeeze1x1
I0604 20:56:02.745162   844 net.cpp:106] Creating Layer fire4/relu_squeeze1x1
I0604 20:56:02.745167   844 net.cpp:454] fire4/relu_squeeze1x1 <- fire4/squeeze1x1
I0604 20:56:02.745174   844 net.cpp:397] fire4/relu_squeeze1x1 -> fire4/squeeze1x1 (in-place)
I0604 20:56:02.746196   844 net.cpp:150] Setting up fire4/relu_squeeze1x1
I0604 20:56:02.746207   844 net.cpp:157] Top shape: 512 32 30 30 (14745600)
I0604 20:56:02.746211   844 net.cpp:165] Memory required for data: 3510241280
I0604 20:56:02.746214   844 layer_factory.hpp:77] Creating layer fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I0604 20:56:02.746222   844 net.cpp:106] Creating Layer fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I0604 20:56:02.746227   844 net.cpp:454] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split <- fire4/squeeze1x1
I0604 20:56:02.746232   844 net.cpp:411] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split -> fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_0
I0604 20:56:02.746239   844 net.cpp:411] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split -> fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_1
I0604 20:56:02.746287   844 net.cpp:150] Setting up fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I0604 20:56:02.746294   844 net.cpp:157] Top shape: 512 32 30 30 (14745600)
I0604 20:56:02.746299   844 net.cpp:157] Top shape: 512 32 30 30 (14745600)
I0604 20:56:02.746300   844 net.cpp:165] Memory required for data: 3628206080
I0604 20:56:02.746304   844 layer_factory.hpp:77] Creating layer fire4/expand1x1
I0604 20:56:02.746321   844 net.cpp:106] Creating Layer fire4/expand1x1
I0604 20:56:02.746325   844 net.cpp:454] fire4/expand1x1 <- fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_0
I0604 20:56:02.746331   844 net.cpp:411] fire4/expand1x1 -> fire4/expand1x1
I0604 20:56:02.749830   844 net.cpp:150] Setting up fire4/expand1x1
I0604 20:56:02.749842   844 net.cpp:157] Top shape: 512 128 30 30 (58982400)
I0604 20:56:02.749845   844 net.cpp:165] Memory required for data: 3864135680
I0604 20:56:02.749857   844 layer_factory.hpp:77] Creating layer fire4/relu_expand1x1
I0604 20:56:02.749864   844 net.cpp:106] Creating Layer fire4/relu_expand1x1
I0604 20:56:02.749869   844 net.cpp:454] fire4/relu_expand1x1 <- fire4/expand1x1
I0604 20:56:02.749876   844 net.cpp:397] fire4/relu_expand1x1 -> fire4/expand1x1 (in-place)
I0604 20:56:02.750900   844 net.cpp:150] Setting up fire4/relu_expand1x1
I0604 20:56:02.750908   844 net.cpp:157] Top shape: 512 128 30 30 (58982400)
I0604 20:56:02.750911   844 net.cpp:165] Memory required for data: 4100065280
I0604 20:56:02.750916   844 layer_factory.hpp:77] Creating layer fire4/expand3x3
I0604 20:56:02.750926   844 net.cpp:106] Creating Layer fire4/expand3x3
I0604 20:56:02.750929   844 net.cpp:454] fire4/expand3x3 <- fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_1
I0604 20:56:02.750936   844 net.cpp:411] fire4/expand3x3 -> fire4/expand3x3
I0604 20:56:02.754547   844 net.cpp:150] Setting up fire4/expand3x3
I0604 20:56:02.754561   844 net.cpp:157] Top shape: 512 128 30 30 (58982400)
I0604 20:56:02.754565   844 net.cpp:165] Memory required for data: 4335994880
I0604 20:56:02.754572   844 layer_factory.hpp:77] Creating layer fire4/relu_expand3x3
I0604 20:56:02.754580   844 net.cpp:106] Creating Layer fire4/relu_expand3x3
I0604 20:56:02.754585   844 net.cpp:454] fire4/relu_expand3x3 <- fire4/expand3x3
I0604 20:56:02.754590   844 net.cpp:397] fire4/relu_expand3x3 -> fire4/expand3x3 (in-place)
I0604 20:56:02.756645   844 net.cpp:150] Setting up fire4/relu_expand3x3
I0604 20:56:02.756657   844 net.cpp:157] Top shape: 512 128 30 30 (58982400)
I0604 20:56:02.756675   844 net.cpp:165] Memory required for data: 4571924480
I0604 20:56:02.756680   844 layer_factory.hpp:77] Creating layer fire4/concat
I0604 20:56:02.756687   844 net.cpp:106] Creating Layer fire4/concat
I0604 20:56:02.756691   844 net.cpp:454] fire4/concat <- fire4/expand1x1
I0604 20:56:02.756696   844 net.cpp:454] fire4/concat <- fire4/expand3x3
I0604 20:56:02.756701   844 net.cpp:411] fire4/concat -> fire4/concat
I0604 20:56:02.756736   844 net.cpp:150] Setting up fire4/concat
I0604 20:56:02.756744   844 net.cpp:157] Top shape: 512 256 30 30 (117964800)
I0604 20:56:02.756748   844 net.cpp:165] Memory required for data: 5043783680
I0604 20:56:02.756752   844 layer_factory.hpp:77] Creating layer pool4
I0604 20:56:02.756758   844 net.cpp:106] Creating Layer pool4
I0604 20:56:02.756762   844 net.cpp:454] pool4 <- fire4/concat
I0604 20:56:02.756769   844 net.cpp:411] pool4 -> pool4
I0604 20:56:02.756811   844 net.cpp:150] Setting up pool4
I0604 20:56:02.756819   844 net.cpp:157] Top shape: 512 256 15 15 (29491200)
I0604 20:56:02.756822   844 net.cpp:165] Memory required for data: 5161748480
I0604 20:56:02.756825   844 layer_factory.hpp:77] Creating layer fire5/squeeze1x1
I0604 20:56:02.756834   844 net.cpp:106] Creating Layer fire5/squeeze1x1
I0604 20:56:02.756836   844 net.cpp:454] fire5/squeeze1x1 <- pool4
I0604 20:56:02.756844   844 net.cpp:411] fire5/squeeze1x1 -> fire5/squeeze1x1
I0604 20:56:02.761343   844 net.cpp:150] Setting up fire5/squeeze1x1
I0604 20:56:02.761358   844 net.cpp:157] Top shape: 512 32 15 15 (3686400)
I0604 20:56:02.761361   844 net.cpp:165] Memory required for data: 5176494080
I0604 20:56:02.761368   844 layer_factory.hpp:77] Creating layer fire5/relu_squeeze1x1
I0604 20:56:02.761375   844 net.cpp:106] Creating Layer fire5/relu_squeeze1x1
I0604 20:56:02.761379   844 net.cpp:454] fire5/relu_squeeze1x1 <- fire5/squeeze1x1
I0604 20:56:02.761384   844 net.cpp:397] fire5/relu_squeeze1x1 -> fire5/squeeze1x1 (in-place)
I0604 20:56:02.762406   844 net.cpp:150] Setting up fire5/relu_squeeze1x1
I0604 20:56:02.762418   844 net.cpp:157] Top shape: 512 32 15 15 (3686400)
I0604 20:56:02.762423   844 net.cpp:165] Memory required for data: 5191239680
I0604 20:56:02.762425   844 layer_factory.hpp:77] Creating layer fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I0604 20:56:02.762433   844 net.cpp:106] Creating Layer fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I0604 20:56:02.762435   844 net.cpp:454] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split <- fire5/squeeze1x1
I0604 20:56:02.762440   844 net.cpp:411] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split -> fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_0
I0604 20:56:02.762450   844 net.cpp:411] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split -> fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_1
I0604 20:56:02.762500   844 net.cpp:150] Setting up fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I0604 20:56:02.762506   844 net.cpp:157] Top shape: 512 32 15 15 (3686400)
I0604 20:56:02.762509   844 net.cpp:157] Top shape: 512 32 15 15 (3686400)
I0604 20:56:02.762512   844 net.cpp:165] Memory required for data: 5220730880
I0604 20:56:02.762516   844 layer_factory.hpp:77] Creating layer fire5/expand1x1
I0604 20:56:02.762534   844 net.cpp:106] Creating Layer fire5/expand1x1
I0604 20:56:02.762539   844 net.cpp:454] fire5/expand1x1 <- fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_0
I0604 20:56:02.762545   844 net.cpp:411] fire5/expand1x1 -> fire5/expand1x1
I0604 20:56:02.766070   844 net.cpp:150] Setting up fire5/expand1x1
I0604 20:56:02.766084   844 net.cpp:157] Top shape: 512 128 15 15 (14745600)
I0604 20:56:02.766088   844 net.cpp:165] Memory required for data: 5279713280
I0604 20:56:02.766095   844 layer_factory.hpp:77] Creating layer fire5/relu_expand1x1
I0604 20:56:02.766103   844 net.cpp:106] Creating Layer fire5/relu_expand1x1
I0604 20:56:02.766108   844 net.cpp:454] fire5/relu_expand1x1 <- fire5/expand1x1
I0604 20:56:02.766114   844 net.cpp:397] fire5/relu_expand1x1 -> fire5/expand1x1 (in-place)
I0604 20:56:02.767130   844 net.cpp:150] Setting up fire5/relu_expand1x1
I0604 20:56:02.767141   844 net.cpp:157] Top shape: 512 128 15 15 (14745600)
I0604 20:56:02.767144   844 net.cpp:165] Memory required for data: 5338695680
I0604 20:56:02.767148   844 layer_factory.hpp:77] Creating layer fire5/expand3x3
I0604 20:56:02.767158   844 net.cpp:106] Creating Layer fire5/expand3x3
I0604 20:56:02.767163   844 net.cpp:454] fire5/expand3x3 <- fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_1
I0604 20:56:02.767171   844 net.cpp:411] fire5/expand3x3 -> fire5/expand3x3
I0604 20:56:02.771807   844 net.cpp:150] Setting up fire5/expand3x3
I0604 20:56:02.771821   844 net.cpp:157] Top shape: 512 128 15 15 (14745600)
I0604 20:56:02.771824   844 net.cpp:165] Memory required for data: 5397678080
I0604 20:56:02.771831   844 layer_factory.hpp:77] Creating layer fire5/relu_expand3x3
I0604 20:56:02.771839   844 net.cpp:106] Creating Layer fire5/relu_expand3x3
I0604 20:56:02.771843   844 net.cpp:454] fire5/relu_expand3x3 <- fire5/expand3x3
I0604 20:56:02.771849   844 net.cpp:397] fire5/relu_expand3x3 -> fire5/expand3x3 (in-place)
I0604 20:56:02.772867   844 net.cpp:150] Setting up fire5/relu_expand3x3
I0604 20:56:02.772881   844 net.cpp:157] Top shape: 512 128 15 15 (14745600)
I0604 20:56:02.772884   844 net.cpp:165] Memory required for data: 5456660480
I0604 20:56:02.772888   844 layer_factory.hpp:77] Creating layer fire5/concat
I0604 20:56:02.772894   844 net.cpp:106] Creating Layer fire5/concat
I0604 20:56:02.772897   844 net.cpp:454] fire5/concat <- fire5/expand1x1
I0604 20:56:02.772902   844 net.cpp:454] fire5/concat <- fire5/expand3x3
I0604 20:56:02.772909   844 net.cpp:411] fire5/concat -> fire5/concat
I0604 20:56:02.772943   844 net.cpp:150] Setting up fire5/concat
I0604 20:56:02.772950   844 net.cpp:157] Top shape: 512 256 15 15 (29491200)
I0604 20:56:02.772953   844 net.cpp:165] Memory required for data: 5574625280
I0604 20:56:02.772956   844 layer_factory.hpp:77] Creating layer fire6/squeeze1x1
I0604 20:56:02.772969   844 net.cpp:106] Creating Layer fire6/squeeze1x1
I0604 20:56:02.772974   844 net.cpp:454] fire6/squeeze1x1 <- fire5/concat
I0604 20:56:02.772980   844 net.cpp:411] fire6/squeeze1x1 -> fire6/squeeze1x1
I0604 20:56:02.776522   844 net.cpp:150] Setting up fire6/squeeze1x1
I0604 20:56:02.776535   844 net.cpp:157] Top shape: 512 48 15 15 (5529600)
I0604 20:56:02.776540   844 net.cpp:165] Memory required for data: 5596743680
I0604 20:56:02.776546   844 layer_factory.hpp:77] Creating layer fire6/relu_squeeze1x1
I0604 20:56:02.776552   844 net.cpp:106] Creating Layer fire6/relu_squeeze1x1
I0604 20:56:02.776556   844 net.cpp:454] fire6/relu_squeeze1x1 <- fire6/squeeze1x1
I0604 20:56:02.776563   844 net.cpp:397] fire6/relu_squeeze1x1 -> fire6/squeeze1x1 (in-place)
I0604 20:56:02.777572   844 net.cpp:150] Setting up fire6/relu_squeeze1x1
I0604 20:56:02.777585   844 net.cpp:157] Top shape: 512 48 15 15 (5529600)
I0604 20:56:02.777587   844 net.cpp:165] Memory required for data: 5618862080
I0604 20:56:02.777591   844 layer_factory.hpp:77] Creating layer fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I0604 20:56:02.777597   844 net.cpp:106] Creating Layer fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I0604 20:56:02.777601   844 net.cpp:454] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split <- fire6/squeeze1x1
I0604 20:56:02.777608   844 net.cpp:411] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split -> fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_0
I0604 20:56:02.777616   844 net.cpp:411] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split -> fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_1
I0604 20:56:02.777663   844 net.cpp:150] Setting up fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I0604 20:56:02.777670   844 net.cpp:157] Top shape: 512 48 15 15 (5529600)
I0604 20:56:02.777674   844 net.cpp:157] Top shape: 512 48 15 15 (5529600)
I0604 20:56:02.777678   844 net.cpp:165] Memory required for data: 5663098880
I0604 20:56:02.777680   844 layer_factory.hpp:77] Creating layer fire6/expand1x1
I0604 20:56:02.777693   844 net.cpp:106] Creating Layer fire6/expand1x1
I0604 20:56:02.777712   844 net.cpp:454] fire6/expand1x1 <- fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_0
I0604 20:56:02.777719   844 net.cpp:411] fire6/expand1x1 -> fire6/expand1x1
I0604 20:56:02.781224   844 net.cpp:150] Setting up fire6/expand1x1
I0604 20:56:02.781242   844 net.cpp:157] Top shape: 512 192 15 15 (22118400)
I0604 20:56:02.781249   844 net.cpp:165] Memory required for data: 5751572480
I0604 20:56:02.781257   844 layer_factory.hpp:77] Creating layer fire6/relu_expand1x1
I0604 20:56:02.781265   844 net.cpp:106] Creating Layer fire6/relu_expand1x1
I0604 20:56:02.781267   844 net.cpp:454] fire6/relu_expand1x1 <- fire6/expand1x1
I0604 20:56:02.781275   844 net.cpp:397] fire6/relu_expand1x1 -> fire6/expand1x1 (in-place)
I0604 20:56:02.782274   844 net.cpp:150] Setting up fire6/relu_expand1x1
I0604 20:56:02.782284   844 net.cpp:157] Top shape: 512 192 15 15 (22118400)
I0604 20:56:02.782286   844 net.cpp:165] Memory required for data: 5840046080
I0604 20:56:02.782290   844 layer_factory.hpp:77] Creating layer fire6/expand3x3
I0604 20:56:02.782300   844 net.cpp:106] Creating Layer fire6/expand3x3
I0604 20:56:02.782304   844 net.cpp:454] fire6/expand3x3 <- fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_1
I0604 20:56:02.782311   844 net.cpp:411] fire6/expand3x3 -> fire6/expand3x3
I0604 20:56:02.786986   844 net.cpp:150] Setting up fire6/expand3x3
I0604 20:56:02.787001   844 net.cpp:157] Top shape: 512 192 15 15 (22118400)
I0604 20:56:02.787005   844 net.cpp:165] Memory required for data: 5928519680
I0604 20:56:02.787012   844 layer_factory.hpp:77] Creating layer fire6/relu_expand3x3
I0604 20:56:02.787020   844 net.cpp:106] Creating Layer fire6/relu_expand3x3
I0604 20:56:02.787024   844 net.cpp:454] fire6/relu_expand3x3 <- fire6/expand3x3
I0604 20:56:02.787032   844 net.cpp:397] fire6/relu_expand3x3 -> fire6/expand3x3 (in-place)
I0604 20:56:02.788041   844 net.cpp:150] Setting up fire6/relu_expand3x3
I0604 20:56:02.788053   844 net.cpp:157] Top shape: 512 192 15 15 (22118400)
I0604 20:56:02.788056   844 net.cpp:165] Memory required for data: 6016993280
I0604 20:56:02.788060   844 layer_factory.hpp:77] Creating layer fire6/concat
I0604 20:56:02.788067   844 net.cpp:106] Creating Layer fire6/concat
I0604 20:56:02.788070   844 net.cpp:454] fire6/concat <- fire6/expand1x1
I0604 20:56:02.788075   844 net.cpp:454] fire6/concat <- fire6/expand3x3
I0604 20:56:02.788082   844 net.cpp:411] fire6/concat -> fire6/concat
I0604 20:56:02.788125   844 net.cpp:150] Setting up fire6/concat
I0604 20:56:02.788131   844 net.cpp:157] Top shape: 512 384 15 15 (44236800)
I0604 20:56:02.788135   844 net.cpp:165] Memory required for data: 6193940480
I0604 20:56:02.788137   844 layer_factory.hpp:77] Creating layer fire7/squeeze1x1
I0604 20:56:02.788146   844 net.cpp:106] Creating Layer fire7/squeeze1x1
I0604 20:56:02.788149   844 net.cpp:454] fire7/squeeze1x1 <- fire6/concat
I0604 20:56:02.788156   844 net.cpp:411] fire7/squeeze1x1 -> fire7/squeeze1x1
I0604 20:56:02.791681   844 net.cpp:150] Setting up fire7/squeeze1x1
I0604 20:56:02.791693   844 net.cpp:157] Top shape: 512 48 15 15 (5529600)
I0604 20:56:02.791697   844 net.cpp:165] Memory required for data: 6216058880
I0604 20:56:02.791713   844 layer_factory.hpp:77] Creating layer fire7/relu_squeeze1x1
I0604 20:56:02.791723   844 net.cpp:106] Creating Layer fire7/relu_squeeze1x1
I0604 20:56:02.791729   844 net.cpp:454] fire7/relu_squeeze1x1 <- fire7/squeeze1x1
I0604 20:56:02.791734   844 net.cpp:397] fire7/relu_squeeze1x1 -> fire7/squeeze1x1 (in-place)
I0604 20:56:02.792734   844 net.cpp:150] Setting up fire7/relu_squeeze1x1
I0604 20:56:02.792747   844 net.cpp:157] Top shape: 512 48 15 15 (5529600)
I0604 20:56:02.792750   844 net.cpp:165] Memory required for data: 6238177280
I0604 20:56:02.792753   844 layer_factory.hpp:77] Creating layer fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I0604 20:56:02.792760   844 net.cpp:106] Creating Layer fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I0604 20:56:02.792763   844 net.cpp:454] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split <- fire7/squeeze1x1
I0604 20:56:02.792786   844 net.cpp:411] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split -> fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_0
I0604 20:56:02.792794   844 net.cpp:411] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split -> fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_1
I0604 20:56:02.792845   844 net.cpp:150] Setting up fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I0604 20:56:02.792852   844 net.cpp:157] Top shape: 512 48 15 15 (5529600)
I0604 20:56:02.792857   844 net.cpp:157] Top shape: 512 48 15 15 (5529600)
I0604 20:56:02.792860   844 net.cpp:165] Memory required for data: 6282414080
I0604 20:56:02.792863   844 layer_factory.hpp:77] Creating layer fire7/expand1x1
I0604 20:56:02.792873   844 net.cpp:106] Creating Layer fire7/expand1x1
I0604 20:56:02.792878   844 net.cpp:454] fire7/expand1x1 <- fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_0
I0604 20:56:02.792884   844 net.cpp:411] fire7/expand1x1 -> fire7/expand1x1
I0604 20:56:02.796439   844 net.cpp:150] Setting up fire7/expand1x1
I0604 20:56:02.796466   844 net.cpp:157] Top shape: 512 192 15 15 (22118400)
I0604 20:56:02.796473   844 net.cpp:165] Memory required for data: 6370887680
I0604 20:56:02.796485   844 layer_factory.hpp:77] Creating layer fire7/relu_expand1x1
I0604 20:56:02.796495   844 net.cpp:106] Creating Layer fire7/relu_expand1x1
I0604 20:56:02.796505   844 net.cpp:454] fire7/relu_expand1x1 <- fire7/expand1x1
I0604 20:56:02.796535   844 net.cpp:397] fire7/relu_expand1x1 -> fire7/expand1x1 (in-place)
I0604 20:56:02.797436   844 net.cpp:150] Setting up fire7/relu_expand1x1
I0604 20:56:02.797451   844 net.cpp:157] Top shape: 512 192 15 15 (22118400)
I0604 20:56:02.797456   844 net.cpp:165] Memory required for data: 6459361280
I0604 20:56:02.797461   844 layer_factory.hpp:77] Creating layer fire7/expand3x3
I0604 20:56:02.797503   844 net.cpp:106] Creating Layer fire7/expand3x3
I0604 20:56:02.797514   844 net.cpp:454] fire7/expand3x3 <- fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_1
I0604 20:56:02.797525   844 net.cpp:411] fire7/expand3x3 -> fire7/expand3x3
I0604 20:56:02.801113   844 net.cpp:150] Setting up fire7/expand3x3
I0604 20:56:02.801134   844 net.cpp:157] Top shape: 512 192 15 15 (22118400)
I0604 20:56:02.801138   844 net.cpp:165] Memory required for data: 6547834880
I0604 20:56:02.801146   844 layer_factory.hpp:77] Creating layer fire7/relu_expand3x3
I0604 20:56:02.801154   844 net.cpp:106] Creating Layer fire7/relu_expand3x3
I0604 20:56:02.801159   844 net.cpp:454] fire7/relu_expand3x3 <- fire7/expand3x3
I0604 20:56:02.801168   844 net.cpp:397] fire7/relu_expand3x3 -> fire7/expand3x3 (in-place)
I0604 20:56:02.802139   844 net.cpp:150] Setting up fire7/relu_expand3x3
I0604 20:56:02.802151   844 net.cpp:157] Top shape: 512 192 15 15 (22118400)
I0604 20:56:02.802155   844 net.cpp:165] Memory required for data: 6636308480
I0604 20:56:02.802158   844 layer_factory.hpp:77] Creating layer fire7/concat
I0604 20:56:02.802165   844 net.cpp:106] Creating Layer fire7/concat
I0604 20:56:02.802170   844 net.cpp:454] fire7/concat <- fire7/expand1x1
I0604 20:56:02.802175   844 net.cpp:454] fire7/concat <- fire7/expand3x3
I0604 20:56:02.802181   844 net.cpp:411] fire7/concat -> fire7/concat
I0604 20:56:02.802217   844 net.cpp:150] Setting up fire7/concat
I0604 20:56:02.802224   844 net.cpp:157] Top shape: 512 384 15 15 (44236800)
I0604 20:56:02.802230   844 net.cpp:165] Memory required for data: 6813255680
I0604 20:56:02.802233   844 layer_factory.hpp:77] Creating layer fire8/squeeze1x1
I0604 20:56:02.802242   844 net.cpp:106] Creating Layer fire8/squeeze1x1
I0604 20:56:02.802245   844 net.cpp:454] fire8/squeeze1x1 <- fire7/concat
I0604 20:56:02.802253   844 net.cpp:411] fire8/squeeze1x1 -> fire8/squeeze1x1
I0604 20:56:02.806448   844 net.cpp:150] Setting up fire8/squeeze1x1
I0604 20:56:02.806462   844 net.cpp:157] Top shape: 512 64 15 15 (7372800)
I0604 20:56:02.806465   844 net.cpp:165] Memory required for data: 6842746880
I0604 20:56:02.806473   844 layer_factory.hpp:77] Creating layer fire8/relu_squeeze1x1
I0604 20:56:02.806481   844 net.cpp:106] Creating Layer fire8/relu_squeeze1x1
I0604 20:56:02.806505   844 net.cpp:454] fire8/relu_squeeze1x1 <- fire8/squeeze1x1
I0604 20:56:02.806512   844 net.cpp:397] fire8/relu_squeeze1x1 -> fire8/squeeze1x1 (in-place)
I0604 20:56:02.807651   844 net.cpp:150] Setting up fire8/relu_squeeze1x1
I0604 20:56:02.807663   844 net.cpp:157] Top shape: 512 64 15 15 (7372800)
I0604 20:56:02.807667   844 net.cpp:165] Memory required for data: 6872238080
I0604 20:56:02.807670   844 layer_factory.hpp:77] Creating layer fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I0604 20:56:02.807679   844 net.cpp:106] Creating Layer fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I0604 20:56:02.807682   844 net.cpp:454] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split <- fire8/squeeze1x1
I0604 20:56:02.807688   844 net.cpp:411] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split -> fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_0
I0604 20:56:02.807696   844 net.cpp:411] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split -> fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_1
I0604 20:56:02.807749   844 net.cpp:150] Setting up fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I0604 20:56:02.807756   844 net.cpp:157] Top shape: 512 64 15 15 (7372800)
I0604 20:56:02.807760   844 net.cpp:157] Top shape: 512 64 15 15 (7372800)
I0604 20:56:02.807763   844 net.cpp:165] Memory required for data: 6931220480
I0604 20:56:02.807766   844 layer_factory.hpp:77] Creating layer fire8/expand1x1
I0604 20:56:02.807776   844 net.cpp:106] Creating Layer fire8/expand1x1
I0604 20:56:02.807782   844 net.cpp:454] fire8/expand1x1 <- fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_0
I0604 20:56:02.807788   844 net.cpp:411] fire8/expand1x1 -> fire8/expand1x1
I0604 20:56:02.811260   844 net.cpp:150] Setting up fire8/expand1x1
I0604 20:56:02.811275   844 net.cpp:157] Top shape: 512 256 15 15 (29491200)
I0604 20:56:02.811277   844 net.cpp:165] Memory required for data: 7049185280
I0604 20:56:02.811285   844 layer_factory.hpp:77] Creating layer fire8/relu_expand1x1
I0604 20:56:02.811293   844 net.cpp:106] Creating Layer fire8/relu_expand1x1
I0604 20:56:02.811300   844 net.cpp:454] fire8/relu_expand1x1 <- fire8/expand1x1
I0604 20:56:02.811305   844 net.cpp:397] fire8/relu_expand1x1 -> fire8/expand1x1 (in-place)
I0604 20:56:02.816697   844 net.cpp:150] Setting up fire8/relu_expand1x1
I0604 20:56:02.816715   844 net.cpp:157] Top shape: 512 256 15 15 (29491200)
I0604 20:56:02.816717   844 net.cpp:165] Memory required for data: 7167150080
I0604 20:56:02.816720   844 layer_factory.hpp:77] Creating layer fire8/expand3x3
I0604 20:56:02.816732   844 net.cpp:106] Creating Layer fire8/expand3x3
I0604 20:56:02.816735   844 net.cpp:454] fire8/expand3x3 <- fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_1
I0604 20:56:02.816741   844 net.cpp:411] fire8/expand3x3 -> fire8/expand3x3
I0604 20:56:02.820350   844 net.cpp:150] Setting up fire8/expand3x3
I0604 20:56:02.820364   844 net.cpp:157] Top shape: 512 256 15 15 (29491200)
I0604 20:56:02.820369   844 net.cpp:165] Memory required for data: 7285114880
I0604 20:56:02.820389   844 layer_factory.hpp:77] Creating layer fire8/relu_expand3x3
I0604 20:56:02.820395   844 net.cpp:106] Creating Layer fire8/relu_expand3x3
I0604 20:56:02.820399   844 net.cpp:454] fire8/relu_expand3x3 <- fire8/expand3x3
I0604 20:56:02.820410   844 net.cpp:397] fire8/relu_expand3x3 -> fire8/expand3x3 (in-place)
I0604 20:56:02.821399   844 net.cpp:150] Setting up fire8/relu_expand3x3
I0604 20:56:02.821413   844 net.cpp:157] Top shape: 512 256 15 15 (29491200)
I0604 20:56:02.821415   844 net.cpp:165] Memory required for data: 7403079680
I0604 20:56:02.821419   844 layer_factory.hpp:77] Creating layer fire8/concat
I0604 20:56:02.821427   844 net.cpp:106] Creating Layer fire8/concat
I0604 20:56:02.821430   844 net.cpp:454] fire8/concat <- fire8/expand1x1
I0604 20:56:02.821435   844 net.cpp:454] fire8/concat <- fire8/expand3x3
I0604 20:56:02.821440   844 net.cpp:411] fire8/concat -> fire8/concat
I0604 20:56:02.821476   844 net.cpp:150] Setting up fire8/concat
I0604 20:56:02.821485   844 net.cpp:157] Top shape: 512 512 15 15 (58982400)
I0604 20:56:02.821503   844 net.cpp:165] Memory required for data: 7639009280
I0604 20:56:02.821507   844 layer_factory.hpp:77] Creating layer pool8
I0604 20:56:02.821517   844 net.cpp:106] Creating Layer pool8
I0604 20:56:02.821521   844 net.cpp:454] pool8 <- fire8/concat
I0604 20:56:02.821526   844 net.cpp:411] pool8 -> pool8
I0604 20:56:02.821573   844 net.cpp:150] Setting up pool8
I0604 20:56:02.821580   844 net.cpp:157] Top shape: 512 512 7 7 (12845056)
I0604 20:56:02.821583   844 net.cpp:165] Memory required for data: 7690389504
I0604 20:56:02.821586   844 layer_factory.hpp:77] Creating layer fire9/squeeze1x1
I0604 20:56:02.821596   844 net.cpp:106] Creating Layer fire9/squeeze1x1
I0604 20:56:02.821600   844 net.cpp:454] fire9/squeeze1x1 <- pool8
I0604 20:56:02.821606   844 net.cpp:411] fire9/squeeze1x1 -> fire9/squeeze1x1
I0604 20:56:02.825064   844 net.cpp:150] Setting up fire9/squeeze1x1
I0604 20:56:02.825078   844 net.cpp:157] Top shape: 512 64 7 7 (1605632)
I0604 20:56:02.825081   844 net.cpp:165] Memory required for data: 7696812032
I0604 20:56:02.825088   844 layer_factory.hpp:77] Creating layer fire9/relu_squeeze1x1
I0604 20:56:02.825094   844 net.cpp:106] Creating Layer fire9/relu_squeeze1x1
I0604 20:56:02.825098   844 net.cpp:454] fire9/relu_squeeze1x1 <- fire9/squeeze1x1
I0604 20:56:02.825104   844 net.cpp:397] fire9/relu_squeeze1x1 -> fire9/squeeze1x1 (in-place)
I0604 20:56:02.826103   844 net.cpp:150] Setting up fire9/relu_squeeze1x1
I0604 20:56:02.826115   844 net.cpp:157] Top shape: 512 64 7 7 (1605632)
I0604 20:56:02.826118   844 net.cpp:165] Memory required for data: 7703234560
I0604 20:56:02.826122   844 layer_factory.hpp:77] Creating layer fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I0604 20:56:02.826139   844 net.cpp:106] Creating Layer fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I0604 20:56:02.826143   844 net.cpp:454] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split <- fire9/squeeze1x1
I0604 20:56:02.826149   844 net.cpp:411] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split -> fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_0
I0604 20:56:02.826159   844 net.cpp:411] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split -> fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_1
I0604 20:56:02.826216   844 net.cpp:150] Setting up fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I0604 20:56:02.826223   844 net.cpp:157] Top shape: 512 64 7 7 (1605632)
I0604 20:56:02.826228   844 net.cpp:157] Top shape: 512 64 7 7 (1605632)
I0604 20:56:02.826231   844 net.cpp:165] Memory required for data: 7716079616
I0604 20:56:02.826234   844 layer_factory.hpp:77] Creating layer fire9/expand1x1
I0604 20:56:02.826246   844 net.cpp:106] Creating Layer fire9/expand1x1
I0604 20:56:02.826251   844 net.cpp:454] fire9/expand1x1 <- fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_0
I0604 20:56:02.826262   844 net.cpp:411] fire9/expand1x1 -> fire9/expand1x1
I0604 20:56:02.829773   844 net.cpp:150] Setting up fire9/expand1x1
I0604 20:56:02.829788   844 net.cpp:157] Top shape: 512 256 7 7 (6422528)
I0604 20:56:02.829792   844 net.cpp:165] Memory required for data: 7741769728
I0604 20:56:02.829798   844 layer_factory.hpp:77] Creating layer fire9/relu_expand1x1
I0604 20:56:02.829805   844 net.cpp:106] Creating Layer fire9/relu_expand1x1
I0604 20:56:02.829808   844 net.cpp:454] fire9/relu_expand1x1 <- fire9/expand1x1
I0604 20:56:02.829814   844 net.cpp:397] fire9/relu_expand1x1 -> fire9/expand1x1 (in-place)
I0604 20:56:02.830811   844 net.cpp:150] Setting up fire9/relu_expand1x1
I0604 20:56:02.830819   844 net.cpp:157] Top shape: 512 256 7 7 (6422528)
I0604 20:56:02.830823   844 net.cpp:165] Memory required for data: 7767459840
I0604 20:56:02.830826   844 layer_factory.hpp:77] Creating layer fire9/expand3x3
I0604 20:56:02.830837   844 net.cpp:106] Creating Layer fire9/expand3x3
I0604 20:56:02.830842   844 net.cpp:454] fire9/expand3x3 <- fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_1
I0604 20:56:02.830848   844 net.cpp:411] fire9/expand3x3 -> fire9/expand3x3
I0604 20:56:02.834486   844 net.cpp:150] Setting up fire9/expand3x3
I0604 20:56:02.834516   844 net.cpp:157] Top shape: 512 256 7 7 (6422528)
I0604 20:56:02.834519   844 net.cpp:165] Memory required for data: 7793149952
I0604 20:56:02.834527   844 layer_factory.hpp:77] Creating layer fire9/relu_expand3x3
I0604 20:56:02.834534   844 net.cpp:106] Creating Layer fire9/relu_expand3x3
I0604 20:56:02.834538   844 net.cpp:454] fire9/relu_expand3x3 <- fire9/expand3x3
I0604 20:56:02.834547   844 net.cpp:397] fire9/relu_expand3x3 -> fire9/expand3x3 (in-place)
I0604 20:56:02.835554   844 net.cpp:150] Setting up fire9/relu_expand3x3
I0604 20:56:02.835567   844 net.cpp:157] Top shape: 512 256 7 7 (6422528)
I0604 20:56:02.835571   844 net.cpp:165] Memory required for data: 7818840064
I0604 20:56:02.835574   844 layer_factory.hpp:77] Creating layer fire9/concat
I0604 20:56:02.835582   844 net.cpp:106] Creating Layer fire9/concat
I0604 20:56:02.835587   844 net.cpp:454] fire9/concat <- fire9/expand1x1
I0604 20:56:02.835592   844 net.cpp:454] fire9/concat <- fire9/expand3x3
I0604 20:56:02.835597   844 net.cpp:411] fire9/concat -> fire9/concat
I0604 20:56:02.835634   844 net.cpp:150] Setting up fire9/concat
I0604 20:56:02.835641   844 net.cpp:157] Top shape: 512 512 7 7 (12845056)
I0604 20:56:02.835644   844 net.cpp:165] Memory required for data: 7870220288
I0604 20:56:02.835647   844 layer_factory.hpp:77] Creating layer drop9
I0604 20:56:02.835654   844 net.cpp:106] Creating Layer drop9
I0604 20:56:02.835659   844 net.cpp:454] drop9 <- fire9/concat
I0604 20:56:02.835665   844 net.cpp:397] drop9 -> fire9/concat (in-place)
I0604 20:56:02.835697   844 net.cpp:150] Setting up drop9
I0604 20:56:02.835705   844 net.cpp:157] Top shape: 512 512 7 7 (12845056)
I0604 20:56:02.835707   844 net.cpp:165] Memory required for data: 7921600512
I0604 20:56:02.835711   844 layer_factory.hpp:77] Creating layer conv10
I0604 20:56:02.835718   844 net.cpp:106] Creating Layer conv10
I0604 20:56:02.835722   844 net.cpp:454] conv10 <- fire9/concat
I0604 20:56:02.835731   844 net.cpp:411] conv10 -> conv10
I0604 20:56:02.856025   844 net.cpp:150] Setting up conv10
I0604 20:56:02.856046   844 net.cpp:157] Top shape: 512 1000 9 9 (41472000)
I0604 20:56:02.856050   844 net.cpp:165] Memory required for data: 8087488512
I0604 20:56:02.856060   844 layer_factory.hpp:77] Creating layer relu_conv10
I0604 20:56:02.856067   844 net.cpp:106] Creating Layer relu_conv10
I0604 20:56:02.856071   844 net.cpp:454] relu_conv10 <- conv10
I0604 20:56:02.856081   844 net.cpp:397] relu_conv10 -> conv10 (in-place)
I0604 20:56:02.857059   844 net.cpp:150] Setting up relu_conv10
I0604 20:56:02.857072   844 net.cpp:157] Top shape: 512 1000 9 9 (41472000)
I0604 20:56:02.857075   844 net.cpp:165] Memory required for data: 8253376512
I0604 20:56:02.857079   844 layer_factory.hpp:77] Creating layer pool10
I0604 20:56:02.857089   844 net.cpp:106] Creating Layer pool10
I0604 20:56:02.857094   844 net.cpp:454] pool10 <- conv10
I0604 20:56:02.857100   844 net.cpp:411] pool10 -> pool10
I0604 20:56:02.858263   844 net.cpp:150] Setting up pool10
I0604 20:56:02.858273   844 net.cpp:157] Top shape: 512 1000 1 1 (512000)
I0604 20:56:02.858276   844 net.cpp:165] Memory required for data: 8255424512
I0604 20:56:02.858279   844 layer_factory.hpp:77] Creating layer loss
I0604 20:56:02.858288   844 net.cpp:106] Creating Layer loss
I0604 20:56:02.858290   844 net.cpp:454] loss <- pool10
I0604 20:56:02.858297   844 net.cpp:454] loss <- label
I0604 20:56:02.858304   844 net.cpp:411] loss -> loss
I0604 20:56:02.858314   844 layer_factory.hpp:77] Creating layer loss
I0604 20:56:02.860864   844 net.cpp:150] Setting up loss
I0604 20:56:02.860877   844 net.cpp:157] Top shape: (1)
I0604 20:56:02.860882   844 net.cpp:160]     with loss weight 1
I0604 20:56:02.860908   844 net.cpp:165] Memory required for data: 8255424516
I0604 20:56:02.860911   844 net.cpp:226] loss needs backward computation.
I0604 20:56:02.860915   844 net.cpp:226] pool10 needs backward computation.
I0604 20:56:02.860918   844 net.cpp:226] relu_conv10 needs backward computation.
I0604 20:56:02.860940   844 net.cpp:226] conv10 needs backward computation.
I0604 20:56:02.860944   844 net.cpp:226] drop9 needs backward computation.
I0604 20:56:02.860947   844 net.cpp:226] fire9/concat needs backward computation.
I0604 20:56:02.860951   844 net.cpp:226] fire9/relu_expand3x3 needs backward computation.
I0604 20:56:02.860954   844 net.cpp:226] fire9/expand3x3 needs backward computation.
I0604 20:56:02.860957   844 net.cpp:226] fire9/relu_expand1x1 needs backward computation.
I0604 20:56:02.860960   844 net.cpp:226] fire9/expand1x1 needs backward computation.
I0604 20:56:02.860965   844 net.cpp:226] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split needs backward computation.
I0604 20:56:02.860968   844 net.cpp:226] fire9/relu_squeeze1x1 needs backward computation.
I0604 20:56:02.860971   844 net.cpp:226] fire9/squeeze1x1 needs backward computation.
I0604 20:56:02.860975   844 net.cpp:226] pool8 needs backward computation.
I0604 20:56:02.860978   844 net.cpp:226] fire8/concat needs backward computation.
I0604 20:56:02.860983   844 net.cpp:226] fire8/relu_expand3x3 needs backward computation.
I0604 20:56:02.860986   844 net.cpp:226] fire8/expand3x3 needs backward computation.
I0604 20:56:02.860990   844 net.cpp:226] fire8/relu_expand1x1 needs backward computation.
I0604 20:56:02.860992   844 net.cpp:226] fire8/expand1x1 needs backward computation.
I0604 20:56:02.860996   844 net.cpp:226] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split needs backward computation.
I0604 20:56:02.860999   844 net.cpp:226] fire8/relu_squeeze1x1 needs backward computation.
I0604 20:56:02.861003   844 net.cpp:226] fire8/squeeze1x1 needs backward computation.
I0604 20:56:02.861006   844 net.cpp:226] fire7/concat needs backward computation.
I0604 20:56:02.861011   844 net.cpp:226] fire7/relu_expand3x3 needs backward computation.
I0604 20:56:02.861013   844 net.cpp:226] fire7/expand3x3 needs backward computation.
I0604 20:56:02.861016   844 net.cpp:226] fire7/relu_expand1x1 needs backward computation.
I0604 20:56:02.861019   844 net.cpp:226] fire7/expand1x1 needs backward computation.
I0604 20:56:02.861022   844 net.cpp:226] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split needs backward computation.
I0604 20:56:02.861027   844 net.cpp:226] fire7/relu_squeeze1x1 needs backward computation.
I0604 20:56:02.861029   844 net.cpp:226] fire7/squeeze1x1 needs backward computation.
I0604 20:56:02.861033   844 net.cpp:226] fire6/concat needs backward computation.
I0604 20:56:02.861037   844 net.cpp:226] fire6/relu_expand3x3 needs backward computation.
I0604 20:56:02.861039   844 net.cpp:226] fire6/expand3x3 needs backward computation.
I0604 20:56:02.861042   844 net.cpp:226] fire6/relu_expand1x1 needs backward computation.
I0604 20:56:02.861045   844 net.cpp:226] fire6/expand1x1 needs backward computation.
I0604 20:56:02.861049   844 net.cpp:226] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split needs backward computation.
I0604 20:56:02.861053   844 net.cpp:226] fire6/relu_squeeze1x1 needs backward computation.
I0604 20:56:02.861057   844 net.cpp:226] fire6/squeeze1x1 needs backward computation.
I0604 20:56:02.861059   844 net.cpp:226] fire5/concat needs backward computation.
I0604 20:56:02.861063   844 net.cpp:226] fire5/relu_expand3x3 needs backward computation.
I0604 20:56:02.861066   844 net.cpp:226] fire5/expand3x3 needs backward computation.
I0604 20:56:02.861069   844 net.cpp:226] fire5/relu_expand1x1 needs backward computation.
I0604 20:56:02.861073   844 net.cpp:226] fire5/expand1x1 needs backward computation.
I0604 20:56:02.861075   844 net.cpp:226] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split needs backward computation.
I0604 20:56:02.861079   844 net.cpp:226] fire5/relu_squeeze1x1 needs backward computation.
I0604 20:56:02.861083   844 net.cpp:226] fire5/squeeze1x1 needs backward computation.
I0604 20:56:02.861086   844 net.cpp:226] pool4 needs backward computation.
I0604 20:56:02.861090   844 net.cpp:226] fire4/concat needs backward computation.
I0604 20:56:02.861094   844 net.cpp:226] fire4/relu_expand3x3 needs backward computation.
I0604 20:56:02.861110   844 net.cpp:226] fire4/expand3x3 needs backward computation.
I0604 20:56:02.861114   844 net.cpp:226] fire4/relu_expand1x1 needs backward computation.
I0604 20:56:02.861116   844 net.cpp:226] fire4/expand1x1 needs backward computation.
I0604 20:56:02.861124   844 net.cpp:226] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split needs backward computation.
I0604 20:56:02.861127   844 net.cpp:226] fire4/relu_squeeze1x1 needs backward computation.
I0604 20:56:02.861130   844 net.cpp:226] fire4/squeeze1x1 needs backward computation.
I0604 20:56:02.861135   844 net.cpp:226] fire3/concat needs backward computation.
I0604 20:56:02.861138   844 net.cpp:226] fire3/relu_expand3x3 needs backward computation.
I0604 20:56:02.861141   844 net.cpp:226] fire3/expand3x3 needs backward computation.
I0604 20:56:02.861145   844 net.cpp:226] fire3/relu_expand1x1 needs backward computation.
I0604 20:56:02.861148   844 net.cpp:226] fire3/expand1x1 needs backward computation.
I0604 20:56:02.861151   844 net.cpp:226] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split needs backward computation.
I0604 20:56:02.861155   844 net.cpp:226] fire3/relu_squeeze1x1 needs backward computation.
I0604 20:56:02.861158   844 net.cpp:226] fire3/squeeze1x1 needs backward computation.
I0604 20:56:02.861161   844 net.cpp:226] fire2/concat needs backward computation.
I0604 20:56:02.861166   844 net.cpp:226] fire2/relu_expand3x3 needs backward computation.
I0604 20:56:02.861168   844 net.cpp:226] fire2/expand3x3 needs backward computation.
I0604 20:56:02.861172   844 net.cpp:226] fire2/relu_expand1x1 needs backward computation.
I0604 20:56:02.861176   844 net.cpp:226] fire2/expand1x1 needs backward computation.
I0604 20:56:02.861178   844 net.cpp:226] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split needs backward computation.
I0604 20:56:02.861181   844 net.cpp:226] fire2/relu_squeeze1x1 needs backward computation.
I0604 20:56:02.861184   844 net.cpp:226] fire2/squeeze1x1 needs backward computation.
I0604 20:56:02.861188   844 net.cpp:226] pool1 needs backward computation.
I0604 20:56:02.861192   844 net.cpp:226] relu_conv1 needs backward computation.
I0604 20:56:02.861196   844 net.cpp:226] conv1 needs backward computation.
I0604 20:56:02.861199   844 net.cpp:228] data does not need backward computation.
I0604 20:56:02.861203   844 net.cpp:270] This network produces output loss
I0604 20:56:02.861258   844 net.cpp:283] Network initialization done.
I0604 20:56:02.861567   844 solver.cpp:181] Creating test net (#0) specified by net_param
I0604 20:56:02.861663   844 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0604 20:56:02.861709   844 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss
I0604 20:56:02.862264   844 net.cpp:49] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.04
    mirror: false
    crop_size: 128
    mean_value: 104
    mean_value: 117
    mean_value: 123
    force_color: true
  }
  data_param {
    source: "/local/temporary/mishkdmy/imagenet144pxlmdb/ilsvrc12_128_val_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 96
    kernel_size: 7
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu_conv1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fire2/squeeze1x1"
  type: "Convolution"
  bottom: "pool1"
  top: "fire2/squeeze1x1"
  convolution_param {
    num_output: 16
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire2/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire2/squeeze1x1"
  top: "fire2/squeeze1x1"
}
layer {
  name: "fire2/expand1x1"
  type: "Convolution"
  bottom: "fire2/squeeze1x1"
  top: "fire2/expand1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire2/relu_expand1x1"
  type: "ReLU"
  bottom: "fire2/expand1x1"
  top: "fire2/expand1x1"
}
layer {
  name: "fire2/expand3x3"
  type: "Convolution"
  bottom: "fire2/squeeze1x1"
  top: "fire2/expand3x3"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire2/relu_expand3x3"
  type: "ReLU"
  bottom: "fire2/expand3x3"
  top: "fire2/expand3x3"
}
layer {
  name: "fire2/concat"
  type: "Concat"
  bottom: "fire2/expand1x1"
  bottom: "fire2/expand3x3"
  top: "fire2/concat"
}
layer {
  name: "fire3/squeeze1x1"
  type: "Convolution"
  bottom: "fire2/concat"
  top: "fire3/squeeze1x1"
  convolution_param {
    num_output: 16
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire3/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire3/squeeze1x1"
  top: "fire3/squeeze1x1"
}
layer {
  name: "fire3/expand1x1"
  type: "Convolution"
  bottom: "fire3/squeeze1x1"
  top: "fire3/expand1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire3/relu_expand1x1"
  type: "ReLU"
  bottom: "fire3/expand1x1"
  top: "fire3/expand1x1"
}
layer {
  name: "fire3/expand3x3"
  type: "Convolution"
  bottom: "fire3/squeeze1x1"
  top: "fire3/expand3x3"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire3/relu_expand3x3"
  type: "ReLU"
  bottom: "fire3/expand3x3"
  top: "fire3/expand3x3"
}
layer {
  name: "fire3/concat"
  type: "Concat"
  bottom: "fire3/expand1x1"
  bottom: "fire3/expand3x3"
  top: "fire3/concat"
}
layer {
  name: "fire4/squeeze1x1"
  type: "Convolution"
  bottom: "fire3/concat"
  top: "fire4/squeeze1x1"
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire4/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire4/squeeze1x1"
  top: "fire4/squeeze1x1"
}
layer {
  name: "fire4/expand1x1"
  type: "Convolution"
  bottom: "fire4/squeeze1x1"
  top: "fire4/expand1x1"
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire4/relu_expand1x1"
  type: "ReLU"
  bottom: "fire4/expand1x1"
  top: "fire4/expand1x1"
}
layer {
  name: "fire4/expand3x3"
  type: "Convolution"
  bottom: "fire4/squeeze1x1"
  top: "fire4/expand3x3"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire4/relu_expand3x3"
  type: "ReLU"
  bottom: "fire4/expand3x3"
  top: "fire4/expand3x3"
}
layer {
  name: "fire4/concat"
  type: "Concat"
  bottom: "fire4/expand1x1"
  bottom: "fire4/expand3x3"
  top: "fire4/concat"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "fire4/concat"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fire5/squeeze1x1"
  type: "Convolution"
  bottom: "pool4"
  top: "fire5/squeeze1x1"
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire5/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire5/squeeze1x1"
  top: "fire5/squeeze1x1"
}
layer {
  name: "fire5/expand1x1"
  type: "Convolution"
  bottom: "fire5/squeeze1x1"
  top: "fire5/expand1x1"
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire5/relu_expand1x1"
  type: "ReLU"
  bottom: "fire5/expand1x1"
  top: "fire5/expand1x1"
}
layer {
  name: "fire5/expand3x3"
  type: "Convolution"
  bottom: "fire5/squeeze1x1"
  top: "fire5/expand3x3"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire5/relu_expand3x3"
  type: "ReLU"
  bottom: "fire5/expand3x3"
  top: "fire5/expand3x3"
}
layer {
  name: "fire5/concat"
  type: "Concat"
  bottom: "fire5/expand1x1"
  bottom: "fire5/expand3x3"
  top: "fire5/concat"
}
layer {
  name: "fire6/squeeze1x1"
  type: "Convolution"
  bottom: "fire5/concat"
  top: "fire6/squeeze1x1"
  convolution_param {
    num_output: 48
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire6/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire6/squeeze1x1"
  top: "fire6/squeeze1x1"
}
layer {
  name: "fire6/expand1x1"
  type: "Convolution"
  bottom: "fire6/squeeze1x1"
  top: "fire6/expand1x1"
  convolution_param {
    num_output: 192
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire6/relu_expand1x1"
  type: "ReLU"
  bottom: "fire6/expand1x1"
  top: "fire6/expand1x1"
}
layer {
  name: "fire6/expand3x3"
  type: "Convolution"
  bottom: "fire6/squeeze1x1"
  top: "fire6/expand3x3"
  convolution_param {
    num_output: 192
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire6/relu_expand3x3"
  type: "ReLU"
  bottom: "fire6/expand3x3"
  top: "fire6/expand3x3"
}
layer {
  name: "fire6/concat"
  type: "Concat"
  bottom: "fire6/expand1x1"
  bottom: "fire6/expand3x3"
  top: "fire6/concat"
}
layer {
  name: "fire7/squeeze1x1"
  type: "Convolution"
  bottom: "fire6/concat"
  top: "fire7/squeeze1x1"
  convolution_param {
    num_output: 48
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire7/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire7/squeeze1x1"
  top: "fire7/squeeze1x1"
}
layer {
  name: "fire7/expand1x1"
  type: "Convolution"
  bottom: "fire7/squeeze1x1"
  top: "fire7/expand1x1"
  convolution_param {
    num_output: 192
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire7/relu_expand1x1"
  type: "ReLU"
  bottom: "fire7/expand1x1"
  top: "fire7/expand1x1"
}
layer {
  name: "fire7/expand3x3"
  type: "Convolution"
  bottom: "fire7/squeeze1x1"
  top: "fire7/expand3x3"
  convolution_param {
    num_output: 192
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire7/relu_expand3x3"
  type: "ReLU"
  bottom: "fire7/expand3x3"
  top: "fire7/expand3x3"
}
layer {
  name: "fire7/concat"
  type: "Concat"
  bottom: "fire7/expand1x1"
  bottom: "fire7/expand3x3"
  top: "fire7/concat"
}
layer {
  name: "fire8/squeeze1x1"
  type: "Convolution"
  bottom: "fire7/concat"
  top: "fire8/squeeze1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire8/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire8/squeeze1x1"
  top: "fire8/squeeze1x1"
}
layer {
  name: "fire8/expand1x1"
  type: "Convolution"
  bottom: "fire8/squeeze1x1"
  top: "fire8/expand1x1"
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire8/relu_expand1x1"
  type: "ReLU"
  bottom: "fire8/expand1x1"
  top: "fire8/expand1x1"
}
layer {
  name: "fire8/expand3x3"
  type: "Convolution"
  bottom: "fire8/squeeze1x1"
  top: "fire8/expand3x3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire8/relu_expand3x3"
  type: "ReLU"
  bottom: "fire8/expand3x3"
  top: "fire8/expand3x3"
}
layer {
  name: "fire8/concat"
  type: "Concat"
  bottom: "fire8/expand1x1"
  bottom: "fire8/expand3x3"
  top: "fire8/concat"
}
layer {
  name: "pool8"
  type: "Pooling"
  bottom: "fire8/concat"
  top: "pool8"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fire9/squeeze1x1"
  type: "Convolution"
  bottom: "pool8"
  top: "fire9/squeeze1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire9/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire9/squeeze1x1"
  top: "fire9/squeeze1x1"
}
layer {
  name: "fire9/expand1x1"
  type: "Convolution"
  bottom: "fire9/squeeze1x1"
  top: "fire9/expand1x1"
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire9/relu_expand1x1"
  type: "ReLU"
  bottom: "fire9/expand1x1"
  top: "fire9/expand1x1"
}
layer {
  name: "fire9/expand3x3"
  type: "Convolution"
  bottom: "fire9/squeeze1x1"
  top: "fire9/expand3x3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire9/relu_expand3x3"
  type: "ReLU"
  bottom: "fire9/expand3x3"
  top: "fire9/expand3x3"
}
layer {
  name: "fire9/concat"
  type: "Concat"
  bottom: "fire9/expand1x1"
  bottom: "fire9/expand3x3"
  top: "fire9/concat"
}
layer {
  name: "drop9"
  type: "Dropout"
  bottom: "fire9/concat"
  top: "fire9/concat"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "conv10"
  type: "Convolution"
  bottom: "fire9/concat"
  top: "conv10"
  convolution_param {
    num_output: 1000
    pad: 1
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      mean: 0
      std: 0.01
    }
  }
}
layer {
  name: "relu_conv10"
  type: "ReLU"
  bottom: "conv10"
  top: "conv10"
}
layer {
  name: "pool10"
  type: "Pooling"
  bottom: "conv10"
  top: "pool10"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "pool10"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "accuracy_top5"
  type: "Accuracy"
  bottom: "pool10"
  bottom: "label"
  top: "accuracy_top5"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 5
  }
}
I0604 20:56:02.862601   844 layer_factory.hpp:77] Creating layer data
I0604 20:56:02.862720   844 net.cpp:106] Creating Layer data
I0604 20:56:02.862731   844 net.cpp:411] data -> data
I0604 20:56:02.862740   844 net.cpp:411] data -> label
I0604 20:56:02.864289   879 db_lmdb.cpp:38] Opened lmdb /local/temporary/mishkdmy/imagenet144pxlmdb/ilsvrc12_128_val_lmdb
I0604 20:56:02.865233   844 data_layer.cpp:41] output data size: 50,3,128,128
I0604 20:56:02.887826   844 net.cpp:150] Setting up data
I0604 20:56:02.887858   844 net.cpp:157] Top shape: 50 3 128 128 (2457600)
I0604 20:56:02.887866   844 net.cpp:157] Top shape: 50 (50)
I0604 20:56:02.887871   844 net.cpp:165] Memory required for data: 9830600
I0604 20:56:02.887879   844 layer_factory.hpp:77] Creating layer label_data_1_split
I0604 20:56:02.887898   844 net.cpp:106] Creating Layer label_data_1_split
I0604 20:56:02.887907   844 net.cpp:454] label_data_1_split <- label
I0604 20:56:02.887918   844 net.cpp:411] label_data_1_split -> label_data_1_split_0
I0604 20:56:02.887931   844 net.cpp:411] label_data_1_split -> label_data_1_split_1
I0604 20:56:02.888008   844 net.cpp:150] Setting up label_data_1_split
I0604 20:56:02.888016   844 net.cpp:157] Top shape: 50 (50)
I0604 20:56:02.888020   844 net.cpp:157] Top shape: 50 (50)
I0604 20:56:02.888023   844 net.cpp:165] Memory required for data: 9831000
I0604 20:56:02.888027   844 layer_factory.hpp:77] Creating layer conv1
I0604 20:56:02.888041   844 net.cpp:106] Creating Layer conv1
I0604 20:56:02.888047   844 net.cpp:454] conv1 <- data
I0604 20:56:02.888056   844 net.cpp:411] conv1 -> conv1
I0604 20:56:02.892343   844 net.cpp:150] Setting up conv1
I0604 20:56:02.892359   844 net.cpp:157] Top shape: 50 96 61 61 (17860800)
I0604 20:56:02.892364   844 net.cpp:165] Memory required for data: 81274200
I0604 20:56:02.892390   844 layer_factory.hpp:77] Creating layer relu_conv1
I0604 20:56:02.892434   844 net.cpp:106] Creating Layer relu_conv1
I0604 20:56:02.892444   844 net.cpp:454] relu_conv1 <- conv1
I0604 20:56:02.892452   844 net.cpp:397] relu_conv1 -> conv1 (in-place)
I0604 20:56:02.893362   844 net.cpp:150] Setting up relu_conv1
I0604 20:56:02.893373   844 net.cpp:157] Top shape: 50 96 61 61 (17860800)
I0604 20:56:02.893376   844 net.cpp:165] Memory required for data: 152717400
I0604 20:56:02.893379   844 layer_factory.hpp:77] Creating layer pool1
I0604 20:56:02.893407   844 net.cpp:106] Creating Layer pool1
I0604 20:56:02.893411   844 net.cpp:454] pool1 <- conv1
I0604 20:56:02.893419   844 net.cpp:411] pool1 -> pool1
I0604 20:56:02.895437   844 net.cpp:150] Setting up pool1
I0604 20:56:02.895453   844 net.cpp:157] Top shape: 50 96 30 30 (4320000)
I0604 20:56:02.895457   844 net.cpp:165] Memory required for data: 169997400
I0604 20:56:02.895462   844 layer_factory.hpp:77] Creating layer fire2/squeeze1x1
I0604 20:56:02.895475   844 net.cpp:106] Creating Layer fire2/squeeze1x1
I0604 20:56:02.895479   844 net.cpp:454] fire2/squeeze1x1 <- pool1
I0604 20:56:02.895485   844 net.cpp:411] fire2/squeeze1x1 -> fire2/squeeze1x1
I0604 20:56:02.898375   844 net.cpp:150] Setting up fire2/squeeze1x1
I0604 20:56:02.898388   844 net.cpp:157] Top shape: 50 16 30 30 (720000)
I0604 20:56:02.898392   844 net.cpp:165] Memory required for data: 172877400
I0604 20:56:02.898406   844 layer_factory.hpp:77] Creating layer fire2/relu_squeeze1x1
I0604 20:56:02.898412   844 net.cpp:106] Creating Layer fire2/relu_squeeze1x1
I0604 20:56:02.898416   844 net.cpp:454] fire2/relu_squeeze1x1 <- fire2/squeeze1x1
I0604 20:56:02.898422   844 net.cpp:397] fire2/relu_squeeze1x1 -> fire2/squeeze1x1 (in-place)
I0604 20:56:02.899437   844 net.cpp:150] Setting up fire2/relu_squeeze1x1
I0604 20:56:02.899449   844 net.cpp:157] Top shape: 50 16 30 30 (720000)
I0604 20:56:02.899453   844 net.cpp:165] Memory required for data: 175757400
I0604 20:56:02.899457   844 layer_factory.hpp:77] Creating layer fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I0604 20:56:02.899463   844 net.cpp:106] Creating Layer fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I0604 20:56:02.899467   844 net.cpp:454] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split <- fire2/squeeze1x1
I0604 20:56:02.899472   844 net.cpp:411] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split -> fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_0
I0604 20:56:02.899480   844 net.cpp:411] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split -> fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_1
I0604 20:56:02.899538   844 net.cpp:150] Setting up fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I0604 20:56:02.899545   844 net.cpp:157] Top shape: 50 16 30 30 (720000)
I0604 20:56:02.899550   844 net.cpp:157] Top shape: 50 16 30 30 (720000)
I0604 20:56:02.899554   844 net.cpp:165] Memory required for data: 181517400
I0604 20:56:02.899557   844 layer_factory.hpp:77] Creating layer fire2/expand1x1
I0604 20:56:02.899570   844 net.cpp:106] Creating Layer fire2/expand1x1
I0604 20:56:02.899577   844 net.cpp:454] fire2/expand1x1 <- fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_0
I0604 20:56:02.899587   844 net.cpp:411] fire2/expand1x1 -> fire2/expand1x1
I0604 20:56:02.905692   844 net.cpp:150] Setting up fire2/expand1x1
I0604 20:56:02.905709   844 net.cpp:157] Top shape: 50 64 30 30 (2880000)
I0604 20:56:02.905714   844 net.cpp:165] Memory required for data: 193037400
I0604 20:56:02.905731   844 layer_factory.hpp:77] Creating layer fire2/relu_expand1x1
I0604 20:56:02.905761   844 net.cpp:106] Creating Layer fire2/relu_expand1x1
I0604 20:56:02.905767   844 net.cpp:454] fire2/relu_expand1x1 <- fire2/expand1x1
I0604 20:56:02.905781   844 net.cpp:397] fire2/relu_expand1x1 -> fire2/expand1x1 (in-place)
I0604 20:56:02.906749   844 net.cpp:150] Setting up fire2/relu_expand1x1
I0604 20:56:02.906761   844 net.cpp:157] Top shape: 50 64 30 30 (2880000)
I0604 20:56:02.906764   844 net.cpp:165] Memory required for data: 204557400
I0604 20:56:02.906769   844 layer_factory.hpp:77] Creating layer fire2/expand3x3
I0604 20:56:02.906780   844 net.cpp:106] Creating Layer fire2/expand3x3
I0604 20:56:02.906783   844 net.cpp:454] fire2/expand3x3 <- fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_1
I0604 20:56:02.906790   844 net.cpp:411] fire2/expand3x3 -> fire2/expand3x3
I0604 20:56:02.910604   844 net.cpp:150] Setting up fire2/expand3x3
I0604 20:56:02.910617   844 net.cpp:157] Top shape: 50 64 30 30 (2880000)
I0604 20:56:02.910621   844 net.cpp:165] Memory required for data: 216077400
I0604 20:56:02.910645   844 layer_factory.hpp:77] Creating layer fire2/relu_expand3x3
I0604 20:56:02.910655   844 net.cpp:106] Creating Layer fire2/relu_expand3x3
I0604 20:56:02.910662   844 net.cpp:454] fire2/relu_expand3x3 <- fire2/expand3x3
I0604 20:56:02.910668   844 net.cpp:397] fire2/relu_expand3x3 -> fire2/expand3x3 (in-place)
I0604 20:56:02.911607   844 net.cpp:150] Setting up fire2/relu_expand3x3
I0604 20:56:02.911617   844 net.cpp:157] Top shape: 50 64 30 30 (2880000)
I0604 20:56:02.911620   844 net.cpp:165] Memory required for data: 227597400
I0604 20:56:02.911623   844 layer_factory.hpp:77] Creating layer fire2/concat
I0604 20:56:02.911630   844 net.cpp:106] Creating Layer fire2/concat
I0604 20:56:02.911633   844 net.cpp:454] fire2/concat <- fire2/expand1x1
I0604 20:56:02.911638   844 net.cpp:454] fire2/concat <- fire2/expand3x3
I0604 20:56:02.911643   844 net.cpp:411] fire2/concat -> fire2/concat
I0604 20:56:02.911681   844 net.cpp:150] Setting up fire2/concat
I0604 20:56:02.911689   844 net.cpp:157] Top shape: 50 128 30 30 (5760000)
I0604 20:56:02.911692   844 net.cpp:165] Memory required for data: 250637400
I0604 20:56:02.911695   844 layer_factory.hpp:77] Creating layer fire3/squeeze1x1
I0604 20:56:02.911705   844 net.cpp:106] Creating Layer fire3/squeeze1x1
I0604 20:56:02.911708   844 net.cpp:454] fire3/squeeze1x1 <- fire2/concat
I0604 20:56:02.911722   844 net.cpp:411] fire3/squeeze1x1 -> fire3/squeeze1x1
I0604 20:56:02.917057   844 net.cpp:150] Setting up fire3/squeeze1x1
I0604 20:56:02.917070   844 net.cpp:157] Top shape: 50 16 30 30 (720000)
I0604 20:56:02.917074   844 net.cpp:165] Memory required for data: 253517400
I0604 20:56:02.917085   844 layer_factory.hpp:77] Creating layer fire3/relu_squeeze1x1
I0604 20:56:02.917093   844 net.cpp:106] Creating Layer fire3/relu_squeeze1x1
I0604 20:56:02.917096   844 net.cpp:454] fire3/relu_squeeze1x1 <- fire3/squeeze1x1
I0604 20:56:02.917104   844 net.cpp:397] fire3/relu_squeeze1x1 -> fire3/squeeze1x1 (in-place)
I0604 20:56:02.918157   844 net.cpp:150] Setting up fire3/relu_squeeze1x1
I0604 20:56:02.918169   844 net.cpp:157] Top shape: 50 16 30 30 (720000)
I0604 20:56:02.918174   844 net.cpp:165] Memory required for data: 256397400
I0604 20:56:02.918176   844 layer_factory.hpp:77] Creating layer fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I0604 20:56:02.918184   844 net.cpp:106] Creating Layer fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I0604 20:56:02.918189   844 net.cpp:454] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split <- fire3/squeeze1x1
I0604 20:56:02.918193   844 net.cpp:411] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split -> fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_0
I0604 20:56:02.918201   844 net.cpp:411] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split -> fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_1
I0604 20:56:02.918257   844 net.cpp:150] Setting up fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I0604 20:56:02.918264   844 net.cpp:157] Top shape: 50 16 30 30 (720000)
I0604 20:56:02.918268   844 net.cpp:157] Top shape: 50 16 30 30 (720000)
I0604 20:56:02.918272   844 net.cpp:165] Memory required for data: 262157400
I0604 20:56:02.918274   844 layer_factory.hpp:77] Creating layer fire3/expand1x1
I0604 20:56:02.918285   844 net.cpp:106] Creating Layer fire3/expand1x1
I0604 20:56:02.918290   844 net.cpp:454] fire3/expand1x1 <- fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_0
I0604 20:56:02.918300   844 net.cpp:411] fire3/expand1x1 -> fire3/expand1x1
I0604 20:56:02.923343   844 net.cpp:150] Setting up fire3/expand1x1
I0604 20:56:02.923357   844 net.cpp:157] Top shape: 50 64 30 30 (2880000)
I0604 20:56:02.923360   844 net.cpp:165] Memory required for data: 273677400
I0604 20:56:02.923367   844 layer_factory.hpp:77] Creating layer fire3/relu_expand1x1
I0604 20:56:02.923374   844 net.cpp:106] Creating Layer fire3/relu_expand1x1
I0604 20:56:02.923377   844 net.cpp:454] fire3/relu_expand1x1 <- fire3/expand1x1
I0604 20:56:02.923383   844 net.cpp:397] fire3/relu_expand1x1 -> fire3/expand1x1 (in-place)
I0604 20:56:02.925300   844 net.cpp:150] Setting up fire3/relu_expand1x1
I0604 20:56:02.925328   844 net.cpp:157] Top shape: 50 64 30 30 (2880000)
I0604 20:56:02.925330   844 net.cpp:165] Memory required for data: 285197400
I0604 20:56:02.925334   844 layer_factory.hpp:77] Creating layer fire3/expand3x3
I0604 20:56:02.925343   844 net.cpp:106] Creating Layer fire3/expand3x3
I0604 20:56:02.925346   844 net.cpp:454] fire3/expand3x3 <- fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_1
I0604 20:56:02.925354   844 net.cpp:411] fire3/expand3x3 -> fire3/expand3x3
I0604 20:56:02.931324   844 net.cpp:150] Setting up fire3/expand3x3
I0604 20:56:02.931345   844 net.cpp:157] Top shape: 50 64 30 30 (2880000)
I0604 20:56:02.931349   844 net.cpp:165] Memory required for data: 296717400
I0604 20:56:02.931357   844 layer_factory.hpp:77] Creating layer fire3/relu_expand3x3
I0604 20:56:02.931365   844 net.cpp:106] Creating Layer fire3/relu_expand3x3
I0604 20:56:02.931368   844 net.cpp:454] fire3/relu_expand3x3 <- fire3/expand3x3
I0604 20:56:02.931377   844 net.cpp:397] fire3/relu_expand3x3 -> fire3/expand3x3 (in-place)
I0604 20:56:02.932325   844 net.cpp:150] Setting up fire3/relu_expand3x3
I0604 20:56:02.932344   844 net.cpp:157] Top shape: 50 64 30 30 (2880000)
I0604 20:56:02.932350   844 net.cpp:165] Memory required for data: 308237400
I0604 20:56:02.932356   844 layer_factory.hpp:77] Creating layer fire3/concat
I0604 20:56:02.932368   844 net.cpp:106] Creating Layer fire3/concat
I0604 20:56:02.932384   844 net.cpp:454] fire3/concat <- fire3/expand1x1
I0604 20:56:02.932391   844 net.cpp:454] fire3/concat <- fire3/expand3x3
I0604 20:56:02.932400   844 net.cpp:411] fire3/concat -> fire3/concat
I0604 20:56:02.932477   844 net.cpp:150] Setting up fire3/concat
I0604 20:56:02.932488   844 net.cpp:157] Top shape: 50 128 30 30 (5760000)
I0604 20:56:02.932493   844 net.cpp:165] Memory required for data: 331277400
I0604 20:56:02.932499   844 layer_factory.hpp:77] Creating layer fire4/squeeze1x1
I0604 20:56:02.932518   844 net.cpp:106] Creating Layer fire4/squeeze1x1
I0604 20:56:02.932536   844 net.cpp:454] fire4/squeeze1x1 <- fire3/concat
I0604 20:56:02.932548   844 net.cpp:411] fire4/squeeze1x1 -> fire4/squeeze1x1
I0604 20:56:02.936178   844 net.cpp:150] Setting up fire4/squeeze1x1
I0604 20:56:02.936215   844 net.cpp:157] Top shape: 50 32 30 30 (1440000)
I0604 20:56:02.936221   844 net.cpp:165] Memory required for data: 337037400
I0604 20:56:02.936235   844 layer_factory.hpp:77] Creating layer fire4/relu_squeeze1x1
I0604 20:56:02.936252   844 net.cpp:106] Creating Layer fire4/relu_squeeze1x1
I0604 20:56:02.936278   844 net.cpp:454] fire4/relu_squeeze1x1 <- fire4/squeeze1x1
I0604 20:56:02.936290   844 net.cpp:397] fire4/relu_squeeze1x1 -> fire4/squeeze1x1 (in-place)
I0604 20:56:02.939528   844 net.cpp:150] Setting up fire4/relu_squeeze1x1
I0604 20:56:02.939543   844 net.cpp:157] Top shape: 50 32 30 30 (1440000)
I0604 20:56:02.939546   844 net.cpp:165] Memory required for data: 342797400
I0604 20:56:02.939550   844 layer_factory.hpp:77] Creating layer fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I0604 20:56:02.939563   844 net.cpp:106] Creating Layer fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I0604 20:56:02.939566   844 net.cpp:454] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split <- fire4/squeeze1x1
I0604 20:56:02.939573   844 net.cpp:411] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split -> fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_0
I0604 20:56:02.939582   844 net.cpp:411] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split -> fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_1
I0604 20:56:02.939642   844 net.cpp:150] Setting up fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I0604 20:56:02.939651   844 net.cpp:157] Top shape: 50 32 30 30 (1440000)
I0604 20:56:02.939656   844 net.cpp:157] Top shape: 50 32 30 30 (1440000)
I0604 20:56:02.939661   844 net.cpp:165] Memory required for data: 354317400
I0604 20:56:02.939663   844 layer_factory.hpp:77] Creating layer fire4/expand1x1
I0604 20:56:02.939677   844 net.cpp:106] Creating Layer fire4/expand1x1
I0604 20:56:02.939682   844 net.cpp:454] fire4/expand1x1 <- fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_0
I0604 20:56:02.939707   844 net.cpp:411] fire4/expand1x1 -> fire4/expand1x1
I0604 20:56:02.943406   844 net.cpp:150] Setting up fire4/expand1x1
I0604 20:56:02.943420   844 net.cpp:157] Top shape: 50 128 30 30 (5760000)
I0604 20:56:02.943423   844 net.cpp:165] Memory required for data: 377357400
I0604 20:56:02.943439   844 layer_factory.hpp:77] Creating layer fire4/relu_expand1x1
I0604 20:56:02.943445   844 net.cpp:106] Creating Layer fire4/relu_expand1x1
I0604 20:56:02.943449   844 net.cpp:454] fire4/relu_expand1x1 <- fire4/expand1x1
I0604 20:56:02.943457   844 net.cpp:397] fire4/relu_expand1x1 -> fire4/expand1x1 (in-place)
I0604 20:56:02.944007   844 net.cpp:150] Setting up fire4/relu_expand1x1
I0604 20:56:02.944017   844 net.cpp:157] Top shape: 50 128 30 30 (5760000)
I0604 20:56:02.944020   844 net.cpp:165] Memory required for data: 400397400
I0604 20:56:02.944023   844 layer_factory.hpp:77] Creating layer fire4/expand3x3
I0604 20:56:02.944036   844 net.cpp:106] Creating Layer fire4/expand3x3
I0604 20:56:02.944041   844 net.cpp:454] fire4/expand3x3 <- fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_1
I0604 20:56:02.944052   844 net.cpp:411] fire4/expand3x3 -> fire4/expand3x3
I0604 20:56:02.946728   844 net.cpp:150] Setting up fire4/expand3x3
I0604 20:56:02.946743   844 net.cpp:157] Top shape: 50 128 30 30 (5760000)
I0604 20:56:02.946746   844 net.cpp:165] Memory required for data: 423437400
I0604 20:56:02.946753   844 layer_factory.hpp:77] Creating layer fire4/relu_expand3x3
I0604 20:56:02.946760   844 net.cpp:106] Creating Layer fire4/relu_expand3x3
I0604 20:56:02.946764   844 net.cpp:454] fire4/relu_expand3x3 <- fire4/expand3x3
I0604 20:56:02.946773   844 net.cpp:397] fire4/relu_expand3x3 -> fire4/expand3x3 (in-place)
I0604 20:56:02.947926   844 net.cpp:150] Setting up fire4/relu_expand3x3
I0604 20:56:02.947938   844 net.cpp:157] Top shape: 50 128 30 30 (5760000)
I0604 20:56:02.947942   844 net.cpp:165] Memory required for data: 446477400
I0604 20:56:02.947945   844 layer_factory.hpp:77] Creating layer fire4/concat
I0604 20:56:02.947953   844 net.cpp:106] Creating Layer fire4/concat
I0604 20:56:02.947957   844 net.cpp:454] fire4/concat <- fire4/expand1x1
I0604 20:56:02.947962   844 net.cpp:454] fire4/concat <- fire4/expand3x3
I0604 20:56:02.947968   844 net.cpp:411] fire4/concat -> fire4/concat
I0604 20:56:02.948010   844 net.cpp:150] Setting up fire4/concat
I0604 20:56:02.948017   844 net.cpp:157] Top shape: 50 256 30 30 (11520000)
I0604 20:56:02.948020   844 net.cpp:165] Memory required for data: 492557400
I0604 20:56:02.948024   844 layer_factory.hpp:77] Creating layer pool4
I0604 20:56:02.948030   844 net.cpp:106] Creating Layer pool4
I0604 20:56:02.948034   844 net.cpp:454] pool4 <- fire4/concat
I0604 20:56:02.948040   844 net.cpp:411] pool4 -> pool4
I0604 20:56:02.948091   844 net.cpp:150] Setting up pool4
I0604 20:56:02.948098   844 net.cpp:157] Top shape: 50 256 15 15 (2880000)
I0604 20:56:02.948101   844 net.cpp:165] Memory required for data: 504077400
I0604 20:56:02.948104   844 layer_factory.hpp:77] Creating layer fire5/squeeze1x1
I0604 20:56:02.948112   844 net.cpp:106] Creating Layer fire5/squeeze1x1
I0604 20:56:02.948115   844 net.cpp:454] fire5/squeeze1x1 <- pool4
I0604 20:56:02.948122   844 net.cpp:411] fire5/squeeze1x1 -> fire5/squeeze1x1
I0604 20:56:02.951884   844 net.cpp:150] Setting up fire5/squeeze1x1
I0604 20:56:02.951897   844 net.cpp:157] Top shape: 50 32 15 15 (360000)
I0604 20:56:02.951900   844 net.cpp:165] Memory required for data: 505517400
I0604 20:56:02.951908   844 layer_factory.hpp:77] Creating layer fire5/relu_squeeze1x1
I0604 20:56:02.951915   844 net.cpp:106] Creating Layer fire5/relu_squeeze1x1
I0604 20:56:02.951918   844 net.cpp:454] fire5/relu_squeeze1x1 <- fire5/squeeze1x1
I0604 20:56:02.951926   844 net.cpp:397] fire5/relu_squeeze1x1 -> fire5/squeeze1x1 (in-place)
I0604 20:56:02.952918   844 net.cpp:150] Setting up fire5/relu_squeeze1x1
I0604 20:56:02.952939   844 net.cpp:157] Top shape: 50 32 15 15 (360000)
I0604 20:56:02.952960   844 net.cpp:165] Memory required for data: 506957400
I0604 20:56:02.952963   844 layer_factory.hpp:77] Creating layer fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I0604 20:56:02.952977   844 net.cpp:106] Creating Layer fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I0604 20:56:02.952981   844 net.cpp:454] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split <- fire5/squeeze1x1
I0604 20:56:02.952987   844 net.cpp:411] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split -> fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_0
I0604 20:56:02.952996   844 net.cpp:411] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split -> fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_1
I0604 20:56:02.953057   844 net.cpp:150] Setting up fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I0604 20:56:02.953063   844 net.cpp:157] Top shape: 50 32 15 15 (360000)
I0604 20:56:02.953068   844 net.cpp:157] Top shape: 50 32 15 15 (360000)
I0604 20:56:02.953070   844 net.cpp:165] Memory required for data: 509837400
I0604 20:56:02.953073   844 layer_factory.hpp:77] Creating layer fire5/expand1x1
I0604 20:56:02.953084   844 net.cpp:106] Creating Layer fire5/expand1x1
I0604 20:56:02.953091   844 net.cpp:454] fire5/expand1x1 <- fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_0
I0604 20:56:02.953099   844 net.cpp:411] fire5/expand1x1 -> fire5/expand1x1
I0604 20:56:02.957772   844 net.cpp:150] Setting up fire5/expand1x1
I0604 20:56:02.957788   844 net.cpp:157] Top shape: 50 128 15 15 (1440000)
I0604 20:56:02.957793   844 net.cpp:165] Memory required for data: 515597400
I0604 20:56:02.957800   844 layer_factory.hpp:77] Creating layer fire5/relu_expand1x1
I0604 20:56:02.957809   844 net.cpp:106] Creating Layer fire5/relu_expand1x1
I0604 20:56:02.957814   844 net.cpp:454] fire5/relu_expand1x1 <- fire5/expand1x1
I0604 20:56:02.957819   844 net.cpp:397] fire5/relu_expand1x1 -> fire5/expand1x1 (in-place)
I0604 20:56:02.958781   844 net.cpp:150] Setting up fire5/relu_expand1x1
I0604 20:56:02.958791   844 net.cpp:157] Top shape: 50 128 15 15 (1440000)
I0604 20:56:02.958794   844 net.cpp:165] Memory required for data: 521357400
I0604 20:56:02.958798   844 layer_factory.hpp:77] Creating layer fire5/expand3x3
I0604 20:56:02.958811   844 net.cpp:106] Creating Layer fire5/expand3x3
I0604 20:56:02.958814   844 net.cpp:454] fire5/expand3x3 <- fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_1
I0604 20:56:02.958822   844 net.cpp:411] fire5/expand3x3 -> fire5/expand3x3
I0604 20:56:02.962762   844 net.cpp:150] Setting up fire5/expand3x3
I0604 20:56:02.962776   844 net.cpp:157] Top shape: 50 128 15 15 (1440000)
I0604 20:56:02.962780   844 net.cpp:165] Memory required for data: 527117400
I0604 20:56:02.962787   844 layer_factory.hpp:77] Creating layer fire5/relu_expand3x3
I0604 20:56:02.962793   844 net.cpp:106] Creating Layer fire5/relu_expand3x3
I0604 20:56:02.962797   844 net.cpp:454] fire5/relu_expand3x3 <- fire5/expand3x3
I0604 20:56:02.962805   844 net.cpp:397] fire5/relu_expand3x3 -> fire5/expand3x3 (in-place)
I0604 20:56:02.964077   844 net.cpp:150] Setting up fire5/relu_expand3x3
I0604 20:56:02.964087   844 net.cpp:157] Top shape: 50 128 15 15 (1440000)
I0604 20:56:02.964089   844 net.cpp:165] Memory required for data: 532877400
I0604 20:56:02.964093   844 layer_factory.hpp:77] Creating layer fire5/concat
I0604 20:56:02.964102   844 net.cpp:106] Creating Layer fire5/concat
I0604 20:56:02.964104   844 net.cpp:454] fire5/concat <- fire5/expand1x1
I0604 20:56:02.964109   844 net.cpp:454] fire5/concat <- fire5/expand3x3
I0604 20:56:02.964114   844 net.cpp:411] fire5/concat -> fire5/concat
I0604 20:56:02.964154   844 net.cpp:150] Setting up fire5/concat
I0604 20:56:02.964161   844 net.cpp:157] Top shape: 50 256 15 15 (2880000)
I0604 20:56:02.964164   844 net.cpp:165] Memory required for data: 544397400
I0604 20:56:02.964167   844 layer_factory.hpp:77] Creating layer fire6/squeeze1x1
I0604 20:56:02.964177   844 net.cpp:106] Creating Layer fire6/squeeze1x1
I0604 20:56:02.964184   844 net.cpp:454] fire6/squeeze1x1 <- fire5/concat
I0604 20:56:02.964189   844 net.cpp:411] fire6/squeeze1x1 -> fire6/squeeze1x1
I0604 20:56:02.969230   844 net.cpp:150] Setting up fire6/squeeze1x1
I0604 20:56:02.969244   844 net.cpp:157] Top shape: 50 48 15 15 (540000)
I0604 20:56:02.969247   844 net.cpp:165] Memory required for data: 546557400
I0604 20:56:02.969254   844 layer_factory.hpp:77] Creating layer fire6/relu_squeeze1x1
I0604 20:56:02.969264   844 net.cpp:106] Creating Layer fire6/relu_squeeze1x1
I0604 20:56:02.969267   844 net.cpp:454] fire6/relu_squeeze1x1 <- fire6/squeeze1x1
I0604 20:56:02.969272   844 net.cpp:397] fire6/relu_squeeze1x1 -> fire6/squeeze1x1 (in-place)
I0604 20:56:02.970399   844 net.cpp:150] Setting up fire6/relu_squeeze1x1
I0604 20:56:02.970412   844 net.cpp:157] Top shape: 50 48 15 15 (540000)
I0604 20:56:02.970414   844 net.cpp:165] Memory required for data: 548717400
I0604 20:56:02.970418   844 layer_factory.hpp:77] Creating layer fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I0604 20:56:02.970427   844 net.cpp:106] Creating Layer fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I0604 20:56:02.970430   844 net.cpp:454] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split <- fire6/squeeze1x1
I0604 20:56:02.970437   844 net.cpp:411] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split -> fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_0
I0604 20:56:02.970449   844 net.cpp:411] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split -> fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_1
I0604 20:56:02.970505   844 net.cpp:150] Setting up fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I0604 20:56:02.970515   844 net.cpp:157] Top shape: 50 48 15 15 (540000)
I0604 20:56:02.970520   844 net.cpp:157] Top shape: 50 48 15 15 (540000)
I0604 20:56:02.970522   844 net.cpp:165] Memory required for data: 553037400
I0604 20:56:02.970525   844 layer_factory.hpp:77] Creating layer fire6/expand1x1
I0604 20:56:02.970535   844 net.cpp:106] Creating Layer fire6/expand1x1
I0604 20:56:02.970541   844 net.cpp:454] fire6/expand1x1 <- fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_0
I0604 20:56:02.970549   844 net.cpp:411] fire6/expand1x1 -> fire6/expand1x1
I0604 20:56:02.977185   844 net.cpp:150] Setting up fire6/expand1x1
I0604 20:56:02.977200   844 net.cpp:157] Top shape: 50 192 15 15 (2160000)
I0604 20:56:02.977203   844 net.cpp:165] Memory required for data: 561677400
I0604 20:56:02.977211   844 layer_factory.hpp:77] Creating layer fire6/relu_expand1x1
I0604 20:56:02.977217   844 net.cpp:106] Creating Layer fire6/relu_expand1x1
I0604 20:56:02.977221   844 net.cpp:454] fire6/relu_expand1x1 <- fire6/expand1x1
I0604 20:56:02.977228   844 net.cpp:397] fire6/relu_expand1x1 -> fire6/expand1x1 (in-place)
I0604 20:56:02.978325   844 net.cpp:150] Setting up fire6/relu_expand1x1
I0604 20:56:02.978337   844 net.cpp:157] Top shape: 50 192 15 15 (2160000)
I0604 20:56:02.978343   844 net.cpp:165] Memory required for data: 570317400
I0604 20:56:02.978345   844 layer_factory.hpp:77] Creating layer fire6/expand3x3
I0604 20:56:02.978356   844 net.cpp:106] Creating Layer fire6/expand3x3
I0604 20:56:02.978359   844 net.cpp:454] fire6/expand3x3 <- fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_1
I0604 20:56:02.978368   844 net.cpp:411] fire6/expand3x3 -> fire6/expand3x3
I0604 20:56:02.982426   844 net.cpp:150] Setting up fire6/expand3x3
I0604 20:56:02.982440   844 net.cpp:157] Top shape: 50 192 15 15 (2160000)
I0604 20:56:02.982444   844 net.cpp:165] Memory required for data: 578957400
I0604 20:56:02.982450   844 layer_factory.hpp:77] Creating layer fire6/relu_expand3x3
I0604 20:56:02.982457   844 net.cpp:106] Creating Layer fire6/relu_expand3x3
I0604 20:56:02.982460   844 net.cpp:454] fire6/relu_expand3x3 <- fire6/expand3x3
I0604 20:56:02.982470   844 net.cpp:397] fire6/relu_expand3x3 -> fire6/expand3x3 (in-place)
I0604 20:56:02.983527   844 net.cpp:150] Setting up fire6/relu_expand3x3
I0604 20:56:02.983541   844 net.cpp:157] Top shape: 50 192 15 15 (2160000)
I0604 20:56:02.983544   844 net.cpp:165] Memory required for data: 587597400
I0604 20:56:02.983548   844 layer_factory.hpp:77] Creating layer fire6/concat
I0604 20:56:02.983554   844 net.cpp:106] Creating Layer fire6/concat
I0604 20:56:02.983574   844 net.cpp:454] fire6/concat <- fire6/expand1x1
I0604 20:56:02.983579   844 net.cpp:454] fire6/concat <- fire6/expand3x3
I0604 20:56:02.983584   844 net.cpp:411] fire6/concat -> fire6/concat
I0604 20:56:02.983626   844 net.cpp:150] Setting up fire6/concat
I0604 20:56:02.983633   844 net.cpp:157] Top shape: 50 384 15 15 (4320000)
I0604 20:56:02.983636   844 net.cpp:165] Memory required for data: 604877400
I0604 20:56:02.983639   844 layer_factory.hpp:77] Creating layer fire7/squeeze1x1
I0604 20:56:02.983649   844 net.cpp:106] Creating Layer fire7/squeeze1x1
I0604 20:56:02.983654   844 net.cpp:454] fire7/squeeze1x1 <- fire6/concat
I0604 20:56:02.983659   844 net.cpp:411] fire7/squeeze1x1 -> fire7/squeeze1x1
I0604 20:56:02.986104   844 net.cpp:150] Setting up fire7/squeeze1x1
I0604 20:56:02.986120   844 net.cpp:157] Top shape: 50 48 15 15 (540000)
I0604 20:56:02.986124   844 net.cpp:165] Memory required for data: 607037400
I0604 20:56:02.986140   844 layer_factory.hpp:77] Creating layer fire7/relu_squeeze1x1
I0604 20:56:02.986150   844 net.cpp:106] Creating Layer fire7/relu_squeeze1x1
I0604 20:56:02.986152   844 net.cpp:454] fire7/relu_squeeze1x1 <- fire7/squeeze1x1
I0604 20:56:02.986158   844 net.cpp:397] fire7/relu_squeeze1x1 -> fire7/squeeze1x1 (in-place)
I0604 20:56:02.987092   844 net.cpp:150] Setting up fire7/relu_squeeze1x1
I0604 20:56:02.987105   844 net.cpp:157] Top shape: 50 48 15 15 (540000)
I0604 20:56:02.987108   844 net.cpp:165] Memory required for data: 609197400
I0604 20:56:02.987112   844 layer_factory.hpp:77] Creating layer fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I0604 20:56:02.987121   844 net.cpp:106] Creating Layer fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I0604 20:56:02.987124   844 net.cpp:454] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split <- fire7/squeeze1x1
I0604 20:56:02.987130   844 net.cpp:411] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split -> fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_0
I0604 20:56:02.987138   844 net.cpp:411] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split -> fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_1
I0604 20:56:02.987200   844 net.cpp:150] Setting up fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I0604 20:56:02.987207   844 net.cpp:157] Top shape: 50 48 15 15 (540000)
I0604 20:56:02.987211   844 net.cpp:157] Top shape: 50 48 15 15 (540000)
I0604 20:56:02.987215   844 net.cpp:165] Memory required for data: 613517400
I0604 20:56:02.987217   844 layer_factory.hpp:77] Creating layer fire7/expand1x1
I0604 20:56:02.987227   844 net.cpp:106] Creating Layer fire7/expand1x1
I0604 20:56:02.987234   844 net.cpp:454] fire7/expand1x1 <- fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_0
I0604 20:56:02.987243   844 net.cpp:411] fire7/expand1x1 -> fire7/expand1x1
I0604 20:56:02.991438   844 net.cpp:150] Setting up fire7/expand1x1
I0604 20:56:02.991457   844 net.cpp:157] Top shape: 50 192 15 15 (2160000)
I0604 20:56:02.991463   844 net.cpp:165] Memory required for data: 622157400
I0604 20:56:02.991483   844 layer_factory.hpp:77] Creating layer fire7/relu_expand1x1
I0604 20:56:02.991497   844 net.cpp:106] Creating Layer fire7/relu_expand1x1
I0604 20:56:02.991502   844 net.cpp:454] fire7/relu_expand1x1 <- fire7/expand1x1
I0604 20:56:02.991508   844 net.cpp:397] fire7/relu_expand1x1 -> fire7/expand1x1 (in-place)
I0604 20:56:02.992821   844 net.cpp:150] Setting up fire7/relu_expand1x1
I0604 20:56:02.992835   844 net.cpp:157] Top shape: 50 192 15 15 (2160000)
I0604 20:56:02.992837   844 net.cpp:165] Memory required for data: 630797400
I0604 20:56:02.992841   844 layer_factory.hpp:77] Creating layer fire7/expand3x3
I0604 20:56:02.992852   844 net.cpp:106] Creating Layer fire7/expand3x3
I0604 20:56:02.992856   844 net.cpp:454] fire7/expand3x3 <- fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_1
I0604 20:56:02.992862   844 net.cpp:411] fire7/expand3x3 -> fire7/expand3x3
I0604 20:56:02.997896   844 net.cpp:150] Setting up fire7/expand3x3
I0604 20:56:02.997921   844 net.cpp:157] Top shape: 50 192 15 15 (2160000)
I0604 20:56:02.997925   844 net.cpp:165] Memory required for data: 639437400
I0604 20:56:02.997967   844 layer_factory.hpp:77] Creating layer fire7/relu_expand3x3
I0604 20:56:02.997999   844 net.cpp:106] Creating Layer fire7/relu_expand3x3
I0604 20:56:02.998013   844 net.cpp:454] fire7/relu_expand3x3 <- fire7/expand3x3
I0604 20:56:02.998023   844 net.cpp:397] fire7/relu_expand3x3 -> fire7/expand3x3 (in-place)
I0604 20:56:02.999006   844 net.cpp:150] Setting up fire7/relu_expand3x3
I0604 20:56:02.999019   844 net.cpp:157] Top shape: 50 192 15 15 (2160000)
I0604 20:56:02.999024   844 net.cpp:165] Memory required for data: 648077400
I0604 20:56:02.999030   844 layer_factory.hpp:77] Creating layer fire7/concat
I0604 20:56:02.999042   844 net.cpp:106] Creating Layer fire7/concat
I0604 20:56:02.999068   844 net.cpp:454] fire7/concat <- fire7/expand1x1
I0604 20:56:02.999076   844 net.cpp:454] fire7/concat <- fire7/expand3x3
I0604 20:56:02.999089   844 net.cpp:411] fire7/concat -> fire7/concat
I0604 20:56:02.999162   844 net.cpp:150] Setting up fire7/concat
I0604 20:56:02.999173   844 net.cpp:157] Top shape: 50 384 15 15 (4320000)
I0604 20:56:02.999178   844 net.cpp:165] Memory required for data: 665357400
I0604 20:56:02.999183   844 layer_factory.hpp:77] Creating layer fire8/squeeze1x1
I0604 20:56:02.999209   844 net.cpp:106] Creating Layer fire8/squeeze1x1
I0604 20:56:02.999217   844 net.cpp:454] fire8/squeeze1x1 <- fire7/concat
I0604 20:56:02.999227   844 net.cpp:411] fire8/squeeze1x1 -> fire8/squeeze1x1
I0604 20:56:03.003651   844 net.cpp:150] Setting up fire8/squeeze1x1
I0604 20:56:03.003674   844 net.cpp:157] Top shape: 50 64 15 15 (720000)
I0604 20:56:03.003679   844 net.cpp:165] Memory required for data: 668237400
I0604 20:56:03.003686   844 layer_factory.hpp:77] Creating layer fire8/relu_squeeze1x1
I0604 20:56:03.003697   844 net.cpp:106] Creating Layer fire8/relu_squeeze1x1
I0604 20:56:03.003701   844 net.cpp:454] fire8/relu_squeeze1x1 <- fire8/squeeze1x1
I0604 20:56:03.003708   844 net.cpp:397] fire8/relu_squeeze1x1 -> fire8/squeeze1x1 (in-place)
I0604 20:56:03.004621   844 net.cpp:150] Setting up fire8/relu_squeeze1x1
I0604 20:56:03.004637   844 net.cpp:157] Top shape: 50 64 15 15 (720000)
I0604 20:56:03.004640   844 net.cpp:165] Memory required for data: 671117400
I0604 20:56:03.004644   844 layer_factory.hpp:77] Creating layer fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I0604 20:56:03.004652   844 net.cpp:106] Creating Layer fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I0604 20:56:03.004655   844 net.cpp:454] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split <- fire8/squeeze1x1
I0604 20:56:03.004662   844 net.cpp:411] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split -> fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_0
I0604 20:56:03.004674   844 net.cpp:411] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split -> fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_1
I0604 20:56:03.004739   844 net.cpp:150] Setting up fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I0604 20:56:03.004746   844 net.cpp:157] Top shape: 50 64 15 15 (720000)
I0604 20:56:03.004752   844 net.cpp:157] Top shape: 50 64 15 15 (720000)
I0604 20:56:03.004755   844 net.cpp:165] Memory required for data: 676877400
I0604 20:56:03.004758   844 layer_factory.hpp:77] Creating layer fire8/expand1x1
I0604 20:56:03.004770   844 net.cpp:106] Creating Layer fire8/expand1x1
I0604 20:56:03.004775   844 net.cpp:454] fire8/expand1x1 <- fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_0
I0604 20:56:03.004782   844 net.cpp:411] fire8/expand1x1 -> fire8/expand1x1
I0604 20:56:03.009276   844 net.cpp:150] Setting up fire8/expand1x1
I0604 20:56:03.009291   844 net.cpp:157] Top shape: 50 256 15 15 (2880000)
I0604 20:56:03.009295   844 net.cpp:165] Memory required for data: 688397400
I0604 20:56:03.009302   844 layer_factory.hpp:77] Creating layer fire8/relu_expand1x1
I0604 20:56:03.009310   844 net.cpp:106] Creating Layer fire8/relu_expand1x1
I0604 20:56:03.009313   844 net.cpp:454] fire8/relu_expand1x1 <- fire8/expand1x1
I0604 20:56:03.009320   844 net.cpp:397] fire8/relu_expand1x1 -> fire8/expand1x1 (in-place)
I0604 20:56:03.010283   844 net.cpp:150] Setting up fire8/relu_expand1x1
I0604 20:56:03.010294   844 net.cpp:157] Top shape: 50 256 15 15 (2880000)
I0604 20:56:03.010298   844 net.cpp:165] Memory required for data: 699917400
I0604 20:56:03.010301   844 layer_factory.hpp:77] Creating layer fire8/expand3x3
I0604 20:56:03.010311   844 net.cpp:106] Creating Layer fire8/expand3x3
I0604 20:56:03.010318   844 net.cpp:454] fire8/expand3x3 <- fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_1
I0604 20:56:03.010327   844 net.cpp:411] fire8/expand3x3 -> fire8/expand3x3
I0604 20:56:03.015010   844 net.cpp:150] Setting up fire8/expand3x3
I0604 20:56:03.015024   844 net.cpp:157] Top shape: 50 256 15 15 (2880000)
I0604 20:56:03.015028   844 net.cpp:165] Memory required for data: 711437400
I0604 20:56:03.015035   844 layer_factory.hpp:77] Creating layer fire8/relu_expand3x3
I0604 20:56:03.015043   844 net.cpp:106] Creating Layer fire8/relu_expand3x3
I0604 20:56:03.015048   844 net.cpp:454] fire8/relu_expand3x3 <- fire8/expand3x3
I0604 20:56:03.015055   844 net.cpp:397] fire8/relu_expand3x3 -> fire8/expand3x3 (in-place)
I0604 20:56:03.016032   844 net.cpp:150] Setting up fire8/relu_expand3x3
I0604 20:56:03.016043   844 net.cpp:157] Top shape: 50 256 15 15 (2880000)
I0604 20:56:03.016047   844 net.cpp:165] Memory required for data: 722957400
I0604 20:56:03.016050   844 layer_factory.hpp:77] Creating layer fire8/concat
I0604 20:56:03.016057   844 net.cpp:106] Creating Layer fire8/concat
I0604 20:56:03.016060   844 net.cpp:454] fire8/concat <- fire8/expand1x1
I0604 20:56:03.016064   844 net.cpp:454] fire8/concat <- fire8/expand3x3
I0604 20:56:03.016072   844 net.cpp:411] fire8/concat -> fire8/concat
I0604 20:56:03.016129   844 net.cpp:150] Setting up fire8/concat
I0604 20:56:03.016139   844 net.cpp:157] Top shape: 50 512 15 15 (5760000)
I0604 20:56:03.016144   844 net.cpp:165] Memory required for data: 745997400
I0604 20:56:03.016152   844 layer_factory.hpp:77] Creating layer pool8
I0604 20:56:03.016163   844 net.cpp:106] Creating Layer pool8
I0604 20:56:03.016167   844 net.cpp:454] pool8 <- fire8/concat
I0604 20:56:03.016175   844 net.cpp:411] pool8 -> pool8
I0604 20:56:03.016247   844 net.cpp:150] Setting up pool8
I0604 20:56:03.016254   844 net.cpp:157] Top shape: 50 512 7 7 (1254400)
I0604 20:56:03.016258   844 net.cpp:165] Memory required for data: 751015000
I0604 20:56:03.016260   844 layer_factory.hpp:77] Creating layer fire9/squeeze1x1
I0604 20:56:03.016270   844 net.cpp:106] Creating Layer fire9/squeeze1x1
I0604 20:56:03.016274   844 net.cpp:454] fire9/squeeze1x1 <- pool8
I0604 20:56:03.016281   844 net.cpp:411] fire9/squeeze1x1 -> fire9/squeeze1x1
I0604 20:56:03.019716   844 net.cpp:150] Setting up fire9/squeeze1x1
I0604 20:56:03.019729   844 net.cpp:157] Top shape: 50 64 7 7 (156800)
I0604 20:56:03.019738   844 net.cpp:165] Memory required for data: 751642200
I0604 20:56:03.019745   844 layer_factory.hpp:77] Creating layer fire9/relu_squeeze1x1
I0604 20:56:03.019765   844 net.cpp:106] Creating Layer fire9/relu_squeeze1x1
I0604 20:56:03.019770   844 net.cpp:454] fire9/relu_squeeze1x1 <- fire9/squeeze1x1
I0604 20:56:03.019776   844 net.cpp:397] fire9/relu_squeeze1x1 -> fire9/squeeze1x1 (in-place)
I0604 20:56:03.020755   844 net.cpp:150] Setting up fire9/relu_squeeze1x1
I0604 20:56:03.020769   844 net.cpp:157] Top shape: 50 64 7 7 (156800)
I0604 20:56:03.020778   844 net.cpp:165] Memory required for data: 752269400
I0604 20:56:03.020783   844 layer_factory.hpp:77] Creating layer fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I0604 20:56:03.020789   844 net.cpp:106] Creating Layer fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I0604 20:56:03.020793   844 net.cpp:454] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split <- fire9/squeeze1x1
I0604 20:56:03.020799   844 net.cpp:411] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split -> fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_0
I0604 20:56:03.020807   844 net.cpp:411] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split -> fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_1
I0604 20:56:03.020870   844 net.cpp:150] Setting up fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I0604 20:56:03.020895   844 net.cpp:157] Top shape: 50 64 7 7 (156800)
I0604 20:56:03.020898   844 net.cpp:157] Top shape: 50 64 7 7 (156800)
I0604 20:56:03.020901   844 net.cpp:165] Memory required for data: 753523800
I0604 20:56:03.020905   844 layer_factory.hpp:77] Creating layer fire9/expand1x1
I0604 20:56:03.020915   844 net.cpp:106] Creating Layer fire9/expand1x1
I0604 20:56:03.020918   844 net.cpp:454] fire9/expand1x1 <- fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_0
I0604 20:56:03.020926   844 net.cpp:411] fire9/expand1x1 -> fire9/expand1x1
I0604 20:56:03.024441   844 net.cpp:150] Setting up fire9/expand1x1
I0604 20:56:03.024461   844 net.cpp:157] Top shape: 50 256 7 7 (627200)
I0604 20:56:03.024466   844 net.cpp:165] Memory required for data: 756032600
I0604 20:56:03.024480   844 layer_factory.hpp:77] Creating layer fire9/relu_expand1x1
I0604 20:56:03.024488   844 net.cpp:106] Creating Layer fire9/relu_expand1x1
I0604 20:56:03.024492   844 net.cpp:454] fire9/relu_expand1x1 <- fire9/expand1x1
I0604 20:56:03.024498   844 net.cpp:397] fire9/relu_expand1x1 -> fire9/expand1x1 (in-place)
I0604 20:56:03.025451   844 net.cpp:150] Setting up fire9/relu_expand1x1
I0604 20:56:03.025463   844 net.cpp:157] Top shape: 50 256 7 7 (627200)
I0604 20:56:03.025466   844 net.cpp:165] Memory required for data: 758541400
I0604 20:56:03.025470   844 layer_factory.hpp:77] Creating layer fire9/expand3x3
I0604 20:56:03.025481   844 net.cpp:106] Creating Layer fire9/expand3x3
I0604 20:56:03.025485   844 net.cpp:454] fire9/expand3x3 <- fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_1
I0604 20:56:03.025493   844 net.cpp:411] fire9/expand3x3 -> fire9/expand3x3
I0604 20:56:03.029127   844 net.cpp:150] Setting up fire9/expand3x3
I0604 20:56:03.029141   844 net.cpp:157] Top shape: 50 256 7 7 (627200)
I0604 20:56:03.029145   844 net.cpp:165] Memory required for data: 761050200
I0604 20:56:03.029152   844 layer_factory.hpp:77] Creating layer fire9/relu_expand3x3
I0604 20:56:03.029160   844 net.cpp:106] Creating Layer fire9/relu_expand3x3
I0604 20:56:03.029163   844 net.cpp:454] fire9/relu_expand3x3 <- fire9/expand3x3
I0604 20:56:03.029171   844 net.cpp:397] fire9/relu_expand3x3 -> fire9/expand3x3 (in-place)
I0604 20:56:03.030164   844 net.cpp:150] Setting up fire9/relu_expand3x3
I0604 20:56:03.030174   844 net.cpp:157] Top shape: 50 256 7 7 (627200)
I0604 20:56:03.030177   844 net.cpp:165] Memory required for data: 763559000
I0604 20:56:03.030184   844 layer_factory.hpp:77] Creating layer fire9/concat
I0604 20:56:03.030191   844 net.cpp:106] Creating Layer fire9/concat
I0604 20:56:03.030195   844 net.cpp:454] fire9/concat <- fire9/expand1x1
I0604 20:56:03.030200   844 net.cpp:454] fire9/concat <- fire9/expand3x3
I0604 20:56:03.030205   844 net.cpp:411] fire9/concat -> fire9/concat
I0604 20:56:03.030247   844 net.cpp:150] Setting up fire9/concat
I0604 20:56:03.030256   844 net.cpp:157] Top shape: 50 512 7 7 (1254400)
I0604 20:56:03.030258   844 net.cpp:165] Memory required for data: 768576600
I0604 20:56:03.030262   844 layer_factory.hpp:77] Creating layer drop9
I0604 20:56:03.030268   844 net.cpp:106] Creating Layer drop9
I0604 20:56:03.030272   844 net.cpp:454] drop9 <- fire9/concat
I0604 20:56:03.030278   844 net.cpp:397] drop9 -> fire9/concat (in-place)
I0604 20:56:03.030311   844 net.cpp:150] Setting up drop9
I0604 20:56:03.030320   844 net.cpp:157] Top shape: 50 512 7 7 (1254400)
I0604 20:56:03.030323   844 net.cpp:165] Memory required for data: 773594200
I0604 20:56:03.030326   844 layer_factory.hpp:77] Creating layer conv10
I0604 20:56:03.030334   844 net.cpp:106] Creating Layer conv10
I0604 20:56:03.030339   844 net.cpp:454] conv10 <- fire9/concat
I0604 20:56:03.030346   844 net.cpp:411] conv10 -> conv10
I0604 20:56:03.049615   844 net.cpp:150] Setting up conv10
I0604 20:56:03.049643   844 net.cpp:157] Top shape: 50 1000 9 9 (4050000)
I0604 20:56:03.049649   844 net.cpp:165] Memory required for data: 789794200
I0604 20:56:03.049656   844 layer_factory.hpp:77] Creating layer relu_conv10
I0604 20:56:03.049690   844 net.cpp:106] Creating Layer relu_conv10
I0604 20:56:03.049695   844 net.cpp:454] relu_conv10 <- conv10
I0604 20:56:03.049707   844 net.cpp:397] relu_conv10 -> conv10 (in-place)
I0604 20:56:03.050737   844 net.cpp:150] Setting up relu_conv10
I0604 20:56:03.050750   844 net.cpp:157] Top shape: 50 1000 9 9 (4050000)
I0604 20:56:03.050753   844 net.cpp:165] Memory required for data: 805994200
I0604 20:56:03.050760   844 layer_factory.hpp:77] Creating layer pool10
I0604 20:56:03.050767   844 net.cpp:106] Creating Layer pool10
I0604 20:56:03.050771   844 net.cpp:454] pool10 <- conv10
I0604 20:56:03.050779   844 net.cpp:411] pool10 -> pool10
I0604 20:56:03.051808   844 net.cpp:150] Setting up pool10
I0604 20:56:03.051820   844 net.cpp:157] Top shape: 50 1000 1 1 (50000)
I0604 20:56:03.051823   844 net.cpp:165] Memory required for data: 806194200
I0604 20:56:03.051831   844 layer_factory.hpp:77] Creating layer pool10_pool10_0_split
I0604 20:56:03.051838   844 net.cpp:106] Creating Layer pool10_pool10_0_split
I0604 20:56:03.051841   844 net.cpp:454] pool10_pool10_0_split <- pool10
I0604 20:56:03.051847   844 net.cpp:411] pool10_pool10_0_split -> pool10_pool10_0_split_0
I0604 20:56:03.051854   844 net.cpp:411] pool10_pool10_0_split -> pool10_pool10_0_split_1
I0604 20:56:03.051909   844 net.cpp:150] Setting up pool10_pool10_0_split
I0604 20:56:03.051916   844 net.cpp:157] Top shape: 50 1000 1 1 (50000)
I0604 20:56:03.051921   844 net.cpp:157] Top shape: 50 1000 1 1 (50000)
I0604 20:56:03.051923   844 net.cpp:165] Memory required for data: 806594200
I0604 20:56:03.051926   844 layer_factory.hpp:77] Creating layer accuracy
I0604 20:56:03.051935   844 net.cpp:106] Creating Layer accuracy
I0604 20:56:03.051939   844 net.cpp:454] accuracy <- pool10_pool10_0_split_0
I0604 20:56:03.051944   844 net.cpp:454] accuracy <- label_data_1_split_0
I0604 20:56:03.051949   844 net.cpp:411] accuracy -> accuracy
I0604 20:56:03.051959   844 net.cpp:150] Setting up accuracy
I0604 20:56:03.051962   844 net.cpp:157] Top shape: (1)
I0604 20:56:03.051965   844 net.cpp:165] Memory required for data: 806594204
I0604 20:56:03.051969   844 layer_factory.hpp:77] Creating layer accuracy_top5
I0604 20:56:03.051975   844 net.cpp:106] Creating Layer accuracy_top5
I0604 20:56:03.051978   844 net.cpp:454] accuracy_top5 <- pool10_pool10_0_split_1
I0604 20:56:03.051983   844 net.cpp:454] accuracy_top5 <- label_data_1_split_1
I0604 20:56:03.051988   844 net.cpp:411] accuracy_top5 -> accuracy_top5
I0604 20:56:03.051995   844 net.cpp:150] Setting up accuracy_top5
I0604 20:56:03.052000   844 net.cpp:157] Top shape: (1)
I0604 20:56:03.052002   844 net.cpp:165] Memory required for data: 806594208
I0604 20:56:03.052007   844 net.cpp:228] accuracy_top5 does not need backward computation.
I0604 20:56:03.052011   844 net.cpp:228] accuracy does not need backward computation.
I0604 20:56:03.052014   844 net.cpp:228] pool10_pool10_0_split does not need backward computation.
I0604 20:56:03.052017   844 net.cpp:228] pool10 does not need backward computation.
I0604 20:56:03.052021   844 net.cpp:228] relu_conv10 does not need backward computation.
I0604 20:56:03.052023   844 net.cpp:228] conv10 does not need backward computation.
I0604 20:56:03.052027   844 net.cpp:228] drop9 does not need backward computation.
I0604 20:56:03.052031   844 net.cpp:228] fire9/concat does not need backward computation.
I0604 20:56:03.052034   844 net.cpp:228] fire9/relu_expand3x3 does not need backward computation.
I0604 20:56:03.052037   844 net.cpp:228] fire9/expand3x3 does not need backward computation.
I0604 20:56:03.052042   844 net.cpp:228] fire9/relu_expand1x1 does not need backward computation.
I0604 20:56:03.052044   844 net.cpp:228] fire9/expand1x1 does not need backward computation.
I0604 20:56:03.052048   844 net.cpp:228] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split does not need backward computation.
I0604 20:56:03.052052   844 net.cpp:228] fire9/relu_squeeze1x1 does not need backward computation.
I0604 20:56:03.052055   844 net.cpp:228] fire9/squeeze1x1 does not need backward computation.
I0604 20:56:03.052070   844 net.cpp:228] pool8 does not need backward computation.
I0604 20:56:03.052074   844 net.cpp:228] fire8/concat does not need backward computation.
I0604 20:56:03.052078   844 net.cpp:228] fire8/relu_expand3x3 does not need backward computation.
I0604 20:56:03.052081   844 net.cpp:228] fire8/expand3x3 does not need backward computation.
I0604 20:56:03.052085   844 net.cpp:228] fire8/relu_expand1x1 does not need backward computation.
I0604 20:56:03.052088   844 net.cpp:228] fire8/expand1x1 does not need backward computation.
I0604 20:56:03.052091   844 net.cpp:228] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split does not need backward computation.
I0604 20:56:03.052095   844 net.cpp:228] fire8/relu_squeeze1x1 does not need backward computation.
I0604 20:56:03.052098   844 net.cpp:228] fire8/squeeze1x1 does not need backward computation.
I0604 20:56:03.052103   844 net.cpp:228] fire7/concat does not need backward computation.
I0604 20:56:03.052105   844 net.cpp:228] fire7/relu_expand3x3 does not need backward computation.
I0604 20:56:03.052109   844 net.cpp:228] fire7/expand3x3 does not need backward computation.
I0604 20:56:03.052112   844 net.cpp:228] fire7/relu_expand1x1 does not need backward computation.
I0604 20:56:03.052115   844 net.cpp:228] fire7/expand1x1 does not need backward computation.
I0604 20:56:03.052119   844 net.cpp:228] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split does not need backward computation.
I0604 20:56:03.052124   844 net.cpp:228] fire7/relu_squeeze1x1 does not need backward computation.
I0604 20:56:03.052127   844 net.cpp:228] fire7/squeeze1x1 does not need backward computation.
I0604 20:56:03.052131   844 net.cpp:228] fire6/concat does not need backward computation.
I0604 20:56:03.052134   844 net.cpp:228] fire6/relu_expand3x3 does not need backward computation.
I0604 20:56:03.052139   844 net.cpp:228] fire6/expand3x3 does not need backward computation.
I0604 20:56:03.052145   844 net.cpp:228] fire6/relu_expand1x1 does not need backward computation.
I0604 20:56:03.052150   844 net.cpp:228] fire6/expand1x1 does not need backward computation.
I0604 20:56:03.052156   844 net.cpp:228] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split does not need backward computation.
I0604 20:56:03.052160   844 net.cpp:228] fire6/relu_squeeze1x1 does not need backward computation.
I0604 20:56:03.052163   844 net.cpp:228] fire6/squeeze1x1 does not need backward computation.
I0604 20:56:03.052167   844 net.cpp:228] fire5/concat does not need backward computation.
I0604 20:56:03.052171   844 net.cpp:228] fire5/relu_expand3x3 does not need backward computation.
I0604 20:56:03.052175   844 net.cpp:228] fire5/expand3x3 does not need backward computation.
I0604 20:56:03.052177   844 net.cpp:228] fire5/relu_expand1x1 does not need backward computation.
I0604 20:56:03.052181   844 net.cpp:228] fire5/expand1x1 does not need backward computation.
I0604 20:56:03.052183   844 net.cpp:228] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split does not need backward computation.
I0604 20:56:03.052187   844 net.cpp:228] fire5/relu_squeeze1x1 does not need backward computation.
I0604 20:56:03.052191   844 net.cpp:228] fire5/squeeze1x1 does not need backward computation.
I0604 20:56:03.052193   844 net.cpp:228] pool4 does not need backward computation.
I0604 20:56:03.052197   844 net.cpp:228] fire4/concat does not need backward computation.
I0604 20:56:03.052201   844 net.cpp:228] fire4/relu_expand3x3 does not need backward computation.
I0604 20:56:03.052204   844 net.cpp:228] fire4/expand3x3 does not need backward computation.
I0604 20:56:03.052207   844 net.cpp:228] fire4/relu_expand1x1 does not need backward computation.
I0604 20:56:03.052211   844 net.cpp:228] fire4/expand1x1 does not need backward computation.
I0604 20:56:03.052214   844 net.cpp:228] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split does not need backward computation.
I0604 20:56:03.052217   844 net.cpp:228] fire4/relu_squeeze1x1 does not need backward computation.
I0604 20:56:03.052220   844 net.cpp:228] fire4/squeeze1x1 does not need backward computation.
I0604 20:56:03.052232   844 net.cpp:228] fire3/concat does not need backward computation.
I0604 20:56:03.052235   844 net.cpp:228] fire3/relu_expand3x3 does not need backward computation.
I0604 20:56:03.052238   844 net.cpp:228] fire3/expand3x3 does not need backward computation.
I0604 20:56:03.052242   844 net.cpp:228] fire3/relu_expand1x1 does not need backward computation.
I0604 20:56:03.052245   844 net.cpp:228] fire3/expand1x1 does not need backward computation.
I0604 20:56:03.052248   844 net.cpp:228] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split does not need backward computation.
I0604 20:56:03.052253   844 net.cpp:228] fire3/relu_squeeze1x1 does not need backward computation.
I0604 20:56:03.052255   844 net.cpp:228] fire3/squeeze1x1 does not need backward computation.
I0604 20:56:03.052258   844 net.cpp:228] fire2/concat does not need backward computation.
I0604 20:56:03.052263   844 net.cpp:228] fire2/relu_expand3x3 does not need backward computation.
I0604 20:56:03.052265   844 net.cpp:228] fire2/expand3x3 does not need backward computation.
I0604 20:56:03.052268   844 net.cpp:228] fire2/relu_expand1x1 does not need backward computation.
I0604 20:56:03.052273   844 net.cpp:228] fire2/expand1x1 does not need backward computation.
I0604 20:56:03.052275   844 net.cpp:228] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split does not need backward computation.
I0604 20:56:03.052278   844 net.cpp:228] fire2/relu_squeeze1x1 does not need backward computation.
I0604 20:56:03.052283   844 net.cpp:228] fire2/squeeze1x1 does not need backward computation.
I0604 20:56:03.052285   844 net.cpp:228] pool1 does not need backward computation.
I0604 20:56:03.052289   844 net.cpp:228] relu_conv1 does not need backward computation.
I0604 20:56:03.052292   844 net.cpp:228] conv1 does not need backward computation.
I0604 20:56:03.052296   844 net.cpp:228] label_data_1_split does not need backward computation.
I0604 20:56:03.052299   844 net.cpp:228] data does not need backward computation.
I0604 20:56:03.052304   844 net.cpp:270] This network produces output accuracy
I0604 20:56:03.052306   844 net.cpp:270] This network produces output accuracy_top5
I0604 20:56:03.052359   844 net.cpp:283] Network initialization done.
I0604 20:56:03.052660   844 solver.cpp:60] Solver scaffolding done.
I0604 20:56:03.055330   844 caffe.cpp:129] Finetuning from SqueezeNet128.prototxt.caffemodel
I0604 20:56:03.069612   844 net.cpp:816] Ignoring source layer loss
I0604 20:56:03.069753   844 caffe.cpp:213] Starting Optimization
I0604 20:56:03.069761   844 solver.cpp:280] Solving 
I0604 20:56:03.069764   844 solver.cpp:281] Learning Rate Policy: poly
F0604 20:56:03.521221   844 syncedmem.cpp:56] Check failed: error == cudaSuccess (2 vs. 0)  out of memory
*** Check failure stack trace: ***
    @     0x7ff10e68985d  google::LogMessage::Fail()
    @     0x7ff10e68b623  google::LogMessage::SendToLog()
    @     0x7ff10e689478  google::LogMessage::Flush()
    @     0x7ff10e68be7e  google::LogMessageFatal::~LogMessageFatal()
    @     0x7ff113effad8  caffe::SyncedMemory::to_gpu()
    @     0x7ff113efeb89  caffe::SyncedMemory::mutable_gpu_data()
    @     0x7ff113f0b573  caffe::Blob<>::mutable_gpu_diff()
    @     0x7ff113f63081  caffe::PoolingLayer<>::Backward_gpu()
    @     0x7ff113f26c33  caffe::Net<>::BackwardFromTo()
    @     0x7ff113f26c7f  caffe::Net<>::Backward()
    @     0x7ff113f1d7f5  caffe::Solver<>::Step()
    @     0x7ff113f1e169  caffe::Solver<>::Solve()
    @           0x408deb  train()
    @           0x405b63  main
    @     0x7ff10651fb45  (unknown)
    @           0x40630c  (unknown)
I0604 20:56:50.400194   904 caffe.cpp:185] Using GPUs 1
I0604 20:56:51.652767   904 solver.cpp:48] Initializing solver from parameters: 
test_iter: 2000
test_interval: 1000
base_lr: 0.04
display: 40
max_iter: 170000
lr_policy: "poly"
power: 1
momentum: 0.9
weight_decay: 0.0002
snapshot: 1000
snapshot_prefix: "snapshots/squeezenet128_"
solver_mode: GPU
device_id: 1
random_seed: 42
net_param {
  layer {
    name: "data"
    type: "Data"
    top: "data"
    top: "label"
    include {
      phase: TRAIN
    }
    transform_param {
      scale: 0.04
      mirror: true
      crop_size: 128
      mean_value: 104
      mean_value: 117
      mean_value: 124
      force_color: true
    }
    data_param {
      source: "/local/temporary/mishkdmy/imagenet144pxlmdb/ilsvrc12_128_train_lmdb"
      batch_size: 256
      backend: LMDB
    }
  }
  layer {
    name: "data"
    type: "Data"
    top: "data"
    top: "label"
    include {
      phase: TEST
    }
    transform_param {
      scale: 0.04
      mirror: false
      crop_size: 128
      mean_value: 104
      mean_value: 117
      mean_value: 123
      force_color: true
    }
    data_param {
      source: "/local/temporary/mishkdmy/imagenet144pxlmdb/ilsvrc12_128_val_lmdb"
      batch_size: 50
      backend: LMDB
    }
  }
  layer {
    name: "conv1"
    type: "Convolution"
    bottom: "data"
    top: "conv1"
    convolution_param {
      num_output: 96
      kernel_size: 7
      stride: 2
      weight_filler {
        type: "xavier"
      }
    }
  }
  layer {
    name: "relu_conv1"
    type: "ReLU"
    bottom: "conv1"
    top: "conv1"
  }
  layer {
    name: "pool1"
    type: "Pooling"
    bottom: "conv1"
    top: "pool1"
    pooling_param {
      pool: MAX
      kernel_size: 3
      stride: 2
    }
  }
  layer {
    name: "fire2/squeeze1x1"
    type: "Convolution"
    bottom: "pool1"
    top: "fire2/squeeze1x1"
    convolution_param {
      num_output: 16
      kernel_size: 1
      weight_filler {
        type: "xavier"
      }
    }
  }
  layer {
    name: "fire2/relu_squeeze1x1"
    type: "ReLU"
    bottom: "fire2/squeeze1x1"
    top: "fire2/squeeze1x1"
  }
  layer {
    name: "fire2/expand1x1"
    type: "Convolution"
    bottom: "fire2/squeeze1x1"
    top: "fire2/expand1x1"
    convolution_param {
      num_output: 64
      kernel_size: 1
      weight_filler {
        type: "xavier"
      }
    }
  }
  layer {
    name: "fire2/relu_expand1x1"
    type: "ReLU"
    bottom: "fire2/expand1x1"
    top: "fire2/expand1x1"
  }
  layer {
    name: "fire2/expand3x3"
    type: "Convolution"
    bottom: "fire2/squeeze1x1"
    top: "fire2/expand3x3"
    convolution_param {
      num_output: 64
      pad: 1
      kernel_size: 3
      weight_filler {
        type: "xavier"
      }
    }
  }
  layer {
    name: "fire2/relu_expand3x3"
    type: "ReLU"
    bottom: "fire2/expand3x3"
    top: "fire2/expand3x3"
  }
  layer {
    name: "fire2/concat"
    type: "Concat"
    bottom: "fire2/expand1x1"
    bottom: "fire2/expand3x3"
    top: "fire2/concat"
  }
  layer {
    name: "fire3/squeeze1x1"
    type: "Convolution"
    bottom: "fire2/concat"
    top: "fire3/squeeze1x1"
    convolution_param {
      num_output: 16
      kernel_size: 1
      weight_filler {
        type: "xavier"
      }
    }
  }
  layer {
    name: "fire3/relu_squeeze1x1"
    type: "ReLU"
    bottom: "fire3/squeeze1x1"
    top: "fire3/squeeze1x1"
  }
  layer {
    name: "fire3/expand1x1"
    type: "Convolution"
    bottom: "fire3/squeeze1x1"
    top: "fire3/expand1x1"
    convolution_param {
      num_output: 64
      kernel_size: 1
      weight_filler {
        type: "xavier"
      }
    }
  }
  layer {
    name: "fire3/relu_expand1x1"
    type: "ReLU"
    bottom: "fire3/expand1x1"
    top: "fire3/expand1x1"
  }
  layer {
    name: "fire3/expand3x3"
    type: "Convolution"
    bottom: "fire3/squeeze1x1"
    top: "fire3/expand3x3"
    convolution_param {
      num_output: 64
      pad: 1
      kernel_size: 3
      weight_filler {
        type: "xavier"
      }
    }
  }
  layer {
    name: "fire3/relu_expand3x3"
    type: "ReLU"
    bottom: "fire3/expand3x3"
    top: "fire3/expand3x3"
  }
  layer {
    name: "fire3/concat"
    type: "Concat"
    bottom: "fire3/expand1x1"
    bottom: "fire3/expand3x3"
    top: "fire3/concat"
  }
  layer {
    name: "fire4/squeeze1x1"
    type: "Convolution"
    bottom: "fire3/concat"
    top: "fire4/squeeze1x1"
    convolution_param {
      num_output: 32
      kernel_size: 1
      weight_filler {
        type: "xavier"
      }
    }
  }
  layer {
    name: "fire4/relu_squeeze1x1"
    type: "ReLU"
    bottom: "fire4/squeeze1x1"
    top: "fire4/squeeze1x1"
  }
  layer {
    name: "fire4/expand1x1"
    type: "Convolution"
    bottom: "fire4/squeeze1x1"
    top: "fire4/expand1x1"
    convolution_param {
      num_output: 128
      kernel_size: 1
      weight_filler {
        type: "xavier"
      }
    }
  }
  layer {
    name: "fire4/relu_expand1x1"
    type: "ReLU"
    bottom: "fire4/expand1x1"
    top: "fire4/expand1x1"
  }
  layer {
    name: "fire4/expand3x3"
    type: "Convolution"
    bottom: "fire4/squeeze1x1"
    top: "fire4/expand3x3"
    convolution_param {
      num_output: 128
      pad: 1
      kernel_size: 3
      weight_filler {
        type: "xavier"
      }
    }
  }
  layer {
    name: "fire4/relu_expand3x3"
    type: "ReLU"
    bottom: "fire4/expand3x3"
    top: "fire4/expand3x3"
  }
  layer {
    name: "fire4/concat"
    type: "Concat"
    bottom: "fire4/expand1x1"
    bottom: "fire4/expand3x3"
    top: "fire4/concat"
  }
  layer {
    name: "pool4"
    type: "Pooling"
    bottom: "fire4/concat"
    top: "pool4"
    pooling_param {
      pool: MAX
      kernel_size: 3
      stride: 2
    }
  }
  layer {
    name: "fire5/squeeze1x1"
    type: "Convolution"
    bottom: "pool4"
    top: "fire5/squeeze1x1"
    convolution_param {
      num_output: 32
      kernel_size: 1
      weight_filler {
        type: "xavier"
      }
    }
  }
  layer {
    name: "fire5/relu_squeeze1x1"
    type: "ReLU"
    bottom: "fire5/squeeze1x1"
    top: "fire5/squeeze1x1"
  }
  layer {
    name: "fire5/expand1x1"
    type: "Convolution"
    bottom: "fire5/squeeze1x1"
    top: "fire5/expand1x1"
    convolution_param {
      num_output: 128
      kernel_size: 1
      weight_filler {
        type: "xavier"
      }
    }
  }
  layer {
    name: "fire5/relu_expand1x1"
    type: "ReLU"
    bottom: "fire5/expand1x1"
    top: "fire5/expand1x1"
  }
  layer {
    name: "fire5/expand3x3"
    type: "Convolution"
    bottom: "fire5/squeeze1x1"
    top: "fire5/expand3x3"
    convolution_param {
      num_output: 128
      pad: 1
      kernel_size: 3
      weight_filler {
        type: "xavier"
      }
    }
  }
  layer {
    name: "fire5/relu_expand3x3"
    type: "ReLU"
    bottom: "fire5/expand3x3"
    top: "fire5/expand3x3"
  }
  layer {
    name: "fire5/concat"
    type: "Concat"
    bottom: "fire5/expand1x1"
    bottom: "fire5/expand3x3"
    top: "fire5/concat"
  }
  layer {
    name: "fire6/squeeze1x1"
    type: "Convolution"
    bottom: "fire5/concat"
    top: "fire6/squeeze1x1"
    convolution_param {
      num_output: 48
      kernel_size: 1
      weight_filler {
        type: "xavier"
      }
    }
  }
  layer {
    name: "fire6/relu_squeeze1x1"
    type: "ReLU"
    bottom: "fire6/squeeze1x1"
    top: "fire6/squeeze1x1"
  }
  layer {
    name: "fire6/expand1x1"
    type: "Convolution"
    bottom: "fire6/squeeze1x1"
    top: "fire6/expand1x1"
    convolution_param {
      num_output: 192
      kernel_size: 1
      weight_filler {
        type: "xavier"
      }
    }
  }
  layer {
    name: "fire6/relu_expand1x1"
    type: "ReLU"
    bottom: "fire6/expand1x1"
    top: "fire6/expand1x1"
  }
  layer {
    name: "fire6/expand3x3"
    type: "Convolution"
    bottom: "fire6/squeeze1x1"
    top: "fire6/expand3x3"
    convolution_param {
      num_output: 192
      pad: 1
      kernel_size: 3
      weight_filler {
        type: "xavier"
      }
    }
  }
  layer {
    name: "fire6/relu_expand3x3"
    type: "ReLU"
    bottom: "fire6/expand3x3"
    top: "fire6/expand3x3"
  }
  layer {
    name: "fire6/concat"
    type: "Concat"
    bottom: "fire6/expand1x1"
    bottom: "fire6/expand3x3"
    top: "fire6/concat"
  }
  layer {
    name: "fire7/squeeze1x1"
    type: "Convolution"
    bottom: "fire6/concat"
    top: "fire7/squeeze1x1"
    convolution_param {
      num_output: 48
      kernel_size: 1
      weight_filler {
        type: "xavier"
      }
    }
  }
  layer {
    name: "fire7/relu_squeeze1x1"
    type: "ReLU"
    bottom: "fire7/squeeze1x1"
    top: "fire7/squeeze1x1"
  }
  layer {
    name: "fire7/expand1x1"
    type: "Convolution"
    bottom: "fire7/squeeze1x1"
    top: "fire7/expand1x1"
    convolution_param {
      num_output: 192
      kernel_size: 1
      weight_filler {
        type: "xavier"
      }
    }
  }
  layer {
    name: "fire7/relu_expand1x1"
    type: "ReLU"
    bottom: "fire7/expand1x1"
    top: "fire7/expand1x1"
  }
  layer {
    name: "fire7/expand3x3"
    type: "Convolution"
    bottom: "fire7/squeeze1x1"
    top: "fire7/expand3x3"
    convolution_param {
      num_output: 192
      pad: 1
      kernel_size: 3
      weight_filler {
        type: "xavier"
      }
    }
  }
  layer {
    name: "fire7/relu_expand3x3"
    type: "ReLU"
    bottom: "fire7/expand3x3"
    top: "fire7/expand3x3"
  }
  layer {
    name: "fire7/concat"
    type: "Concat"
    bottom: "fire7/expand1x1"
    bottom: "fire7/expand3x3"
    top: "fire7/concat"
  }
  layer {
    name: "fire8/squeeze1x1"
    type: "Convolution"
    bottom: "fire7/concat"
    top: "fire8/squeeze1x1"
    convolution_param {
      num_output: 64
      kernel_size: 1
      weight_filler {
        type: "xavier"
      }
    }
  }
  layer {
    name: "fire8/relu_squeeze1x1"
    type: "ReLU"
    bottom: "fire8/squeeze1x1"
    top: "fire8/squeeze1x1"
  }
  layer {
    name: "fire8/expand1x1"
    type: "Convolution"
    bottom: "fire8/squeeze1x1"
    top: "fire8/expand1x1"
    convolution_param {
      num_output: 256
      kernel_size: 1
      weight_filler {
        type: "xavier"
      }
    }
  }
  layer {
    name: "fire8/relu_expand1x1"
    type: "ReLU"
    bottom: "fire8/expand1x1"
    top: "fire8/expand1x1"
  }
  layer {
    name: "fire8/expand3x3"
    type: "Convolution"
    bottom: "fire8/squeeze1x1"
    top: "fire8/expand3x3"
    convolution_param {
      num_output: 256
      pad: 1
      kernel_size: 3
      weight_filler {
        type: "xavier"
      }
    }
  }
  layer {
    name: "fire8/relu_expand3x3"
    type: "ReLU"
    bottom: "fire8/expand3x3"
    top: "fire8/expand3x3"
  }
  layer {
    name: "fire8/concat"
    type: "Concat"
    bottom: "fire8/expand1x1"
    bottom: "fire8/expand3x3"
    top: "fire8/concat"
  }
  layer {
    name: "pool8"
    type: "Pooling"
    bottom: "fire8/concat"
    top: "pool8"
    pooling_param {
      pool: MAX
      kernel_size: 3
      stride: 2
    }
  }
  layer {
    name: "fire9/squeeze1x1"
    type: "Convolution"
    bottom: "pool8"
    top: "fire9/squeeze1x1"
    convolution_param {
      num_output: 64
      kernel_size: 1
      weight_filler {
        type: "xavier"
      }
    }
  }
  layer {
    name: "fire9/relu_squeeze1x1"
    type: "ReLU"
    bottom: "fire9/squeeze1x1"
    top: "fire9/squeeze1x1"
  }
  layer {
    name: "fire9/expand1x1"
    type: "Convolution"
    bottom: "fire9/squeeze1x1"
    top: "fire9/expand1x1"
    convolution_param {
      num_output: 256
      kernel_size: 1
      weight_filler {
        type: "xavier"
      }
    }
  }
  layer {
    name: "fire9/relu_expand1x1"
    type: "ReLU"
    bottom: "fire9/expand1x1"
    top: "fire9/expand1x1"
  }
  layer {
    name: "fire9/expand3x3"
    type: "Convolution"
    bottom: "fire9/squeeze1x1"
    top: "fire9/expand3x3"
    convolution_param {
      num_output: 256
      pad: 1
      kernel_size: 3
      weight_filler {
        type: "xavier"
      }
    }
  }
  layer {
    name: "fire9/relu_expand3x3"
    type: "ReLU"
    bottom: "fire9/expand3x3"
    top: "fire9/expand3x3"
  }
  layer {
    name: "fire9/concat"
    type: "Concat"
    bottom: "fire9/expand1x1"
    bottom: "fire9/expand3x3"
    top: "fire9/concat"
  }
  layer {
    name: "drop9"
    type: "Dropout"
    bottom: "fire9/concat"
    top: "fire9/concat"
    dropout_param {
      dropout_ratio: 0.5
    }
  }
  layer {
    name: "conv10"
    type: "Convolution"
    bottom: "fire9/concat"
    top: "conv10"
    convolution_param {
      num_output: 1000
      pad: 1
      kernel_size: 1
      weight_filler {
        type: "gaussian"
        mean: 0
        std: 0.01
      }
    }
  }
  layer {
    name: "relu_conv10"
    type: "ReLU"
    bottom: "conv10"
    top: "conv10"
  }
  layer {
    name: "pool10"
    type: "Pooling"
    bottom: "conv10"
    top: "pool10"
    pooling_param {
      pool: AVE
      global_pooling: true
    }
  }
  layer {
    name: "loss"
    type: "SoftmaxWithLoss"
    bottom: "pool10"
    bottom: "label"
    top: "loss"
    include {
      phase: TRAIN
    }
  }
  layer {
    name: "accuracy"
    type: "Accuracy"
    bottom: "pool10"
    bottom: "label"
    top: "accuracy"
    include {
      phase: TEST
    }
  }
  layer {
    name: "accuracy_top5"
    type: "Accuracy"
    bottom: "pool10"
    bottom: "label"
    top: "accuracy_top5"
    include {
      phase: TEST
    }
    accuracy_param {
      top_k: 5
    }
  }
}
test_initialization: false
average_loss: 40
iter_size: 2
I0604 20:56:51.654400   904 solver.cpp:86] Creating training net specified in net_param.
I0604 20:56:51.654809   904 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0604 20:56:51.654906   904 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0604 20:56:51.654916   904 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy_top5
I0604 20:56:51.655956   904 net.cpp:49] Initializing net from parameters: 
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.04
    mirror: true
    crop_size: 128
    mean_value: 104
    mean_value: 117
    mean_value: 124
    force_color: true
  }
  data_param {
    source: "/local/temporary/mishkdmy/imagenet144pxlmdb/ilsvrc12_128_train_lmdb"
    batch_size: 256
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 96
    kernel_size: 7
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu_conv1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fire2/squeeze1x1"
  type: "Convolution"
  bottom: "pool1"
  top: "fire2/squeeze1x1"
  convolution_param {
    num_output: 16
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire2/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire2/squeeze1x1"
  top: "fire2/squeeze1x1"
}
layer {
  name: "fire2/expand1x1"
  type: "Convolution"
  bottom: "fire2/squeeze1x1"
  top: "fire2/expand1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire2/relu_expand1x1"
  type: "ReLU"
  bottom: "fire2/expand1x1"
  top: "fire2/expand1x1"
}
layer {
  name: "fire2/expand3x3"
  type: "Convolution"
  bottom: "fire2/squeeze1x1"
  top: "fire2/expand3x3"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire2/relu_expand3x3"
  type: "ReLU"
  bottom: "fire2/expand3x3"
  top: "fire2/expand3x3"
}
layer {
  name: "fire2/concat"
  type: "Concat"
  bottom: "fire2/expand1x1"
  bottom: "fire2/expand3x3"
  top: "fire2/concat"
}
layer {
  name: "fire3/squeeze1x1"
  type: "Convolution"
  bottom: "fire2/concat"
  top: "fire3/squeeze1x1"
  convolution_param {
    num_output: 16
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire3/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire3/squeeze1x1"
  top: "fire3/squeeze1x1"
}
layer {
  name: "fire3/expand1x1"
  type: "Convolution"
  bottom: "fire3/squeeze1x1"
  top: "fire3/expand1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire3/relu_expand1x1"
  type: "ReLU"
  bottom: "fire3/expand1x1"
  top: "fire3/expand1x1"
}
layer {
  name: "fire3/expand3x3"
  type: "Convolution"
  bottom: "fire3/squeeze1x1"
  top: "fire3/expand3x3"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire3/relu_expand3x3"
  type: "ReLU"
  bottom: "fire3/expand3x3"
  top: "fire3/expand3x3"
}
layer {
  name: "fire3/concat"
  type: "Concat"
  bottom: "fire3/expand1x1"
  bottom: "fire3/expand3x3"
  top: "fire3/concat"
}
layer {
  name: "fire4/squeeze1x1"
  type: "Convolution"
  bottom: "fire3/concat"
  top: "fire4/squeeze1x1"
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire4/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire4/squeeze1x1"
  top: "fire4/squeeze1x1"
}
layer {
  name: "fire4/expand1x1"
  type: "Convolution"
  bottom: "fire4/squeeze1x1"
  top: "fire4/expand1x1"
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire4/relu_expand1x1"
  type: "ReLU"
  bottom: "fire4/expand1x1"
  top: "fire4/expand1x1"
}
layer {
  name: "fire4/expand3x3"
  type: "Convolution"
  bottom: "fire4/squeeze1x1"
  top: "fire4/expand3x3"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire4/relu_expand3x3"
  type: "ReLU"
  bottom: "fire4/expand3x3"
  top: "fire4/expand3x3"
}
layer {
  name: "fire4/concat"
  type: "Concat"
  bottom: "fire4/expand1x1"
  bottom: "fire4/expand3x3"
  top: "fire4/concat"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "fire4/concat"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fire5/squeeze1x1"
  type: "Convolution"
  bottom: "pool4"
  top: "fire5/squeeze1x1"
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire5/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire5/squeeze1x1"
  top: "fire5/squeeze1x1"
}
layer {
  name: "fire5/expand1x1"
  type: "Convolution"
  bottom: "fire5/squeeze1x1"
  top: "fire5/expand1x1"
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire5/relu_expand1x1"
  type: "ReLU"
  bottom: "fire5/expand1x1"
  top: "fire5/expand1x1"
}
layer {
  name: "fire5/expand3x3"
  type: "Convolution"
  bottom: "fire5/squeeze1x1"
  top: "fire5/expand3x3"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire5/relu_expand3x3"
  type: "ReLU"
  bottom: "fire5/expand3x3"
  top: "fire5/expand3x3"
}
layer {
  name: "fire5/concat"
  type: "Concat"
  bottom: "fire5/expand1x1"
  bottom: "fire5/expand3x3"
  top: "fire5/concat"
}
layer {
  name: "fire6/squeeze1x1"
  type: "Convolution"
  bottom: "fire5/concat"
  top: "fire6/squeeze1x1"
  convolution_param {
    num_output: 48
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire6/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire6/squeeze1x1"
  top: "fire6/squeeze1x1"
}
layer {
  name: "fire6/expand1x1"
  type: "Convolution"
  bottom: "fire6/squeeze1x1"
  top: "fire6/expand1x1"
  convolution_param {
    num_output: 192
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire6/relu_expand1x1"
  type: "ReLU"
  bottom: "fire6/expand1x1"
  top: "fire6/expand1x1"
}
layer {
  name: "fire6/expand3x3"
  type: "Convolution"
  bottom: "fire6/squeeze1x1"
  top: "fire6/expand3x3"
  convolution_param {
    num_output: 192
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire6/relu_expand3x3"
  type: "ReLU"
  bottom: "fire6/expand3x3"
  top: "fire6/expand3x3"
}
layer {
  name: "fire6/concat"
  type: "Concat"
  bottom: "fire6/expand1x1"
  bottom: "fire6/expand3x3"
  top: "fire6/concat"
}
layer {
  name: "fire7/squeeze1x1"
  type: "Convolution"
  bottom: "fire6/concat"
  top: "fire7/squeeze1x1"
  convolution_param {
    num_output: 48
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire7/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire7/squeeze1x1"
  top: "fire7/squeeze1x1"
}
layer {
  name: "fire7/expand1x1"
  type: "Convolution"
  bottom: "fire7/squeeze1x1"
  top: "fire7/expand1x1"
  convolution_param {
    num_output: 192
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire7/relu_expand1x1"
  type: "ReLU"
  bottom: "fire7/expand1x1"
  top: "fire7/expand1x1"
}
layer {
  name: "fire7/expand3x3"
  type: "Convolution"
  bottom: "fire7/squeeze1x1"
  top: "fire7/expand3x3"
  convolution_param {
    num_output: 192
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire7/relu_expand3x3"
  type: "ReLU"
  bottom: "fire7/expand3x3"
  top: "fire7/expand3x3"
}
layer {
  name: "fire7/concat"
  type: "Concat"
  bottom: "fire7/expand1x1"
  bottom: "fire7/expand3x3"
  top: "fire7/concat"
}
layer {
  name: "fire8/squeeze1x1"
  type: "Convolution"
  bottom: "fire7/concat"
  top: "fire8/squeeze1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire8/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire8/squeeze1x1"
  top: "fire8/squeeze1x1"
}
layer {
  name: "fire8/expand1x1"
  type: "Convolution"
  bottom: "fire8/squeeze1x1"
  top: "fire8/expand1x1"
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire8/relu_expand1x1"
  type: "ReLU"
  bottom: "fire8/expand1x1"
  top: "fire8/expand1x1"
}
layer {
  name: "fire8/expand3x3"
  type: "Convolution"
  bottom: "fire8/squeeze1x1"
  top: "fire8/expand3x3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire8/relu_expand3x3"
  type: "ReLU"
  bottom: "fire8/expand3x3"
  top: "fire8/expand3x3"
}
layer {
  name: "fire8/concat"
  type: "Concat"
  bottom: "fire8/expand1x1"
  bottom: "fire8/expand3x3"
  top: "fire8/concat"
}
layer {
  name: "pool8"
  type: "Pooling"
  bottom: "fire8/concat"
  top: "pool8"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fire9/squeeze1x1"
  type: "Convolution"
  bottom: "pool8"
  top: "fire9/squeeze1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire9/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire9/squeeze1x1"
  top: "fire9/squeeze1x1"
}
layer {
  name: "fire9/expand1x1"
  type: "Convolution"
  bottom: "fire9/squeeze1x1"
  top: "fire9/expand1x1"
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire9/relu_expand1x1"
  type: "ReLU"
  bottom: "fire9/expand1x1"
  top: "fire9/expand1x1"
}
layer {
  name: "fire9/expand3x3"
  type: "Convolution"
  bottom: "fire9/squeeze1x1"
  top: "fire9/expand3x3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire9/relu_expand3x3"
  type: "ReLU"
  bottom: "fire9/expand3x3"
  top: "fire9/expand3x3"
}
layer {
  name: "fire9/concat"
  type: "Concat"
  bottom: "fire9/expand1x1"
  bottom: "fire9/expand3x3"
  top: "fire9/concat"
}
layer {
  name: "drop9"
  type: "Dropout"
  bottom: "fire9/concat"
  top: "fire9/concat"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "conv10"
  type: "Convolution"
  bottom: "fire9/concat"
  top: "conv10"
  convolution_param {
    num_output: 1000
    pad: 1
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      mean: 0
      std: 0.01
    }
  }
}
layer {
  name: "relu_conv10"
  type: "ReLU"
  bottom: "conv10"
  top: "conv10"
}
layer {
  name: "pool10"
  type: "Pooling"
  bottom: "conv10"
  top: "pool10"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "pool10"
  bottom: "label"
  top: "loss"
  include {
    phase: TRAIN
  }
}
I0604 20:56:51.656658   904 layer_factory.hpp:77] Creating layer data
I0604 20:56:51.657202   904 net.cpp:106] Creating Layer data
I0604 20:56:51.657233   904 net.cpp:411] data -> data
I0604 20:56:51.657277   904 net.cpp:411] data -> label
I0604 20:56:51.658638   934 db_lmdb.cpp:38] Opened lmdb /local/temporary/mishkdmy/imagenet144pxlmdb/ilsvrc12_128_train_lmdb
I0604 20:56:51.718016   904 data_layer.cpp:41] output data size: 256,3,128,128
I0604 20:56:51.829545   904 net.cpp:150] Setting up data
I0604 20:56:51.829593   904 net.cpp:157] Top shape: 256 3 128 128 (12582912)
I0604 20:56:51.829601   904 net.cpp:157] Top shape: 256 (256)
I0604 20:56:51.829604   904 net.cpp:165] Memory required for data: 50332672
I0604 20:56:51.829625   904 layer_factory.hpp:77] Creating layer conv1
I0604 20:56:51.829651   904 net.cpp:106] Creating Layer conv1
I0604 20:56:51.829658   904 net.cpp:454] conv1 <- data
I0604 20:56:51.829680   904 net.cpp:411] conv1 -> conv1
I0604 20:56:52.134946   904 net.cpp:150] Setting up conv1
I0604 20:56:52.134994   904 net.cpp:157] Top shape: 256 96 61 61 (91447296)
I0604 20:56:52.135001   904 net.cpp:165] Memory required for data: 416121856
I0604 20:56:52.135026   904 layer_factory.hpp:77] Creating layer relu_conv1
I0604 20:56:52.135042   904 net.cpp:106] Creating Layer relu_conv1
I0604 20:56:52.135048   904 net.cpp:454] relu_conv1 <- conv1
I0604 20:56:52.135057   904 net.cpp:397] relu_conv1 -> conv1 (in-place)
I0604 20:56:52.136144   904 net.cpp:150] Setting up relu_conv1
I0604 20:56:52.136162   904 net.cpp:157] Top shape: 256 96 61 61 (91447296)
I0604 20:56:52.136168   904 net.cpp:165] Memory required for data: 781911040
I0604 20:56:52.136174   904 layer_factory.hpp:77] Creating layer pool1
I0604 20:56:52.136184   904 net.cpp:106] Creating Layer pool1
I0604 20:56:52.136189   904 net.cpp:454] pool1 <- conv1
I0604 20:56:52.136198   904 net.cpp:411] pool1 -> pool1
I0604 20:56:52.136268   904 net.cpp:150] Setting up pool1
I0604 20:56:52.136278   904 net.cpp:157] Top shape: 256 96 30 30 (22118400)
I0604 20:56:52.136283   904 net.cpp:165] Memory required for data: 870384640
I0604 20:56:52.136287   904 layer_factory.hpp:77] Creating layer fire2/squeeze1x1
I0604 20:56:52.136304   904 net.cpp:106] Creating Layer fire2/squeeze1x1
I0604 20:56:52.136310   904 net.cpp:454] fire2/squeeze1x1 <- pool1
I0604 20:56:52.136318   904 net.cpp:411] fire2/squeeze1x1 -> fire2/squeeze1x1
I0604 20:56:52.140475   904 net.cpp:150] Setting up fire2/squeeze1x1
I0604 20:56:52.140496   904 net.cpp:157] Top shape: 256 16 30 30 (3686400)
I0604 20:56:52.140501   904 net.cpp:165] Memory required for data: 885130240
I0604 20:56:52.140516   904 layer_factory.hpp:77] Creating layer fire2/relu_squeeze1x1
I0604 20:56:52.140530   904 net.cpp:106] Creating Layer fire2/relu_squeeze1x1
I0604 20:56:52.140535   904 net.cpp:454] fire2/relu_squeeze1x1 <- fire2/squeeze1x1
I0604 20:56:52.140543   904 net.cpp:397] fire2/relu_squeeze1x1 -> fire2/squeeze1x1 (in-place)
I0604 20:56:52.140951   904 net.cpp:150] Setting up fire2/relu_squeeze1x1
I0604 20:56:52.140967   904 net.cpp:157] Top shape: 256 16 30 30 (3686400)
I0604 20:56:52.140972   904 net.cpp:165] Memory required for data: 899875840
I0604 20:56:52.140977   904 layer_factory.hpp:77] Creating layer fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I0604 20:56:52.140986   904 net.cpp:106] Creating Layer fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I0604 20:56:52.140991   904 net.cpp:454] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split <- fire2/squeeze1x1
I0604 20:56:52.141000   904 net.cpp:411] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split -> fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_0
I0604 20:56:52.141010   904 net.cpp:411] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split -> fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_1
I0604 20:56:52.141098   904 net.cpp:150] Setting up fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I0604 20:56:52.141106   904 net.cpp:157] Top shape: 256 16 30 30 (3686400)
I0604 20:56:52.141113   904 net.cpp:157] Top shape: 256 16 30 30 (3686400)
I0604 20:56:52.141116   904 net.cpp:165] Memory required for data: 929367040
I0604 20:56:52.141121   904 layer_factory.hpp:77] Creating layer fire2/expand1x1
I0604 20:56:52.141132   904 net.cpp:106] Creating Layer fire2/expand1x1
I0604 20:56:52.141139   904 net.cpp:454] fire2/expand1x1 <- fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_0
I0604 20:56:52.141152   904 net.cpp:411] fire2/expand1x1 -> fire2/expand1x1
I0604 20:56:52.144511   904 net.cpp:150] Setting up fire2/expand1x1
I0604 20:56:52.144529   904 net.cpp:157] Top shape: 256 64 30 30 (14745600)
I0604 20:56:52.144534   904 net.cpp:165] Memory required for data: 988349440
I0604 20:56:52.144547   904 layer_factory.hpp:77] Creating layer fire2/relu_expand1x1
I0604 20:56:52.144559   904 net.cpp:106] Creating Layer fire2/relu_expand1x1
I0604 20:56:52.144564   904 net.cpp:454] fire2/relu_expand1x1 <- fire2/expand1x1
I0604 20:56:52.144572   904 net.cpp:397] fire2/relu_expand1x1 -> fire2/expand1x1 (in-place)
I0604 20:56:52.145537   904 net.cpp:150] Setting up fire2/relu_expand1x1
I0604 20:56:52.145550   904 net.cpp:157] Top shape: 256 64 30 30 (14745600)
I0604 20:56:52.145555   904 net.cpp:165] Memory required for data: 1047331840
I0604 20:56:52.145558   904 layer_factory.hpp:77] Creating layer fire2/expand3x3
I0604 20:56:52.145571   904 net.cpp:106] Creating Layer fire2/expand3x3
I0604 20:56:52.145576   904 net.cpp:454] fire2/expand3x3 <- fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_1
I0604 20:56:52.145584   904 net.cpp:411] fire2/expand3x3 -> fire2/expand3x3
I0604 20:56:52.149322   904 net.cpp:150] Setting up fire2/expand3x3
I0604 20:56:52.149340   904 net.cpp:157] Top shape: 256 64 30 30 (14745600)
I0604 20:56:52.149345   904 net.cpp:165] Memory required for data: 1106314240
I0604 20:56:52.149355   904 layer_factory.hpp:77] Creating layer fire2/relu_expand3x3
I0604 20:56:52.149365   904 net.cpp:106] Creating Layer fire2/relu_expand3x3
I0604 20:56:52.149370   904 net.cpp:454] fire2/relu_expand3x3 <- fire2/expand3x3
I0604 20:56:52.149379   904 net.cpp:397] fire2/relu_expand3x3 -> fire2/expand3x3 (in-place)
I0604 20:56:52.150223   904 net.cpp:150] Setting up fire2/relu_expand3x3
I0604 20:56:52.150238   904 net.cpp:157] Top shape: 256 64 30 30 (14745600)
I0604 20:56:52.150243   904 net.cpp:165] Memory required for data: 1165296640
I0604 20:56:52.150248   904 layer_factory.hpp:77] Creating layer fire2/concat
I0604 20:56:52.150261   904 net.cpp:106] Creating Layer fire2/concat
I0604 20:56:52.150269   904 net.cpp:454] fire2/concat <- fire2/expand1x1
I0604 20:56:52.150275   904 net.cpp:454] fire2/concat <- fire2/expand3x3
I0604 20:56:52.150282   904 net.cpp:411] fire2/concat -> fire2/concat
I0604 20:56:52.150323   904 net.cpp:150] Setting up fire2/concat
I0604 20:56:52.150332   904 net.cpp:157] Top shape: 256 128 30 30 (29491200)
I0604 20:56:52.150336   904 net.cpp:165] Memory required for data: 1283261440
I0604 20:56:52.150341   904 layer_factory.hpp:77] Creating layer fire3/squeeze1x1
I0604 20:56:52.150357   904 net.cpp:106] Creating Layer fire3/squeeze1x1
I0604 20:56:52.150362   904 net.cpp:454] fire3/squeeze1x1 <- fire2/concat
I0604 20:56:52.150369   904 net.cpp:411] fire3/squeeze1x1 -> fire3/squeeze1x1
I0604 20:56:52.153880   904 net.cpp:150] Setting up fire3/squeeze1x1
I0604 20:56:52.153897   904 net.cpp:157] Top shape: 256 16 30 30 (3686400)
I0604 20:56:52.153901   904 net.cpp:165] Memory required for data: 1298007040
I0604 20:56:52.153916   904 layer_factory.hpp:77] Creating layer fire3/relu_squeeze1x1
I0604 20:56:52.153924   904 net.cpp:106] Creating Layer fire3/relu_squeeze1x1
I0604 20:56:52.153929   904 net.cpp:454] fire3/relu_squeeze1x1 <- fire3/squeeze1x1
I0604 20:56:52.153939   904 net.cpp:397] fire3/relu_squeeze1x1 -> fire3/squeeze1x1 (in-place)
I0604 20:56:52.154932   904 net.cpp:150] Setting up fire3/relu_squeeze1x1
I0604 20:56:52.154947   904 net.cpp:157] Top shape: 256 16 30 30 (3686400)
I0604 20:56:52.154952   904 net.cpp:165] Memory required for data: 1312752640
I0604 20:56:52.154956   904 layer_factory.hpp:77] Creating layer fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I0604 20:56:52.154966   904 net.cpp:106] Creating Layer fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I0604 20:56:52.154970   904 net.cpp:454] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split <- fire3/squeeze1x1
I0604 20:56:52.154980   904 net.cpp:411] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split -> fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_0
I0604 20:56:52.154989   904 net.cpp:411] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split -> fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_1
I0604 20:56:52.155046   904 net.cpp:150] Setting up fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I0604 20:56:52.155055   904 net.cpp:157] Top shape: 256 16 30 30 (3686400)
I0604 20:56:52.155061   904 net.cpp:157] Top shape: 256 16 30 30 (3686400)
I0604 20:56:52.155064   904 net.cpp:165] Memory required for data: 1342243840
I0604 20:56:52.155068   904 layer_factory.hpp:77] Creating layer fire3/expand1x1
I0604 20:56:52.155081   904 net.cpp:106] Creating Layer fire3/expand1x1
I0604 20:56:52.155086   904 net.cpp:454] fire3/expand1x1 <- fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_0
I0604 20:56:52.155093   904 net.cpp:411] fire3/expand1x1 -> fire3/expand1x1
I0604 20:56:52.158560   904 net.cpp:150] Setting up fire3/expand1x1
I0604 20:56:52.158583   904 net.cpp:157] Top shape: 256 64 30 30 (14745600)
I0604 20:56:52.158588   904 net.cpp:165] Memory required for data: 1401226240
I0604 20:56:52.158597   904 layer_factory.hpp:77] Creating layer fire3/relu_expand1x1
I0604 20:56:52.158609   904 net.cpp:106] Creating Layer fire3/relu_expand1x1
I0604 20:56:52.158614   904 net.cpp:454] fire3/relu_expand1x1 <- fire3/expand1x1
I0604 20:56:52.158622   904 net.cpp:397] fire3/relu_expand1x1 -> fire3/expand1x1 (in-place)
I0604 20:56:52.159616   904 net.cpp:150] Setting up fire3/relu_expand1x1
I0604 20:56:52.159628   904 net.cpp:157] Top shape: 256 64 30 30 (14745600)
I0604 20:56:52.159632   904 net.cpp:165] Memory required for data: 1460208640
I0604 20:56:52.159636   904 layer_factory.hpp:77] Creating layer fire3/expand3x3
I0604 20:56:52.159649   904 net.cpp:106] Creating Layer fire3/expand3x3
I0604 20:56:52.159657   904 net.cpp:454] fire3/expand3x3 <- fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_1
I0604 20:56:52.159669   904 net.cpp:411] fire3/expand3x3 -> fire3/expand3x3
I0604 20:56:52.163400   904 net.cpp:150] Setting up fire3/expand3x3
I0604 20:56:52.163416   904 net.cpp:157] Top shape: 256 64 30 30 (14745600)
I0604 20:56:52.163421   904 net.cpp:165] Memory required for data: 1519191040
I0604 20:56:52.163430   904 layer_factory.hpp:77] Creating layer fire3/relu_expand3x3
I0604 20:56:52.163447   904 net.cpp:106] Creating Layer fire3/relu_expand3x3
I0604 20:56:52.163452   904 net.cpp:454] fire3/relu_expand3x3 <- fire3/expand3x3
I0604 20:56:52.163460   904 net.cpp:397] fire3/relu_expand3x3 -> fire3/expand3x3 (in-place)
I0604 20:56:52.164296   904 net.cpp:150] Setting up fire3/relu_expand3x3
I0604 20:56:52.164311   904 net.cpp:157] Top shape: 256 64 30 30 (14745600)
I0604 20:56:52.164315   904 net.cpp:165] Memory required for data: 1578173440
I0604 20:56:52.164320   904 layer_factory.hpp:77] Creating layer fire3/concat
I0604 20:56:52.164330   904 net.cpp:106] Creating Layer fire3/concat
I0604 20:56:52.164336   904 net.cpp:454] fire3/concat <- fire3/expand1x1
I0604 20:56:52.164342   904 net.cpp:454] fire3/concat <- fire3/expand3x3
I0604 20:56:52.164348   904 net.cpp:411] fire3/concat -> fire3/concat
I0604 20:56:52.164397   904 net.cpp:150] Setting up fire3/concat
I0604 20:56:52.164405   904 net.cpp:157] Top shape: 256 128 30 30 (29491200)
I0604 20:56:52.164419   904 net.cpp:165] Memory required for data: 1696138240
I0604 20:56:52.164423   904 layer_factory.hpp:77] Creating layer fire4/squeeze1x1
I0604 20:56:52.164453   904 net.cpp:106] Creating Layer fire4/squeeze1x1
I0604 20:56:52.164458   904 net.cpp:454] fire4/squeeze1x1 <- fire3/concat
I0604 20:56:52.164466   904 net.cpp:411] fire4/squeeze1x1 -> fire4/squeeze1x1
I0604 20:56:52.168994   904 net.cpp:150] Setting up fire4/squeeze1x1
I0604 20:56:52.169014   904 net.cpp:157] Top shape: 256 32 30 30 (7372800)
I0604 20:56:52.169018   904 net.cpp:165] Memory required for data: 1725629440
I0604 20:56:52.169028   904 layer_factory.hpp:77] Creating layer fire4/relu_squeeze1x1
I0604 20:56:52.169037   904 net.cpp:106] Creating Layer fire4/relu_squeeze1x1
I0604 20:56:52.169042   904 net.cpp:454] fire4/relu_squeeze1x1 <- fire4/squeeze1x1
I0604 20:56:52.169049   904 net.cpp:397] fire4/relu_squeeze1x1 -> fire4/squeeze1x1 (in-place)
I0604 20:56:52.170038   904 net.cpp:150] Setting up fire4/relu_squeeze1x1
I0604 20:56:52.170053   904 net.cpp:157] Top shape: 256 32 30 30 (7372800)
I0604 20:56:52.170058   904 net.cpp:165] Memory required for data: 1755120640
I0604 20:56:52.170061   904 layer_factory.hpp:77] Creating layer fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I0604 20:56:52.170083   904 net.cpp:106] Creating Layer fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I0604 20:56:52.170089   904 net.cpp:454] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split <- fire4/squeeze1x1
I0604 20:56:52.170096   904 net.cpp:411] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split -> fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_0
I0604 20:56:52.170109   904 net.cpp:411] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split -> fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_1
I0604 20:56:52.170163   904 net.cpp:150] Setting up fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I0604 20:56:52.170173   904 net.cpp:157] Top shape: 256 32 30 30 (7372800)
I0604 20:56:52.170179   904 net.cpp:157] Top shape: 256 32 30 30 (7372800)
I0604 20:56:52.170186   904 net.cpp:165] Memory required for data: 1814103040
I0604 20:56:52.170189   904 layer_factory.hpp:77] Creating layer fire4/expand1x1
I0604 20:56:52.170205   904 net.cpp:106] Creating Layer fire4/expand1x1
I0604 20:56:52.170212   904 net.cpp:454] fire4/expand1x1 <- fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_0
I0604 20:56:52.170222   904 net.cpp:411] fire4/expand1x1 -> fire4/expand1x1
I0604 20:56:52.174722   904 net.cpp:150] Setting up fire4/expand1x1
I0604 20:56:52.174738   904 net.cpp:157] Top shape: 256 128 30 30 (29491200)
I0604 20:56:52.174742   904 net.cpp:165] Memory required for data: 1932067840
I0604 20:56:52.174758   904 layer_factory.hpp:77] Creating layer fire4/relu_expand1x1
I0604 20:56:52.174767   904 net.cpp:106] Creating Layer fire4/relu_expand1x1
I0604 20:56:52.174772   904 net.cpp:454] fire4/relu_expand1x1 <- fire4/expand1x1
I0604 20:56:52.174778   904 net.cpp:397] fire4/relu_expand1x1 -> fire4/expand1x1 (in-place)
I0604 20:56:52.175775   904 net.cpp:150] Setting up fire4/relu_expand1x1
I0604 20:56:52.175786   904 net.cpp:157] Top shape: 256 128 30 30 (29491200)
I0604 20:56:52.175789   904 net.cpp:165] Memory required for data: 2050032640
I0604 20:56:52.175793   904 layer_factory.hpp:77] Creating layer fire4/expand3x3
I0604 20:56:52.175806   904 net.cpp:106] Creating Layer fire4/expand3x3
I0604 20:56:52.175811   904 net.cpp:454] fire4/expand3x3 <- fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_1
I0604 20:56:52.175819   904 net.cpp:411] fire4/expand3x3 -> fire4/expand3x3
I0604 20:56:52.179431   904 net.cpp:150] Setting up fire4/expand3x3
I0604 20:56:52.179447   904 net.cpp:157] Top shape: 256 128 30 30 (29491200)
I0604 20:56:52.179451   904 net.cpp:165] Memory required for data: 2167997440
I0604 20:56:52.179460   904 layer_factory.hpp:77] Creating layer fire4/relu_expand3x3
I0604 20:56:52.179469   904 net.cpp:106] Creating Layer fire4/relu_expand3x3
I0604 20:56:52.179473   904 net.cpp:454] fire4/relu_expand3x3 <- fire4/expand3x3
I0604 20:56:52.179481   904 net.cpp:397] fire4/relu_expand3x3 -> fire4/expand3x3 (in-place)
I0604 20:56:52.180464   904 net.cpp:150] Setting up fire4/relu_expand3x3
I0604 20:56:52.180477   904 net.cpp:157] Top shape: 256 128 30 30 (29491200)
I0604 20:56:52.180502   904 net.cpp:165] Memory required for data: 2285962240
I0604 20:56:52.180506   904 layer_factory.hpp:77] Creating layer fire4/concat
I0604 20:56:52.180516   904 net.cpp:106] Creating Layer fire4/concat
I0604 20:56:52.180521   904 net.cpp:454] fire4/concat <- fire4/expand1x1
I0604 20:56:52.180526   904 net.cpp:454] fire4/concat <- fire4/expand3x3
I0604 20:56:52.180534   904 net.cpp:411] fire4/concat -> fire4/concat
I0604 20:56:52.180572   904 net.cpp:150] Setting up fire4/concat
I0604 20:56:52.180580   904 net.cpp:157] Top shape: 256 256 30 30 (58982400)
I0604 20:56:52.180583   904 net.cpp:165] Memory required for data: 2521891840
I0604 20:56:52.180588   904 layer_factory.hpp:77] Creating layer pool4
I0604 20:56:52.180598   904 net.cpp:106] Creating Layer pool4
I0604 20:56:52.180603   904 net.cpp:454] pool4 <- fire4/concat
I0604 20:56:52.180610   904 net.cpp:411] pool4 -> pool4
I0604 20:56:52.180657   904 net.cpp:150] Setting up pool4
I0604 20:56:52.180665   904 net.cpp:157] Top shape: 256 256 15 15 (14745600)
I0604 20:56:52.180668   904 net.cpp:165] Memory required for data: 2580874240
I0604 20:56:52.180672   904 layer_factory.hpp:77] Creating layer fire5/squeeze1x1
I0604 20:56:52.180682   904 net.cpp:106] Creating Layer fire5/squeeze1x1
I0604 20:56:52.180688   904 net.cpp:454] fire5/squeeze1x1 <- pool4
I0604 20:56:52.180694   904 net.cpp:411] fire5/squeeze1x1 -> fire5/squeeze1x1
I0604 20:56:52.185159   904 net.cpp:150] Setting up fire5/squeeze1x1
I0604 20:56:52.185175   904 net.cpp:157] Top shape: 256 32 15 15 (1843200)
I0604 20:56:52.185179   904 net.cpp:165] Memory required for data: 2588247040
I0604 20:56:52.185187   904 layer_factory.hpp:77] Creating layer fire5/relu_squeeze1x1
I0604 20:56:52.185195   904 net.cpp:106] Creating Layer fire5/relu_squeeze1x1
I0604 20:56:52.185199   904 net.cpp:454] fire5/relu_squeeze1x1 <- fire5/squeeze1x1
I0604 20:56:52.185209   904 net.cpp:397] fire5/relu_squeeze1x1 -> fire5/squeeze1x1 (in-place)
I0604 20:56:52.186359   904 net.cpp:150] Setting up fire5/relu_squeeze1x1
I0604 20:56:52.186373   904 net.cpp:157] Top shape: 256 32 15 15 (1843200)
I0604 20:56:52.186378   904 net.cpp:165] Memory required for data: 2595619840
I0604 20:56:52.186383   904 layer_factory.hpp:77] Creating layer fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I0604 20:56:52.186389   904 net.cpp:106] Creating Layer fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I0604 20:56:52.186399   904 net.cpp:454] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split <- fire5/squeeze1x1
I0604 20:56:52.186405   904 net.cpp:411] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split -> fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_0
I0604 20:56:52.186414   904 net.cpp:411] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split -> fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_1
I0604 20:56:52.186470   904 net.cpp:150] Setting up fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I0604 20:56:52.186478   904 net.cpp:157] Top shape: 256 32 15 15 (1843200)
I0604 20:56:52.186483   904 net.cpp:157] Top shape: 256 32 15 15 (1843200)
I0604 20:56:52.186486   904 net.cpp:165] Memory required for data: 2610365440
I0604 20:56:52.186491   904 layer_factory.hpp:77] Creating layer fire5/expand1x1
I0604 20:56:52.186506   904 net.cpp:106] Creating Layer fire5/expand1x1
I0604 20:56:52.186512   904 net.cpp:454] fire5/expand1x1 <- fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_0
I0604 20:56:52.186522   904 net.cpp:411] fire5/expand1x1 -> fire5/expand1x1
I0604 20:56:52.190186   904 net.cpp:150] Setting up fire5/expand1x1
I0604 20:56:52.190201   904 net.cpp:157] Top shape: 256 128 15 15 (7372800)
I0604 20:56:52.190210   904 net.cpp:165] Memory required for data: 2639856640
I0604 20:56:52.190218   904 layer_factory.hpp:77] Creating layer fire5/relu_expand1x1
I0604 20:56:52.190225   904 net.cpp:106] Creating Layer fire5/relu_expand1x1
I0604 20:56:52.190229   904 net.cpp:454] fire5/relu_expand1x1 <- fire5/expand1x1
I0604 20:56:52.190237   904 net.cpp:397] fire5/relu_expand1x1 -> fire5/expand1x1 (in-place)
I0604 20:56:52.191243   904 net.cpp:150] Setting up fire5/relu_expand1x1
I0604 20:56:52.191269   904 net.cpp:157] Top shape: 256 128 15 15 (7372800)
I0604 20:56:52.191273   904 net.cpp:165] Memory required for data: 2669347840
I0604 20:56:52.191277   904 layer_factory.hpp:77] Creating layer fire5/expand3x3
I0604 20:56:52.191287   904 net.cpp:106] Creating Layer fire5/expand3x3
I0604 20:56:52.191292   904 net.cpp:454] fire5/expand3x3 <- fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_1
I0604 20:56:52.191299   904 net.cpp:411] fire5/expand3x3 -> fire5/expand3x3
I0604 20:56:52.196995   904 net.cpp:150] Setting up fire5/expand3x3
I0604 20:56:52.197010   904 net.cpp:157] Top shape: 256 128 15 15 (7372800)
I0604 20:56:52.197013   904 net.cpp:165] Memory required for data: 2698839040
I0604 20:56:52.197021   904 layer_factory.hpp:77] Creating layer fire5/relu_expand3x3
I0604 20:56:52.197028   904 net.cpp:106] Creating Layer fire5/relu_expand3x3
I0604 20:56:52.197032   904 net.cpp:454] fire5/relu_expand3x3 <- fire5/expand3x3
I0604 20:56:52.197047   904 net.cpp:397] fire5/relu_expand3x3 -> fire5/expand3x3 (in-place)
I0604 20:56:52.199080   904 net.cpp:150] Setting up fire5/relu_expand3x3
I0604 20:56:52.199093   904 net.cpp:157] Top shape: 256 128 15 15 (7372800)
I0604 20:56:52.199097   904 net.cpp:165] Memory required for data: 2728330240
I0604 20:56:52.199101   904 layer_factory.hpp:77] Creating layer fire5/concat
I0604 20:56:52.199107   904 net.cpp:106] Creating Layer fire5/concat
I0604 20:56:52.199111   904 net.cpp:454] fire5/concat <- fire5/expand1x1
I0604 20:56:52.199117   904 net.cpp:454] fire5/concat <- fire5/expand3x3
I0604 20:56:52.199125   904 net.cpp:411] fire5/concat -> fire5/concat
I0604 20:56:52.199161   904 net.cpp:150] Setting up fire5/concat
I0604 20:56:52.199169   904 net.cpp:157] Top shape: 256 256 15 15 (14745600)
I0604 20:56:52.199172   904 net.cpp:165] Memory required for data: 2787312640
I0604 20:56:52.199177   904 layer_factory.hpp:77] Creating layer fire6/squeeze1x1
I0604 20:56:52.199187   904 net.cpp:106] Creating Layer fire6/squeeze1x1
I0604 20:56:52.199192   904 net.cpp:454] fire6/squeeze1x1 <- fire5/concat
I0604 20:56:52.199198   904 net.cpp:411] fire6/squeeze1x1 -> fire6/squeeze1x1
I0604 20:56:52.202710   904 net.cpp:150] Setting up fire6/squeeze1x1
I0604 20:56:52.202724   904 net.cpp:157] Top shape: 256 48 15 15 (2764800)
I0604 20:56:52.202728   904 net.cpp:165] Memory required for data: 2798371840
I0604 20:56:52.202735   904 layer_factory.hpp:77] Creating layer fire6/relu_squeeze1x1
I0604 20:56:52.202744   904 net.cpp:106] Creating Layer fire6/relu_squeeze1x1
I0604 20:56:52.202749   904 net.cpp:454] fire6/relu_squeeze1x1 <- fire6/squeeze1x1
I0604 20:56:52.202754   904 net.cpp:397] fire6/relu_squeeze1x1 -> fire6/squeeze1x1 (in-place)
I0604 20:56:52.203758   904 net.cpp:150] Setting up fire6/relu_squeeze1x1
I0604 20:56:52.203773   904 net.cpp:157] Top shape: 256 48 15 15 (2764800)
I0604 20:56:52.203776   904 net.cpp:165] Memory required for data: 2809431040
I0604 20:56:52.203780   904 layer_factory.hpp:77] Creating layer fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I0604 20:56:52.203788   904 net.cpp:106] Creating Layer fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I0604 20:56:52.203791   904 net.cpp:454] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split <- fire6/squeeze1x1
I0604 20:56:52.203796   904 net.cpp:411] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split -> fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_0
I0604 20:56:52.203804   904 net.cpp:411] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split -> fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_1
I0604 20:56:52.203860   904 net.cpp:150] Setting up fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I0604 20:56:52.203867   904 net.cpp:157] Top shape: 256 48 15 15 (2764800)
I0604 20:56:52.203872   904 net.cpp:157] Top shape: 256 48 15 15 (2764800)
I0604 20:56:52.203876   904 net.cpp:165] Memory required for data: 2831549440
I0604 20:56:52.203881   904 layer_factory.hpp:77] Creating layer fire6/expand1x1
I0604 20:56:52.203891   904 net.cpp:106] Creating Layer fire6/expand1x1
I0604 20:56:52.203909   904 net.cpp:454] fire6/expand1x1 <- fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_0
I0604 20:56:52.203917   904 net.cpp:411] fire6/expand1x1 -> fire6/expand1x1
I0604 20:56:52.207394   904 net.cpp:150] Setting up fire6/expand1x1
I0604 20:56:52.207409   904 net.cpp:157] Top shape: 256 192 15 15 (11059200)
I0604 20:56:52.207413   904 net.cpp:165] Memory required for data: 2875786240
I0604 20:56:52.207422   904 layer_factory.hpp:77] Creating layer fire6/relu_expand1x1
I0604 20:56:52.207427   904 net.cpp:106] Creating Layer fire6/relu_expand1x1
I0604 20:56:52.207432   904 net.cpp:454] fire6/relu_expand1x1 <- fire6/expand1x1
I0604 20:56:52.207442   904 net.cpp:397] fire6/relu_expand1x1 -> fire6/expand1x1 (in-place)
I0604 20:56:52.209491   904 net.cpp:150] Setting up fire6/relu_expand1x1
I0604 20:56:52.209502   904 net.cpp:157] Top shape: 256 192 15 15 (11059200)
I0604 20:56:52.209506   904 net.cpp:165] Memory required for data: 2920023040
I0604 20:56:52.209509   904 layer_factory.hpp:77] Creating layer fire6/expand3x3
I0604 20:56:52.209519   904 net.cpp:106] Creating Layer fire6/expand3x3
I0604 20:56:52.209523   904 net.cpp:454] fire6/expand3x3 <- fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_1
I0604 20:56:52.209530   904 net.cpp:411] fire6/expand3x3 -> fire6/expand3x3
I0604 20:56:52.213172   904 net.cpp:150] Setting up fire6/expand3x3
I0604 20:56:52.213186   904 net.cpp:157] Top shape: 256 192 15 15 (11059200)
I0604 20:56:52.213189   904 net.cpp:165] Memory required for data: 2964259840
I0604 20:56:52.213196   904 layer_factory.hpp:77] Creating layer fire6/relu_expand3x3
I0604 20:56:52.213206   904 net.cpp:106] Creating Layer fire6/relu_expand3x3
I0604 20:56:52.213209   904 net.cpp:454] fire6/relu_expand3x3 <- fire6/expand3x3
I0604 20:56:52.213214   904 net.cpp:397] fire6/relu_expand3x3 -> fire6/expand3x3 (in-place)
I0604 20:56:52.214185   904 net.cpp:150] Setting up fire6/relu_expand3x3
I0604 20:56:52.214200   904 net.cpp:157] Top shape: 256 192 15 15 (11059200)
I0604 20:56:52.214203   904 net.cpp:165] Memory required for data: 3008496640
I0604 20:56:52.214207   904 layer_factory.hpp:77] Creating layer fire6/concat
I0604 20:56:52.214213   904 net.cpp:106] Creating Layer fire6/concat
I0604 20:56:52.214216   904 net.cpp:454] fire6/concat <- fire6/expand1x1
I0604 20:56:52.214221   904 net.cpp:454] fire6/concat <- fire6/expand3x3
I0604 20:56:52.214226   904 net.cpp:411] fire6/concat -> fire6/concat
I0604 20:56:52.214264   904 net.cpp:150] Setting up fire6/concat
I0604 20:56:52.214280   904 net.cpp:157] Top shape: 256 384 15 15 (22118400)
I0604 20:56:52.214283   904 net.cpp:165] Memory required for data: 3096970240
I0604 20:56:52.214287   904 layer_factory.hpp:77] Creating layer fire7/squeeze1x1
I0604 20:56:52.214296   904 net.cpp:106] Creating Layer fire7/squeeze1x1
I0604 20:56:52.214300   904 net.cpp:454] fire7/squeeze1x1 <- fire6/concat
I0604 20:56:52.214305   904 net.cpp:411] fire7/squeeze1x1 -> fire7/squeeze1x1
I0604 20:56:52.217828   904 net.cpp:150] Setting up fire7/squeeze1x1
I0604 20:56:52.217840   904 net.cpp:157] Top shape: 256 48 15 15 (2764800)
I0604 20:56:52.217844   904 net.cpp:165] Memory required for data: 3108029440
I0604 20:56:52.217860   904 layer_factory.hpp:77] Creating layer fire7/relu_squeeze1x1
I0604 20:56:52.217866   904 net.cpp:106] Creating Layer fire7/relu_squeeze1x1
I0604 20:56:52.217870   904 net.cpp:454] fire7/relu_squeeze1x1 <- fire7/squeeze1x1
I0604 20:56:52.217876   904 net.cpp:397] fire7/relu_squeeze1x1 -> fire7/squeeze1x1 (in-place)
I0604 20:56:52.218885   904 net.cpp:150] Setting up fire7/relu_squeeze1x1
I0604 20:56:52.218899   904 net.cpp:157] Top shape: 256 48 15 15 (2764800)
I0604 20:56:52.218901   904 net.cpp:165] Memory required for data: 3119088640
I0604 20:56:52.218905   904 layer_factory.hpp:77] Creating layer fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I0604 20:56:52.218911   904 net.cpp:106] Creating Layer fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I0604 20:56:52.218915   904 net.cpp:454] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split <- fire7/squeeze1x1
I0604 20:56:52.218935   904 net.cpp:411] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split -> fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_0
I0604 20:56:52.218941   904 net.cpp:411] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split -> fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_1
I0604 20:56:52.218992   904 net.cpp:150] Setting up fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I0604 20:56:52.218999   904 net.cpp:157] Top shape: 256 48 15 15 (2764800)
I0604 20:56:52.219003   904 net.cpp:157] Top shape: 256 48 15 15 (2764800)
I0604 20:56:52.219007   904 net.cpp:165] Memory required for data: 3141207040
I0604 20:56:52.219010   904 layer_factory.hpp:77] Creating layer fire7/expand1x1
I0604 20:56:52.219020   904 net.cpp:106] Creating Layer fire7/expand1x1
I0604 20:56:52.219027   904 net.cpp:454] fire7/expand1x1 <- fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_0
I0604 20:56:52.219033   904 net.cpp:411] fire7/expand1x1 -> fire7/expand1x1
I0604 20:56:52.222530   904 net.cpp:150] Setting up fire7/expand1x1
I0604 20:56:52.222544   904 net.cpp:157] Top shape: 256 192 15 15 (11059200)
I0604 20:56:52.222548   904 net.cpp:165] Memory required for data: 3185443840
I0604 20:56:52.222555   904 layer_factory.hpp:77] Creating layer fire7/relu_expand1x1
I0604 20:56:52.222561   904 net.cpp:106] Creating Layer fire7/relu_expand1x1
I0604 20:56:52.222568   904 net.cpp:454] fire7/relu_expand1x1 <- fire7/expand1x1
I0604 20:56:52.222573   904 net.cpp:397] fire7/relu_expand1x1 -> fire7/expand1x1 (in-place)
I0604 20:56:52.223572   904 net.cpp:150] Setting up fire7/relu_expand1x1
I0604 20:56:52.223582   904 net.cpp:157] Top shape: 256 192 15 15 (11059200)
I0604 20:56:52.223585   904 net.cpp:165] Memory required for data: 3229680640
I0604 20:56:52.223588   904 layer_factory.hpp:77] Creating layer fire7/expand3x3
I0604 20:56:52.223600   904 net.cpp:106] Creating Layer fire7/expand3x3
I0604 20:56:52.223604   904 net.cpp:454] fire7/expand3x3 <- fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_1
I0604 20:56:52.223610   904 net.cpp:411] fire7/expand3x3 -> fire7/expand3x3
I0604 20:56:52.227211   904 net.cpp:150] Setting up fire7/expand3x3
I0604 20:56:52.227226   904 net.cpp:157] Top shape: 256 192 15 15 (11059200)
I0604 20:56:52.227228   904 net.cpp:165] Memory required for data: 3273917440
I0604 20:56:52.227236   904 layer_factory.hpp:77] Creating layer fire7/relu_expand3x3
I0604 20:56:52.227244   904 net.cpp:106] Creating Layer fire7/relu_expand3x3
I0604 20:56:52.227248   904 net.cpp:454] fire7/relu_expand3x3 <- fire7/expand3x3
I0604 20:56:52.227254   904 net.cpp:397] fire7/relu_expand3x3 -> fire7/expand3x3 (in-place)
I0604 20:56:52.229310   904 net.cpp:150] Setting up fire7/relu_expand3x3
I0604 20:56:52.229323   904 net.cpp:157] Top shape: 256 192 15 15 (11059200)
I0604 20:56:52.229326   904 net.cpp:165] Memory required for data: 3318154240
I0604 20:56:52.229331   904 layer_factory.hpp:77] Creating layer fire7/concat
I0604 20:56:52.229338   904 net.cpp:106] Creating Layer fire7/concat
I0604 20:56:52.229342   904 net.cpp:454] fire7/concat <- fire7/expand1x1
I0604 20:56:52.229347   904 net.cpp:454] fire7/concat <- fire7/expand3x3
I0604 20:56:52.229353   904 net.cpp:411] fire7/concat -> fire7/concat
I0604 20:56:52.229389   904 net.cpp:150] Setting up fire7/concat
I0604 20:56:52.229398   904 net.cpp:157] Top shape: 256 384 15 15 (22118400)
I0604 20:56:52.229400   904 net.cpp:165] Memory required for data: 3406627840
I0604 20:56:52.229405   904 layer_factory.hpp:77] Creating layer fire8/squeeze1x1
I0604 20:56:52.229414   904 net.cpp:106] Creating Layer fire8/squeeze1x1
I0604 20:56:52.229418   904 net.cpp:454] fire8/squeeze1x1 <- fire7/concat
I0604 20:56:52.229426   904 net.cpp:411] fire8/squeeze1x1 -> fire8/squeeze1x1
I0604 20:56:52.232929   904 net.cpp:150] Setting up fire8/squeeze1x1
I0604 20:56:52.232944   904 net.cpp:157] Top shape: 256 64 15 15 (3686400)
I0604 20:56:52.232946   904 net.cpp:165] Memory required for data: 3421373440
I0604 20:56:52.232954   904 layer_factory.hpp:77] Creating layer fire8/relu_squeeze1x1
I0604 20:56:52.232962   904 net.cpp:106] Creating Layer fire8/relu_squeeze1x1
I0604 20:56:52.232980   904 net.cpp:454] fire8/relu_squeeze1x1 <- fire8/squeeze1x1
I0604 20:56:52.232985   904 net.cpp:397] fire8/relu_squeeze1x1 -> fire8/squeeze1x1 (in-place)
I0604 20:56:52.233983   904 net.cpp:150] Setting up fire8/relu_squeeze1x1
I0604 20:56:52.233995   904 net.cpp:157] Top shape: 256 64 15 15 (3686400)
I0604 20:56:52.233999   904 net.cpp:165] Memory required for data: 3436119040
I0604 20:56:52.234002   904 layer_factory.hpp:77] Creating layer fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I0604 20:56:52.234011   904 net.cpp:106] Creating Layer fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I0604 20:56:52.234014   904 net.cpp:454] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split <- fire8/squeeze1x1
I0604 20:56:52.234020   904 net.cpp:411] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split -> fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_0
I0604 20:56:52.234030   904 net.cpp:411] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split -> fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_1
I0604 20:56:52.234078   904 net.cpp:150] Setting up fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I0604 20:56:52.234089   904 net.cpp:157] Top shape: 256 64 15 15 (3686400)
I0604 20:56:52.234094   904 net.cpp:157] Top shape: 256 64 15 15 (3686400)
I0604 20:56:52.234097   904 net.cpp:165] Memory required for data: 3465610240
I0604 20:56:52.234100   904 layer_factory.hpp:77] Creating layer fire8/expand1x1
I0604 20:56:52.234117   904 net.cpp:106] Creating Layer fire8/expand1x1
I0604 20:56:52.234122   904 net.cpp:454] fire8/expand1x1 <- fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_0
I0604 20:56:52.234136   904 net.cpp:411] fire8/expand1x1 -> fire8/expand1x1
I0604 20:56:52.237627   904 net.cpp:150] Setting up fire8/expand1x1
I0604 20:56:52.237649   904 net.cpp:157] Top shape: 256 256 15 15 (14745600)
I0604 20:56:52.237656   904 net.cpp:165] Memory required for data: 3524592640
I0604 20:56:52.237663   904 layer_factory.hpp:77] Creating layer fire8/relu_expand1x1
I0604 20:56:52.237670   904 net.cpp:106] Creating Layer fire8/relu_expand1x1
I0604 20:56:52.237674   904 net.cpp:454] fire8/relu_expand1x1 <- fire8/expand1x1
I0604 20:56:52.237680   904 net.cpp:397] fire8/relu_expand1x1 -> fire8/expand1x1 (in-place)
I0604 20:56:52.238668   904 net.cpp:150] Setting up fire8/relu_expand1x1
I0604 20:56:52.238678   904 net.cpp:157] Top shape: 256 256 15 15 (14745600)
I0604 20:56:52.238682   904 net.cpp:165] Memory required for data: 3583575040
I0604 20:56:52.238692   904 layer_factory.hpp:77] Creating layer fire8/expand3x3
I0604 20:56:52.238705   904 net.cpp:106] Creating Layer fire8/expand3x3
I0604 20:56:52.238709   904 net.cpp:454] fire8/expand3x3 <- fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_1
I0604 20:56:52.238718   904 net.cpp:411] fire8/expand3x3 -> fire8/expand3x3
I0604 20:56:52.243407   904 net.cpp:150] Setting up fire8/expand3x3
I0604 20:56:52.243435   904 net.cpp:157] Top shape: 256 256 15 15 (14745600)
I0604 20:56:52.243439   904 net.cpp:165] Memory required for data: 3642557440
I0604 20:56:52.243450   904 layer_factory.hpp:77] Creating layer fire8/relu_expand3x3
I0604 20:56:52.243458   904 net.cpp:106] Creating Layer fire8/relu_expand3x3
I0604 20:56:52.243463   904 net.cpp:454] fire8/relu_expand3x3 <- fire8/expand3x3
I0604 20:56:52.243471   904 net.cpp:397] fire8/relu_expand3x3 -> fire8/expand3x3 (in-place)
I0604 20:56:52.244407   904 net.cpp:150] Setting up fire8/relu_expand3x3
I0604 20:56:52.244421   904 net.cpp:157] Top shape: 256 256 15 15 (14745600)
I0604 20:56:52.244423   904 net.cpp:165] Memory required for data: 3701539840
I0604 20:56:52.244427   904 layer_factory.hpp:77] Creating layer fire8/concat
I0604 20:56:52.244441   904 net.cpp:106] Creating Layer fire8/concat
I0604 20:56:52.244443   904 net.cpp:454] fire8/concat <- fire8/expand1x1
I0604 20:56:52.244448   904 net.cpp:454] fire8/concat <- fire8/expand3x3
I0604 20:56:52.244456   904 net.cpp:411] fire8/concat -> fire8/concat
I0604 20:56:52.244499   904 net.cpp:150] Setting up fire8/concat
I0604 20:56:52.244508   904 net.cpp:157] Top shape: 256 512 15 15 (29491200)
I0604 20:56:52.244531   904 net.cpp:165] Memory required for data: 3819504640
I0604 20:56:52.244535   904 layer_factory.hpp:77] Creating layer pool8
I0604 20:56:52.244544   904 net.cpp:106] Creating Layer pool8
I0604 20:56:52.244549   904 net.cpp:454] pool8 <- fire8/concat
I0604 20:56:52.244554   904 net.cpp:411] pool8 -> pool8
I0604 20:56:52.244602   904 net.cpp:150] Setting up pool8
I0604 20:56:52.244609   904 net.cpp:157] Top shape: 256 512 7 7 (6422528)
I0604 20:56:52.244612   904 net.cpp:165] Memory required for data: 3845194752
I0604 20:56:52.244616   904 layer_factory.hpp:77] Creating layer fire9/squeeze1x1
I0604 20:56:52.244626   904 net.cpp:106] Creating Layer fire9/squeeze1x1
I0604 20:56:52.244631   904 net.cpp:454] fire9/squeeze1x1 <- pool8
I0604 20:56:52.244637   904 net.cpp:411] fire9/squeeze1x1 -> fire9/squeeze1x1
I0604 20:56:52.248078   904 net.cpp:150] Setting up fire9/squeeze1x1
I0604 20:56:52.248095   904 net.cpp:157] Top shape: 256 64 7 7 (802816)
I0604 20:56:52.248100   904 net.cpp:165] Memory required for data: 3848406016
I0604 20:56:52.248106   904 layer_factory.hpp:77] Creating layer fire9/relu_squeeze1x1
I0604 20:56:52.248116   904 net.cpp:106] Creating Layer fire9/relu_squeeze1x1
I0604 20:56:52.248119   904 net.cpp:454] fire9/relu_squeeze1x1 <- fire9/squeeze1x1
I0604 20:56:52.248126   904 net.cpp:397] fire9/relu_squeeze1x1 -> fire9/squeeze1x1 (in-place)
I0604 20:56:52.249099   904 net.cpp:150] Setting up fire9/relu_squeeze1x1
I0604 20:56:52.249111   904 net.cpp:157] Top shape: 256 64 7 7 (802816)
I0604 20:56:52.249114   904 net.cpp:165] Memory required for data: 3851617280
I0604 20:56:52.249120   904 layer_factory.hpp:77] Creating layer fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I0604 20:56:52.249138   904 net.cpp:106] Creating Layer fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I0604 20:56:52.249142   904 net.cpp:454] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split <- fire9/squeeze1x1
I0604 20:56:52.249150   904 net.cpp:411] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split -> fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_0
I0604 20:56:52.249157   904 net.cpp:411] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split -> fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_1
I0604 20:56:52.249220   904 net.cpp:150] Setting up fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I0604 20:56:52.249228   904 net.cpp:157] Top shape: 256 64 7 7 (802816)
I0604 20:56:52.249231   904 net.cpp:157] Top shape: 256 64 7 7 (802816)
I0604 20:56:52.249234   904 net.cpp:165] Memory required for data: 3858039808
I0604 20:56:52.249238   904 layer_factory.hpp:77] Creating layer fire9/expand1x1
I0604 20:56:52.249253   904 net.cpp:106] Creating Layer fire9/expand1x1
I0604 20:56:52.249258   904 net.cpp:454] fire9/expand1x1 <- fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_0
I0604 20:56:52.249264   904 net.cpp:411] fire9/expand1x1 -> fire9/expand1x1
I0604 20:56:52.253813   904 net.cpp:150] Setting up fire9/expand1x1
I0604 20:56:52.253829   904 net.cpp:157] Top shape: 256 256 7 7 (3211264)
I0604 20:56:52.253834   904 net.cpp:165] Memory required for data: 3870884864
I0604 20:56:52.253840   904 layer_factory.hpp:77] Creating layer fire9/relu_expand1x1
I0604 20:56:52.253850   904 net.cpp:106] Creating Layer fire9/relu_expand1x1
I0604 20:56:52.253854   904 net.cpp:454] fire9/relu_expand1x1 <- fire9/expand1x1
I0604 20:56:52.253860   904 net.cpp:397] fire9/relu_expand1x1 -> fire9/expand1x1 (in-place)
I0604 20:56:52.255874   904 net.cpp:150] Setting up fire9/relu_expand1x1
I0604 20:56:52.255885   904 net.cpp:157] Top shape: 256 256 7 7 (3211264)
I0604 20:56:52.255888   904 net.cpp:165] Memory required for data: 3883729920
I0604 20:56:52.255892   904 layer_factory.hpp:77] Creating layer fire9/expand3x3
I0604 20:56:52.255904   904 net.cpp:106] Creating Layer fire9/expand3x3
I0604 20:56:52.255908   904 net.cpp:454] fire9/expand3x3 <- fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_1
I0604 20:56:52.255914   904 net.cpp:411] fire9/expand3x3 -> fire9/expand3x3
I0604 20:56:52.259513   904 net.cpp:150] Setting up fire9/expand3x3
I0604 20:56:52.259549   904 net.cpp:157] Top shape: 256 256 7 7 (3211264)
I0604 20:56:52.259554   904 net.cpp:165] Memory required for data: 3896574976
I0604 20:56:52.259562   904 layer_factory.hpp:77] Creating layer fire9/relu_expand3x3
I0604 20:56:52.259568   904 net.cpp:106] Creating Layer fire9/relu_expand3x3
I0604 20:56:52.259572   904 net.cpp:454] fire9/relu_expand3x3 <- fire9/expand3x3
I0604 20:56:52.259578   904 net.cpp:397] fire9/relu_expand3x3 -> fire9/expand3x3 (in-place)
I0604 20:56:52.260570   904 net.cpp:150] Setting up fire9/relu_expand3x3
I0604 20:56:52.260583   904 net.cpp:157] Top shape: 256 256 7 7 (3211264)
I0604 20:56:52.260587   904 net.cpp:165] Memory required for data: 3909420032
I0604 20:56:52.260591   904 layer_factory.hpp:77] Creating layer fire9/concat
I0604 20:56:52.260597   904 net.cpp:106] Creating Layer fire9/concat
I0604 20:56:52.260601   904 net.cpp:454] fire9/concat <- fire9/expand1x1
I0604 20:56:52.260607   904 net.cpp:454] fire9/concat <- fire9/expand3x3
I0604 20:56:52.260612   904 net.cpp:411] fire9/concat -> fire9/concat
I0604 20:56:52.260648   904 net.cpp:150] Setting up fire9/concat
I0604 20:56:52.260658   904 net.cpp:157] Top shape: 256 512 7 7 (6422528)
I0604 20:56:52.260661   904 net.cpp:165] Memory required for data: 3935110144
I0604 20:56:52.260664   904 layer_factory.hpp:77] Creating layer drop9
I0604 20:56:52.260673   904 net.cpp:106] Creating Layer drop9
I0604 20:56:52.260676   904 net.cpp:454] drop9 <- fire9/concat
I0604 20:56:52.260681   904 net.cpp:397] drop9 -> fire9/concat (in-place)
I0604 20:56:52.260715   904 net.cpp:150] Setting up drop9
I0604 20:56:52.260721   904 net.cpp:157] Top shape: 256 512 7 7 (6422528)
I0604 20:56:52.260725   904 net.cpp:165] Memory required for data: 3960800256
I0604 20:56:52.260727   904 layer_factory.hpp:77] Creating layer conv10
I0604 20:56:52.260737   904 net.cpp:106] Creating Layer conv10
I0604 20:56:52.260741   904 net.cpp:454] conv10 <- fire9/concat
I0604 20:56:52.260746   904 net.cpp:411] conv10 -> conv10
I0604 20:56:52.280850   904 net.cpp:150] Setting up conv10
I0604 20:56:52.280875   904 net.cpp:157] Top shape: 256 1000 9 9 (20736000)
I0604 20:56:52.280879   904 net.cpp:165] Memory required for data: 4043744256
I0604 20:56:52.280887   904 layer_factory.hpp:77] Creating layer relu_conv10
I0604 20:56:52.280897   904 net.cpp:106] Creating Layer relu_conv10
I0604 20:56:52.280902   904 net.cpp:454] relu_conv10 <- conv10
I0604 20:56:52.280908   904 net.cpp:397] relu_conv10 -> conv10 (in-place)
I0604 20:56:52.281831   904 net.cpp:150] Setting up relu_conv10
I0604 20:56:52.281844   904 net.cpp:157] Top shape: 256 1000 9 9 (20736000)
I0604 20:56:52.281847   904 net.cpp:165] Memory required for data: 4126688256
I0604 20:56:52.281852   904 layer_factory.hpp:77] Creating layer pool10
I0604 20:56:52.281862   904 net.cpp:106] Creating Layer pool10
I0604 20:56:52.281865   904 net.cpp:454] pool10 <- conv10
I0604 20:56:52.281873   904 net.cpp:411] pool10 -> pool10
I0604 20:56:52.283387   904 net.cpp:150] Setting up pool10
I0604 20:56:52.283398   904 net.cpp:157] Top shape: 256 1000 1 1 (256000)
I0604 20:56:52.283401   904 net.cpp:165] Memory required for data: 4127712256
I0604 20:56:52.283404   904 layer_factory.hpp:77] Creating layer loss
I0604 20:56:52.283414   904 net.cpp:106] Creating Layer loss
I0604 20:56:52.283417   904 net.cpp:454] loss <- pool10
I0604 20:56:52.283422   904 net.cpp:454] loss <- label
I0604 20:56:52.283428   904 net.cpp:411] loss -> loss
I0604 20:56:52.283439   904 layer_factory.hpp:77] Creating layer loss
I0604 20:56:52.286257   904 net.cpp:150] Setting up loss
I0604 20:56:52.286270   904 net.cpp:157] Top shape: (1)
I0604 20:56:52.286273   904 net.cpp:160]     with loss weight 1
I0604 20:56:52.286298   904 net.cpp:165] Memory required for data: 4127712260
I0604 20:56:52.286303   904 net.cpp:226] loss needs backward computation.
I0604 20:56:52.286309   904 net.cpp:226] pool10 needs backward computation.
I0604 20:56:52.286311   904 net.cpp:226] relu_conv10 needs backward computation.
I0604 20:56:52.286314   904 net.cpp:226] conv10 needs backward computation.
I0604 20:56:52.286330   904 net.cpp:226] drop9 needs backward computation.
I0604 20:56:52.286334   904 net.cpp:226] fire9/concat needs backward computation.
I0604 20:56:52.286336   904 net.cpp:226] fire9/relu_expand3x3 needs backward computation.
I0604 20:56:52.286339   904 net.cpp:226] fire9/expand3x3 needs backward computation.
I0604 20:56:52.286342   904 net.cpp:226] fire9/relu_expand1x1 needs backward computation.
I0604 20:56:52.286345   904 net.cpp:226] fire9/expand1x1 needs backward computation.
I0604 20:56:52.286348   904 net.cpp:226] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split needs backward computation.
I0604 20:56:52.286352   904 net.cpp:226] fire9/relu_squeeze1x1 needs backward computation.
I0604 20:56:52.286355   904 net.cpp:226] fire9/squeeze1x1 needs backward computation.
I0604 20:56:52.286358   904 net.cpp:226] pool8 needs backward computation.
I0604 20:56:52.286361   904 net.cpp:226] fire8/concat needs backward computation.
I0604 20:56:52.286365   904 net.cpp:226] fire8/relu_expand3x3 needs backward computation.
I0604 20:56:52.286368   904 net.cpp:226] fire8/expand3x3 needs backward computation.
I0604 20:56:52.286372   904 net.cpp:226] fire8/relu_expand1x1 needs backward computation.
I0604 20:56:52.286375   904 net.cpp:226] fire8/expand1x1 needs backward computation.
I0604 20:56:52.286378   904 net.cpp:226] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split needs backward computation.
I0604 20:56:52.286381   904 net.cpp:226] fire8/relu_squeeze1x1 needs backward computation.
I0604 20:56:52.286384   904 net.cpp:226] fire8/squeeze1x1 needs backward computation.
I0604 20:56:52.286387   904 net.cpp:226] fire7/concat needs backward computation.
I0604 20:56:52.286391   904 net.cpp:226] fire7/relu_expand3x3 needs backward computation.
I0604 20:56:52.286393   904 net.cpp:226] fire7/expand3x3 needs backward computation.
I0604 20:56:52.286397   904 net.cpp:226] fire7/relu_expand1x1 needs backward computation.
I0604 20:56:52.286401   904 net.cpp:226] fire7/expand1x1 needs backward computation.
I0604 20:56:52.286403   904 net.cpp:226] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split needs backward computation.
I0604 20:56:52.286406   904 net.cpp:226] fire7/relu_squeeze1x1 needs backward computation.
I0604 20:56:52.286412   904 net.cpp:226] fire7/squeeze1x1 needs backward computation.
I0604 20:56:52.286415   904 net.cpp:226] fire6/concat needs backward computation.
I0604 20:56:52.286419   904 net.cpp:226] fire6/relu_expand3x3 needs backward computation.
I0604 20:56:52.286422   904 net.cpp:226] fire6/expand3x3 needs backward computation.
I0604 20:56:52.286428   904 net.cpp:226] fire6/relu_expand1x1 needs backward computation.
I0604 20:56:52.286432   904 net.cpp:226] fire6/expand1x1 needs backward computation.
I0604 20:56:52.286454   904 net.cpp:226] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split needs backward computation.
I0604 20:56:52.286459   904 net.cpp:226] fire6/relu_squeeze1x1 needs backward computation.
I0604 20:56:52.286463   904 net.cpp:226] fire6/squeeze1x1 needs backward computation.
I0604 20:56:52.286466   904 net.cpp:226] fire5/concat needs backward computation.
I0604 20:56:52.286469   904 net.cpp:226] fire5/relu_expand3x3 needs backward computation.
I0604 20:56:52.286473   904 net.cpp:226] fire5/expand3x3 needs backward computation.
I0604 20:56:52.286475   904 net.cpp:226] fire5/relu_expand1x1 needs backward computation.
I0604 20:56:52.286478   904 net.cpp:226] fire5/expand1x1 needs backward computation.
I0604 20:56:52.286481   904 net.cpp:226] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split needs backward computation.
I0604 20:56:52.286485   904 net.cpp:226] fire5/relu_squeeze1x1 needs backward computation.
I0604 20:56:52.286489   904 net.cpp:226] fire5/squeeze1x1 needs backward computation.
I0604 20:56:52.286491   904 net.cpp:226] pool4 needs backward computation.
I0604 20:56:52.286494   904 net.cpp:226] fire4/concat needs backward computation.
I0604 20:56:52.286499   904 net.cpp:226] fire4/relu_expand3x3 needs backward computation.
I0604 20:56:52.286501   904 net.cpp:226] fire4/expand3x3 needs backward computation.
I0604 20:56:52.286511   904 net.cpp:226] fire4/relu_expand1x1 needs backward computation.
I0604 20:56:52.286514   904 net.cpp:226] fire4/expand1x1 needs backward computation.
I0604 20:56:52.286517   904 net.cpp:226] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split needs backward computation.
I0604 20:56:52.286520   904 net.cpp:226] fire4/relu_squeeze1x1 needs backward computation.
I0604 20:56:52.286523   904 net.cpp:226] fire4/squeeze1x1 needs backward computation.
I0604 20:56:52.286526   904 net.cpp:226] fire3/concat needs backward computation.
I0604 20:56:52.286530   904 net.cpp:226] fire3/relu_expand3x3 needs backward computation.
I0604 20:56:52.286533   904 net.cpp:226] fire3/expand3x3 needs backward computation.
I0604 20:56:52.286536   904 net.cpp:226] fire3/relu_expand1x1 needs backward computation.
I0604 20:56:52.286540   904 net.cpp:226] fire3/expand1x1 needs backward computation.
I0604 20:56:52.286542   904 net.cpp:226] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split needs backward computation.
I0604 20:56:52.286545   904 net.cpp:226] fire3/relu_squeeze1x1 needs backward computation.
I0604 20:56:52.286548   904 net.cpp:226] fire3/squeeze1x1 needs backward computation.
I0604 20:56:52.286551   904 net.cpp:226] fire2/concat needs backward computation.
I0604 20:56:52.286556   904 net.cpp:226] fire2/relu_expand3x3 needs backward computation.
I0604 20:56:52.286557   904 net.cpp:226] fire2/expand3x3 needs backward computation.
I0604 20:56:52.286561   904 net.cpp:226] fire2/relu_expand1x1 needs backward computation.
I0604 20:56:52.286563   904 net.cpp:226] fire2/expand1x1 needs backward computation.
I0604 20:56:52.286567   904 net.cpp:226] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split needs backward computation.
I0604 20:56:52.286571   904 net.cpp:226] fire2/relu_squeeze1x1 needs backward computation.
I0604 20:56:52.286573   904 net.cpp:226] fire2/squeeze1x1 needs backward computation.
I0604 20:56:52.286576   904 net.cpp:226] pool1 needs backward computation.
I0604 20:56:52.286579   904 net.cpp:226] relu_conv1 needs backward computation.
I0604 20:56:52.286582   904 net.cpp:226] conv1 needs backward computation.
I0604 20:56:52.286586   904 net.cpp:228] data does not need backward computation.
I0604 20:56:52.286589   904 net.cpp:270] This network produces output loss
I0604 20:56:52.286643   904 net.cpp:283] Network initialization done.
I0604 20:56:52.286936   904 solver.cpp:181] Creating test net (#0) specified by net_param
I0604 20:56:52.287037   904 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0604 20:56:52.287081   904 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss
I0604 20:56:52.287641   904 net.cpp:49] Initializing net from parameters: 
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.04
    mirror: false
    crop_size: 128
    mean_value: 104
    mean_value: 117
    mean_value: 123
    force_color: true
  }
  data_param {
    source: "/local/temporary/mishkdmy/imagenet144pxlmdb/ilsvrc12_128_val_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 96
    kernel_size: 7
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "relu_conv1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fire2/squeeze1x1"
  type: "Convolution"
  bottom: "pool1"
  top: "fire2/squeeze1x1"
  convolution_param {
    num_output: 16
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire2/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire2/squeeze1x1"
  top: "fire2/squeeze1x1"
}
layer {
  name: "fire2/expand1x1"
  type: "Convolution"
  bottom: "fire2/squeeze1x1"
  top: "fire2/expand1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire2/relu_expand1x1"
  type: "ReLU"
  bottom: "fire2/expand1x1"
  top: "fire2/expand1x1"
}
layer {
  name: "fire2/expand3x3"
  type: "Convolution"
  bottom: "fire2/squeeze1x1"
  top: "fire2/expand3x3"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire2/relu_expand3x3"
  type: "ReLU"
  bottom: "fire2/expand3x3"
  top: "fire2/expand3x3"
}
layer {
  name: "fire2/concat"
  type: "Concat"
  bottom: "fire2/expand1x1"
  bottom: "fire2/expand3x3"
  top: "fire2/concat"
}
layer {
  name: "fire3/squeeze1x1"
  type: "Convolution"
  bottom: "fire2/concat"
  top: "fire3/squeeze1x1"
  convolution_param {
    num_output: 16
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire3/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire3/squeeze1x1"
  top: "fire3/squeeze1x1"
}
layer {
  name: "fire3/expand1x1"
  type: "Convolution"
  bottom: "fire3/squeeze1x1"
  top: "fire3/expand1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire3/relu_expand1x1"
  type: "ReLU"
  bottom: "fire3/expand1x1"
  top: "fire3/expand1x1"
}
layer {
  name: "fire3/expand3x3"
  type: "Convolution"
  bottom: "fire3/squeeze1x1"
  top: "fire3/expand3x3"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire3/relu_expand3x3"
  type: "ReLU"
  bottom: "fire3/expand3x3"
  top: "fire3/expand3x3"
}
layer {
  name: "fire3/concat"
  type: "Concat"
  bottom: "fire3/expand1x1"
  bottom: "fire3/expand3x3"
  top: "fire3/concat"
}
layer {
  name: "fire4/squeeze1x1"
  type: "Convolution"
  bottom: "fire3/concat"
  top: "fire4/squeeze1x1"
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire4/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire4/squeeze1x1"
  top: "fire4/squeeze1x1"
}
layer {
  name: "fire4/expand1x1"
  type: "Convolution"
  bottom: "fire4/squeeze1x1"
  top: "fire4/expand1x1"
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire4/relu_expand1x1"
  type: "ReLU"
  bottom: "fire4/expand1x1"
  top: "fire4/expand1x1"
}
layer {
  name: "fire4/expand3x3"
  type: "Convolution"
  bottom: "fire4/squeeze1x1"
  top: "fire4/expand3x3"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire4/relu_expand3x3"
  type: "ReLU"
  bottom: "fire4/expand3x3"
  top: "fire4/expand3x3"
}
layer {
  name: "fire4/concat"
  type: "Concat"
  bottom: "fire4/expand1x1"
  bottom: "fire4/expand3x3"
  top: "fire4/concat"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "fire4/concat"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fire5/squeeze1x1"
  type: "Convolution"
  bottom: "pool4"
  top: "fire5/squeeze1x1"
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire5/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire5/squeeze1x1"
  top: "fire5/squeeze1x1"
}
layer {
  name: "fire5/expand1x1"
  type: "Convolution"
  bottom: "fire5/squeeze1x1"
  top: "fire5/expand1x1"
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire5/relu_expand1x1"
  type: "ReLU"
  bottom: "fire5/expand1x1"
  top: "fire5/expand1x1"
}
layer {
  name: "fire5/expand3x3"
  type: "Convolution"
  bottom: "fire5/squeeze1x1"
  top: "fire5/expand3x3"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire5/relu_expand3x3"
  type: "ReLU"
  bottom: "fire5/expand3x3"
  top: "fire5/expand3x3"
}
layer {
  name: "fire5/concat"
  type: "Concat"
  bottom: "fire5/expand1x1"
  bottom: "fire5/expand3x3"
  top: "fire5/concat"
}
layer {
  name: "fire6/squeeze1x1"
  type: "Convolution"
  bottom: "fire5/concat"
  top: "fire6/squeeze1x1"
  convolution_param {
    num_output: 48
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire6/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire6/squeeze1x1"
  top: "fire6/squeeze1x1"
}
layer {
  name: "fire6/expand1x1"
  type: "Convolution"
  bottom: "fire6/squeeze1x1"
  top: "fire6/expand1x1"
  convolution_param {
    num_output: 192
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire6/relu_expand1x1"
  type: "ReLU"
  bottom: "fire6/expand1x1"
  top: "fire6/expand1x1"
}
layer {
  name: "fire6/expand3x3"
  type: "Convolution"
  bottom: "fire6/squeeze1x1"
  top: "fire6/expand3x3"
  convolution_param {
    num_output: 192
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire6/relu_expand3x3"
  type: "ReLU"
  bottom: "fire6/expand3x3"
  top: "fire6/expand3x3"
}
layer {
  name: "fire6/concat"
  type: "Concat"
  bottom: "fire6/expand1x1"
  bottom: "fire6/expand3x3"
  top: "fire6/concat"
}
layer {
  name: "fire7/squeeze1x1"
  type: "Convolution"
  bottom: "fire6/concat"
  top: "fire7/squeeze1x1"
  convolution_param {
    num_output: 48
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire7/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire7/squeeze1x1"
  top: "fire7/squeeze1x1"
}
layer {
  name: "fire7/expand1x1"
  type: "Convolution"
  bottom: "fire7/squeeze1x1"
  top: "fire7/expand1x1"
  convolution_param {
    num_output: 192
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire7/relu_expand1x1"
  type: "ReLU"
  bottom: "fire7/expand1x1"
  top: "fire7/expand1x1"
}
layer {
  name: "fire7/expand3x3"
  type: "Convolution"
  bottom: "fire7/squeeze1x1"
  top: "fire7/expand3x3"
  convolution_param {
    num_output: 192
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire7/relu_expand3x3"
  type: "ReLU"
  bottom: "fire7/expand3x3"
  top: "fire7/expand3x3"
}
layer {
  name: "fire7/concat"
  type: "Concat"
  bottom: "fire7/expand1x1"
  bottom: "fire7/expand3x3"
  top: "fire7/concat"
}
layer {
  name: "fire8/squeeze1x1"
  type: "Convolution"
  bottom: "fire7/concat"
  top: "fire8/squeeze1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire8/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire8/squeeze1x1"
  top: "fire8/squeeze1x1"
}
layer {
  name: "fire8/expand1x1"
  type: "Convolution"
  bottom: "fire8/squeeze1x1"
  top: "fire8/expand1x1"
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire8/relu_expand1x1"
  type: "ReLU"
  bottom: "fire8/expand1x1"
  top: "fire8/expand1x1"
}
layer {
  name: "fire8/expand3x3"
  type: "Convolution"
  bottom: "fire8/squeeze1x1"
  top: "fire8/expand3x3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire8/relu_expand3x3"
  type: "ReLU"
  bottom: "fire8/expand3x3"
  top: "fire8/expand3x3"
}
layer {
  name: "fire8/concat"
  type: "Concat"
  bottom: "fire8/expand1x1"
  bottom: "fire8/expand3x3"
  top: "fire8/concat"
}
layer {
  name: "pool8"
  type: "Pooling"
  bottom: "fire8/concat"
  top: "pool8"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fire9/squeeze1x1"
  type: "Convolution"
  bottom: "pool8"
  top: "fire9/squeeze1x1"
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire9/relu_squeeze1x1"
  type: "ReLU"
  bottom: "fire9/squeeze1x1"
  top: "fire9/squeeze1x1"
}
layer {
  name: "fire9/expand1x1"
  type: "Convolution"
  bottom: "fire9/squeeze1x1"
  top: "fire9/expand1x1"
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire9/relu_expand1x1"
  type: "ReLU"
  bottom: "fire9/expand1x1"
  top: "fire9/expand1x1"
}
layer {
  name: "fire9/expand3x3"
  type: "Convolution"
  bottom: "fire9/squeeze1x1"
  top: "fire9/expand3x3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "fire9/relu_expand3x3"
  type: "ReLU"
  bottom: "fire9/expand3x3"
  top: "fire9/expand3x3"
}
layer {
  name: "fire9/concat"
  type: "Concat"
  bottom: "fire9/expand1x1"
  bottom: "fire9/expand3x3"
  top: "fire9/concat"
}
layer {
  name: "drop9"
  type: "Dropout"
  bottom: "fire9/concat"
  top: "fire9/concat"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "conv10"
  type: "Convolution"
  bottom: "fire9/concat"
  top: "conv10"
  convolution_param {
    num_output: 1000
    pad: 1
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      mean: 0
      std: 0.01
    }
  }
}
layer {
  name: "relu_conv10"
  type: "ReLU"
  bottom: "conv10"
  top: "conv10"
}
layer {
  name: "pool10"
  type: "Pooling"
  bottom: "conv10"
  top: "pool10"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "pool10"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "accuracy_top5"
  type: "Accuracy"
  bottom: "pool10"
  bottom: "label"
  top: "accuracy_top5"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 5
  }
}
I0604 20:56:52.287997   904 layer_factory.hpp:77] Creating layer data
I0604 20:56:52.288111   904 net.cpp:106] Creating Layer data
I0604 20:56:52.288120   904 net.cpp:411] data -> data
I0604 20:56:52.288130   904 net.cpp:411] data -> label
I0604 20:56:52.289691   937 db_lmdb.cpp:38] Opened lmdb /local/temporary/mishkdmy/imagenet144pxlmdb/ilsvrc12_128_val_lmdb
I0604 20:56:52.290666   904 data_layer.cpp:41] output data size: 50,3,128,128
I0604 20:56:52.312422   904 net.cpp:150] Setting up data
I0604 20:56:52.312455   904 net.cpp:157] Top shape: 50 3 128 128 (2457600)
I0604 20:56:52.312461   904 net.cpp:157] Top shape: 50 (50)
I0604 20:56:52.312464   904 net.cpp:165] Memory required for data: 9830600
I0604 20:56:52.312471   904 layer_factory.hpp:77] Creating layer label_data_1_split
I0604 20:56:52.312487   904 net.cpp:106] Creating Layer label_data_1_split
I0604 20:56:52.312494   904 net.cpp:454] label_data_1_split <- label
I0604 20:56:52.312502   904 net.cpp:411] label_data_1_split -> label_data_1_split_0
I0604 20:56:52.312515   904 net.cpp:411] label_data_1_split -> label_data_1_split_1
I0604 20:56:52.312695   904 net.cpp:150] Setting up label_data_1_split
I0604 20:56:52.312705   904 net.cpp:157] Top shape: 50 (50)
I0604 20:56:52.312714   904 net.cpp:157] Top shape: 50 (50)
I0604 20:56:52.312717   904 net.cpp:165] Memory required for data: 9831000
I0604 20:56:52.312721   904 layer_factory.hpp:77] Creating layer conv1
I0604 20:56:52.312736   904 net.cpp:106] Creating Layer conv1
I0604 20:56:52.312741   904 net.cpp:454] conv1 <- data
I0604 20:56:52.312752   904 net.cpp:411] conv1 -> conv1
I0604 20:56:52.322317   904 net.cpp:150] Setting up conv1
I0604 20:56:52.322337   904 net.cpp:157] Top shape: 50 96 61 61 (17860800)
I0604 20:56:52.322343   904 net.cpp:165] Memory required for data: 81274200
I0604 20:56:52.322365   904 layer_factory.hpp:77] Creating layer relu_conv1
I0604 20:56:52.322378   904 net.cpp:106] Creating Layer relu_conv1
I0604 20:56:52.322388   904 net.cpp:454] relu_conv1 <- conv1
I0604 20:56:52.322396   904 net.cpp:397] relu_conv1 -> conv1 (in-place)
I0604 20:56:52.322610   904 net.cpp:150] Setting up relu_conv1
I0604 20:56:52.322620   904 net.cpp:157] Top shape: 50 96 61 61 (17860800)
I0604 20:56:52.322623   904 net.cpp:165] Memory required for data: 152717400
I0604 20:56:52.322628   904 layer_factory.hpp:77] Creating layer pool1
I0604 20:56:52.322659   904 net.cpp:106] Creating Layer pool1
I0604 20:56:52.322665   904 net.cpp:454] pool1 <- conv1
I0604 20:56:52.322670   904 net.cpp:411] pool1 -> pool1
I0604 20:56:52.322727   904 net.cpp:150] Setting up pool1
I0604 20:56:52.322736   904 net.cpp:157] Top shape: 50 96 30 30 (4320000)
I0604 20:56:52.322738   904 net.cpp:165] Memory required for data: 169997400
I0604 20:56:52.322741   904 layer_factory.hpp:77] Creating layer fire2/squeeze1x1
I0604 20:56:52.322756   904 net.cpp:106] Creating Layer fire2/squeeze1x1
I0604 20:56:52.322758   904 net.cpp:454] fire2/squeeze1x1 <- pool1
I0604 20:56:52.322764   904 net.cpp:411] fire2/squeeze1x1 -> fire2/squeeze1x1
I0604 20:56:52.324563   904 net.cpp:150] Setting up fire2/squeeze1x1
I0604 20:56:52.324578   904 net.cpp:157] Top shape: 50 16 30 30 (720000)
I0604 20:56:52.324586   904 net.cpp:165] Memory required for data: 172877400
I0604 20:56:52.324597   904 layer_factory.hpp:77] Creating layer fire2/relu_squeeze1x1
I0604 20:56:52.324604   904 net.cpp:106] Creating Layer fire2/relu_squeeze1x1
I0604 20:56:52.324607   904 net.cpp:454] fire2/relu_squeeze1x1 <- fire2/squeeze1x1
I0604 20:56:52.324612   904 net.cpp:397] fire2/relu_squeeze1x1 -> fire2/squeeze1x1 (in-place)
I0604 20:56:52.325536   904 net.cpp:150] Setting up fire2/relu_squeeze1x1
I0604 20:56:52.325549   904 net.cpp:157] Top shape: 50 16 30 30 (720000)
I0604 20:56:52.325558   904 net.cpp:165] Memory required for data: 175757400
I0604 20:56:52.325562   904 layer_factory.hpp:77] Creating layer fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I0604 20:56:52.325569   904 net.cpp:106] Creating Layer fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I0604 20:56:52.325578   904 net.cpp:454] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split <- fire2/squeeze1x1
I0604 20:56:52.325587   904 net.cpp:411] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split -> fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_0
I0604 20:56:52.325595   904 net.cpp:411] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split -> fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_1
I0604 20:56:52.325654   904 net.cpp:150] Setting up fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split
I0604 20:56:52.325660   904 net.cpp:157] Top shape: 50 16 30 30 (720000)
I0604 20:56:52.325665   904 net.cpp:157] Top shape: 50 16 30 30 (720000)
I0604 20:56:52.325669   904 net.cpp:165] Memory required for data: 181517400
I0604 20:56:52.325671   904 layer_factory.hpp:77] Creating layer fire2/expand1x1
I0604 20:56:52.325682   904 net.cpp:106] Creating Layer fire2/expand1x1
I0604 20:56:52.325688   904 net.cpp:454] fire2/expand1x1 <- fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_0
I0604 20:56:52.325695   904 net.cpp:411] fire2/expand1x1 -> fire2/expand1x1
I0604 20:56:52.329377   904 net.cpp:150] Setting up fire2/expand1x1
I0604 20:56:52.329392   904 net.cpp:157] Top shape: 50 64 30 30 (2880000)
I0604 20:56:52.329396   904 net.cpp:165] Memory required for data: 193037400
I0604 20:56:52.329406   904 layer_factory.hpp:77] Creating layer fire2/relu_expand1x1
I0604 20:56:52.329416   904 net.cpp:106] Creating Layer fire2/relu_expand1x1
I0604 20:56:52.329421   904 net.cpp:454] fire2/relu_expand1x1 <- fire2/expand1x1
I0604 20:56:52.329433   904 net.cpp:397] fire2/relu_expand1x1 -> fire2/expand1x1 (in-place)
I0604 20:56:52.330303   904 net.cpp:150] Setting up fire2/relu_expand1x1
I0604 20:56:52.330313   904 net.cpp:157] Top shape: 50 64 30 30 (2880000)
I0604 20:56:52.330317   904 net.cpp:165] Memory required for data: 204557400
I0604 20:56:52.330325   904 layer_factory.hpp:77] Creating layer fire2/expand3x3
I0604 20:56:52.330335   904 net.cpp:106] Creating Layer fire2/expand3x3
I0604 20:56:52.330339   904 net.cpp:454] fire2/expand3x3 <- fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split_1
I0604 20:56:52.330348   904 net.cpp:411] fire2/expand3x3 -> fire2/expand3x3
I0604 20:56:52.334789   904 net.cpp:150] Setting up fire2/expand3x3
I0604 20:56:52.334811   904 net.cpp:157] Top shape: 50 64 30 30 (2880000)
I0604 20:56:52.334815   904 net.cpp:165] Memory required for data: 216077400
I0604 20:56:52.334822   904 layer_factory.hpp:77] Creating layer fire2/relu_expand3x3
I0604 20:56:52.334841   904 net.cpp:106] Creating Layer fire2/relu_expand3x3
I0604 20:56:52.334846   904 net.cpp:454] fire2/relu_expand3x3 <- fire2/expand3x3
I0604 20:56:52.334858   904 net.cpp:397] fire2/relu_expand3x3 -> fire2/expand3x3 (in-place)
I0604 20:56:52.336113   904 net.cpp:150] Setting up fire2/relu_expand3x3
I0604 20:56:52.336123   904 net.cpp:157] Top shape: 50 64 30 30 (2880000)
I0604 20:56:52.336127   904 net.cpp:165] Memory required for data: 227597400
I0604 20:56:52.336135   904 layer_factory.hpp:77] Creating layer fire2/concat
I0604 20:56:52.336141   904 net.cpp:106] Creating Layer fire2/concat
I0604 20:56:52.336145   904 net.cpp:454] fire2/concat <- fire2/expand1x1
I0604 20:56:52.336156   904 net.cpp:454] fire2/concat <- fire2/expand3x3
I0604 20:56:52.336174   904 net.cpp:411] fire2/concat -> fire2/concat
I0604 20:56:52.336220   904 net.cpp:150] Setting up fire2/concat
I0604 20:56:52.336227   904 net.cpp:157] Top shape: 50 128 30 30 (5760000)
I0604 20:56:52.336230   904 net.cpp:165] Memory required for data: 250637400
I0604 20:56:52.336233   904 layer_factory.hpp:77] Creating layer fire3/squeeze1x1
I0604 20:56:52.336246   904 net.cpp:106] Creating Layer fire3/squeeze1x1
I0604 20:56:52.336252   904 net.cpp:454] fire3/squeeze1x1 <- fire2/concat
I0604 20:56:52.336264   904 net.cpp:411] fire3/squeeze1x1 -> fire3/squeeze1x1
I0604 20:56:52.340021   904 net.cpp:150] Setting up fire3/squeeze1x1
I0604 20:56:52.340034   904 net.cpp:157] Top shape: 50 16 30 30 (720000)
I0604 20:56:52.340039   904 net.cpp:165] Memory required for data: 253517400
I0604 20:56:52.340049   904 layer_factory.hpp:77] Creating layer fire3/relu_squeeze1x1
I0604 20:56:52.340060   904 net.cpp:106] Creating Layer fire3/relu_squeeze1x1
I0604 20:56:52.340065   904 net.cpp:454] fire3/relu_squeeze1x1 <- fire3/squeeze1x1
I0604 20:56:52.340070   904 net.cpp:397] fire3/relu_squeeze1x1 -> fire3/squeeze1x1 (in-place)
I0604 20:56:52.341382   904 net.cpp:150] Setting up fire3/relu_squeeze1x1
I0604 20:56:52.341395   904 net.cpp:157] Top shape: 50 16 30 30 (720000)
I0604 20:56:52.341398   904 net.cpp:165] Memory required for data: 256397400
I0604 20:56:52.341406   904 layer_factory.hpp:77] Creating layer fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I0604 20:56:52.341413   904 net.cpp:106] Creating Layer fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I0604 20:56:52.341416   904 net.cpp:454] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split <- fire3/squeeze1x1
I0604 20:56:52.341424   904 net.cpp:411] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split -> fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_0
I0604 20:56:52.341431   904 net.cpp:411] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split -> fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_1
I0604 20:56:52.341490   904 net.cpp:150] Setting up fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split
I0604 20:56:52.341498   904 net.cpp:157] Top shape: 50 16 30 30 (720000)
I0604 20:56:52.341503   904 net.cpp:157] Top shape: 50 16 30 30 (720000)
I0604 20:56:52.341506   904 net.cpp:165] Memory required for data: 262157400
I0604 20:56:52.341509   904 layer_factory.hpp:77] Creating layer fire3/expand1x1
I0604 20:56:52.341521   904 net.cpp:106] Creating Layer fire3/expand1x1
I0604 20:56:52.341524   904 net.cpp:454] fire3/expand1x1 <- fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_0
I0604 20:56:52.341529   904 net.cpp:411] fire3/expand1x1 -> fire3/expand1x1
I0604 20:56:52.346806   904 net.cpp:150] Setting up fire3/expand1x1
I0604 20:56:52.346819   904 net.cpp:157] Top shape: 50 64 30 30 (2880000)
I0604 20:56:52.346823   904 net.cpp:165] Memory required for data: 273677400
I0604 20:56:52.346830   904 layer_factory.hpp:77] Creating layer fire3/relu_expand1x1
I0604 20:56:52.346838   904 net.cpp:106] Creating Layer fire3/relu_expand1x1
I0604 20:56:52.346842   904 net.cpp:454] fire3/relu_expand1x1 <- fire3/expand1x1
I0604 20:56:52.346848   904 net.cpp:397] fire3/relu_expand1x1 -> fire3/expand1x1 (in-place)
I0604 20:56:52.348318   904 net.cpp:150] Setting up fire3/relu_expand1x1
I0604 20:56:52.348340   904 net.cpp:157] Top shape: 50 64 30 30 (2880000)
I0604 20:56:52.348343   904 net.cpp:165] Memory required for data: 285197400
I0604 20:56:52.348351   904 layer_factory.hpp:77] Creating layer fire3/expand3x3
I0604 20:56:52.348369   904 net.cpp:106] Creating Layer fire3/expand3x3
I0604 20:56:52.348377   904 net.cpp:454] fire3/expand3x3 <- fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split_1
I0604 20:56:52.348384   904 net.cpp:411] fire3/expand3x3 -> fire3/expand3x3
I0604 20:56:52.353588   904 net.cpp:150] Setting up fire3/expand3x3
I0604 20:56:52.353602   904 net.cpp:157] Top shape: 50 64 30 30 (2880000)
I0604 20:56:52.353612   904 net.cpp:165] Memory required for data: 296717400
I0604 20:56:52.353620   904 layer_factory.hpp:77] Creating layer fire3/relu_expand3x3
I0604 20:56:52.353628   904 net.cpp:106] Creating Layer fire3/relu_expand3x3
I0604 20:56:52.353632   904 net.cpp:454] fire3/relu_expand3x3 <- fire3/expand3x3
I0604 20:56:52.353638   904 net.cpp:397] fire3/relu_expand3x3 -> fire3/expand3x3 (in-place)
I0604 20:56:52.354915   904 net.cpp:150] Setting up fire3/relu_expand3x3
I0604 20:56:52.354925   904 net.cpp:157] Top shape: 50 64 30 30 (2880000)
I0604 20:56:52.354935   904 net.cpp:165] Memory required for data: 308237400
I0604 20:56:52.354938   904 layer_factory.hpp:77] Creating layer fire3/concat
I0604 20:56:52.354944   904 net.cpp:106] Creating Layer fire3/concat
I0604 20:56:52.354948   904 net.cpp:454] fire3/concat <- fire3/expand1x1
I0604 20:56:52.354953   904 net.cpp:454] fire3/concat <- fire3/expand3x3
I0604 20:56:52.354959   904 net.cpp:411] fire3/concat -> fire3/concat
I0604 20:56:52.354998   904 net.cpp:150] Setting up fire3/concat
I0604 20:56:52.355006   904 net.cpp:157] Top shape: 50 128 30 30 (5760000)
I0604 20:56:52.355010   904 net.cpp:165] Memory required for data: 331277400
I0604 20:56:52.355012   904 layer_factory.hpp:77] Creating layer fire4/squeeze1x1
I0604 20:56:52.355020   904 net.cpp:106] Creating Layer fire4/squeeze1x1
I0604 20:56:52.355023   904 net.cpp:454] fire4/squeeze1x1 <- fire3/concat
I0604 20:56:52.355031   904 net.cpp:411] fire4/squeeze1x1 -> fire4/squeeze1x1
I0604 20:56:52.360077   904 net.cpp:150] Setting up fire4/squeeze1x1
I0604 20:56:52.360091   904 net.cpp:157] Top shape: 50 32 30 30 (1440000)
I0604 20:56:52.360095   904 net.cpp:165] Memory required for data: 337037400
I0604 20:56:52.360102   904 layer_factory.hpp:77] Creating layer fire4/relu_squeeze1x1
I0604 20:56:52.360108   904 net.cpp:106] Creating Layer fire4/relu_squeeze1x1
I0604 20:56:52.360112   904 net.cpp:454] fire4/relu_squeeze1x1 <- fire4/squeeze1x1
I0604 20:56:52.360119   904 net.cpp:397] fire4/relu_squeeze1x1 -> fire4/squeeze1x1 (in-place)
I0604 20:56:52.365952   904 net.cpp:150] Setting up fire4/relu_squeeze1x1
I0604 20:56:52.365968   904 net.cpp:157] Top shape: 50 32 30 30 (1440000)
I0604 20:56:52.365972   904 net.cpp:165] Memory required for data: 342797400
I0604 20:56:52.365977   904 layer_factory.hpp:77] Creating layer fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I0604 20:56:52.365985   904 net.cpp:106] Creating Layer fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I0604 20:56:52.365988   904 net.cpp:454] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split <- fire4/squeeze1x1
I0604 20:56:52.365994   904 net.cpp:411] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split -> fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_0
I0604 20:56:52.366003   904 net.cpp:411] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split -> fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_1
I0604 20:56:52.366070   904 net.cpp:150] Setting up fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split
I0604 20:56:52.366077   904 net.cpp:157] Top shape: 50 32 30 30 (1440000)
I0604 20:56:52.366082   904 net.cpp:157] Top shape: 50 32 30 30 (1440000)
I0604 20:56:52.366086   904 net.cpp:165] Memory required for data: 354317400
I0604 20:56:52.366088   904 layer_factory.hpp:77] Creating layer fire4/expand1x1
I0604 20:56:52.366098   904 net.cpp:106] Creating Layer fire4/expand1x1
I0604 20:56:52.366102   904 net.cpp:454] fire4/expand1x1 <- fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_0
I0604 20:56:52.366122   904 net.cpp:411] fire4/expand1x1 -> fire4/expand1x1
I0604 20:56:52.368567   904 net.cpp:150] Setting up fire4/expand1x1
I0604 20:56:52.368589   904 net.cpp:157] Top shape: 50 128 30 30 (5760000)
I0604 20:56:52.368594   904 net.cpp:165] Memory required for data: 377357400
I0604 20:56:52.368607   904 layer_factory.hpp:77] Creating layer fire4/relu_expand1x1
I0604 20:56:52.368616   904 net.cpp:106] Creating Layer fire4/relu_expand1x1
I0604 20:56:52.368620   904 net.cpp:454] fire4/relu_expand1x1 <- fire4/expand1x1
I0604 20:56:52.368625   904 net.cpp:397] fire4/relu_expand1x1 -> fire4/expand1x1 (in-place)
I0604 20:56:52.369758   904 net.cpp:150] Setting up fire4/relu_expand1x1
I0604 20:56:52.369768   904 net.cpp:157] Top shape: 50 128 30 30 (5760000)
I0604 20:56:52.369771   904 net.cpp:165] Memory required for data: 400397400
I0604 20:56:52.369776   904 layer_factory.hpp:77] Creating layer fire4/expand3x3
I0604 20:56:52.369787   904 net.cpp:106] Creating Layer fire4/expand3x3
I0604 20:56:52.369791   904 net.cpp:454] fire4/expand3x3 <- fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split_1
I0604 20:56:52.369797   904 net.cpp:411] fire4/expand3x3 -> fire4/expand3x3
I0604 20:56:52.374249   904 net.cpp:150] Setting up fire4/expand3x3
I0604 20:56:52.374264   904 net.cpp:157] Top shape: 50 128 30 30 (5760000)
I0604 20:56:52.374267   904 net.cpp:165] Memory required for data: 423437400
I0604 20:56:52.374274   904 layer_factory.hpp:77] Creating layer fire4/relu_expand3x3
I0604 20:56:52.374284   904 net.cpp:106] Creating Layer fire4/relu_expand3x3
I0604 20:56:52.374287   904 net.cpp:454] fire4/relu_expand3x3 <- fire4/expand3x3
I0604 20:56:52.374292   904 net.cpp:397] fire4/relu_expand3x3 -> fire4/expand3x3 (in-place)
I0604 20:56:52.375653   904 net.cpp:150] Setting up fire4/relu_expand3x3
I0604 20:56:52.375665   904 net.cpp:157] Top shape: 50 128 30 30 (5760000)
I0604 20:56:52.375669   904 net.cpp:165] Memory required for data: 446477400
I0604 20:56:52.375674   904 layer_factory.hpp:77] Creating layer fire4/concat
I0604 20:56:52.375682   904 net.cpp:106] Creating Layer fire4/concat
I0604 20:56:52.375686   904 net.cpp:454] fire4/concat <- fire4/expand1x1
I0604 20:56:52.375692   904 net.cpp:454] fire4/concat <- fire4/expand3x3
I0604 20:56:52.375697   904 net.cpp:411] fire4/concat -> fire4/concat
I0604 20:56:52.375737   904 net.cpp:150] Setting up fire4/concat
I0604 20:56:52.375743   904 net.cpp:157] Top shape: 50 256 30 30 (11520000)
I0604 20:56:52.375747   904 net.cpp:165] Memory required for data: 492557400
I0604 20:56:52.375751   904 layer_factory.hpp:77] Creating layer pool4
I0604 20:56:52.375758   904 net.cpp:106] Creating Layer pool4
I0604 20:56:52.375761   904 net.cpp:454] pool4 <- fire4/concat
I0604 20:56:52.375766   904 net.cpp:411] pool4 -> pool4
I0604 20:56:52.375816   904 net.cpp:150] Setting up pool4
I0604 20:56:52.375823   904 net.cpp:157] Top shape: 50 256 15 15 (2880000)
I0604 20:56:52.375826   904 net.cpp:165] Memory required for data: 504077400
I0604 20:56:52.375829   904 layer_factory.hpp:77] Creating layer fire5/squeeze1x1
I0604 20:56:52.375838   904 net.cpp:106] Creating Layer fire5/squeeze1x1
I0604 20:56:52.375843   904 net.cpp:454] fire5/squeeze1x1 <- pool4
I0604 20:56:52.375847   904 net.cpp:411] fire5/squeeze1x1 -> fire5/squeeze1x1
I0604 20:56:52.379688   904 net.cpp:150] Setting up fire5/squeeze1x1
I0604 20:56:52.379716   904 net.cpp:157] Top shape: 50 32 15 15 (360000)
I0604 20:56:52.379722   904 net.cpp:165] Memory required for data: 505517400
I0604 20:56:52.379734   904 layer_factory.hpp:77] Creating layer fire5/relu_squeeze1x1
I0604 20:56:52.379750   904 net.cpp:106] Creating Layer fire5/relu_squeeze1x1
I0604 20:56:52.379755   904 net.cpp:454] fire5/relu_squeeze1x1 <- fire5/squeeze1x1
I0604 20:56:52.379765   904 net.cpp:397] fire5/relu_squeeze1x1 -> fire5/squeeze1x1 (in-place)
I0604 20:56:52.380664   904 net.cpp:150] Setting up fire5/relu_squeeze1x1
I0604 20:56:52.380686   904 net.cpp:157] Top shape: 50 32 15 15 (360000)
I0604 20:56:52.380692   904 net.cpp:165] Memory required for data: 506957400
I0604 20:56:52.380728   904 layer_factory.hpp:77] Creating layer fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I0604 20:56:52.380759   904 net.cpp:106] Creating Layer fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I0604 20:56:52.380766   904 net.cpp:454] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split <- fire5/squeeze1x1
I0604 20:56:52.380777   904 net.cpp:411] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split -> fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_0
I0604 20:56:52.380790   904 net.cpp:411] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split -> fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_1
I0604 20:56:52.380868   904 net.cpp:150] Setting up fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split
I0604 20:56:52.380879   904 net.cpp:157] Top shape: 50 32 15 15 (360000)
I0604 20:56:52.380887   904 net.cpp:157] Top shape: 50 32 15 15 (360000)
I0604 20:56:52.380892   904 net.cpp:165] Memory required for data: 509837400
I0604 20:56:52.380897   904 layer_factory.hpp:77] Creating layer fire5/expand1x1
I0604 20:56:52.380915   904 net.cpp:106] Creating Layer fire5/expand1x1
I0604 20:56:52.380924   904 net.cpp:454] fire5/expand1x1 <- fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_0
I0604 20:56:52.380934   904 net.cpp:411] fire5/expand1x1 -> fire5/expand1x1
I0604 20:56:52.386335   904 net.cpp:150] Setting up fire5/expand1x1
I0604 20:56:52.386384   904 net.cpp:157] Top shape: 50 128 15 15 (1440000)
I0604 20:56:52.386394   904 net.cpp:165] Memory required for data: 515597400
I0604 20:56:52.386406   904 layer_factory.hpp:77] Creating layer fire5/relu_expand1x1
I0604 20:56:52.386415   904 net.cpp:106] Creating Layer fire5/relu_expand1x1
I0604 20:56:52.386421   904 net.cpp:454] fire5/relu_expand1x1 <- fire5/expand1x1
I0604 20:56:52.386430   904 net.cpp:397] fire5/relu_expand1x1 -> fire5/expand1x1 (in-place)
I0604 20:56:52.386750   904 net.cpp:150] Setting up fire5/relu_expand1x1
I0604 20:56:52.386764   904 net.cpp:157] Top shape: 50 128 15 15 (1440000)
I0604 20:56:52.386770   904 net.cpp:165] Memory required for data: 521357400
I0604 20:56:52.386775   904 layer_factory.hpp:77] Creating layer fire5/expand3x3
I0604 20:56:52.386790   904 net.cpp:106] Creating Layer fire5/expand3x3
I0604 20:56:52.386796   904 net.cpp:454] fire5/expand3x3 <- fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split_1
I0604 20:56:52.386809   904 net.cpp:411] fire5/expand3x3 -> fire5/expand3x3
I0604 20:56:52.389878   904 net.cpp:150] Setting up fire5/expand3x3
I0604 20:56:52.389894   904 net.cpp:157] Top shape: 50 128 15 15 (1440000)
I0604 20:56:52.389901   904 net.cpp:165] Memory required for data: 527117400
I0604 20:56:52.389914   904 layer_factory.hpp:77] Creating layer fire5/relu_expand3x3
I0604 20:56:52.389924   904 net.cpp:106] Creating Layer fire5/relu_expand3x3
I0604 20:56:52.389930   904 net.cpp:454] fire5/relu_expand3x3 <- fire5/expand3x3
I0604 20:56:52.389940   904 net.cpp:397] fire5/relu_expand3x3 -> fire5/expand3x3 (in-place)
I0604 20:56:52.390910   904 net.cpp:150] Setting up fire5/relu_expand3x3
I0604 20:56:52.390923   904 net.cpp:157] Top shape: 50 128 15 15 (1440000)
I0604 20:56:52.390928   904 net.cpp:165] Memory required for data: 532877400
I0604 20:56:52.390934   904 layer_factory.hpp:77] Creating layer fire5/concat
I0604 20:56:52.390944   904 net.cpp:106] Creating Layer fire5/concat
I0604 20:56:52.390952   904 net.cpp:454] fire5/concat <- fire5/expand1x1
I0604 20:56:52.390960   904 net.cpp:454] fire5/concat <- fire5/expand3x3
I0604 20:56:52.390969   904 net.cpp:411] fire5/concat -> fire5/concat
I0604 20:56:52.391016   904 net.cpp:150] Setting up fire5/concat
I0604 20:56:52.391027   904 net.cpp:157] Top shape: 50 256 15 15 (2880000)
I0604 20:56:52.391032   904 net.cpp:165] Memory required for data: 544397400
I0604 20:56:52.391038   904 layer_factory.hpp:77] Creating layer fire6/squeeze1x1
I0604 20:56:52.391057   904 net.cpp:106] Creating Layer fire6/squeeze1x1
I0604 20:56:52.391065   904 net.cpp:454] fire6/squeeze1x1 <- fire5/concat
I0604 20:56:52.391075   904 net.cpp:411] fire6/squeeze1x1 -> fire6/squeeze1x1
I0604 20:56:52.394585   904 net.cpp:150] Setting up fire6/squeeze1x1
I0604 20:56:52.394603   904 net.cpp:157] Top shape: 50 48 15 15 (540000)
I0604 20:56:52.394609   904 net.cpp:165] Memory required for data: 546557400
I0604 20:56:52.394621   904 layer_factory.hpp:77] Creating layer fire6/relu_squeeze1x1
I0604 20:56:52.394634   904 net.cpp:106] Creating Layer fire6/relu_squeeze1x1
I0604 20:56:52.394640   904 net.cpp:454] fire6/relu_squeeze1x1 <- fire6/squeeze1x1
I0604 20:56:52.394650   904 net.cpp:397] fire6/relu_squeeze1x1 -> fire6/squeeze1x1 (in-place)
I0604 20:56:52.395604   904 net.cpp:150] Setting up fire6/relu_squeeze1x1
I0604 20:56:52.395620   904 net.cpp:157] Top shape: 50 48 15 15 (540000)
I0604 20:56:52.395627   904 net.cpp:165] Memory required for data: 548717400
I0604 20:56:52.395632   904 layer_factory.hpp:77] Creating layer fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I0604 20:56:52.395644   904 net.cpp:106] Creating Layer fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I0604 20:56:52.395651   904 net.cpp:454] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split <- fire6/squeeze1x1
I0604 20:56:52.395663   904 net.cpp:411] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split -> fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_0
I0604 20:56:52.395681   904 net.cpp:411] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split -> fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_1
I0604 20:56:52.395757   904 net.cpp:150] Setting up fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split
I0604 20:56:52.395771   904 net.cpp:157] Top shape: 50 48 15 15 (540000)
I0604 20:56:52.395778   904 net.cpp:157] Top shape: 50 48 15 15 (540000)
I0604 20:56:52.395783   904 net.cpp:165] Memory required for data: 553037400
I0604 20:56:52.395789   904 layer_factory.hpp:77] Creating layer fire6/expand1x1
I0604 20:56:52.395804   904 net.cpp:106] Creating Layer fire6/expand1x1
I0604 20:56:52.395814   904 net.cpp:454] fire6/expand1x1 <- fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_0
I0604 20:56:52.395828   904 net.cpp:411] fire6/expand1x1 -> fire6/expand1x1
I0604 20:56:52.399265   904 net.cpp:150] Setting up fire6/expand1x1
I0604 20:56:52.399281   904 net.cpp:157] Top shape: 50 192 15 15 (2160000)
I0604 20:56:52.399288   904 net.cpp:165] Memory required for data: 561677400
I0604 20:56:52.399301   904 layer_factory.hpp:77] Creating layer fire6/relu_expand1x1
I0604 20:56:52.399313   904 net.cpp:106] Creating Layer fire6/relu_expand1x1
I0604 20:56:52.399320   904 net.cpp:454] fire6/relu_expand1x1 <- fire6/expand1x1
I0604 20:56:52.399329   904 net.cpp:397] fire6/relu_expand1x1 -> fire6/expand1x1 (in-place)
I0604 20:56:52.400290   904 net.cpp:150] Setting up fire6/relu_expand1x1
I0604 20:56:52.400302   904 net.cpp:157] Top shape: 50 192 15 15 (2160000)
I0604 20:56:52.400308   904 net.cpp:165] Memory required for data: 570317400
I0604 20:56:52.400315   904 layer_factory.hpp:77] Creating layer fire6/expand3x3
I0604 20:56:52.400331   904 net.cpp:106] Creating Layer fire6/expand3x3
I0604 20:56:52.400336   904 net.cpp:454] fire6/expand3x3 <- fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split_1
I0604 20:56:52.400347   904 net.cpp:411] fire6/expand3x3 -> fire6/expand3x3
I0604 20:56:52.405007   904 net.cpp:150] Setting up fire6/expand3x3
I0604 20:56:52.405025   904 net.cpp:157] Top shape: 50 192 15 15 (2160000)
I0604 20:56:52.405030   904 net.cpp:165] Memory required for data: 578957400
I0604 20:56:52.405042   904 layer_factory.hpp:77] Creating layer fire6/relu_expand3x3
I0604 20:56:52.405055   904 net.cpp:106] Creating Layer fire6/relu_expand3x3
I0604 20:56:52.405062   904 net.cpp:454] fire6/relu_expand3x3 <- fire6/expand3x3
I0604 20:56:52.405071   904 net.cpp:397] fire6/relu_expand3x3 -> fire6/expand3x3 (in-place)
I0604 20:56:52.406040   904 net.cpp:150] Setting up fire6/relu_expand3x3
I0604 20:56:52.406054   904 net.cpp:157] Top shape: 50 192 15 15 (2160000)
I0604 20:56:52.406059   904 net.cpp:165] Memory required for data: 587597400
I0604 20:56:52.406065   904 layer_factory.hpp:77] Creating layer fire6/concat
I0604 20:56:52.406075   904 net.cpp:106] Creating Layer fire6/concat
I0604 20:56:52.406100   904 net.cpp:454] fire6/concat <- fire6/expand1x1
I0604 20:56:52.406108   904 net.cpp:454] fire6/concat <- fire6/expand3x3
I0604 20:56:52.406121   904 net.cpp:411] fire6/concat -> fire6/concat
I0604 20:56:52.406172   904 net.cpp:150] Setting up fire6/concat
I0604 20:56:52.406183   904 net.cpp:157] Top shape: 50 384 15 15 (4320000)
I0604 20:56:52.406188   904 net.cpp:165] Memory required for data: 604877400
I0604 20:56:52.406193   904 layer_factory.hpp:77] Creating layer fire7/squeeze1x1
I0604 20:56:52.406206   904 net.cpp:106] Creating Layer fire7/squeeze1x1
I0604 20:56:52.406213   904 net.cpp:454] fire7/squeeze1x1 <- fire6/concat
I0604 20:56:52.406225   904 net.cpp:411] fire7/squeeze1x1 -> fire7/squeeze1x1
I0604 20:56:52.409694   904 net.cpp:150] Setting up fire7/squeeze1x1
I0604 20:56:52.409710   904 net.cpp:157] Top shape: 50 48 15 15 (540000)
I0604 20:56:52.409716   904 net.cpp:165] Memory required for data: 607037400
I0604 20:56:52.409740   904 layer_factory.hpp:77] Creating layer fire7/relu_squeeze1x1
I0604 20:56:52.409754   904 net.cpp:106] Creating Layer fire7/relu_squeeze1x1
I0604 20:56:52.409760   904 net.cpp:454] fire7/relu_squeeze1x1 <- fire7/squeeze1x1
I0604 20:56:52.409772   904 net.cpp:397] fire7/relu_squeeze1x1 -> fire7/squeeze1x1 (in-place)
I0604 20:56:52.410727   904 net.cpp:150] Setting up fire7/relu_squeeze1x1
I0604 20:56:52.410742   904 net.cpp:157] Top shape: 50 48 15 15 (540000)
I0604 20:56:52.410748   904 net.cpp:165] Memory required for data: 609197400
I0604 20:56:52.410754   904 layer_factory.hpp:77] Creating layer fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I0604 20:56:52.410764   904 net.cpp:106] Creating Layer fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I0604 20:56:52.410770   904 net.cpp:454] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split <- fire7/squeeze1x1
I0604 20:56:52.410783   904 net.cpp:411] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split -> fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_0
I0604 20:56:52.410795   904 net.cpp:411] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split -> fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_1
I0604 20:56:52.410868   904 net.cpp:150] Setting up fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split
I0604 20:56:52.410881   904 net.cpp:157] Top shape: 50 48 15 15 (540000)
I0604 20:56:52.410888   904 net.cpp:157] Top shape: 50 48 15 15 (540000)
I0604 20:56:52.410894   904 net.cpp:165] Memory required for data: 613517400
I0604 20:56:52.410899   904 layer_factory.hpp:77] Creating layer fire7/expand1x1
I0604 20:56:52.410912   904 net.cpp:106] Creating Layer fire7/expand1x1
I0604 20:56:52.410924   904 net.cpp:454] fire7/expand1x1 <- fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_0
I0604 20:56:52.410938   904 net.cpp:411] fire7/expand1x1 -> fire7/expand1x1
I0604 20:56:52.414384   904 net.cpp:150] Setting up fire7/expand1x1
I0604 20:56:52.414402   904 net.cpp:157] Top shape: 50 192 15 15 (2160000)
I0604 20:56:52.414407   904 net.cpp:165] Memory required for data: 622157400
I0604 20:56:52.414425   904 layer_factory.hpp:77] Creating layer fire7/relu_expand1x1
I0604 20:56:52.414435   904 net.cpp:106] Creating Layer fire7/relu_expand1x1
I0604 20:56:52.414443   904 net.cpp:454] fire7/relu_expand1x1 <- fire7/expand1x1
I0604 20:56:52.414454   904 net.cpp:397] fire7/relu_expand1x1 -> fire7/expand1x1 (in-place)
I0604 20:56:52.415535   904 net.cpp:150] Setting up fire7/relu_expand1x1
I0604 20:56:52.415550   904 net.cpp:157] Top shape: 50 192 15 15 (2160000)
I0604 20:56:52.415556   904 net.cpp:165] Memory required for data: 630797400
I0604 20:56:52.415562   904 layer_factory.hpp:77] Creating layer fire7/expand3x3
I0604 20:56:52.415578   904 net.cpp:106] Creating Layer fire7/expand3x3
I0604 20:56:52.415585   904 net.cpp:454] fire7/expand3x3 <- fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split_1
I0604 20:56:52.415603   904 net.cpp:411] fire7/expand3x3 -> fire7/expand3x3
I0604 20:56:52.419078   904 net.cpp:150] Setting up fire7/expand3x3
I0604 20:56:52.419095   904 net.cpp:157] Top shape: 50 192 15 15 (2160000)
I0604 20:56:52.419101   904 net.cpp:165] Memory required for data: 639437400
I0604 20:56:52.419134   904 layer_factory.hpp:77] Creating layer fire7/relu_expand3x3
I0604 20:56:52.419152   904 net.cpp:106] Creating Layer fire7/relu_expand3x3
I0604 20:56:52.419162   904 net.cpp:454] fire7/relu_expand3x3 <- fire7/expand3x3
I0604 20:56:52.419174   904 net.cpp:397] fire7/relu_expand3x3 -> fire7/expand3x3 (in-place)
I0604 20:56:52.420112   904 net.cpp:150] Setting up fire7/relu_expand3x3
I0604 20:56:52.420125   904 net.cpp:157] Top shape: 50 192 15 15 (2160000)
I0604 20:56:52.420131   904 net.cpp:165] Memory required for data: 648077400
I0604 20:56:52.420136   904 layer_factory.hpp:77] Creating layer fire7/concat
I0604 20:56:52.420148   904 net.cpp:106] Creating Layer fire7/concat
I0604 20:56:52.420155   904 net.cpp:454] fire7/concat <- fire7/expand1x1
I0604 20:56:52.420162   904 net.cpp:454] fire7/concat <- fire7/expand3x3
I0604 20:56:52.420171   904 net.cpp:411] fire7/concat -> fire7/concat
I0604 20:56:52.420220   904 net.cpp:150] Setting up fire7/concat
I0604 20:56:52.420231   904 net.cpp:157] Top shape: 50 384 15 15 (4320000)
I0604 20:56:52.420236   904 net.cpp:165] Memory required for data: 665357400
I0604 20:56:52.420243   904 layer_factory.hpp:77] Creating layer fire8/squeeze1x1
I0604 20:56:52.420258   904 net.cpp:106] Creating Layer fire8/squeeze1x1
I0604 20:56:52.420269   904 net.cpp:454] fire8/squeeze1x1 <- fire7/concat
I0604 20:56:52.420280   904 net.cpp:411] fire8/squeeze1x1 -> fire8/squeeze1x1
I0604 20:56:52.423768   904 net.cpp:150] Setting up fire8/squeeze1x1
I0604 20:56:52.423785   904 net.cpp:157] Top shape: 50 64 15 15 (720000)
I0604 20:56:52.423791   904 net.cpp:165] Memory required for data: 668237400
I0604 20:56:52.423804   904 layer_factory.hpp:77] Creating layer fire8/relu_squeeze1x1
I0604 20:56:52.423816   904 net.cpp:106] Creating Layer fire8/relu_squeeze1x1
I0604 20:56:52.423823   904 net.cpp:454] fire8/relu_squeeze1x1 <- fire8/squeeze1x1
I0604 20:56:52.423832   904 net.cpp:397] fire8/relu_squeeze1x1 -> fire8/squeeze1x1 (in-place)
I0604 20:56:52.424799   904 net.cpp:150] Setting up fire8/relu_squeeze1x1
I0604 20:56:52.424815   904 net.cpp:157] Top shape: 50 64 15 15 (720000)
I0604 20:56:52.424821   904 net.cpp:165] Memory required for data: 671117400
I0604 20:56:52.424828   904 layer_factory.hpp:77] Creating layer fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I0604 20:56:52.424839   904 net.cpp:106] Creating Layer fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I0604 20:56:52.424846   904 net.cpp:454] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split <- fire8/squeeze1x1
I0604 20:56:52.424855   904 net.cpp:411] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split -> fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_0
I0604 20:56:52.424868   904 net.cpp:411] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split -> fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_1
I0604 20:56:52.424945   904 net.cpp:150] Setting up fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split
I0604 20:56:52.424957   904 net.cpp:157] Top shape: 50 64 15 15 (720000)
I0604 20:56:52.424964   904 net.cpp:157] Top shape: 50 64 15 15 (720000)
I0604 20:56:52.424969   904 net.cpp:165] Memory required for data: 676877400
I0604 20:56:52.424975   904 layer_factory.hpp:77] Creating layer fire8/expand1x1
I0604 20:56:52.424990   904 net.cpp:106] Creating Layer fire8/expand1x1
I0604 20:56:52.425004   904 net.cpp:454] fire8/expand1x1 <- fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_0
I0604 20:56:52.425014   904 net.cpp:411] fire8/expand1x1 -> fire8/expand1x1
I0604 20:56:52.430595   904 net.cpp:150] Setting up fire8/expand1x1
I0604 20:56:52.430611   904 net.cpp:157] Top shape: 50 256 15 15 (2880000)
I0604 20:56:52.430618   904 net.cpp:165] Memory required for data: 688397400
I0604 20:56:52.430629   904 layer_factory.hpp:77] Creating layer fire8/relu_expand1x1
I0604 20:56:52.430641   904 net.cpp:106] Creating Layer fire8/relu_expand1x1
I0604 20:56:52.430649   904 net.cpp:454] fire8/relu_expand1x1 <- fire8/expand1x1
I0604 20:56:52.430658   904 net.cpp:397] fire8/relu_expand1x1 -> fire8/expand1x1 (in-place)
I0604 20:56:52.431596   904 net.cpp:150] Setting up fire8/relu_expand1x1
I0604 20:56:52.431609   904 net.cpp:157] Top shape: 50 256 15 15 (2880000)
I0604 20:56:52.431615   904 net.cpp:165] Memory required for data: 699917400
I0604 20:56:52.431627   904 layer_factory.hpp:77] Creating layer fire8/expand3x3
I0604 20:56:52.431646   904 net.cpp:106] Creating Layer fire8/expand3x3
I0604 20:56:52.431653   904 net.cpp:454] fire8/expand3x3 <- fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split_1
I0604 20:56:52.431664   904 net.cpp:411] fire8/expand3x3 -> fire8/expand3x3
I0604 20:56:52.437340   904 net.cpp:150] Setting up fire8/expand3x3
I0604 20:56:52.437360   904 net.cpp:157] Top shape: 50 256 15 15 (2880000)
I0604 20:56:52.437366   904 net.cpp:165] Memory required for data: 711437400
I0604 20:56:52.437378   904 layer_factory.hpp:77] Creating layer fire8/relu_expand3x3
I0604 20:56:52.437392   904 net.cpp:106] Creating Layer fire8/relu_expand3x3
I0604 20:56:52.437399   904 net.cpp:454] fire8/relu_expand3x3 <- fire8/expand3x3
I0604 20:56:52.437409   904 net.cpp:397] fire8/relu_expand3x3 -> fire8/expand3x3 (in-place)
I0604 20:56:52.438364   904 net.cpp:150] Setting up fire8/relu_expand3x3
I0604 20:56:52.438380   904 net.cpp:157] Top shape: 50 256 15 15 (2880000)
I0604 20:56:52.438385   904 net.cpp:165] Memory required for data: 722957400
I0604 20:56:52.438391   904 layer_factory.hpp:77] Creating layer fire8/concat
I0604 20:56:52.438403   904 net.cpp:106] Creating Layer fire8/concat
I0604 20:56:52.438410   904 net.cpp:454] fire8/concat <- fire8/expand1x1
I0604 20:56:52.438417   904 net.cpp:454] fire8/concat <- fire8/expand3x3
I0604 20:56:52.438426   904 net.cpp:411] fire8/concat -> fire8/concat
I0604 20:56:52.438478   904 net.cpp:150] Setting up fire8/concat
I0604 20:56:52.438489   904 net.cpp:157] Top shape: 50 512 15 15 (5760000)
I0604 20:56:52.438494   904 net.cpp:165] Memory required for data: 745997400
I0604 20:56:52.438500   904 layer_factory.hpp:77] Creating layer pool8
I0604 20:56:52.438511   904 net.cpp:106] Creating Layer pool8
I0604 20:56:52.438518   904 net.cpp:454] pool8 <- fire8/concat
I0604 20:56:52.438529   904 net.cpp:411] pool8 -> pool8
I0604 20:56:52.438597   904 net.cpp:150] Setting up pool8
I0604 20:56:52.438609   904 net.cpp:157] Top shape: 50 512 7 7 (1254400)
I0604 20:56:52.438614   904 net.cpp:165] Memory required for data: 751015000
I0604 20:56:52.438621   904 layer_factory.hpp:77] Creating layer fire9/squeeze1x1
I0604 20:56:52.438635   904 net.cpp:106] Creating Layer fire9/squeeze1x1
I0604 20:56:52.438645   904 net.cpp:454] fire9/squeeze1x1 <- pool8
I0604 20:56:52.438655   904 net.cpp:411] fire9/squeeze1x1 -> fire9/squeeze1x1
I0604 20:56:52.442029   904 net.cpp:150] Setting up fire9/squeeze1x1
I0604 20:56:52.442046   904 net.cpp:157] Top shape: 50 64 7 7 (156800)
I0604 20:56:52.442052   904 net.cpp:165] Memory required for data: 751642200
I0604 20:56:52.442065   904 layer_factory.hpp:77] Creating layer fire9/relu_squeeze1x1
I0604 20:56:52.442092   904 net.cpp:106] Creating Layer fire9/relu_squeeze1x1
I0604 20:56:52.442101   904 net.cpp:454] fire9/relu_squeeze1x1 <- fire9/squeeze1x1
I0604 20:56:52.442114   904 net.cpp:397] fire9/relu_squeeze1x1 -> fire9/squeeze1x1 (in-place)
I0604 20:56:52.443056   904 net.cpp:150] Setting up fire9/relu_squeeze1x1
I0604 20:56:52.443073   904 net.cpp:157] Top shape: 50 64 7 7 (156800)
I0604 20:56:52.443078   904 net.cpp:165] Memory required for data: 752269400
I0604 20:56:52.443085   904 layer_factory.hpp:77] Creating layer fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I0604 20:56:52.443094   904 net.cpp:106] Creating Layer fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I0604 20:56:52.443101   904 net.cpp:454] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split <- fire9/squeeze1x1
I0604 20:56:52.443114   904 net.cpp:411] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split -> fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_0
I0604 20:56:52.443125   904 net.cpp:411] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split -> fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_1
I0604 20:56:52.443202   904 net.cpp:150] Setting up fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split
I0604 20:56:52.443227   904 net.cpp:157] Top shape: 50 64 7 7 (156800)
I0604 20:56:52.443234   904 net.cpp:157] Top shape: 50 64 7 7 (156800)
I0604 20:56:52.443240   904 net.cpp:165] Memory required for data: 753523800
I0604 20:56:52.443245   904 layer_factory.hpp:77] Creating layer fire9/expand1x1
I0604 20:56:52.443265   904 net.cpp:106] Creating Layer fire9/expand1x1
I0604 20:56:52.443272   904 net.cpp:454] fire9/expand1x1 <- fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_0
I0604 20:56:52.443284   904 net.cpp:411] fire9/expand1x1 -> fire9/expand1x1
I0604 20:56:52.446723   904 net.cpp:150] Setting up fire9/expand1x1
I0604 20:56:52.446746   904 net.cpp:157] Top shape: 50 256 7 7 (627200)
I0604 20:56:52.446758   904 net.cpp:165] Memory required for data: 756032600
I0604 20:56:52.446771   904 layer_factory.hpp:77] Creating layer fire9/relu_expand1x1
I0604 20:56:52.446782   904 net.cpp:106] Creating Layer fire9/relu_expand1x1
I0604 20:56:52.446795   904 net.cpp:454] fire9/relu_expand1x1 <- fire9/expand1x1
I0604 20:56:52.446808   904 net.cpp:397] fire9/relu_expand1x1 -> fire9/expand1x1 (in-place)
I0604 20:56:52.447741   904 net.cpp:150] Setting up fire9/relu_expand1x1
I0604 20:56:52.447754   904 net.cpp:157] Top shape: 50 256 7 7 (627200)
I0604 20:56:52.447759   904 net.cpp:165] Memory required for data: 758541400
I0604 20:56:52.447765   904 layer_factory.hpp:77] Creating layer fire9/expand3x3
I0604 20:56:52.447784   904 net.cpp:106] Creating Layer fire9/expand3x3
I0604 20:56:52.447800   904 net.cpp:454] fire9/expand3x3 <- fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split_1
I0604 20:56:52.447811   904 net.cpp:411] fire9/expand3x3 -> fire9/expand3x3
I0604 20:56:52.451444   904 net.cpp:150] Setting up fire9/expand3x3
I0604 20:56:52.451472   904 net.cpp:157] Top shape: 50 256 7 7 (627200)
I0604 20:56:52.451478   904 net.cpp:165] Memory required for data: 761050200
I0604 20:56:52.451493   904 layer_factory.hpp:77] Creating layer fire9/relu_expand3x3
I0604 20:56:52.451504   904 net.cpp:106] Creating Layer fire9/relu_expand3x3
I0604 20:56:52.451514   904 net.cpp:454] fire9/relu_expand3x3 <- fire9/expand3x3
I0604 20:56:52.451524   904 net.cpp:397] fire9/relu_expand3x3 -> fire9/expand3x3 (in-place)
I0604 20:56:52.452556   904 net.cpp:150] Setting up fire9/relu_expand3x3
I0604 20:56:52.452570   904 net.cpp:157] Top shape: 50 256 7 7 (627200)
I0604 20:56:52.452576   904 net.cpp:165] Memory required for data: 763559000
I0604 20:56:52.452582   904 layer_factory.hpp:77] Creating layer fire9/concat
I0604 20:56:52.452591   904 net.cpp:106] Creating Layer fire9/concat
I0604 20:56:52.452599   904 net.cpp:454] fire9/concat <- fire9/expand1x1
I0604 20:56:52.452606   904 net.cpp:454] fire9/concat <- fire9/expand3x3
I0604 20:56:52.452618   904 net.cpp:411] fire9/concat -> fire9/concat
I0604 20:56:52.452673   904 net.cpp:150] Setting up fire9/concat
I0604 20:56:52.452684   904 net.cpp:157] Top shape: 50 512 7 7 (1254400)
I0604 20:56:52.452689   904 net.cpp:165] Memory required for data: 768576600
I0604 20:56:52.452695   904 layer_factory.hpp:77] Creating layer drop9
I0604 20:56:52.452708   904 net.cpp:106] Creating Layer drop9
I0604 20:56:52.452715   904 net.cpp:454] drop9 <- fire9/concat
I0604 20:56:52.452724   904 net.cpp:397] drop9 -> fire9/concat (in-place)
I0604 20:56:52.452771   904 net.cpp:150] Setting up drop9
I0604 20:56:52.452781   904 net.cpp:157] Top shape: 50 512 7 7 (1254400)
I0604 20:56:52.452786   904 net.cpp:165] Memory required for data: 773594200
I0604 20:56:52.452791   904 layer_factory.hpp:77] Creating layer conv10
I0604 20:56:52.452810   904 net.cpp:106] Creating Layer conv10
I0604 20:56:52.452821   904 net.cpp:454] conv10 <- fire9/concat
I0604 20:56:52.452834   904 net.cpp:411] conv10 -> conv10
I0604 20:56:52.472090   904 net.cpp:150] Setting up conv10
I0604 20:56:52.472110   904 net.cpp:157] Top shape: 50 1000 9 9 (4050000)
I0604 20:56:52.472116   904 net.cpp:165] Memory required for data: 789794200
I0604 20:56:52.472129   904 layer_factory.hpp:77] Creating layer relu_conv10
I0604 20:56:52.472172   904 net.cpp:106] Creating Layer relu_conv10
I0604 20:56:52.472180   904 net.cpp:454] relu_conv10 <- conv10
I0604 20:56:52.472190   904 net.cpp:397] relu_conv10 -> conv10 (in-place)
I0604 20:56:52.473255   904 net.cpp:150] Setting up relu_conv10
I0604 20:56:52.473270   904 net.cpp:157] Top shape: 50 1000 9 9 (4050000)
I0604 20:56:52.473276   904 net.cpp:165] Memory required for data: 805994200
I0604 20:56:52.473284   904 layer_factory.hpp:77] Creating layer pool10
I0604 20:56:52.473297   904 net.cpp:106] Creating Layer pool10
I0604 20:56:52.473304   904 net.cpp:454] pool10 <- conv10
I0604 20:56:52.473315   904 net.cpp:411] pool10 -> pool10
I0604 20:56:52.474318   904 net.cpp:150] Setting up pool10
I0604 20:56:52.474331   904 net.cpp:157] Top shape: 50 1000 1 1 (50000)
I0604 20:56:52.474337   904 net.cpp:165] Memory required for data: 806194200
I0604 20:56:52.474344   904 layer_factory.hpp:77] Creating layer pool10_pool10_0_split
I0604 20:56:52.474354   904 net.cpp:106] Creating Layer pool10_pool10_0_split
I0604 20:56:52.474359   904 net.cpp:454] pool10_pool10_0_split <- pool10
I0604 20:56:52.474371   904 net.cpp:411] pool10_pool10_0_split -> pool10_pool10_0_split_0
I0604 20:56:52.474383   904 net.cpp:411] pool10_pool10_0_split -> pool10_pool10_0_split_1
I0604 20:56:52.474452   904 net.cpp:150] Setting up pool10_pool10_0_split
I0604 20:56:52.474464   904 net.cpp:157] Top shape: 50 1000 1 1 (50000)
I0604 20:56:52.474472   904 net.cpp:157] Top shape: 50 1000 1 1 (50000)
I0604 20:56:52.474478   904 net.cpp:165] Memory required for data: 806594200
I0604 20:56:52.474483   904 layer_factory.hpp:77] Creating layer accuracy
I0604 20:56:52.474493   904 net.cpp:106] Creating Layer accuracy
I0604 20:56:52.474499   904 net.cpp:454] accuracy <- pool10_pool10_0_split_0
I0604 20:56:52.474508   904 net.cpp:454] accuracy <- label_data_1_split_0
I0604 20:56:52.474516   904 net.cpp:411] accuracy -> accuracy
I0604 20:56:52.474529   904 net.cpp:150] Setting up accuracy
I0604 20:56:52.474550   904 net.cpp:157] Top shape: (1)
I0604 20:56:52.474556   904 net.cpp:165] Memory required for data: 806594204
I0604 20:56:52.474561   904 layer_factory.hpp:77] Creating layer accuracy_top5
I0604 20:56:52.474575   904 net.cpp:106] Creating Layer accuracy_top5
I0604 20:56:52.474587   904 net.cpp:454] accuracy_top5 <- pool10_pool10_0_split_1
I0604 20:56:52.474596   904 net.cpp:454] accuracy_top5 <- label_data_1_split_1
I0604 20:56:52.474606   904 net.cpp:411] accuracy_top5 -> accuracy_top5
I0604 20:56:52.474619   904 net.cpp:150] Setting up accuracy_top5
I0604 20:56:52.474628   904 net.cpp:157] Top shape: (1)
I0604 20:56:52.474633   904 net.cpp:165] Memory required for data: 806594208
I0604 20:56:52.474642   904 net.cpp:228] accuracy_top5 does not need backward computation.
I0604 20:56:52.474647   904 net.cpp:228] accuracy does not need backward computation.
I0604 20:56:52.474653   904 net.cpp:228] pool10_pool10_0_split does not need backward computation.
I0604 20:56:52.474659   904 net.cpp:228] pool10 does not need backward computation.
I0604 20:56:52.474665   904 net.cpp:228] relu_conv10 does not need backward computation.
I0604 20:56:52.474670   904 net.cpp:228] conv10 does not need backward computation.
I0604 20:56:52.474675   904 net.cpp:228] drop9 does not need backward computation.
I0604 20:56:52.474680   904 net.cpp:228] fire9/concat does not need backward computation.
I0604 20:56:52.474687   904 net.cpp:228] fire9/relu_expand3x3 does not need backward computation.
I0604 20:56:52.474692   904 net.cpp:228] fire9/expand3x3 does not need backward computation.
I0604 20:56:52.474699   904 net.cpp:228] fire9/relu_expand1x1 does not need backward computation.
I0604 20:56:52.474704   904 net.cpp:228] fire9/expand1x1 does not need backward computation.
I0604 20:56:52.474709   904 net.cpp:228] fire9/squeeze1x1_fire9/relu_squeeze1x1_0_split does not need backward computation.
I0604 20:56:52.474716   904 net.cpp:228] fire9/relu_squeeze1x1 does not need backward computation.
I0604 20:56:52.474721   904 net.cpp:228] fire9/squeeze1x1 does not need backward computation.
I0604 20:56:52.474741   904 net.cpp:228] pool8 does not need backward computation.
I0604 20:56:52.474748   904 net.cpp:228] fire8/concat does not need backward computation.
I0604 20:56:52.474755   904 net.cpp:228] fire8/relu_expand3x3 does not need backward computation.
I0604 20:56:52.474759   904 net.cpp:228] fire8/expand3x3 does not need backward computation.
I0604 20:56:52.474766   904 net.cpp:228] fire8/relu_expand1x1 does not need backward computation.
I0604 20:56:52.474771   904 net.cpp:228] fire8/expand1x1 does not need backward computation.
I0604 20:56:52.474776   904 net.cpp:228] fire8/squeeze1x1_fire8/relu_squeeze1x1_0_split does not need backward computation.
I0604 20:56:52.474782   904 net.cpp:228] fire8/relu_squeeze1x1 does not need backward computation.
I0604 20:56:52.474791   904 net.cpp:228] fire8/squeeze1x1 does not need backward computation.
I0604 20:56:52.474797   904 net.cpp:228] fire7/concat does not need backward computation.
I0604 20:56:52.474804   904 net.cpp:228] fire7/relu_expand3x3 does not need backward computation.
I0604 20:56:52.474809   904 net.cpp:228] fire7/expand3x3 does not need backward computation.
I0604 20:56:52.474815   904 net.cpp:228] fire7/relu_expand1x1 does not need backward computation.
I0604 20:56:52.474820   904 net.cpp:228] fire7/expand1x1 does not need backward computation.
I0604 20:56:52.474827   904 net.cpp:228] fire7/squeeze1x1_fire7/relu_squeeze1x1_0_split does not need backward computation.
I0604 20:56:52.474831   904 net.cpp:228] fire7/relu_squeeze1x1 does not need backward computation.
I0604 20:56:52.474838   904 net.cpp:228] fire7/squeeze1x1 does not need backward computation.
I0604 20:56:52.474843   904 net.cpp:228] fire6/concat does not need backward computation.
I0604 20:56:52.474848   904 net.cpp:228] fire6/relu_expand3x3 does not need backward computation.
I0604 20:56:52.474853   904 net.cpp:228] fire6/expand3x3 does not need backward computation.
I0604 20:56:52.474859   904 net.cpp:228] fire6/relu_expand1x1 does not need backward computation.
I0604 20:56:52.474866   904 net.cpp:228] fire6/expand1x1 does not need backward computation.
I0604 20:56:52.474872   904 net.cpp:228] fire6/squeeze1x1_fire6/relu_squeeze1x1_0_split does not need backward computation.
I0604 20:56:52.474879   904 net.cpp:228] fire6/relu_squeeze1x1 does not need backward computation.
I0604 20:56:52.474884   904 net.cpp:228] fire6/squeeze1x1 does not need backward computation.
I0604 20:56:52.474889   904 net.cpp:228] fire5/concat does not need backward computation.
I0604 20:56:52.474895   904 net.cpp:228] fire5/relu_expand3x3 does not need backward computation.
I0604 20:56:52.474900   904 net.cpp:228] fire5/expand3x3 does not need backward computation.
I0604 20:56:52.474906   904 net.cpp:228] fire5/relu_expand1x1 does not need backward computation.
I0604 20:56:52.474911   904 net.cpp:228] fire5/expand1x1 does not need backward computation.
I0604 20:56:52.474917   904 net.cpp:228] fire5/squeeze1x1_fire5/relu_squeeze1x1_0_split does not need backward computation.
I0604 20:56:52.474923   904 net.cpp:228] fire5/relu_squeeze1x1 does not need backward computation.
I0604 20:56:52.474928   904 net.cpp:228] fire5/squeeze1x1 does not need backward computation.
I0604 20:56:52.474934   904 net.cpp:228] pool4 does not need backward computation.
I0604 20:56:52.474939   904 net.cpp:228] fire4/concat does not need backward computation.
I0604 20:56:52.474946   904 net.cpp:228] fire4/relu_expand3x3 does not need backward computation.
I0604 20:56:52.474951   904 net.cpp:228] fire4/expand3x3 does not need backward computation.
I0604 20:56:52.474956   904 net.cpp:228] fire4/relu_expand1x1 does not need backward computation.
I0604 20:56:52.474961   904 net.cpp:228] fire4/expand1x1 does not need backward computation.
I0604 20:56:52.474967   904 net.cpp:228] fire4/squeeze1x1_fire4/relu_squeeze1x1_0_split does not need backward computation.
I0604 20:56:52.474972   904 net.cpp:228] fire4/relu_squeeze1x1 does not need backward computation.
I0604 20:56:52.474978   904 net.cpp:228] fire4/squeeze1x1 does not need backward computation.
I0604 20:56:52.474992   904 net.cpp:228] fire3/concat does not need backward computation.
I0604 20:56:52.474999   904 net.cpp:228] fire3/relu_expand3x3 does not need backward computation.
I0604 20:56:52.475004   904 net.cpp:228] fire3/expand3x3 does not need backward computation.
I0604 20:56:52.475009   904 net.cpp:228] fire3/relu_expand1x1 does not need backward computation.
I0604 20:56:52.475015   904 net.cpp:228] fire3/expand1x1 does not need backward computation.
I0604 20:56:52.475020   904 net.cpp:228] fire3/squeeze1x1_fire3/relu_squeeze1x1_0_split does not need backward computation.
I0604 20:56:52.475026   904 net.cpp:228] fire3/relu_squeeze1x1 does not need backward computation.
I0604 20:56:52.475033   904 net.cpp:228] fire3/squeeze1x1 does not need backward computation.
I0604 20:56:52.475038   904 net.cpp:228] fire2/concat does not need backward computation.
I0604 20:56:52.475044   904 net.cpp:228] fire2/relu_expand3x3 does not need backward computation.
I0604 20:56:52.475049   904 net.cpp:228] fire2/expand3x3 does not need backward computation.
I0604 20:56:52.475054   904 net.cpp:228] fire2/relu_expand1x1 does not need backward computation.
I0604 20:56:52.475059   904 net.cpp:228] fire2/expand1x1 does not need backward computation.
I0604 20:56:52.475065   904 net.cpp:228] fire2/squeeze1x1_fire2/relu_squeeze1x1_0_split does not need backward computation.
I0604 20:56:52.475070   904 net.cpp:228] fire2/relu_squeeze1x1 does not need backward computation.
I0604 20:56:52.475075   904 net.cpp:228] fire2/squeeze1x1 does not need backward computation.
I0604 20:56:52.475081   904 net.cpp:228] pool1 does not need backward computation.
I0604 20:56:52.475090   904 net.cpp:228] relu_conv1 does not need backward computation.
I0604 20:56:52.475095   904 net.cpp:228] conv1 does not need backward computation.
I0604 20:56:52.475101   904 net.cpp:228] label_data_1_split does not need backward computation.
I0604 20:56:52.475107   904 net.cpp:228] data does not need backward computation.
I0604 20:56:52.475112   904 net.cpp:270] This network produces output accuracy
I0604 20:56:52.475118   904 net.cpp:270] This network produces output accuracy_top5
I0604 20:56:52.475178   904 net.cpp:283] Network initialization done.
I0604 20:56:52.475461   904 solver.cpp:60] Solver scaffolding done.
I0604 20:56:52.478083   904 caffe.cpp:129] Finetuning from SqueezeNet128.prototxt.caffemodel
I0604 20:56:52.486935   904 net.cpp:816] Ignoring source layer loss
I0604 20:56:52.487078   904 caffe.cpp:213] Starting Optimization
I0604 20:56:52.487088   904 solver.cpp:280] Solving 
I0604 20:56:52.487094   904 solver.cpp:281] Learning Rate Policy: poly
I0604 20:56:53.277104   904 solver.cpp:229] Iteration 0, loss = 6.94159
I0604 20:56:53.277153   904 solver.cpp:245]     Train net output #0: loss = 6.95404 (* 1 = 6.95404 loss)
I0604 20:56:53.277168   904 sgd_solver.cpp:106] Iteration 0, lr = 0.04
I0604 20:57:34.718351   904 solver.cpp:229] Iteration 40, loss = 6.9083
I0604 20:57:34.718495   904 solver.cpp:245]     Train net output #0: loss = 6.90817 (* 1 = 6.90817 loss)
I0604 20:57:34.718528   904 sgd_solver.cpp:106] Iteration 40, lr = 0.0399906
I0604 20:58:01.834219   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0604 20:58:10.989132   904 solver.cpp:229] Iteration 80, loss = 6.90773
I0604 20:58:10.989296   904 solver.cpp:245]     Train net output #0: loss = 6.90858 (* 1 = 6.90858 loss)
I0604 20:58:10.989305   904 sgd_solver.cpp:106] Iteration 80, lr = 0.0399812
I0604 20:58:42.081509   904 solver.cpp:229] Iteration 120, loss = 6.90771
I0604 20:58:42.081689   904 solver.cpp:245]     Train net output #0: loss = 6.90768 (* 1 = 6.90768 loss)
I0604 20:58:42.081707   904 sgd_solver.cpp:106] Iteration 120, lr = 0.0399718
I0604 20:59:23.572700   904 solver.cpp:229] Iteration 160, loss = 6.90758
I0604 20:59:23.572916   904 solver.cpp:245]     Train net output #0: loss = 6.90692 (* 1 = 6.90692 loss)
I0604 20:59:23.572942   904 sgd_solver.cpp:106] Iteration 160, lr = 0.0399624
I0604 21:00:05.326742   904 solver.cpp:229] Iteration 200, loss = 6.9073
I0604 21:00:05.326970   904 solver.cpp:245]     Train net output #0: loss = 6.90889 (* 1 = 6.90889 loss)
I0604 21:00:05.326992   904 sgd_solver.cpp:106] Iteration 200, lr = 0.0399529
I0604 21:00:47.067035   904 solver.cpp:229] Iteration 240, loss = 6.90738
I0604 21:00:47.067282   904 solver.cpp:245]     Train net output #0: loss = 6.90746 (* 1 = 6.90746 loss)
I0604 21:00:47.067306   904 sgd_solver.cpp:106] Iteration 240, lr = 0.0399435
I0604 21:01:28.740944   904 solver.cpp:229] Iteration 280, loss = 6.90609
I0604 21:01:28.741060   904 solver.cpp:245]     Train net output #0: loss = 6.90002 (* 1 = 6.90002 loss)
I0604 21:01:28.741070   904 sgd_solver.cpp:106] Iteration 280, lr = 0.0399341
I0604 21:02:10.458703   904 solver.cpp:229] Iteration 320, loss = 6.90144
I0604 21:02:10.458922   904 solver.cpp:245]     Train net output #0: loss = 6.87745 (* 1 = 6.87745 loss)
I0604 21:02:10.458959   904 sgd_solver.cpp:106] Iteration 320, lr = 0.0399247
I0604 21:02:52.112361   904 solver.cpp:229] Iteration 360, loss = 6.89358
I0604 21:02:52.112521   904 solver.cpp:245]     Train net output #0: loss = 6.90361 (* 1 = 6.90361 loss)
I0604 21:02:52.112532   904 sgd_solver.cpp:106] Iteration 360, lr = 0.0399153
I0604 21:03:33.786849   904 solver.cpp:229] Iteration 400, loss = 6.8882
I0604 21:03:33.786968   904 solver.cpp:245]     Train net output #0: loss = 6.89563 (* 1 = 6.89563 loss)
I0604 21:03:33.786979   904 sgd_solver.cpp:106] Iteration 400, lr = 0.0399059
I0604 21:04:15.520615   904 solver.cpp:229] Iteration 440, loss = 6.88028
I0604 21:04:15.520880   904 solver.cpp:245]     Train net output #0: loss = 6.89622 (* 1 = 6.89622 loss)
I0604 21:04:15.520915   904 sgd_solver.cpp:106] Iteration 440, lr = 0.0398965
I0604 21:04:53.233811   904 solver.cpp:229] Iteration 480, loss = 6.87161
I0604 21:04:53.233914   904 solver.cpp:245]     Train net output #0: loss = 6.87517 (* 1 = 6.87517 loss)
I0604 21:04:53.233923   904 sgd_solver.cpp:106] Iteration 480, lr = 0.0398871
I0604 21:05:13.676683   904 solver.cpp:229] Iteration 520, loss = 6.86942
I0604 21:05:13.676731   904 solver.cpp:245]     Train net output #0: loss = 6.85729 (* 1 = 6.85729 loss)
I0604 21:05:13.676740   904 sgd_solver.cpp:106] Iteration 520, lr = 0.0398776
I0604 21:05:34.212388   904 solver.cpp:229] Iteration 560, loss = 6.86589
I0604 21:05:34.212525   904 solver.cpp:245]     Train net output #0: loss = 6.87632 (* 1 = 6.87632 loss)
I0604 21:05:34.212538   904 sgd_solver.cpp:106] Iteration 560, lr = 0.0398682
I0604 21:05:54.754138   904 solver.cpp:229] Iteration 600, loss = 6.86469
I0604 21:05:54.754187   904 solver.cpp:245]     Train net output #0: loss = 6.85369 (* 1 = 6.85369 loss)
I0604 21:05:54.754196   904 sgd_solver.cpp:106] Iteration 600, lr = 0.0398588
I0604 21:06:15.220814   904 solver.cpp:229] Iteration 640, loss = 6.85686
I0604 21:06:15.220971   904 solver.cpp:245]     Train net output #0: loss = 6.85039 (* 1 = 6.85039 loss)
I0604 21:06:15.220984   904 sgd_solver.cpp:106] Iteration 640, lr = 0.0398494
I0604 21:06:35.571957   904 solver.cpp:229] Iteration 680, loss = 6.85619
I0604 21:06:35.572003   904 solver.cpp:245]     Train net output #0: loss = 6.89169 (* 1 = 6.89169 loss)
I0604 21:06:35.572015   904 sgd_solver.cpp:106] Iteration 680, lr = 0.03984
I0604 21:06:55.939610   904 solver.cpp:229] Iteration 720, loss = 6.8547
I0604 21:06:55.939826   904 solver.cpp:245]     Train net output #0: loss = 6.84578 (* 1 = 6.84578 loss)
I0604 21:06:55.939852   904 sgd_solver.cpp:106] Iteration 720, lr = 0.0398306
I0604 21:07:16.303761   904 solver.cpp:229] Iteration 760, loss = 6.84842
I0604 21:07:16.303822   904 solver.cpp:245]     Train net output #0: loss = 6.81834 (* 1 = 6.81834 loss)
I0604 21:07:16.303838   904 sgd_solver.cpp:106] Iteration 760, lr = 0.0398212
I0604 21:07:36.649566   904 solver.cpp:229] Iteration 800, loss = 6.84918
I0604 21:07:36.649821   904 solver.cpp:245]     Train net output #0: loss = 6.82974 (* 1 = 6.82974 loss)
I0604 21:07:36.649847   904 sgd_solver.cpp:106] Iteration 800, lr = 0.0398118
I0604 21:07:56.985582   904 solver.cpp:229] Iteration 840, loss = 6.84787
I0604 21:07:56.985635   904 solver.cpp:245]     Train net output #0: loss = 6.85336 (* 1 = 6.85336 loss)
I0604 21:07:56.985656   904 sgd_solver.cpp:106] Iteration 840, lr = 0.0398024
I0604 21:08:17.333387   904 solver.cpp:229] Iteration 880, loss = 6.84455
I0604 21:08:17.333523   904 solver.cpp:245]     Train net output #0: loss = 6.84354 (* 1 = 6.84354 loss)
I0604 21:08:17.333534   904 sgd_solver.cpp:106] Iteration 880, lr = 0.0397929
I0604 21:08:37.670640   904 solver.cpp:229] Iteration 920, loss = 6.85009
I0604 21:08:37.670691   904 solver.cpp:245]     Train net output #0: loss = 6.90436 (* 1 = 6.90436 loss)
I0604 21:08:37.670701   904 sgd_solver.cpp:106] Iteration 920, lr = 0.0397835
I0604 21:08:58.015048   904 solver.cpp:229] Iteration 960, loss = 6.84328
I0604 21:08:58.015211   904 solver.cpp:245]     Train net output #0: loss = 6.8663 (* 1 = 6.8663 loss)
I0604 21:08:58.015226   904 sgd_solver.cpp:106] Iteration 960, lr = 0.0397741
I0604 21:09:17.334514   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0604 21:09:17.842823   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_1000.caffemodel
I0604 21:09:18.141141   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_1000.solverstate
I0604 21:09:18.223836   904 solver.cpp:338] Iteration 1000, Testing net (#0)
I0604 21:09:18.226366   904 net.cpp:748] Ignoring source layer loss
I0604 21:09:52.262048   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0604 21:10:24.495285   904 solver.cpp:406]     Test net output #0: accuracy = 0.00238
I0604 21:10:24.495501   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.0102201
I0604 21:10:24.810921   904 solver.cpp:229] Iteration 1000, loss = 6.83835
I0604 21:10:24.810964   904 solver.cpp:245]     Train net output #0: loss = 6.85155 (* 1 = 6.85155 loss)
I0604 21:10:24.810976   904 sgd_solver.cpp:106] Iteration 1000, lr = 0.0397647
I0604 21:10:26.015601   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0604 21:10:44.058354   904 solver.cpp:229] Iteration 1040, loss = 6.8344
I0604 21:10:44.058399   904 solver.cpp:245]     Train net output #0: loss = 6.83784 (* 1 = 6.83784 loss)
I0604 21:10:44.058408   904 sgd_solver.cpp:106] Iteration 1040, lr = 0.0397553
I0604 21:11:05.434553   904 solver.cpp:229] Iteration 1080, loss = 6.83632
I0604 21:11:05.434784   904 solver.cpp:245]     Train net output #0: loss = 6.86734 (* 1 = 6.86734 loss)
I0604 21:11:05.434818   904 sgd_solver.cpp:106] Iteration 1080, lr = 0.0397459
I0604 21:11:26.923231   904 solver.cpp:229] Iteration 1120, loss = 6.83604
I0604 21:11:26.923301   904 solver.cpp:245]     Train net output #0: loss = 6.86191 (* 1 = 6.86191 loss)
I0604 21:11:26.923319   904 sgd_solver.cpp:106] Iteration 1120, lr = 0.0397365
I0604 21:11:47.901954   904 solver.cpp:229] Iteration 1160, loss = 6.83438
I0604 21:11:47.902133   904 solver.cpp:245]     Train net output #0: loss = 6.805 (* 1 = 6.805 loss)
I0604 21:11:47.902145   904 sgd_solver.cpp:106] Iteration 1160, lr = 0.0397271
I0604 21:12:08.901187   904 solver.cpp:229] Iteration 1200, loss = 6.83306
I0604 21:12:08.901249   904 solver.cpp:245]     Train net output #0: loss = 6.85137 (* 1 = 6.85137 loss)
I0604 21:12:08.901259   904 sgd_solver.cpp:106] Iteration 1200, lr = 0.0397176
I0604 21:12:29.887162   904 solver.cpp:229] Iteration 1240, loss = 6.83019
I0604 21:12:29.887374   904 solver.cpp:245]     Train net output #0: loss = 6.82655 (* 1 = 6.82655 loss)
I0604 21:12:29.887401   904 sgd_solver.cpp:106] Iteration 1240, lr = 0.0397082
I0604 21:12:50.885923   904 solver.cpp:229] Iteration 1280, loss = 6.82182
I0604 21:12:50.885969   904 solver.cpp:245]     Train net output #0: loss = 6.82974 (* 1 = 6.82974 loss)
I0604 21:12:50.885980   904 sgd_solver.cpp:106] Iteration 1280, lr = 0.0396988
I0604 21:13:11.761277   904 solver.cpp:229] Iteration 1320, loss = 6.82247
I0604 21:13:11.761488   904 solver.cpp:245]     Train net output #0: loss = 6.83639 (* 1 = 6.83639 loss)
I0604 21:13:11.761512   904 sgd_solver.cpp:106] Iteration 1320, lr = 0.0396894
I0604 21:13:32.479535   904 solver.cpp:229] Iteration 1360, loss = 6.81626
I0604 21:13:32.479590   904 solver.cpp:245]     Train net output #0: loss = 6.76276 (* 1 = 6.76276 loss)
I0604 21:13:32.479600   904 sgd_solver.cpp:106] Iteration 1360, lr = 0.03968
I0604 21:13:53.177672   904 solver.cpp:229] Iteration 1400, loss = 6.81522
I0604 21:13:53.177870   904 solver.cpp:245]     Train net output #0: loss = 6.82478 (* 1 = 6.82478 loss)
I0604 21:13:53.177884   904 sgd_solver.cpp:106] Iteration 1400, lr = 0.0396706
I0604 21:14:13.890359   904 solver.cpp:229] Iteration 1440, loss = 6.80645
I0604 21:14:13.890406   904 solver.cpp:245]     Train net output #0: loss = 6.81991 (* 1 = 6.81991 loss)
I0604 21:14:13.890419   904 sgd_solver.cpp:106] Iteration 1440, lr = 0.0396612
I0604 21:14:34.588294   904 solver.cpp:229] Iteration 1480, loss = 6.79673
I0604 21:14:34.588506   904 solver.cpp:245]     Train net output #0: loss = 6.75669 (* 1 = 6.75669 loss)
I0604 21:14:34.588537   904 sgd_solver.cpp:106] Iteration 1480, lr = 0.0396518
I0604 21:14:55.159806   904 solver.cpp:229] Iteration 1520, loss = 6.79962
I0604 21:14:55.159857   904 solver.cpp:245]     Train net output #0: loss = 6.76898 (* 1 = 6.76898 loss)
I0604 21:14:55.159867   904 sgd_solver.cpp:106] Iteration 1520, lr = 0.0396424
I0604 21:15:11.073995   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0604 21:15:15.838215   904 solver.cpp:229] Iteration 1560, loss = 6.77996
I0604 21:15:15.838280   904 solver.cpp:245]     Train net output #0: loss = 6.74907 (* 1 = 6.74907 loss)
I0604 21:15:15.838291   904 sgd_solver.cpp:106] Iteration 1560, lr = 0.0396329
I0604 21:15:36.294524   904 solver.cpp:229] Iteration 1600, loss = 6.76349
I0604 21:15:36.294567   904 solver.cpp:245]     Train net output #0: loss = 6.77625 (* 1 = 6.77625 loss)
I0604 21:15:36.294576   904 sgd_solver.cpp:106] Iteration 1600, lr = 0.0396235
I0604 21:15:56.812012   904 solver.cpp:229] Iteration 1640, loss = 6.76004
I0604 21:15:56.813174   904 solver.cpp:245]     Train net output #0: loss = 6.70574 (* 1 = 6.70574 loss)
I0604 21:15:56.813195   904 sgd_solver.cpp:106] Iteration 1640, lr = 0.0396141
I0604 21:16:17.301440   904 solver.cpp:229] Iteration 1680, loss = 6.74441
I0604 21:16:17.301486   904 solver.cpp:245]     Train net output #0: loss = 6.70114 (* 1 = 6.70114 loss)
I0604 21:16:17.301493   904 sgd_solver.cpp:106] Iteration 1680, lr = 0.0396047
I0604 21:16:37.812819   904 solver.cpp:229] Iteration 1720, loss = 6.7183
I0604 21:16:37.813011   904 solver.cpp:245]     Train net output #0: loss = 6.64517 (* 1 = 6.64517 loss)
I0604 21:16:37.813040   904 sgd_solver.cpp:106] Iteration 1720, lr = 0.0395953
I0604 21:16:58.280071   904 solver.cpp:229] Iteration 1760, loss = 6.70927
I0604 21:16:58.280118   904 solver.cpp:245]     Train net output #0: loss = 6.71333 (* 1 = 6.71333 loss)
I0604 21:16:58.280130   904 sgd_solver.cpp:106] Iteration 1760, lr = 0.0395859
I0604 21:17:18.602313   904 solver.cpp:229] Iteration 1800, loss = 6.68087
I0604 21:17:18.602473   904 solver.cpp:245]     Train net output #0: loss = 6.65889 (* 1 = 6.65889 loss)
I0604 21:17:18.602485   904 sgd_solver.cpp:106] Iteration 1800, lr = 0.0395765
I0604 21:17:38.890990   904 solver.cpp:229] Iteration 1840, loss = 6.65565
I0604 21:17:38.891038   904 solver.cpp:245]     Train net output #0: loss = 6.64397 (* 1 = 6.64397 loss)
I0604 21:17:38.891048   904 sgd_solver.cpp:106] Iteration 1840, lr = 0.0395671
I0604 21:17:59.220389   904 solver.cpp:229] Iteration 1880, loss = 6.60869
I0604 21:17:59.220602   904 solver.cpp:245]     Train net output #0: loss = 6.64569 (* 1 = 6.64569 loss)
I0604 21:17:59.220625   904 sgd_solver.cpp:106] Iteration 1880, lr = 0.0395576
I0604 21:18:19.526628   904 solver.cpp:229] Iteration 1920, loss = 6.61021
I0604 21:18:19.526684   904 solver.cpp:245]     Train net output #0: loss = 6.56645 (* 1 = 6.56645 loss)
I0604 21:18:19.526695   904 sgd_solver.cpp:106] Iteration 1920, lr = 0.0395482
I0604 21:18:39.831610   904 solver.cpp:229] Iteration 1960, loss = 6.5778
I0604 21:18:39.831869   904 solver.cpp:245]     Train net output #0: loss = 6.53157 (* 1 = 6.53157 loss)
I0604 21:18:39.831893   904 sgd_solver.cpp:106] Iteration 1960, lr = 0.0395388
I0604 21:18:59.626685   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_2000.caffemodel
I0604 21:18:59.883303   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_2000.solverstate
I0604 21:18:59.965106   904 solver.cpp:338] Iteration 2000, Testing net (#0)
I0604 21:18:59.965185   904 net.cpp:748] Ignoring source layer loss
I0604 21:19:04.867403   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0604 21:19:39.257956   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0604 21:20:09.571914   904 solver.cpp:406]     Test net output #0: accuracy = 0.00600003
I0604 21:20:09.572108   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.0281804
I0604 21:20:09.889695   904 solver.cpp:229] Iteration 2000, loss = 6.53846
I0604 21:20:09.889742   904 solver.cpp:245]     Train net output #0: loss = 6.508 (* 1 = 6.508 loss)
I0604 21:20:09.889752   904 sgd_solver.cpp:106] Iteration 2000, lr = 0.0395294
I0604 21:20:29.089898   904 solver.cpp:229] Iteration 2040, loss = 6.50785
I0604 21:20:29.089946   904 solver.cpp:245]     Train net output #0: loss = 6.57919 (* 1 = 6.57919 loss)
I0604 21:20:29.089958   904 sgd_solver.cpp:106] Iteration 2040, lr = 0.03952
I0604 21:20:48.499943   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0604 21:20:50.386656   904 solver.cpp:229] Iteration 2080, loss = 6.50533
I0604 21:20:50.386720   904 solver.cpp:245]     Train net output #0: loss = 6.57593 (* 1 = 6.57593 loss)
I0604 21:20:50.386731   904 sgd_solver.cpp:106] Iteration 2080, lr = 0.0395106
I0604 21:21:11.795529   904 solver.cpp:229] Iteration 2120, loss = 6.47403
I0604 21:21:11.795583   904 solver.cpp:245]     Train net output #0: loss = 6.44208 (* 1 = 6.44208 loss)
I0604 21:21:11.795593   904 sgd_solver.cpp:106] Iteration 2120, lr = 0.0395012
I0604 21:21:32.896440   904 solver.cpp:229] Iteration 2160, loss = 6.44186
I0604 21:21:32.896560   904 solver.cpp:245]     Train net output #0: loss = 6.44259 (* 1 = 6.44259 loss)
I0604 21:21:32.896575   904 sgd_solver.cpp:106] Iteration 2160, lr = 0.0394918
I0604 21:21:53.894652   904 solver.cpp:229] Iteration 2200, loss = 6.42668
I0604 21:21:53.894702   904 solver.cpp:245]     Train net output #0: loss = 6.35972 (* 1 = 6.35972 loss)
I0604 21:21:53.894716   904 sgd_solver.cpp:106] Iteration 2200, lr = 0.0394824
I0604 21:22:14.917330   904 solver.cpp:229] Iteration 2240, loss = 6.42877
I0604 21:22:14.917500   904 solver.cpp:245]     Train net output #0: loss = 6.48196 (* 1 = 6.48196 loss)
I0604 21:22:14.917511   904 sgd_solver.cpp:106] Iteration 2240, lr = 0.0394729
I0604 21:22:35.839007   904 solver.cpp:229] Iteration 2280, loss = 6.40342
I0604 21:22:35.839079   904 solver.cpp:245]     Train net output #0: loss = 6.34343 (* 1 = 6.34343 loss)
I0604 21:22:35.839092   904 sgd_solver.cpp:106] Iteration 2280, lr = 0.0394635
I0604 21:22:56.699887   904 solver.cpp:229] Iteration 2320, loss = 6.36311
I0604 21:22:56.700122   904 solver.cpp:245]     Train net output #0: loss = 6.62101 (* 1 = 6.62101 loss)
I0604 21:22:56.700156   904 sgd_solver.cpp:106] Iteration 2320, lr = 0.0394541
I0604 21:23:17.467048   904 solver.cpp:229] Iteration 2360, loss = 6.30397
I0604 21:23:17.467103   904 solver.cpp:245]     Train net output #0: loss = 6.31375 (* 1 = 6.31375 loss)
I0604 21:23:17.467113   904 sgd_solver.cpp:106] Iteration 2360, lr = 0.0394447
I0604 21:23:38.173302   904 solver.cpp:229] Iteration 2400, loss = 6.31814
I0604 21:23:38.173532   904 solver.cpp:245]     Train net output #0: loss = 6.35695 (* 1 = 6.35695 loss)
I0604 21:23:38.173559   904 sgd_solver.cpp:106] Iteration 2400, lr = 0.0394353
I0604 21:23:58.865959   904 solver.cpp:229] Iteration 2440, loss = 6.27714
I0604 21:23:58.866008   904 solver.cpp:245]     Train net output #0: loss = 6.24399 (* 1 = 6.24399 loss)
I0604 21:23:58.866019   904 sgd_solver.cpp:106] Iteration 2440, lr = 0.0394259
I0604 21:24:19.564440   904 solver.cpp:229] Iteration 2480, loss = 6.26926
I0604 21:24:19.564698   904 solver.cpp:245]     Train net output #0: loss = 6.32781 (* 1 = 6.32781 loss)
I0604 21:24:19.564725   904 sgd_solver.cpp:106] Iteration 2480, lr = 0.0394165
I0604 21:24:40.251170   904 solver.cpp:229] Iteration 2520, loss = 6.28276
I0604 21:24:40.251224   904 solver.cpp:245]     Train net output #0: loss = 6.08847 (* 1 = 6.08847 loss)
I0604 21:24:40.251232   904 sgd_solver.cpp:106] Iteration 2520, lr = 0.0394071
I0604 21:25:00.909735   904 solver.cpp:229] Iteration 2560, loss = 6.24363
I0604 21:25:00.909889   904 solver.cpp:245]     Train net output #0: loss = 6.22639 (* 1 = 6.22639 loss)
I0604 21:25:00.909903   904 sgd_solver.cpp:106] Iteration 2560, lr = 0.0393976
I0604 21:25:21.415966   904 solver.cpp:229] Iteration 2600, loss = 6.1967
I0604 21:25:21.416018   904 solver.cpp:245]     Train net output #0: loss = 6.20875 (* 1 = 6.20875 loss)
I0604 21:25:21.416028   904 sgd_solver.cpp:106] Iteration 2600, lr = 0.0393882
I0604 21:25:23.206800   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0604 21:25:41.975814   904 solver.cpp:229] Iteration 2640, loss = 6.14039
I0604 21:25:41.976006   904 solver.cpp:245]     Train net output #0: loss = 6.0859 (* 1 = 6.0859 loss)
I0604 21:25:41.976035   904 sgd_solver.cpp:106] Iteration 2640, lr = 0.0393788
I0604 21:26:02.614181   904 solver.cpp:229] Iteration 2680, loss = 6.21243
I0604 21:26:02.614226   904 solver.cpp:245]     Train net output #0: loss = 5.96162 (* 1 = 5.96162 loss)
I0604 21:26:02.614236   904 sgd_solver.cpp:106] Iteration 2680, lr = 0.0393694
I0604 21:26:23.150768   904 solver.cpp:229] Iteration 2720, loss = 6.13629
I0604 21:26:23.150959   904 solver.cpp:245]     Train net output #0: loss = 6.09772 (* 1 = 6.09772 loss)
I0604 21:26:23.150985   904 sgd_solver.cpp:106] Iteration 2720, lr = 0.03936
I0604 21:26:43.654069   904 solver.cpp:229] Iteration 2760, loss = 6.10704
I0604 21:26:43.654126   904 solver.cpp:245]     Train net output #0: loss = 6.1072 (* 1 = 6.1072 loss)
I0604 21:26:43.654136   904 sgd_solver.cpp:106] Iteration 2760, lr = 0.0393506
I0604 21:27:04.146497   904 solver.cpp:229] Iteration 2800, loss = 6.07028
I0604 21:27:04.146705   904 solver.cpp:245]     Train net output #0: loss = 6.06272 (* 1 = 6.06272 loss)
I0604 21:27:04.146733   904 sgd_solver.cpp:106] Iteration 2800, lr = 0.0393412
I0604 21:27:24.674144   904 solver.cpp:229] Iteration 2840, loss = 6.04936
I0604 21:27:24.674190   904 solver.cpp:245]     Train net output #0: loss = 6.05779 (* 1 = 6.05779 loss)
I0604 21:27:24.674199   904 sgd_solver.cpp:106] Iteration 2840, lr = 0.0393318
I0604 21:27:45.198807   904 solver.cpp:229] Iteration 2880, loss = 6.02513
I0604 21:27:45.198912   904 solver.cpp:245]     Train net output #0: loss = 6.07764 (* 1 = 6.07764 loss)
I0604 21:27:45.198922   904 sgd_solver.cpp:106] Iteration 2880, lr = 0.0393224
I0604 21:28:05.751874   904 solver.cpp:229] Iteration 2920, loss = 6.01717
I0604 21:28:05.751924   904 solver.cpp:245]     Train net output #0: loss = 6.0474 (* 1 = 6.0474 loss)
I0604 21:28:05.751936   904 sgd_solver.cpp:106] Iteration 2920, lr = 0.0393129
I0604 21:28:26.352294   904 solver.cpp:229] Iteration 2960, loss = 6.01465
I0604 21:28:26.352478   904 solver.cpp:245]     Train net output #0: loss = 5.85268 (* 1 = 5.85268 loss)
I0604 21:28:26.352489   904 sgd_solver.cpp:106] Iteration 2960, lr = 0.0393035
I0604 21:28:46.351532   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_3000.caffemodel
I0604 21:28:46.617524   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_3000.solverstate
I0604 21:28:46.694393   904 solver.cpp:338] Iteration 3000, Testing net (#0)
I0604 21:28:46.694474   904 net.cpp:748] Ignoring source layer loss
I0604 21:28:55.372406   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0604 21:29:32.417415   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0604 21:29:59.289876   904 solver.cpp:406]     Test net output #0: accuracy = 0.0224403
I0604 21:29:59.289919   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.08376
I0604 21:29:59.603557   904 solver.cpp:229] Iteration 3000, loss = 5.991
I0604 21:29:59.603606   904 solver.cpp:245]     Train net output #0: loss = 5.96981 (* 1 = 5.96981 loss)
I0604 21:29:59.603617   904 sgd_solver.cpp:106] Iteration 3000, lr = 0.0392941
I0604 21:30:18.806980   904 solver.cpp:229] Iteration 3040, loss = 5.97099
I0604 21:30:18.807132   904 solver.cpp:245]     Train net output #0: loss = 6.09933 (* 1 = 6.09933 loss)
I0604 21:30:18.807144   904 sgd_solver.cpp:106] Iteration 3040, lr = 0.0392847
I0604 21:30:40.256283   904 solver.cpp:229] Iteration 3080, loss = 5.93204
I0604 21:30:40.256327   904 solver.cpp:245]     Train net output #0: loss = 5.73049 (* 1 = 5.73049 loss)
I0604 21:30:40.256337   904 sgd_solver.cpp:106] Iteration 3080, lr = 0.0392753
I0604 21:31:01.757271   904 solver.cpp:229] Iteration 3120, loss = 5.89834
I0604 21:31:01.757424   904 solver.cpp:245]     Train net output #0: loss = 5.88189 (* 1 = 5.88189 loss)
I0604 21:31:01.757434   904 sgd_solver.cpp:106] Iteration 3120, lr = 0.0392659
I0604 21:31:03.105654   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0604 21:31:22.879319   904 solver.cpp:229] Iteration 3160, loss = 5.94654
I0604 21:31:22.879421   904 solver.cpp:245]     Train net output #0: loss = 5.90807 (* 1 = 5.90807 loss)
I0604 21:31:22.879446   904 sgd_solver.cpp:106] Iteration 3160, lr = 0.0392565
I0604 21:31:43.798401   904 solver.cpp:229] Iteration 3200, loss = 5.87494
I0604 21:31:43.798632   904 solver.cpp:245]     Train net output #0: loss = 5.92736 (* 1 = 5.92736 loss)
I0604 21:31:43.798660   904 sgd_solver.cpp:106] Iteration 3200, lr = 0.0392471
I0604 21:32:04.746228   904 solver.cpp:229] Iteration 3240, loss = 5.91901
I0604 21:32:04.746284   904 solver.cpp:245]     Train net output #0: loss = 6.01057 (* 1 = 6.01057 loss)
I0604 21:32:04.746295   904 sgd_solver.cpp:106] Iteration 3240, lr = 0.0392376
I0604 21:32:25.699944   904 solver.cpp:229] Iteration 3280, loss = 5.93806
I0604 21:32:25.700192   904 solver.cpp:245]     Train net output #0: loss = 5.85047 (* 1 = 5.85047 loss)
I0604 21:32:25.700215   904 sgd_solver.cpp:106] Iteration 3280, lr = 0.0392282
I0604 21:32:46.599318   904 solver.cpp:229] Iteration 3320, loss = 5.83345
I0604 21:32:46.599367   904 solver.cpp:245]     Train net output #0: loss = 5.69179 (* 1 = 5.69179 loss)
I0604 21:32:46.599378   904 sgd_solver.cpp:106] Iteration 3320, lr = 0.0392188
I0604 21:33:07.362534   904 solver.cpp:229] Iteration 3360, loss = 5.82118
I0604 21:33:07.362797   904 solver.cpp:245]     Train net output #0: loss = 5.91934 (* 1 = 5.91934 loss)
I0604 21:33:07.362835   904 sgd_solver.cpp:106] Iteration 3360, lr = 0.0392094
I0604 21:33:28.150853   904 solver.cpp:229] Iteration 3400, loss = 5.79597
I0604 21:33:28.150912   904 solver.cpp:245]     Train net output #0: loss = 5.74375 (* 1 = 5.74375 loss)
I0604 21:33:28.150921   904 sgd_solver.cpp:106] Iteration 3400, lr = 0.0392
I0604 21:33:48.939007   904 solver.cpp:229] Iteration 3440, loss = 5.77761
I0604 21:33:48.939198   904 solver.cpp:245]     Train net output #0: loss = 5.84001 (* 1 = 5.84001 loss)
I0604 21:33:48.939227   904 sgd_solver.cpp:106] Iteration 3440, lr = 0.0391906
I0604 21:34:09.596643   904 solver.cpp:229] Iteration 3480, loss = 5.74511
I0604 21:34:09.596701   904 solver.cpp:245]     Train net output #0: loss = 5.68194 (* 1 = 5.68194 loss)
I0604 21:34:09.596712   904 sgd_solver.cpp:106] Iteration 3480, lr = 0.0391812
I0604 21:34:30.047715   904 solver.cpp:229] Iteration 3520, loss = 5.77034
I0604 21:34:30.047858   904 solver.cpp:245]     Train net output #0: loss = 5.80853 (* 1 = 5.80853 loss)
I0604 21:34:30.047869   904 sgd_solver.cpp:106] Iteration 3520, lr = 0.0391718
I0604 21:34:50.639919   904 solver.cpp:229] Iteration 3560, loss = 5.73482
I0604 21:34:50.639966   904 solver.cpp:245]     Train net output #0: loss = 5.61057 (* 1 = 5.61057 loss)
I0604 21:34:50.639977   904 sgd_solver.cpp:106] Iteration 3560, lr = 0.0391624
I0604 21:35:11.226883   904 solver.cpp:229] Iteration 3600, loss = 5.72278
I0604 21:35:11.227118   904 solver.cpp:245]     Train net output #0: loss = 5.69695 (* 1 = 5.69695 loss)
I0604 21:35:11.227144   904 sgd_solver.cpp:106] Iteration 3600, lr = 0.0391529
I0604 21:35:26.835810   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0604 21:35:31.681694   904 solver.cpp:229] Iteration 3640, loss = 5.67191
I0604 21:35:31.681735   904 solver.cpp:245]     Train net output #0: loss = 5.65033 (* 1 = 5.65033 loss)
I0604 21:35:31.681743   904 sgd_solver.cpp:106] Iteration 3640, lr = 0.0391435
I0604 21:35:52.110437   904 solver.cpp:229] Iteration 3680, loss = 5.6865
I0604 21:35:52.110623   904 solver.cpp:245]     Train net output #0: loss = 5.75602 (* 1 = 5.75602 loss)
I0604 21:35:52.110649   904 sgd_solver.cpp:106] Iteration 3680, lr = 0.0391341
I0604 21:36:12.790256   904 solver.cpp:229] Iteration 3720, loss = 5.70689
I0604 21:36:12.790307   904 solver.cpp:245]     Train net output #0: loss = 5.653 (* 1 = 5.653 loss)
I0604 21:36:12.790328   904 sgd_solver.cpp:106] Iteration 3720, lr = 0.0391247
I0604 21:36:33.227552   904 solver.cpp:229] Iteration 3760, loss = 5.62652
I0604 21:36:33.227746   904 solver.cpp:245]     Train net output #0: loss = 5.5283 (* 1 = 5.5283 loss)
I0604 21:36:33.227772   904 sgd_solver.cpp:106] Iteration 3760, lr = 0.0391153
I0604 21:36:53.737210   904 solver.cpp:229] Iteration 3800, loss = 5.60845
I0604 21:36:53.737259   904 solver.cpp:245]     Train net output #0: loss = 5.55827 (* 1 = 5.55827 loss)
I0604 21:36:53.737270   904 sgd_solver.cpp:106] Iteration 3800, lr = 0.0391059
I0604 21:37:13.950815   904 solver.cpp:229] Iteration 3840, loss = 5.66279
I0604 21:37:13.951053   904 solver.cpp:245]     Train net output #0: loss = 5.61077 (* 1 = 5.61077 loss)
I0604 21:37:13.951084   904 sgd_solver.cpp:106] Iteration 3840, lr = 0.0390965
I0604 21:37:34.156771   904 solver.cpp:229] Iteration 3880, loss = 5.62841
I0604 21:37:34.156810   904 solver.cpp:245]     Train net output #0: loss = 5.46643 (* 1 = 5.46643 loss)
I0604 21:37:34.156816   904 sgd_solver.cpp:106] Iteration 3880, lr = 0.0390871
I0604 21:37:54.366292   904 solver.cpp:229] Iteration 3920, loss = 5.65441
I0604 21:37:54.366472   904 solver.cpp:245]     Train net output #0: loss = 5.48089 (* 1 = 5.48089 loss)
I0604 21:37:54.366497   904 sgd_solver.cpp:106] Iteration 3920, lr = 0.0390776
I0604 21:38:14.567845   904 solver.cpp:229] Iteration 3960, loss = 5.59824
I0604 21:38:14.567893   904 solver.cpp:245]     Train net output #0: loss = 5.62545 (* 1 = 5.62545 loss)
I0604 21:38:14.567900   904 sgd_solver.cpp:106] Iteration 3960, lr = 0.0390682
I0604 21:38:34.276453   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_4000.caffemodel
I0604 21:38:34.546500   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_4000.solverstate
I0604 21:38:34.620092   904 solver.cpp:338] Iteration 4000, Testing net (#0)
I0604 21:38:34.620167   904 net.cpp:748] Ignoring source layer loss
I0604 21:38:43.837551   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0604 21:39:19.086184   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0604 21:39:44.290377   904 solver.cpp:406]     Test net output #0: accuracy = 0.0465201
I0604 21:39:44.290426   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.14126
I0604 21:39:44.605355   904 solver.cpp:229] Iteration 4000, loss = 5.58744
I0604 21:39:44.605412   904 solver.cpp:245]     Train net output #0: loss = 5.61763 (* 1 = 5.61763 loss)
I0604 21:39:44.605427   904 sgd_solver.cpp:106] Iteration 4000, lr = 0.0390588
I0604 21:40:03.867122   904 solver.cpp:229] Iteration 4040, loss = 5.54824
I0604 21:40:03.867344   904 solver.cpp:245]     Train net output #0: loss = 5.67015 (* 1 = 5.67015 loss)
I0604 21:40:03.867372   904 sgd_solver.cpp:106] Iteration 4040, lr = 0.0390494
I0604 21:40:25.213270   904 solver.cpp:229] Iteration 4080, loss = 5.5482
I0604 21:40:25.213320   904 solver.cpp:245]     Train net output #0: loss = 5.52289 (* 1 = 5.52289 loss)
I0604 21:40:25.213328   904 sgd_solver.cpp:106] Iteration 4080, lr = 0.03904
I0604 21:40:46.599884   904 solver.cpp:229] Iteration 4120, loss = 5.55271
I0604 21:40:46.600148   904 solver.cpp:245]     Train net output #0: loss = 5.40729 (* 1 = 5.40729 loss)
I0604 21:40:46.600173   904 sgd_solver.cpp:106] Iteration 4120, lr = 0.0390306
I0604 21:40:56.599634   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0604 21:41:07.593869   904 solver.cpp:229] Iteration 4160, loss = 5.58625
I0604 21:41:07.593924   904 solver.cpp:245]     Train net output #0: loss = 5.52374 (* 1 = 5.52374 loss)
I0604 21:41:07.593935   904 sgd_solver.cpp:106] Iteration 4160, lr = 0.0390212
I0604 21:41:28.605718   904 solver.cpp:229] Iteration 4200, loss = 5.52465
I0604 21:41:28.605909   904 solver.cpp:245]     Train net output #0: loss = 5.42776 (* 1 = 5.42776 loss)
I0604 21:41:28.605937   904 sgd_solver.cpp:106] Iteration 4200, lr = 0.0390118
I0604 21:41:49.592761   904 solver.cpp:229] Iteration 4240, loss = 5.45947
I0604 21:41:49.592804   904 solver.cpp:245]     Train net output #0: loss = 5.46576 (* 1 = 5.46576 loss)
I0604 21:41:49.592813   904 sgd_solver.cpp:106] Iteration 4240, lr = 0.0390024
I0604 21:42:10.536128   904 solver.cpp:229] Iteration 4280, loss = 5.49642
I0604 21:42:10.536470   904 solver.cpp:245]     Train net output #0: loss = 5.55048 (* 1 = 5.55048 loss)
I0604 21:42:10.536495   904 sgd_solver.cpp:106] Iteration 4280, lr = 0.0389929
I0604 21:42:31.385094   904 solver.cpp:229] Iteration 4320, loss = 5.45374
I0604 21:42:31.385138   904 solver.cpp:245]     Train net output #0: loss = 5.31602 (* 1 = 5.31602 loss)
I0604 21:42:31.385148   904 sgd_solver.cpp:106] Iteration 4320, lr = 0.0389835
I0604 21:42:52.116812   904 solver.cpp:229] Iteration 4360, loss = 5.47156
I0604 21:42:52.117020   904 solver.cpp:245]     Train net output #0: loss = 5.55042 (* 1 = 5.55042 loss)
I0604 21:42:52.117046   904 sgd_solver.cpp:106] Iteration 4360, lr = 0.0389741
I0604 21:43:12.803483   904 solver.cpp:229] Iteration 4400, loss = 5.436
I0604 21:43:12.803535   904 solver.cpp:245]     Train net output #0: loss = 5.31888 (* 1 = 5.31888 loss)
I0604 21:43:12.803542   904 sgd_solver.cpp:106] Iteration 4400, lr = 0.0389647
I0604 21:43:33.481624   904 solver.cpp:229] Iteration 4440, loss = 5.4059
I0604 21:43:33.481812   904 solver.cpp:245]     Train net output #0: loss = 5.5112 (* 1 = 5.5112 loss)
I0604 21:43:33.481847   904 sgd_solver.cpp:106] Iteration 4440, lr = 0.0389553
I0604 21:43:54.088901   904 solver.cpp:229] Iteration 4480, loss = 5.43288
I0604 21:43:54.088942   904 solver.cpp:245]     Train net output #0: loss = 5.38484 (* 1 = 5.38484 loss)
I0604 21:43:54.088950   904 sgd_solver.cpp:106] Iteration 4480, lr = 0.0389459
I0604 21:44:14.576755   904 solver.cpp:229] Iteration 4520, loss = 5.38577
I0604 21:44:14.576951   904 solver.cpp:245]     Train net output #0: loss = 5.43273 (* 1 = 5.43273 loss)
I0604 21:44:14.576977   904 sgd_solver.cpp:106] Iteration 4520, lr = 0.0389365
I0604 21:44:35.085415   904 solver.cpp:229] Iteration 4560, loss = 5.39999
I0604 21:44:35.085459   904 solver.cpp:245]     Train net output #0: loss = 5.30561 (* 1 = 5.30561 loss)
I0604 21:44:35.085469   904 sgd_solver.cpp:106] Iteration 4560, lr = 0.0389271
I0604 21:44:55.617161   904 solver.cpp:229] Iteration 4600, loss = 5.38618
I0604 21:44:55.617393   904 solver.cpp:245]     Train net output #0: loss = 5.41157 (* 1 = 5.41157 loss)
I0604 21:44:55.617416   904 sgd_solver.cpp:106] Iteration 4600, lr = 0.0389176
I0604 21:45:16.124722   904 solver.cpp:229] Iteration 4640, loss = 5.33132
I0604 21:45:16.124769   904 solver.cpp:245]     Train net output #0: loss = 5.47374 (* 1 = 5.47374 loss)
I0604 21:45:16.124778   904 sgd_solver.cpp:106] Iteration 4640, lr = 0.0389082
I0604 21:45:18.433815   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0604 21:45:36.639600   904 solver.cpp:229] Iteration 4680, loss = 5.33346
I0604 21:45:36.639842   904 solver.cpp:245]     Train net output #0: loss = 5.2176 (* 1 = 5.2176 loss)
I0604 21:45:36.639868   904 sgd_solver.cpp:106] Iteration 4680, lr = 0.0388988
I0604 21:45:56.998080   904 solver.cpp:229] Iteration 4720, loss = 5.30615
I0604 21:45:56.998133   904 solver.cpp:245]     Train net output #0: loss = 5.37102 (* 1 = 5.37102 loss)
I0604 21:45:56.998143   904 sgd_solver.cpp:106] Iteration 4720, lr = 0.0388894
I0604 21:46:17.310573   904 solver.cpp:229] Iteration 4760, loss = 5.35063
I0604 21:46:17.310750   904 solver.cpp:245]     Train net output #0: loss = 5.49125 (* 1 = 5.49125 loss)
I0604 21:46:17.310760   904 sgd_solver.cpp:106] Iteration 4760, lr = 0.03888
I0604 21:46:37.607504   904 solver.cpp:229] Iteration 4800, loss = 5.3315
I0604 21:46:37.607574   904 solver.cpp:245]     Train net output #0: loss = 5.23662 (* 1 = 5.23662 loss)
I0604 21:46:37.607586   904 sgd_solver.cpp:106] Iteration 4800, lr = 0.0388706
I0604 21:46:57.810680   904 solver.cpp:229] Iteration 4840, loss = 5.27721
I0604 21:46:57.810886   904 solver.cpp:245]     Train net output #0: loss = 5.14617 (* 1 = 5.14617 loss)
I0604 21:46:57.810899   904 sgd_solver.cpp:106] Iteration 4840, lr = 0.0388612
I0604 21:47:18.059500   904 solver.cpp:229] Iteration 4880, loss = 5.2842
I0604 21:47:18.059582   904 solver.cpp:245]     Train net output #0: loss = 5.28232 (* 1 = 5.28232 loss)
I0604 21:47:18.059594   904 sgd_solver.cpp:106] Iteration 4880, lr = 0.0388518
I0604 21:47:38.148458   904 solver.cpp:229] Iteration 4920, loss = 5.26165
I0604 21:47:38.148619   904 solver.cpp:245]     Train net output #0: loss = 5.23351 (* 1 = 5.23351 loss)
I0604 21:47:38.148633   904 sgd_solver.cpp:106] Iteration 4920, lr = 0.0388424
I0604 21:47:58.169970   904 solver.cpp:229] Iteration 4960, loss = 5.29023
I0604 21:47:58.170016   904 solver.cpp:245]     Train net output #0: loss = 5.32506 (* 1 = 5.32506 loss)
I0604 21:47:58.170024   904 sgd_solver.cpp:106] Iteration 4960, lr = 0.0388329
I0604 21:48:17.566150   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_5000.caffemodel
I0604 21:48:17.828516   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_5000.solverstate
I0604 21:48:17.906353   904 solver.cpp:338] Iteration 5000, Testing net (#0)
I0604 21:48:17.906435   904 net.cpp:748] Ignoring source layer loss
I0604 21:48:29.957631   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0604 21:49:03.627486   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0604 21:49:24.385124   904 solver.cpp:406]     Test net output #0: accuracy = 0.0693199
I0604 21:49:24.385162   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.19264
I0604 21:49:24.700629   904 solver.cpp:229] Iteration 5000, loss = 5.24246
I0604 21:49:24.700680   904 solver.cpp:245]     Train net output #0: loss = 5.25806 (* 1 = 5.25806 loss)
I0604 21:49:24.700692   904 sgd_solver.cpp:106] Iteration 5000, lr = 0.0388235
I0604 21:49:43.924192   904 solver.cpp:229] Iteration 5040, loss = 5.27113
I0604 21:49:43.924317   904 solver.cpp:245]     Train net output #0: loss = 5.22707 (* 1 = 5.22707 loss)
I0604 21:49:43.924327   904 sgd_solver.cpp:106] Iteration 5040, lr = 0.0388141
I0604 21:50:04.628531   904 solver.cpp:229] Iteration 5080, loss = 5.27808
I0604 21:50:04.628585   904 solver.cpp:245]     Train net output #0: loss = 5.0108 (* 1 = 5.0108 loss)
I0604 21:50:04.628595   904 sgd_solver.cpp:106] Iteration 5080, lr = 0.0388047
I0604 21:50:25.676012   904 solver.cpp:229] Iteration 5120, loss = 5.22529
I0604 21:50:25.676236   904 solver.cpp:245]     Train net output #0: loss = 5.01315 (* 1 = 5.01315 loss)
I0604 21:50:25.676267   904 sgd_solver.cpp:106] Iteration 5120, lr = 0.0387953
I0604 21:50:46.362812   904 solver.cpp:229] Iteration 5160, loss = 5.21857
I0604 21:50:46.362866   904 solver.cpp:245]     Train net output #0: loss = 5.36304 (* 1 = 5.36304 loss)
I0604 21:50:46.362875   904 sgd_solver.cpp:106] Iteration 5160, lr = 0.0387859
I0604 21:51:01.339447   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0604 21:51:07.027732   904 solver.cpp:229] Iteration 5200, loss = 5.1757
I0604 21:51:07.027772   904 solver.cpp:245]     Train net output #0: loss = 5.09914 (* 1 = 5.09914 loss)
I0604 21:51:07.027781   904 sgd_solver.cpp:106] Iteration 5200, lr = 0.0387765
I0604 21:51:27.709426   904 solver.cpp:229] Iteration 5240, loss = 5.18197
I0604 21:51:27.709476   904 solver.cpp:245]     Train net output #0: loss = 5.23375 (* 1 = 5.23375 loss)
I0604 21:51:27.709484   904 sgd_solver.cpp:106] Iteration 5240, lr = 0.0387671
I0604 21:51:48.378036   904 solver.cpp:229] Iteration 5280, loss = 5.16667
I0604 21:51:48.378240   904 solver.cpp:245]     Train net output #0: loss = 5.13893 (* 1 = 5.13893 loss)
I0604 21:51:48.378252   904 sgd_solver.cpp:106] Iteration 5280, lr = 0.0387576
I0604 21:52:09.048957   904 solver.cpp:229] Iteration 5320, loss = 5.15359
I0604 21:52:09.049007   904 solver.cpp:245]     Train net output #0: loss = 4.81485 (* 1 = 4.81485 loss)
I0604 21:52:09.049016   904 sgd_solver.cpp:106] Iteration 5320, lr = 0.0387482
I0604 21:52:29.638352   904 solver.cpp:229] Iteration 5360, loss = 5.10706
I0604 21:52:29.638561   904 solver.cpp:245]     Train net output #0: loss = 5.22634 (* 1 = 5.22634 loss)
I0604 21:52:29.638599   904 sgd_solver.cpp:106] Iteration 5360, lr = 0.0387388
I0604 21:52:50.287713   904 solver.cpp:229] Iteration 5400, loss = 5.13975
I0604 21:52:50.287762   904 solver.cpp:245]     Train net output #0: loss = 4.88246 (* 1 = 4.88246 loss)
I0604 21:52:50.287771   904 sgd_solver.cpp:106] Iteration 5400, lr = 0.0387294
I0604 21:53:10.916486   904 solver.cpp:229] Iteration 5440, loss = 5.11416
I0604 21:53:10.916664   904 solver.cpp:245]     Train net output #0: loss = 5.01618 (* 1 = 5.01618 loss)
I0604 21:53:10.916697   904 sgd_solver.cpp:106] Iteration 5440, lr = 0.03872
I0604 21:53:31.515132   904 solver.cpp:229] Iteration 5480, loss = 5.11767
I0604 21:53:31.515200   904 solver.cpp:245]     Train net output #0: loss = 5.05189 (* 1 = 5.05189 loss)
I0604 21:53:31.515211   904 sgd_solver.cpp:106] Iteration 5480, lr = 0.0387106
I0604 21:53:52.026595   904 solver.cpp:229] Iteration 5520, loss = 5.10199
I0604 21:53:52.026803   904 solver.cpp:245]     Train net output #0: loss = 4.78802 (* 1 = 4.78802 loss)
I0604 21:53:52.026836   904 sgd_solver.cpp:106] Iteration 5520, lr = 0.0387012
I0604 21:54:12.516485   904 solver.cpp:229] Iteration 5560, loss = 5.09795
I0604 21:54:12.516533   904 solver.cpp:245]     Train net output #0: loss = 4.80503 (* 1 = 4.80503 loss)
I0604 21:54:12.516544   904 sgd_solver.cpp:106] Iteration 5560, lr = 0.0386918
I0604 21:54:33.112869   904 solver.cpp:229] Iteration 5600, loss = 5.1469
I0604 21:54:33.113054   904 solver.cpp:245]     Train net output #0: loss = 5.37101 (* 1 = 5.37101 loss)
I0604 21:54:33.113078   904 sgd_solver.cpp:106] Iteration 5600, lr = 0.0386824
I0604 21:54:53.741399   904 solver.cpp:229] Iteration 5640, loss = 5.18194
I0604 21:54:53.741446   904 solver.cpp:245]     Train net output #0: loss = 5.06025 (* 1 = 5.06025 loss)
I0604 21:54:53.741453   904 sgd_solver.cpp:106] Iteration 5640, lr = 0.0386729
I0604 21:55:14.075016   904 solver.cpp:229] Iteration 5680, loss = 5.05103
I0604 21:55:14.075218   904 solver.cpp:245]     Train net output #0: loss = 4.79452 (* 1 = 4.79452 loss)
I0604 21:55:14.075240   904 sgd_solver.cpp:106] Iteration 5680, lr = 0.0386635
I0604 21:55:34.530583   904 solver.cpp:229] Iteration 5720, loss = 5.06987
I0604 21:55:34.530613   904 solver.cpp:245]     Train net output #0: loss = 4.9056 (* 1 = 4.9056 loss)
I0604 21:55:34.530619   904 sgd_solver.cpp:106] Iteration 5720, lr = 0.0386541
I0604 21:55:55.142051   904 solver.cpp:229] Iteration 5760, loss = 5.03645
I0604 21:55:55.142287   904 solver.cpp:245]     Train net output #0: loss = 4.99862 (* 1 = 4.99862 loss)
I0604 21:55:55.142324   904 sgd_solver.cpp:106] Iteration 5760, lr = 0.0386447
I0604 21:55:56.935117   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0604 21:56:15.637140   904 solver.cpp:229] Iteration 5800, loss = 5.01833
I0604 21:56:15.637186   904 solver.cpp:245]     Train net output #0: loss = 5.08295 (* 1 = 5.08295 loss)
I0604 21:56:15.637195   904 sgd_solver.cpp:106] Iteration 5800, lr = 0.0386353
I0604 21:56:36.180716   904 solver.cpp:229] Iteration 5840, loss = 5.00328
I0604 21:56:36.180955   904 solver.cpp:245]     Train net output #0: loss = 5.05901 (* 1 = 5.05901 loss)
I0604 21:56:36.180981   904 sgd_solver.cpp:106] Iteration 5840, lr = 0.0386259
I0604 21:56:56.637536   904 solver.cpp:229] Iteration 5880, loss = 4.98533
I0604 21:56:56.637585   904 solver.cpp:245]     Train net output #0: loss = 4.74546 (* 1 = 4.74546 loss)
I0604 21:56:56.637594   904 sgd_solver.cpp:106] Iteration 5880, lr = 0.0386165
I0604 21:57:17.273634   904 solver.cpp:229] Iteration 5920, loss = 4.99132
I0604 21:57:17.273826   904 solver.cpp:245]     Train net output #0: loss = 5.03591 (* 1 = 5.03591 loss)
I0604 21:57:17.273855   904 sgd_solver.cpp:106] Iteration 5920, lr = 0.0386071
I0604 21:57:37.779189   904 solver.cpp:229] Iteration 5960, loss = 4.95948
I0604 21:57:37.779238   904 solver.cpp:245]     Train net output #0: loss = 4.85581 (* 1 = 4.85581 loss)
I0604 21:57:37.779247   904 sgd_solver.cpp:106] Iteration 5960, lr = 0.0385976
I0604 21:57:57.782812   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_6000.caffemodel
I0604 21:57:58.046105   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_6000.solverstate
I0604 21:57:58.124301   904 solver.cpp:338] Iteration 6000, Testing net (#0)
I0604 21:57:58.124406   904 net.cpp:748] Ignoring source layer loss
I0604 21:58:17.415717   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0604 21:58:50.992529   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0604 21:59:05.088475   904 solver.cpp:406]     Test net output #0: accuracy = 0.10488
I0604 21:59:05.088522   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.2623
I0604 21:59:05.401008   904 solver.cpp:229] Iteration 6000, loss = 4.98611
I0604 21:59:05.401051   904 solver.cpp:245]     Train net output #0: loss = 5.06448 (* 1 = 5.06448 loss)
I0604 21:59:05.401062   904 sgd_solver.cpp:106] Iteration 6000, lr = 0.0385882
I0604 21:59:24.647181   904 solver.cpp:229] Iteration 6040, loss = 4.93973
I0604 21:59:24.647356   904 solver.cpp:245]     Train net output #0: loss = 4.95036 (* 1 = 4.95036 loss)
I0604 21:59:24.647379   904 sgd_solver.cpp:106] Iteration 6040, lr = 0.0385788
I0604 21:59:46.104156   904 solver.cpp:229] Iteration 6080, loss = 4.92709
I0604 21:59:46.104197   904 solver.cpp:245]     Train net output #0: loss = 4.73414 (* 1 = 4.73414 loss)
I0604 21:59:46.104204   904 sgd_solver.cpp:106] Iteration 6080, lr = 0.0385694
I0604 22:00:07.606739   904 solver.cpp:229] Iteration 6120, loss = 4.90267
I0604 22:00:07.606914   904 solver.cpp:245]     Train net output #0: loss = 5.08827 (* 1 = 5.08827 loss)
I0604 22:00:07.606932   904 sgd_solver.cpp:106] Iteration 6120, lr = 0.03856
I0604 22:00:28.868103   904 solver.cpp:229] Iteration 6160, loss = 4.91181
I0604 22:00:28.868142   904 solver.cpp:245]     Train net output #0: loss = 4.79193 (* 1 = 4.79193 loss)
I0604 22:00:28.868162   904 sgd_solver.cpp:106] Iteration 6160, lr = 0.0385506
I0604 22:00:49.869156   904 solver.cpp:229] Iteration 6200, loss = 4.89065
I0604 22:00:49.869369   904 solver.cpp:245]     Train net output #0: loss = 4.86922 (* 1 = 4.86922 loss)
I0604 22:00:49.869402   904 sgd_solver.cpp:106] Iteration 6200, lr = 0.0385412
I0604 22:01:10.969691   904 solver.cpp:229] Iteration 6240, loss = 4.90129
I0604 22:01:10.969743   904 solver.cpp:245]     Train net output #0: loss = 5.01377 (* 1 = 5.01377 loss)
I0604 22:01:10.969763   904 sgd_solver.cpp:106] Iteration 6240, lr = 0.0385318
I0604 22:01:32.006176   904 solver.cpp:229] Iteration 6280, loss = 4.85712
I0604 22:01:32.006351   904 solver.cpp:245]     Train net output #0: loss = 4.81227 (* 1 = 4.81227 loss)
I0604 22:01:32.006378   904 sgd_solver.cpp:106] Iteration 6280, lr = 0.0385224
I0604 22:01:52.950996   904 solver.cpp:229] Iteration 6320, loss = 4.90029
I0604 22:01:52.951045   904 solver.cpp:245]     Train net output #0: loss = 4.93122 (* 1 = 4.93122 loss)
I0604 22:01:52.951055   904 sgd_solver.cpp:106] Iteration 6320, lr = 0.0385129
I0604 22:01:59.503851   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0604 22:02:13.921531   904 solver.cpp:229] Iteration 6360, loss = 4.89995
I0604 22:02:13.921772   904 solver.cpp:245]     Train net output #0: loss = 4.74556 (* 1 = 4.74556 loss)
I0604 22:02:13.921811   904 sgd_solver.cpp:106] Iteration 6360, lr = 0.0385035
I0604 22:02:34.709777   904 solver.cpp:229] Iteration 6400, loss = 4.85935
I0604 22:02:34.709859   904 solver.cpp:245]     Train net output #0: loss = 4.89227 (* 1 = 4.89227 loss)
I0604 22:02:34.709869   904 sgd_solver.cpp:106] Iteration 6400, lr = 0.0384941
I0604 22:02:55.457861   904 solver.cpp:229] Iteration 6440, loss = 4.88076
I0604 22:02:55.458029   904 solver.cpp:245]     Train net output #0: loss = 4.87217 (* 1 = 4.87217 loss)
I0604 22:02:55.458039   904 sgd_solver.cpp:106] Iteration 6440, lr = 0.0384847
I0604 22:03:16.101634   904 solver.cpp:229] Iteration 6480, loss = 4.85316
I0604 22:03:16.101675   904 solver.cpp:245]     Train net output #0: loss = 4.95197 (* 1 = 4.95197 loss)
I0604 22:03:16.101680   904 sgd_solver.cpp:106] Iteration 6480, lr = 0.0384753
I0604 22:03:36.759738   904 solver.cpp:229] Iteration 6520, loss = 4.84586
I0604 22:03:36.759925   904 solver.cpp:245]     Train net output #0: loss = 4.95274 (* 1 = 4.95274 loss)
I0604 22:03:36.759948   904 sgd_solver.cpp:106] Iteration 6520, lr = 0.0384659
I0604 22:03:57.420969   904 solver.cpp:229] Iteration 6560, loss = 4.81234
I0604 22:03:57.421015   904 solver.cpp:245]     Train net output #0: loss = 4.84277 (* 1 = 4.84277 loss)
I0604 22:03:57.421026   904 sgd_solver.cpp:106] Iteration 6560, lr = 0.0384565
I0604 22:04:18.059171   904 solver.cpp:229] Iteration 6600, loss = 4.8231
I0604 22:04:18.059365   904 solver.cpp:245]     Train net output #0: loss = 4.94752 (* 1 = 4.94752 loss)
I0604 22:04:18.059391   904 sgd_solver.cpp:106] Iteration 6600, lr = 0.0384471
I0604 22:04:38.515779   904 solver.cpp:229] Iteration 6640, loss = 4.81426
I0604 22:04:38.515830   904 solver.cpp:245]     Train net output #0: loss = 4.81973 (* 1 = 4.81973 loss)
I0604 22:04:38.515837   904 sgd_solver.cpp:106] Iteration 6640, lr = 0.0384376
I0604 22:04:59.008872   904 solver.cpp:229] Iteration 6680, loss = 4.86944
I0604 22:04:59.009057   904 solver.cpp:245]     Train net output #0: loss = 5.16178 (* 1 = 5.16178 loss)
I0604 22:04:59.009081   904 sgd_solver.cpp:106] Iteration 6680, lr = 0.0384282
I0604 22:05:19.479933   904 solver.cpp:229] Iteration 6720, loss = 4.77768
I0604 22:05:19.479992   904 solver.cpp:245]     Train net output #0: loss = 4.63505 (* 1 = 4.63505 loss)
I0604 22:05:19.480003   904 sgd_solver.cpp:106] Iteration 6720, lr = 0.0384188
I0604 22:05:39.937847   904 solver.cpp:229] Iteration 6760, loss = 4.77562
I0604 22:05:39.938036   904 solver.cpp:245]     Train net output #0: loss = 4.76662 (* 1 = 4.76662 loss)
I0604 22:05:39.938067   904 sgd_solver.cpp:106] Iteration 6760, lr = 0.0384094
I0604 22:06:00.400069   904 solver.cpp:229] Iteration 6800, loss = 4.86004
I0604 22:06:00.400117   904 solver.cpp:245]     Train net output #0: loss = 4.67024 (* 1 = 4.67024 loss)
I0604 22:06:00.400125   904 sgd_solver.cpp:106] Iteration 6800, lr = 0.0384
I0604 22:06:20.878281   904 solver.cpp:229] Iteration 6840, loss = 4.75611
I0604 22:06:20.878479   904 solver.cpp:245]     Train net output #0: loss = 4.58626 (* 1 = 4.58626 loss)
I0604 22:06:20.878506   904 sgd_solver.cpp:106] Iteration 6840, lr = 0.0383906
I0604 22:06:32.648130   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0604 22:06:41.360584   904 solver.cpp:229] Iteration 6880, loss = 4.82383
I0604 22:06:41.360649   904 solver.cpp:245]     Train net output #0: loss = 4.53235 (* 1 = 4.53235 loss)
I0604 22:06:41.360663   904 sgd_solver.cpp:106] Iteration 6880, lr = 0.0383812
I0604 22:07:01.707939   904 solver.cpp:229] Iteration 6920, loss = 4.75345
I0604 22:07:01.708158   904 solver.cpp:245]     Train net output #0: loss = 4.65186 (* 1 = 4.65186 loss)
I0604 22:07:01.708183   904 sgd_solver.cpp:106] Iteration 6920, lr = 0.0383718
I0604 22:07:21.997156   904 solver.cpp:229] Iteration 6960, loss = 4.84261
I0604 22:07:21.997208   904 solver.cpp:245]     Train net output #0: loss = 4.8798 (* 1 = 4.8798 loss)
I0604 22:07:21.997216   904 sgd_solver.cpp:106] Iteration 6960, lr = 0.0383624
I0604 22:07:41.755937   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_7000.caffemodel
I0604 22:07:42.023537   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_7000.solverstate
I0604 22:07:42.104987   904 solver.cpp:338] Iteration 7000, Testing net (#0)
I0604 22:07:42.105063   904 net.cpp:748] Ignoring source layer loss
I0604 22:08:06.499673   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0604 22:08:38.865550   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0604 22:08:46.683373   904 solver.cpp:406]     Test net output #0: accuracy = 0.1194
I0604 22:08:46.683416   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.28798
I0604 22:08:46.996426   904 solver.cpp:229] Iteration 7000, loss = 4.76223
I0604 22:08:46.996475   904 solver.cpp:245]     Train net output #0: loss = 4.57756 (* 1 = 4.57756 loss)
I0604 22:08:46.996484   904 sgd_solver.cpp:106] Iteration 7000, lr = 0.0383529
I0604 22:09:06.183512   904 solver.cpp:229] Iteration 7040, loss = 4.73324
I0604 22:09:06.183560   904 solver.cpp:245]     Train net output #0: loss = 4.6232 (* 1 = 4.6232 loss)
I0604 22:09:06.183569   904 sgd_solver.cpp:106] Iteration 7040, lr = 0.0383435
I0604 22:09:27.534162   904 solver.cpp:229] Iteration 7080, loss = 4.68794
I0604 22:09:27.534334   904 solver.cpp:245]     Train net output #0: loss = 4.96312 (* 1 = 4.96312 loss)
I0604 22:09:27.534344   904 sgd_solver.cpp:106] Iteration 7080, lr = 0.0383341
I0604 22:09:49.041856   904 solver.cpp:229] Iteration 7120, loss = 4.74732
I0604 22:09:49.041919   904 solver.cpp:245]     Train net output #0: loss = 4.67286 (* 1 = 4.67286 loss)
I0604 22:09:49.041932   904 sgd_solver.cpp:106] Iteration 7120, lr = 0.0383247
I0604 22:10:10.190342   904 solver.cpp:229] Iteration 7160, loss = 4.67955
I0604 22:10:10.190503   904 solver.cpp:245]     Train net output #0: loss = 4.66243 (* 1 = 4.66243 loss)
I0604 22:10:10.190513   904 sgd_solver.cpp:106] Iteration 7160, lr = 0.0383153
I0604 22:10:31.171270   904 solver.cpp:229] Iteration 7200, loss = 4.72171
I0604 22:10:31.171329   904 solver.cpp:245]     Train net output #0: loss = 4.67216 (* 1 = 4.67216 loss)
I0604 22:10:31.171339   904 sgd_solver.cpp:106] Iteration 7200, lr = 0.0383059
I0604 22:10:52.131824   904 solver.cpp:229] Iteration 7240, loss = 4.67171
I0604 22:10:52.132020   904 solver.cpp:245]     Train net output #0: loss = 4.9889 (* 1 = 4.9889 loss)
I0604 22:10:52.132046   904 sgd_solver.cpp:106] Iteration 7240, lr = 0.0382965
I0604 22:11:13.090031   904 solver.cpp:229] Iteration 7280, loss = 4.68882
I0604 22:11:13.090088   904 solver.cpp:245]     Train net output #0: loss = 4.94184 (* 1 = 4.94184 loss)
I0604 22:11:13.090102   904 sgd_solver.cpp:106] Iteration 7280, lr = 0.0382871
I0604 22:11:33.909750   904 solver.cpp:229] Iteration 7320, loss = 4.63742
I0604 22:11:33.909937   904 solver.cpp:245]     Train net output #0: loss = 4.39593 (* 1 = 4.39593 loss)
I0604 22:11:33.909957   904 sgd_solver.cpp:106] Iteration 7320, lr = 0.0382776
I0604 22:11:54.713959   904 solver.cpp:229] Iteration 7360, loss = 4.63311
I0604 22:11:54.714017   904 solver.cpp:245]     Train net output #0: loss = 4.45816 (* 1 = 4.45816 loss)
I0604 22:11:54.714030   904 sgd_solver.cpp:106] Iteration 7360, lr = 0.0382682
I0604 22:12:15.394179   904 solver.cpp:229] Iteration 7400, loss = 4.66121
I0604 22:12:15.394397   904 solver.cpp:245]     Train net output #0: loss = 4.72408 (* 1 = 4.72408 loss)
I0604 22:12:15.394419   904 sgd_solver.cpp:106] Iteration 7400, lr = 0.0382588
I0604 22:12:36.047366   904 solver.cpp:229] Iteration 7440, loss = 4.61535
I0604 22:12:36.047417   904 solver.cpp:245]     Train net output #0: loss = 4.58876 (* 1 = 4.58876 loss)
I0604 22:12:36.047426   904 sgd_solver.cpp:106] Iteration 7440, lr = 0.0382494
I0604 22:12:45.353888   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0604 22:12:56.660125   904 solver.cpp:229] Iteration 7480, loss = 4.63146
I0604 22:12:56.660416   904 solver.cpp:245]     Train net output #0: loss = 4.61564 (* 1 = 4.61564 loss)
I0604 22:12:56.660442   904 sgd_solver.cpp:106] Iteration 7480, lr = 0.03824
I0604 22:13:17.216162   904 solver.cpp:229] Iteration 7520, loss = 4.64473
I0604 22:13:17.216210   904 solver.cpp:245]     Train net output #0: loss = 4.43783 (* 1 = 4.43783 loss)
I0604 22:13:17.216222   904 sgd_solver.cpp:106] Iteration 7520, lr = 0.0382306
I0604 22:13:37.890530   904 solver.cpp:229] Iteration 7560, loss = 4.63433
I0604 22:13:37.890744   904 solver.cpp:245]     Train net output #0: loss = 4.80734 (* 1 = 4.80734 loss)
I0604 22:13:37.890772   904 sgd_solver.cpp:106] Iteration 7560, lr = 0.0382212
I0604 22:13:58.425931   904 solver.cpp:229] Iteration 7600, loss = 4.6057
I0604 22:13:58.425971   904 solver.cpp:245]     Train net output #0: loss = 4.4326 (* 1 = 4.4326 loss)
I0604 22:13:58.425979   904 sgd_solver.cpp:106] Iteration 7600, lr = 0.0382118
I0604 22:14:18.868739   904 solver.cpp:229] Iteration 7640, loss = 4.61982
I0604 22:14:18.868891   904 solver.cpp:245]     Train net output #0: loss = 4.80641 (* 1 = 4.80641 loss)
I0604 22:14:18.868901   904 sgd_solver.cpp:106] Iteration 7640, lr = 0.0382024
I0604 22:14:39.260881   904 solver.cpp:229] Iteration 7680, loss = 4.58439
I0604 22:14:39.260931   904 solver.cpp:245]     Train net output #0: loss = 4.56007 (* 1 = 4.56007 loss)
I0604 22:14:39.260941   904 sgd_solver.cpp:106] Iteration 7680, lr = 0.0381929
I0604 22:14:59.757176   904 solver.cpp:229] Iteration 7720, loss = 4.57729
I0604 22:14:59.757321   904 solver.cpp:245]     Train net output #0: loss = 4.56937 (* 1 = 4.56937 loss)
I0604 22:14:59.757334   904 sgd_solver.cpp:106] Iteration 7720, lr = 0.0381835
I0604 22:15:20.263209   904 solver.cpp:229] Iteration 7760, loss = 4.67353
I0604 22:15:20.263253   904 solver.cpp:245]     Train net output #0: loss = 4.82003 (* 1 = 4.82003 loss)
I0604 22:15:20.263265   904 sgd_solver.cpp:106] Iteration 7760, lr = 0.0381741
I0604 22:15:40.765938   904 solver.cpp:229] Iteration 7800, loss = 4.68911
I0604 22:15:40.766162   904 solver.cpp:245]     Train net output #0: loss = 4.92467 (* 1 = 4.92467 loss)
I0604 22:15:40.766191   904 sgd_solver.cpp:106] Iteration 7800, lr = 0.0381647
I0604 22:16:01.177093   904 solver.cpp:229] Iteration 7840, loss = 4.61815
I0604 22:16:01.177146   904 solver.cpp:245]     Train net output #0: loss = 4.41395 (* 1 = 4.41395 loss)
I0604 22:16:01.177155   904 sgd_solver.cpp:106] Iteration 7840, lr = 0.0381553
I0604 22:16:21.356127   904 solver.cpp:229] Iteration 7880, loss = 4.5143
I0604 22:16:21.356272   904 solver.cpp:245]     Train net output #0: loss = 4.64546 (* 1 = 4.64546 loss)
I0604 22:16:21.356282   904 sgd_solver.cpp:106] Iteration 7880, lr = 0.0381459
I0604 22:16:41.776862   904 solver.cpp:229] Iteration 7920, loss = 4.54563
I0604 22:16:41.776904   904 solver.cpp:245]     Train net output #0: loss = 4.53562 (* 1 = 4.53562 loss)
I0604 22:16:41.776913   904 sgd_solver.cpp:106] Iteration 7920, lr = 0.0381365
I0604 22:17:02.231626   904 solver.cpp:229] Iteration 7960, loss = 4.59327
I0604 22:17:02.231822   904 solver.cpp:245]     Train net output #0: loss = 4.78713 (* 1 = 4.78713 loss)
I0604 22:17:02.231851   904 sgd_solver.cpp:106] Iteration 7960, lr = 0.0381271
I0604 22:17:21.877787   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_8000.caffemodel
I0604 22:17:22.143537   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_8000.solverstate
I0604 22:17:22.228957   904 solver.cpp:338] Iteration 8000, Testing net (#0)
I0604 22:17:22.229040   904 net.cpp:748] Ignoring source layer loss
I0604 22:17:24.655021   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0604 22:17:59.000406   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0604 22:18:30.570541   904 solver.cpp:406]     Test net output #0: accuracy = 0.15006
I0604 22:18:30.570725   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.336281
I0604 22:18:30.887475   904 solver.cpp:229] Iteration 8000, loss = 4.55619
I0604 22:18:30.887511   904 solver.cpp:245]     Train net output #0: loss = 4.77745 (* 1 = 4.77745 loss)
I0604 22:18:30.887521   904 sgd_solver.cpp:106] Iteration 8000, lr = 0.0381176
I0604 22:18:48.374886   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0604 22:18:50.059273   904 solver.cpp:229] Iteration 8040, loss = 4.52774
I0604 22:18:50.059320   904 solver.cpp:245]     Train net output #0: loss = 4.43981 (* 1 = 4.43981 loss)
I0604 22:18:50.059329   904 sgd_solver.cpp:106] Iteration 8040, lr = 0.0381082
I0604 22:19:11.390321   904 solver.cpp:229] Iteration 8080, loss = 4.57713
I0604 22:19:11.390497   904 solver.cpp:245]     Train net output #0: loss = 4.76786 (* 1 = 4.76786 loss)
I0604 22:19:11.390525   904 sgd_solver.cpp:106] Iteration 8080, lr = 0.0380988
I0604 22:19:32.874817   904 solver.cpp:229] Iteration 8120, loss = 4.5121
I0604 22:19:32.874873   904 solver.cpp:245]     Train net output #0: loss = 4.38982 (* 1 = 4.38982 loss)
I0604 22:19:32.874883   904 sgd_solver.cpp:106] Iteration 8120, lr = 0.0380894
I0604 22:19:54.004637   904 solver.cpp:229] Iteration 8160, loss = 4.54454
I0604 22:19:54.004835   904 solver.cpp:245]     Train net output #0: loss = 4.49864 (* 1 = 4.49864 loss)
I0604 22:19:54.004860   904 sgd_solver.cpp:106] Iteration 8160, lr = 0.03808
I0604 22:20:14.913110   904 solver.cpp:229] Iteration 8200, loss = 4.48942
I0604 22:20:14.913158   904 solver.cpp:245]     Train net output #0: loss = 4.45022 (* 1 = 4.45022 loss)
I0604 22:20:14.913167   904 sgd_solver.cpp:106] Iteration 8200, lr = 0.0380706
I0604 22:20:35.912009   904 solver.cpp:229] Iteration 8240, loss = 4.52989
I0604 22:20:35.912225   904 solver.cpp:245]     Train net output #0: loss = 4.4681 (* 1 = 4.4681 loss)
I0604 22:20:35.912276   904 sgd_solver.cpp:106] Iteration 8240, lr = 0.0380612
I0604 22:20:56.926163   904 solver.cpp:229] Iteration 8280, loss = 4.48378
I0604 22:20:56.926219   904 solver.cpp:245]     Train net output #0: loss = 4.55654 (* 1 = 4.55654 loss)
I0604 22:20:56.926234   904 sgd_solver.cpp:106] Iteration 8280, lr = 0.0380518
I0604 22:21:17.684666   904 solver.cpp:229] Iteration 8320, loss = 4.49673
I0604 22:21:17.684892   904 solver.cpp:245]     Train net output #0: loss = 4.32991 (* 1 = 4.32991 loss)
I0604 22:21:17.684917   904 sgd_solver.cpp:106] Iteration 8320, lr = 0.0380424
I0604 22:21:38.430879   904 solver.cpp:229] Iteration 8360, loss = 4.45391
I0604 22:21:38.430945   904 solver.cpp:245]     Train net output #0: loss = 4.39045 (* 1 = 4.39045 loss)
I0604 22:21:38.430958   904 sgd_solver.cpp:106] Iteration 8360, lr = 0.0380329
I0604 22:21:59.177451   904 solver.cpp:229] Iteration 8400, loss = 4.4625
I0604 22:21:59.177567   904 solver.cpp:245]     Train net output #0: loss = 4.41929 (* 1 = 4.41929 loss)
I0604 22:21:59.177577   904 sgd_solver.cpp:106] Iteration 8400, lr = 0.0380235
I0604 22:22:19.927707   904 solver.cpp:229] Iteration 8440, loss = 4.43085
I0604 22:22:19.927747   904 solver.cpp:245]     Train net output #0: loss = 4.27829 (* 1 = 4.27829 loss)
I0604 22:22:19.927757   904 sgd_solver.cpp:106] Iteration 8440, lr = 0.0380141
I0604 22:22:40.651232   904 solver.cpp:229] Iteration 8480, loss = 4.45686
I0604 22:22:40.651393   904 solver.cpp:245]     Train net output #0: loss = 4.31001 (* 1 = 4.31001 loss)
I0604 22:22:40.651424   904 sgd_solver.cpp:106] Iteration 8480, lr = 0.0380047
I0604 22:23:01.321076   904 solver.cpp:229] Iteration 8520, loss = 4.45983
I0604 22:23:01.321130   904 solver.cpp:245]     Train net output #0: loss = 4.42482 (* 1 = 4.42482 loss)
I0604 22:23:01.321141   904 sgd_solver.cpp:106] Iteration 8520, lr = 0.0379953
I0604 22:23:12.913498   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0604 22:23:21.924187   904 solver.cpp:229] Iteration 8560, loss = 4.43197
I0604 22:23:21.924237   904 solver.cpp:245]     Train net output #0: loss = 4.40357 (* 1 = 4.40357 loss)
I0604 22:23:21.924247   904 sgd_solver.cpp:106] Iteration 8560, lr = 0.0379859
I0604 22:23:42.509559   904 solver.cpp:229] Iteration 8600, loss = 4.41627
I0604 22:23:42.509610   904 solver.cpp:245]     Train net output #0: loss = 4.72977 (* 1 = 4.72977 loss)
I0604 22:23:42.509619   904 sgd_solver.cpp:106] Iteration 8600, lr = 0.0379765
I0604 22:24:03.111520   904 solver.cpp:229] Iteration 8640, loss = 4.43285
I0604 22:24:03.111717   904 solver.cpp:245]     Train net output #0: loss = 4.47615 (* 1 = 4.47615 loss)
I0604 22:24:03.111744   904 sgd_solver.cpp:106] Iteration 8640, lr = 0.0379671
I0604 22:24:23.706861   904 solver.cpp:229] Iteration 8680, loss = 4.4992
I0604 22:24:23.706899   904 solver.cpp:245]     Train net output #0: loss = 4.29532 (* 1 = 4.29532 loss)
I0604 22:24:23.706907   904 sgd_solver.cpp:106] Iteration 8680, lr = 0.0379576
I0604 22:24:44.178211   904 solver.cpp:229] Iteration 8720, loss = 4.45717
I0604 22:24:44.178383   904 solver.cpp:245]     Train net output #0: loss = 4.32106 (* 1 = 4.32106 loss)
I0604 22:24:44.178411   904 sgd_solver.cpp:106] Iteration 8720, lr = 0.0379482
I0604 22:25:04.742636   904 solver.cpp:229] Iteration 8760, loss = 4.39295
I0604 22:25:04.742684   904 solver.cpp:245]     Train net output #0: loss = 4.35312 (* 1 = 4.35312 loss)
I0604 22:25:04.742694   904 sgd_solver.cpp:106] Iteration 8760, lr = 0.0379388
I0604 22:25:25.175307   904 solver.cpp:229] Iteration 8800, loss = 4.41646
I0604 22:25:25.175494   904 solver.cpp:245]     Train net output #0: loss = 4.43573 (* 1 = 4.43573 loss)
I0604 22:25:25.175504   904 sgd_solver.cpp:106] Iteration 8800, lr = 0.0379294
I0604 22:25:45.707662   904 solver.cpp:229] Iteration 8840, loss = 4.41431
I0604 22:25:45.707706   904 solver.cpp:245]     Train net output #0: loss = 4.32869 (* 1 = 4.32869 loss)
I0604 22:25:45.707717   904 sgd_solver.cpp:106] Iteration 8840, lr = 0.03792
I0604 22:26:06.258471   904 solver.cpp:229] Iteration 8880, loss = 4.40126
I0604 22:26:06.258689   904 solver.cpp:245]     Train net output #0: loss = 4.48636 (* 1 = 4.48636 loss)
I0604 22:26:06.258723   904 sgd_solver.cpp:106] Iteration 8880, lr = 0.0379106
I0604 22:26:26.739012   904 solver.cpp:229] Iteration 8920, loss = 4.348
I0604 22:26:26.739051   904 solver.cpp:245]     Train net output #0: loss = 4.32184 (* 1 = 4.32184 loss)
I0604 22:26:26.739058   904 sgd_solver.cpp:106] Iteration 8920, lr = 0.0379012
I0604 22:26:47.157320   904 solver.cpp:229] Iteration 8960, loss = 4.41321
I0604 22:26:47.157513   904 solver.cpp:245]     Train net output #0: loss = 4.46697 (* 1 = 4.46697 loss)
I0604 22:26:47.157538   904 sgd_solver.cpp:106] Iteration 8960, lr = 0.0378918
I0604 22:27:07.184149   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_9000.caffemodel
I0604 22:27:07.448074   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_9000.solverstate
I0604 22:27:07.527390   904 solver.cpp:338] Iteration 9000, Testing net (#0)
I0604 22:27:07.527474   904 net.cpp:748] Ignoring source layer loss
I0604 22:27:10.707016   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0604 22:27:45.005739   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0604 22:28:15.529000   904 solver.cpp:406]     Test net output #0: accuracy = 0.17154
I0604 22:28:15.529125   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.371601
I0604 22:28:15.844959   904 solver.cpp:229] Iteration 9000, loss = 4.45184
I0604 22:28:15.844997   904 solver.cpp:245]     Train net output #0: loss = 4.33628 (* 1 = 4.33628 loss)
I0604 22:28:15.845006   904 sgd_solver.cpp:106] Iteration 9000, lr = 0.0378824
I0604 22:28:35.123090   904 solver.cpp:229] Iteration 9040, loss = 4.37066
I0604 22:28:35.123131   904 solver.cpp:245]     Train net output #0: loss = 4.2214 (* 1 = 4.2214 loss)
I0604 22:28:35.123139   904 sgd_solver.cpp:106] Iteration 9040, lr = 0.0378729
I0604 22:28:39.393753   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0604 22:28:56.619420   904 solver.cpp:229] Iteration 9080, loss = 4.37732
I0604 22:28:56.619709   904 solver.cpp:245]     Train net output #0: loss = 4.23021 (* 1 = 4.23021 loss)
I0604 22:28:56.619736   904 sgd_solver.cpp:106] Iteration 9080, lr = 0.0378635
I0604 22:29:18.170667   904 solver.cpp:229] Iteration 9120, loss = 4.42985
I0604 22:29:18.170711   904 solver.cpp:245]     Train net output #0: loss = 4.40937 (* 1 = 4.40937 loss)
I0604 22:29:18.170720   904 sgd_solver.cpp:106] Iteration 9120, lr = 0.0378541
I0604 22:29:39.539613   904 solver.cpp:229] Iteration 9160, loss = 4.34004
I0604 22:29:39.539855   904 solver.cpp:245]     Train net output #0: loss = 4.23751 (* 1 = 4.23751 loss)
I0604 22:29:39.539883   904 sgd_solver.cpp:106] Iteration 9160, lr = 0.0378447
I0604 22:30:00.545351   904 solver.cpp:229] Iteration 9200, loss = 4.40123
I0604 22:30:00.545403   904 solver.cpp:245]     Train net output #0: loss = 4.20144 (* 1 = 4.20144 loss)
I0604 22:30:00.545414   904 sgd_solver.cpp:106] Iteration 9200, lr = 0.0378353
I0604 22:30:21.542757   904 solver.cpp:229] Iteration 9240, loss = 4.35825
I0604 22:30:21.542954   904 solver.cpp:245]     Train net output #0: loss = 4.33524 (* 1 = 4.33524 loss)
I0604 22:30:21.542966   904 sgd_solver.cpp:106] Iteration 9240, lr = 0.0378259
I0604 22:30:42.553566   904 solver.cpp:229] Iteration 9280, loss = 4.32743
I0604 22:30:42.553618   904 solver.cpp:245]     Train net output #0: loss = 4.24371 (* 1 = 4.24371 loss)
I0604 22:30:42.553632   904 sgd_solver.cpp:106] Iteration 9280, lr = 0.0378165
I0604 22:31:03.549348   904 solver.cpp:229] Iteration 9320, loss = 4.32846
I0604 22:31:03.549538   904 solver.cpp:245]     Train net output #0: loss = 4.29138 (* 1 = 4.29138 loss)
I0604 22:31:03.549566   904 sgd_solver.cpp:106] Iteration 9320, lr = 0.0378071
I0604 22:31:24.472614   904 solver.cpp:229] Iteration 9360, loss = 4.30151
I0604 22:31:24.472666   904 solver.cpp:245]     Train net output #0: loss = 4.59401 (* 1 = 4.59401 loss)
I0604 22:31:24.472676   904 sgd_solver.cpp:106] Iteration 9360, lr = 0.0377976
I0604 22:31:45.149613   904 solver.cpp:229] Iteration 9400, loss = 4.28219
I0604 22:31:45.149822   904 solver.cpp:245]     Train net output #0: loss = 4.07604 (* 1 = 4.07604 loss)
I0604 22:31:45.149852   904 sgd_solver.cpp:106] Iteration 9400, lr = 0.0377882
I0604 22:32:05.831805   904 solver.cpp:229] Iteration 9440, loss = 4.26863
I0604 22:32:05.831861   904 solver.cpp:245]     Train net output #0: loss = 4.04977 (* 1 = 4.04977 loss)
I0604 22:32:05.831871   904 sgd_solver.cpp:106] Iteration 9440, lr = 0.0377788
I0604 22:32:26.513684   904 solver.cpp:229] Iteration 9480, loss = 4.26308
I0604 22:32:26.513890   904 solver.cpp:245]     Train net output #0: loss = 4.00661 (* 1 = 4.00661 loss)
I0604 22:32:26.513917   904 sgd_solver.cpp:106] Iteration 9480, lr = 0.0377694
I0604 22:32:47.208405   904 solver.cpp:229] Iteration 9520, loss = 4.26438
I0604 22:32:47.208447   904 solver.cpp:245]     Train net output #0: loss = 4.35054 (* 1 = 4.35054 loss)
I0604 22:32:47.208456   904 sgd_solver.cpp:106] Iteration 9520, lr = 0.03776
I0604 22:33:02.427577   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0604 22:33:07.799425   904 solver.cpp:229] Iteration 9560, loss = 4.316
I0604 22:33:07.799479   904 solver.cpp:245]     Train net output #0: loss = 4.25693 (* 1 = 4.25693 loss)
I0604 22:33:07.799489   904 sgd_solver.cpp:106] Iteration 9560, lr = 0.0377506
I0604 22:33:28.300420   904 solver.cpp:229] Iteration 9600, loss = 4.27733
I0604 22:33:28.300459   904 solver.cpp:245]     Train net output #0: loss = 4.36207 (* 1 = 4.36207 loss)
I0604 22:33:28.300468   904 sgd_solver.cpp:106] Iteration 9600, lr = 0.0377412
I0604 22:33:48.938576   904 solver.cpp:229] Iteration 9640, loss = 4.32097
I0604 22:33:48.938762   904 solver.cpp:245]     Train net output #0: loss = 4.95761 (* 1 = 4.95761 loss)
I0604 22:33:48.938789   904 sgd_solver.cpp:106] Iteration 9640, lr = 0.0377318
I0604 22:34:09.515933   904 solver.cpp:229] Iteration 9680, loss = 4.50888
I0604 22:34:09.515982   904 solver.cpp:245]     Train net output #0: loss = 4.28638 (* 1 = 4.28638 loss)
I0604 22:34:09.515993   904 sgd_solver.cpp:106] Iteration 9680, lr = 0.0377224
I0604 22:34:30.041247   904 solver.cpp:229] Iteration 9720, loss = 4.27012
I0604 22:34:30.041422   904 solver.cpp:245]     Train net output #0: loss = 4.03446 (* 1 = 4.03446 loss)
I0604 22:34:30.041435   904 sgd_solver.cpp:106] Iteration 9720, lr = 0.0377129
I0604 22:34:50.581408   904 solver.cpp:229] Iteration 9760, loss = 4.2945
I0604 22:34:50.581446   904 solver.cpp:245]     Train net output #0: loss = 4.18931 (* 1 = 4.18931 loss)
I0604 22:34:50.581457   904 sgd_solver.cpp:106] Iteration 9760, lr = 0.0377035
I0604 22:35:11.107831   904 solver.cpp:229] Iteration 9800, loss = 4.27297
I0604 22:35:11.107936   904 solver.cpp:245]     Train net output #0: loss = 4.26483 (* 1 = 4.26483 loss)
I0604 22:35:11.107944   904 sgd_solver.cpp:106] Iteration 9800, lr = 0.0376941
I0604 22:35:31.607463   904 solver.cpp:229] Iteration 9840, loss = 4.24378
I0604 22:35:31.607517   904 solver.cpp:245]     Train net output #0: loss = 4.18005 (* 1 = 4.18005 loss)
I0604 22:35:31.607530   904 sgd_solver.cpp:106] Iteration 9840, lr = 0.0376847
I0604 22:35:52.131003   904 solver.cpp:229] Iteration 9880, loss = 4.24718
I0604 22:35:52.131171   904 solver.cpp:245]     Train net output #0: loss = 4.16389 (* 1 = 4.16389 loss)
I0604 22:35:52.131182   904 sgd_solver.cpp:106] Iteration 9880, lr = 0.0376753
I0604 22:36:12.438848   904 solver.cpp:229] Iteration 9920, loss = 4.2632
I0604 22:36:12.438902   904 solver.cpp:245]     Train net output #0: loss = 4.31009 (* 1 = 4.31009 loss)
I0604 22:36:12.438912   904 sgd_solver.cpp:106] Iteration 9920, lr = 0.0376659
I0604 22:36:32.741425   904 solver.cpp:229] Iteration 9960, loss = 4.2774
I0604 22:36:32.741605   904 solver.cpp:245]     Train net output #0: loss = 4.18654 (* 1 = 4.18654 loss)
I0604 22:36:32.741636   904 sgd_solver.cpp:106] Iteration 9960, lr = 0.0376565
I0604 22:36:52.527227   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_10000.caffemodel
I0604 22:36:52.792199   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_10000.solverstate
I0604 22:36:52.873462   904 solver.cpp:338] Iteration 10000, Testing net (#0)
I0604 22:36:52.873539   904 net.cpp:748] Ignoring source layer loss
I0604 22:36:56.508185   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0604 22:37:29.145668   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0604 22:37:58.368983   904 solver.cpp:406]     Test net output #0: accuracy = 0.19566
I0604 22:37:58.369067   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.406061
I0604 22:37:58.683434   904 solver.cpp:229] Iteration 10000, loss = 4.25373
I0604 22:37:58.683509   904 solver.cpp:245]     Train net output #0: loss = 4.16516 (* 1 = 4.16516 loss)
I0604 22:37:58.683523   904 sgd_solver.cpp:106] Iteration 10000, lr = 0.0376471
I0604 22:38:17.875082   904 solver.cpp:229] Iteration 10040, loss = 4.22781
I0604 22:38:17.875417   904 solver.cpp:245]     Train net output #0: loss = 4.34302 (* 1 = 4.34302 loss)
I0604 22:38:17.875479   904 sgd_solver.cpp:106] Iteration 10040, lr = 0.0376376
I0604 22:38:26.771924   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0604 22:38:38.373452   904 solver.cpp:229] Iteration 10080, loss = 4.2273
I0604 22:38:38.373502   904 solver.cpp:245]     Train net output #0: loss = 4.34157 (* 1 = 4.34157 loss)
I0604 22:38:38.373512   904 sgd_solver.cpp:106] Iteration 10080, lr = 0.0376282
I0604 22:38:59.297226   904 solver.cpp:229] Iteration 10120, loss = 4.22556
I0604 22:38:59.297396   904 solver.cpp:245]     Train net output #0: loss = 4.3555 (* 1 = 4.3555 loss)
I0604 22:38:59.297410   904 sgd_solver.cpp:106] Iteration 10120, lr = 0.0376188
I0604 22:39:19.896450   904 solver.cpp:229] Iteration 10160, loss = 4.23266
I0604 22:39:19.896504   904 solver.cpp:245]     Train net output #0: loss = 4.29271 (* 1 = 4.29271 loss)
I0604 22:39:19.896514   904 sgd_solver.cpp:106] Iteration 10160, lr = 0.0376094
I0604 22:39:40.395519   904 solver.cpp:229] Iteration 10200, loss = 4.22038
I0604 22:39:40.395777   904 solver.cpp:245]     Train net output #0: loss = 4.00823 (* 1 = 4.00823 loss)
I0604 22:39:40.395788   904 sgd_solver.cpp:106] Iteration 10200, lr = 0.0376
I0604 22:40:00.903699   904 solver.cpp:229] Iteration 10240, loss = 4.19142
I0604 22:40:00.903730   904 solver.cpp:245]     Train net output #0: loss = 4.29519 (* 1 = 4.29519 loss)
I0604 22:40:00.903736   904 sgd_solver.cpp:106] Iteration 10240, lr = 0.0375906
I0604 22:40:21.562814   904 solver.cpp:229] Iteration 10280, loss = 4.27185
I0604 22:40:21.562952   904 solver.cpp:245]     Train net output #0: loss = 3.98435 (* 1 = 3.98435 loss)
I0604 22:40:21.562961   904 sgd_solver.cpp:106] Iteration 10280, lr = 0.0375812
I0604 22:40:42.106295   904 solver.cpp:229] Iteration 10320, loss = 4.20833
I0604 22:40:42.106348   904 solver.cpp:245]     Train net output #0: loss = 4.04511 (* 1 = 4.04511 loss)
I0604 22:40:42.106358   904 sgd_solver.cpp:106] Iteration 10320, lr = 0.0375718
I0604 22:41:02.641624   904 solver.cpp:229] Iteration 10360, loss = 4.1649
I0604 22:41:02.641789   904 solver.cpp:245]     Train net output #0: loss = 4.06826 (* 1 = 4.06826 loss)
I0604 22:41:02.641813   904 sgd_solver.cpp:106] Iteration 10360, lr = 0.0375624
I0604 22:41:23.156828   904 solver.cpp:229] Iteration 10400, loss = 4.17286
I0604 22:41:23.156879   904 solver.cpp:245]     Train net output #0: loss = 4.45761 (* 1 = 4.45761 loss)
I0604 22:41:23.156888   904 sgd_solver.cpp:106] Iteration 10400, lr = 0.0375529
I0604 22:41:43.685334   904 solver.cpp:229] Iteration 10440, loss = 4.26666
I0604 22:41:43.685554   904 solver.cpp:245]     Train net output #0: loss = 4.16094 (* 1 = 4.16094 loss)
I0604 22:41:43.685580   904 sgd_solver.cpp:106] Iteration 10440, lr = 0.0375435
I0604 22:42:04.205850   904 solver.cpp:229] Iteration 10480, loss = 4.24657
I0604 22:42:04.205893   904 solver.cpp:245]     Train net output #0: loss = 4.27555 (* 1 = 4.27555 loss)
I0604 22:42:04.205904   904 sgd_solver.cpp:106] Iteration 10480, lr = 0.0375341
I0604 22:42:24.697437   904 solver.cpp:229] Iteration 10520, loss = 4.21288
I0604 22:42:24.697640   904 solver.cpp:245]     Train net output #0: loss = 3.91683 (* 1 = 3.91683 loss)
I0604 22:42:24.697669   904 sgd_solver.cpp:106] Iteration 10520, lr = 0.0375247
I0604 22:42:44.981576   904 solver.cpp:229] Iteration 10560, loss = 4.1553
I0604 22:42:44.981633   904 solver.cpp:245]     Train net output #0: loss = 4.36227 (* 1 = 4.36227 loss)
I0604 22:42:44.981644   904 sgd_solver.cpp:106] Iteration 10560, lr = 0.0375153
I0604 22:43:02.984454   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0604 22:43:05.269271   904 solver.cpp:229] Iteration 10600, loss = 4.17886
I0604 22:43:05.269327   904 solver.cpp:245]     Train net output #0: loss = 3.87355 (* 1 = 3.87355 loss)
I0604 22:43:05.269338   904 sgd_solver.cpp:106] Iteration 10600, lr = 0.0375059
I0604 22:43:25.552757   904 solver.cpp:229] Iteration 10640, loss = 4.14128
I0604 22:43:25.552825   904 solver.cpp:245]     Train net output #0: loss = 4.12147 (* 1 = 4.12147 loss)
I0604 22:43:25.552835   904 sgd_solver.cpp:106] Iteration 10640, lr = 0.0374965
I0604 22:43:45.829023   904 solver.cpp:229] Iteration 10680, loss = 4.17205
I0604 22:43:45.829197   904 solver.cpp:245]     Train net output #0: loss = 4.1566 (* 1 = 4.1566 loss)
I0604 22:43:45.829224   904 sgd_solver.cpp:106] Iteration 10680, lr = 0.0374871
I0604 22:44:06.115551   904 solver.cpp:229] Iteration 10720, loss = 4.10777
I0604 22:44:06.115608   904 solver.cpp:245]     Train net output #0: loss = 4.38766 (* 1 = 4.38766 loss)
I0604 22:44:06.115617   904 sgd_solver.cpp:106] Iteration 10720, lr = 0.0374776
I0604 22:44:26.390916   904 solver.cpp:229] Iteration 10760, loss = 4.19135
I0604 22:44:26.391137   904 solver.cpp:245]     Train net output #0: loss = 4.12536 (* 1 = 4.12536 loss)
I0604 22:44:26.391161   904 sgd_solver.cpp:106] Iteration 10760, lr = 0.0374682
I0604 22:44:46.681587   904 solver.cpp:229] Iteration 10800, loss = 4.18219
I0604 22:44:46.681646   904 solver.cpp:245]     Train net output #0: loss = 4.275 (* 1 = 4.275 loss)
I0604 22:44:46.681668   904 sgd_solver.cpp:106] Iteration 10800, lr = 0.0374588
I0604 22:45:06.988973   904 solver.cpp:229] Iteration 10840, loss = 4.11453
I0604 22:45:06.989217   904 solver.cpp:245]     Train net output #0: loss = 4.21402 (* 1 = 4.21402 loss)
I0604 22:45:06.989229   904 sgd_solver.cpp:106] Iteration 10840, lr = 0.0374494
I0604 22:45:27.266903   904 solver.cpp:229] Iteration 10880, loss = 4.13104
I0604 22:45:27.266963   904 solver.cpp:245]     Train net output #0: loss = 4.19848 (* 1 = 4.19848 loss)
I0604 22:45:27.266973   904 sgd_solver.cpp:106] Iteration 10880, lr = 0.03744
I0604 22:45:47.556355   904 solver.cpp:229] Iteration 10920, loss = 4.1231
I0604 22:45:47.556558   904 solver.cpp:245]     Train net output #0: loss = 4.23315 (* 1 = 4.23315 loss)
I0604 22:45:47.556581   904 sgd_solver.cpp:106] Iteration 10920, lr = 0.0374306
I0604 22:46:07.833875   904 solver.cpp:229] Iteration 10960, loss = 4.08906
I0604 22:46:07.833931   904 solver.cpp:245]     Train net output #0: loss = 3.85022 (* 1 = 3.85022 loss)
I0604 22:46:07.833941   904 sgd_solver.cpp:106] Iteration 10960, lr = 0.0374212
I0604 22:46:27.634344   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_11000.caffemodel
I0604 22:46:27.902230   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_11000.solverstate
I0604 22:46:27.980855   904 solver.cpp:338] Iteration 11000, Testing net (#0)
I0604 22:46:27.980934   904 net.cpp:748] Ignoring source layer loss
I0604 22:46:34.846529   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0604 22:47:08.386895   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0604 22:47:34.654642   904 solver.cpp:406]     Test net output #0: accuracy = 0.195941
I0604 22:47:34.654678   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.409821
I0604 22:47:34.969651   904 solver.cpp:229] Iteration 11000, loss = 4.22653
I0604 22:47:34.969704   904 solver.cpp:245]     Train net output #0: loss = 4.53286 (* 1 = 4.53286 loss)
I0604 22:47:34.969717   904 sgd_solver.cpp:106] Iteration 11000, lr = 0.0374118
I0604 22:47:54.262670   904 solver.cpp:229] Iteration 11040, loss = 4.09225
I0604 22:47:54.262881   904 solver.cpp:245]     Train net output #0: loss = 4.19233 (* 1 = 4.19233 loss)
I0604 22:47:54.262913   904 sgd_solver.cpp:106] Iteration 11040, lr = 0.0374024
I0604 22:48:15.728658   904 solver.cpp:229] Iteration 11080, loss = 4.1071
I0604 22:48:15.728709   904 solver.cpp:245]     Train net output #0: loss = 4.18723 (* 1 = 4.18723 loss)
I0604 22:48:15.728719   904 sgd_solver.cpp:106] Iteration 11080, lr = 0.0373929
I0604 22:48:30.543469   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0604 22:48:37.288519   904 solver.cpp:229] Iteration 11120, loss = 4.06125
I0604 22:48:37.288569   904 solver.cpp:245]     Train net output #0: loss = 4.13701 (* 1 = 4.13701 loss)
I0604 22:48:37.288583   904 sgd_solver.cpp:106] Iteration 11120, lr = 0.0373835
I0604 22:48:58.628615   904 solver.cpp:229] Iteration 11160, loss = 4.12819
I0604 22:48:58.628655   904 solver.cpp:245]     Train net output #0: loss = 3.94698 (* 1 = 3.94698 loss)
I0604 22:48:58.628664   904 sgd_solver.cpp:106] Iteration 11160, lr = 0.0373741
I0604 22:49:19.777258   904 solver.cpp:229] Iteration 11200, loss = 4.11196
I0604 22:49:19.777496   904 solver.cpp:245]     Train net output #0: loss = 4.12724 (* 1 = 4.12724 loss)
I0604 22:49:19.777520   904 sgd_solver.cpp:106] Iteration 11200, lr = 0.0373647
I0604 22:49:40.764169   904 solver.cpp:229] Iteration 11240, loss = 4.08904
I0604 22:49:40.764233   904 solver.cpp:245]     Train net output #0: loss = 3.82273 (* 1 = 3.82273 loss)
I0604 22:49:40.764255   904 sgd_solver.cpp:106] Iteration 11240, lr = 0.0373553
I0604 22:50:01.736459   904 solver.cpp:229] Iteration 11280, loss = 4.07372
I0604 22:50:01.736598   904 solver.cpp:245]     Train net output #0: loss = 3.99167 (* 1 = 3.99167 loss)
I0604 22:50:01.736608   904 sgd_solver.cpp:106] Iteration 11280, lr = 0.0373459
I0604 22:50:22.727938   904 solver.cpp:229] Iteration 11320, loss = 4.07899
I0604 22:50:22.727985   904 solver.cpp:245]     Train net output #0: loss = 4.28033 (* 1 = 4.28033 loss)
I0604 22:50:22.727996   904 sgd_solver.cpp:106] Iteration 11320, lr = 0.0373365
I0604 22:50:43.695158   904 solver.cpp:229] Iteration 11360, loss = 4.12782
I0604 22:50:43.695399   904 solver.cpp:245]     Train net output #0: loss = 4.1 (* 1 = 4.1 loss)
I0604 22:50:43.695425   904 sgd_solver.cpp:106] Iteration 11360, lr = 0.0373271
I0604 22:51:04.694890   904 solver.cpp:229] Iteration 11400, loss = 4.08351
I0604 22:51:04.694922   904 solver.cpp:245]     Train net output #0: loss = 3.90827 (* 1 = 3.90827 loss)
I0604 22:51:04.694928   904 sgd_solver.cpp:106] Iteration 11400, lr = 0.0373176
I0604 22:51:25.431566   904 solver.cpp:229] Iteration 11440, loss = 4.12721
I0604 22:51:25.431705   904 solver.cpp:245]     Train net output #0: loss = 4.1092 (* 1 = 4.1092 loss)
I0604 22:51:25.431715   904 sgd_solver.cpp:106] Iteration 11440, lr = 0.0373082
I0604 22:51:46.109499   904 solver.cpp:229] Iteration 11480, loss = 4.0964
I0604 22:51:46.109539   904 solver.cpp:245]     Train net output #0: loss = 4.10144 (* 1 = 4.10144 loss)
I0604 22:51:46.109546   904 sgd_solver.cpp:106] Iteration 11480, lr = 0.0372988
I0604 22:52:06.766791   904 solver.cpp:229] Iteration 11520, loss = 4.07097
I0604 22:52:06.766940   904 solver.cpp:245]     Train net output #0: loss = 4.21417 (* 1 = 4.21417 loss)
I0604 22:52:06.766948   904 sgd_solver.cpp:106] Iteration 11520, lr = 0.0372894
I0604 22:52:27.437168   904 solver.cpp:229] Iteration 11560, loss = 4.06608
I0604 22:52:27.437217   904 solver.cpp:245]     Train net output #0: loss = 4.17499 (* 1 = 4.17499 loss)
I0604 22:52:27.437227   904 sgd_solver.cpp:106] Iteration 11560, lr = 0.03728
I0604 22:52:48.114002   904 solver.cpp:229] Iteration 11600, loss = 4.06797
I0604 22:52:48.114207   904 solver.cpp:245]     Train net output #0: loss = 3.86263 (* 1 = 3.86263 loss)
I0604 22:52:48.114229   904 sgd_solver.cpp:106] Iteration 11600, lr = 0.0372706
I0604 22:53:08.776309   904 solver.cpp:229] Iteration 11640, loss = 4.02494
I0604 22:53:08.776367   904 solver.cpp:245]     Train net output #0: loss = 4.07202 (* 1 = 4.07202 loss)
I0604 22:53:08.776382   904 sgd_solver.cpp:106] Iteration 11640, lr = 0.0372612
I0604 22:53:17.576047   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0604 22:53:29.423575   904 solver.cpp:229] Iteration 11680, loss = 4.09062
I0604 22:53:29.423749   904 solver.cpp:245]     Train net output #0: loss = 4.07105 (* 1 = 4.07105 loss)
I0604 22:53:29.423768   904 sgd_solver.cpp:106] Iteration 11680, lr = 0.0372518
I0604 22:53:49.923996   904 solver.cpp:229] Iteration 11720, loss = 4.01952
I0604 22:53:49.924048   904 solver.cpp:245]     Train net output #0: loss = 3.92461 (* 1 = 3.92461 loss)
I0604 22:53:49.924057   904 sgd_solver.cpp:106] Iteration 11720, lr = 0.0372424
I0604 22:54:10.430691   904 solver.cpp:229] Iteration 11760, loss = 4.01068
I0604 22:54:10.430886   904 solver.cpp:245]     Train net output #0: loss = 3.93248 (* 1 = 3.93248 loss)
I0604 22:54:10.430905   904 sgd_solver.cpp:106] Iteration 11760, lr = 0.0372329
I0604 22:54:31.004166   904 solver.cpp:229] Iteration 11800, loss = 4.2152
I0604 22:54:31.004223   904 solver.cpp:245]     Train net output #0: loss = 4.24527 (* 1 = 4.24527 loss)
I0604 22:54:31.004240   904 sgd_solver.cpp:106] Iteration 11800, lr = 0.0372235
I0604 22:54:51.609648   904 solver.cpp:229] Iteration 11840, loss = 4.06156
I0604 22:54:51.609802   904 solver.cpp:245]     Train net output #0: loss = 4.05516 (* 1 = 4.05516 loss)
I0604 22:54:51.609812   904 sgd_solver.cpp:106] Iteration 11840, lr = 0.0372141
I0604 22:55:11.988034   904 solver.cpp:229] Iteration 11880, loss = 4.01561
I0604 22:55:11.988083   904 solver.cpp:245]     Train net output #0: loss = 3.95604 (* 1 = 3.95604 loss)
I0604 22:55:11.988090   904 sgd_solver.cpp:106] Iteration 11880, lr = 0.0372047
I0604 22:55:32.430754   904 solver.cpp:229] Iteration 11920, loss = 3.98577
I0604 22:55:32.431006   904 solver.cpp:245]     Train net output #0: loss = 4.18771 (* 1 = 4.18771 loss)
I0604 22:55:32.431021   904 sgd_solver.cpp:106] Iteration 11920, lr = 0.0371953
I0604 22:55:52.934000   904 solver.cpp:229] Iteration 11960, loss = 4.02012
I0604 22:55:52.934047   904 solver.cpp:245]     Train net output #0: loss = 4.08999 (* 1 = 4.08999 loss)
I0604 22:55:52.934056   904 sgd_solver.cpp:106] Iteration 11960, lr = 0.0371859
I0604 22:56:13.075448   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_12000.caffemodel
I0604 22:56:13.341508   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_12000.solverstate
I0604 22:56:13.422122   904 solver.cpp:338] Iteration 12000, Testing net (#0)
I0604 22:56:13.422201   904 net.cpp:748] Ignoring source layer loss
I0604 22:56:30.629914   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0604 22:57:03.190259   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0604 22:57:18.076411   904 solver.cpp:406]     Test net output #0: accuracy = 0.22194
I0604 22:57:18.076448   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.440901
I0604 22:57:18.391072   904 solver.cpp:229] Iteration 12000, loss = 4.01927
I0604 22:57:18.391120   904 solver.cpp:245]     Train net output #0: loss = 4.01767 (* 1 = 4.01767 loss)
I0604 22:57:18.391134   904 sgd_solver.cpp:106] Iteration 12000, lr = 0.0371765
I0604 22:57:37.713701   904 solver.cpp:229] Iteration 12040, loss = 4.02851
I0604 22:57:37.713893   904 solver.cpp:245]     Train net output #0: loss = 3.8732 (* 1 = 3.8732 loss)
I0604 22:57:37.713915   904 sgd_solver.cpp:106] Iteration 12040, lr = 0.0371671
I0604 22:57:59.226398   904 solver.cpp:229] Iteration 12080, loss = 3.98359
I0604 22:57:59.226469   904 solver.cpp:245]     Train net output #0: loss = 3.95762 (* 1 = 3.95762 loss)
I0604 22:57:59.226477   904 sgd_solver.cpp:106] Iteration 12080, lr = 0.0371576
I0604 22:58:20.815168   904 solver.cpp:229] Iteration 12120, loss = 4.01526
I0604 22:58:20.815357   904 solver.cpp:245]     Train net output #0: loss = 3.98502 (* 1 = 3.98502 loss)
I0604 22:58:20.815400   904 sgd_solver.cpp:106] Iteration 12120, lr = 0.0371482
I0604 22:58:42.034597   904 solver.cpp:229] Iteration 12160, loss = 4.07127
I0604 22:58:42.034646   904 solver.cpp:245]     Train net output #0: loss = 4.04784 (* 1 = 4.04784 loss)
I0604 22:58:42.034667   904 sgd_solver.cpp:106] Iteration 12160, lr = 0.0371388
I0604 22:59:03.070304   904 solver.cpp:229] Iteration 12200, loss = 4.03543
I0604 22:59:03.070508   904 solver.cpp:245]     Train net output #0: loss = 3.87239 (* 1 = 3.87239 loss)
I0604 22:59:03.070536   904 sgd_solver.cpp:106] Iteration 12200, lr = 0.0371294
I0604 22:59:24.101203   904 solver.cpp:229] Iteration 12240, loss = 3.99003
I0604 22:59:24.101239   904 solver.cpp:245]     Train net output #0: loss = 3.92563 (* 1 = 3.92563 loss)
I0604 22:59:24.101248   904 sgd_solver.cpp:106] Iteration 12240, lr = 0.03712
I0604 22:59:45.116055   904 solver.cpp:229] Iteration 12280, loss = 4.04493
I0604 22:59:45.116262   904 solver.cpp:245]     Train net output #0: loss = 3.87743 (* 1 = 3.87743 loss)
I0604 22:59:45.116299   904 sgd_solver.cpp:106] Iteration 12280, lr = 0.0371106
I0604 22:59:55.879945   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0604 23:00:06.084084   904 solver.cpp:229] Iteration 12320, loss = 3.9701
I0604 23:00:06.084134   904 solver.cpp:245]     Train net output #0: loss = 4.00472 (* 1 = 4.00472 loss)
I0604 23:00:06.084141   904 sgd_solver.cpp:106] Iteration 12320, lr = 0.0371012
I0604 23:00:26.964922   904 solver.cpp:229] Iteration 12360, loss = 4.00058
I0604 23:00:26.965111   904 solver.cpp:245]     Train net output #0: loss = 4.20359 (* 1 = 4.20359 loss)
I0604 23:00:26.965133   904 sgd_solver.cpp:106] Iteration 12360, lr = 0.0370918
I0604 23:00:47.671789   904 solver.cpp:229] Iteration 12400, loss = 4.00313
I0604 23:00:47.671833   904 solver.cpp:245]     Train net output #0: loss = 3.86114 (* 1 = 3.86114 loss)
I0604 23:00:47.671856   904 sgd_solver.cpp:106] Iteration 12400, lr = 0.0370824
I0604 23:01:08.427178   904 solver.cpp:229] Iteration 12440, loss = 3.99007
I0604 23:01:08.427458   904 solver.cpp:245]     Train net output #0: loss = 4.2193 (* 1 = 4.2193 loss)
I0604 23:01:08.427481   904 sgd_solver.cpp:106] Iteration 12440, lr = 0.0370729
I0604 23:01:29.176067   904 solver.cpp:229] Iteration 12480, loss = 3.99382
I0604 23:01:29.176131   904 solver.cpp:245]     Train net output #0: loss = 4.10721 (* 1 = 4.10721 loss)
I0604 23:01:29.176144   904 sgd_solver.cpp:106] Iteration 12480, lr = 0.0370635
I0604 23:01:49.859638   904 solver.cpp:229] Iteration 12520, loss = 4.01395
I0604 23:01:49.859828   904 solver.cpp:245]     Train net output #0: loss = 4.00991 (* 1 = 4.00991 loss)
I0604 23:01:49.859856   904 sgd_solver.cpp:106] Iteration 12520, lr = 0.0370541
I0604 23:02:10.381893   904 solver.cpp:229] Iteration 12560, loss = 3.99756
I0604 23:02:10.381935   904 solver.cpp:245]     Train net output #0: loss = 3.95875 (* 1 = 3.95875 loss)
I0604 23:02:10.381944   904 sgd_solver.cpp:106] Iteration 12560, lr = 0.0370447
I0604 23:02:30.927356   904 solver.cpp:229] Iteration 12600, loss = 3.95675
I0604 23:02:30.927557   904 solver.cpp:245]     Train net output #0: loss = 4.03052 (* 1 = 4.03052 loss)
I0604 23:02:30.927585   904 sgd_solver.cpp:106] Iteration 12600, lr = 0.0370353
I0604 23:02:51.470111   904 solver.cpp:229] Iteration 12640, loss = 3.99972
I0604 23:02:51.470161   904 solver.cpp:245]     Train net output #0: loss = 3.94738 (* 1 = 3.94738 loss)
I0604 23:02:51.470170   904 sgd_solver.cpp:106] Iteration 12640, lr = 0.0370259
I0604 23:03:12.002925   904 solver.cpp:229] Iteration 12680, loss = 3.94054
I0604 23:03:12.003128   904 solver.cpp:245]     Train net output #0: loss = 4.0449 (* 1 = 4.0449 loss)
I0604 23:03:12.003154   904 sgd_solver.cpp:106] Iteration 12680, lr = 0.0370165
I0604 23:03:32.542176   904 solver.cpp:229] Iteration 12720, loss = 3.9544
I0604 23:03:32.542222   904 solver.cpp:245]     Train net output #0: loss = 3.79772 (* 1 = 3.79772 loss)
I0604 23:03:32.542232   904 sgd_solver.cpp:106] Iteration 12720, lr = 0.0370071
I0604 23:03:52.975846   904 solver.cpp:229] Iteration 12760, loss = 3.97508
I0604 23:03:52.976049   904 solver.cpp:245]     Train net output #0: loss = 3.73962 (* 1 = 3.73962 loss)
I0604 23:03:52.976079   904 sgd_solver.cpp:106] Iteration 12760, lr = 0.0369976
I0604 23:04:13.303580   904 solver.cpp:229] Iteration 12800, loss = 4.04876
I0604 23:04:13.303630   904 solver.cpp:245]     Train net output #0: loss = 3.95984 (* 1 = 3.95984 loss)
I0604 23:04:13.303638   904 sgd_solver.cpp:106] Iteration 12800, lr = 0.0369882
I0604 23:04:33.609766   904 solver.cpp:229] Iteration 12840, loss = 3.94681
I0604 23:04:33.609984   904 solver.cpp:245]     Train net output #0: loss = 4.12068 (* 1 = 4.12068 loss)
I0604 23:04:33.610010   904 sgd_solver.cpp:106] Iteration 12840, lr = 0.0369788
I0604 23:04:53.983592   904 solver.cpp:229] Iteration 12880, loss = 3.9161
I0604 23:04:53.983639   904 solver.cpp:245]     Train net output #0: loss = 4.15115 (* 1 = 4.15115 loss)
I0604 23:04:53.983647   904 sgd_solver.cpp:106] Iteration 12880, lr = 0.0369694
I0604 23:05:07.458863   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0604 23:05:14.322316   904 solver.cpp:229] Iteration 12920, loss = 3.93063
I0604 23:05:14.322365   904 solver.cpp:245]     Train net output #0: loss = 4.04313 (* 1 = 4.04313 loss)
I0604 23:05:14.322376   904 sgd_solver.cpp:106] Iteration 12920, lr = 0.03696
I0604 23:05:34.674481   904 solver.cpp:229] Iteration 12960, loss = 3.97185
I0604 23:05:34.674530   904 solver.cpp:245]     Train net output #0: loss = 4.05495 (* 1 = 4.05495 loss)
I0604 23:05:34.674540   904 sgd_solver.cpp:106] Iteration 12960, lr = 0.0369506
I0604 23:05:54.516912   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_13000.caffemodel
I0604 23:05:54.780906   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_13000.solverstate
I0604 23:05:54.859385   904 solver.cpp:338] Iteration 13000, Testing net (#0)
I0604 23:05:54.859457   904 net.cpp:748] Ignoring source layer loss
I0604 23:06:21.662627   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0604 23:06:55.145064   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0604 23:07:01.248689   904 solver.cpp:406]     Test net output #0: accuracy = 0.23476
I0604 23:07:01.248726   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.456821
I0604 23:07:01.561209   904 solver.cpp:229] Iteration 13000, loss = 3.91953
I0604 23:07:01.561264   904 solver.cpp:245]     Train net output #0: loss = 3.96191 (* 1 = 3.96191 loss)
I0604 23:07:01.561275   904 sgd_solver.cpp:106] Iteration 13000, lr = 0.0369412
I0604 23:07:20.823676   904 solver.cpp:229] Iteration 13040, loss = 3.92405
I0604 23:07:20.823712   904 solver.cpp:245]     Train net output #0: loss = 4.06143 (* 1 = 4.06143 loss)
I0604 23:07:20.823720   904 sgd_solver.cpp:106] Iteration 13040, lr = 0.0369318
I0604 23:07:42.118113   904 solver.cpp:229] Iteration 13080, loss = 3.95154
I0604 23:07:42.118322   904 solver.cpp:245]     Train net output #0: loss = 4.04551 (* 1 = 4.04551 loss)
I0604 23:07:42.118350   904 sgd_solver.cpp:106] Iteration 13080, lr = 0.0369224
I0604 23:08:03.612619   904 solver.cpp:229] Iteration 13120, loss = 3.96239
I0604 23:08:03.612676   904 solver.cpp:245]     Train net output #0: loss = 3.81971 (* 1 = 3.81971 loss)
I0604 23:08:03.612689   904 sgd_solver.cpp:106] Iteration 13120, lr = 0.0369129
I0604 23:08:24.515024   904 solver.cpp:229] Iteration 13160, loss = 3.94154
I0604 23:08:24.515230   904 solver.cpp:245]     Train net output #0: loss = 4.21736 (* 1 = 4.21736 loss)
I0604 23:08:24.515257   904 sgd_solver.cpp:106] Iteration 13160, lr = 0.0369035
I0604 23:08:45.409708   904 solver.cpp:229] Iteration 13200, loss = 3.90803
I0604 23:08:45.409760   904 solver.cpp:245]     Train net output #0: loss = 3.94124 (* 1 = 3.94124 loss)
I0604 23:08:45.409775   904 sgd_solver.cpp:106] Iteration 13200, lr = 0.0368941
I0604 23:09:06.393159   904 solver.cpp:229] Iteration 13240, loss = 3.93207
I0604 23:09:06.393371   904 solver.cpp:245]     Train net output #0: loss = 3.78157 (* 1 = 3.78157 loss)
I0604 23:09:06.393398   904 sgd_solver.cpp:106] Iteration 13240, lr = 0.0368847
I0604 23:09:27.352960   904 solver.cpp:229] Iteration 13280, loss = 3.91639
I0604 23:09:27.353009   904 solver.cpp:245]     Train net output #0: loss = 3.82658 (* 1 = 3.82658 loss)
I0604 23:09:27.353018   904 sgd_solver.cpp:106] Iteration 13280, lr = 0.0368753
I0604 23:09:48.152510   904 solver.cpp:229] Iteration 13320, loss = 3.87356
I0604 23:09:48.152673   904 solver.cpp:245]     Train net output #0: loss = 3.68287 (* 1 = 3.68287 loss)
I0604 23:09:48.152698   904 sgd_solver.cpp:106] Iteration 13320, lr = 0.0368659
I0604 23:10:08.886227   904 solver.cpp:229] Iteration 13360, loss = 3.87637
I0604 23:10:08.886286   904 solver.cpp:245]     Train net output #0: loss = 4.22805 (* 1 = 4.22805 loss)
I0604 23:10:08.886296   904 sgd_solver.cpp:106] Iteration 13360, lr = 0.0368565
I0604 23:10:29.569223   904 solver.cpp:229] Iteration 13400, loss = 3.91518
I0604 23:10:29.569408   904 solver.cpp:245]     Train net output #0: loss = 3.90685 (* 1 = 3.90685 loss)
I0604 23:10:29.569432   904 sgd_solver.cpp:106] Iteration 13400, lr = 0.0368471
I0604 23:10:37.060009   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0604 23:10:50.257728   904 solver.cpp:229] Iteration 13440, loss = 3.89465
I0604 23:10:50.257779   904 solver.cpp:245]     Train net output #0: loss = 3.91535 (* 1 = 3.91535 loss)
I0604 23:10:50.257788   904 sgd_solver.cpp:106] Iteration 13440, lr = 0.0368376
I0604 23:11:10.958302   904 solver.cpp:229] Iteration 13480, loss = 3.86659
I0604 23:11:10.958449   904 solver.cpp:245]     Train net output #0: loss = 3.56015 (* 1 = 3.56015 loss)
I0604 23:11:10.958461   904 sgd_solver.cpp:106] Iteration 13480, lr = 0.0368282
I0604 23:11:31.475829   904 solver.cpp:229] Iteration 13520, loss = 3.86329
I0604 23:11:31.475873   904 solver.cpp:245]     Train net output #0: loss = 3.9961 (* 1 = 3.9961 loss)
I0604 23:11:31.475879   904 sgd_solver.cpp:106] Iteration 13520, lr = 0.0368188
I0604 23:11:52.056768   904 solver.cpp:229] Iteration 13560, loss = 3.91306
I0604 23:11:52.056962   904 solver.cpp:245]     Train net output #0: loss = 4.13463 (* 1 = 4.13463 loss)
I0604 23:11:52.056972   904 sgd_solver.cpp:106] Iteration 13560, lr = 0.0368094
I0604 23:12:12.717324   904 solver.cpp:229] Iteration 13600, loss = 3.83296
I0604 23:12:12.717370   904 solver.cpp:245]     Train net output #0: loss = 3.9694 (* 1 = 3.9694 loss)
I0604 23:12:12.717380   904 sgd_solver.cpp:106] Iteration 13600, lr = 0.0368
I0604 23:12:33.264976   904 solver.cpp:229] Iteration 13640, loss = 3.86627
I0604 23:12:33.265172   904 solver.cpp:245]     Train net output #0: loss = 4.02939 (* 1 = 4.02939 loss)
I0604 23:12:33.265197   904 sgd_solver.cpp:106] Iteration 13640, lr = 0.0367906
I0604 23:12:53.784204   904 solver.cpp:229] Iteration 13680, loss = 3.91414
I0604 23:12:53.784247   904 solver.cpp:245]     Train net output #0: loss = 3.69437 (* 1 = 3.69437 loss)
I0604 23:12:53.784256   904 sgd_solver.cpp:106] Iteration 13680, lr = 0.0367812
I0604 23:13:14.306748   904 solver.cpp:229] Iteration 13720, loss = 3.90055
I0604 23:13:14.306957   904 solver.cpp:245]     Train net output #0: loss = 3.99573 (* 1 = 3.99573 loss)
I0604 23:13:14.306983   904 sgd_solver.cpp:106] Iteration 13720, lr = 0.0367718
I0604 23:13:34.827656   904 solver.cpp:229] Iteration 13760, loss = 3.84611
I0604 23:13:34.827702   904 solver.cpp:245]     Train net output #0: loss = 3.95221 (* 1 = 3.95221 loss)
I0604 23:13:34.827710   904 sgd_solver.cpp:106] Iteration 13760, lr = 0.0367623
I0604 23:13:55.346325   904 solver.cpp:229] Iteration 13800, loss = 3.88177
I0604 23:13:55.346578   904 solver.cpp:245]     Train net output #0: loss = 3.84721 (* 1 = 3.84721 loss)
I0604 23:13:55.346606   904 sgd_solver.cpp:106] Iteration 13800, lr = 0.0367529
I0604 23:14:15.862607   904 solver.cpp:229] Iteration 13840, loss = 3.88359
I0604 23:14:15.862659   904 solver.cpp:245]     Train net output #0: loss = 4.14151 (* 1 = 4.14151 loss)
I0604 23:14:15.862668   904 sgd_solver.cpp:106] Iteration 13840, lr = 0.0367435
I0604 23:14:36.388294   904 solver.cpp:229] Iteration 13880, loss = 3.91148
I0604 23:14:36.388550   904 solver.cpp:245]     Train net output #0: loss = 3.95738 (* 1 = 3.95738 loss)
I0604 23:14:36.388586   904 sgd_solver.cpp:106] Iteration 13880, lr = 0.0367341
I0604 23:14:55.382376   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0604 23:14:56.923847   904 solver.cpp:229] Iteration 13920, loss = 3.82744
I0604 23:14:56.923897   904 solver.cpp:245]     Train net output #0: loss = 3.61013 (* 1 = 3.61013 loss)
I0604 23:14:56.923907   904 sgd_solver.cpp:106] Iteration 13920, lr = 0.0367247
I0604 23:15:17.446213   904 solver.cpp:229] Iteration 13960, loss = 3.9682
I0604 23:15:17.446442   904 solver.cpp:245]     Train net output #0: loss = 4.00359 (* 1 = 4.00359 loss)
I0604 23:15:17.446470   904 sgd_solver.cpp:106] Iteration 13960, lr = 0.0367153
I0604 23:15:37.441694   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_14000.caffemodel
I0604 23:15:37.706025   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_14000.solverstate
I0604 23:15:37.784610   904 solver.cpp:338] Iteration 14000, Testing net (#0)
I0604 23:15:37.784703   904 net.cpp:748] Ignoring source layer loss
I0604 23:16:07.085584   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0604 23:16:41.295157   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0604 23:16:46.450534   904 solver.cpp:406]     Test net output #0: accuracy = 0.23646
I0604 23:16:46.450577   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.458121
I0604 23:16:46.766160   904 solver.cpp:229] Iteration 14000, loss = 3.93433
I0604 23:16:46.766201   904 solver.cpp:245]     Train net output #0: loss = 4.0427 (* 1 = 4.0427 loss)
I0604 23:16:46.766211   904 sgd_solver.cpp:106] Iteration 14000, lr = 0.0367059
I0604 23:17:06.011925   904 solver.cpp:229] Iteration 14040, loss = 3.83355
I0604 23:17:06.011972   904 solver.cpp:245]     Train net output #0: loss = 3.77022 (* 1 = 3.77022 loss)
I0604 23:17:06.011981   904 sgd_solver.cpp:106] Iteration 14040, lr = 0.0366965
I0604 23:17:27.540467   904 solver.cpp:229] Iteration 14080, loss = 3.85918
I0604 23:17:27.540702   904 solver.cpp:245]     Train net output #0: loss = 3.7065 (* 1 = 3.7065 loss)
I0604 23:17:27.540712   904 sgd_solver.cpp:106] Iteration 14080, lr = 0.0366871
I0604 23:17:49.021311   904 solver.cpp:229] Iteration 14120, loss = 3.84966
I0604 23:17:49.021356   904 solver.cpp:245]     Train net output #0: loss = 3.82194 (* 1 = 3.82194 loss)
I0604 23:17:49.021365   904 sgd_solver.cpp:106] Iteration 14120, lr = 0.0366776
I0604 23:18:10.323086   904 solver.cpp:229] Iteration 14160, loss = 3.87202
I0604 23:18:10.323287   904 solver.cpp:245]     Train net output #0: loss = 3.87801 (* 1 = 3.87801 loss)
I0604 23:18:10.323314   904 sgd_solver.cpp:106] Iteration 14160, lr = 0.0366682
I0604 23:18:31.321418   904 solver.cpp:229] Iteration 14200, loss = 3.86208
I0604 23:18:31.321472   904 solver.cpp:245]     Train net output #0: loss = 3.79702 (* 1 = 3.79702 loss)
I0604 23:18:31.321480   904 sgd_solver.cpp:106] Iteration 14200, lr = 0.0366588
I0604 23:18:52.319888   904 solver.cpp:229] Iteration 14240, loss = 3.80919
I0604 23:18:52.320098   904 solver.cpp:245]     Train net output #0: loss = 3.94088 (* 1 = 3.94088 loss)
I0604 23:18:52.320124   904 sgd_solver.cpp:106] Iteration 14240, lr = 0.0366494
I0604 23:19:13.306139   904 solver.cpp:229] Iteration 14280, loss = 3.87353
I0604 23:19:13.306180   904 solver.cpp:245]     Train net output #0: loss = 4.13199 (* 1 = 4.13199 loss)
I0604 23:19:13.306188   904 sgd_solver.cpp:106] Iteration 14280, lr = 0.03664
I0604 23:19:34.312129   904 solver.cpp:229] Iteration 14320, loss = 3.79915
I0604 23:19:34.312353   904 solver.cpp:245]     Train net output #0: loss = 3.80917 (* 1 = 3.80917 loss)
I0604 23:19:34.312392   904 sgd_solver.cpp:106] Iteration 14320, lr = 0.0366306
I0604 23:19:55.313117   904 solver.cpp:229] Iteration 14360, loss = 3.7705
I0604 23:19:55.313174   904 solver.cpp:245]     Train net output #0: loss = 3.84421 (* 1 = 3.84421 loss)
I0604 23:19:55.313187   904 sgd_solver.cpp:106] Iteration 14360, lr = 0.0366212
I0604 23:20:16.148495   904 solver.cpp:229] Iteration 14400, loss = 3.80362
I0604 23:20:16.148643   904 solver.cpp:245]     Train net output #0: loss = 3.67578 (* 1 = 3.67578 loss)
I0604 23:20:16.148655   904 sgd_solver.cpp:106] Iteration 14400, lr = 0.0366118
I0604 23:20:29.447468   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0604 23:20:37.472847   904 solver.cpp:229] Iteration 14440, loss = 3.79424
I0604 23:20:37.472905   904 solver.cpp:245]     Train net output #0: loss = 3.83691 (* 1 = 3.83691 loss)
I0604 23:20:37.472918   904 sgd_solver.cpp:106] Iteration 14440, lr = 0.0366024
I0604 23:20:58.106501   904 solver.cpp:229] Iteration 14480, loss = 3.82895
I0604 23:20:58.106727   904 solver.cpp:245]     Train net output #0: loss = 3.60758 (* 1 = 3.60758 loss)
I0604 23:20:58.106762   904 sgd_solver.cpp:106] Iteration 14480, lr = 0.0365929
I0604 23:21:18.753888   904 solver.cpp:229] Iteration 14520, loss = 3.79423
I0604 23:21:18.753929   904 solver.cpp:245]     Train net output #0: loss = 3.8363 (* 1 = 3.8363 loss)
I0604 23:21:18.753940   904 sgd_solver.cpp:106] Iteration 14520, lr = 0.0365835
I0604 23:21:39.411443   904 solver.cpp:229] Iteration 14560, loss = 3.76993
I0604 23:21:39.411676   904 solver.cpp:245]     Train net output #0: loss = 3.67647 (* 1 = 3.67647 loss)
I0604 23:21:39.411705   904 sgd_solver.cpp:106] Iteration 14560, lr = 0.0365741
I0604 23:22:00.003332   904 solver.cpp:229] Iteration 14600, loss = 3.8173
I0604 23:22:00.003387   904 solver.cpp:245]     Train net output #0: loss = 3.48547 (* 1 = 3.48547 loss)
I0604 23:22:00.003398   904 sgd_solver.cpp:106] Iteration 14600, lr = 0.0365647
I0604 23:22:20.526042   904 solver.cpp:229] Iteration 14640, loss = 3.84333
I0604 23:22:20.526301   904 solver.cpp:245]     Train net output #0: loss = 3.96548 (* 1 = 3.96548 loss)
I0604 23:22:20.526327   904 sgd_solver.cpp:106] Iteration 14640, lr = 0.0365553
I0604 23:22:41.045429   904 solver.cpp:229] Iteration 14680, loss = 3.82433
I0604 23:22:41.045466   904 solver.cpp:245]     Train net output #0: loss = 3.7826 (* 1 = 3.7826 loss)
I0604 23:22:41.045475   904 sgd_solver.cpp:106] Iteration 14680, lr = 0.0365459
I0604 23:23:01.672791   904 solver.cpp:229] Iteration 14720, loss = 3.78753
I0604 23:23:01.672929   904 solver.cpp:245]     Train net output #0: loss = 3.61589 (* 1 = 3.61589 loss)
I0604 23:23:01.672938   904 sgd_solver.cpp:106] Iteration 14720, lr = 0.0365365
I0604 23:23:22.188627   904 solver.cpp:229] Iteration 14760, loss = 3.83195
I0604 23:23:22.188670   904 solver.cpp:245]     Train net output #0: loss = 4.03489 (* 1 = 4.03489 loss)
I0604 23:23:22.188678   904 sgd_solver.cpp:106] Iteration 14760, lr = 0.0365271
I0604 23:23:42.693274   904 solver.cpp:229] Iteration 14800, loss = 3.88349
I0604 23:23:42.693428   904 solver.cpp:245]     Train net output #0: loss = 3.86254 (* 1 = 3.86254 loss)
I0604 23:23:42.693439   904 sgd_solver.cpp:106] Iteration 14800, lr = 0.0365176
I0604 23:24:03.207592   904 solver.cpp:229] Iteration 14840, loss = 3.77157
I0604 23:24:03.207649   904 solver.cpp:245]     Train net output #0: loss = 4.27479 (* 1 = 4.27479 loss)
I0604 23:24:03.207659   904 sgd_solver.cpp:106] Iteration 14840, lr = 0.0365082
I0604 23:24:23.711077   904 solver.cpp:229] Iteration 14880, loss = 3.77883
I0604 23:24:23.711221   904 solver.cpp:245]     Train net output #0: loss = 4.10864 (* 1 = 4.10864 loss)
I0604 23:24:23.711231   904 sgd_solver.cpp:106] Iteration 14880, lr = 0.0364988
I0604 23:24:44.142144   904 solver.cpp:229] Iteration 14920, loss = 3.78589
I0604 23:24:44.142185   904 solver.cpp:245]     Train net output #0: loss = 3.79616 (* 1 = 3.79616 loss)
I0604 23:24:44.142195   904 sgd_solver.cpp:106] Iteration 14920, lr = 0.0364894
I0604 23:24:48.709542   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0604 23:25:04.407948   904 solver.cpp:229] Iteration 14960, loss = 3.79862
I0604 23:25:04.408097   904 solver.cpp:245]     Train net output #0: loss = 4.03097 (* 1 = 4.03097 loss)
I0604 23:25:04.408105   904 sgd_solver.cpp:106] Iteration 14960, lr = 0.03648
I0604 23:25:24.176298   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_15000.caffemodel
I0604 23:25:24.440145   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_15000.solverstate
I0604 23:25:24.521445   904 solver.cpp:338] Iteration 15000, Testing net (#0)
I0604 23:25:24.521538   904 net.cpp:748] Ignoring source layer loss
I0604 23:25:52.919875   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0604 23:26:25.614791   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0604 23:26:30.053179   904 solver.cpp:406]     Test net output #0: accuracy = 0.25316
I0604 23:26:30.053226   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.4842
I0604 23:26:30.364791   904 solver.cpp:229] Iteration 15000, loss = 3.75991
I0604 23:26:30.364836   904 solver.cpp:245]     Train net output #0: loss = 3.67131 (* 1 = 3.67131 loss)
I0604 23:26:30.364850   904 sgd_solver.cpp:106] Iteration 15000, lr = 0.0364706
I0604 23:26:49.548210   904 solver.cpp:229] Iteration 15040, loss = 3.79879
I0604 23:26:49.548254   904 solver.cpp:245]     Train net output #0: loss = 3.95595 (* 1 = 3.95595 loss)
I0604 23:26:49.548265   904 sgd_solver.cpp:106] Iteration 15040, lr = 0.0364612
I0604 23:27:10.904683   904 solver.cpp:229] Iteration 15080, loss = 3.8103
I0604 23:27:10.904914   904 solver.cpp:245]     Train net output #0: loss = 3.52333 (* 1 = 3.52333 loss)
I0604 23:27:10.904948   904 sgd_solver.cpp:106] Iteration 15080, lr = 0.0364518
I0604 23:27:32.370947   904 solver.cpp:229] Iteration 15120, loss = 3.76688
I0604 23:27:32.371008   904 solver.cpp:245]     Train net output #0: loss = 3.82653 (* 1 = 3.82653 loss)
I0604 23:27:32.371022   904 sgd_solver.cpp:106] Iteration 15120, lr = 0.0364424
I0604 23:27:53.272816   904 solver.cpp:229] Iteration 15160, loss = 3.80521
I0604 23:27:53.273121   904 solver.cpp:245]     Train net output #0: loss = 3.80769 (* 1 = 3.80769 loss)
I0604 23:27:53.273149   904 sgd_solver.cpp:106] Iteration 15160, lr = 0.0364329
I0604 23:28:13.895756   904 solver.cpp:229] Iteration 15200, loss = 3.80975
I0604 23:28:13.895793   904 solver.cpp:245]     Train net output #0: loss = 3.5604 (* 1 = 3.5604 loss)
I0604 23:28:13.895802   904 sgd_solver.cpp:106] Iteration 15200, lr = 0.0364235
I0604 23:28:34.424142   904 solver.cpp:229] Iteration 15240, loss = 3.7768
I0604 23:28:34.424401   904 solver.cpp:245]     Train net output #0: loss = 3.98904 (* 1 = 3.98904 loss)
I0604 23:28:34.424427   904 sgd_solver.cpp:106] Iteration 15240, lr = 0.0364141
I0604 23:28:54.849148   904 solver.cpp:229] Iteration 15280, loss = 3.82564
I0604 23:28:54.849211   904 solver.cpp:245]     Train net output #0: loss = 3.898 (* 1 = 3.898 loss)
I0604 23:28:54.849223   904 sgd_solver.cpp:106] Iteration 15280, lr = 0.0364047
I0604 23:29:15.149137   904 solver.cpp:229] Iteration 15320, loss = 3.78625
I0604 23:29:15.149376   904 solver.cpp:245]     Train net output #0: loss = 3.84411 (* 1 = 3.84411 loss)
I0604 23:29:15.149408   904 sgd_solver.cpp:106] Iteration 15320, lr = 0.0363953
I0604 23:29:35.376150   904 solver.cpp:229] Iteration 15360, loss = 3.76722
I0604 23:29:35.376197   904 solver.cpp:245]     Train net output #0: loss = 3.96666 (* 1 = 3.96666 loss)
I0604 23:29:35.376220   904 sgd_solver.cpp:106] Iteration 15360, lr = 0.0363859
I0604 23:29:55.375756   904 solver.cpp:229] Iteration 15400, loss = 3.73412
I0604 23:29:55.375908   904 solver.cpp:245]     Train net output #0: loss = 3.60191 (* 1 = 3.60191 loss)
I0604 23:29:55.375921   904 sgd_solver.cpp:106] Iteration 15400, lr = 0.0363765
I0604 23:30:15.483377   904 solver.cpp:229] Iteration 15440, loss = 3.76254
I0604 23:30:15.483420   904 solver.cpp:245]     Train net output #0: loss = 3.8809 (* 1 = 3.8809 loss)
I0604 23:30:15.483430   904 sgd_solver.cpp:106] Iteration 15440, lr = 0.0363671
I0604 23:30:22.910156   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0604 23:30:35.939368   904 solver.cpp:229] Iteration 15480, loss = 3.77569
I0604 23:30:35.939591   904 solver.cpp:245]     Train net output #0: loss = 3.97839 (* 1 = 3.97839 loss)
I0604 23:30:35.939618   904 sgd_solver.cpp:106] Iteration 15480, lr = 0.0363576
I0604 23:30:56.170140   904 solver.cpp:229] Iteration 15520, loss = 3.80106
I0604 23:30:56.170188   904 solver.cpp:245]     Train net output #0: loss = 3.56995 (* 1 = 3.56995 loss)
I0604 23:30:56.170197   904 sgd_solver.cpp:106] Iteration 15520, lr = 0.0363482
I0604 23:31:16.335168   904 solver.cpp:229] Iteration 15560, loss = 3.72598
I0604 23:31:16.335371   904 solver.cpp:245]     Train net output #0: loss = 3.5914 (* 1 = 3.5914 loss)
I0604 23:31:16.335402   904 sgd_solver.cpp:106] Iteration 15560, lr = 0.0363388
I0604 23:31:36.761657   904 solver.cpp:229] Iteration 15600, loss = 3.76297
I0604 23:31:36.761698   904 solver.cpp:245]     Train net output #0: loss = 3.5856 (* 1 = 3.5856 loss)
I0604 23:31:36.761706   904 sgd_solver.cpp:106] Iteration 15600, lr = 0.0363294
I0604 23:31:57.022807   904 solver.cpp:229] Iteration 15640, loss = 3.79095
I0604 23:31:57.022996   904 solver.cpp:245]     Train net output #0: loss = 3.80577 (* 1 = 3.80577 loss)
I0604 23:31:57.023020   904 sgd_solver.cpp:106] Iteration 15640, lr = 0.03632
I0604 23:32:17.281092   904 solver.cpp:229] Iteration 15680, loss = 3.79745
I0604 23:32:17.281133   904 solver.cpp:245]     Train net output #0: loss = 3.59835 (* 1 = 3.59835 loss)
I0604 23:32:17.281142   904 sgd_solver.cpp:106] Iteration 15680, lr = 0.0363106
I0604 23:32:37.527479   904 solver.cpp:229] Iteration 15720, loss = 3.70837
I0604 23:32:37.527657   904 solver.cpp:245]     Train net output #0: loss = 3.46324 (* 1 = 3.46324 loss)
I0604 23:32:37.527680   904 sgd_solver.cpp:106] Iteration 15720, lr = 0.0363012
I0604 23:32:57.750022   904 solver.cpp:229] Iteration 15760, loss = 3.73953
I0604 23:32:57.750073   904 solver.cpp:245]     Train net output #0: loss = 3.68469 (* 1 = 3.68469 loss)
I0604 23:32:57.750082   904 sgd_solver.cpp:106] Iteration 15760, lr = 0.0362918
I0604 23:33:17.974212   904 solver.cpp:229] Iteration 15800, loss = 3.74199
I0604 23:33:17.974460   904 solver.cpp:245]     Train net output #0: loss = 3.78891 (* 1 = 3.78891 loss)
I0604 23:33:17.974472   904 sgd_solver.cpp:106] Iteration 15800, lr = 0.0362824
I0604 23:33:38.209934   904 solver.cpp:229] Iteration 15840, loss = 3.68683
I0604 23:33:38.209967   904 solver.cpp:245]     Train net output #0: loss = 3.58653 (* 1 = 3.58653 loss)
I0604 23:33:38.209975   904 sgd_solver.cpp:106] Iteration 15840, lr = 0.0362729
I0604 23:33:58.449765   904 solver.cpp:229] Iteration 15880, loss = 3.71788
I0604 23:33:58.449960   904 solver.cpp:245]     Train net output #0: loss = 3.997 (* 1 = 3.997 loss)
I0604 23:33:58.449987   904 sgd_solver.cpp:106] Iteration 15880, lr = 0.0362635
I0604 23:34:18.674590   904 solver.cpp:229] Iteration 15920, loss = 3.73506
I0604 23:34:18.674657   904 solver.cpp:245]     Train net output #0: loss = 3.70886 (* 1 = 3.70886 loss)
I0604 23:34:18.674670   904 sgd_solver.cpp:106] Iteration 15920, lr = 0.0362541
I0604 23:34:38.892477   904 solver.cpp:229] Iteration 15960, loss = 3.69334
I0604 23:34:38.892652   904 solver.cpp:245]     Train net output #0: loss = 3.61635 (* 1 = 3.61635 loss)
I0604 23:34:38.892674   904 sgd_solver.cpp:106] Iteration 15960, lr = 0.0362447
I0604 23:34:53.578331   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0604 23:34:58.640872   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_16000.caffemodel
I0604 23:34:58.893090   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_16000.solverstate
I0604 23:34:58.968911   904 solver.cpp:338] Iteration 16000, Testing net (#0)
I0604 23:34:58.968969   904 net.cpp:748] Ignoring source layer loss
I0604 23:35:31.395923   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0604 23:36:04.582298   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0604 23:36:05.171368   904 solver.cpp:406]     Test net output #0: accuracy = 0.2669
I0604 23:36:05.171404   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.50174
I0604 23:36:05.486207   904 solver.cpp:229] Iteration 16000, loss = 3.7057
I0604 23:36:05.486256   904 solver.cpp:245]     Train net output #0: loss = 3.54118 (* 1 = 3.54118 loss)
I0604 23:36:05.486264   904 sgd_solver.cpp:106] Iteration 16000, lr = 0.0362353
I0604 23:36:24.729725   904 solver.cpp:229] Iteration 16040, loss = 3.74172
I0604 23:36:24.729766   904 solver.cpp:245]     Train net output #0: loss = 3.69322 (* 1 = 3.69322 loss)
I0604 23:36:24.729775   904 sgd_solver.cpp:106] Iteration 16040, lr = 0.0362259
I0604 23:36:46.028522   904 solver.cpp:229] Iteration 16080, loss = 3.71264
I0604 23:36:46.028730   904 solver.cpp:245]     Train net output #0: loss = 3.70199 (* 1 = 3.70199 loss)
I0604 23:36:46.028753   904 sgd_solver.cpp:106] Iteration 16080, lr = 0.0362165
I0604 23:37:07.373841   904 solver.cpp:229] Iteration 16120, loss = 3.68693
I0604 23:37:07.373888   904 solver.cpp:245]     Train net output #0: loss = 3.77028 (* 1 = 3.77028 loss)
I0604 23:37:07.373895   904 sgd_solver.cpp:106] Iteration 16120, lr = 0.0362071
I0604 23:37:28.373556   904 solver.cpp:229] Iteration 16160, loss = 3.80486
I0604 23:37:28.373764   904 solver.cpp:245]     Train net output #0: loss = 3.95579 (* 1 = 3.95579 loss)
I0604 23:37:28.373792   904 sgd_solver.cpp:106] Iteration 16160, lr = 0.0361976
I0604 23:37:49.402340   904 solver.cpp:229] Iteration 16200, loss = 3.71128
I0604 23:37:49.402390   904 solver.cpp:245]     Train net output #0: loss = 3.66829 (* 1 = 3.66829 loss)
I0604 23:37:49.402400   904 sgd_solver.cpp:106] Iteration 16200, lr = 0.0361882
I0604 23:38:10.418081   904 solver.cpp:229] Iteration 16240, loss = 3.68601
I0604 23:38:10.418237   904 solver.cpp:245]     Train net output #0: loss = 3.76111 (* 1 = 3.76111 loss)
I0604 23:38:10.418247   904 sgd_solver.cpp:106] Iteration 16240, lr = 0.0361788
I0604 23:38:31.238255   904 solver.cpp:229] Iteration 16280, loss = 3.69571
I0604 23:38:31.238293   904 solver.cpp:245]     Train net output #0: loss = 3.88507 (* 1 = 3.88507 loss)
I0604 23:38:31.238302   904 sgd_solver.cpp:106] Iteration 16280, lr = 0.0361694
I0604 23:38:51.988175   904 solver.cpp:229] Iteration 16320, loss = 3.69055
I0604 23:38:51.988420   904 solver.cpp:245]     Train net output #0: loss = 3.9223 (* 1 = 3.9223 loss)
I0604 23:38:51.988430   904 sgd_solver.cpp:106] Iteration 16320, lr = 0.03616
I0604 23:39:12.694972   904 solver.cpp:229] Iteration 16360, loss = 3.7014
I0604 23:39:12.695030   904 solver.cpp:245]     Train net output #0: loss = 3.29517 (* 1 = 3.29517 loss)
I0604 23:39:12.695039   904 sgd_solver.cpp:106] Iteration 16360, lr = 0.0361506
I0604 23:39:33.438051   904 solver.cpp:229] Iteration 16400, loss = 3.70739
I0604 23:39:33.438253   904 solver.cpp:245]     Train net output #0: loss = 3.78112 (* 1 = 3.78112 loss)
I0604 23:39:33.438279   904 sgd_solver.cpp:106] Iteration 16400, lr = 0.0361412
I0604 23:39:54.182251   904 solver.cpp:229] Iteration 16440, loss = 3.69935
I0604 23:39:54.182304   904 solver.cpp:245]     Train net output #0: loss = 3.86041 (* 1 = 3.86041 loss)
I0604 23:39:54.182313   904 sgd_solver.cpp:106] Iteration 16440, lr = 0.0361318
I0604 23:40:14.836566   904 solver.cpp:229] Iteration 16480, loss = 3.7034
I0604 23:40:14.836730   904 solver.cpp:245]     Train net output #0: loss = 3.81845 (* 1 = 3.81845 loss)
I0604 23:40:14.836755   904 sgd_solver.cpp:106] Iteration 16480, lr = 0.0361224
I0604 23:40:35.378443   904 solver.cpp:229] Iteration 16520, loss = 3.71445
I0604 23:40:35.378481   904 solver.cpp:245]     Train net output #0: loss = 4.0592 (* 1 = 4.0592 loss)
I0604 23:40:35.378491   904 sgd_solver.cpp:106] Iteration 16520, lr = 0.0361129
I0604 23:40:56.043792   904 solver.cpp:229] Iteration 16560, loss = 3.68638
I0604 23:40:56.043967   904 solver.cpp:245]     Train net output #0: loss = 3.43533 (* 1 = 3.43533 loss)
I0604 23:40:56.043993   904 sgd_solver.cpp:106] Iteration 16560, lr = 0.0361035
I0604 23:40:56.047318   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0604 23:41:16.592202   904 solver.cpp:229] Iteration 16600, loss = 3.6882
I0604 23:41:16.592241   904 solver.cpp:245]     Train net output #0: loss = 3.72184 (* 1 = 3.72184 loss)
I0604 23:41:16.592247   904 sgd_solver.cpp:106] Iteration 16600, lr = 0.0360941
I0604 23:41:37.138556   904 solver.cpp:229] Iteration 16640, loss = 3.68223
I0604 23:41:37.138698   904 solver.cpp:245]     Train net output #0: loss = 3.55907 (* 1 = 3.55907 loss)
I0604 23:41:37.138707   904 sgd_solver.cpp:106] Iteration 16640, lr = 0.0360847
I0604 23:41:57.679751   904 solver.cpp:229] Iteration 16680, loss = 3.72857
I0604 23:41:57.679801   904 solver.cpp:245]     Train net output #0: loss = 3.70186 (* 1 = 3.70186 loss)
I0604 23:41:57.679811   904 sgd_solver.cpp:106] Iteration 16680, lr = 0.0360753
I0604 23:42:18.194576   904 solver.cpp:229] Iteration 16720, loss = 3.68037
I0604 23:42:18.194774   904 solver.cpp:245]     Train net output #0: loss = 3.46392 (* 1 = 3.46392 loss)
I0604 23:42:18.194802   904 sgd_solver.cpp:106] Iteration 16720, lr = 0.0360659
I0604 23:42:38.727833   904 solver.cpp:229] Iteration 16760, loss = 3.65445
I0604 23:42:38.727885   904 solver.cpp:245]     Train net output #0: loss = 3.76666 (* 1 = 3.76666 loss)
I0604 23:42:38.727895   904 sgd_solver.cpp:106] Iteration 16760, lr = 0.0360565
I0604 23:42:59.264286   904 solver.cpp:229] Iteration 16800, loss = 3.71015
I0604 23:42:59.264459   904 solver.cpp:245]     Train net output #0: loss = 3.6099 (* 1 = 3.6099 loss)
I0604 23:42:59.264482   904 sgd_solver.cpp:106] Iteration 16800, lr = 0.0360471
I0604 23:43:19.798372   904 solver.cpp:229] Iteration 16840, loss = 3.59149
I0604 23:43:19.798423   904 solver.cpp:245]     Train net output #0: loss = 3.79862 (* 1 = 3.79862 loss)
I0604 23:43:19.798430   904 sgd_solver.cpp:106] Iteration 16840, lr = 0.0360376
I0604 23:43:40.330464   904 solver.cpp:229] Iteration 16880, loss = 3.67577
I0604 23:43:40.330678   904 solver.cpp:245]     Train net output #0: loss = 3.73685 (* 1 = 3.73685 loss)
I0604 23:43:40.330706   904 sgd_solver.cpp:106] Iteration 16880, lr = 0.0360282
I0604 23:44:00.887275   904 solver.cpp:229] Iteration 16920, loss = 3.73225
I0604 23:44:00.887320   904 solver.cpp:245]     Train net output #0: loss = 4.03446 (* 1 = 4.03446 loss)
I0604 23:44:00.887331   904 sgd_solver.cpp:106] Iteration 16920, lr = 0.0360188
I0604 23:44:21.420357   904 solver.cpp:229] Iteration 16960, loss = 3.6881
I0604 23:44:21.420522   904 solver.cpp:245]     Train net output #0: loss = 3.86824 (* 1 = 3.86824 loss)
I0604 23:44:21.420534   904 sgd_solver.cpp:106] Iteration 16960, lr = 0.0360094
I0604 23:44:41.440799   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_17000.caffemodel
I0604 23:44:41.706271   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_17000.solverstate
I0604 23:44:41.787386   904 solver.cpp:338] Iteration 17000, Testing net (#0)
I0604 23:44:41.787464   904 net.cpp:748] Ignoring source layer loss
I0604 23:44:48.300117   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0604 23:45:22.241888   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0604 23:45:49.875434   904 solver.cpp:406]     Test net output #0: accuracy = 0.26226
I0604 23:45:49.875468   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.4967
I0604 23:45:50.190923   904 solver.cpp:229] Iteration 17000, loss = 3.68516
I0604 23:45:50.190963   904 solver.cpp:245]     Train net output #0: loss = 3.82683 (* 1 = 3.82683 loss)
I0604 23:45:50.190973   904 sgd_solver.cpp:106] Iteration 17000, lr = 0.036
I0604 23:46:09.425729   904 solver.cpp:229] Iteration 17040, loss = 3.69267
I0604 23:46:09.425863   904 solver.cpp:245]     Train net output #0: loss = 3.59729 (* 1 = 3.59729 loss)
I0604 23:46:09.425876   904 sgd_solver.cpp:106] Iteration 17040, lr = 0.0359906
I0604 23:46:30.855938   904 solver.cpp:229] Iteration 17080, loss = 3.64824
I0604 23:46:30.855995   904 solver.cpp:245]     Train net output #0: loss = 3.58686 (* 1 = 3.58686 loss)
I0604 23:46:30.856019   904 sgd_solver.cpp:106] Iteration 17080, lr = 0.0359812
I0604 23:46:41.086516   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0604 23:46:52.305137   904 solver.cpp:229] Iteration 17120, loss = 3.65275
I0604 23:46:52.305181   904 solver.cpp:245]     Train net output #0: loss = 3.67079 (* 1 = 3.67079 loss)
I0604 23:46:52.305188   904 sgd_solver.cpp:106] Iteration 17120, lr = 0.0359718
I0604 23:47:13.280279   904 solver.cpp:229] Iteration 17160, loss = 3.66523
I0604 23:47:13.280437   904 solver.cpp:245]     Train net output #0: loss = 3.66643 (* 1 = 3.66643 loss)
I0604 23:47:13.280459   904 sgd_solver.cpp:106] Iteration 17160, lr = 0.0359624
I0604 23:47:34.261348   904 solver.cpp:229] Iteration 17200, loss = 3.68818
I0604 23:47:34.261384   904 solver.cpp:245]     Train net output #0: loss = 3.61374 (* 1 = 3.61374 loss)
I0604 23:47:34.261391   904 sgd_solver.cpp:106] Iteration 17200, lr = 0.0359529
I0604 23:47:55.242332   904 solver.cpp:229] Iteration 17240, loss = 3.62432
I0604 23:47:55.242513   904 solver.cpp:245]     Train net output #0: loss = 3.80361 (* 1 = 3.80361 loss)
I0604 23:47:55.242533   904 sgd_solver.cpp:106] Iteration 17240, lr = 0.0359435
I0604 23:48:16.230417   904 solver.cpp:229] Iteration 17280, loss = 3.7114
I0604 23:48:16.230454   904 solver.cpp:245]     Train net output #0: loss = 3.73459 (* 1 = 3.73459 loss)
I0604 23:48:16.230463   904 sgd_solver.cpp:106] Iteration 17280, lr = 0.0359341
I0604 23:48:37.183435   904 solver.cpp:229] Iteration 17320, loss = 3.62414
I0604 23:48:37.183647   904 solver.cpp:245]     Train net output #0: loss = 3.46031 (* 1 = 3.46031 loss)
I0604 23:48:37.183673   904 sgd_solver.cpp:106] Iteration 17320, lr = 0.0359247
I0604 23:48:57.851316   904 solver.cpp:229] Iteration 17360, loss = 3.61648
I0604 23:48:57.851353   904 solver.cpp:245]     Train net output #0: loss = 3.47302 (* 1 = 3.47302 loss)
I0604 23:48:57.851361   904 sgd_solver.cpp:106] Iteration 17360, lr = 0.0359153
I0604 23:49:18.520287   904 solver.cpp:229] Iteration 17400, loss = 3.65137
I0604 23:49:18.520581   904 solver.cpp:245]     Train net output #0: loss = 3.87667 (* 1 = 3.87667 loss)
I0604 23:49:18.520606   904 sgd_solver.cpp:106] Iteration 17400, lr = 0.0359059
I0604 23:49:39.240057   904 solver.cpp:229] Iteration 17440, loss = 3.64177
I0604 23:49:39.240097   904 solver.cpp:245]     Train net output #0: loss = 3.60779 (* 1 = 3.60779 loss)
I0604 23:49:39.240105   904 sgd_solver.cpp:106] Iteration 17440, lr = 0.0358965
I0604 23:49:59.892570   904 solver.cpp:229] Iteration 17480, loss = 3.6565
I0604 23:49:59.892696   904 solver.cpp:245]     Train net output #0: loss = 3.62269 (* 1 = 3.62269 loss)
I0604 23:49:59.892705   904 sgd_solver.cpp:106] Iteration 17480, lr = 0.0358871
I0604 23:50:20.571449   904 solver.cpp:229] Iteration 17520, loss = 3.66321
I0604 23:50:20.571509   904 solver.cpp:245]     Train net output #0: loss = 3.90339 (* 1 = 3.90339 loss)
I0604 23:50:20.571518   904 sgd_solver.cpp:106] Iteration 17520, lr = 0.0358776
I0604 23:50:41.246508   904 solver.cpp:229] Iteration 17560, loss = 3.66481
I0604 23:50:41.246692   904 solver.cpp:245]     Train net output #0: loss = 3.35735 (* 1 = 3.35735 loss)
I0604 23:50:41.246714   904 sgd_solver.cpp:106] Iteration 17560, lr = 0.0358682
I0604 23:51:01.809170   904 solver.cpp:229] Iteration 17600, loss = 3.62839
I0604 23:51:01.809221   904 solver.cpp:245]     Train net output #0: loss = 3.7016 (* 1 = 3.7016 loss)
I0604 23:51:01.809229   904 sgd_solver.cpp:106] Iteration 17600, lr = 0.0358588
I0604 23:51:22.307561   904 solver.cpp:229] Iteration 17640, loss = 3.62301
I0604 23:51:22.307750   904 solver.cpp:245]     Train net output #0: loss = 3.71503 (* 1 = 3.71503 loss)
I0604 23:51:22.307770   904 sgd_solver.cpp:106] Iteration 17640, lr = 0.0358494
I0604 23:51:41.492916   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0604 23:51:42.775043   904 solver.cpp:229] Iteration 17680, loss = 3.61668
I0604 23:51:42.775089   904 solver.cpp:245]     Train net output #0: loss = 3.63269 (* 1 = 3.63269 loss)
I0604 23:51:42.775096   904 sgd_solver.cpp:106] Iteration 17680, lr = 0.03584
I0604 23:52:03.384878   904 solver.cpp:229] Iteration 17720, loss = 3.65405
I0604 23:52:03.385118   904 solver.cpp:245]     Train net output #0: loss = 3.2534 (* 1 = 3.2534 loss)
I0604 23:52:03.385143   904 sgd_solver.cpp:106] Iteration 17720, lr = 0.0358306
I0604 23:52:23.913103   904 solver.cpp:229] Iteration 17760, loss = 3.61517
I0604 23:52:23.913133   904 solver.cpp:245]     Train net output #0: loss = 3.4757 (* 1 = 3.4757 loss)
I0604 23:52:23.913139   904 sgd_solver.cpp:106] Iteration 17760, lr = 0.0358212
I0604 23:52:44.295908   904 solver.cpp:229] Iteration 17800, loss = 3.65604
I0604 23:52:44.296052   904 solver.cpp:245]     Train net output #0: loss = 3.53641 (* 1 = 3.53641 loss)
I0604 23:52:44.296077   904 sgd_solver.cpp:106] Iteration 17800, lr = 0.0358118
I0604 23:53:04.564538   904 solver.cpp:229] Iteration 17840, loss = 3.62373
I0604 23:53:04.564584   904 solver.cpp:245]     Train net output #0: loss = 3.5086 (* 1 = 3.5086 loss)
I0604 23:53:04.564592   904 sgd_solver.cpp:106] Iteration 17840, lr = 0.0358024
I0604 23:53:24.959081   904 solver.cpp:229] Iteration 17880, loss = 3.58707
I0604 23:53:24.959216   904 solver.cpp:245]     Train net output #0: loss = 3.36861 (* 1 = 3.36861 loss)
I0604 23:53:24.959225   904 sgd_solver.cpp:106] Iteration 17880, lr = 0.0357929
I0604 23:53:45.453085   904 solver.cpp:229] Iteration 17920, loss = 3.60434
I0604 23:53:45.453136   904 solver.cpp:245]     Train net output #0: loss = 3.50045 (* 1 = 3.50045 loss)
I0604 23:53:45.453150   904 sgd_solver.cpp:106] Iteration 17920, lr = 0.0357835
I0604 23:54:05.904472   904 solver.cpp:229] Iteration 17960, loss = 3.62402
I0604 23:54:05.904644   904 solver.cpp:245]     Train net output #0: loss = 3.61646 (* 1 = 3.61646 loss)
I0604 23:54:05.904664   904 sgd_solver.cpp:106] Iteration 17960, lr = 0.0357741
I0604 23:54:26.233129   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_18000.caffemodel
I0604 23:54:26.493651   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_18000.solverstate
I0604 23:54:26.570442   904 solver.cpp:338] Iteration 18000, Testing net (#0)
I0604 23:54:26.570523   904 net.cpp:748] Ignoring source layer loss
I0604 23:54:41.971243   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0604 23:55:16.035554   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0604 23:55:34.348476   904 solver.cpp:406]     Test net output #0: accuracy = 0.27228
I0604 23:55:34.348517   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.512339
I0604 23:55:34.665724   904 solver.cpp:229] Iteration 18000, loss = 3.66408
I0604 23:55:34.665817   904 solver.cpp:245]     Train net output #0: loss = 3.60788 (* 1 = 3.60788 loss)
I0604 23:55:34.665841   904 sgd_solver.cpp:106] Iteration 18000, lr = 0.0357647
I0604 23:55:53.851016   904 solver.cpp:229] Iteration 18040, loss = 3.57799
I0604 23:55:53.851155   904 solver.cpp:245]     Train net output #0: loss = 3.52728 (* 1 = 3.52728 loss)
I0604 23:55:53.851167   904 sgd_solver.cpp:106] Iteration 18040, lr = 0.0357553
I0604 23:56:15.114439   904 solver.cpp:229] Iteration 18080, loss = 3.57302
I0604 23:56:15.114482   904 solver.cpp:245]     Train net output #0: loss = 3.62652 (* 1 = 3.62652 loss)
I0604 23:56:15.114492   904 sgd_solver.cpp:106] Iteration 18080, lr = 0.0357459
I0604 23:56:36.527446   904 solver.cpp:229] Iteration 18120, loss = 3.57568
I0604 23:56:36.527614   904 solver.cpp:245]     Train net output #0: loss = 3.52516 (* 1 = 3.52516 loss)
I0604 23:56:36.527624   904 sgd_solver.cpp:106] Iteration 18120, lr = 0.0357365
I0604 23:56:57.746889   904 solver.cpp:229] Iteration 18160, loss = 3.62295
I0604 23:56:57.746932   904 solver.cpp:245]     Train net output #0: loss = 3.69342 (* 1 = 3.69342 loss)
I0604 23:56:57.746938   904 sgd_solver.cpp:106] Iteration 18160, lr = 0.0357271
I0604 23:57:18.708079   904 solver.cpp:229] Iteration 18200, loss = 3.64304
I0604 23:57:18.708250   904 solver.cpp:245]     Train net output #0: loss = 3.55238 (* 1 = 3.55238 loss)
I0604 23:57:18.708272   904 sgd_solver.cpp:106] Iteration 18200, lr = 0.0357176
I0604 23:57:39.675750   904 solver.cpp:229] Iteration 18240, loss = 3.6126
I0604 23:57:39.675807   904 solver.cpp:245]     Train net output #0: loss = 3.78237 (* 1 = 3.78237 loss)
I0604 23:57:39.675817   904 sgd_solver.cpp:106] Iteration 18240, lr = 0.0357082
I0604 23:57:41.252356   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0604 23:58:00.635987   904 solver.cpp:229] Iteration 18280, loss = 3.6177
I0604 23:58:00.636133   904 solver.cpp:245]     Train net output #0: loss = 3.70974 (* 1 = 3.70974 loss)
I0604 23:58:00.636144   904 sgd_solver.cpp:106] Iteration 18280, lr = 0.0356988
I0604 23:58:21.497217   904 solver.cpp:229] Iteration 18320, loss = 3.63343
I0604 23:58:21.497265   904 solver.cpp:245]     Train net output #0: loss = 3.44453 (* 1 = 3.44453 loss)
I0604 23:58:21.497282   904 sgd_solver.cpp:106] Iteration 18320, lr = 0.0356894
I0604 23:58:42.150682   904 solver.cpp:229] Iteration 18360, loss = 3.6091
I0604 23:58:42.150898   904 solver.cpp:245]     Train net output #0: loss = 3.43395 (* 1 = 3.43395 loss)
I0604 23:58:42.150946   904 sgd_solver.cpp:106] Iteration 18360, lr = 0.03568
I0604 23:59:02.809258   904 solver.cpp:229] Iteration 18400, loss = 3.59861
I0604 23:59:02.809298   904 solver.cpp:245]     Train net output #0: loss = 3.9113 (* 1 = 3.9113 loss)
I0604 23:59:02.809309   904 sgd_solver.cpp:106] Iteration 18400, lr = 0.0356706
I0604 23:59:23.445454   904 solver.cpp:229] Iteration 18440, loss = 3.57654
I0604 23:59:23.445662   904 solver.cpp:245]     Train net output #0: loss = 3.64695 (* 1 = 3.64695 loss)
I0604 23:59:23.445688   904 sgd_solver.cpp:106] Iteration 18440, lr = 0.0356612
I0604 23:59:44.073791   904 solver.cpp:229] Iteration 18480, loss = 3.598
I0604 23:59:44.073843   904 solver.cpp:245]     Train net output #0: loss = 3.71111 (* 1 = 3.71111 loss)
I0604 23:59:44.073853   904 sgd_solver.cpp:106] Iteration 18480, lr = 0.0356518
I0605 00:00:04.569319   904 solver.cpp:229] Iteration 18520, loss = 3.60188
I0605 00:00:04.569556   904 solver.cpp:245]     Train net output #0: loss = 3.44569 (* 1 = 3.44569 loss)
I0605 00:00:04.569583   904 sgd_solver.cpp:106] Iteration 18520, lr = 0.0356424
I0605 00:00:25.053057   904 solver.cpp:229] Iteration 18560, loss = 3.57972
I0605 00:00:25.053110   904 solver.cpp:245]     Train net output #0: loss = 3.58398 (* 1 = 3.58398 loss)
I0605 00:00:25.053124   904 sgd_solver.cpp:106] Iteration 18560, lr = 0.0356329
I0605 00:00:45.523869   904 solver.cpp:229] Iteration 18600, loss = 3.56676
I0605 00:00:45.524066   904 solver.cpp:245]     Train net output #0: loss = 3.72832 (* 1 = 3.72832 loss)
I0605 00:00:45.524092   904 sgd_solver.cpp:106] Iteration 18600, lr = 0.0356235
I0605 00:01:05.996793   904 solver.cpp:229] Iteration 18640, loss = 3.59384
I0605 00:01:05.996860   904 solver.cpp:245]     Train net output #0: loss = 3.73288 (* 1 = 3.73288 loss)
I0605 00:01:05.996868   904 sgd_solver.cpp:106] Iteration 18640, lr = 0.0356141
I0605 00:01:26.461359   904 solver.cpp:229] Iteration 18680, loss = 3.62605
I0605 00:01:26.461572   904 solver.cpp:245]     Train net output #0: loss = 3.64975 (* 1 = 3.64975 loss)
I0605 00:01:26.461604   904 sgd_solver.cpp:106] Iteration 18680, lr = 0.0356047
I0605 00:01:46.898636   904 solver.cpp:229] Iteration 18720, loss = 3.61666
I0605 00:01:46.898694   904 solver.cpp:245]     Train net output #0: loss = 3.5481 (* 1 = 3.5481 loss)
I0605 00:01:46.898704   904 sgd_solver.cpp:106] Iteration 18720, lr = 0.0355953
I0605 00:01:59.955991   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 00:02:07.298821   904 solver.cpp:229] Iteration 18760, loss = 3.62342
I0605 00:02:07.298864   904 solver.cpp:245]     Train net output #0: loss = 3.64642 (* 1 = 3.64642 loss)
I0605 00:02:07.298874   904 sgd_solver.cpp:106] Iteration 18760, lr = 0.0355859
I0605 00:02:27.566304   904 solver.cpp:229] Iteration 18800, loss = 3.5563
I0605 00:02:27.566344   904 solver.cpp:245]     Train net output #0: loss = 3.62282 (* 1 = 3.62282 loss)
I0605 00:02:27.566352   904 sgd_solver.cpp:106] Iteration 18800, lr = 0.0355765
I0605 00:02:47.838739   904 solver.cpp:229] Iteration 18840, loss = 3.58692
I0605 00:02:47.838868   904 solver.cpp:245]     Train net output #0: loss = 3.6513 (* 1 = 3.6513 loss)
I0605 00:02:47.838882   904 sgd_solver.cpp:106] Iteration 18840, lr = 0.0355671
I0605 00:03:08.114933   904 solver.cpp:229] Iteration 18880, loss = 3.57192
I0605 00:03:08.114982   904 solver.cpp:245]     Train net output #0: loss = 3.28457 (* 1 = 3.28457 loss)
I0605 00:03:08.114995   904 sgd_solver.cpp:106] Iteration 18880, lr = 0.0355576
I0605 00:03:28.395011   904 solver.cpp:229] Iteration 18920, loss = 3.56863
I0605 00:03:28.395160   904 solver.cpp:245]     Train net output #0: loss = 3.42707 (* 1 = 3.42707 loss)
I0605 00:03:28.395175   904 sgd_solver.cpp:106] Iteration 18920, lr = 0.0355482
I0605 00:03:48.636535   904 solver.cpp:229] Iteration 18960, loss = 3.61011
I0605 00:03:48.636592   904 solver.cpp:245]     Train net output #0: loss = 3.66925 (* 1 = 3.66925 loss)
I0605 00:03:48.636605   904 sgd_solver.cpp:106] Iteration 18960, lr = 0.0355388
I0605 00:04:08.380511   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_19000.caffemodel
I0605 00:04:08.640218   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_19000.solverstate
I0605 00:04:08.719058   904 solver.cpp:338] Iteration 19000, Testing net (#0)
I0605 00:04:08.719161   904 net.cpp:748] Ignoring source layer loss
I0605 00:04:26.130486   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 00:05:00.516247   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 00:05:17.534651   904 solver.cpp:406]     Test net output #0: accuracy = 0.28676
I0605 00:05:17.534694   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.529019
I0605 00:05:17.850026   904 solver.cpp:229] Iteration 19000, loss = 3.60436
I0605 00:05:17.850067   904 solver.cpp:245]     Train net output #0: loss = 3.81265 (* 1 = 3.81265 loss)
I0605 00:05:17.850076   904 sgd_solver.cpp:106] Iteration 19000, lr = 0.0355294
I0605 00:05:37.048583   904 solver.cpp:229] Iteration 19040, loss = 3.5889
I0605 00:05:37.048840   904 solver.cpp:245]     Train net output #0: loss = 3.49966 (* 1 = 3.49966 loss)
I0605 00:05:37.048868   904 sgd_solver.cpp:106] Iteration 19040, lr = 0.03552
I0605 00:05:59.180896   904 solver.cpp:229] Iteration 19080, loss = 3.58083
I0605 00:05:59.180948   904 solver.cpp:245]     Train net output #0: loss = 3.73087 (* 1 = 3.73087 loss)
I0605 00:05:59.180958   904 sgd_solver.cpp:106] Iteration 19080, lr = 0.0355106
I0605 00:06:21.403566   904 solver.cpp:229] Iteration 19120, loss = 3.55296
I0605 00:06:21.403729   904 solver.cpp:245]     Train net output #0: loss = 3.69115 (* 1 = 3.69115 loss)
I0605 00:06:21.403738   904 sgd_solver.cpp:106] Iteration 19120, lr = 0.0355012
I0605 00:06:42.395143   904 solver.cpp:229] Iteration 19160, loss = 3.5793
I0605 00:06:42.395195   904 solver.cpp:245]     Train net output #0: loss = 3.63019 (* 1 = 3.63019 loss)
I0605 00:06:42.395205   904 sgd_solver.cpp:106] Iteration 19160, lr = 0.0354918
I0605 00:07:03.486276   904 solver.cpp:229] Iteration 19200, loss = 3.59398
I0605 00:07:03.486466   904 solver.cpp:245]     Train net output #0: loss = 3.33244 (* 1 = 3.33244 loss)
I0605 00:07:03.486491   904 sgd_solver.cpp:106] Iteration 19200, lr = 0.0354824
I0605 00:07:24.237630   904 solver.cpp:229] Iteration 19240, loss = 3.54673
I0605 00:07:24.237699   904 solver.cpp:245]     Train net output #0: loss = 3.62353 (* 1 = 3.62353 loss)
I0605 00:07:24.237709   904 sgd_solver.cpp:106] Iteration 19240, lr = 0.0354729
I0605 00:07:31.980844   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 00:07:44.896282   904 solver.cpp:229] Iteration 19280, loss = 3.57172
I0605 00:07:44.896440   904 solver.cpp:245]     Train net output #0: loss = 3.72297 (* 1 = 3.72297 loss)
I0605 00:07:44.896453   904 sgd_solver.cpp:106] Iteration 19280, lr = 0.0354635
I0605 00:08:05.567672   904 solver.cpp:229] Iteration 19320, loss = 3.53807
I0605 00:08:05.567729   904 solver.cpp:245]     Train net output #0: loss = 3.32397 (* 1 = 3.32397 loss)
I0605 00:08:05.567739   904 sgd_solver.cpp:106] Iteration 19320, lr = 0.0354541
I0605 00:08:26.238785   904 solver.cpp:229] Iteration 19360, loss = 3.53816
I0605 00:08:26.238963   904 solver.cpp:245]     Train net output #0: loss = 3.54561 (* 1 = 3.54561 loss)
I0605 00:08:26.238991   904 sgd_solver.cpp:106] Iteration 19360, lr = 0.0354447
I0605 00:08:46.899957   904 solver.cpp:229] Iteration 19400, loss = 3.54085
I0605 00:08:46.900008   904 solver.cpp:245]     Train net output #0: loss = 3.51651 (* 1 = 3.51651 loss)
I0605 00:08:46.900017   904 sgd_solver.cpp:106] Iteration 19400, lr = 0.0354353
I0605 00:09:07.424484   904 solver.cpp:229] Iteration 19440, loss = 3.51598
I0605 00:09:07.424687   904 solver.cpp:245]     Train net output #0: loss = 3.57988 (* 1 = 3.57988 loss)
I0605 00:09:07.424713   904 sgd_solver.cpp:106] Iteration 19440, lr = 0.0354259
I0605 00:09:27.994891   904 solver.cpp:229] Iteration 19480, loss = 3.53773
I0605 00:09:27.994936   904 solver.cpp:245]     Train net output #0: loss = 3.50654 (* 1 = 3.50654 loss)
I0605 00:09:27.994946   904 sgd_solver.cpp:106] Iteration 19480, lr = 0.0354165
I0605 00:09:48.606458   904 solver.cpp:229] Iteration 19520, loss = 3.52689
I0605 00:09:48.606623   904 solver.cpp:245]     Train net output #0: loss = 3.57777 (* 1 = 3.57777 loss)
I0605 00:09:48.606636   904 sgd_solver.cpp:106] Iteration 19520, lr = 0.0354071
I0605 00:10:09.147735   904 solver.cpp:229] Iteration 19560, loss = 3.55219
I0605 00:10:09.147791   904 solver.cpp:245]     Train net output #0: loss = 3.68082 (* 1 = 3.68082 loss)
I0605 00:10:09.147801   904 sgd_solver.cpp:106] Iteration 19560, lr = 0.0353976
I0605 00:10:29.648705   904 solver.cpp:229] Iteration 19600, loss = 3.54674
I0605 00:10:29.648915   904 solver.cpp:245]     Train net output #0: loss = 3.72153 (* 1 = 3.72153 loss)
I0605 00:10:29.648929   904 sgd_solver.cpp:106] Iteration 19600, lr = 0.0353882
I0605 00:10:50.157829   904 solver.cpp:229] Iteration 19640, loss = 3.5678
I0605 00:10:50.157877   904 solver.cpp:245]     Train net output #0: loss = 3.51862 (* 1 = 3.51862 loss)
I0605 00:10:50.157896   904 sgd_solver.cpp:106] Iteration 19640, lr = 0.0353788
I0605 00:11:10.662992   904 solver.cpp:229] Iteration 19680, loss = 3.53947
I0605 00:11:10.663192   904 solver.cpp:245]     Train net output #0: loss = 3.57531 (* 1 = 3.57531 loss)
I0605 00:11:10.663203   904 sgd_solver.cpp:106] Iteration 19680, lr = 0.0353694
I0605 00:11:31.194437   904 solver.cpp:229] Iteration 19720, loss = 3.53453
I0605 00:11:31.194481   904 solver.cpp:245]     Train net output #0: loss = 3.4875 (* 1 = 3.4875 loss)
I0605 00:11:31.194490   904 sgd_solver.cpp:106] Iteration 19720, lr = 0.03536
I0605 00:11:49.652700   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 00:11:51.696833   904 solver.cpp:229] Iteration 19760, loss = 3.55396
I0605 00:11:51.696890   904 solver.cpp:245]     Train net output #0: loss = 3.67876 (* 1 = 3.67876 loss)
I0605 00:11:51.696900   904 sgd_solver.cpp:106] Iteration 19760, lr = 0.0353506
I0605 00:12:12.205648   904 solver.cpp:229] Iteration 19800, loss = 3.56464
I0605 00:12:12.205705   904 solver.cpp:245]     Train net output #0: loss = 3.4867 (* 1 = 3.4867 loss)
I0605 00:12:12.205716   904 sgd_solver.cpp:106] Iteration 19800, lr = 0.0353412
I0605 00:12:32.721640   904 solver.cpp:229] Iteration 19840, loss = 3.49782
I0605 00:12:32.721856   904 solver.cpp:245]     Train net output #0: loss = 3.43075 (* 1 = 3.43075 loss)
I0605 00:12:32.721884   904 sgd_solver.cpp:106] Iteration 19840, lr = 0.0353318
I0605 00:12:53.199929   904 solver.cpp:229] Iteration 19880, loss = 3.49472
I0605 00:12:53.199976   904 solver.cpp:245]     Train net output #0: loss = 3.57991 (* 1 = 3.57991 loss)
I0605 00:12:53.199985   904 sgd_solver.cpp:106] Iteration 19880, lr = 0.0353224
I0605 00:13:13.697592   904 solver.cpp:229] Iteration 19920, loss = 3.53809
I0605 00:13:13.697795   904 solver.cpp:245]     Train net output #0: loss = 3.54402 (* 1 = 3.54402 loss)
I0605 00:13:13.697821   904 sgd_solver.cpp:106] Iteration 19920, lr = 0.0353129
I0605 00:13:34.210109   904 solver.cpp:229] Iteration 19960, loss = 3.53525
I0605 00:13:34.210170   904 solver.cpp:245]     Train net output #0: loss = 3.55451 (* 1 = 3.55451 loss)
I0605 00:13:34.210182   904 sgd_solver.cpp:106] Iteration 19960, lr = 0.0353035
I0605 00:13:54.192962   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_20000.caffemodel
I0605 00:13:54.460950   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_20000.solverstate
I0605 00:13:54.571599   904 solver.cpp:338] Iteration 20000, Testing net (#0)
I0605 00:13:54.571707   904 net.cpp:748] Ignoring source layer loss
I0605 00:14:12.760840   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 00:14:47.565379   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 00:15:03.532536   904 solver.cpp:406]     Test net output #0: accuracy = 0.29134
I0605 00:15:03.532575   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.535299
I0605 00:15:03.846534   904 solver.cpp:229] Iteration 20000, loss = 3.54401
I0605 00:15:03.846601   904 solver.cpp:245]     Train net output #0: loss = 3.57263 (* 1 = 3.57263 loss)
I0605 00:15:03.846611   904 sgd_solver.cpp:106] Iteration 20000, lr = 0.0352941
I0605 00:15:23.043257   904 solver.cpp:229] Iteration 20040, loss = 3.5477
I0605 00:15:23.043377   904 solver.cpp:245]     Train net output #0: loss = 3.75547 (* 1 = 3.75547 loss)
I0605 00:15:23.043388   904 sgd_solver.cpp:106] Iteration 20040, lr = 0.0352847
I0605 00:15:44.474231   904 solver.cpp:229] Iteration 20080, loss = 3.55742
I0605 00:15:44.474272   904 solver.cpp:245]     Train net output #0: loss = 3.4879 (* 1 = 3.4879 loss)
I0605 00:15:44.474280   904 sgd_solver.cpp:106] Iteration 20080, lr = 0.0352753
I0605 00:16:05.976363   904 solver.cpp:229] Iteration 20120, loss = 3.49978
I0605 00:16:05.976586   904 solver.cpp:245]     Train net output #0: loss = 3.53547 (* 1 = 3.53547 loss)
I0605 00:16:05.976613   904 sgd_solver.cpp:106] Iteration 20120, lr = 0.0352659
I0605 00:16:27.372658   904 solver.cpp:229] Iteration 20160, loss = 3.53993
I0605 00:16:27.372709   904 solver.cpp:245]     Train net output #0: loss = 3.44268 (* 1 = 3.44268 loss)
I0605 00:16:27.372720   904 sgd_solver.cpp:106] Iteration 20160, lr = 0.0352565
I0605 00:16:48.407541   904 solver.cpp:229] Iteration 20200, loss = 3.54147
I0605 00:16:48.407696   904 solver.cpp:245]     Train net output #0: loss = 3.50582 (* 1 = 3.50582 loss)
I0605 00:16:48.407707   904 sgd_solver.cpp:106] Iteration 20200, lr = 0.0352471
I0605 00:17:09.314206   904 solver.cpp:229] Iteration 20240, loss = 3.50945
I0605 00:17:09.314260   904 solver.cpp:245]     Train net output #0: loss = 3.60549 (* 1 = 3.60549 loss)
I0605 00:17:09.314265   904 sgd_solver.cpp:106] Iteration 20240, lr = 0.0352376
I0605 00:17:23.940940   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 00:17:30.210886   904 solver.cpp:229] Iteration 20280, loss = 3.55917
I0605 00:17:30.210947   904 solver.cpp:245]     Train net output #0: loss = 3.50482 (* 1 = 3.50482 loss)
I0605 00:17:30.210958   904 sgd_solver.cpp:106] Iteration 20280, lr = 0.0352282
I0605 00:17:51.140492   904 solver.cpp:229] Iteration 20320, loss = 3.54647
I0605 00:17:51.140543   904 solver.cpp:245]     Train net output #0: loss = 3.53417 (* 1 = 3.53417 loss)
I0605 00:17:51.140555   904 sgd_solver.cpp:106] Iteration 20320, lr = 0.0352188
I0605 00:18:11.731312   904 solver.cpp:229] Iteration 20360, loss = 3.46575
I0605 00:18:11.731547   904 solver.cpp:245]     Train net output #0: loss = 3.77856 (* 1 = 3.77856 loss)
I0605 00:18:11.731573   904 sgd_solver.cpp:106] Iteration 20360, lr = 0.0352094
I0605 00:18:32.123350   904 solver.cpp:229] Iteration 20400, loss = 3.48367
I0605 00:18:32.123400   904 solver.cpp:245]     Train net output #0: loss = 3.51612 (* 1 = 3.51612 loss)
I0605 00:18:32.123409   904 sgd_solver.cpp:106] Iteration 20400, lr = 0.0352
I0605 00:18:52.533445   904 solver.cpp:229] Iteration 20440, loss = 3.50661
I0605 00:18:52.533689   904 solver.cpp:245]     Train net output #0: loss = 3.20952 (* 1 = 3.20952 loss)
I0605 00:18:52.533710   904 sgd_solver.cpp:106] Iteration 20440, lr = 0.0351906
I0605 00:19:12.756978   904 solver.cpp:229] Iteration 20480, loss = 3.54774
I0605 00:19:12.757035   904 solver.cpp:245]     Train net output #0: loss = 3.68338 (* 1 = 3.68338 loss)
I0605 00:19:12.757047   904 sgd_solver.cpp:106] Iteration 20480, lr = 0.0351812
I0605 00:19:32.799291   904 solver.cpp:229] Iteration 20520, loss = 3.52486
I0605 00:19:32.799527   904 solver.cpp:245]     Train net output #0: loss = 3.52423 (* 1 = 3.52423 loss)
I0605 00:19:32.799557   904 sgd_solver.cpp:106] Iteration 20520, lr = 0.0351718
I0605 00:19:52.876610   904 solver.cpp:229] Iteration 20560, loss = 3.48131
I0605 00:19:52.876658   904 solver.cpp:245]     Train net output #0: loss = 3.80456 (* 1 = 3.80456 loss)
I0605 00:19:52.876667   904 sgd_solver.cpp:106] Iteration 20560, lr = 0.0351624
I0605 00:20:12.941005   904 solver.cpp:229] Iteration 20600, loss = 3.49381
I0605 00:20:12.941248   904 solver.cpp:245]     Train net output #0: loss = 3.3446 (* 1 = 3.3446 loss)
I0605 00:20:12.941277   904 sgd_solver.cpp:106] Iteration 20600, lr = 0.0351529
I0605 00:20:33.031800   904 solver.cpp:229] Iteration 20640, loss = 3.50886
I0605 00:20:33.031847   904 solver.cpp:245]     Train net output #0: loss = 3.66601 (* 1 = 3.66601 loss)
I0605 00:20:33.031854   904 sgd_solver.cpp:106] Iteration 20640, lr = 0.0351435
I0605 00:20:53.132743   904 solver.cpp:229] Iteration 20680, loss = 3.54594
I0605 00:20:53.132930   904 solver.cpp:245]     Train net output #0: loss = 3.61206 (* 1 = 3.61206 loss)
I0605 00:20:53.132952   904 sgd_solver.cpp:106] Iteration 20680, lr = 0.0351341
I0605 00:21:13.553858   904 solver.cpp:229] Iteration 20720, loss = 3.49389
I0605 00:21:13.553899   904 solver.cpp:245]     Train net output #0: loss = 3.53811 (* 1 = 3.53811 loss)
I0605 00:21:13.553907   904 sgd_solver.cpp:106] Iteration 20720, lr = 0.0351247
I0605 00:21:33.819149   904 solver.cpp:229] Iteration 20760, loss = 3.54633
I0605 00:21:33.819406   904 solver.cpp:245]     Train net output #0: loss = 3.75134 (* 1 = 3.75134 loss)
I0605 00:21:33.819427   904 sgd_solver.cpp:106] Iteration 20760, lr = 0.0351153
I0605 00:21:54.046047   904 solver.cpp:229] Iteration 20800, loss = 3.48878
I0605 00:21:54.046090   904 solver.cpp:245]     Train net output #0: loss = 3.61385 (* 1 = 3.61385 loss)
I0605 00:21:54.046100   904 sgd_solver.cpp:106] Iteration 20800, lr = 0.0351059
I0605 00:22:02.646054   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 00:22:14.277936   904 solver.cpp:229] Iteration 20840, loss = 3.47484
I0605 00:22:14.278129   904 solver.cpp:245]     Train net output #0: loss = 3.56048 (* 1 = 3.56048 loss)
I0605 00:22:14.278156   904 sgd_solver.cpp:106] Iteration 20840, lr = 0.0350965
I0605 00:22:34.504317   904 solver.cpp:229] Iteration 20880, loss = 3.44814
I0605 00:22:34.504370   904 solver.cpp:245]     Train net output #0: loss = 3.62762 (* 1 = 3.62762 loss)
I0605 00:22:34.504386   904 sgd_solver.cpp:106] Iteration 20880, lr = 0.0350871
I0605 00:22:54.743731   904 solver.cpp:229] Iteration 20920, loss = 3.50218
I0605 00:22:54.743870   904 solver.cpp:245]     Train net output #0: loss = 3.44432 (* 1 = 3.44432 loss)
I0605 00:22:54.743881   904 sgd_solver.cpp:106] Iteration 20920, lr = 0.0350776
I0605 00:23:14.986666   904 solver.cpp:229] Iteration 20960, loss = 3.43432
I0605 00:23:14.986713   904 solver.cpp:245]     Train net output #0: loss = 3.52006 (* 1 = 3.52006 loss)
I0605 00:23:14.986721   904 sgd_solver.cpp:106] Iteration 20960, lr = 0.0350682
I0605 00:23:34.707649   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_21000.caffemodel
I0605 00:23:34.970842   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_21000.solverstate
I0605 00:23:35.048564   904 solver.cpp:338] Iteration 21000, Testing net (#0)
I0605 00:23:35.048646   904 net.cpp:748] Ignoring source layer loss
I0605 00:23:58.445649   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 00:24:32.938854   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 00:24:44.539723   904 solver.cpp:406]     Test net output #0: accuracy = 0.2919
I0605 00:24:44.539780   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.534279
I0605 00:24:44.854053   904 solver.cpp:229] Iteration 21000, loss = 3.48405
I0605 00:24:44.854090   904 solver.cpp:245]     Train net output #0: loss = 3.5567 (* 1 = 3.5567 loss)
I0605 00:24:44.854099   904 sgd_solver.cpp:106] Iteration 21000, lr = 0.0350588
I0605 00:25:04.076622   904 solver.cpp:229] Iteration 21040, loss = 3.44927
I0605 00:25:04.076820   904 solver.cpp:245]     Train net output #0: loss = 3.62423 (* 1 = 3.62423 loss)
I0605 00:25:04.076846   904 sgd_solver.cpp:106] Iteration 21040, lr = 0.0350494
I0605 00:25:25.511806   904 solver.cpp:229] Iteration 21080, loss = 3.4759
I0605 00:25:25.511860   904 solver.cpp:245]     Train net output #0: loss = 3.63088 (* 1 = 3.63088 loss)
I0605 00:25:25.511871   904 sgd_solver.cpp:106] Iteration 21080, lr = 0.03504
I0605 00:25:47.030794   904 solver.cpp:229] Iteration 21120, loss = 3.4646
I0605 00:25:47.031007   904 solver.cpp:245]     Train net output #0: loss = 3.50519 (* 1 = 3.50519 loss)
I0605 00:25:47.031033   904 sgd_solver.cpp:106] Iteration 21120, lr = 0.0350306
I0605 00:26:08.047062   904 solver.cpp:229] Iteration 21160, loss = 3.4974
I0605 00:26:08.047114   904 solver.cpp:245]     Train net output #0: loss = 3.65354 (* 1 = 3.65354 loss)
I0605 00:26:08.047123   904 sgd_solver.cpp:106] Iteration 21160, lr = 0.0350212
I0605 00:26:29.053035   904 solver.cpp:229] Iteration 21200, loss = 3.50231
I0605 00:26:29.053218   904 solver.cpp:245]     Train net output #0: loss = 3.78387 (* 1 = 3.78387 loss)
I0605 00:26:29.053246   904 sgd_solver.cpp:106] Iteration 21200, lr = 0.0350118
I0605 00:26:50.035238   904 solver.cpp:229] Iteration 21240, loss = 3.46691
I0605 00:26:50.035281   904 solver.cpp:245]     Train net output #0: loss = 3.204 (* 1 = 3.204 loss)
I0605 00:26:50.035290   904 sgd_solver.cpp:106] Iteration 21240, lr = 0.0350024
I0605 00:27:11.012482   904 solver.cpp:229] Iteration 21280, loss = 3.48991
I0605 00:27:11.012768   904 solver.cpp:245]     Train net output #0: loss = 3.55646 (* 1 = 3.55646 loss)
I0605 00:27:11.012795   904 sgd_solver.cpp:106] Iteration 21280, lr = 0.0349929
I0605 00:27:31.863668   904 solver.cpp:229] Iteration 21320, loss = 3.43759
I0605 00:27:31.863718   904 solver.cpp:245]     Train net output #0: loss = 3.45861 (* 1 = 3.45861 loss)
I0605 00:27:31.863728   904 sgd_solver.cpp:106] Iteration 21320, lr = 0.0349835
I0605 00:27:41.684869   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 00:27:52.538471   904 solver.cpp:229] Iteration 21360, loss = 3.4949
I0605 00:27:52.538521   904 solver.cpp:245]     Train net output #0: loss = 3.4963 (* 1 = 3.4963 loss)
I0605 00:27:52.538528   904 sgd_solver.cpp:106] Iteration 21360, lr = 0.0349741
I0605 00:28:13.219017   904 solver.cpp:229] Iteration 21400, loss = 3.471
I0605 00:28:13.219140   904 solver.cpp:245]     Train net output #0: loss = 3.59112 (* 1 = 3.59112 loss)
I0605 00:28:13.219163   904 sgd_solver.cpp:106] Iteration 21400, lr = 0.0349647
I0605 00:28:33.890864   904 solver.cpp:229] Iteration 21440, loss = 3.48207
I0605 00:28:33.890900   904 solver.cpp:245]     Train net output #0: loss = 3.40922 (* 1 = 3.40922 loss)
I0605 00:28:33.890909   904 sgd_solver.cpp:106] Iteration 21440, lr = 0.0349553
I0605 00:28:54.497779   904 solver.cpp:229] Iteration 21480, loss = 3.5309
I0605 00:28:54.497982   904 solver.cpp:245]     Train net output #0: loss = 3.41331 (* 1 = 3.41331 loss)
I0605 00:28:54.497999   904 sgd_solver.cpp:106] Iteration 21480, lr = 0.0349459
I0605 00:29:15.231513   904 solver.cpp:229] Iteration 21520, loss = 3.45207
I0605 00:29:15.231550   904 solver.cpp:245]     Train net output #0: loss = 3.46772 (* 1 = 3.46772 loss)
I0605 00:29:15.231559   904 sgd_solver.cpp:106] Iteration 21520, lr = 0.0349365
I0605 00:29:35.803869   904 solver.cpp:229] Iteration 21560, loss = 3.45986
I0605 00:29:35.804067   904 solver.cpp:245]     Train net output #0: loss = 3.35171 (* 1 = 3.35171 loss)
I0605 00:29:35.804091   904 sgd_solver.cpp:106] Iteration 21560, lr = 0.0349271
I0605 00:29:56.317184   904 solver.cpp:229] Iteration 21600, loss = 3.4753
I0605 00:29:56.317227   904 solver.cpp:245]     Train net output #0: loss = 3.0533 (* 1 = 3.0533 loss)
I0605 00:29:56.317237   904 sgd_solver.cpp:106] Iteration 21600, lr = 0.0349176
I0605 00:30:16.825320   904 solver.cpp:229] Iteration 21640, loss = 3.47855
I0605 00:30:16.825541   904 solver.cpp:245]     Train net output #0: loss = 3.65613 (* 1 = 3.65613 loss)
I0605 00:30:16.825567   904 sgd_solver.cpp:106] Iteration 21640, lr = 0.0349082
I0605 00:30:37.367314   904 solver.cpp:229] Iteration 21680, loss = 3.50466
I0605 00:30:37.367363   904 solver.cpp:245]     Train net output #0: loss = 4.04363 (* 1 = 4.04363 loss)
I0605 00:30:37.367372   904 sgd_solver.cpp:106] Iteration 21680, lr = 0.0348988
I0605 00:30:57.890974   904 solver.cpp:229] Iteration 21720, loss = 3.50844
I0605 00:30:57.891196   904 solver.cpp:245]     Train net output #0: loss = 3.30746 (* 1 = 3.30746 loss)
I0605 00:30:57.891222   904 sgd_solver.cpp:106] Iteration 21720, lr = 0.0348894
I0605 00:31:18.262739   904 solver.cpp:229] Iteration 21760, loss = 3.44355
I0605 00:31:18.262794   904 solver.cpp:245]     Train net output #0: loss = 3.19898 (* 1 = 3.19898 loss)
I0605 00:31:18.262802   904 sgd_solver.cpp:106] Iteration 21760, lr = 0.03488
I0605 00:31:38.498999   904 solver.cpp:229] Iteration 21800, loss = 3.49607
I0605 00:31:38.499150   904 solver.cpp:245]     Train net output #0: loss = 3.31409 (* 1 = 3.31409 loss)
I0605 00:31:38.499178   904 sgd_solver.cpp:106] Iteration 21800, lr = 0.0348706
I0605 00:31:58.781828   904 solver.cpp:229] Iteration 21840, loss = 3.42881
I0605 00:31:58.781879   904 solver.cpp:245]     Train net output #0: loss = 3.14968 (* 1 = 3.14968 loss)
I0605 00:31:58.781890   904 sgd_solver.cpp:106] Iteration 21840, lr = 0.0348612
I0605 00:32:19.054880   904 solver.cpp:229] Iteration 21880, loss = 3.44019
I0605 00:32:19.055130   904 solver.cpp:245]     Train net output #0: loss = 3.62113 (* 1 = 3.62113 loss)
I0605 00:32:19.055155   904 sgd_solver.cpp:106] Iteration 21880, lr = 0.0348518
I0605 00:32:20.828604   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 00:32:39.325773   904 solver.cpp:229] Iteration 21920, loss = 3.41667
I0605 00:32:39.325820   904 solver.cpp:245]     Train net output #0: loss = 3.68624 (* 1 = 3.68624 loss)
I0605 00:32:39.325829   904 sgd_solver.cpp:106] Iteration 21920, lr = 0.0348424
I0605 00:32:59.592588   904 solver.cpp:229] Iteration 21960, loss = 3.4342
I0605 00:32:59.592826   904 solver.cpp:245]     Train net output #0: loss = 3.46756 (* 1 = 3.46756 loss)
I0605 00:32:59.592854   904 sgd_solver.cpp:106] Iteration 21960, lr = 0.0348329
I0605 00:33:19.777209   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_22000.caffemodel
I0605 00:33:20.026175   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_22000.solverstate
I0605 00:33:20.107389   904 solver.cpp:338] Iteration 22000, Testing net (#0)
I0605 00:33:20.107460   904 net.cpp:748] Ignoring source layer loss
I0605 00:33:45.153108   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 00:34:17.369647   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 00:34:23.708163   904 solver.cpp:406]     Test net output #0: accuracy = 0.29898
I0605 00:34:23.708204   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.54188
I0605 00:34:24.023293   904 solver.cpp:229] Iteration 22000, loss = 3.42107
I0605 00:34:24.023342   904 solver.cpp:245]     Train net output #0: loss = 3.68124 (* 1 = 3.68124 loss)
I0605 00:34:24.023353   904 sgd_solver.cpp:106] Iteration 22000, lr = 0.0348235
I0605 00:34:43.241997   904 solver.cpp:229] Iteration 22040, loss = 3.41224
I0605 00:34:43.242051   904 solver.cpp:245]     Train net output #0: loss = 3.5835 (* 1 = 3.5835 loss)
I0605 00:34:43.242061   904 sgd_solver.cpp:106] Iteration 22040, lr = 0.0348141
I0605 00:35:04.608762   904 solver.cpp:229] Iteration 22080, loss = 3.43889
I0605 00:35:04.608919   904 solver.cpp:245]     Train net output #0: loss = 3.27412 (* 1 = 3.27412 loss)
I0605 00:35:04.608930   904 sgd_solver.cpp:106] Iteration 22080, lr = 0.0348047
I0605 00:35:26.180956   904 solver.cpp:229] Iteration 22120, loss = 3.42436
I0605 00:35:26.181005   904 solver.cpp:245]     Train net output #0: loss = 3.38782 (* 1 = 3.38782 loss)
I0605 00:35:26.181013   904 sgd_solver.cpp:106] Iteration 22120, lr = 0.0347953
I0605 00:35:47.461060   904 solver.cpp:229] Iteration 22160, loss = 3.44752
I0605 00:35:47.461205   904 solver.cpp:245]     Train net output #0: loss = 3.2967 (* 1 = 3.2967 loss)
I0605 00:35:47.461215   904 sgd_solver.cpp:106] Iteration 22160, lr = 0.0347859
I0605 00:36:08.460841   904 solver.cpp:229] Iteration 22200, loss = 3.46911
I0605 00:36:08.460888   904 solver.cpp:245]     Train net output #0: loss = 3.36306 (* 1 = 3.36306 loss)
I0605 00:36:08.460908   904 sgd_solver.cpp:106] Iteration 22200, lr = 0.0347765
I0605 00:36:29.448390   904 solver.cpp:229] Iteration 22240, loss = 3.42614
I0605 00:36:29.448560   904 solver.cpp:245]     Train net output #0: loss = 3.49661 (* 1 = 3.49661 loss)
I0605 00:36:29.448586   904 sgd_solver.cpp:106] Iteration 22240, lr = 0.0347671
I0605 00:36:50.554060   904 solver.cpp:229] Iteration 22280, loss = 3.50961
I0605 00:36:50.554108   904 solver.cpp:245]     Train net output #0: loss = 3.73605 (* 1 = 3.73605 loss)
I0605 00:36:50.554119   904 sgd_solver.cpp:106] Iteration 22280, lr = 0.0347576
I0605 00:37:11.647886   904 solver.cpp:229] Iteration 22320, loss = 3.44123
I0605 00:37:11.648033   904 solver.cpp:245]     Train net output #0: loss = 3.34333 (* 1 = 3.34333 loss)
I0605 00:37:11.648041   904 sgd_solver.cpp:106] Iteration 22320, lr = 0.0347482
I0605 00:37:32.487210   904 solver.cpp:229] Iteration 22360, loss = 3.39645
I0605 00:37:32.487257   904 solver.cpp:245]     Train net output #0: loss = 3.45992 (* 1 = 3.45992 loss)
I0605 00:37:32.487265   904 sgd_solver.cpp:106] Iteration 22360, lr = 0.0347388
I0605 00:37:53.292664   904 solver.cpp:229] Iteration 22400, loss = 3.44386
I0605 00:37:53.292946   904 solver.cpp:245]     Train net output #0: loss = 3.71297 (* 1 = 3.71297 loss)
I0605 00:37:53.292975   904 sgd_solver.cpp:106] Iteration 22400, lr = 0.0347294
I0605 00:38:14.103329   904 solver.cpp:229] Iteration 22440, loss = 3.46408
I0605 00:38:14.103380   904 solver.cpp:245]     Train net output #0: loss = 3.49536 (* 1 = 3.49536 loss)
I0605 00:38:14.103389   904 sgd_solver.cpp:106] Iteration 22440, lr = 0.03472
I0605 00:38:14.364794   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 00:38:34.830873   904 solver.cpp:229] Iteration 22480, loss = 3.43274
I0605 00:38:34.831042   904 solver.cpp:245]     Train net output #0: loss = 3.50373 (* 1 = 3.50373 loss)
I0605 00:38:34.831050   904 sgd_solver.cpp:106] Iteration 22480, lr = 0.0347106
I0605 00:38:55.522639   904 solver.cpp:229] Iteration 22520, loss = 3.45937
I0605 00:38:55.522680   904 solver.cpp:245]     Train net output #0: loss = 3.41995 (* 1 = 3.41995 loss)
I0605 00:38:55.522688   904 sgd_solver.cpp:106] Iteration 22520, lr = 0.0347012
I0605 00:39:16.190364   904 solver.cpp:229] Iteration 22560, loss = 3.44143
I0605 00:39:16.190557   904 solver.cpp:245]     Train net output #0: loss = 3.31286 (* 1 = 3.31286 loss)
I0605 00:39:16.190578   904 sgd_solver.cpp:106] Iteration 22560, lr = 0.0346918
I0605 00:39:36.831718   904 solver.cpp:229] Iteration 22600, loss = 3.41754
I0605 00:39:36.831765   904 solver.cpp:245]     Train net output #0: loss = 3.16614 (* 1 = 3.16614 loss)
I0605 00:39:36.831773   904 sgd_solver.cpp:106] Iteration 22600, lr = 0.0346824
I0605 00:39:57.362690   904 solver.cpp:229] Iteration 22640, loss = 3.41908
I0605 00:39:57.362838   904 solver.cpp:245]     Train net output #0: loss = 3.39653 (* 1 = 3.39653 loss)
I0605 00:39:57.362848   904 sgd_solver.cpp:106] Iteration 22640, lr = 0.0346729
I0605 00:40:18.020541   904 solver.cpp:229] Iteration 22680, loss = 3.46346
I0605 00:40:18.020586   904 solver.cpp:245]     Train net output #0: loss = 3.37316 (* 1 = 3.37316 loss)
I0605 00:40:18.020592   904 sgd_solver.cpp:106] Iteration 22680, lr = 0.0346635
I0605 00:40:38.697351   904 solver.cpp:229] Iteration 22720, loss = 3.4327
I0605 00:40:38.697525   904 solver.cpp:245]     Train net output #0: loss = 3.55081 (* 1 = 3.55081 loss)
I0605 00:40:38.697546   904 sgd_solver.cpp:106] Iteration 22720, lr = 0.0346541
I0605 00:40:59.319509   904 solver.cpp:229] Iteration 22760, loss = 3.41414
I0605 00:40:59.319564   904 solver.cpp:245]     Train net output #0: loss = 3.66709 (* 1 = 3.66709 loss)
I0605 00:40:59.319573   904 sgd_solver.cpp:106] Iteration 22760, lr = 0.0346447
I0605 00:41:19.823144   904 solver.cpp:229] Iteration 22800, loss = 3.46777
I0605 00:41:19.823333   904 solver.cpp:245]     Train net output #0: loss = 3.39458 (* 1 = 3.39458 loss)
I0605 00:41:19.823355   904 sgd_solver.cpp:106] Iteration 22800, lr = 0.0346353
I0605 00:41:40.478499   904 solver.cpp:229] Iteration 22840, loss = 3.43246
I0605 00:41:40.478549   904 solver.cpp:245]     Train net output #0: loss = 3.52612 (* 1 = 3.52612 loss)
I0605 00:41:40.478559   904 sgd_solver.cpp:106] Iteration 22840, lr = 0.0346259
I0605 00:42:01.020025   904 solver.cpp:229] Iteration 22880, loss = 3.38671
I0605 00:42:01.020171   904 solver.cpp:245]     Train net output #0: loss = 3.65356 (* 1 = 3.65356 loss)
I0605 00:42:01.020189   904 sgd_solver.cpp:106] Iteration 22880, lr = 0.0346165
I0605 00:42:21.549252   904 solver.cpp:229] Iteration 22920, loss = 3.42331
I0605 00:42:21.549306   904 solver.cpp:245]     Train net output #0: loss = 3.46405 (* 1 = 3.46405 loss)
I0605 00:42:21.549315   904 sgd_solver.cpp:106] Iteration 22920, lr = 0.0346071
I0605 00:42:42.064607   904 solver.cpp:229] Iteration 22960, loss = 3.42473
I0605 00:42:42.064882   904 solver.cpp:245]     Train net output #0: loss = 3.41929 (* 1 = 3.41929 loss)
I0605 00:42:42.064909   904 sgd_solver.cpp:106] Iteration 22960, lr = 0.0345976
I0605 00:43:02.108183   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_23000.caffemodel
I0605 00:43:02.364982   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_23000.solverstate
I0605 00:43:02.444891   904 solver.cpp:338] Iteration 23000, Testing net (#0)
I0605 00:43:02.444963   904 net.cpp:748] Ignoring source layer loss
I0605 00:43:04.031918   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 00:43:38.077381   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 00:44:09.642056   904 solver.cpp:406]     Test net output #0: accuracy = 0.30892
I0605 00:44:09.642154   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.552019
I0605 00:44:09.958628   904 solver.cpp:229] Iteration 23000, loss = 3.44734
I0605 00:44:09.958675   904 solver.cpp:245]     Train net output #0: loss = 3.41263 (* 1 = 3.41263 loss)
I0605 00:44:09.958685   904 sgd_solver.cpp:106] Iteration 23000, lr = 0.0345882
I0605 00:44:21.742928   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 00:44:29.273249   904 solver.cpp:229] Iteration 23040, loss = 3.40586
I0605 00:44:29.273296   904 solver.cpp:245]     Train net output #0: loss = 3.50437 (* 1 = 3.50437 loss)
I0605 00:44:29.273316   904 sgd_solver.cpp:106] Iteration 23040, lr = 0.0345788
I0605 00:44:50.809604   904 solver.cpp:229] Iteration 23080, loss = 3.38216
I0605 00:44:50.809742   904 solver.cpp:245]     Train net output #0: loss = 3.33803 (* 1 = 3.33803 loss)
I0605 00:44:50.809752   904 sgd_solver.cpp:106] Iteration 23080, lr = 0.0345694
I0605 00:45:12.383258   904 solver.cpp:229] Iteration 23120, loss = 3.3912
I0605 00:45:12.383299   904 solver.cpp:245]     Train net output #0: loss = 3.22878 (* 1 = 3.22878 loss)
I0605 00:45:12.383316   904 sgd_solver.cpp:106] Iteration 23120, lr = 0.03456
I0605 00:45:33.861150   904 solver.cpp:229] Iteration 23160, loss = 3.43281
I0605 00:45:33.861289   904 solver.cpp:245]     Train net output #0: loss = 3.58226 (* 1 = 3.58226 loss)
I0605 00:45:33.861299   904 sgd_solver.cpp:106] Iteration 23160, lr = 0.0345506
I0605 00:45:55.209403   904 solver.cpp:229] Iteration 23200, loss = 3.4481
I0605 00:45:55.209455   904 solver.cpp:245]     Train net output #0: loss = 3.2508 (* 1 = 3.2508 loss)
I0605 00:45:55.209463   904 sgd_solver.cpp:106] Iteration 23200, lr = 0.0345412
I0605 00:46:16.235893   904 solver.cpp:229] Iteration 23240, loss = 3.43257
I0605 00:46:16.236073   904 solver.cpp:245]     Train net output #0: loss = 3.38398 (* 1 = 3.38398 loss)
I0605 00:46:16.236099   904 sgd_solver.cpp:106] Iteration 23240, lr = 0.0345318
I0605 00:46:37.239153   904 solver.cpp:229] Iteration 23280, loss = 3.40762
I0605 00:46:37.239212   904 solver.cpp:245]     Train net output #0: loss = 3.35005 (* 1 = 3.35005 loss)
I0605 00:46:37.239224   904 sgd_solver.cpp:106] Iteration 23280, lr = 0.0345224
I0605 00:46:58.217592   904 solver.cpp:229] Iteration 23320, loss = 3.41372
I0605 00:46:58.217831   904 solver.cpp:245]     Train net output #0: loss = 3.49186 (* 1 = 3.49186 loss)
I0605 00:46:58.217857   904 sgd_solver.cpp:106] Iteration 23320, lr = 0.0345129
I0605 00:47:19.217545   904 solver.cpp:229] Iteration 23360, loss = 3.37613
I0605 00:47:19.217595   904 solver.cpp:245]     Train net output #0: loss = 3.29273 (* 1 = 3.29273 loss)
I0605 00:47:19.217607   904 sgd_solver.cpp:106] Iteration 23360, lr = 0.0345035
I0605 00:47:40.160701   904 solver.cpp:229] Iteration 23400, loss = 3.39808
I0605 00:47:40.160837   904 solver.cpp:245]     Train net output #0: loss = 3.70542 (* 1 = 3.70542 loss)
I0605 00:47:40.160858   904 sgd_solver.cpp:106] Iteration 23400, lr = 0.0344941
I0605 00:48:01.027048   904 solver.cpp:229] Iteration 23440, loss = 3.37085
I0605 00:48:01.027101   904 solver.cpp:245]     Train net output #0: loss = 3.25184 (* 1 = 3.25184 loss)
I0605 00:48:01.027109   904 sgd_solver.cpp:106] Iteration 23440, lr = 0.0344847
I0605 00:48:21.848637   904 solver.cpp:229] Iteration 23480, loss = 3.34246
I0605 00:48:21.848814   904 solver.cpp:245]     Train net output #0: loss = 3.55461 (* 1 = 3.55461 loss)
I0605 00:48:21.848824   904 sgd_solver.cpp:106] Iteration 23480, lr = 0.0344753
I0605 00:48:42.568688   904 solver.cpp:229] Iteration 23520, loss = 3.38552
I0605 00:48:42.568733   904 solver.cpp:245]     Train net output #0: loss = 3.23787 (* 1 = 3.23787 loss)
I0605 00:48:42.568742   904 sgd_solver.cpp:106] Iteration 23520, lr = 0.0344659
I0605 00:49:03.076484   904 solver.cpp:229] Iteration 23560, loss = 3.39709
I0605 00:49:03.076647   904 solver.cpp:245]     Train net output #0: loss = 3.2144 (* 1 = 3.2144 loss)
I0605 00:49:03.076666   904 sgd_solver.cpp:106] Iteration 23560, lr = 0.0344565
I0605 00:49:07.699424   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 00:49:23.711612   904 solver.cpp:229] Iteration 23600, loss = 3.39852
I0605 00:49:23.711663   904 solver.cpp:245]     Train net output #0: loss = 3.36528 (* 1 = 3.36528 loss)
I0605 00:49:23.711674   904 sgd_solver.cpp:106] Iteration 23600, lr = 0.0344471
I0605 00:49:44.359079   904 solver.cpp:229] Iteration 23640, loss = 3.38622
I0605 00:49:44.359266   904 solver.cpp:245]     Train net output #0: loss = 3.13222 (* 1 = 3.13222 loss)
I0605 00:49:44.359290   904 sgd_solver.cpp:106] Iteration 23640, lr = 0.0344376
I0605 00:50:04.654852   904 solver.cpp:229] Iteration 23680, loss = 3.38454
I0605 00:50:04.654903   904 solver.cpp:245]     Train net output #0: loss = 3.15109 (* 1 = 3.15109 loss)
I0605 00:50:04.654911   904 sgd_solver.cpp:106] Iteration 23680, lr = 0.0344282
I0605 00:50:25.051801   904 solver.cpp:229] Iteration 23720, loss = 3.39085
I0605 00:50:25.052019   904 solver.cpp:245]     Train net output #0: loss = 3.42353 (* 1 = 3.42353 loss)
I0605 00:50:25.052048   904 sgd_solver.cpp:106] Iteration 23720, lr = 0.0344188
I0605 00:50:45.548224   904 solver.cpp:229] Iteration 23760, loss = 3.37754
I0605 00:50:45.548271   904 solver.cpp:245]     Train net output #0: loss = 3.52356 (* 1 = 3.52356 loss)
I0605 00:50:45.548280   904 sgd_solver.cpp:106] Iteration 23760, lr = 0.0344094
I0605 00:51:06.069463   904 solver.cpp:229] Iteration 23800, loss = 3.38704
I0605 00:51:06.069633   904 solver.cpp:245]     Train net output #0: loss = 3.62564 (* 1 = 3.62564 loss)
I0605 00:51:06.069658   904 sgd_solver.cpp:106] Iteration 23800, lr = 0.0344
I0605 00:51:26.542412   904 solver.cpp:229] Iteration 23840, loss = 3.37506
I0605 00:51:26.542460   904 solver.cpp:245]     Train net output #0: loss = 3.326 (* 1 = 3.326 loss)
I0605 00:51:26.542469   904 sgd_solver.cpp:106] Iteration 23840, lr = 0.0343906
I0605 00:51:47.740530   904 solver.cpp:229] Iteration 23880, loss = 3.41755
I0605 00:51:47.740689   904 solver.cpp:245]     Train net output #0: loss = 3.63639 (* 1 = 3.63639 loss)
I0605 00:51:47.740712   904 sgd_solver.cpp:106] Iteration 23880, lr = 0.0343812
I0605 00:52:08.034292   904 solver.cpp:229] Iteration 23920, loss = 3.40569
I0605 00:52:08.034334   904 solver.cpp:245]     Train net output #0: loss = 3.48513 (* 1 = 3.48513 loss)
I0605 00:52:08.034343   904 sgd_solver.cpp:106] Iteration 23920, lr = 0.0343718
I0605 00:52:28.528803   904 solver.cpp:229] Iteration 23960, loss = 3.39707
I0605 00:52:28.528929   904 solver.cpp:245]     Train net output #0: loss = 3.57234 (* 1 = 3.57234 loss)
I0605 00:52:28.528939   904 sgd_solver.cpp:106] Iteration 23960, lr = 0.0343624
I0605 00:52:48.409265   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_24000.caffemodel
I0605 00:52:48.675348   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_24000.solverstate
I0605 00:52:48.754648   904 solver.cpp:338] Iteration 24000, Testing net (#0)
I0605 00:52:48.754724   904 net.cpp:748] Ignoring source layer loss
I0605 00:52:55.014608   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 00:53:28.408442   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 00:53:55.159394   904 solver.cpp:406]     Test net output #0: accuracy = 0.30996
I0605 00:53:55.159442   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.5534
I0605 00:53:55.476613   904 solver.cpp:229] Iteration 24000, loss = 3.40512
I0605 00:53:55.476660   904 solver.cpp:245]     Train net output #0: loss = 3.30974 (* 1 = 3.30974 loss)
I0605 00:53:55.476668   904 sgd_solver.cpp:106] Iteration 24000, lr = 0.0343529
I0605 00:54:14.751642   904 solver.cpp:229] Iteration 24040, loss = 3.37318
I0605 00:54:14.751822   904 solver.cpp:245]     Train net output #0: loss = 3.36431 (* 1 = 3.36431 loss)
I0605 00:54:14.751848   904 sgd_solver.cpp:106] Iteration 24040, lr = 0.0343435
I0605 00:54:36.164214   904 solver.cpp:229] Iteration 24080, loss = 3.4018
I0605 00:54:36.164268   904 solver.cpp:245]     Train net output #0: loss = 3.29232 (* 1 = 3.29232 loss)
I0605 00:54:36.164280   904 sgd_solver.cpp:106] Iteration 24080, lr = 0.0343341
I0605 00:54:44.005508   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 00:54:57.672456   904 solver.cpp:229] Iteration 24120, loss = 3.37198
I0605 00:54:57.672646   904 solver.cpp:245]     Train net output #0: loss = 3.42633 (* 1 = 3.42633 loss)
I0605 00:54:57.672670   904 sgd_solver.cpp:106] Iteration 24120, lr = 0.0343247
I0605 00:55:18.714725   904 solver.cpp:229] Iteration 24160, loss = 3.41495
I0605 00:55:18.714763   904 solver.cpp:245]     Train net output #0: loss = 3.74372 (* 1 = 3.74372 loss)
I0605 00:55:18.714773   904 sgd_solver.cpp:106] Iteration 24160, lr = 0.0343153
I0605 00:55:41.109076   904 solver.cpp:229] Iteration 24200, loss = 3.40228
I0605 00:55:41.109256   904 solver.cpp:245]     Train net output #0: loss = 3.45703 (* 1 = 3.45703 loss)
I0605 00:55:41.109288   904 sgd_solver.cpp:106] Iteration 24200, lr = 0.0343059
I0605 00:56:02.000602   904 solver.cpp:229] Iteration 24240, loss = 3.34796
I0605 00:56:02.000643   904 solver.cpp:245]     Train net output #0: loss = 3.40258 (* 1 = 3.40258 loss)
I0605 00:56:02.000654   904 sgd_solver.cpp:106] Iteration 24240, lr = 0.0342965
I0605 00:56:22.941486   904 solver.cpp:229] Iteration 24280, loss = 3.34404
I0605 00:56:22.941727   904 solver.cpp:245]     Train net output #0: loss = 3.48071 (* 1 = 3.48071 loss)
I0605 00:56:22.941762   904 sgd_solver.cpp:106] Iteration 24280, lr = 0.0342871
I0605 00:56:43.848740   904 solver.cpp:229] Iteration 24320, loss = 3.38688
I0605 00:56:43.848778   904 solver.cpp:245]     Train net output #0: loss = 3.26031 (* 1 = 3.26031 loss)
I0605 00:56:43.848785   904 sgd_solver.cpp:106] Iteration 24320, lr = 0.0342776
I0605 00:57:04.606138   904 solver.cpp:229] Iteration 24360, loss = 3.33576
I0605 00:57:04.606263   904 solver.cpp:245]     Train net output #0: loss = 3.09366 (* 1 = 3.09366 loss)
I0605 00:57:04.606271   904 sgd_solver.cpp:106] Iteration 24360, lr = 0.0342682
I0605 00:57:25.142292   904 solver.cpp:229] Iteration 24400, loss = 3.37686
I0605 00:57:25.142335   904 solver.cpp:245]     Train net output #0: loss = 3.25745 (* 1 = 3.25745 loss)
I0605 00:57:25.142344   904 sgd_solver.cpp:106] Iteration 24400, lr = 0.0342588
I0605 00:57:45.830232   904 solver.cpp:229] Iteration 24440, loss = 3.41691
I0605 00:57:45.830354   904 solver.cpp:245]     Train net output #0: loss = 3.09505 (* 1 = 3.09505 loss)
I0605 00:57:45.830366   904 sgd_solver.cpp:106] Iteration 24440, lr = 0.0342494
I0605 00:58:06.479146   904 solver.cpp:229] Iteration 24480, loss = 3.33847
I0605 00:58:06.479202   904 solver.cpp:245]     Train net output #0: loss = 3.08206 (* 1 = 3.08206 loss)
I0605 00:58:06.479213   904 sgd_solver.cpp:106] Iteration 24480, lr = 0.03424
I0605 00:58:27.042937   904 solver.cpp:229] Iteration 24520, loss = 3.39559
I0605 00:58:27.043123   904 solver.cpp:245]     Train net output #0: loss = 3.20233 (* 1 = 3.20233 loss)
I0605 00:58:27.043148   904 sgd_solver.cpp:106] Iteration 24520, lr = 0.0342306
I0605 00:58:47.612485   904 solver.cpp:229] Iteration 24560, loss = 3.37469
I0605 00:58:47.612537   904 solver.cpp:245]     Train net output #0: loss = 3.25344 (* 1 = 3.25344 loss)
I0605 00:58:47.612545   904 sgd_solver.cpp:106] Iteration 24560, lr = 0.0342212
I0605 00:59:08.176455   904 solver.cpp:229] Iteration 24600, loss = 3.34429
I0605 00:59:08.176709   904 solver.cpp:245]     Train net output #0: loss = 3.23377 (* 1 = 3.23377 loss)
I0605 00:59:08.176741   904 sgd_solver.cpp:106] Iteration 24600, lr = 0.0342118
I0605 00:59:23.436920   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 00:59:28.512655   904 solver.cpp:229] Iteration 24640, loss = 3.36108
I0605 00:59:28.512698   904 solver.cpp:245]     Train net output #0: loss = 3.28218 (* 1 = 3.28218 loss)
I0605 00:59:28.512711   904 sgd_solver.cpp:106] Iteration 24640, lr = 0.0342024
I0605 00:59:48.843801   904 solver.cpp:229] Iteration 24680, loss = 3.39565
I0605 00:59:48.843997   904 solver.cpp:245]     Train net output #0: loss = 3.45461 (* 1 = 3.45461 loss)
I0605 00:59:48.844024   904 sgd_solver.cpp:106] Iteration 24680, lr = 0.0341929
I0605 01:00:09.176321   904 solver.cpp:229] Iteration 24720, loss = 3.38755
I0605 01:00:09.176383   904 solver.cpp:245]     Train net output #0: loss = 3.38197 (* 1 = 3.38197 loss)
I0605 01:00:09.176396   904 sgd_solver.cpp:106] Iteration 24720, lr = 0.0341835
I0605 01:00:29.499434   904 solver.cpp:229] Iteration 24760, loss = 3.37379
I0605 01:00:29.499580   904 solver.cpp:245]     Train net output #0: loss = 3.69425 (* 1 = 3.69425 loss)
I0605 01:00:29.499589   904 sgd_solver.cpp:106] Iteration 24760, lr = 0.0341741
I0605 01:00:49.831342   904 solver.cpp:229] Iteration 24800, loss = 3.34988
I0605 01:00:49.831384   904 solver.cpp:245]     Train net output #0: loss = 3.35991 (* 1 = 3.35991 loss)
I0605 01:00:49.831393   904 sgd_solver.cpp:106] Iteration 24800, lr = 0.0341647
I0605 01:01:10.146658   904 solver.cpp:229] Iteration 24840, loss = 3.32771
I0605 01:01:10.146860   904 solver.cpp:245]     Train net output #0: loss = 3.56808 (* 1 = 3.56808 loss)
I0605 01:01:10.146885   904 sgd_solver.cpp:106] Iteration 24840, lr = 0.0341553
I0605 01:01:30.449703   904 solver.cpp:229] Iteration 24880, loss = 3.32788
I0605 01:01:30.449746   904 solver.cpp:245]     Train net output #0: loss = 3.40705 (* 1 = 3.40705 loss)
I0605 01:01:30.449756   904 sgd_solver.cpp:106] Iteration 24880, lr = 0.0341459
I0605 01:01:50.593356   904 solver.cpp:229] Iteration 24920, loss = 3.39495
I0605 01:01:50.593567   904 solver.cpp:245]     Train net output #0: loss = 3.56464 (* 1 = 3.56464 loss)
I0605 01:01:50.593593   904 sgd_solver.cpp:106] Iteration 24920, lr = 0.0341365
I0605 01:02:10.800495   904 solver.cpp:229] Iteration 24960, loss = 3.37439
I0605 01:02:10.800539   904 solver.cpp:245]     Train net output #0: loss = 3.11292 (* 1 = 3.11292 loss)
I0605 01:02:10.800549   904 sgd_solver.cpp:106] Iteration 24960, lr = 0.0341271
I0605 01:02:30.595700   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_25000.caffemodel
I0605 01:02:30.861526   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_25000.solverstate
I0605 01:02:30.934952   904 solver.cpp:338] Iteration 25000, Testing net (#0)
I0605 01:02:30.935035   904 net.cpp:748] Ignoring source layer loss
I0605 01:02:40.348179   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 01:03:14.258141   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 01:03:38.387372   904 solver.cpp:406]     Test net output #0: accuracy = 0.31122
I0605 01:03:38.387411   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.55244
I0605 01:03:38.700379   904 solver.cpp:229] Iteration 25000, loss = 3.35529
I0605 01:03:38.700426   904 solver.cpp:245]     Train net output #0: loss = 3.37789 (* 1 = 3.37789 loss)
I0605 01:03:38.700436   904 sgd_solver.cpp:106] Iteration 25000, lr = 0.0341176
I0605 01:03:57.931036   904 solver.cpp:229] Iteration 25040, loss = 3.37436
I0605 01:03:57.931181   904 solver.cpp:245]     Train net output #0: loss = 3.49155 (* 1 = 3.49155 loss)
I0605 01:03:57.931195   904 sgd_solver.cpp:106] Iteration 25040, lr = 0.0341082
I0605 01:04:19.239614   904 solver.cpp:229] Iteration 25080, loss = 3.38926
I0605 01:04:19.239665   904 solver.cpp:245]     Train net output #0: loss = 3.15601 (* 1 = 3.15601 loss)
I0605 01:04:19.239675   904 sgd_solver.cpp:106] Iteration 25080, lr = 0.0340988
I0605 01:04:40.566072   904 solver.cpp:229] Iteration 25120, loss = 3.33266
I0605 01:04:40.566318   904 solver.cpp:245]     Train net output #0: loss = 3.42541 (* 1 = 3.42541 loss)
I0605 01:04:40.566354   904 sgd_solver.cpp:106] Iteration 25120, lr = 0.0340894
I0605 01:04:52.713651   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 01:05:01.650395   904 solver.cpp:229] Iteration 25160, loss = 3.35831
I0605 01:05:01.650456   904 solver.cpp:245]     Train net output #0: loss = 3.21562 (* 1 = 3.21562 loss)
I0605 01:05:01.650470   904 sgd_solver.cpp:106] Iteration 25160, lr = 0.03408
I0605 01:05:22.653501   904 solver.cpp:229] Iteration 25200, loss = 3.37004
I0605 01:05:22.653700   904 solver.cpp:245]     Train net output #0: loss = 3.39494 (* 1 = 3.39494 loss)
I0605 01:05:22.653729   904 sgd_solver.cpp:106] Iteration 25200, lr = 0.0340706
I0605 01:05:43.659905   904 solver.cpp:229] Iteration 25240, loss = 3.32434
I0605 01:05:43.659953   904 solver.cpp:245]     Train net output #0: loss = 2.96916 (* 1 = 2.96916 loss)
I0605 01:05:43.659963   904 sgd_solver.cpp:106] Iteration 25240, lr = 0.0340612
I0605 01:06:04.514384   904 solver.cpp:229] Iteration 25280, loss = 3.36727
I0605 01:06:04.514550   904 solver.cpp:245]     Train net output #0: loss = 3.41332 (* 1 = 3.41332 loss)
I0605 01:06:04.514576   904 sgd_solver.cpp:106] Iteration 25280, lr = 0.0340518
I0605 01:06:25.343799   904 solver.cpp:229] Iteration 25320, loss = 3.35539
I0605 01:06:25.343852   904 solver.cpp:245]     Train net output #0: loss = 3.51976 (* 1 = 3.51976 loss)
I0605 01:06:25.343859   904 sgd_solver.cpp:106] Iteration 25320, lr = 0.0340424
I0605 01:06:46.153151   904 solver.cpp:229] Iteration 25360, loss = 3.35372
I0605 01:06:46.153364   904 solver.cpp:245]     Train net output #0: loss = 3.07278 (* 1 = 3.07278 loss)
I0605 01:06:46.153391   904 sgd_solver.cpp:106] Iteration 25360, lr = 0.0340329
I0605 01:07:06.971237   904 solver.cpp:229] Iteration 25400, loss = 3.3142
I0605 01:07:06.971274   904 solver.cpp:245]     Train net output #0: loss = 3.2299 (* 1 = 3.2299 loss)
I0605 01:07:06.971281   904 sgd_solver.cpp:106] Iteration 25400, lr = 0.0340235
I0605 01:07:27.649499   904 solver.cpp:229] Iteration 25440, loss = 3.3161
I0605 01:07:27.649680   904 solver.cpp:245]     Train net output #0: loss = 3.21003 (* 1 = 3.21003 loss)
I0605 01:07:27.649705   904 sgd_solver.cpp:106] Iteration 25440, lr = 0.0340141
I0605 01:07:48.172230   904 solver.cpp:229] Iteration 25480, loss = 3.3954
I0605 01:07:48.172272   904 solver.cpp:245]     Train net output #0: loss = 3.32781 (* 1 = 3.32781 loss)
I0605 01:07:48.172281   904 sgd_solver.cpp:106] Iteration 25480, lr = 0.0340047
I0605 01:08:08.828274   904 solver.cpp:229] Iteration 25520, loss = 3.35485
I0605 01:08:08.828413   904 solver.cpp:245]     Train net output #0: loss = 2.85922 (* 1 = 2.85922 loss)
I0605 01:08:08.828423   904 sgd_solver.cpp:106] Iteration 25520, lr = 0.0339953
I0605 01:08:29.454438   904 solver.cpp:229] Iteration 25560, loss = 3.28222
I0605 01:08:29.454488   904 solver.cpp:245]     Train net output #0: loss = 3.3431 (* 1 = 3.3431 loss)
I0605 01:08:29.454496   904 sgd_solver.cpp:106] Iteration 25560, lr = 0.0339859
I0605 01:08:50.111389   904 solver.cpp:229] Iteration 25600, loss = 3.33482
I0605 01:08:50.111572   904 solver.cpp:245]     Train net output #0: loss = 3.48395 (* 1 = 3.48395 loss)
I0605 01:08:50.111584   904 sgd_solver.cpp:106] Iteration 25600, lr = 0.0339765
I0605 01:09:10.710719   904 solver.cpp:229] Iteration 25640, loss = 3.33916
I0605 01:09:10.710769   904 solver.cpp:245]     Train net output #0: loss = 3.43917 (* 1 = 3.43917 loss)
I0605 01:09:10.710778   904 sgd_solver.cpp:106] Iteration 25640, lr = 0.0339671
I0605 01:09:14.560585   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 01:09:31.251345   904 solver.cpp:229] Iteration 25680, loss = 3.36911
I0605 01:09:31.251601   904 solver.cpp:245]     Train net output #0: loss = 3.46981 (* 1 = 3.46981 loss)
I0605 01:09:31.251631   904 sgd_solver.cpp:106] Iteration 25680, lr = 0.0339576
I0605 01:09:51.762172   904 solver.cpp:229] Iteration 25720, loss = 3.32535
I0605 01:09:51.762223   904 solver.cpp:245]     Train net output #0: loss = 3.23633 (* 1 = 3.23633 loss)
I0605 01:09:51.762233   904 sgd_solver.cpp:106] Iteration 25720, lr = 0.0339482
I0605 01:10:12.360359   904 solver.cpp:229] Iteration 25760, loss = 3.34977
I0605 01:10:12.360545   904 solver.cpp:245]     Train net output #0: loss = 3.42949 (* 1 = 3.42949 loss)
I0605 01:10:12.360558   904 sgd_solver.cpp:106] Iteration 25760, lr = 0.0339388
I0605 01:10:33.010339   904 solver.cpp:229] Iteration 25800, loss = 3.36645
I0605 01:10:33.010385   904 solver.cpp:245]     Train net output #0: loss = 3.54849 (* 1 = 3.54849 loss)
I0605 01:10:33.010396   904 sgd_solver.cpp:106] Iteration 25800, lr = 0.0339294
I0605 01:10:53.458542   904 solver.cpp:229] Iteration 25840, loss = 3.33386
I0605 01:10:53.458698   904 solver.cpp:245]     Train net output #0: loss = 3.4912 (* 1 = 3.4912 loss)
I0605 01:10:53.458711   904 sgd_solver.cpp:106] Iteration 25840, lr = 0.03392
I0605 01:11:13.876518   904 solver.cpp:229] Iteration 25880, loss = 3.32336
I0605 01:11:13.876567   904 solver.cpp:245]     Train net output #0: loss = 3.54033 (* 1 = 3.54033 loss)
I0605 01:11:13.876579   904 sgd_solver.cpp:106] Iteration 25880, lr = 0.0339106
I0605 01:11:34.374476   904 solver.cpp:229] Iteration 25920, loss = 3.35309
I0605 01:11:34.374627   904 solver.cpp:245]     Train net output #0: loss = 3.44949 (* 1 = 3.44949 loss)
I0605 01:11:34.374640   904 sgd_solver.cpp:106] Iteration 25920, lr = 0.0339012
I0605 01:11:54.845643   904 solver.cpp:229] Iteration 25960, loss = 3.32665
I0605 01:11:54.845684   904 solver.cpp:245]     Train net output #0: loss = 3.30008 (* 1 = 3.30008 loss)
I0605 01:11:54.845697   904 sgd_solver.cpp:106] Iteration 25960, lr = 0.0338918
I0605 01:12:14.812535   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_26000.caffemodel
I0605 01:12:15.079062   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_26000.solverstate
I0605 01:12:15.152511   904 solver.cpp:338] Iteration 26000, Testing net (#0)
I0605 01:12:15.152577   904 net.cpp:748] Ignoring source layer loss
I0605 01:12:25.736012   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 01:12:59.683404   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 01:13:23.282587   904 solver.cpp:406]     Test net output #0: accuracy = 0.3047
I0605 01:13:23.282629   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.550759
I0605 01:13:23.598147   904 solver.cpp:229] Iteration 26000, loss = 3.32259
I0605 01:13:23.598192   904 solver.cpp:245]     Train net output #0: loss = 3.48151 (* 1 = 3.48151 loss)
I0605 01:13:23.598203   904 sgd_solver.cpp:106] Iteration 26000, lr = 0.0338824
I0605 01:13:42.815093   904 solver.cpp:229] Iteration 26040, loss = 3.35367
I0605 01:13:42.815248   904 solver.cpp:245]     Train net output #0: loss = 3.52056 (* 1 = 3.52056 loss)
I0605 01:13:42.815261   904 sgd_solver.cpp:106] Iteration 26040, lr = 0.0338729
I0605 01:14:04.266157   904 solver.cpp:229] Iteration 26080, loss = 3.36822
I0605 01:14:04.266206   904 solver.cpp:245]     Train net output #0: loss = 3.2217 (* 1 = 3.2217 loss)
I0605 01:14:04.266217   904 sgd_solver.cpp:106] Iteration 26080, lr = 0.0338635
I0605 01:14:25.815511   904 solver.cpp:229] Iteration 26120, loss = 3.30791
I0605 01:14:25.815630   904 solver.cpp:245]     Train net output #0: loss = 3.50139 (* 1 = 3.50139 loss)
I0605 01:14:25.815642   904 sgd_solver.cpp:106] Iteration 26120, lr = 0.0338541
I0605 01:14:45.563773   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 01:14:47.134163   904 solver.cpp:229] Iteration 26160, loss = 3.37196
I0605 01:14:47.134217   904 solver.cpp:245]     Train net output #0: loss = 3.31719 (* 1 = 3.31719 loss)
I0605 01:14:47.134229   904 sgd_solver.cpp:106] Iteration 26160, lr = 0.0338447
I0605 01:15:08.117380   904 solver.cpp:229] Iteration 26200, loss = 3.34196
I0605 01:15:08.117712   904 solver.cpp:245]     Train net output #0: loss = 3.55102 (* 1 = 3.55102 loss)
I0605 01:15:08.117738   904 sgd_solver.cpp:106] Iteration 26200, lr = 0.0338353
I0605 01:15:29.108814   904 solver.cpp:229] Iteration 26240, loss = 3.31883
I0605 01:15:29.108860   904 solver.cpp:245]     Train net output #0: loss = 3.20174 (* 1 = 3.20174 loss)
I0605 01:15:29.108870   904 sgd_solver.cpp:106] Iteration 26240, lr = 0.0338259
I0605 01:15:50.101776   904 solver.cpp:229] Iteration 26280, loss = 3.33413
I0605 01:15:50.101981   904 solver.cpp:245]     Train net output #0: loss = 3.51305 (* 1 = 3.51305 loss)
I0605 01:15:50.102007   904 sgd_solver.cpp:106] Iteration 26280, lr = 0.0338165
I0605 01:16:11.104104   904 solver.cpp:229] Iteration 26320, loss = 3.31023
I0605 01:16:11.104159   904 solver.cpp:245]     Train net output #0: loss = 3.33019 (* 1 = 3.33019 loss)
I0605 01:16:11.104169   904 sgd_solver.cpp:106] Iteration 26320, lr = 0.0338071
I0605 01:16:31.977624   904 solver.cpp:229] Iteration 26360, loss = 3.34321
I0605 01:16:31.977788   904 solver.cpp:245]     Train net output #0: loss = 3.50386 (* 1 = 3.50386 loss)
I0605 01:16:31.977812   904 sgd_solver.cpp:106] Iteration 26360, lr = 0.0337976
I0605 01:16:52.767493   904 solver.cpp:229] Iteration 26400, loss = 3.31619
I0605 01:16:52.767525   904 solver.cpp:245]     Train net output #0: loss = 3.3602 (* 1 = 3.3602 loss)
I0605 01:16:52.767534   904 sgd_solver.cpp:106] Iteration 26400, lr = 0.0337882
I0605 01:17:13.436980   904 solver.cpp:229] Iteration 26440, loss = 3.33888
I0605 01:17:13.437144   904 solver.cpp:245]     Train net output #0: loss = 3.23758 (* 1 = 3.23758 loss)
I0605 01:17:13.437167   904 sgd_solver.cpp:106] Iteration 26440, lr = 0.0337788
I0605 01:17:34.125833   904 solver.cpp:229] Iteration 26480, loss = 3.321
I0605 01:17:34.125881   904 solver.cpp:245]     Train net output #0: loss = 3.38902 (* 1 = 3.38902 loss)
I0605 01:17:34.125890   904 sgd_solver.cpp:106] Iteration 26480, lr = 0.0337694
I0605 01:17:54.803056   904 solver.cpp:229] Iteration 26520, loss = 3.31503
I0605 01:17:54.803227   904 solver.cpp:245]     Train net output #0: loss = 3.18215 (* 1 = 3.18215 loss)
I0605 01:17:54.803238   904 sgd_solver.cpp:106] Iteration 26520, lr = 0.03376
I0605 01:18:15.389881   904 solver.cpp:229] Iteration 26560, loss = 3.30089
I0605 01:18:15.389937   904 solver.cpp:245]     Train net output #0: loss = 3.07816 (* 1 = 3.07816 loss)
I0605 01:18:15.389946   904 sgd_solver.cpp:106] Iteration 26560, lr = 0.0337506
I0605 01:18:35.862887   904 solver.cpp:229] Iteration 26600, loss = 3.3216
I0605 01:18:35.863147   904 solver.cpp:245]     Train net output #0: loss = 3.22983 (* 1 = 3.22983 loss)
I0605 01:18:35.863173   904 sgd_solver.cpp:106] Iteration 26600, lr = 0.0337412
I0605 01:18:56.427137   904 solver.cpp:229] Iteration 26640, loss = 3.27547
I0605 01:18:56.427184   904 solver.cpp:245]     Train net output #0: loss = 3.27964 (* 1 = 3.27964 loss)
I0605 01:18:56.427196   904 sgd_solver.cpp:106] Iteration 26640, lr = 0.0337318
I0605 01:19:08.063771   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 01:19:17.079890   904 solver.cpp:229] Iteration 26680, loss = 3.34892
I0605 01:19:17.079936   904 solver.cpp:245]     Train net output #0: loss = 3.29461 (* 1 = 3.29461 loss)
I0605 01:19:17.079969   904 sgd_solver.cpp:106] Iteration 26680, lr = 0.0337224
I0605 01:19:37.590104   904 solver.cpp:229] Iteration 26720, loss = 3.30857
I0605 01:19:37.590162   904 solver.cpp:245]     Train net output #0: loss = 3.04122 (* 1 = 3.04122 loss)
I0605 01:19:37.590172   904 sgd_solver.cpp:106] Iteration 26720, lr = 0.0337129
I0605 01:19:58.079903   904 solver.cpp:229] Iteration 26760, loss = 3.25157
I0605 01:19:58.080181   904 solver.cpp:245]     Train net output #0: loss = 3.44207 (* 1 = 3.44207 loss)
I0605 01:19:58.080207   904 sgd_solver.cpp:106] Iteration 26760, lr = 0.0337035
I0605 01:20:18.559528   904 solver.cpp:229] Iteration 26800, loss = 3.31816
I0605 01:20:18.559576   904 solver.cpp:245]     Train net output #0: loss = 3.27386 (* 1 = 3.27386 loss)
I0605 01:20:18.559587   904 sgd_solver.cpp:106] Iteration 26800, lr = 0.0336941
I0605 01:20:38.815714   904 solver.cpp:229] Iteration 26840, loss = 3.29284
I0605 01:20:38.816179   904 solver.cpp:245]     Train net output #0: loss = 3.11682 (* 1 = 3.11682 loss)
I0605 01:20:38.816190   904 sgd_solver.cpp:106] Iteration 26840, lr = 0.0336847
I0605 01:20:58.923559   904 solver.cpp:229] Iteration 26880, loss = 3.28116
I0605 01:20:58.923600   904 solver.cpp:245]     Train net output #0: loss = 3.61548 (* 1 = 3.61548 loss)
I0605 01:20:58.923610   904 sgd_solver.cpp:106] Iteration 26880, lr = 0.0336753
I0605 01:21:19.051370   904 solver.cpp:229] Iteration 26920, loss = 3.31923
I0605 01:21:19.051813   904 solver.cpp:245]     Train net output #0: loss = 3.27783 (* 1 = 3.27783 loss)
I0605 01:21:19.051863   904 sgd_solver.cpp:106] Iteration 26920, lr = 0.0336659
I0605 01:21:39.049036   904 solver.cpp:229] Iteration 26960, loss = 3.2975
I0605 01:21:39.049096   904 solver.cpp:245]     Train net output #0: loss = 3.30669 (* 1 = 3.30669 loss)
I0605 01:21:39.049108   904 sgd_solver.cpp:106] Iteration 26960, lr = 0.0336565
I0605 01:21:58.404093   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_27000.caffemodel
I0605 01:21:58.665341   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_27000.solverstate
I0605 01:21:58.743481   904 solver.cpp:338] Iteration 27000, Testing net (#0)
I0605 01:21:58.743566   904 net.cpp:748] Ignoring source layer loss
I0605 01:22:11.665804   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 01:22:45.141582   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 01:23:06.057849   904 solver.cpp:406]     Test net output #0: accuracy = 0.318901
I0605 01:23:06.057898   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.561739
I0605 01:23:06.371739   904 solver.cpp:229] Iteration 27000, loss = 3.31723
I0605 01:23:06.371793   904 solver.cpp:245]     Train net output #0: loss = 3.1494 (* 1 = 3.1494 loss)
I0605 01:23:06.371804   904 sgd_solver.cpp:106] Iteration 27000, lr = 0.0336471
I0605 01:23:25.526288   904 solver.cpp:229] Iteration 27040, loss = 3.33079
I0605 01:23:25.526499   904 solver.cpp:245]     Train net output #0: loss = 3.49064 (* 1 = 3.49064 loss)
I0605 01:23:25.526525   904 sgd_solver.cpp:106] Iteration 27040, lr = 0.0336376
I0605 01:23:46.526742   904 solver.cpp:229] Iteration 27080, loss = 3.27746
I0605 01:23:46.526793   904 solver.cpp:245]     Train net output #0: loss = 2.81847 (* 1 = 2.81847 loss)
I0605 01:23:46.526804   904 sgd_solver.cpp:106] Iteration 27080, lr = 0.0336282
I0605 01:24:07.489845   904 solver.cpp:229] Iteration 27120, loss = 3.31406
I0605 01:24:07.490026   904 solver.cpp:245]     Train net output #0: loss = 3.28038 (* 1 = 3.28038 loss)
I0605 01:24:07.490037   904 sgd_solver.cpp:106] Iteration 27120, lr = 0.0336188
I0605 01:24:28.238600   904 solver.cpp:229] Iteration 27160, loss = 3.27284
I0605 01:24:28.238631   904 solver.cpp:245]     Train net output #0: loss = 3.44363 (* 1 = 3.44363 loss)
I0605 01:24:28.238637   904 sgd_solver.cpp:106] Iteration 27160, lr = 0.0336094
I0605 01:24:48.894824   904 solver.cpp:229] Iteration 27200, loss = 3.28893
I0605 01:24:48.895009   904 solver.cpp:245]     Train net output #0: loss = 3.21436 (* 1 = 3.21436 loss)
I0605 01:24:48.895037   904 sgd_solver.cpp:106] Iteration 27200, lr = 0.0336
I0605 01:25:08.986156   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 01:25:09.498976   904 solver.cpp:229] Iteration 27240, loss = 3.27162
I0605 01:25:09.499038   904 solver.cpp:245]     Train net output #0: loss = 3.20804 (* 1 = 3.20804 loss)
I0605 01:25:09.499059   904 sgd_solver.cpp:106] Iteration 27240, lr = 0.0335906
I0605 01:25:30.095953   904 solver.cpp:229] Iteration 27280, loss = 3.31719
I0605 01:25:30.096177   904 solver.cpp:245]     Train net output #0: loss = 3.35895 (* 1 = 3.35895 loss)
I0605 01:25:30.096205   904 sgd_solver.cpp:106] Iteration 27280, lr = 0.0335812
I0605 01:25:50.695003   904 solver.cpp:229] Iteration 27320, loss = 3.31528
I0605 01:25:50.695050   904 solver.cpp:245]     Train net output #0: loss = 3.20947 (* 1 = 3.20947 loss)
I0605 01:25:50.695060   904 sgd_solver.cpp:106] Iteration 27320, lr = 0.0335718
I0605 01:26:11.301336   904 solver.cpp:229] Iteration 27360, loss = 3.27705
I0605 01:26:11.301545   904 solver.cpp:245]     Train net output #0: loss = 2.89984 (* 1 = 2.89984 loss)
I0605 01:26:11.301571   904 sgd_solver.cpp:106] Iteration 27360, lr = 0.0335624
I0605 01:26:31.811038   904 solver.cpp:229] Iteration 27400, loss = 3.3297
I0605 01:26:31.811097   904 solver.cpp:245]     Train net output #0: loss = 3.44776 (* 1 = 3.44776 loss)
I0605 01:26:31.811110   904 sgd_solver.cpp:106] Iteration 27400, lr = 0.0335529
I0605 01:26:52.225592   904 solver.cpp:229] Iteration 27440, loss = 3.33781
I0605 01:26:52.225734   904 solver.cpp:245]     Train net output #0: loss = 3.22927 (* 1 = 3.22927 loss)
I0605 01:26:52.225745   904 sgd_solver.cpp:106] Iteration 27440, lr = 0.0335435
I0605 01:27:12.781640   904 solver.cpp:229] Iteration 27480, loss = 3.29059
I0605 01:27:12.781689   904 solver.cpp:245]     Train net output #0: loss = 3.18909 (* 1 = 3.18909 loss)
I0605 01:27:12.781699   904 sgd_solver.cpp:106] Iteration 27480, lr = 0.0335341
I0605 01:27:33.348310   904 solver.cpp:229] Iteration 27520, loss = 3.27467
I0605 01:27:33.348462   904 solver.cpp:245]     Train net output #0: loss = 3.29844 (* 1 = 3.29844 loss)
I0605 01:27:33.348474   904 sgd_solver.cpp:106] Iteration 27520, lr = 0.0335247
I0605 01:27:53.783591   904 solver.cpp:229] Iteration 27560, loss = 3.34171
I0605 01:27:53.783641   904 solver.cpp:245]     Train net output #0: loss = 3.21538 (* 1 = 3.21538 loss)
I0605 01:27:53.783650   904 sgd_solver.cpp:106] Iteration 27560, lr = 0.0335153
I0605 01:28:14.112646   904 solver.cpp:229] Iteration 27600, loss = 3.30362
I0605 01:28:14.112784   904 solver.cpp:245]     Train net output #0: loss = 3.50011 (* 1 = 3.50011 loss)
I0605 01:28:14.112792   904 sgd_solver.cpp:106] Iteration 27600, lr = 0.0335059
I0605 01:28:34.362272   904 solver.cpp:229] Iteration 27640, loss = 3.27918
I0605 01:28:34.362315   904 solver.cpp:245]     Train net output #0: loss = 3.2367 (* 1 = 3.2367 loss)
I0605 01:28:34.362325   904 sgd_solver.cpp:106] Iteration 27640, lr = 0.0334965
I0605 01:28:54.776909   904 solver.cpp:229] Iteration 27680, loss = 3.27611
I0605 01:28:54.777109   904 solver.cpp:245]     Train net output #0: loss = 3.15967 (* 1 = 3.15967 loss)
I0605 01:28:54.777138   904 sgd_solver.cpp:106] Iteration 27680, lr = 0.0334871
I0605 01:29:15.203963   904 solver.cpp:229] Iteration 27720, loss = 3.27322
I0605 01:29:15.204002   904 solver.cpp:245]     Train net output #0: loss = 3.22581 (* 1 = 3.22581 loss)
I0605 01:29:15.204011   904 sgd_solver.cpp:106] Iteration 27720, lr = 0.0334776
I0605 01:29:35.595877   904 solver.cpp:229] Iteration 27760, loss = 3.28956
I0605 01:29:35.596076   904 solver.cpp:245]     Train net output #0: loss = 3.32895 (* 1 = 3.32895 loss)
I0605 01:29:35.596098   904 sgd_solver.cpp:106] Iteration 27760, lr = 0.0334682
I0605 01:29:53.035629   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 01:29:55.819531   904 solver.cpp:229] Iteration 27800, loss = 3.27829
I0605 01:29:55.819584   904 solver.cpp:245]     Train net output #0: loss = 3.27782 (* 1 = 3.27782 loss)
I0605 01:29:55.819599   904 sgd_solver.cpp:106] Iteration 27800, lr = 0.0334588
I0605 01:30:16.038334   904 solver.cpp:229] Iteration 27840, loss = 3.30375
I0605 01:30:16.038547   904 solver.cpp:245]     Train net output #0: loss = 3.11021 (* 1 = 3.11021 loss)
I0605 01:30:16.038570   904 sgd_solver.cpp:106] Iteration 27840, lr = 0.0334494
I0605 01:30:36.262476   904 solver.cpp:229] Iteration 27880, loss = 3.24767
I0605 01:30:36.262524   904 solver.cpp:245]     Train net output #0: loss = 3.41556 (* 1 = 3.41556 loss)
I0605 01:30:36.262531   904 sgd_solver.cpp:106] Iteration 27880, lr = 0.03344
I0605 01:30:56.478536   904 solver.cpp:229] Iteration 27920, loss = 3.2437
I0605 01:30:56.478793   904 solver.cpp:245]     Train net output #0: loss = 3.47152 (* 1 = 3.47152 loss)
I0605 01:30:56.478804   904 sgd_solver.cpp:106] Iteration 27920, lr = 0.0334306
I0605 01:31:16.718670   904 solver.cpp:229] Iteration 27960, loss = 3.29304
I0605 01:31:16.718730   904 solver.cpp:245]     Train net output #0: loss = 3.27956 (* 1 = 3.27956 loss)
I0605 01:31:16.718741   904 sgd_solver.cpp:106] Iteration 27960, lr = 0.0334212
I0605 01:31:36.431526   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_28000.caffemodel
I0605 01:31:36.695112   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_28000.solverstate
I0605 01:31:36.772631   904 solver.cpp:338] Iteration 28000, Testing net (#0)
I0605 01:31:36.772716   904 net.cpp:748] Ignoring source layer loss
I0605 01:31:57.031589   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 01:32:32.877713   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 01:32:44.724400   904 solver.cpp:406]     Test net output #0: accuracy = 0.32126
I0605 01:32:44.724445   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.5667
I0605 01:32:45.037878   904 solver.cpp:229] Iteration 28000, loss = 3.31287
I0605 01:32:45.037914   904 solver.cpp:245]     Train net output #0: loss = 3.30935 (* 1 = 3.30935 loss)
I0605 01:32:45.037922   904 sgd_solver.cpp:106] Iteration 28000, lr = 0.0334118
I0605 01:33:04.252830   904 solver.cpp:229] Iteration 28040, loss = 3.3039
I0605 01:33:04.253041   904 solver.cpp:245]     Train net output #0: loss = 3.30619 (* 1 = 3.30619 loss)
I0605 01:33:04.253073   904 sgd_solver.cpp:106] Iteration 28040, lr = 0.0334023
I0605 01:33:25.635643   904 solver.cpp:229] Iteration 28080, loss = 3.25303
I0605 01:33:25.635695   904 solver.cpp:245]     Train net output #0: loss = 3.20546 (* 1 = 3.20546 loss)
I0605 01:33:25.635706   904 sgd_solver.cpp:106] Iteration 28080, lr = 0.0333929
I0605 01:33:47.175132   904 solver.cpp:229] Iteration 28120, loss = 3.25155
I0605 01:33:47.175343   904 solver.cpp:245]     Train net output #0: loss = 3.12899 (* 1 = 3.12899 loss)
I0605 01:33:47.175369   904 sgd_solver.cpp:106] Iteration 28120, lr = 0.0333835
I0605 01:34:08.190618   904 solver.cpp:229] Iteration 28160, loss = 3.26287
I0605 01:34:08.190677   904 solver.cpp:245]     Train net output #0: loss = 3.22621 (* 1 = 3.22621 loss)
I0605 01:34:08.190685   904 sgd_solver.cpp:106] Iteration 28160, lr = 0.0333741
I0605 01:34:29.187783   904 solver.cpp:229] Iteration 28200, loss = 3.2727
I0605 01:34:29.187911   904 solver.cpp:245]     Train net output #0: loss = 2.93788 (* 1 = 2.93788 loss)
I0605 01:34:29.187922   904 sgd_solver.cpp:106] Iteration 28200, lr = 0.0333647
I0605 01:34:50.199961   904 solver.cpp:229] Iteration 28240, loss = 3.25724
I0605 01:34:50.200011   904 solver.cpp:245]     Train net output #0: loss = 3.26278 (* 1 = 3.26278 loss)
I0605 01:34:50.200018   904 sgd_solver.cpp:106] Iteration 28240, lr = 0.0333553
I0605 01:35:11.208209   904 solver.cpp:229] Iteration 28280, loss = 3.25753
I0605 01:35:11.208470   904 solver.cpp:245]     Train net output #0: loss = 3.34088 (* 1 = 3.34088 loss)
I0605 01:35:11.208498   904 sgd_solver.cpp:106] Iteration 28280, lr = 0.0333459
I0605 01:35:32.150581   904 solver.cpp:229] Iteration 28320, loss = 3.27326
I0605 01:35:32.150627   904 solver.cpp:245]     Train net output #0: loss = 3.59437 (* 1 = 3.59437 loss)
I0605 01:35:32.150638   904 sgd_solver.cpp:106] Iteration 28320, lr = 0.0333365
I0605 01:35:34.237697   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 01:35:52.971385   904 solver.cpp:229] Iteration 28360, loss = 3.22922
I0605 01:35:52.971518   904 solver.cpp:245]     Train net output #0: loss = 3.44054 (* 1 = 3.44054 loss)
I0605 01:35:52.971529   904 sgd_solver.cpp:106] Iteration 28360, lr = 0.0333271
I0605 01:36:13.820271   904 solver.cpp:229] Iteration 28400, loss = 3.24949
I0605 01:36:13.820333   904 solver.cpp:245]     Train net output #0: loss = 3.20853 (* 1 = 3.20853 loss)
I0605 01:36:13.820343   904 sgd_solver.cpp:106] Iteration 28400, lr = 0.0333176
I0605 01:36:34.647802   904 solver.cpp:229] Iteration 28440, loss = 3.2575
I0605 01:36:34.648082   904 solver.cpp:245]     Train net output #0: loss = 3.47462 (* 1 = 3.47462 loss)
I0605 01:36:34.648113   904 sgd_solver.cpp:106] Iteration 28440, lr = 0.0333082
I0605 01:36:55.478132   904 solver.cpp:229] Iteration 28480, loss = 3.22995
I0605 01:36:55.478178   904 solver.cpp:245]     Train net output #0: loss = 3.23813 (* 1 = 3.23813 loss)
I0605 01:36:55.478188   904 sgd_solver.cpp:106] Iteration 28480, lr = 0.0332988
I0605 01:37:16.198139   904 solver.cpp:229] Iteration 28520, loss = 3.26213
I0605 01:37:16.198330   904 solver.cpp:245]     Train net output #0: loss = 3.01913 (* 1 = 3.01913 loss)
I0605 01:37:16.198357   904 sgd_solver.cpp:106] Iteration 28520, lr = 0.0332894
I0605 01:37:36.893003   904 solver.cpp:229] Iteration 28560, loss = 3.25611
I0605 01:37:36.893064   904 solver.cpp:245]     Train net output #0: loss = 3.28122 (* 1 = 3.28122 loss)
I0605 01:37:36.893071   904 sgd_solver.cpp:106] Iteration 28560, lr = 0.03328
I0605 01:37:57.609578   904 solver.cpp:229] Iteration 28600, loss = 3.28408
I0605 01:37:57.609791   904 solver.cpp:245]     Train net output #0: loss = 3.31252 (* 1 = 3.31252 loss)
I0605 01:37:57.609815   904 sgd_solver.cpp:106] Iteration 28600, lr = 0.0332706
I0605 01:38:18.308473   904 solver.cpp:229] Iteration 28640, loss = 3.22645
I0605 01:38:18.308532   904 solver.cpp:245]     Train net output #0: loss = 3.11575 (* 1 = 3.11575 loss)
I0605 01:38:18.308542   904 sgd_solver.cpp:106] Iteration 28640, lr = 0.0332612
I0605 01:38:39.021291   904 solver.cpp:229] Iteration 28680, loss = 3.28575
I0605 01:38:39.021432   904 solver.cpp:245]     Train net output #0: loss = 3.26696 (* 1 = 3.26696 loss)
I0605 01:38:39.021440   904 sgd_solver.cpp:106] Iteration 28680, lr = 0.0332518
I0605 01:38:59.694190   904 solver.cpp:229] Iteration 28720, loss = 3.27929
I0605 01:38:59.694238   904 solver.cpp:245]     Train net output #0: loss = 3.43402 (* 1 = 3.43402 loss)
I0605 01:38:59.694250   904 sgd_solver.cpp:106] Iteration 28720, lr = 0.0332424
I0605 01:39:20.233193   904 solver.cpp:229] Iteration 28760, loss = 3.26045
I0605 01:39:20.233387   904 solver.cpp:245]     Train net output #0: loss = 3.34781 (* 1 = 3.34781 loss)
I0605 01:39:20.233410   904 sgd_solver.cpp:106] Iteration 28760, lr = 0.0332329
I0605 01:39:40.787062   904 solver.cpp:229] Iteration 28800, loss = 3.25145
I0605 01:39:40.787114   904 solver.cpp:245]     Train net output #0: loss = 3.44523 (* 1 = 3.44523 loss)
I0605 01:39:40.787123   904 sgd_solver.cpp:106] Iteration 28800, lr = 0.0332235
I0605 01:40:01.466982   904 solver.cpp:229] Iteration 28840, loss = 3.24865
I0605 01:40:01.467157   904 solver.cpp:245]     Train net output #0: loss = 3.2035 (* 1 = 3.2035 loss)
I0605 01:40:01.467180   904 sgd_solver.cpp:106] Iteration 28840, lr = 0.0332141
I0605 01:40:20.558553   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 01:40:22.099056   904 solver.cpp:229] Iteration 28880, loss = 3.30128
I0605 01:40:22.099108   904 solver.cpp:245]     Train net output #0: loss = 3.35416 (* 1 = 3.35416 loss)
I0605 01:40:22.099117   904 sgd_solver.cpp:106] Iteration 28880, lr = 0.0332047
I0605 01:40:42.624191   904 solver.cpp:229] Iteration 28920, loss = 3.26402
I0605 01:40:42.624444   904 solver.cpp:245]     Train net output #0: loss = 2.94922 (* 1 = 2.94922 loss)
I0605 01:40:42.624469   904 sgd_solver.cpp:106] Iteration 28920, lr = 0.0331953
I0605 01:41:03.156671   904 solver.cpp:229] Iteration 28960, loss = 3.29456
I0605 01:41:03.156725   904 solver.cpp:245]     Train net output #0: loss = 3.21463 (* 1 = 3.21463 loss)
I0605 01:41:03.156749   904 sgd_solver.cpp:106] Iteration 28960, lr = 0.0331859
I0605 01:41:23.170311   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_29000.caffemodel
I0605 01:41:23.432907   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_29000.solverstate
I0605 01:41:23.513748   904 solver.cpp:338] Iteration 29000, Testing net (#0)
I0605 01:41:23.513830   904 net.cpp:748] Ignoring source layer loss
I0605 01:41:49.580646   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 01:42:23.687973   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 01:42:31.338367   904 solver.cpp:406]     Test net output #0: accuracy = 0.335341
I0605 01:42:31.338399   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.586899
I0605 01:42:31.651202   904 solver.cpp:229] Iteration 29000, loss = 3.29751
I0605 01:42:31.651242   904 solver.cpp:245]     Train net output #0: loss = 3.17596 (* 1 = 3.17596 loss)
I0605 01:42:31.651252   904 sgd_solver.cpp:106] Iteration 29000, lr = 0.0331765
I0605 01:42:50.894716   904 solver.cpp:229] Iteration 29040, loss = 3.25169
I0605 01:42:50.894765   904 solver.cpp:245]     Train net output #0: loss = 3.13345 (* 1 = 3.13345 loss)
I0605 01:42:50.894774   904 sgd_solver.cpp:106] Iteration 29040, lr = 0.0331671
I0605 01:43:12.378476   904 solver.cpp:229] Iteration 29080, loss = 3.25954
I0605 01:43:12.378661   904 solver.cpp:245]     Train net output #0: loss = 3.10243 (* 1 = 3.10243 loss)
I0605 01:43:12.378680   904 sgd_solver.cpp:106] Iteration 29080, lr = 0.0331576
I0605 01:43:33.937119   904 solver.cpp:229] Iteration 29120, loss = 3.2176
I0605 01:43:33.937171   904 solver.cpp:245]     Train net output #0: loss = 3.30051 (* 1 = 3.30051 loss)
I0605 01:43:33.937180   904 sgd_solver.cpp:106] Iteration 29120, lr = 0.0331482
I0605 01:43:55.185580   904 solver.cpp:229] Iteration 29160, loss = 3.26027
I0605 01:43:55.185763   904 solver.cpp:245]     Train net output #0: loss = 3.22591 (* 1 = 3.22591 loss)
I0605 01:43:55.185773   904 sgd_solver.cpp:106] Iteration 29160, lr = 0.0331388
I0605 01:44:16.164589   904 solver.cpp:229] Iteration 29200, loss = 3.28111
I0605 01:44:16.164625   904 solver.cpp:245]     Train net output #0: loss = 3.2403 (* 1 = 3.2403 loss)
I0605 01:44:16.164633   904 sgd_solver.cpp:106] Iteration 29200, lr = 0.0331294
I0605 01:44:37.136109   904 solver.cpp:229] Iteration 29240, loss = 3.2591
I0605 01:44:37.136278   904 solver.cpp:245]     Train net output #0: loss = 3.37392 (* 1 = 3.37392 loss)
I0605 01:44:37.136302   904 sgd_solver.cpp:106] Iteration 29240, lr = 0.03312
I0605 01:44:58.117252   904 solver.cpp:229] Iteration 29280, loss = 3.2363
I0605 01:44:58.117302   904 solver.cpp:245]     Train net output #0: loss = 3.13 (* 1 = 3.13 loss)
I0605 01:44:58.117311   904 sgd_solver.cpp:106] Iteration 29280, lr = 0.0331106
I0605 01:45:19.085508   904 solver.cpp:229] Iteration 29320, loss = 3.2734
I0605 01:45:19.085708   904 solver.cpp:245]     Train net output #0: loss = 3.02371 (* 1 = 3.02371 loss)
I0605 01:45:19.085737   904 sgd_solver.cpp:106] Iteration 29320, lr = 0.0331012
I0605 01:45:39.862169   904 solver.cpp:229] Iteration 29360, loss = 3.25894
I0605 01:45:39.862233   904 solver.cpp:245]     Train net output #0: loss = 3.19189 (* 1 = 3.19189 loss)
I0605 01:45:39.862244   904 sgd_solver.cpp:106] Iteration 29360, lr = 0.0330918
I0605 01:45:59.663194   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 01:46:00.431650   904 solver.cpp:229] Iteration 29400, loss = 3.2625
I0605 01:46:00.431694   904 solver.cpp:245]     Train net output #0: loss = 3.16415 (* 1 = 3.16415 loss)
I0605 01:46:00.431704   904 sgd_solver.cpp:106] Iteration 29400, lr = 0.0330824
I0605 01:46:21.079751   904 solver.cpp:229] Iteration 29440, loss = 3.22546
I0605 01:46:21.079802   904 solver.cpp:245]     Train net output #0: loss = 3.11994 (* 1 = 3.11994 loss)
I0605 01:46:21.079813   904 sgd_solver.cpp:106] Iteration 29440, lr = 0.0330729
I0605 01:46:41.841802   904 solver.cpp:229] Iteration 29480, loss = 3.22858
I0605 01:46:41.842036   904 solver.cpp:245]     Train net output #0: loss = 2.96085 (* 1 = 2.96085 loss)
I0605 01:46:41.842061   904 sgd_solver.cpp:106] Iteration 29480, lr = 0.0330635
I0605 01:47:02.418298   904 solver.cpp:229] Iteration 29520, loss = 3.26434
I0605 01:47:02.418339   904 solver.cpp:245]     Train net output #0: loss = 3.25227 (* 1 = 3.25227 loss)
I0605 01:47:02.418349   904 sgd_solver.cpp:106] Iteration 29520, lr = 0.0330541
I0605 01:47:22.923241   904 solver.cpp:229] Iteration 29560, loss = 3.261
I0605 01:47:22.932530   904 solver.cpp:245]     Train net output #0: loss = 3.33195 (* 1 = 3.33195 loss)
I0605 01:47:22.932554   904 sgd_solver.cpp:106] Iteration 29560, lr = 0.0330447
I0605 01:47:43.512079   904 solver.cpp:229] Iteration 29600, loss = 3.19057
I0605 01:47:43.512132   904 solver.cpp:245]     Train net output #0: loss = 3.14823 (* 1 = 3.14823 loss)
I0605 01:47:43.512141   904 sgd_solver.cpp:106] Iteration 29600, lr = 0.0330353
I0605 01:48:04.035323   904 solver.cpp:229] Iteration 29640, loss = 3.27595
I0605 01:48:04.035528   904 solver.cpp:245]     Train net output #0: loss = 3.24444 (* 1 = 3.24444 loss)
I0605 01:48:04.035557   904 sgd_solver.cpp:106] Iteration 29640, lr = 0.0330259
I0605 01:48:24.391166   904 solver.cpp:229] Iteration 29680, loss = 3.25075
I0605 01:48:24.391213   904 solver.cpp:245]     Train net output #0: loss = 3.37705 (* 1 = 3.37705 loss)
I0605 01:48:24.391222   904 sgd_solver.cpp:106] Iteration 29680, lr = 0.0330165
I0605 01:48:44.734244   904 solver.cpp:229] Iteration 29720, loss = 3.25157
I0605 01:48:44.734416   904 solver.cpp:245]     Train net output #0: loss = 3.15074 (* 1 = 3.15074 loss)
I0605 01:48:44.734427   904 sgd_solver.cpp:106] Iteration 29720, lr = 0.0330071
I0605 01:49:05.202442   904 solver.cpp:229] Iteration 29760, loss = 3.24612
I0605 01:49:05.202494   904 solver.cpp:245]     Train net output #0: loss = 3.41408 (* 1 = 3.41408 loss)
I0605 01:49:05.202505   904 sgd_solver.cpp:106] Iteration 29760, lr = 0.0329976
I0605 01:49:25.672492   904 solver.cpp:229] Iteration 29800, loss = 3.25725
I0605 01:49:25.672655   904 solver.cpp:245]     Train net output #0: loss = 3.42109 (* 1 = 3.42109 loss)
I0605 01:49:25.672690   904 sgd_solver.cpp:106] Iteration 29800, lr = 0.0329882
I0605 01:49:46.115214   904 solver.cpp:229] Iteration 29840, loss = 3.21158
I0605 01:49:46.115265   904 solver.cpp:245]     Train net output #0: loss = 3.13919 (* 1 = 3.13919 loss)
I0605 01:49:46.115278   904 sgd_solver.cpp:106] Iteration 29840, lr = 0.0329788
I0605 01:50:06.410992   904 solver.cpp:229] Iteration 29880, loss = 3.23908
I0605 01:50:06.411123   904 solver.cpp:245]     Train net output #0: loss = 3.45452 (* 1 = 3.45452 loss)
I0605 01:50:06.411134   904 sgd_solver.cpp:106] Iteration 29880, lr = 0.0329694
I0605 01:50:26.680953   904 solver.cpp:229] Iteration 29920, loss = 3.27218
I0605 01:50:26.681000   904 solver.cpp:245]     Train net output #0: loss = 3.251 (* 1 = 3.251 loss)
I0605 01:50:26.681010   904 sgd_solver.cpp:106] Iteration 29920, lr = 0.03296
I0605 01:50:32.269387   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 01:50:46.977630   904 solver.cpp:229] Iteration 29960, loss = 3.24627
I0605 01:50:46.977771   904 solver.cpp:245]     Train net output #0: loss = 3.23112 (* 1 = 3.23112 loss)
I0605 01:50:46.977782   904 sgd_solver.cpp:106] Iteration 29960, lr = 0.0329506
I0605 01:51:06.759519   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_30000.caffemodel
I0605 01:51:07.027839   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_30000.solverstate
I0605 01:51:07.105298   904 solver.cpp:338] Iteration 30000, Testing net (#0)
I0605 01:51:07.105378   904 net.cpp:748] Ignoring source layer loss
I0605 01:51:35.053865   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 01:52:07.503716   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 01:52:12.181357   904 solver.cpp:406]     Test net output #0: accuracy = 0.331201
I0605 01:52:12.181414   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.579659
I0605 01:52:12.494535   904 solver.cpp:229] Iteration 30000, loss = 3.21871
I0605 01:52:12.494580   904 solver.cpp:245]     Train net output #0: loss = 3.23741 (* 1 = 3.23741 loss)
I0605 01:52:12.494591   904 sgd_solver.cpp:106] Iteration 30000, lr = 0.0329412
I0605 01:52:31.691539   904 solver.cpp:229] Iteration 30040, loss = 3.24981
I0605 01:52:31.691586   904 solver.cpp:245]     Train net output #0: loss = 3.13605 (* 1 = 3.13605 loss)
I0605 01:52:31.691594   904 sgd_solver.cpp:106] Iteration 30040, lr = 0.0329318
I0605 01:52:52.958222   904 solver.cpp:229] Iteration 30080, loss = 3.27499
I0605 01:52:52.958478   904 solver.cpp:245]     Train net output #0: loss = 3.31617 (* 1 = 3.31617 loss)
I0605 01:52:52.958506   904 sgd_solver.cpp:106] Iteration 30080, lr = 0.0329224
I0605 01:53:14.333760   904 solver.cpp:229] Iteration 30120, loss = 3.21153
I0605 01:53:14.333797   904 solver.cpp:245]     Train net output #0: loss = 2.90823 (* 1 = 2.90823 loss)
I0605 01:53:14.333807   904 sgd_solver.cpp:106] Iteration 30120, lr = 0.0329129
I0605 01:53:35.297174   904 solver.cpp:229] Iteration 30160, loss = 3.24204
I0605 01:53:35.297364   904 solver.cpp:245]     Train net output #0: loss = 3.05788 (* 1 = 3.05788 loss)
I0605 01:53:35.297391   904 sgd_solver.cpp:106] Iteration 30160, lr = 0.0329035
I0605 01:53:56.259968   904 solver.cpp:229] Iteration 30200, loss = 3.27755
I0605 01:53:56.260022   904 solver.cpp:245]     Train net output #0: loss = 3.465 (* 1 = 3.465 loss)
I0605 01:53:56.260033   904 sgd_solver.cpp:106] Iteration 30200, lr = 0.0328941
I0605 01:54:17.200909   904 solver.cpp:229] Iteration 30240, loss = 3.21644
I0605 01:54:17.201033   904 solver.cpp:245]     Train net output #0: loss = 3.32378 (* 1 = 3.32378 loss)
I0605 01:54:17.201041   904 sgd_solver.cpp:106] Iteration 30240, lr = 0.0328847
I0605 01:54:38.167850   904 solver.cpp:229] Iteration 30280, loss = 3.22664
I0605 01:54:38.167893   904 solver.cpp:245]     Train net output #0: loss = 3.43319 (* 1 = 3.43319 loss)
I0605 01:54:38.167903   904 sgd_solver.cpp:106] Iteration 30280, lr = 0.0328753
I0605 01:54:58.638276   904 solver.cpp:229] Iteration 30320, loss = 3.27982
I0605 01:54:58.638418   904 solver.cpp:245]     Train net output #0: loss = 3.27092 (* 1 = 3.27092 loss)
I0605 01:54:58.638425   904 sgd_solver.cpp:106] Iteration 30320, lr = 0.0328659
I0605 01:55:19.372859   904 solver.cpp:229] Iteration 30360, loss = 3.23233
I0605 01:55:19.372931   904 solver.cpp:245]     Train net output #0: loss = 3.44853 (* 1 = 3.44853 loss)
I0605 01:55:19.372947   904 sgd_solver.cpp:106] Iteration 30360, lr = 0.0328565
I0605 01:55:40.163476   904 solver.cpp:229] Iteration 30400, loss = 3.18399
I0605 01:55:40.163677   904 solver.cpp:245]     Train net output #0: loss = 3.25266 (* 1 = 3.25266 loss)
I0605 01:55:40.163722   904 sgd_solver.cpp:106] Iteration 30400, lr = 0.0328471
I0605 01:55:59.880919   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 01:56:00.646358   904 solver.cpp:229] Iteration 30440, loss = 3.20667
I0605 01:56:00.646407   904 solver.cpp:245]     Train net output #0: loss = 3.27763 (* 1 = 3.27763 loss)
I0605 01:56:00.646416   904 sgd_solver.cpp:106] Iteration 30440, lr = 0.0328376
I0605 01:56:21.103121   904 solver.cpp:229] Iteration 30480, loss = 3.26347
I0605 01:56:21.103274   904 solver.cpp:245]     Train net output #0: loss = 3.10189 (* 1 = 3.10189 loss)
I0605 01:56:21.103286   904 sgd_solver.cpp:106] Iteration 30480, lr = 0.0328282
I0605 01:56:41.711328   904 solver.cpp:229] Iteration 30520, loss = 3.27185
I0605 01:56:41.711383   904 solver.cpp:245]     Train net output #0: loss = 3.15498 (* 1 = 3.15498 loss)
I0605 01:56:41.711395   904 sgd_solver.cpp:106] Iteration 30520, lr = 0.0328188
I0605 01:57:02.201366   904 solver.cpp:229] Iteration 30560, loss = 3.19505
I0605 01:57:02.201516   904 solver.cpp:245]     Train net output #0: loss = 3.2933 (* 1 = 3.2933 loss)
I0605 01:57:02.201529   904 sgd_solver.cpp:106] Iteration 30560, lr = 0.0328094
I0605 01:57:22.657151   904 solver.cpp:229] Iteration 30600, loss = 3.21564
I0605 01:57:22.657208   904 solver.cpp:245]     Train net output #0: loss = 3.37243 (* 1 = 3.37243 loss)
I0605 01:57:22.657218   904 sgd_solver.cpp:106] Iteration 30600, lr = 0.0328
I0605 01:57:42.893769   904 solver.cpp:229] Iteration 30640, loss = 3.22043
I0605 01:57:42.893976   904 solver.cpp:245]     Train net output #0: loss = 3.11893 (* 1 = 3.11893 loss)
I0605 01:57:42.893990   904 sgd_solver.cpp:106] Iteration 30640, lr = 0.0327906
I0605 01:58:03.217119   904 solver.cpp:229] Iteration 30680, loss = 3.25493
I0605 01:58:03.217171   904 solver.cpp:245]     Train net output #0: loss = 3.32001 (* 1 = 3.32001 loss)
I0605 01:58:03.217181   904 sgd_solver.cpp:106] Iteration 30680, lr = 0.0327812
I0605 01:58:23.661703   904 solver.cpp:229] Iteration 30720, loss = 3.22026
I0605 01:58:23.661914   904 solver.cpp:245]     Train net output #0: loss = 3.17316 (* 1 = 3.17316 loss)
I0605 01:58:23.661942   904 sgd_solver.cpp:106] Iteration 30720, lr = 0.0327718
I0605 01:58:43.963663   904 solver.cpp:229] Iteration 30760, loss = 3.21995
I0605 01:58:43.963711   904 solver.cpp:245]     Train net output #0: loss = 3.25266 (* 1 = 3.25266 loss)
I0605 01:58:43.963721   904 sgd_solver.cpp:106] Iteration 30760, lr = 0.0327624
I0605 01:59:04.119856   904 solver.cpp:229] Iteration 30800, loss = 3.24164
I0605 01:59:04.119990   904 solver.cpp:245]     Train net output #0: loss = 3.10466 (* 1 = 3.10466 loss)
I0605 01:59:04.120002   904 sgd_solver.cpp:106] Iteration 30800, lr = 0.0327529
I0605 01:59:24.377635   904 solver.cpp:229] Iteration 30840, loss = 3.19029
I0605 01:59:24.377686   904 solver.cpp:245]     Train net output #0: loss = 3.10176 (* 1 = 3.10176 loss)
I0605 01:59:24.377696   904 sgd_solver.cpp:106] Iteration 30840, lr = 0.0327435
I0605 01:59:44.605682   904 solver.cpp:229] Iteration 30880, loss = 3.16525
I0605 01:59:44.605880   904 solver.cpp:245]     Train net output #0: loss = 3.3085 (* 1 = 3.3085 loss)
I0605 01:59:44.605902   904 sgd_solver.cpp:106] Iteration 30880, lr = 0.0327341
I0605 02:00:04.825240   904 solver.cpp:229] Iteration 30920, loss = 3.21636
I0605 02:00:04.825291   904 solver.cpp:245]     Train net output #0: loss = 3.32063 (* 1 = 3.32063 loss)
I0605 02:00:04.825299   904 sgd_solver.cpp:106] Iteration 30920, lr = 0.0327247
I0605 02:00:17.143744   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 02:00:24.956328   904 solver.cpp:229] Iteration 30960, loss = 3.19373
I0605 02:00:24.956392   904 solver.cpp:245]     Train net output #0: loss = 3.13936 (* 1 = 3.13936 loss)
I0605 02:00:24.956421   904 sgd_solver.cpp:106] Iteration 30960, lr = 0.0327153
I0605 02:00:44.637678   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_31000.caffemodel
I0605 02:00:44.907114   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_31000.solverstate
I0605 02:00:44.983361   904 solver.cpp:338] Iteration 31000, Testing net (#0)
I0605 02:00:44.983443   904 net.cpp:748] Ignoring source layer loss
I0605 02:01:15.169505   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 02:01:48.454993   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 02:01:51.797871   904 solver.cpp:406]     Test net output #0: accuracy = 0.33672
I0605 02:01:51.797921   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.580759
I0605 02:01:52.110658   904 solver.cpp:229] Iteration 31000, loss = 3.20738
I0605 02:01:52.110715   904 solver.cpp:245]     Train net output #0: loss = 3.43406 (* 1 = 3.43406 loss)
I0605 02:01:52.110725   904 sgd_solver.cpp:106] Iteration 31000, lr = 0.0327059
I0605 02:02:11.327148   904 solver.cpp:229] Iteration 31040, loss = 3.16496
I0605 02:02:11.327204   904 solver.cpp:245]     Train net output #0: loss = 3.10067 (* 1 = 3.10067 loss)
I0605 02:02:11.327214   904 sgd_solver.cpp:106] Iteration 31040, lr = 0.0326965
I0605 02:02:32.652582   904 solver.cpp:229] Iteration 31080, loss = 3.25595
I0605 02:02:32.652781   904 solver.cpp:245]     Train net output #0: loss = 3.25199 (* 1 = 3.25199 loss)
I0605 02:02:32.652809   904 sgd_solver.cpp:106] Iteration 31080, lr = 0.0326871
I0605 02:02:54.129328   904 solver.cpp:229] Iteration 31120, loss = 3.20108
I0605 02:02:54.129370   904 solver.cpp:245]     Train net output #0: loss = 3.25317 (* 1 = 3.25317 loss)
I0605 02:02:54.129379   904 sgd_solver.cpp:106] Iteration 31120, lr = 0.0326776
I0605 02:03:15.110028   904 solver.cpp:229] Iteration 31160, loss = 3.20651
I0605 02:03:15.110329   904 solver.cpp:245]     Train net output #0: loss = 3.13979 (* 1 = 3.13979 loss)
I0605 02:03:15.110357   904 sgd_solver.cpp:106] Iteration 31160, lr = 0.0326682
I0605 02:03:36.096792   904 solver.cpp:229] Iteration 31200, loss = 3.20753
I0605 02:03:36.096848   904 solver.cpp:245]     Train net output #0: loss = 3.12639 (* 1 = 3.12639 loss)
I0605 02:03:36.096856   904 sgd_solver.cpp:106] Iteration 31200, lr = 0.0326588
I0605 02:03:57.079854   904 solver.cpp:229] Iteration 31240, loss = 3.21354
I0605 02:03:57.080055   904 solver.cpp:245]     Train net output #0: loss = 3.05747 (* 1 = 3.05747 loss)
I0605 02:03:57.080081   904 sgd_solver.cpp:106] Iteration 31240, lr = 0.0326494
I0605 02:04:18.078627   904 solver.cpp:229] Iteration 31280, loss = 3.22616
I0605 02:04:18.078682   904 solver.cpp:245]     Train net output #0: loss = 3.41282 (* 1 = 3.41282 loss)
I0605 02:04:18.078692   904 sgd_solver.cpp:106] Iteration 31280, lr = 0.03264
I0605 02:04:38.978766   904 solver.cpp:229] Iteration 31320, loss = 3.19262
I0605 02:04:38.978961   904 solver.cpp:245]     Train net output #0: loss = 3.15044 (* 1 = 3.15044 loss)
I0605 02:04:38.978988   904 sgd_solver.cpp:106] Iteration 31320, lr = 0.0326306
I0605 02:04:59.734062   904 solver.cpp:229] Iteration 31360, loss = 3.19298
I0605 02:04:59.734109   904 solver.cpp:245]     Train net output #0: loss = 3.418 (* 1 = 3.418 loss)
I0605 02:04:59.734120   904 sgd_solver.cpp:106] Iteration 31360, lr = 0.0326212
I0605 02:05:20.403426   904 solver.cpp:229] Iteration 31400, loss = 3.18118
I0605 02:05:20.403627   904 solver.cpp:245]     Train net output #0: loss = 3.28807 (* 1 = 3.28807 loss)
I0605 02:05:20.403656   904 sgd_solver.cpp:106] Iteration 31400, lr = 0.0326118
I0605 02:05:41.092308   904 solver.cpp:229] Iteration 31440, loss = 3.22948
I0605 02:05:41.092378   904 solver.cpp:245]     Train net output #0: loss = 3.17884 (* 1 = 3.17884 loss)
I0605 02:05:41.092394   904 sgd_solver.cpp:106] Iteration 31440, lr = 0.0326024
I0605 02:05:56.346127   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 02:06:01.768028   904 solver.cpp:229] Iteration 31480, loss = 3.21893
I0605 02:06:01.768085   904 solver.cpp:245]     Train net output #0: loss = 3.34984 (* 1 = 3.34984 loss)
I0605 02:06:01.768095   904 sgd_solver.cpp:106] Iteration 31480, lr = 0.0325929
I0605 02:06:22.437557   904 solver.cpp:229] Iteration 31520, loss = 3.21031
I0605 02:06:22.437615   904 solver.cpp:245]     Train net output #0: loss = 3.00792 (* 1 = 3.00792 loss)
I0605 02:06:22.437628   904 sgd_solver.cpp:106] Iteration 31520, lr = 0.0325835
I0605 02:06:43.111909   904 solver.cpp:229] Iteration 31560, loss = 3.20896
I0605 02:06:43.112114   904 solver.cpp:245]     Train net output #0: loss = 3.32756 (* 1 = 3.32756 loss)
I0605 02:06:43.112140   904 sgd_solver.cpp:106] Iteration 31560, lr = 0.0325741
I0605 02:07:03.661995   904 solver.cpp:229] Iteration 31600, loss = 3.20854
I0605 02:07:03.662036   904 solver.cpp:245]     Train net output #0: loss = 3.42945 (* 1 = 3.42945 loss)
I0605 02:07:03.662045   904 sgd_solver.cpp:106] Iteration 31600, lr = 0.0325647
I0605 02:07:24.173135   904 solver.cpp:229] Iteration 31640, loss = 3.17445
I0605 02:07:24.173281   904 solver.cpp:245]     Train net output #0: loss = 3.06173 (* 1 = 3.06173 loss)
I0605 02:07:24.173290   904 sgd_solver.cpp:106] Iteration 31640, lr = 0.0325553
I0605 02:07:44.729738   904 solver.cpp:229] Iteration 31680, loss = 3.21666
I0605 02:07:44.729799   904 solver.cpp:245]     Train net output #0: loss = 3.10191 (* 1 = 3.10191 loss)
I0605 02:07:44.729805   904 sgd_solver.cpp:106] Iteration 31680, lr = 0.0325459
I0605 02:08:05.378789   904 solver.cpp:229] Iteration 31720, loss = 3.19556
I0605 02:08:05.378974   904 solver.cpp:245]     Train net output #0: loss = 3.19483 (* 1 = 3.19483 loss)
I0605 02:08:05.379001   904 sgd_solver.cpp:106] Iteration 31720, lr = 0.0325365
I0605 02:08:25.913372   904 solver.cpp:229] Iteration 31760, loss = 3.15772
I0605 02:08:25.913424   904 solver.cpp:245]     Train net output #0: loss = 3.11675 (* 1 = 3.11675 loss)
I0605 02:08:25.913434   904 sgd_solver.cpp:106] Iteration 31760, lr = 0.0325271
I0605 02:08:46.412017   904 solver.cpp:229] Iteration 31800, loss = 3.21967
I0605 02:08:46.412227   904 solver.cpp:245]     Train net output #0: loss = 3.11341 (* 1 = 3.11341 loss)
I0605 02:08:46.412246   904 sgd_solver.cpp:106] Iteration 31800, lr = 0.0325176
I0605 02:09:06.921651   904 solver.cpp:229] Iteration 31840, loss = 3.19823
I0605 02:09:06.921701   904 solver.cpp:245]     Train net output #0: loss = 3.25289 (* 1 = 3.25289 loss)
I0605 02:09:06.921710   904 sgd_solver.cpp:106] Iteration 31840, lr = 0.0325082
I0605 02:09:27.410303   904 solver.cpp:229] Iteration 31880, loss = 3.15941
I0605 02:09:27.410436   904 solver.cpp:245]     Train net output #0: loss = 2.84154 (* 1 = 2.84154 loss)
I0605 02:09:27.410446   904 sgd_solver.cpp:106] Iteration 31880, lr = 0.0324988
I0605 02:09:47.896915   904 solver.cpp:229] Iteration 31920, loss = 3.1817
I0605 02:09:47.896951   904 solver.cpp:245]     Train net output #0: loss = 3.40354 (* 1 = 3.40354 loss)
I0605 02:09:47.896960   904 sgd_solver.cpp:106] Iteration 31920, lr = 0.0324894
I0605 02:10:08.438803   904 solver.cpp:229] Iteration 31960, loss = 3.13919
I0605 02:10:08.438992   904 solver.cpp:245]     Train net output #0: loss = 3.21418 (* 1 = 3.21418 loss)
I0605 02:10:08.439002   904 sgd_solver.cpp:106] Iteration 31960, lr = 0.03248
I0605 02:10:16.390174   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 02:10:28.433023   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_32000.caffemodel
I0605 02:10:28.703651   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_32000.solverstate
I0605 02:10:28.785131   904 solver.cpp:338] Iteration 32000, Testing net (#0)
I0605 02:10:28.785223   904 net.cpp:748] Ignoring source layer loss
I0605 02:11:00.745817   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 02:11:34.021661   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 02:11:35.250542   904 solver.cpp:406]     Test net output #0: accuracy = 0.344781
I0605 02:11:35.250591   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.593599
I0605 02:11:35.564690   904 solver.cpp:229] Iteration 32000, loss = 3.20561
I0605 02:11:35.564752   904 solver.cpp:245]     Train net output #0: loss = 3.01986 (* 1 = 3.01986 loss)
I0605 02:11:35.564765   904 sgd_solver.cpp:106] Iteration 32000, lr = 0.0324706
I0605 02:11:54.689285   904 solver.cpp:229] Iteration 32040, loss = 3.13841
I0605 02:11:54.689327   904 solver.cpp:245]     Train net output #0: loss = 3.27561 (* 1 = 3.27561 loss)
I0605 02:11:54.689335   904 sgd_solver.cpp:106] Iteration 32040, lr = 0.0324612
I0605 02:12:15.380069   904 solver.cpp:229] Iteration 32080, loss = 3.16289
I0605 02:12:15.380167   904 solver.cpp:245]     Train net output #0: loss = 3.45264 (* 1 = 3.45264 loss)
I0605 02:12:15.380177   904 sgd_solver.cpp:106] Iteration 32080, lr = 0.0324518
I0605 02:12:36.266618   904 solver.cpp:229] Iteration 32120, loss = 3.19521
I0605 02:12:36.266670   904 solver.cpp:245]     Train net output #0: loss = 2.99586 (* 1 = 2.99586 loss)
I0605 02:12:36.266681   904 sgd_solver.cpp:106] Iteration 32120, lr = 0.0324424
I0605 02:12:56.887228   904 solver.cpp:229] Iteration 32160, loss = 3.16014
I0605 02:12:56.887428   904 solver.cpp:245]     Train net output #0: loss = 3.2069 (* 1 = 3.2069 loss)
I0605 02:12:56.887450   904 sgd_solver.cpp:106] Iteration 32160, lr = 0.0324329
I0605 02:13:17.505177   904 solver.cpp:229] Iteration 32200, loss = 3.19838
I0605 02:13:17.505225   904 solver.cpp:245]     Train net output #0: loss = 3.21512 (* 1 = 3.21512 loss)
I0605 02:13:17.505234   904 sgd_solver.cpp:106] Iteration 32200, lr = 0.0324235
I0605 02:13:38.088626   904 solver.cpp:229] Iteration 32240, loss = 3.14212
I0605 02:13:38.088877   904 solver.cpp:245]     Train net output #0: loss = 3.07244 (* 1 = 3.07244 loss)
I0605 02:13:38.088897   904 sgd_solver.cpp:106] Iteration 32240, lr = 0.0324141
I0605 02:13:58.720157   904 solver.cpp:229] Iteration 32280, loss = 3.18952
I0605 02:13:58.720208   904 solver.cpp:245]     Train net output #0: loss = 3.31079 (* 1 = 3.31079 loss)
I0605 02:13:58.720216   904 sgd_solver.cpp:106] Iteration 32280, lr = 0.0324047
I0605 02:14:19.371212   904 solver.cpp:229] Iteration 32320, loss = 3.16979
I0605 02:14:19.371373   904 solver.cpp:245]     Train net output #0: loss = 3.01871 (* 1 = 3.01871 loss)
I0605 02:14:19.371395   904 sgd_solver.cpp:106] Iteration 32320, lr = 0.0323953
I0605 02:14:40.006404   904 solver.cpp:229] Iteration 32360, loss = 3.1488
I0605 02:14:40.006446   904 solver.cpp:245]     Train net output #0: loss = 3.09407 (* 1 = 3.09407 loss)
I0605 02:14:40.006455   904 sgd_solver.cpp:106] Iteration 32360, lr = 0.0323859
I0605 02:15:00.633374   904 solver.cpp:229] Iteration 32400, loss = 3.16089
I0605 02:15:00.633566   904 solver.cpp:245]     Train net output #0: loss = 3.22716 (* 1 = 3.22716 loss)
I0605 02:15:00.633591   904 sgd_solver.cpp:106] Iteration 32400, lr = 0.0323765
I0605 02:15:21.139734   904 solver.cpp:229] Iteration 32440, loss = 3.16829
I0605 02:15:21.139782   904 solver.cpp:245]     Train net output #0: loss = 3.04321 (* 1 = 3.04321 loss)
I0605 02:15:21.139791   904 sgd_solver.cpp:106] Iteration 32440, lr = 0.0323671
I0605 02:15:41.587497   904 solver.cpp:229] Iteration 32480, loss = 3.2131
I0605 02:15:41.587699   904 solver.cpp:245]     Train net output #0: loss = 3.19058 (* 1 = 3.19058 loss)
I0605 02:15:41.587726   904 sgd_solver.cpp:106] Iteration 32480, lr = 0.0323576
I0605 02:16:02.138109   904 solver.cpp:229] Iteration 32520, loss = 3.18008
I0605 02:16:02.138171   904 solver.cpp:245]     Train net output #0: loss = 3.25924 (* 1 = 3.25924 loss)
I0605 02:16:02.138185   904 sgd_solver.cpp:106] Iteration 32520, lr = 0.0323482
I0605 02:16:18.831534   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 02:16:22.668864   904 solver.cpp:229] Iteration 32560, loss = 3.20689
I0605 02:16:22.668905   904 solver.cpp:245]     Train net output #0: loss = 3.04931 (* 1 = 3.04931 loss)
I0605 02:16:22.668915   904 sgd_solver.cpp:106] Iteration 32560, lr = 0.0323388
I0605 02:16:43.123339   904 solver.cpp:229] Iteration 32600, loss = 3.16623
I0605 02:16:43.123390   904 solver.cpp:245]     Train net output #0: loss = 3.30348 (* 1 = 3.30348 loss)
I0605 02:16:43.123399   904 sgd_solver.cpp:106] Iteration 32600, lr = 0.0323294
I0605 02:17:03.576539   904 solver.cpp:229] Iteration 32640, loss = 3.21703
I0605 02:17:03.576704   904 solver.cpp:245]     Train net output #0: loss = 2.83367 (* 1 = 2.83367 loss)
I0605 02:17:03.576731   904 sgd_solver.cpp:106] Iteration 32640, lr = 0.03232
I0605 02:17:23.927191   904 solver.cpp:229] Iteration 32680, loss = 3.17764
I0605 02:17:23.927242   904 solver.cpp:245]     Train net output #0: loss = 3.43359 (* 1 = 3.43359 loss)
I0605 02:17:23.927250   904 sgd_solver.cpp:106] Iteration 32680, lr = 0.0323106
I0605 02:17:44.287505   904 solver.cpp:229] Iteration 32720, loss = 3.19458
I0605 02:17:44.287714   904 solver.cpp:245]     Train net output #0: loss = 3.51507 (* 1 = 3.51507 loss)
I0605 02:17:44.287736   904 sgd_solver.cpp:106] Iteration 32720, lr = 0.0323012
I0605 02:18:04.718520   904 solver.cpp:229] Iteration 32760, loss = 3.17774
I0605 02:18:04.718559   904 solver.cpp:245]     Train net output #0: loss = 3.13361 (* 1 = 3.13361 loss)
I0605 02:18:04.718567   904 sgd_solver.cpp:106] Iteration 32760, lr = 0.0322918
I0605 02:18:25.178470   904 solver.cpp:229] Iteration 32800, loss = 3.21733
I0605 02:18:25.178630   904 solver.cpp:245]     Train net output #0: loss = 3.3322 (* 1 = 3.3322 loss)
I0605 02:18:25.178663   904 sgd_solver.cpp:106] Iteration 32800, lr = 0.0322824
I0605 02:18:45.580502   904 solver.cpp:229] Iteration 32840, loss = 3.1937
I0605 02:18:45.580543   904 solver.cpp:245]     Train net output #0: loss = 3.16666 (* 1 = 3.16666 loss)
I0605 02:18:45.580551   904 sgd_solver.cpp:106] Iteration 32840, lr = 0.0322729
I0605 02:19:05.815023   904 solver.cpp:229] Iteration 32880, loss = 3.21447
I0605 02:19:05.815233   904 solver.cpp:245]     Train net output #0: loss = 3.15692 (* 1 = 3.15692 loss)
I0605 02:19:05.815243   904 sgd_solver.cpp:106] Iteration 32880, lr = 0.0322635
I0605 02:19:26.062209   904 solver.cpp:229] Iteration 32920, loss = 3.17976
I0605 02:19:26.062273   904 solver.cpp:245]     Train net output #0: loss = 3.26549 (* 1 = 3.26549 loss)
I0605 02:19:26.062280   904 sgd_solver.cpp:106] Iteration 32920, lr = 0.0322541
I0605 02:19:46.288468   904 solver.cpp:229] Iteration 32960, loss = 3.19999
I0605 02:19:46.288672   904 solver.cpp:245]     Train net output #0: loss = 3.11403 (* 1 = 3.11403 loss)
I0605 02:19:46.288717   904 sgd_solver.cpp:106] Iteration 32960, lr = 0.0322447
I0605 02:20:06.030040   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_33000.caffemodel
I0605 02:20:06.293356   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_33000.solverstate
I0605 02:20:06.370440   904 solver.cpp:338] Iteration 33000, Testing net (#0)
I0605 02:20:06.370517   904 net.cpp:748] Ignoring source layer loss
I0605 02:20:13.095614   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 02:20:48.856837   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 02:21:16.319360   904 solver.cpp:406]     Test net output #0: accuracy = 0.34396
I0605 02:21:16.319396   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.592179
I0605 02:21:16.635754   904 solver.cpp:229] Iteration 33000, loss = 3.20423
I0605 02:21:16.635804   904 solver.cpp:245]     Train net output #0: loss = 3.34317 (* 1 = 3.34317 loss)
I0605 02:21:16.635817   904 sgd_solver.cpp:106] Iteration 33000, lr = 0.0322353
I0605 02:21:35.816886   904 solver.cpp:229] Iteration 33040, loss = 3.19613
I0605 02:21:35.817065   904 solver.cpp:245]     Train net output #0: loss = 3.07397 (* 1 = 3.07397 loss)
I0605 02:21:35.817086   904 sgd_solver.cpp:106] Iteration 33040, lr = 0.0322259
I0605 02:21:57.097765   904 solver.cpp:229] Iteration 33080, loss = 3.11483
I0605 02:21:57.097820   904 solver.cpp:245]     Train net output #0: loss = 3.23348 (* 1 = 3.23348 loss)
I0605 02:21:57.097831   904 sgd_solver.cpp:106] Iteration 33080, lr = 0.0322165
I0605 02:22:10.555027   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 02:22:18.583849   904 solver.cpp:229] Iteration 33120, loss = 3.18908
I0605 02:22:18.583910   904 solver.cpp:245]     Train net output #0: loss = 3.31177 (* 1 = 3.31177 loss)
I0605 02:22:18.583921   904 sgd_solver.cpp:106] Iteration 33120, lr = 0.0322071
I0605 02:22:39.599278   904 solver.cpp:229] Iteration 33160, loss = 3.16941
I0605 02:22:39.599339   904 solver.cpp:245]     Train net output #0: loss = 3.00516 (* 1 = 3.00516 loss)
I0605 02:22:39.599347   904 sgd_solver.cpp:106] Iteration 33160, lr = 0.0321976
I0605 02:23:00.586809   904 solver.cpp:229] Iteration 33200, loss = 3.20018
I0605 02:23:00.587009   904 solver.cpp:245]     Train net output #0: loss = 3.17559 (* 1 = 3.17559 loss)
I0605 02:23:00.587038   904 sgd_solver.cpp:106] Iteration 33200, lr = 0.0321882
I0605 02:23:21.557181   904 solver.cpp:229] Iteration 33240, loss = 3.16691
I0605 02:23:21.557232   904 solver.cpp:245]     Train net output #0: loss = 3.48076 (* 1 = 3.48076 loss)
I0605 02:23:21.557241   904 sgd_solver.cpp:106] Iteration 33240, lr = 0.0321788
I0605 02:23:42.407006   904 solver.cpp:229] Iteration 33280, loss = 3.22318
I0605 02:23:42.407224   904 solver.cpp:245]     Train net output #0: loss = 2.94548 (* 1 = 2.94548 loss)
I0605 02:23:42.407250   904 sgd_solver.cpp:106] Iteration 33280, lr = 0.0321694
I0605 02:24:03.224885   904 solver.cpp:229] Iteration 33320, loss = 3.21264
I0605 02:24:03.224931   904 solver.cpp:245]     Train net output #0: loss = 3.26465 (* 1 = 3.26465 loss)
I0605 02:24:03.224939   904 sgd_solver.cpp:106] Iteration 33320, lr = 0.03216
I0605 02:24:24.029636   904 solver.cpp:229] Iteration 33360, loss = 3.13607
I0605 02:24:24.029840   904 solver.cpp:245]     Train net output #0: loss = 3.33262 (* 1 = 3.33262 loss)
I0605 02:24:24.029861   904 sgd_solver.cpp:106] Iteration 33360, lr = 0.0321506
I0605 02:24:44.714337   904 solver.cpp:229] Iteration 33400, loss = 3.14927
I0605 02:24:44.714385   904 solver.cpp:245]     Train net output #0: loss = 3.25803 (* 1 = 3.25803 loss)
I0605 02:24:44.714395   904 sgd_solver.cpp:106] Iteration 33400, lr = 0.0321412
I0605 02:25:05.414923   904 solver.cpp:229] Iteration 33440, loss = 3.1532
I0605 02:25:05.415114   904 solver.cpp:245]     Train net output #0: loss = 3.19252 (* 1 = 3.19252 loss)
I0605 02:25:05.415138   904 sgd_solver.cpp:106] Iteration 33440, lr = 0.0321318
I0605 02:25:25.909517   904 solver.cpp:229] Iteration 33480, loss = 3.12772
I0605 02:25:25.909556   904 solver.cpp:245]     Train net output #0: loss = 3.04531 (* 1 = 3.04531 loss)
I0605 02:25:25.909577   904 sgd_solver.cpp:106] Iteration 33480, lr = 0.0321224
I0605 02:25:46.445463   904 solver.cpp:229] Iteration 33520, loss = 3.12091
I0605 02:25:46.445611   904 solver.cpp:245]     Train net output #0: loss = 2.89473 (* 1 = 2.89473 loss)
I0605 02:25:46.445621   904 sgd_solver.cpp:106] Iteration 33520, lr = 0.0321129
I0605 02:26:07.117151   904 solver.cpp:229] Iteration 33560, loss = 3.11388
I0605 02:26:07.117199   904 solver.cpp:245]     Train net output #0: loss = 3.33214 (* 1 = 3.33214 loss)
I0605 02:26:07.117208   904 sgd_solver.cpp:106] Iteration 33560, lr = 0.0321035
I0605 02:26:27.674221   904 solver.cpp:229] Iteration 33600, loss = 3.14633
I0605 02:26:27.674417   904 solver.cpp:245]     Train net output #0: loss = 3.14289 (* 1 = 3.14289 loss)
I0605 02:26:27.674443   904 sgd_solver.cpp:106] Iteration 33600, lr = 0.0320941
I0605 02:26:48.172719   904 solver.cpp:229] Iteration 33640, loss = 3.17394
I0605 02:26:48.172787   904 solver.cpp:245]     Train net output #0: loss = 3.34027 (* 1 = 3.34027 loss)
I0605 02:26:48.172801   904 sgd_solver.cpp:106] Iteration 33640, lr = 0.0320847
I0605 02:27:08.713538   904 solver.cpp:229] Iteration 33680, loss = 3.17282
I0605 02:27:08.713721   904 solver.cpp:245]     Train net output #0: loss = 3.2784 (* 1 = 3.2784 loss)
I0605 02:27:08.713744   904 sgd_solver.cpp:106] Iteration 33680, lr = 0.0320753
I0605 02:27:23.560427   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 02:27:29.204879   904 solver.cpp:229] Iteration 33720, loss = 3.1435
I0605 02:27:29.204932   904 solver.cpp:245]     Train net output #0: loss = 2.9703 (* 1 = 2.9703 loss)
I0605 02:27:29.204942   904 sgd_solver.cpp:106] Iteration 33720, lr = 0.0320659
I0605 02:27:49.610054   904 solver.cpp:229] Iteration 33760, loss = 3.1772
I0605 02:27:49.610245   904 solver.cpp:245]     Train net output #0: loss = 3.15549 (* 1 = 3.15549 loss)
I0605 02:27:49.610267   904 sgd_solver.cpp:106] Iteration 33760, lr = 0.0320565
I0605 02:28:09.904034   904 solver.cpp:229] Iteration 33800, loss = 3.13733
I0605 02:28:09.904089   904 solver.cpp:245]     Train net output #0: loss = 3.31697 (* 1 = 3.31697 loss)
I0605 02:28:09.904100   904 sgd_solver.cpp:106] Iteration 33800, lr = 0.0320471
I0605 02:28:30.167945   904 solver.cpp:229] Iteration 33840, loss = 3.12181
I0605 02:28:30.168098   904 solver.cpp:245]     Train net output #0: loss = 3.33735 (* 1 = 3.33735 loss)
I0605 02:28:30.168108   904 sgd_solver.cpp:106] Iteration 33840, lr = 0.0320376
I0605 02:28:50.469132   904 solver.cpp:229] Iteration 33880, loss = 3.14557
I0605 02:28:50.469183   904 solver.cpp:245]     Train net output #0: loss = 3.16528 (* 1 = 3.16528 loss)
I0605 02:28:50.469192   904 sgd_solver.cpp:106] Iteration 33880, lr = 0.0320282
I0605 02:29:10.750346   904 solver.cpp:229] Iteration 33920, loss = 3.11432
I0605 02:29:10.750490   904 solver.cpp:245]     Train net output #0: loss = 3.17977 (* 1 = 3.17977 loss)
I0605 02:29:10.750499   904 sgd_solver.cpp:106] Iteration 33920, lr = 0.0320188
I0605 02:29:31.072948   904 solver.cpp:229] Iteration 33960, loss = 3.1794
I0605 02:29:31.072999   904 solver.cpp:245]     Train net output #0: loss = 3.21249 (* 1 = 3.21249 loss)
I0605 02:29:31.073007   904 sgd_solver.cpp:106] Iteration 33960, lr = 0.0320094
I0605 02:29:50.856832   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_34000.caffemodel
I0605 02:29:51.122176   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_34000.solverstate
I0605 02:29:51.196671   904 solver.cpp:338] Iteration 34000, Testing net (#0)
I0605 02:29:51.196754   904 net.cpp:748] Ignoring source layer loss
I0605 02:30:11.304193   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 02:30:43.826941   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 02:30:59.465332   904 solver.cpp:406]     Test net output #0: accuracy = 0.349601
I0605 02:30:59.465374   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.600419
I0605 02:30:59.780390   904 solver.cpp:229] Iteration 34000, loss = 3.16393
I0605 02:30:59.780434   904 solver.cpp:245]     Train net output #0: loss = 3.20422 (* 1 = 3.20422 loss)
I0605 02:30:59.780449   904 sgd_solver.cpp:106] Iteration 34000, lr = 0.032
I0605 02:31:19.005090   904 solver.cpp:229] Iteration 34040, loss = 3.15567
I0605 02:31:19.005292   904 solver.cpp:245]     Train net output #0: loss = 3.21498 (* 1 = 3.21498 loss)
I0605 02:31:19.005322   904 sgd_solver.cpp:106] Iteration 34040, lr = 0.0319906
I0605 02:31:40.468533   904 solver.cpp:229] Iteration 34080, loss = 3.16241
I0605 02:31:40.468581   904 solver.cpp:245]     Train net output #0: loss = 3.24823 (* 1 = 3.24823 loss)
I0605 02:31:40.468590   904 sgd_solver.cpp:106] Iteration 34080, lr = 0.0319812
I0605 02:32:01.765810   904 solver.cpp:229] Iteration 34120, loss = 3.18054
I0605 02:32:01.766015   904 solver.cpp:245]     Train net output #0: loss = 3.44764 (* 1 = 3.44764 loss)
I0605 02:32:01.766037   904 sgd_solver.cpp:106] Iteration 34120, lr = 0.0319718
I0605 02:32:22.625347   904 solver.cpp:229] Iteration 34160, loss = 3.14199
I0605 02:32:22.625394   904 solver.cpp:245]     Train net output #0: loss = 3.09826 (* 1 = 3.09826 loss)
I0605 02:32:22.625401   904 sgd_solver.cpp:106] Iteration 34160, lr = 0.0319624
I0605 02:32:43.450825   904 solver.cpp:229] Iteration 34200, loss = 3.18389
I0605 02:32:43.451041   904 solver.cpp:245]     Train net output #0: loss = 3.0975 (* 1 = 3.0975 loss)
I0605 02:32:43.451081   904 sgd_solver.cpp:106] Iteration 34200, lr = 0.0319529
I0605 02:33:04.308329   904 solver.cpp:229] Iteration 34240, loss = 3.11707
I0605 02:33:04.308383   904 solver.cpp:245]     Train net output #0: loss = 3.22364 (* 1 = 3.22364 loss)
I0605 02:33:04.308393   904 sgd_solver.cpp:106] Iteration 34240, lr = 0.0319435
I0605 02:33:25.123327   904 solver.cpp:229] Iteration 34280, loss = 3.14205
I0605 02:33:25.123548   904 solver.cpp:245]     Train net output #0: loss = 3.01331 (* 1 = 3.01331 loss)
I0605 02:33:25.123569   904 sgd_solver.cpp:106] Iteration 34280, lr = 0.0319341
I0605 02:33:32.665488   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 02:33:45.933156   904 solver.cpp:229] Iteration 34320, loss = 3.16978
I0605 02:33:45.933239   904 solver.cpp:245]     Train net output #0: loss = 3.0995 (* 1 = 3.0995 loss)
I0605 02:33:45.933248   904 sgd_solver.cpp:106] Iteration 34320, lr = 0.0319247
I0605 02:34:06.750560   904 solver.cpp:229] Iteration 34360, loss = 3.14127
I0605 02:34:06.750763   904 solver.cpp:245]     Train net output #0: loss = 3.24153 (* 1 = 3.24153 loss)
I0605 02:34:06.750784   904 sgd_solver.cpp:106] Iteration 34360, lr = 0.0319153
I0605 02:34:27.445489   904 solver.cpp:229] Iteration 34400, loss = 3.16674
I0605 02:34:27.445540   904 solver.cpp:245]     Train net output #0: loss = 3.26918 (* 1 = 3.26918 loss)
I0605 02:34:27.445559   904 sgd_solver.cpp:106] Iteration 34400, lr = 0.0319059
I0605 02:34:48.145160   904 solver.cpp:229] Iteration 34440, loss = 3.13808
I0605 02:34:48.145342   904 solver.cpp:245]     Train net output #0: loss = 3.30014 (* 1 = 3.30014 loss)
I0605 02:34:48.145364   904 sgd_solver.cpp:106] Iteration 34440, lr = 0.0318965
I0605 02:35:08.848915   904 solver.cpp:229] Iteration 34480, loss = 3.17289
I0605 02:35:08.848953   904 solver.cpp:245]     Train net output #0: loss = 3.4052 (* 1 = 3.4052 loss)
I0605 02:35:08.848958   904 sgd_solver.cpp:106] Iteration 34480, lr = 0.0318871
I0605 02:35:29.549808   904 solver.cpp:229] Iteration 34520, loss = 3.16455
I0605 02:35:29.550060   904 solver.cpp:245]     Train net output #0: loss = 3.27257 (* 1 = 3.27257 loss)
I0605 02:35:29.550086   904 sgd_solver.cpp:106] Iteration 34520, lr = 0.0318776
I0605 02:35:50.221492   904 solver.cpp:229] Iteration 34560, loss = 3.14862
I0605 02:35:50.221540   904 solver.cpp:245]     Train net output #0: loss = 3.10447 (* 1 = 3.10447 loss)
I0605 02:35:50.221549   904 sgd_solver.cpp:106] Iteration 34560, lr = 0.0318682
I0605 02:36:10.808306   904 solver.cpp:229] Iteration 34600, loss = 3.12575
I0605 02:36:10.808495   904 solver.cpp:245]     Train net output #0: loss = 3.1847 (* 1 = 3.1847 loss)
I0605 02:36:10.808516   904 sgd_solver.cpp:106] Iteration 34600, lr = 0.0318588
I0605 02:36:31.387938   904 solver.cpp:229] Iteration 34640, loss = 3.1195
I0605 02:36:31.387989   904 solver.cpp:245]     Train net output #0: loss = 2.98719 (* 1 = 2.98719 loss)
I0605 02:36:31.387997   904 sgd_solver.cpp:106] Iteration 34640, lr = 0.0318494
I0605 02:36:52.078284   904 solver.cpp:229] Iteration 34680, loss = 3.12872
I0605 02:36:52.078476   904 solver.cpp:245]     Train net output #0: loss = 3.22172 (* 1 = 3.22172 loss)
I0605 02:36:52.078500   904 sgd_solver.cpp:106] Iteration 34680, lr = 0.03184
I0605 02:37:12.756258   904 solver.cpp:229] Iteration 34720, loss = 3.1237
I0605 02:37:12.756326   904 solver.cpp:245]     Train net output #0: loss = 3.19602 (* 1 = 3.19602 loss)
I0605 02:37:12.756340   904 sgd_solver.cpp:106] Iteration 34720, lr = 0.0318306
I0605 02:37:33.333529   904 solver.cpp:229] Iteration 34760, loss = 3.11671
I0605 02:37:33.333673   904 solver.cpp:245]     Train net output #0: loss = 2.98037 (* 1 = 2.98037 loss)
I0605 02:37:33.333681   904 sgd_solver.cpp:106] Iteration 34760, lr = 0.0318212
I0605 02:37:53.855937   904 solver.cpp:229] Iteration 34800, loss = 3.17239
I0605 02:37:53.855975   904 solver.cpp:245]     Train net output #0: loss = 3.16359 (* 1 = 3.16359 loss)
I0605 02:37:53.855983   904 sgd_solver.cpp:106] Iteration 34800, lr = 0.0318118
I0605 02:38:14.359849   904 solver.cpp:229] Iteration 34840, loss = 3.11411
I0605 02:38:14.359983   904 solver.cpp:245]     Train net output #0: loss = 3.06569 (* 1 = 3.06569 loss)
I0605 02:38:14.359992   904 sgd_solver.cpp:106] Iteration 34840, lr = 0.0318024
I0605 02:38:30.537351   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 02:38:34.908685   904 solver.cpp:229] Iteration 34880, loss = 3.12986
I0605 02:38:34.908736   904 solver.cpp:245]     Train net output #0: loss = 2.7822 (* 1 = 2.7822 loss)
I0605 02:38:34.908746   904 sgd_solver.cpp:106] Iteration 34880, lr = 0.0317929
I0605 02:38:55.433068   904 solver.cpp:229] Iteration 34920, loss = 3.15666
I0605 02:38:55.433208   904 solver.cpp:245]     Train net output #0: loss = 3.28207 (* 1 = 3.28207 loss)
I0605 02:38:55.433234   904 sgd_solver.cpp:106] Iteration 34920, lr = 0.0317835
I0605 02:39:15.935578   904 solver.cpp:229] Iteration 34960, loss = 3.14247
I0605 02:39:15.935621   904 solver.cpp:245]     Train net output #0: loss = 3.30879 (* 1 = 3.30879 loss)
I0605 02:39:15.935629   904 sgd_solver.cpp:106] Iteration 34960, lr = 0.0317741
I0605 02:39:35.922622   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_35000.caffemodel
I0605 02:39:36.189167   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_35000.solverstate
I0605 02:39:36.258325   904 solver.cpp:338] Iteration 35000, Testing net (#0)
I0605 02:39:36.258402   904 net.cpp:748] Ignoring source layer loss
I0605 02:40:00.497674   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 02:40:34.250298   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 02:40:42.474827   904 solver.cpp:406]     Test net output #0: accuracy = 0.354141
I0605 02:40:42.474869   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.602539
I0605 02:40:42.790771   904 solver.cpp:229] Iteration 35000, loss = 3.1605
I0605 02:40:42.790817   904 solver.cpp:245]     Train net output #0: loss = 3.21829 (* 1 = 3.21829 loss)
I0605 02:40:42.790830   904 sgd_solver.cpp:106] Iteration 35000, lr = 0.0317647
I0605 02:41:02.030627   904 solver.cpp:229] Iteration 35040, loss = 3.14861
I0605 02:41:02.030671   904 solver.cpp:245]     Train net output #0: loss = 3.10758 (* 1 = 3.10758 loss)
I0605 02:41:02.030680   904 sgd_solver.cpp:106] Iteration 35040, lr = 0.0317553
I0605 02:41:23.442296   904 solver.cpp:229] Iteration 35080, loss = 3.13779
I0605 02:41:23.442531   904 solver.cpp:245]     Train net output #0: loss = 3.00066 (* 1 = 3.00066 loss)
I0605 02:41:23.442561   904 sgd_solver.cpp:106] Iteration 35080, lr = 0.0317459
I0605 02:41:44.972920   904 solver.cpp:229] Iteration 35120, loss = 3.14313
I0605 02:41:44.972960   904 solver.cpp:245]     Train net output #0: loss = 2.9286 (* 1 = 2.9286 loss)
I0605 02:41:44.972970   904 sgd_solver.cpp:106] Iteration 35120, lr = 0.0317365
I0605 02:42:06.380053   904 solver.cpp:229] Iteration 35160, loss = 3.13877
I0605 02:42:06.380239   904 solver.cpp:245]     Train net output #0: loss = 3.445 (* 1 = 3.445 loss)
I0605 02:42:06.380264   904 sgd_solver.cpp:106] Iteration 35160, lr = 0.0317271
I0605 02:42:27.381098   904 solver.cpp:229] Iteration 35200, loss = 3.15439
I0605 02:42:27.381141   904 solver.cpp:245]     Train net output #0: loss = 3.03098 (* 1 = 3.03098 loss)
I0605 02:42:27.381151   904 sgd_solver.cpp:106] Iteration 35200, lr = 0.0317176
I0605 02:42:48.325824   904 solver.cpp:229] Iteration 35240, loss = 3.13524
I0605 02:42:48.326021   904 solver.cpp:245]     Train net output #0: loss = 3.05254 (* 1 = 3.05254 loss)
I0605 02:42:48.326046   904 sgd_solver.cpp:106] Iteration 35240, lr = 0.0317082
I0605 02:43:09.288367   904 solver.cpp:229] Iteration 35280, loss = 3.10138
I0605 02:43:09.288427   904 solver.cpp:245]     Train net output #0: loss = 3.19989 (* 1 = 3.19989 loss)
I0605 02:43:09.288437   904 sgd_solver.cpp:106] Iteration 35280, lr = 0.0316988
I0605 02:43:30.256597   904 solver.cpp:229] Iteration 35320, loss = 3.15016
I0605 02:43:30.256757   904 solver.cpp:245]     Train net output #0: loss = 2.92952 (* 1 = 2.92952 loss)
I0605 02:43:30.256784   904 sgd_solver.cpp:106] Iteration 35320, lr = 0.0316894
I0605 02:43:51.176486   904 solver.cpp:229] Iteration 35360, loss = 3.13263
I0605 02:43:51.176533   904 solver.cpp:245]     Train net output #0: loss = 3.02843 (* 1 = 3.02843 loss)
I0605 02:43:51.176545   904 sgd_solver.cpp:106] Iteration 35360, lr = 0.03168
I0605 02:44:01.316592   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 02:44:11.906610   904 solver.cpp:229] Iteration 35400, loss = 3.08164
I0605 02:44:11.906659   904 solver.cpp:245]     Train net output #0: loss = 2.98256 (* 1 = 2.98256 loss)
I0605 02:44:11.906669   904 sgd_solver.cpp:106] Iteration 35400, lr = 0.0316706
I0605 02:44:32.563977   904 solver.cpp:229] Iteration 35440, loss = 3.13002
I0605 02:44:32.564184   904 solver.cpp:245]     Train net output #0: loss = 3.1835 (* 1 = 3.1835 loss)
I0605 02:44:32.564213   904 sgd_solver.cpp:106] Iteration 35440, lr = 0.0316612
I0605 02:44:53.216624   904 solver.cpp:229] Iteration 35480, loss = 3.14775
I0605 02:44:53.216667   904 solver.cpp:245]     Train net output #0: loss = 3.43791 (* 1 = 3.43791 loss)
I0605 02:44:53.216678   904 sgd_solver.cpp:106] Iteration 35480, lr = 0.0316518
I0605 02:45:13.877826   904 solver.cpp:229] Iteration 35520, loss = 3.16432
I0605 02:45:13.877974   904 solver.cpp:245]     Train net output #0: loss = 3.25153 (* 1 = 3.25153 loss)
I0605 02:45:13.877986   904 sgd_solver.cpp:106] Iteration 35520, lr = 0.0316424
I0605 02:45:34.495630   904 solver.cpp:229] Iteration 35560, loss = 3.11779
I0605 02:45:34.495671   904 solver.cpp:245]     Train net output #0: loss = 2.91267 (* 1 = 2.91267 loss)
I0605 02:45:34.495679   904 sgd_solver.cpp:106] Iteration 35560, lr = 0.0316329
I0605 02:45:54.988589   904 solver.cpp:229] Iteration 35600, loss = 3.1446
I0605 02:45:54.988798   904 solver.cpp:245]     Train net output #0: loss = 3.1046 (* 1 = 3.1046 loss)
I0605 02:45:54.988812   904 sgd_solver.cpp:106] Iteration 35600, lr = 0.0316235
I0605 02:46:15.504778   904 solver.cpp:229] Iteration 35640, loss = 3.13698
I0605 02:46:15.504817   904 solver.cpp:245]     Train net output #0: loss = 3.04795 (* 1 = 3.04795 loss)
I0605 02:46:15.504823   904 sgd_solver.cpp:106] Iteration 35640, lr = 0.0316141
I0605 02:46:35.988127   904 solver.cpp:229] Iteration 35680, loss = 3.16825
I0605 02:46:35.988348   904 solver.cpp:245]     Train net output #0: loss = 2.9776 (* 1 = 2.9776 loss)
I0605 02:46:35.988401   904 sgd_solver.cpp:106] Iteration 35680, lr = 0.0316047
I0605 02:46:56.469229   904 solver.cpp:229] Iteration 35720, loss = 3.14895
I0605 02:46:56.469286   904 solver.cpp:245]     Train net output #0: loss = 3.00978 (* 1 = 3.00978 loss)
I0605 02:46:56.469297   904 sgd_solver.cpp:106] Iteration 35720, lr = 0.0315953
I0605 02:47:16.938982   904 solver.cpp:229] Iteration 35760, loss = 3.11695
I0605 02:47:16.939098   904 solver.cpp:245]     Train net output #0: loss = 3.13764 (* 1 = 3.13764 loss)
I0605 02:47:16.939110   904 sgd_solver.cpp:106] Iteration 35760, lr = 0.0315859
I0605 02:47:37.424299   904 solver.cpp:229] Iteration 35800, loss = 3.14634
I0605 02:47:37.424347   904 solver.cpp:245]     Train net output #0: loss = 3.15338 (* 1 = 3.15338 loss)
I0605 02:47:37.424357   904 sgd_solver.cpp:106] Iteration 35800, lr = 0.0315765
I0605 02:47:57.877074   904 solver.cpp:229] Iteration 35840, loss = 3.15704
I0605 02:47:57.877225   904 solver.cpp:245]     Train net output #0: loss = 2.8799 (* 1 = 2.8799 loss)
I0605 02:47:57.877238   904 sgd_solver.cpp:106] Iteration 35840, lr = 0.0315671
I0605 02:48:18.141072   904 solver.cpp:229] Iteration 35880, loss = 3.10351
I0605 02:48:18.141122   904 solver.cpp:245]     Train net output #0: loss = 2.91663 (* 1 = 2.91663 loss)
I0605 02:48:18.141129   904 sgd_solver.cpp:106] Iteration 35880, lr = 0.0315576
I0605 02:48:21.184183   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 02:48:38.418509   904 solver.cpp:229] Iteration 35920, loss = 3.15727
I0605 02:48:38.418673   904 solver.cpp:245]     Train net output #0: loss = 3.29708 (* 1 = 3.29708 loss)
I0605 02:48:38.418684   904 sgd_solver.cpp:106] Iteration 35920, lr = 0.0315482
I0605 02:48:58.673768   904 solver.cpp:229] Iteration 35960, loss = 3.08227
I0605 02:48:58.673822   904 solver.cpp:245]     Train net output #0: loss = 2.95969 (* 1 = 2.95969 loss)
I0605 02:48:58.673832   904 sgd_solver.cpp:106] Iteration 35960, lr = 0.0315388
I0605 02:49:18.453855   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_36000.caffemodel
I0605 02:49:18.722702   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_36000.solverstate
I0605 02:49:18.802945   904 solver.cpp:338] Iteration 36000, Testing net (#0)
I0605 02:49:18.803027   904 net.cpp:748] Ignoring source layer loss
I0605 02:49:45.275123   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 02:50:17.594810   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 02:50:24.664187   904 solver.cpp:406]     Test net output #0: accuracy = 0.358121
I0605 02:50:24.664230   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.609699
I0605 02:50:24.979856   904 solver.cpp:229] Iteration 36000, loss = 3.09917
I0605 02:50:24.979894   904 solver.cpp:245]     Train net output #0: loss = 3.35449 (* 1 = 3.35449 loss)
I0605 02:50:24.979904   904 sgd_solver.cpp:106] Iteration 36000, lr = 0.0315294
I0605 02:50:44.250373   904 solver.cpp:229] Iteration 36040, loss = 3.06517
I0605 02:50:44.250424   904 solver.cpp:245]     Train net output #0: loss = 2.88763 (* 1 = 2.88763 loss)
I0605 02:50:44.250432   904 sgd_solver.cpp:106] Iteration 36040, lr = 0.03152
I0605 02:51:05.685941   904 solver.cpp:229] Iteration 36080, loss = 3.11686
I0605 02:51:05.686111   904 solver.cpp:245]     Train net output #0: loss = 3.09808 (* 1 = 3.09808 loss)
I0605 02:51:05.686136   904 sgd_solver.cpp:106] Iteration 36080, lr = 0.0315106
I0605 02:51:27.167435   904 solver.cpp:229] Iteration 36120, loss = 3.11327
I0605 02:51:27.167490   904 solver.cpp:245]     Train net output #0: loss = 3.26118 (* 1 = 3.26118 loss)
I0605 02:51:27.167505   904 sgd_solver.cpp:106] Iteration 36120, lr = 0.0315012
I0605 02:51:48.203707   904 solver.cpp:229] Iteration 36160, loss = 3.10277
I0605 02:51:48.203894   904 solver.cpp:245]     Train net output #0: loss = 3.03246 (* 1 = 3.03246 loss)
I0605 02:51:48.203910   904 sgd_solver.cpp:106] Iteration 36160, lr = 0.0314918
I0605 02:52:09.221757   904 solver.cpp:229] Iteration 36200, loss = 3.12229
I0605 02:52:09.221817   904 solver.cpp:245]     Train net output #0: loss = 2.87776 (* 1 = 2.87776 loss)
I0605 02:52:09.221832   904 sgd_solver.cpp:106] Iteration 36200, lr = 0.0314824
I0605 02:52:30.266047   904 solver.cpp:229] Iteration 36240, loss = 3.12908
I0605 02:52:30.266250   904 solver.cpp:245]     Train net output #0: loss = 2.91131 (* 1 = 2.91131 loss)
I0605 02:52:30.266276   904 sgd_solver.cpp:106] Iteration 36240, lr = 0.0314729
I0605 02:52:51.242568   904 solver.cpp:229] Iteration 36280, loss = 3.08085
I0605 02:52:51.242611   904 solver.cpp:245]     Train net output #0: loss = 3.10481 (* 1 = 3.10481 loss)
I0605 02:52:51.242619   904 sgd_solver.cpp:106] Iteration 36280, lr = 0.0314635
I0605 02:53:11.990609   904 solver.cpp:229] Iteration 36320, loss = 3.08877
I0605 02:53:11.990787   904 solver.cpp:245]     Train net output #0: loss = 3.09914 (* 1 = 3.09914 loss)
I0605 02:53:11.990813   904 sgd_solver.cpp:106] Iteration 36320, lr = 0.0314541
I0605 02:53:32.693301   904 solver.cpp:229] Iteration 36360, loss = 3.1088
I0605 02:53:32.693341   904 solver.cpp:245]     Train net output #0: loss = 3.14385 (* 1 = 3.14385 loss)
I0605 02:53:32.693351   904 sgd_solver.cpp:106] Iteration 36360, lr = 0.0314447
I0605 02:53:49.796874   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 02:53:53.420974   904 solver.cpp:229] Iteration 36400, loss = 3.12246
I0605 02:53:53.421016   904 solver.cpp:245]     Train net output #0: loss = 2.88224 (* 1 = 2.88224 loss)
I0605 02:53:53.421025   904 sgd_solver.cpp:106] Iteration 36400, lr = 0.0314353
I0605 02:54:14.136514   904 solver.cpp:229] Iteration 36440, loss = 3.14855
I0605 02:54:14.136561   904 solver.cpp:245]     Train net output #0: loss = 3.09611 (* 1 = 3.09611 loss)
I0605 02:54:14.136572   904 sgd_solver.cpp:106] Iteration 36440, lr = 0.0314259
I0605 02:54:34.678081   904 solver.cpp:229] Iteration 36480, loss = 3.15068
I0605 02:54:34.678217   904 solver.cpp:245]     Train net output #0: loss = 3.16593 (* 1 = 3.16593 loss)
I0605 02:54:34.678231   904 sgd_solver.cpp:106] Iteration 36480, lr = 0.0314165
I0605 02:54:55.199002   904 solver.cpp:229] Iteration 36520, loss = 3.12351
I0605 02:54:55.199059   904 solver.cpp:245]     Train net output #0: loss = 3.07165 (* 1 = 3.07165 loss)
I0605 02:54:55.199069   904 sgd_solver.cpp:106] Iteration 36520, lr = 0.0314071
I0605 02:55:15.766216   904 solver.cpp:229] Iteration 36560, loss = 3.11697
I0605 02:55:15.766350   904 solver.cpp:245]     Train net output #0: loss = 3.16732 (* 1 = 3.16732 loss)
I0605 02:55:15.766360   904 sgd_solver.cpp:106] Iteration 36560, lr = 0.0313976
I0605 02:55:36.436648   904 solver.cpp:229] Iteration 36600, loss = 3.1207
I0605 02:55:36.436698   904 solver.cpp:245]     Train net output #0: loss = 3.10066 (* 1 = 3.10066 loss)
I0605 02:55:36.436707   904 sgd_solver.cpp:106] Iteration 36600, lr = 0.0313882
I0605 02:55:56.989351   904 solver.cpp:229] Iteration 36640, loss = 3.09543
I0605 02:55:56.989526   904 solver.cpp:245]     Train net output #0: loss = 2.9716 (* 1 = 2.9716 loss)
I0605 02:55:56.989553   904 sgd_solver.cpp:106] Iteration 36640, lr = 0.0313788
I0605 02:56:17.344863   904 solver.cpp:229] Iteration 36680, loss = 3.08513
I0605 02:56:17.344913   904 solver.cpp:245]     Train net output #0: loss = 3.11408 (* 1 = 3.11408 loss)
I0605 02:56:17.344923   904 sgd_solver.cpp:106] Iteration 36680, lr = 0.0313694
I0605 02:56:37.664304   904 solver.cpp:229] Iteration 36720, loss = 3.09477
I0605 02:56:37.664607   904 solver.cpp:245]     Train net output #0: loss = 3.18847 (* 1 = 3.18847 loss)
I0605 02:56:37.664645   904 sgd_solver.cpp:106] Iteration 36720, lr = 0.03136
I0605 02:56:58.004604   904 solver.cpp:229] Iteration 36760, loss = 3.06196
I0605 02:56:58.004640   904 solver.cpp:245]     Train net output #0: loss = 2.98667 (* 1 = 2.98667 loss)
I0605 02:56:58.004647   904 sgd_solver.cpp:106] Iteration 36760, lr = 0.0313506
I0605 02:57:18.355491   904 solver.cpp:229] Iteration 36800, loss = 3.10106
I0605 02:57:18.355633   904 solver.cpp:245]     Train net output #0: loss = 3.04516 (* 1 = 3.04516 loss)
I0605 02:57:18.355645   904 sgd_solver.cpp:106] Iteration 36800, lr = 0.0313412
I0605 02:57:38.671504   904 solver.cpp:229] Iteration 36840, loss = 3.10139
I0605 02:57:38.671555   904 solver.cpp:245]     Train net output #0: loss = 3.30692 (* 1 = 3.30692 loss)
I0605 02:57:38.671563   904 sgd_solver.cpp:106] Iteration 36840, lr = 0.0313318
I0605 02:57:58.981638   904 solver.cpp:229] Iteration 36880, loss = 3.09135
I0605 02:57:58.981791   904 solver.cpp:245]     Train net output #0: loss = 3.11027 (* 1 = 3.11027 loss)
I0605 02:57:58.981802   904 sgd_solver.cpp:106] Iteration 36880, lr = 0.0313224
I0605 02:58:08.101660   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 02:58:19.278545   904 solver.cpp:229] Iteration 36920, loss = 3.11145
I0605 02:58:19.278597   904 solver.cpp:245]     Train net output #0: loss = 3.15781 (* 1 = 3.15781 loss)
I0605 02:58:19.278607   904 sgd_solver.cpp:106] Iteration 36920, lr = 0.0313129
I0605 02:58:39.600296   904 solver.cpp:229] Iteration 36960, loss = 3.06598
I0605 02:58:39.600435   904 solver.cpp:245]     Train net output #0: loss = 3.1437 (* 1 = 3.1437 loss)
I0605 02:58:39.600447   904 sgd_solver.cpp:106] Iteration 36960, lr = 0.0313035
I0605 02:58:59.427382   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_37000.caffemodel
I0605 02:58:59.685535   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_37000.solverstate
I0605 02:58:59.769258   904 solver.cpp:338] Iteration 37000, Testing net (#0)
I0605 02:58:59.769338   904 net.cpp:748] Ignoring source layer loss
I0605 02:59:28.095744   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 03:00:02.302950   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 03:00:09.006651   904 solver.cpp:406]     Test net output #0: accuracy = 0.359941
I0605 03:00:09.006711   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.609339
I0605 03:00:09.318807   904 solver.cpp:229] Iteration 37000, loss = 3.12202
I0605 03:00:09.318850   904 solver.cpp:245]     Train net output #0: loss = 3.22477 (* 1 = 3.22477 loss)
I0605 03:00:09.318859   904 sgd_solver.cpp:106] Iteration 37000, lr = 0.0312941
I0605 03:00:28.537051   904 solver.cpp:229] Iteration 37040, loss = 3.06461
I0605 03:00:28.537113   904 solver.cpp:245]     Train net output #0: loss = 3.37797 (* 1 = 3.37797 loss)
I0605 03:00:28.537128   904 sgd_solver.cpp:106] Iteration 37040, lr = 0.0312847
I0605 03:00:49.994365   904 solver.cpp:229] Iteration 37080, loss = 3.11203
I0605 03:00:49.994601   904 solver.cpp:245]     Train net output #0: loss = 3.07093 (* 1 = 3.07093 loss)
I0605 03:00:49.994632   904 sgd_solver.cpp:106] Iteration 37080, lr = 0.0312753
I0605 03:01:11.217710   904 solver.cpp:229] Iteration 37120, loss = 3.09161
I0605 03:01:11.217756   904 solver.cpp:245]     Train net output #0: loss = 2.99256 (* 1 = 2.99256 loss)
I0605 03:01:11.217766   904 sgd_solver.cpp:106] Iteration 37120, lr = 0.0312659
I0605 03:01:31.848593   904 solver.cpp:229] Iteration 37160, loss = 3.07934
I0605 03:01:31.848749   904 solver.cpp:245]     Train net output #0: loss = 3.09597 (* 1 = 3.09597 loss)
I0605 03:01:31.848760   904 sgd_solver.cpp:106] Iteration 37160, lr = 0.0312565
I0605 03:01:52.389433   904 solver.cpp:229] Iteration 37200, loss = 3.10022
I0605 03:01:52.389498   904 solver.cpp:245]     Train net output #0: loss = 3.16962 (* 1 = 3.16962 loss)
I0605 03:01:52.389518   904 sgd_solver.cpp:106] Iteration 37200, lr = 0.0312471
I0605 03:02:12.951823   904 solver.cpp:229] Iteration 37240, loss = 3.07547
I0605 03:02:12.952111   904 solver.cpp:245]     Train net output #0: loss = 3.02295 (* 1 = 3.02295 loss)
I0605 03:02:12.952136   904 sgd_solver.cpp:106] Iteration 37240, lr = 0.0312376
I0605 03:02:33.201675   904 solver.cpp:229] Iteration 37280, loss = 3.10031
I0605 03:02:33.201719   904 solver.cpp:245]     Train net output #0: loss = 3.00685 (* 1 = 3.00685 loss)
I0605 03:02:33.201728   904 sgd_solver.cpp:106] Iteration 37280, lr = 0.0312282
I0605 03:02:54.160639   904 solver.cpp:229] Iteration 37320, loss = 3.10456
I0605 03:02:54.160774   904 solver.cpp:245]     Train net output #0: loss = 3.15084 (* 1 = 3.15084 loss)
I0605 03:02:54.160783   904 sgd_solver.cpp:106] Iteration 37320, lr = 0.0312188
I0605 03:03:14.203649   904 solver.cpp:229] Iteration 37360, loss = 3.07915
I0605 03:03:14.203694   904 solver.cpp:245]     Train net output #0: loss = 3.02248 (* 1 = 3.02248 loss)
I0605 03:03:14.203702   904 sgd_solver.cpp:106] Iteration 37360, lr = 0.0312094
I0605 03:03:34.437508   904 solver.cpp:229] Iteration 37400, loss = 3.0607
I0605 03:03:34.437659   904 solver.cpp:245]     Train net output #0: loss = 3.15246 (* 1 = 3.15246 loss)
I0605 03:03:34.437669   904 sgd_solver.cpp:106] Iteration 37400, lr = 0.0312
I0605 03:03:51.925609   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 03:03:54.716392   904 solver.cpp:229] Iteration 37440, loss = 3.1129
I0605 03:03:54.716444   904 solver.cpp:245]     Train net output #0: loss = 2.88468 (* 1 = 2.88468 loss)
I0605 03:03:54.716452   904 sgd_solver.cpp:106] Iteration 37440, lr = 0.0311906
I0605 03:04:14.988162   904 solver.cpp:229] Iteration 37480, loss = 3.09886
I0605 03:04:14.988298   904 solver.cpp:245]     Train net output #0: loss = 3.05138 (* 1 = 3.05138 loss)
I0605 03:04:14.988318   904 sgd_solver.cpp:106] Iteration 37480, lr = 0.0311812
I0605 03:04:35.341835   904 solver.cpp:229] Iteration 37520, loss = 3.09347
I0605 03:04:35.341886   904 solver.cpp:245]     Train net output #0: loss = 3.149 (* 1 = 3.149 loss)
I0605 03:04:35.341894   904 sgd_solver.cpp:106] Iteration 37520, lr = 0.0311718
I0605 03:04:55.853189   904 solver.cpp:229] Iteration 37560, loss = 3.11837
I0605 03:04:55.853396   904 solver.cpp:245]     Train net output #0: loss = 2.90616 (* 1 = 2.90616 loss)
I0605 03:04:55.853423   904 sgd_solver.cpp:106] Iteration 37560, lr = 0.0311624
I0605 03:05:16.302301   904 solver.cpp:229] Iteration 37600, loss = 3.09074
I0605 03:05:16.302347   904 solver.cpp:245]     Train net output #0: loss = 2.86155 (* 1 = 2.86155 loss)
I0605 03:05:16.302356   904 sgd_solver.cpp:106] Iteration 37600, lr = 0.0311529
I0605 03:05:36.593168   904 solver.cpp:229] Iteration 37640, loss = 3.12074
I0605 03:05:36.593389   904 solver.cpp:245]     Train net output #0: loss = 3.13756 (* 1 = 3.13756 loss)
I0605 03:05:36.593412   904 sgd_solver.cpp:106] Iteration 37640, lr = 0.0311435
I0605 03:05:56.881270   904 solver.cpp:229] Iteration 37680, loss = 3.11051
I0605 03:05:56.881320   904 solver.cpp:245]     Train net output #0: loss = 2.98575 (* 1 = 2.98575 loss)
I0605 03:05:56.881331   904 sgd_solver.cpp:106] Iteration 37680, lr = 0.0311341
I0605 03:06:17.338567   904 solver.cpp:229] Iteration 37720, loss = 3.09589
I0605 03:06:17.338758   904 solver.cpp:245]     Train net output #0: loss = 2.96896 (* 1 = 2.96896 loss)
I0605 03:06:17.338783   904 sgd_solver.cpp:106] Iteration 37720, lr = 0.0311247
I0605 03:06:37.841127   904 solver.cpp:229] Iteration 37760, loss = 3.06986
I0605 03:06:37.841192   904 solver.cpp:245]     Train net output #0: loss = 3.08446 (* 1 = 3.08446 loss)
I0605 03:06:37.841209   904 sgd_solver.cpp:106] Iteration 37760, lr = 0.0311153
I0605 03:06:58.338812   904 solver.cpp:229] Iteration 37800, loss = 3.10619
I0605 03:06:58.339000   904 solver.cpp:245]     Train net output #0: loss = 3.08502 (* 1 = 3.08502 loss)
I0605 03:06:58.339021   904 sgd_solver.cpp:106] Iteration 37800, lr = 0.0311059
I0605 03:07:18.829818   904 solver.cpp:229] Iteration 37840, loss = 3.12204
I0605 03:07:18.829851   904 solver.cpp:245]     Train net output #0: loss = 3.27772 (* 1 = 3.27772 loss)
I0605 03:07:18.829859   904 sgd_solver.cpp:106] Iteration 37840, lr = 0.0310965
I0605 03:07:39.296775   904 solver.cpp:229] Iteration 37880, loss = 3.10432
I0605 03:07:39.296993   904 solver.cpp:245]     Train net output #0: loss = 3.06225 (* 1 = 3.06225 loss)
I0605 03:07:39.297003   904 sgd_solver.cpp:106] Iteration 37880, lr = 0.0310871
I0605 03:07:59.871354   904 solver.cpp:229] Iteration 37920, loss = 3.06475
I0605 03:07:59.871399   904 solver.cpp:245]     Train net output #0: loss = 3.12585 (* 1 = 3.12585 loss)
I0605 03:07:59.871405   904 sgd_solver.cpp:106] Iteration 37920, lr = 0.0310776
I0605 03:08:20.366330   904 solver.cpp:229] Iteration 37960, loss = 3.10191
I0605 03:08:20.366478   904 solver.cpp:245]     Train net output #0: loss = 3.30998 (* 1 = 3.30998 loss)
I0605 03:08:20.366487   904 sgd_solver.cpp:106] Iteration 37960, lr = 0.0310682
I0605 03:08:23.442371   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 03:08:40.337744   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_38000.caffemodel
I0605 03:08:40.610985   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_38000.solverstate
I0605 03:08:40.688050   904 solver.cpp:338] Iteration 38000, Testing net (#0)
I0605 03:08:40.688133   904 net.cpp:748] Ignoring source layer loss
I0605 03:09:10.812717   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 03:09:43.888384   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 03:09:45.623704   904 solver.cpp:406]     Test net output #0: accuracy = 0.349401
I0605 03:09:45.623731   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.598959
I0605 03:09:45.936220   904 solver.cpp:229] Iteration 38000, loss = 3.12942
I0605 03:09:45.936260   904 solver.cpp:245]     Train net output #0: loss = 2.91885 (* 1 = 2.91885 loss)
I0605 03:09:45.936269   904 sgd_solver.cpp:106] Iteration 38000, lr = 0.0310588
I0605 03:10:05.178580   904 solver.cpp:229] Iteration 38040, loss = 3.09151
I0605 03:10:05.178632   904 solver.cpp:245]     Train net output #0: loss = 3.14219 (* 1 = 3.14219 loss)
I0605 03:10:05.178642   904 sgd_solver.cpp:106] Iteration 38040, lr = 0.0310494
I0605 03:10:26.634371   904 solver.cpp:229] Iteration 38080, loss = 3.05002
I0605 03:10:26.634555   904 solver.cpp:245]     Train net output #0: loss = 2.98186 (* 1 = 2.98186 loss)
I0605 03:10:26.634580   904 sgd_solver.cpp:106] Iteration 38080, lr = 0.03104
I0605 03:10:48.169103   904 solver.cpp:229] Iteration 38120, loss = 3.09604
I0605 03:10:48.169155   904 solver.cpp:245]     Train net output #0: loss = 3.1421 (* 1 = 3.1421 loss)
I0605 03:10:48.169164   904 sgd_solver.cpp:106] Iteration 38120, lr = 0.0310306
I0605 03:11:09.780653   904 solver.cpp:229] Iteration 38160, loss = 3.08029
I0605 03:11:09.780879   904 solver.cpp:245]     Train net output #0: loss = 3.2342 (* 1 = 3.2342 loss)
I0605 03:11:09.780905   904 sgd_solver.cpp:106] Iteration 38160, lr = 0.0310212
I0605 03:11:30.670951   904 solver.cpp:229] Iteration 38200, loss = 3.10828
I0605 03:11:30.671001   904 solver.cpp:245]     Train net output #0: loss = 3.17967 (* 1 = 3.17967 loss)
I0605 03:11:30.671010   904 sgd_solver.cpp:106] Iteration 38200, lr = 0.0310118
I0605 03:11:51.829452   904 solver.cpp:229] Iteration 38240, loss = 3.09557
I0605 03:11:51.829622   904 solver.cpp:245]     Train net output #0: loss = 3.11622 (* 1 = 3.11622 loss)
I0605 03:11:51.829649   904 sgd_solver.cpp:106] Iteration 38240, lr = 0.0310024
I0605 03:12:12.915096   904 solver.cpp:229] Iteration 38280, loss = 3.11473
I0605 03:12:12.915146   904 solver.cpp:245]     Train net output #0: loss = 3.3333 (* 1 = 3.3333 loss)
I0605 03:12:12.915155   904 sgd_solver.cpp:106] Iteration 38280, lr = 0.0309929
I0605 03:12:33.859585   904 solver.cpp:229] Iteration 38320, loss = 3.05518
I0605 03:12:33.859791   904 solver.cpp:245]     Train net output #0: loss = 3.10758 (* 1 = 3.10758 loss)
I0605 03:12:33.859800   904 sgd_solver.cpp:106] Iteration 38320, lr = 0.0309835
I0605 03:12:54.697687   904 solver.cpp:229] Iteration 38360, loss = 3.06
I0605 03:12:54.697738   904 solver.cpp:245]     Train net output #0: loss = 3.05201 (* 1 = 3.05201 loss)
I0605 03:12:54.697752   904 sgd_solver.cpp:106] Iteration 38360, lr = 0.0309741
I0605 03:13:15.536481   904 solver.cpp:229] Iteration 38400, loss = 3.05463
I0605 03:13:15.536662   904 solver.cpp:245]     Train net output #0: loss = 2.97575 (* 1 = 2.97575 loss)
I0605 03:13:15.536684   904 sgd_solver.cpp:106] Iteration 38400, lr = 0.0309647
I0605 03:13:36.377425   904 solver.cpp:229] Iteration 38440, loss = 3.08615
I0605 03:13:36.377480   904 solver.cpp:245]     Train net output #0: loss = 3.10795 (* 1 = 3.10795 loss)
I0605 03:13:36.377496   904 sgd_solver.cpp:106] Iteration 38440, lr = 0.0309553
I0605 03:13:57.113247   904 solver.cpp:229] Iteration 38480, loss = 3.04958
I0605 03:13:57.113415   904 solver.cpp:245]     Train net output #0: loss = 3.1711 (* 1 = 3.1711 loss)
I0605 03:13:57.113425   904 sgd_solver.cpp:106] Iteration 38480, lr = 0.0309459
I0605 03:14:17.662096   904 solver.cpp:229] Iteration 38520, loss = 3.0857
I0605 03:14:17.662148   904 solver.cpp:245]     Train net output #0: loss = 3.12408 (* 1 = 3.12408 loss)
I0605 03:14:17.662158   904 sgd_solver.cpp:106] Iteration 38520, lr = 0.0309365
I0605 03:14:38.324450   904 solver.cpp:229] Iteration 38560, loss = 3.04234
I0605 03:14:38.324645   904 solver.cpp:245]     Train net output #0: loss = 3.25247 (* 1 = 3.25247 loss)
I0605 03:14:38.324671   904 sgd_solver.cpp:106] Iteration 38560, lr = 0.0309271
I0605 03:14:48.140823   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 03:14:58.986019   904 solver.cpp:229] Iteration 38600, loss = 3.07965
I0605 03:14:58.986052   904 solver.cpp:245]     Train net output #0: loss = 3.04657 (* 1 = 3.04657 loss)
I0605 03:14:58.986058   904 sgd_solver.cpp:106] Iteration 38600, lr = 0.0309176
I0605 03:15:19.563526   904 solver.cpp:229] Iteration 38640, loss = 3.07451
I0605 03:15:19.563740   904 solver.cpp:245]     Train net output #0: loss = 3.46316 (* 1 = 3.46316 loss)
I0605 03:15:19.563767   904 sgd_solver.cpp:106] Iteration 38640, lr = 0.0309082
I0605 03:15:40.088117   904 solver.cpp:229] Iteration 38680, loss = 3.09242
I0605 03:15:40.088173   904 solver.cpp:245]     Train net output #0: loss = 3.06235 (* 1 = 3.06235 loss)
I0605 03:15:40.088182   904 sgd_solver.cpp:106] Iteration 38680, lr = 0.0308988
I0605 03:16:00.587972   904 solver.cpp:229] Iteration 38720, loss = 3.04329
I0605 03:16:00.588125   904 solver.cpp:245]     Train net output #0: loss = 3.23443 (* 1 = 3.23443 loss)
I0605 03:16:00.588135   904 sgd_solver.cpp:106] Iteration 38720, lr = 0.0308894
I0605 03:16:21.109704   904 solver.cpp:229] Iteration 38760, loss = 3.06259
I0605 03:16:21.109755   904 solver.cpp:245]     Train net output #0: loss = 3.26731 (* 1 = 3.26731 loss)
I0605 03:16:21.109762   904 sgd_solver.cpp:106] Iteration 38760, lr = 0.03088
I0605 03:16:41.619534   904 solver.cpp:229] Iteration 38800, loss = 3.06966
I0605 03:16:41.619741   904 solver.cpp:245]     Train net output #0: loss = 2.97675 (* 1 = 2.97675 loss)
I0605 03:16:41.619770   904 sgd_solver.cpp:106] Iteration 38800, lr = 0.0308706
I0605 03:17:02.140278   904 solver.cpp:229] Iteration 38840, loss = 3.03352
I0605 03:17:02.140327   904 solver.cpp:245]     Train net output #0: loss = 2.94624 (* 1 = 2.94624 loss)
I0605 03:17:02.140341   904 sgd_solver.cpp:106] Iteration 38840, lr = 0.0308612
I0605 03:17:22.444851   904 solver.cpp:229] Iteration 38880, loss = 3.1053
I0605 03:17:22.445019   904 solver.cpp:245]     Train net output #0: loss = 3.08085 (* 1 = 3.08085 loss)
I0605 03:17:22.445031   904 sgd_solver.cpp:106] Iteration 38880, lr = 0.0308518
I0605 03:17:42.737493   904 solver.cpp:229] Iteration 38920, loss = 3.09043
I0605 03:17:42.737546   904 solver.cpp:245]     Train net output #0: loss = 2.74459 (* 1 = 2.74459 loss)
I0605 03:17:42.737566   904 sgd_solver.cpp:106] Iteration 38920, lr = 0.0308424
I0605 03:18:02.989758   904 solver.cpp:229] Iteration 38960, loss = 3.08749
I0605 03:18:02.989986   904 solver.cpp:245]     Train net output #0: loss = 3.00806 (* 1 = 3.00806 loss)
I0605 03:18:02.989998   904 sgd_solver.cpp:106] Iteration 38960, lr = 0.0308329
I0605 03:18:22.742183   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_39000.caffemodel
I0605 03:18:23.009332   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_39000.solverstate
I0605 03:18:23.090406   904 solver.cpp:338] Iteration 39000, Testing net (#0)
I0605 03:18:23.090493   904 net.cpp:748] Ignoring source layer loss
I0605 03:18:32.008877   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 03:19:04.562304   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 03:19:29.111786   904 solver.cpp:406]     Test net output #0: accuracy = 0.364041
I0605 03:19:29.111824   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.612439
I0605 03:19:29.426615   904 solver.cpp:229] Iteration 39000, loss = 3.09811
I0605 03:19:29.426658   904 solver.cpp:245]     Train net output #0: loss = 3.09987 (* 1 = 3.09987 loss)
I0605 03:19:29.426669   904 sgd_solver.cpp:106] Iteration 39000, lr = 0.0308235
I0605 03:19:48.582697   904 solver.cpp:229] Iteration 39040, loss = 3.08536
I0605 03:19:48.582911   904 solver.cpp:245]     Train net output #0: loss = 2.88204 (* 1 = 2.88204 loss)
I0605 03:19:48.582938   904 sgd_solver.cpp:106] Iteration 39040, lr = 0.0308141
I0605 03:20:09.832921   904 solver.cpp:229] Iteration 39080, loss = 3.06883
I0605 03:20:09.832976   904 solver.cpp:245]     Train net output #0: loss = 3.03424 (* 1 = 3.03424 loss)
I0605 03:20:09.832988   904 sgd_solver.cpp:106] Iteration 39080, lr = 0.0308047
I0605 03:20:31.279038   904 solver.cpp:229] Iteration 39120, loss = 3.0778
I0605 03:20:31.279247   904 solver.cpp:245]     Train net output #0: loss = 3.14849 (* 1 = 3.14849 loss)
I0605 03:20:31.279273   904 sgd_solver.cpp:106] Iteration 39120, lr = 0.0307953
I0605 03:20:52.292847   904 solver.cpp:229] Iteration 39160, loss = 3.10882
I0605 03:20:52.292902   904 solver.cpp:245]     Train net output #0: loss = 2.8247 (* 1 = 2.8247 loss)
I0605 03:20:52.292937   904 sgd_solver.cpp:106] Iteration 39160, lr = 0.0307859
I0605 03:20:57.268139   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 03:21:13.207917   904 solver.cpp:229] Iteration 39200, loss = 3.13016
I0605 03:21:13.208048   904 solver.cpp:245]     Train net output #0: loss = 3.08598 (* 1 = 3.08598 loss)
I0605 03:21:13.208058   904 sgd_solver.cpp:106] Iteration 39200, lr = 0.0307765
I0605 03:21:34.138609   904 solver.cpp:229] Iteration 39240, loss = 3.07309
I0605 03:21:34.138655   904 solver.cpp:245]     Train net output #0: loss = 2.94603 (* 1 = 2.94603 loss)
I0605 03:21:34.138662   904 sgd_solver.cpp:106] Iteration 39240, lr = 0.0307671
I0605 03:21:55.109906   904 solver.cpp:229] Iteration 39280, loss = 3.05851
I0605 03:21:55.110121   904 solver.cpp:245]     Train net output #0: loss = 3.11054 (* 1 = 3.11054 loss)
I0605 03:21:55.110151   904 sgd_solver.cpp:106] Iteration 39280, lr = 0.0307576
I0605 03:22:15.905304   904 solver.cpp:229] Iteration 39320, loss = 3.0812
I0605 03:22:15.905341   904 solver.cpp:245]     Train net output #0: loss = 2.89947 (* 1 = 2.89947 loss)
I0605 03:22:15.905349   904 sgd_solver.cpp:106] Iteration 39320, lr = 0.0307482
I0605 03:22:36.544091   904 solver.cpp:229] Iteration 39360, loss = 3.07197
I0605 03:22:36.544219   904 solver.cpp:245]     Train net output #0: loss = 3.04192 (* 1 = 3.04192 loss)
I0605 03:22:36.544226   904 sgd_solver.cpp:106] Iteration 39360, lr = 0.0307388
I0605 03:22:57.191680   904 solver.cpp:229] Iteration 39400, loss = 3.08614
I0605 03:22:57.191720   904 solver.cpp:245]     Train net output #0: loss = 2.91814 (* 1 = 2.91814 loss)
I0605 03:22:57.191730   904 sgd_solver.cpp:106] Iteration 39400, lr = 0.0307294
I0605 03:23:17.828182   904 solver.cpp:229] Iteration 39440, loss = 3.0285
I0605 03:23:17.828462   904 solver.cpp:245]     Train net output #0: loss = 2.99675 (* 1 = 2.99675 loss)
I0605 03:23:17.828491   904 sgd_solver.cpp:106] Iteration 39440, lr = 0.03072
I0605 03:23:38.344236   904 solver.cpp:229] Iteration 39480, loss = 3.07979
I0605 03:23:38.344280   904 solver.cpp:245]     Train net output #0: loss = 3.02342 (* 1 = 3.02342 loss)
I0605 03:23:38.344287   904 sgd_solver.cpp:106] Iteration 39480, lr = 0.0307106
I0605 03:23:58.788079   904 solver.cpp:229] Iteration 39520, loss = 3.04815
I0605 03:23:58.788266   904 solver.cpp:245]     Train net output #0: loss = 3.08207 (* 1 = 3.08207 loss)
I0605 03:23:58.788300   904 sgd_solver.cpp:106] Iteration 39520, lr = 0.0307012
I0605 03:24:19.212530   904 solver.cpp:229] Iteration 39560, loss = 3.09649
I0605 03:24:19.212574   904 solver.cpp:245]     Train net output #0: loss = 3.17107 (* 1 = 3.17107 loss)
I0605 03:24:19.212585   904 sgd_solver.cpp:106] Iteration 39560, lr = 0.0306918
I0605 03:24:39.648854   904 solver.cpp:229] Iteration 39600, loss = 3.05855
I0605 03:24:39.649039   904 solver.cpp:245]     Train net output #0: loss = 3.16406 (* 1 = 3.16406 loss)
I0605 03:24:39.649061   904 sgd_solver.cpp:106] Iteration 39600, lr = 0.0306824
I0605 03:25:00.307785   904 solver.cpp:229] Iteration 39640, loss = 3.05288
I0605 03:25:00.307827   904 solver.cpp:245]     Train net output #0: loss = 3.23379 (* 1 = 3.23379 loss)
I0605 03:25:00.307837   904 sgd_solver.cpp:106] Iteration 39640, lr = 0.0306729
I0605 03:25:20.641186   904 solver.cpp:229] Iteration 39680, loss = 3.04545
I0605 03:25:20.641363   904 solver.cpp:245]     Train net output #0: loss = 3.23417 (* 1 = 3.23417 loss)
I0605 03:25:20.641391   904 sgd_solver.cpp:106] Iteration 39680, lr = 0.0306635
I0605 03:25:32.532676   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 03:25:40.866282   904 solver.cpp:229] Iteration 39720, loss = 3.09104
I0605 03:25:40.866322   904 solver.cpp:245]     Train net output #0: loss = 2.89013 (* 1 = 2.89013 loss)
I0605 03:25:40.866331   904 sgd_solver.cpp:106] Iteration 39720, lr = 0.0306541
I0605 03:26:01.091472   904 solver.cpp:229] Iteration 39760, loss = 3.02592
I0605 03:26:01.091650   904 solver.cpp:245]     Train net output #0: loss = 3.13274 (* 1 = 3.13274 loss)
I0605 03:26:01.091663   904 sgd_solver.cpp:106] Iteration 39760, lr = 0.0306447
I0605 03:26:21.331120   904 solver.cpp:229] Iteration 39800, loss = 3.09514
I0605 03:26:21.331163   904 solver.cpp:245]     Train net output #0: loss = 2.93128 (* 1 = 2.93128 loss)
I0605 03:26:21.331184   904 sgd_solver.cpp:106] Iteration 39800, lr = 0.0306353
I0605 03:26:41.565141   904 solver.cpp:229] Iteration 39840, loss = 3.07074
I0605 03:26:41.565323   904 solver.cpp:245]     Train net output #0: loss = 3.12861 (* 1 = 3.12861 loss)
I0605 03:26:41.565356   904 sgd_solver.cpp:106] Iteration 39840, lr = 0.0306259
I0605 03:27:01.843510   904 solver.cpp:229] Iteration 39880, loss = 3.00994
I0605 03:27:01.843562   904 solver.cpp:245]     Train net output #0: loss = 2.96212 (* 1 = 2.96212 loss)
I0605 03:27:01.843572   904 sgd_solver.cpp:106] Iteration 39880, lr = 0.0306165
I0605 03:27:21.942970   904 solver.cpp:229] Iteration 39920, loss = 3.04491
I0605 03:27:21.943091   904 solver.cpp:245]     Train net output #0: loss = 3.01381 (* 1 = 3.01381 loss)
I0605 03:27:21.943104   904 sgd_solver.cpp:106] Iteration 39920, lr = 0.0306071
I0605 03:27:42.062435   904 solver.cpp:229] Iteration 39960, loss = 3.05244
I0605 03:27:42.062489   904 solver.cpp:245]     Train net output #0: loss = 3.0691 (* 1 = 3.0691 loss)
I0605 03:27:42.062499   904 sgd_solver.cpp:106] Iteration 39960, lr = 0.0305976
I0605 03:28:01.756839   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_40000.caffemodel
I0605 03:28:02.015271   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_40000.solverstate
I0605 03:28:02.094439   904 solver.cpp:338] Iteration 40000, Testing net (#0)
I0605 03:28:02.094497   904 net.cpp:748] Ignoring source layer loss
I0605 03:28:17.074221   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 03:28:50.621284   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 03:29:09.228929   904 solver.cpp:406]     Test net output #0: accuracy = 0.374321
I0605 03:29:09.228971   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.626439
I0605 03:29:09.542932   904 solver.cpp:229] Iteration 40000, loss = 3.04839
I0605 03:29:09.542982   904 solver.cpp:245]     Train net output #0: loss = 2.91562 (* 1 = 2.91562 loss)
I0605 03:29:09.542994   904 sgd_solver.cpp:106] Iteration 40000, lr = 0.0305882
I0605 03:29:28.843252   904 solver.cpp:229] Iteration 40040, loss = 3.04619
I0605 03:29:28.843376   904 solver.cpp:245]     Train net output #0: loss = 3.14137 (* 1 = 3.14137 loss)
I0605 03:29:28.843386   904 sgd_solver.cpp:106] Iteration 40040, lr = 0.0305788
I0605 03:29:50.029031   904 solver.cpp:229] Iteration 40080, loss = 3.07025
I0605 03:29:50.029100   904 solver.cpp:245]     Train net output #0: loss = 3.28384 (* 1 = 3.28384 loss)
I0605 03:29:50.029110   904 sgd_solver.cpp:106] Iteration 40080, lr = 0.0305694
I0605 03:30:11.305701   904 solver.cpp:229] Iteration 40120, loss = 3.06915
I0605 03:30:11.305831   904 solver.cpp:245]     Train net output #0: loss = 2.92227 (* 1 = 2.92227 loss)
I0605 03:30:11.305842   904 sgd_solver.cpp:106] Iteration 40120, lr = 0.03056
I0605 03:30:32.307543   904 solver.cpp:229] Iteration 40160, loss = 3.07034
I0605 03:30:32.307595   904 solver.cpp:245]     Train net output #0: loss = 3.31664 (* 1 = 3.31664 loss)
I0605 03:30:32.307606   904 sgd_solver.cpp:106] Iteration 40160, lr = 0.0305506
I0605 03:30:53.317245   904 solver.cpp:229] Iteration 40200, loss = 3.06352
I0605 03:30:53.317459   904 solver.cpp:245]     Train net output #0: loss = 2.95743 (* 1 = 2.95743 loss)
I0605 03:30:53.317481   904 sgd_solver.cpp:106] Iteration 40200, lr = 0.0305412
I0605 03:31:07.733538   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 03:31:14.232722   904 solver.cpp:229] Iteration 40240, loss = 3.04603
I0605 03:31:14.232769   904 solver.cpp:245]     Train net output #0: loss = 3.15693 (* 1 = 3.15693 loss)
I0605 03:31:14.232777   904 sgd_solver.cpp:106] Iteration 40240, lr = 0.0305318
I0605 03:31:35.270100   904 solver.cpp:229] Iteration 40280, loss = 3.03005
I0605 03:31:35.270318   904 solver.cpp:245]     Train net output #0: loss = 3.04211 (* 1 = 3.04211 loss)
I0605 03:31:35.270344   904 sgd_solver.cpp:106] Iteration 40280, lr = 0.0305224
I0605 03:31:55.995126   904 solver.cpp:229] Iteration 40320, loss = 3.06728
I0605 03:31:55.995178   904 solver.cpp:245]     Train net output #0: loss = 3.02219 (* 1 = 3.02219 loss)
I0605 03:31:55.995188   904 sgd_solver.cpp:106] Iteration 40320, lr = 0.0305129
I0605 03:32:16.694304   904 solver.cpp:229] Iteration 40360, loss = 3.04723
I0605 03:32:16.694511   904 solver.cpp:245]     Train net output #0: loss = 3.34952 (* 1 = 3.34952 loss)
I0605 03:32:16.694540   904 sgd_solver.cpp:106] Iteration 40360, lr = 0.0305035
I0605 03:32:37.376541   904 solver.cpp:229] Iteration 40400, loss = 3.02291
I0605 03:32:37.376593   904 solver.cpp:245]     Train net output #0: loss = 3.33371 (* 1 = 3.33371 loss)
I0605 03:32:37.376603   904 sgd_solver.cpp:106] Iteration 40400, lr = 0.0304941
I0605 03:32:58.129473   904 solver.cpp:229] Iteration 40440, loss = 3.05817
I0605 03:32:58.129633   904 solver.cpp:245]     Train net output #0: loss = 3.2848 (* 1 = 3.2848 loss)
I0605 03:32:58.129645   904 sgd_solver.cpp:106] Iteration 40440, lr = 0.0304847
I0605 03:33:18.822986   904 solver.cpp:229] Iteration 40480, loss = 3.06199
I0605 03:33:18.823026   904 solver.cpp:245]     Train net output #0: loss = 3.05834 (* 1 = 3.05834 loss)
I0605 03:33:18.823035   904 sgd_solver.cpp:106] Iteration 40480, lr = 0.0304753
I0605 03:33:39.313609   904 solver.cpp:229] Iteration 40520, loss = 3.07271
I0605 03:33:39.313774   904 solver.cpp:245]     Train net output #0: loss = 3.0518 (* 1 = 3.0518 loss)
I0605 03:33:39.313786   904 sgd_solver.cpp:106] Iteration 40520, lr = 0.0304659
I0605 03:33:59.797266   904 solver.cpp:229] Iteration 40560, loss = 3.02062
I0605 03:33:59.797318   904 solver.cpp:245]     Train net output #0: loss = 3.10133 (* 1 = 3.10133 loss)
I0605 03:33:59.797327   904 sgd_solver.cpp:106] Iteration 40560, lr = 0.0304565
I0605 03:34:20.330143   904 solver.cpp:229] Iteration 40600, loss = 3.02206
I0605 03:34:20.330420   904 solver.cpp:245]     Train net output #0: loss = 2.95774 (* 1 = 2.95774 loss)
I0605 03:34:20.330445   904 sgd_solver.cpp:106] Iteration 40600, lr = 0.0304471
I0605 03:34:40.845912   904 solver.cpp:229] Iteration 40640, loss = 3.05284
I0605 03:34:40.845968   904 solver.cpp:245]     Train net output #0: loss = 2.83296 (* 1 = 2.83296 loss)
I0605 03:34:40.845976   904 sgd_solver.cpp:106] Iteration 40640, lr = 0.0304376
I0605 03:35:01.364522   904 solver.cpp:229] Iteration 40680, loss = 3.05767
I0605 03:35:01.364696   904 solver.cpp:245]     Train net output #0: loss = 3.21242 (* 1 = 3.21242 loss)
I0605 03:35:01.364723   904 sgd_solver.cpp:106] Iteration 40680, lr = 0.0304282
I0605 03:35:21.900609   904 solver.cpp:229] Iteration 40720, loss = 3.07875
I0605 03:35:21.900666   904 solver.cpp:245]     Train net output #0: loss = 3.1284 (* 1 = 3.1284 loss)
I0605 03:35:21.900687   904 sgd_solver.cpp:106] Iteration 40720, lr = 0.0304188
I0605 03:35:28.060045   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 03:35:42.409935   904 solver.cpp:229] Iteration 40760, loss = 3.04113
I0605 03:35:42.410064   904 solver.cpp:245]     Train net output #0: loss = 3.16356 (* 1 = 3.16356 loss)
I0605 03:35:42.410073   904 sgd_solver.cpp:106] Iteration 40760, lr = 0.0304094
I0605 03:36:02.939478   904 solver.cpp:229] Iteration 40800, loss = 3.02407
I0605 03:36:02.939534   904 solver.cpp:245]     Train net output #0: loss = 3.10377 (* 1 = 3.10377 loss)
I0605 03:36:02.939548   904 sgd_solver.cpp:106] Iteration 40800, lr = 0.0304
I0605 03:36:24.117771   904 solver.cpp:229] Iteration 40840, loss = 3.02845
I0605 03:36:24.117993   904 solver.cpp:245]     Train net output #0: loss = 3.27076 (* 1 = 3.27076 loss)
I0605 03:36:24.118019   904 sgd_solver.cpp:106] Iteration 40840, lr = 0.0303906
I0605 03:36:44.631904   904 solver.cpp:229] Iteration 40880, loss = 3.0311
I0605 03:36:44.631954   904 solver.cpp:245]     Train net output #0: loss = 2.91748 (* 1 = 2.91748 loss)
I0605 03:36:44.631966   904 sgd_solver.cpp:106] Iteration 40880, lr = 0.0303812
I0605 03:37:05.161280   904 solver.cpp:229] Iteration 40920, loss = 3.03825
I0605 03:37:05.161430   904 solver.cpp:245]     Train net output #0: loss = 3.04029 (* 1 = 3.04029 loss)
I0605 03:37:05.161456   904 sgd_solver.cpp:106] Iteration 40920, lr = 0.0303718
I0605 03:37:25.673984   904 solver.cpp:229] Iteration 40960, loss = 3.01335
I0605 03:37:25.674036   904 solver.cpp:245]     Train net output #0: loss = 3.14 (* 1 = 3.14 loss)
I0605 03:37:25.674046   904 sgd_solver.cpp:106] Iteration 40960, lr = 0.0303624
I0605 03:37:45.543407   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_41000.caffemodel
I0605 03:37:45.810928   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_41000.solverstate
I0605 03:37:45.894747   904 solver.cpp:338] Iteration 41000, Testing net (#0)
I0605 03:37:45.894832   904 net.cpp:748] Ignoring source layer loss
I0605 03:38:01.639493   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 03:38:34.382053   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 03:38:52.362304   904 solver.cpp:406]     Test net output #0: accuracy = 0.369301
I0605 03:38:52.362352   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.617719
I0605 03:38:52.675767   904 solver.cpp:229] Iteration 41000, loss = 2.98515
I0605 03:38:52.675814   904 solver.cpp:245]     Train net output #0: loss = 2.59975 (* 1 = 2.59975 loss)
I0605 03:38:52.675824   904 sgd_solver.cpp:106] Iteration 41000, lr = 0.0303529
I0605 03:39:11.889153   904 solver.cpp:229] Iteration 41040, loss = 3.00026
I0605 03:39:11.889302   904 solver.cpp:245]     Train net output #0: loss = 3.02533 (* 1 = 3.02533 loss)
I0605 03:39:11.889313   904 sgd_solver.cpp:106] Iteration 41040, lr = 0.0303435
I0605 03:39:33.346539   904 solver.cpp:229] Iteration 41080, loss = 3.04093
I0605 03:39:33.346580   904 solver.cpp:245]     Train net output #0: loss = 2.82894 (* 1 = 2.82894 loss)
I0605 03:39:33.346590   904 sgd_solver.cpp:106] Iteration 41080, lr = 0.0303341
I0605 03:39:54.914981   904 solver.cpp:229] Iteration 41120, loss = 3.0335
I0605 03:39:54.915262   904 solver.cpp:245]     Train net output #0: loss = 2.79043 (* 1 = 2.79043 loss)
I0605 03:39:54.915287   904 sgd_solver.cpp:106] Iteration 41120, lr = 0.0303247
I0605 03:40:16.120898   904 solver.cpp:229] Iteration 41160, loss = 3.04987
I0605 03:40:16.120942   904 solver.cpp:245]     Train net output #0: loss = 3.10249 (* 1 = 3.10249 loss)
I0605 03:40:16.120952   904 sgd_solver.cpp:106] Iteration 41160, lr = 0.0303153
I0605 03:40:37.123183   904 solver.cpp:229] Iteration 41200, loss = 3.06342
I0605 03:40:37.123314   904 solver.cpp:245]     Train net output #0: loss = 3.06423 (* 1 = 3.06423 loss)
I0605 03:40:37.123323   904 sgd_solver.cpp:106] Iteration 41200, lr = 0.0303059
I0605 03:40:58.085405   904 solver.cpp:229] Iteration 41240, loss = 3.06233
I0605 03:40:58.085458   904 solver.cpp:245]     Train net output #0: loss = 2.82666 (* 1 = 2.82666 loss)
I0605 03:40:58.085467   904 sgd_solver.cpp:106] Iteration 41240, lr = 0.0302965
I0605 03:40:58.348740   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 03:41:19.063504   904 solver.cpp:229] Iteration 41280, loss = 3.01624
I0605 03:41:19.063688   904 solver.cpp:245]     Train net output #0: loss = 2.90782 (* 1 = 2.90782 loss)
I0605 03:41:19.063726   904 sgd_solver.cpp:106] Iteration 41280, lr = 0.0302871
I0605 03:41:40.038605   904 solver.cpp:229] Iteration 41320, loss = 3.03246
I0605 03:41:40.038652   904 solver.cpp:245]     Train net output #0: loss = 2.89715 (* 1 = 2.89715 loss)
I0605 03:41:40.038664   904 sgd_solver.cpp:106] Iteration 41320, lr = 0.0302776
I0605 03:42:00.847746   904 solver.cpp:229] Iteration 41360, loss = 3.02021
I0605 03:42:00.847929   904 solver.cpp:245]     Train net output #0: loss = 3.01154 (* 1 = 3.01154 loss)
I0605 03:42:00.847970   904 sgd_solver.cpp:106] Iteration 41360, lr = 0.0302682
I0605 03:42:21.663776   904 solver.cpp:229] Iteration 41400, loss = 3.06229
I0605 03:42:21.663832   904 solver.cpp:245]     Train net output #0: loss = 2.88781 (* 1 = 2.88781 loss)
I0605 03:42:21.663842   904 sgd_solver.cpp:106] Iteration 41400, lr = 0.0302588
I0605 03:42:42.465576   904 solver.cpp:229] Iteration 41440, loss = 3.04678
I0605 03:42:42.465790   904 solver.cpp:245]     Train net output #0: loss = 2.98971 (* 1 = 2.98971 loss)
I0605 03:42:42.465816   904 sgd_solver.cpp:106] Iteration 41440, lr = 0.0302494
I0605 03:43:03.074620   904 solver.cpp:229] Iteration 41480, loss = 3.05062
I0605 03:43:03.074673   904 solver.cpp:245]     Train net output #0: loss = 2.98217 (* 1 = 2.98217 loss)
I0605 03:43:03.074682   904 sgd_solver.cpp:106] Iteration 41480, lr = 0.03024
I0605 03:43:23.619834   904 solver.cpp:229] Iteration 41520, loss = 3.06816
I0605 03:43:23.620043   904 solver.cpp:245]     Train net output #0: loss = 3.12037 (* 1 = 3.12037 loss)
I0605 03:43:23.620072   904 sgd_solver.cpp:106] Iteration 41520, lr = 0.0302306
I0605 03:43:44.253585   904 solver.cpp:229] Iteration 41560, loss = 3.0304
I0605 03:43:44.253635   904 solver.cpp:245]     Train net output #0: loss = 3.15968 (* 1 = 3.15968 loss)
I0605 03:43:44.253646   904 sgd_solver.cpp:106] Iteration 41560, lr = 0.0302212
I0605 03:44:04.846015   904 solver.cpp:229] Iteration 41600, loss = 3.05032
I0605 03:44:04.846235   904 solver.cpp:245]     Train net output #0: loss = 2.91256 (* 1 = 2.91256 loss)
I0605 03:44:04.846263   904 sgd_solver.cpp:106] Iteration 41600, lr = 0.0302118
I0605 03:44:25.360800   904 solver.cpp:229] Iteration 41640, loss = 3.05948
I0605 03:44:25.360852   904 solver.cpp:245]     Train net output #0: loss = 3.12761 (* 1 = 3.12761 loss)
I0605 03:44:25.360862   904 sgd_solver.cpp:106] Iteration 41640, lr = 0.0302024
I0605 03:44:45.853019   904 solver.cpp:229] Iteration 41680, loss = 3.03391
I0605 03:44:45.853302   904 solver.cpp:245]     Train net output #0: loss = 3.0708 (* 1 = 3.0708 loss)
I0605 03:44:45.853330   904 sgd_solver.cpp:106] Iteration 41680, lr = 0.0301929
I0605 03:45:06.320480   904 solver.cpp:229] Iteration 41720, loss = 3.03944
I0605 03:45:06.320529   904 solver.cpp:245]     Train net output #0: loss = 3.01392 (* 1 = 3.01392 loss)
I0605 03:45:06.320539   904 sgd_solver.cpp:106] Iteration 41720, lr = 0.0301835
I0605 03:45:19.635648   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 03:45:26.804761   904 solver.cpp:229] Iteration 41760, loss = 3.00425
I0605 03:45:26.804816   904 solver.cpp:245]     Train net output #0: loss = 3.25854 (* 1 = 3.25854 loss)
I0605 03:45:26.804826   904 sgd_solver.cpp:106] Iteration 41760, lr = 0.0301741
I0605 03:45:47.272204   904 solver.cpp:229] Iteration 41800, loss = 3.02022
I0605 03:45:47.272258   904 solver.cpp:245]     Train net output #0: loss = 3.01912 (* 1 = 3.01912 loss)
I0605 03:45:47.272269   904 sgd_solver.cpp:106] Iteration 41800, lr = 0.0301647
I0605 03:46:07.781059   904 solver.cpp:229] Iteration 41840, loss = 3.02258
I0605 03:46:07.781275   904 solver.cpp:245]     Train net output #0: loss = 2.88788 (* 1 = 2.88788 loss)
I0605 03:46:07.781301   904 sgd_solver.cpp:106] Iteration 41840, lr = 0.0301553
I0605 03:46:28.274689   904 solver.cpp:229] Iteration 41880, loss = 2.99168
I0605 03:46:28.274735   904 solver.cpp:245]     Train net output #0: loss = 2.98464 (* 1 = 2.98464 loss)
I0605 03:46:28.274746   904 sgd_solver.cpp:106] Iteration 41880, lr = 0.0301459
I0605 03:46:48.552459   904 solver.cpp:229] Iteration 41920, loss = 3.0513
I0605 03:46:48.552597   904 solver.cpp:245]     Train net output #0: loss = 2.87818 (* 1 = 2.87818 loss)
I0605 03:46:48.552608   904 sgd_solver.cpp:106] Iteration 41920, lr = 0.0301365
I0605 03:47:08.833979   904 solver.cpp:229] Iteration 41960, loss = 3.01486
I0605 03:47:08.834036   904 solver.cpp:245]     Train net output #0: loss = 3.06954 (* 1 = 3.06954 loss)
I0605 03:47:08.834048   904 sgd_solver.cpp:106] Iteration 41960, lr = 0.0301271
I0605 03:47:28.636937   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_42000.caffemodel
I0605 03:47:28.898838   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_42000.solverstate
I0605 03:47:28.975857   904 solver.cpp:338] Iteration 42000, Testing net (#0)
I0605 03:47:28.975935   904 net.cpp:748] Ignoring source layer loss
I0605 03:47:45.548509   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 03:48:18.219952   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 03:48:34.427585   904 solver.cpp:406]     Test net output #0: accuracy = 0.366901
I0605 03:48:34.427619   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.616119
I0605 03:48:34.744477   904 solver.cpp:229] Iteration 42000, loss = 3.02663
I0605 03:48:34.744519   904 solver.cpp:245]     Train net output #0: loss = 3.22008 (* 1 = 3.22008 loss)
I0605 03:48:34.744535   904 sgd_solver.cpp:106] Iteration 42000, lr = 0.0301176
I0605 03:48:53.925534   904 solver.cpp:229] Iteration 42040, loss = 2.98541
I0605 03:48:53.925701   904 solver.cpp:245]     Train net output #0: loss = 3.01287 (* 1 = 3.01287 loss)
I0605 03:48:53.925714   904 sgd_solver.cpp:106] Iteration 42040, lr = 0.0301082
I0605 03:49:15.200037   904 solver.cpp:229] Iteration 42080, loss = 3.03356
I0605 03:49:15.200156   904 solver.cpp:245]     Train net output #0: loss = 2.86302 (* 1 = 2.86302 loss)
I0605 03:49:15.200182   904 sgd_solver.cpp:106] Iteration 42080, lr = 0.0300988
I0605 03:49:36.575829   904 solver.cpp:229] Iteration 42120, loss = 3.01995
I0605 03:49:36.576043   904 solver.cpp:245]     Train net output #0: loss = 2.8482 (* 1 = 2.8482 loss)
I0605 03:49:36.576069   904 sgd_solver.cpp:106] Iteration 42120, lr = 0.0300894
I0605 03:49:57.514722   904 solver.cpp:229] Iteration 42160, loss = 3.01702
I0605 03:49:57.514761   904 solver.cpp:245]     Train net output #0: loss = 2.86765 (* 1 = 2.86765 loss)
I0605 03:49:57.514770   904 sgd_solver.cpp:106] Iteration 42160, lr = 0.03008
I0605 03:50:18.447201   904 solver.cpp:229] Iteration 42200, loss = 3.00207
I0605 03:50:18.447412   904 solver.cpp:245]     Train net output #0: loss = 3.14572 (* 1 = 3.14572 loss)
I0605 03:50:18.447423   904 sgd_solver.cpp:106] Iteration 42200, lr = 0.0300706
I0605 03:50:39.402113   904 solver.cpp:229] Iteration 42240, loss = 2.99685
I0605 03:50:39.402166   904 solver.cpp:245]     Train net output #0: loss = 3.37869 (* 1 = 3.37869 loss)
I0605 03:50:39.402178   904 sgd_solver.cpp:106] Iteration 42240, lr = 0.0300612
I0605 03:50:49.620501   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 03:51:00.180737   904 solver.cpp:229] Iteration 42280, loss = 3.02827
I0605 03:51:00.180791   904 solver.cpp:245]     Train net output #0: loss = 3.15861 (* 1 = 3.15861 loss)
I0605 03:51:00.180801   904 sgd_solver.cpp:106] Iteration 42280, lr = 0.0300518
I0605 03:51:20.645807   904 solver.cpp:229] Iteration 42320, loss = 3.03753
I0605 03:51:20.645918   904 solver.cpp:245]     Train net output #0: loss = 2.92097 (* 1 = 2.92097 loss)
I0605 03:51:20.645930   904 sgd_solver.cpp:106] Iteration 42320, lr = 0.0300424
I0605 03:51:41.114902   904 solver.cpp:229] Iteration 42360, loss = 3.02473
I0605 03:51:41.114955   904 solver.cpp:245]     Train net output #0: loss = 2.89572 (* 1 = 2.89572 loss)
I0605 03:51:41.114974   904 sgd_solver.cpp:106] Iteration 42360, lr = 0.0300329
I0605 03:52:01.331336   904 solver.cpp:229] Iteration 42400, loss = 3.00299
I0605 03:52:01.331540   904 solver.cpp:245]     Train net output #0: loss = 3.08253 (* 1 = 3.08253 loss)
I0605 03:52:01.331568   904 sgd_solver.cpp:106] Iteration 42400, lr = 0.0300235
I0605 03:52:21.316583   904 solver.cpp:229] Iteration 42440, loss = 3.03845
I0605 03:52:21.316629   904 solver.cpp:245]     Train net output #0: loss = 3.02765 (* 1 = 3.02765 loss)
I0605 03:52:21.316639   904 sgd_solver.cpp:106] Iteration 42440, lr = 0.0300141
I0605 03:52:41.288661   904 solver.cpp:229] Iteration 42480, loss = 3.04695
I0605 03:52:41.288875   904 solver.cpp:245]     Train net output #0: loss = 3.08815 (* 1 = 3.08815 loss)
I0605 03:52:41.288907   904 sgd_solver.cpp:106] Iteration 42480, lr = 0.0300047
I0605 03:53:01.277223   904 solver.cpp:229] Iteration 42520, loss = 3.00295
I0605 03:53:01.277264   904 solver.cpp:245]     Train net output #0: loss = 3.14696 (* 1 = 3.14696 loss)
I0605 03:53:01.277273   904 sgd_solver.cpp:106] Iteration 42520, lr = 0.0299953
I0605 03:53:21.255537   904 solver.cpp:229] Iteration 42560, loss = 3.03997
I0605 03:53:21.255688   904 solver.cpp:245]     Train net output #0: loss = 3.03896 (* 1 = 3.03896 loss)
I0605 03:53:21.255699   904 sgd_solver.cpp:106] Iteration 42560, lr = 0.0299859
I0605 03:53:41.233750   904 solver.cpp:229] Iteration 42600, loss = 3.01838
I0605 03:53:41.233790   904 solver.cpp:245]     Train net output #0: loss = 2.91464 (* 1 = 2.91464 loss)
I0605 03:53:41.233800   904 sgd_solver.cpp:106] Iteration 42600, lr = 0.0299765
I0605 03:54:01.190557   904 solver.cpp:229] Iteration 42640, loss = 3.00641
I0605 03:54:01.190717   904 solver.cpp:245]     Train net output #0: loss = 2.87855 (* 1 = 2.87855 loss)
I0605 03:54:01.190748   904 sgd_solver.cpp:106] Iteration 42640, lr = 0.0299671
I0605 03:54:21.310252   904 solver.cpp:229] Iteration 42680, loss = 2.99947
I0605 03:54:21.310302   904 solver.cpp:245]     Train net output #0: loss = 2.95146 (* 1 = 2.95146 loss)
I0605 03:54:21.310312   904 sgd_solver.cpp:106] Iteration 42680, lr = 0.0299576
I0605 03:54:42.102951   904 solver.cpp:229] Iteration 42720, loss = 3.03853
I0605 03:54:42.103126   904 solver.cpp:245]     Train net output #0: loss = 2.78324 (* 1 = 2.78324 loss)
I0605 03:54:42.103135   904 sgd_solver.cpp:106] Iteration 42720, lr = 0.0299482
I0605 03:55:02.175408   904 solver.cpp:229] Iteration 42760, loss = 3.0182
I0605 03:55:02.175472   904 solver.cpp:245]     Train net output #0: loss = 2.74554 (* 1 = 2.74554 loss)
I0605 03:55:02.175480   904 sgd_solver.cpp:106] Iteration 42760, lr = 0.0299388
I0605 03:55:22.304100   904 solver.cpp:229] Iteration 42800, loss = 3.03171
I0605 03:55:22.304435   904 solver.cpp:245]     Train net output #0: loss = 3.14736 (* 1 = 3.14736 loss)
I0605 03:55:22.304466   904 sgd_solver.cpp:106] Iteration 42800, lr = 0.0299294
I0605 03:55:38.910372   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 03:55:42.437700   904 solver.cpp:229] Iteration 42840, loss = 3.04595
I0605 03:55:42.437748   904 solver.cpp:245]     Train net output #0: loss = 3.03491 (* 1 = 3.03491 loss)
I0605 03:55:42.437760   904 sgd_solver.cpp:106] Iteration 42840, lr = 0.02992
I0605 03:56:02.589819   904 solver.cpp:229] Iteration 42880, loss = 3.01865
I0605 03:56:02.590061   904 solver.cpp:245]     Train net output #0: loss = 3.25915 (* 1 = 3.25915 loss)
I0605 03:56:02.590085   904 sgd_solver.cpp:106] Iteration 42880, lr = 0.0299106
I0605 03:56:22.753279   904 solver.cpp:229] Iteration 42920, loss = 2.99456
I0605 03:56:22.753340   904 solver.cpp:245]     Train net output #0: loss = 3.03133 (* 1 = 3.03133 loss)
I0605 03:56:22.753353   904 sgd_solver.cpp:106] Iteration 42920, lr = 0.0299012
I0605 03:56:42.920306   904 solver.cpp:229] Iteration 42960, loss = 3.00763
I0605 03:56:42.920451   904 solver.cpp:245]     Train net output #0: loss = 2.87966 (* 1 = 2.87966 loss)
I0605 03:56:42.920465   904 sgd_solver.cpp:106] Iteration 42960, lr = 0.0298918
I0605 03:57:02.647842   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_43000.caffemodel
I0605 03:57:02.912113   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_43000.solverstate
I0605 03:57:02.992920   904 solver.cpp:338] Iteration 43000, Testing net (#0)
I0605 03:57:02.992998   904 net.cpp:748] Ignoring source layer loss
I0605 03:57:26.003887   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 03:58:00.070329   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 03:58:10.865419   904 solver.cpp:406]     Test net output #0: accuracy = 0.363681
I0605 03:58:10.865463   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.614099
I0605 03:58:11.181455   904 solver.cpp:229] Iteration 43000, loss = 3.05087
I0605 03:58:11.181496   904 solver.cpp:245]     Train net output #0: loss = 2.70119 (* 1 = 2.70119 loss)
I0605 03:58:11.181509   904 sgd_solver.cpp:106] Iteration 43000, lr = 0.0298824
I0605 03:58:30.392799   904 solver.cpp:229] Iteration 43040, loss = 3.04928
I0605 03:58:30.393004   904 solver.cpp:245]     Train net output #0: loss = 3.10754 (* 1 = 3.10754 loss)
I0605 03:58:30.393030   904 sgd_solver.cpp:106] Iteration 43040, lr = 0.0298729
I0605 03:58:51.638119   904 solver.cpp:229] Iteration 43080, loss = 3.00636
I0605 03:58:51.638175   904 solver.cpp:245]     Train net output #0: loss = 2.96084 (* 1 = 2.96084 loss)
I0605 03:58:51.638185   904 sgd_solver.cpp:106] Iteration 43080, lr = 0.0298635
I0605 03:59:13.045271   904 solver.cpp:229] Iteration 43120, loss = 3.0458
I0605 03:59:13.045455   904 solver.cpp:245]     Train net output #0: loss = 2.93276 (* 1 = 2.93276 loss)
I0605 03:59:13.045485   904 sgd_solver.cpp:106] Iteration 43120, lr = 0.0298541
I0605 03:59:34.024893   904 solver.cpp:229] Iteration 43160, loss = 3.02972
I0605 03:59:34.024960   904 solver.cpp:245]     Train net output #0: loss = 2.76169 (* 1 = 2.76169 loss)
I0605 03:59:34.024969   904 sgd_solver.cpp:106] Iteration 43160, lr = 0.0298447
I0605 03:59:55.038936   904 solver.cpp:229] Iteration 43200, loss = 3.05511
I0605 03:59:55.039070   904 solver.cpp:245]     Train net output #0: loss = 3.26899 (* 1 = 3.26899 loss)
I0605 03:59:55.039080   904 sgd_solver.cpp:106] Iteration 43200, lr = 0.0298353
I0605 04:00:16.008211   904 solver.cpp:229] Iteration 43240, loss = 2.96762
I0605 04:00:16.008261   904 solver.cpp:245]     Train net output #0: loss = 3.03909 (* 1 = 3.03909 loss)
I0605 04:00:16.008270   904 sgd_solver.cpp:106] Iteration 43240, lr = 0.0298259
I0605 04:00:36.988379   904 solver.cpp:229] Iteration 43280, loss = 3.02011
I0605 04:00:36.988649   904 solver.cpp:245]     Train net output #0: loss = 3.38718 (* 1 = 3.38718 loss)
I0605 04:00:36.988672   904 sgd_solver.cpp:106] Iteration 43280, lr = 0.0298165
I0605 04:00:57.823078   904 solver.cpp:229] Iteration 43320, loss = 3.02293
I0605 04:00:57.823122   904 solver.cpp:245]     Train net output #0: loss = 2.96492 (* 1 = 2.96492 loss)
I0605 04:00:57.823132   904 sgd_solver.cpp:106] Iteration 43320, lr = 0.0298071
I0605 04:01:18.665145   904 solver.cpp:229] Iteration 43360, loss = 2.982
I0605 04:01:18.665366   904 solver.cpp:245]     Train net output #0: loss = 2.8757 (* 1 = 2.8757 loss)
I0605 04:01:18.665395   904 sgd_solver.cpp:106] Iteration 43360, lr = 0.0297976
I0605 04:01:21.528288   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 04:01:39.398478   904 solver.cpp:229] Iteration 43400, loss = 2.99366
I0605 04:01:39.398545   904 solver.cpp:245]     Train net output #0: loss = 2.81941 (* 1 = 2.81941 loss)
I0605 04:01:39.398555   904 sgd_solver.cpp:106] Iteration 43400, lr = 0.0297882
I0605 04:02:00.098551   904 solver.cpp:229] Iteration 43440, loss = 3.02599
I0605 04:02:00.098754   904 solver.cpp:245]     Train net output #0: loss = 3.14328 (* 1 = 3.14328 loss)
I0605 04:02:00.098779   904 sgd_solver.cpp:106] Iteration 43440, lr = 0.0297788
I0605 04:02:20.778188   904 solver.cpp:229] Iteration 43480, loss = 2.96289
I0605 04:02:20.778235   904 solver.cpp:245]     Train net output #0: loss = 3.07044 (* 1 = 3.07044 loss)
I0605 04:02:20.778244   904 sgd_solver.cpp:106] Iteration 43480, lr = 0.0297694
I0605 04:02:41.461539   904 solver.cpp:229] Iteration 43520, loss = 3.01451
I0605 04:02:41.461716   904 solver.cpp:245]     Train net output #0: loss = 3.05357 (* 1 = 3.05357 loss)
I0605 04:02:41.461726   904 sgd_solver.cpp:106] Iteration 43520, lr = 0.02976
I0605 04:03:02.168272   904 solver.cpp:229] Iteration 43560, loss = 2.98454
I0605 04:03:02.168325   904 solver.cpp:245]     Train net output #0: loss = 2.90037 (* 1 = 2.90037 loss)
I0605 04:03:02.168339   904 sgd_solver.cpp:106] Iteration 43560, lr = 0.0297506
I0605 04:03:22.751566   904 solver.cpp:229] Iteration 43600, loss = 3.03108
I0605 04:03:22.751744   904 solver.cpp:245]     Train net output #0: loss = 3.14074 (* 1 = 3.14074 loss)
I0605 04:03:22.751767   904 sgd_solver.cpp:106] Iteration 43600, lr = 0.0297412
I0605 04:03:43.406513   904 solver.cpp:229] Iteration 43640, loss = 2.9912
I0605 04:03:43.406565   904 solver.cpp:245]     Train net output #0: loss = 3.1411 (* 1 = 3.1411 loss)
I0605 04:03:43.406574   904 sgd_solver.cpp:106] Iteration 43640, lr = 0.0297318
I0605 04:04:04.008415   904 solver.cpp:229] Iteration 43680, loss = 3.03392
I0605 04:04:04.008611   904 solver.cpp:245]     Train net output #0: loss = 3.05609 (* 1 = 3.05609 loss)
I0605 04:04:04.008641   904 sgd_solver.cpp:106] Iteration 43680, lr = 0.0297224
I0605 04:04:24.519513   904 solver.cpp:229] Iteration 43720, loss = 3.03826
I0605 04:04:24.519561   904 solver.cpp:245]     Train net output #0: loss = 2.87759 (* 1 = 2.87759 loss)
I0605 04:04:24.519570   904 sgd_solver.cpp:106] Iteration 43720, lr = 0.0297129
I0605 04:04:45.119252   904 solver.cpp:229] Iteration 43760, loss = 2.99275
I0605 04:04:45.119451   904 solver.cpp:245]     Train net output #0: loss = 2.97811 (* 1 = 2.97811 loss)
I0605 04:04:45.119472   904 sgd_solver.cpp:106] Iteration 43760, lr = 0.0297035
I0605 04:05:05.786670   904 solver.cpp:229] Iteration 43800, loss = 3.00935
I0605 04:05:05.786718   904 solver.cpp:245]     Train net output #0: loss = 3.17491 (* 1 = 3.17491 loss)
I0605 04:05:05.786727   904 sgd_solver.cpp:106] Iteration 43800, lr = 0.0296941
I0605 04:05:26.108407   904 solver.cpp:229] Iteration 43840, loss = 2.98814
I0605 04:05:26.108568   904 solver.cpp:245]     Train net output #0: loss = 2.95725 (* 1 = 2.95725 loss)
I0605 04:05:26.108578   904 sgd_solver.cpp:106] Iteration 43840, lr = 0.0296847
I0605 04:05:46.531370   904 solver.cpp:229] Iteration 43880, loss = 3.01079
I0605 04:05:46.531419   904 solver.cpp:245]     Train net output #0: loss = 3.22564 (* 1 = 3.22564 loss)
I0605 04:05:46.531427   904 sgd_solver.cpp:106] Iteration 43880, lr = 0.0296753
I0605 04:05:54.218278   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 04:06:07.035573   904 solver.cpp:229] Iteration 43920, loss = 3.01448
I0605 04:06:07.035784   904 solver.cpp:245]     Train net output #0: loss = 3.45115 (* 1 = 3.45115 loss)
I0605 04:06:07.035800   904 sgd_solver.cpp:106] Iteration 43920, lr = 0.0296659
I0605 04:06:27.520897   904 solver.cpp:229] Iteration 43960, loss = 3.04623
I0605 04:06:27.520948   904 solver.cpp:245]     Train net output #0: loss = 3.10961 (* 1 = 3.10961 loss)
I0605 04:06:27.520959   904 sgd_solver.cpp:106] Iteration 43960, lr = 0.0296565
I0605 04:06:47.525883   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_44000.caffemodel
I0605 04:06:47.792124   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_44000.solverstate
I0605 04:06:47.867849   904 solver.cpp:338] Iteration 44000, Testing net (#0)
I0605 04:06:47.867941   904 net.cpp:748] Ignoring source layer loss
I0605 04:07:16.980559   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 04:07:50.606674   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 04:07:55.854393   904 solver.cpp:406]     Test net output #0: accuracy = 0.379301
I0605 04:07:55.854446   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.633539
I0605 04:07:56.168948   904 solver.cpp:229] Iteration 44000, loss = 3.00557
I0605 04:07:56.169003   904 solver.cpp:245]     Train net output #0: loss = 2.7622 (* 1 = 2.7622 loss)
I0605 04:07:56.169014   904 sgd_solver.cpp:106] Iteration 44000, lr = 0.0296471
I0605 04:08:15.337285   904 solver.cpp:229] Iteration 44040, loss = 2.9576
I0605 04:08:15.337335   904 solver.cpp:245]     Train net output #0: loss = 3.0592 (* 1 = 3.0592 loss)
I0605 04:08:15.337344   904 sgd_solver.cpp:106] Iteration 44040, lr = 0.0296376
I0605 04:08:36.738734   904 solver.cpp:229] Iteration 44080, loss = 3.00863
I0605 04:08:36.738943   904 solver.cpp:245]     Train net output #0: loss = 3.09562 (* 1 = 3.09562 loss)
I0605 04:08:36.738966   904 sgd_solver.cpp:106] Iteration 44080, lr = 0.0296282
I0605 04:08:58.220244   904 solver.cpp:229] Iteration 44120, loss = 2.99537
I0605 04:08:58.220300   904 solver.cpp:245]     Train net output #0: loss = 2.95585 (* 1 = 2.95585 loss)
I0605 04:08:58.220312   904 sgd_solver.cpp:106] Iteration 44120, lr = 0.0296188
I0605 04:09:19.262909   904 solver.cpp:229] Iteration 44160, loss = 3.02089
I0605 04:09:19.263065   904 solver.cpp:245]     Train net output #0: loss = 3.05072 (* 1 = 3.05072 loss)
I0605 04:09:19.263075   904 sgd_solver.cpp:106] Iteration 44160, lr = 0.0296094
I0605 04:09:40.202885   904 solver.cpp:229] Iteration 44200, loss = 2.98696
I0605 04:09:40.202936   904 solver.cpp:245]     Train net output #0: loss = 3.28494 (* 1 = 3.28494 loss)
I0605 04:09:40.202956   904 sgd_solver.cpp:106] Iteration 44200, lr = 0.0296
I0605 04:10:01.122611   904 solver.cpp:229] Iteration 44240, loss = 3.00968
I0605 04:10:01.122818   904 solver.cpp:245]     Train net output #0: loss = 3.12313 (* 1 = 3.12313 loss)
I0605 04:10:01.122840   904 sgd_solver.cpp:106] Iteration 44240, lr = 0.0295906
I0605 04:10:22.053025   904 solver.cpp:229] Iteration 44280, loss = 3.00172
I0605 04:10:22.053071   904 solver.cpp:245]     Train net output #0: loss = 2.85932 (* 1 = 2.85932 loss)
I0605 04:10:22.053092   904 sgd_solver.cpp:106] Iteration 44280, lr = 0.0295812
I0605 04:10:42.879953   904 solver.cpp:229] Iteration 44320, loss = 3.02096
I0605 04:10:42.880187   904 solver.cpp:245]     Train net output #0: loss = 3.00721 (* 1 = 3.00721 loss)
I0605 04:10:42.880211   904 sgd_solver.cpp:106] Iteration 44320, lr = 0.0295718
I0605 04:11:03.892185   904 solver.cpp:229] Iteration 44360, loss = 2.9934
I0605 04:11:03.892225   904 solver.cpp:245]     Train net output #0: loss = 3.05548 (* 1 = 3.05548 loss)
I0605 04:11:03.892233   904 sgd_solver.cpp:106] Iteration 44360, lr = 0.0295624
I0605 04:11:24.451164   904 solver.cpp:229] Iteration 44400, loss = 3.00184
I0605 04:11:24.451375   904 solver.cpp:245]     Train net output #0: loss = 2.96792 (* 1 = 2.96792 loss)
I0605 04:11:24.451398   904 sgd_solver.cpp:106] Iteration 44400, lr = 0.0295529
I0605 04:11:45.057579   904 solver.cpp:229] Iteration 44440, loss = 2.98782
I0605 04:11:45.057615   904 solver.cpp:245]     Train net output #0: loss = 2.79519 (* 1 = 2.79519 loss)
I0605 04:11:45.057621   904 sgd_solver.cpp:106] Iteration 44440, lr = 0.0295435
I0605 04:11:49.951279   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 04:12:05.629729   904 solver.cpp:229] Iteration 44480, loss = 2.99425
I0605 04:12:05.629987   904 solver.cpp:245]     Train net output #0: loss = 2.86868 (* 1 = 2.86868 loss)
I0605 04:12:05.630014   904 sgd_solver.cpp:106] Iteration 44480, lr = 0.0295341
I0605 04:12:26.977156   904 solver.cpp:229] Iteration 44520, loss = 2.97076
I0605 04:12:26.977203   904 solver.cpp:245]     Train net output #0: loss = 2.88801 (* 1 = 2.88801 loss)
I0605 04:12:26.977215   904 sgd_solver.cpp:106] Iteration 44520, lr = 0.0295247
I0605 04:12:47.632907   904 solver.cpp:229] Iteration 44560, loss = 3.04247
I0605 04:12:47.633054   904 solver.cpp:245]     Train net output #0: loss = 3.09213 (* 1 = 3.09213 loss)
I0605 04:12:47.633064   904 sgd_solver.cpp:106] Iteration 44560, lr = 0.0295153
I0605 04:13:08.078011   904 solver.cpp:229] Iteration 44600, loss = 2.97304
I0605 04:13:08.078063   904 solver.cpp:245]     Train net output #0: loss = 2.94576 (* 1 = 2.94576 loss)
I0605 04:13:08.078073   904 sgd_solver.cpp:106] Iteration 44600, lr = 0.0295059
I0605 04:13:28.660362   904 solver.cpp:229] Iteration 44640, loss = 3.00069
I0605 04:13:28.660569   904 solver.cpp:245]     Train net output #0: loss = 2.84126 (* 1 = 2.84126 loss)
I0605 04:13:28.660598   904 sgd_solver.cpp:106] Iteration 44640, lr = 0.0294965
I0605 04:13:49.018201   904 solver.cpp:229] Iteration 44680, loss = 2.97897
I0605 04:13:49.018240   904 solver.cpp:245]     Train net output #0: loss = 3.12826 (* 1 = 3.12826 loss)
I0605 04:13:49.018261   904 sgd_solver.cpp:106] Iteration 44680, lr = 0.0294871
I0605 04:14:09.462790   904 solver.cpp:229] Iteration 44720, loss = 3.02676
I0605 04:14:09.462983   904 solver.cpp:245]     Train net output #0: loss = 2.93204 (* 1 = 2.93204 loss)
I0605 04:14:09.463013   904 sgd_solver.cpp:106] Iteration 44720, lr = 0.0294776
I0605 04:14:29.702402   904 solver.cpp:229] Iteration 44760, loss = 2.96024
I0605 04:14:29.702453   904 solver.cpp:245]     Train net output #0: loss = 2.95506 (* 1 = 2.95506 loss)
I0605 04:14:29.702461   904 sgd_solver.cpp:106] Iteration 44760, lr = 0.0294682
I0605 04:14:49.805012   904 solver.cpp:229] Iteration 44800, loss = 3.01723
I0605 04:14:49.816411   904 solver.cpp:245]     Train net output #0: loss = 3.21115 (* 1 = 3.21115 loss)
I0605 04:14:49.816422   904 sgd_solver.cpp:106] Iteration 44800, lr = 0.0294588
I0605 04:15:10.028693   904 solver.cpp:229] Iteration 44840, loss = 3.01842
I0605 04:15:10.028729   904 solver.cpp:245]     Train net output #0: loss = 3.08753 (* 1 = 3.08753 loss)
I0605 04:15:10.028738   904 sgd_solver.cpp:106] Iteration 44840, lr = 0.0294494
I0605 04:15:30.226436   904 solver.cpp:229] Iteration 44880, loss = 2.9237
I0605 04:15:30.226651   904 solver.cpp:245]     Train net output #0: loss = 2.91025 (* 1 = 2.91025 loss)
I0605 04:15:30.226675   904 sgd_solver.cpp:106] Iteration 44880, lr = 0.02944
I0605 04:15:50.410812   904 solver.cpp:229] Iteration 44920, loss = 3.01145
I0605 04:15:50.410868   904 solver.cpp:245]     Train net output #0: loss = 2.79851 (* 1 = 2.79851 loss)
I0605 04:15:50.410879   904 sgd_solver.cpp:106] Iteration 44920, lr = 0.0294306
I0605 04:16:10.569638   904 solver.cpp:229] Iteration 44960, loss = 2.97653
I0605 04:16:10.569854   904 solver.cpp:245]     Train net output #0: loss = 2.89975 (* 1 = 2.89975 loss)
I0605 04:16:10.569880   904 sgd_solver.cpp:106] Iteration 44960, lr = 0.0294212
I0605 04:16:30.160650   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_45000.caffemodel
I0605 04:16:30.418318   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_45000.solverstate
I0605 04:16:30.497603   904 solver.cpp:338] Iteration 45000, Testing net (#0)
I0605 04:16:30.497683   904 net.cpp:748] Ignoring source layer loss
I0605 04:16:31.691332   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 04:17:07.673652   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 04:17:39.714540   904 solver.cpp:406]     Test net output #0: accuracy = 0.366501
I0605 04:17:39.714690   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.61646
I0605 04:17:40.029140   904 solver.cpp:229] Iteration 45000, loss = 3.02498
I0605 04:17:40.029176   904 solver.cpp:245]     Train net output #0: loss = 2.78728 (* 1 = 2.78728 loss)
I0605 04:17:40.029186   904 sgd_solver.cpp:106] Iteration 45000, lr = 0.0294118
I0605 04:17:48.906147   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 04:17:59.249343   904 solver.cpp:229] Iteration 45040, loss = 3.02056
I0605 04:17:59.249388   904 solver.cpp:245]     Train net output #0: loss = 3.20538 (* 1 = 3.20538 loss)
I0605 04:17:59.249398   904 sgd_solver.cpp:106] Iteration 45040, lr = 0.0294024
I0605 04:18:20.618643   904 solver.cpp:229] Iteration 45080, loss = 3.01126
I0605 04:18:20.618774   904 solver.cpp:245]     Train net output #0: loss = 2.95233 (* 1 = 2.95233 loss)
I0605 04:18:20.618784   904 sgd_solver.cpp:106] Iteration 45080, lr = 0.0293929
I0605 04:18:42.130138   904 solver.cpp:229] Iteration 45120, loss = 2.9793
I0605 04:18:42.130185   904 solver.cpp:245]     Train net output #0: loss = 3.1041 (* 1 = 3.1041 loss)
I0605 04:18:42.130193   904 sgd_solver.cpp:106] Iteration 45120, lr = 0.0293835
I0605 04:19:03.283326   904 solver.cpp:229] Iteration 45160, loss = 2.99851
I0605 04:19:03.283524   904 solver.cpp:245]     Train net output #0: loss = 2.93816 (* 1 = 2.93816 loss)
I0605 04:19:03.283548   904 sgd_solver.cpp:106] Iteration 45160, lr = 0.0293741
I0605 04:19:24.259436   904 solver.cpp:229] Iteration 45200, loss = 3.01966
I0605 04:19:24.259485   904 solver.cpp:245]     Train net output #0: loss = 3.17791 (* 1 = 3.17791 loss)
I0605 04:19:24.259496   904 sgd_solver.cpp:106] Iteration 45200, lr = 0.0293647
I0605 04:19:45.218293   904 solver.cpp:229] Iteration 45240, loss = 2.97559
I0605 04:19:45.218400   904 solver.cpp:245]     Train net output #0: loss = 2.94873 (* 1 = 2.94873 loss)
I0605 04:19:45.218412   904 sgd_solver.cpp:106] Iteration 45240, lr = 0.0293553
I0605 04:20:06.178077   904 solver.cpp:229] Iteration 45280, loss = 2.99385
I0605 04:20:06.178130   904 solver.cpp:245]     Train net output #0: loss = 2.98056 (* 1 = 2.98056 loss)
I0605 04:20:06.178139   904 sgd_solver.cpp:106] Iteration 45280, lr = 0.0293459
I0605 04:20:27.056253   904 solver.cpp:229] Iteration 45320, loss = 3.00511
I0605 04:20:27.056370   904 solver.cpp:245]     Train net output #0: loss = 2.99341 (* 1 = 2.99341 loss)
I0605 04:20:27.056386   904 sgd_solver.cpp:106] Iteration 45320, lr = 0.0293365
I0605 04:20:47.734232   904 solver.cpp:229] Iteration 45360, loss = 3.00331
I0605 04:20:47.734294   904 solver.cpp:245]     Train net output #0: loss = 2.95315 (* 1 = 2.95315 loss)
I0605 04:20:47.734305   904 sgd_solver.cpp:106] Iteration 45360, lr = 0.0293271
I0605 04:21:08.412288   904 solver.cpp:229] Iteration 45400, loss = 2.97168
I0605 04:21:08.412482   904 solver.cpp:245]     Train net output #0: loss = 2.89449 (* 1 = 2.89449 loss)
I0605 04:21:08.412508   904 sgd_solver.cpp:106] Iteration 45400, lr = 0.0293176
I0605 04:21:29.077285   904 solver.cpp:229] Iteration 45440, loss = 2.96554
I0605 04:21:29.077332   904 solver.cpp:245]     Train net output #0: loss = 2.98002 (* 1 = 2.98002 loss)
I0605 04:21:29.077340   904 sgd_solver.cpp:106] Iteration 45440, lr = 0.0293082
I0605 04:21:49.676172   904 solver.cpp:229] Iteration 45480, loss = 3.00815
I0605 04:21:49.676404   904 solver.cpp:245]     Train net output #0: loss = 3.07371 (* 1 = 3.07371 loss)
I0605 04:21:49.676432   904 sgd_solver.cpp:106] Iteration 45480, lr = 0.0292988
I0605 04:22:10.185935   904 solver.cpp:229] Iteration 45520, loss = 3.02517
I0605 04:22:10.185977   904 solver.cpp:245]     Train net output #0: loss = 2.89628 (* 1 = 2.89628 loss)
I0605 04:22:10.185983   904 sgd_solver.cpp:106] Iteration 45520, lr = 0.0292894
I0605 04:22:30.702901   904 solver.cpp:229] Iteration 45560, loss = 2.97575
I0605 04:22:30.703151   904 solver.cpp:245]     Train net output #0: loss = 2.94634 (* 1 = 2.94634 loss)
I0605 04:22:30.703177   904 sgd_solver.cpp:106] Iteration 45560, lr = 0.02928
I0605 04:22:30.705822   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 04:22:51.238195   904 solver.cpp:229] Iteration 45600, loss = 2.96195
I0605 04:22:51.238239   904 solver.cpp:245]     Train net output #0: loss = 3.10306 (* 1 = 3.10306 loss)
I0605 04:22:51.238248   904 sgd_solver.cpp:106] Iteration 45600, lr = 0.0292706
I0605 04:23:11.746594   904 solver.cpp:229] Iteration 45640, loss = 3.00184
I0605 04:23:11.746801   904 solver.cpp:245]     Train net output #0: loss = 3.08832 (* 1 = 3.08832 loss)
I0605 04:23:11.746824   904 sgd_solver.cpp:106] Iteration 45640, lr = 0.0292612
I0605 04:23:32.256409   904 solver.cpp:229] Iteration 45680, loss = 3.00489
I0605 04:23:32.256448   904 solver.cpp:245]     Train net output #0: loss = 2.85379 (* 1 = 2.85379 loss)
I0605 04:23:32.256456   904 sgd_solver.cpp:106] Iteration 45680, lr = 0.0292518
I0605 04:23:52.573631   904 solver.cpp:229] Iteration 45720, loss = 3.03067
I0605 04:23:52.573818   904 solver.cpp:245]     Train net output #0: loss = 3.0056 (* 1 = 3.0056 loss)
I0605 04:23:52.573844   904 sgd_solver.cpp:106] Iteration 45720, lr = 0.0292424
I0605 04:24:12.852020   904 solver.cpp:229] Iteration 45760, loss = 2.9814
I0605 04:24:12.852069   904 solver.cpp:245]     Train net output #0: loss = 2.85765 (* 1 = 2.85765 loss)
I0605 04:24:12.852079   904 sgd_solver.cpp:106] Iteration 45760, lr = 0.0292329
I0605 04:24:33.139219   904 solver.cpp:229] Iteration 45800, loss = 3.02538
I0605 04:24:33.139415   904 solver.cpp:245]     Train net output #0: loss = 3.09621 (* 1 = 3.09621 loss)
I0605 04:24:33.139433   904 sgd_solver.cpp:106] Iteration 45800, lr = 0.0292235
I0605 04:24:53.415243   904 solver.cpp:229] Iteration 45840, loss = 3.03715
I0605 04:24:53.415292   904 solver.cpp:245]     Train net output #0: loss = 3.05497 (* 1 = 3.05497 loss)
I0605 04:24:53.415302   904 sgd_solver.cpp:106] Iteration 45840, lr = 0.0292141
I0605 04:25:13.703240   904 solver.cpp:229] Iteration 45880, loss = 2.9535
I0605 04:25:13.703398   904 solver.cpp:245]     Train net output #0: loss = 2.90201 (* 1 = 2.90201 loss)
I0605 04:25:13.703423   904 sgd_solver.cpp:106] Iteration 45880, lr = 0.0292047
I0605 04:25:33.986747   904 solver.cpp:229] Iteration 45920, loss = 2.95841
I0605 04:25:33.986802   904 solver.cpp:245]     Train net output #0: loss = 2.97066 (* 1 = 2.97066 loss)
I0605 04:25:33.986814   904 sgd_solver.cpp:106] Iteration 45920, lr = 0.0291953
I0605 04:25:54.258657   904 solver.cpp:229] Iteration 45960, loss = 2.97948
I0605 04:25:54.258893   904 solver.cpp:245]     Train net output #0: loss = 2.79167 (* 1 = 2.79167 loss)
I0605 04:25:54.258919   904 sgd_solver.cpp:106] Iteration 45960, lr = 0.0291859
I0605 04:26:13.972863   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_46000.caffemodel
I0605 04:26:14.239329   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_46000.solverstate
I0605 04:26:14.308730   904 solver.cpp:338] Iteration 46000, Testing net (#0)
I0605 04:26:14.308800   904 net.cpp:748] Ignoring source layer loss
I0605 04:26:18.761567   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 04:26:53.307909   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 04:27:22.999873   904 solver.cpp:406]     Test net output #0: accuracy = 0.372521
I0605 04:27:22.999914   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.624319
I0605 04:27:23.313335   904 solver.cpp:229] Iteration 46000, loss = 2.96114
I0605 04:27:23.313518   904 solver.cpp:245]     Train net output #0: loss = 3.01365 (* 1 = 3.01365 loss)
I0605 04:27:23.313544   904 sgd_solver.cpp:106] Iteration 46000, lr = 0.0291765
I0605 04:27:42.541914   904 solver.cpp:229] Iteration 46040, loss = 2.98137
I0605 04:27:42.541952   904 solver.cpp:245]     Train net output #0: loss = 2.98725 (* 1 = 2.98725 loss)
I0605 04:27:42.541960   904 sgd_solver.cpp:106] Iteration 46040, lr = 0.0291671
I0605 04:27:56.811882   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 04:28:03.823570   904 solver.cpp:229] Iteration 46080, loss = 2.97057
I0605 04:28:03.823603   904 solver.cpp:245]     Train net output #0: loss = 2.95036 (* 1 = 2.95036 loss)
I0605 04:28:03.823611   904 sgd_solver.cpp:106] Iteration 46080, lr = 0.0291576
I0605 04:28:25.063746   904 solver.cpp:229] Iteration 46120, loss = 2.96179
I0605 04:28:25.063791   904 solver.cpp:245]     Train net output #0: loss = 3.03356 (* 1 = 3.03356 loss)
I0605 04:28:25.063799   904 sgd_solver.cpp:106] Iteration 46120, lr = 0.0291482
I0605 04:28:45.934020   904 solver.cpp:229] Iteration 46160, loss = 2.95512
I0605 04:28:45.934186   904 solver.cpp:245]     Train net output #0: loss = 2.91171 (* 1 = 2.91171 loss)
I0605 04:28:45.934212   904 sgd_solver.cpp:106] Iteration 46160, lr = 0.0291388
I0605 04:29:06.752360   904 solver.cpp:229] Iteration 46200, loss = 2.99952
I0605 04:29:06.752444   904 solver.cpp:245]     Train net output #0: loss = 2.97352 (* 1 = 2.97352 loss)
I0605 04:29:06.752455   904 sgd_solver.cpp:106] Iteration 46200, lr = 0.0291294
I0605 04:29:27.608114   904 solver.cpp:229] Iteration 46240, loss = 3.01166
I0605 04:29:27.608258   904 solver.cpp:245]     Train net output #0: loss = 2.80405 (* 1 = 2.80405 loss)
I0605 04:29:27.608270   904 sgd_solver.cpp:106] Iteration 46240, lr = 0.02912
I0605 04:29:48.436256   904 solver.cpp:229] Iteration 46280, loss = 2.97085
I0605 04:29:48.436311   904 solver.cpp:245]     Train net output #0: loss = 3.12014 (* 1 = 3.12014 loss)
I0605 04:29:48.436321   904 sgd_solver.cpp:106] Iteration 46280, lr = 0.0291106
I0605 04:30:09.259985   904 solver.cpp:229] Iteration 46320, loss = 2.98033
I0605 04:30:09.260123   904 solver.cpp:245]     Train net output #0: loss = 3.11341 (* 1 = 3.11341 loss)
I0605 04:30:09.260140   904 sgd_solver.cpp:106] Iteration 46320, lr = 0.0291012
I0605 04:30:29.945588   904 solver.cpp:229] Iteration 46360, loss = 2.94962
I0605 04:30:29.945629   904 solver.cpp:245]     Train net output #0: loss = 3.05844 (* 1 = 3.05844 loss)
I0605 04:30:29.945637   904 sgd_solver.cpp:106] Iteration 46360, lr = 0.0290918
I0605 04:30:50.641711   904 solver.cpp:229] Iteration 46400, loss = 3.01578
I0605 04:30:50.641865   904 solver.cpp:245]     Train net output #0: loss = 2.98121 (* 1 = 2.98121 loss)
I0605 04:30:50.641892   904 sgd_solver.cpp:106] Iteration 46400, lr = 0.0290824
I0605 04:31:11.321998   904 solver.cpp:229] Iteration 46440, loss = 2.996
I0605 04:31:11.322048   904 solver.cpp:245]     Train net output #0: loss = 3.11683 (* 1 = 3.11683 loss)
I0605 04:31:11.322057   904 sgd_solver.cpp:106] Iteration 46440, lr = 0.0290729
I0605 04:31:32.002522   904 solver.cpp:229] Iteration 46480, loss = 3.02588
I0605 04:31:32.002691   904 solver.cpp:245]     Train net output #0: loss = 2.82101 (* 1 = 2.82101 loss)
I0605 04:31:32.002703   904 sgd_solver.cpp:106] Iteration 46480, lr = 0.0290635
I0605 04:31:52.678294   904 solver.cpp:229] Iteration 46520, loss = 3.02174
I0605 04:31:52.678344   904 solver.cpp:245]     Train net output #0: loss = 2.80367 (* 1 = 2.80367 loss)
I0605 04:31:52.678356   904 sgd_solver.cpp:106] Iteration 46520, lr = 0.0290541
I0605 04:32:13.372851   904 solver.cpp:229] Iteration 46560, loss = 2.97253
I0605 04:32:13.373070   904 solver.cpp:245]     Train net output #0: loss = 2.90186 (* 1 = 2.90186 loss)
I0605 04:32:13.373093   904 sgd_solver.cpp:106] Iteration 46560, lr = 0.0290447
I0605 04:32:18.029289   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 04:32:34.057817   904 solver.cpp:229] Iteration 46600, loss = 3.00772
I0605 04:32:34.057867   904 solver.cpp:245]     Train net output #0: loss = 3.37946 (* 1 = 3.37946 loss)
I0605 04:32:34.057878   904 sgd_solver.cpp:106] Iteration 46600, lr = 0.0290353
I0605 04:32:54.673467   904 solver.cpp:229] Iteration 46640, loss = 2.94366
I0605 04:32:54.673714   904 solver.cpp:245]     Train net output #0: loss = 2.97732 (* 1 = 2.97732 loss)
I0605 04:32:54.673745   904 sgd_solver.cpp:106] Iteration 46640, lr = 0.0290259
I0605 04:33:15.171118   904 solver.cpp:229] Iteration 46680, loss = 2.97793
I0605 04:33:15.171174   904 solver.cpp:245]     Train net output #0: loss = 2.99548 (* 1 = 2.99548 loss)
I0605 04:33:15.171180   904 sgd_solver.cpp:106] Iteration 46680, lr = 0.0290165
I0605 04:33:35.721839   904 solver.cpp:229] Iteration 46720, loss = 2.99918
I0605 04:33:35.721984   904 solver.cpp:245]     Train net output #0: loss = 2.94633 (* 1 = 2.94633 loss)
I0605 04:33:35.721993   904 sgd_solver.cpp:106] Iteration 46720, lr = 0.0290071
I0605 04:33:56.380108   904 solver.cpp:229] Iteration 46760, loss = 2.95624
I0605 04:33:56.380156   904 solver.cpp:245]     Train net output #0: loss = 3.0885 (* 1 = 3.0885 loss)
I0605 04:33:56.380167   904 sgd_solver.cpp:106] Iteration 46760, lr = 0.0289976
I0605 04:34:16.917529   904 solver.cpp:229] Iteration 46800, loss = 2.94115
I0605 04:34:16.917698   904 solver.cpp:245]     Train net output #0: loss = 3.03967 (* 1 = 3.03967 loss)
I0605 04:34:16.917714   904 sgd_solver.cpp:106] Iteration 46800, lr = 0.0289882
I0605 04:34:37.432410   904 solver.cpp:229] Iteration 46840, loss = 2.95214
I0605 04:34:37.432464   904 solver.cpp:245]     Train net output #0: loss = 3.03115 (* 1 = 3.03115 loss)
I0605 04:34:37.432477   904 sgd_solver.cpp:106] Iteration 46840, lr = 0.0289788
I0605 04:34:57.940829   904 solver.cpp:229] Iteration 46880, loss = 2.93027
I0605 04:34:57.941025   904 solver.cpp:245]     Train net output #0: loss = 3.0149 (* 1 = 3.0149 loss)
I0605 04:34:57.941051   904 sgd_solver.cpp:106] Iteration 46880, lr = 0.0289694
I0605 04:35:18.462625   904 solver.cpp:229] Iteration 46920, loss = 2.95479
I0605 04:35:18.462661   904 solver.cpp:245]     Train net output #0: loss = 2.95436 (* 1 = 2.95436 loss)
I0605 04:35:18.462669   904 sgd_solver.cpp:106] Iteration 46920, lr = 0.02896
I0605 04:35:38.985627   904 solver.cpp:229] Iteration 46960, loss = 2.96795
I0605 04:35:38.985832   904 solver.cpp:245]     Train net output #0: loss = 3.17112 (* 1 = 3.17112 loss)
I0605 04:35:38.985857   904 sgd_solver.cpp:106] Iteration 46960, lr = 0.0289506
I0605 04:35:59.007652   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_47000.caffemodel
I0605 04:35:59.269690   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_47000.solverstate
I0605 04:35:59.346786   904 solver.cpp:338] Iteration 47000, Testing net (#0)
I0605 04:35:59.346863   904 net.cpp:748] Ignoring source layer loss
I0605 04:36:04.998390   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 04:36:38.028000   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 04:37:05.460486   904 solver.cpp:406]     Test net output #0: accuracy = 0.381642
I0605 04:37:05.460522   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.63374
I0605 04:37:05.776724   904 solver.cpp:229] Iteration 47000, loss = 2.94949
I0605 04:37:05.776768   904 solver.cpp:245]     Train net output #0: loss = 2.82275 (* 1 = 2.82275 loss)
I0605 04:37:05.776780   904 sgd_solver.cpp:106] Iteration 47000, lr = 0.0289412
I0605 04:37:25.041188   904 solver.cpp:229] Iteration 47040, loss = 2.94488
I0605 04:37:25.041391   904 solver.cpp:245]     Train net output #0: loss = 2.98527 (* 1 = 2.98527 loss)
I0605 04:37:25.041416   904 sgd_solver.cpp:106] Iteration 47040, lr = 0.0289318
I0605 04:37:46.495673   904 solver.cpp:229] Iteration 47080, loss = 2.96585
I0605 04:37:46.495735   904 solver.cpp:245]     Train net output #0: loss = 2.91022 (* 1 = 2.91022 loss)
I0605 04:37:46.495744   904 sgd_solver.cpp:106] Iteration 47080, lr = 0.0289224
I0605 04:37:50.539197   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 04:38:08.005736   904 solver.cpp:229] Iteration 47120, loss = 2.94646
I0605 04:38:08.006027   904 solver.cpp:245]     Train net output #0: loss = 3.04363 (* 1 = 3.04363 loss)
I0605 04:38:08.006059   904 sgd_solver.cpp:106] Iteration 47120, lr = 0.0289129
I0605 04:38:29.369102   904 solver.cpp:229] Iteration 47160, loss = 2.99731
I0605 04:38:29.369143   904 solver.cpp:245]     Train net output #0: loss = 3.01247 (* 1 = 3.01247 loss)
I0605 04:38:29.369153   904 sgd_solver.cpp:106] Iteration 47160, lr = 0.0289035
I0605 04:38:50.354318   904 solver.cpp:229] Iteration 47200, loss = 3.01835
I0605 04:38:50.354526   904 solver.cpp:245]     Train net output #0: loss = 3.09468 (* 1 = 3.09468 loss)
I0605 04:38:50.354552   904 sgd_solver.cpp:106] Iteration 47200, lr = 0.0288941
I0605 04:39:11.329110   904 solver.cpp:229] Iteration 47240, loss = 2.9653
I0605 04:39:11.329155   904 solver.cpp:245]     Train net output #0: loss = 2.78843 (* 1 = 2.78843 loss)
I0605 04:39:11.329175   904 sgd_solver.cpp:106] Iteration 47240, lr = 0.0288847
I0605 04:39:32.318059   904 solver.cpp:229] Iteration 47280, loss = 2.96361
I0605 04:39:32.318240   904 solver.cpp:245]     Train net output #0: loss = 3.09206 (* 1 = 3.09206 loss)
I0605 04:39:32.318265   904 sgd_solver.cpp:106] Iteration 47280, lr = 0.0288753
I0605 04:39:53.289600   904 solver.cpp:229] Iteration 47320, loss = 2.99545
I0605 04:39:53.289667   904 solver.cpp:245]     Train net output #0: loss = 2.8871 (* 1 = 2.8871 loss)
I0605 04:39:53.289677   904 sgd_solver.cpp:106] Iteration 47320, lr = 0.0288659
I0605 04:40:14.235355   904 solver.cpp:229] Iteration 47360, loss = 2.95436
I0605 04:40:14.235478   904 solver.cpp:245]     Train net output #0: loss = 2.77345 (* 1 = 2.77345 loss)
I0605 04:40:14.235488   904 sgd_solver.cpp:106] Iteration 47360, lr = 0.0288565
I0605 04:40:35.026342   904 solver.cpp:229] Iteration 47400, loss = 2.93448
I0605 04:40:35.026404   904 solver.cpp:245]     Train net output #0: loss = 2.88878 (* 1 = 2.88878 loss)
I0605 04:40:35.026423   904 sgd_solver.cpp:106] Iteration 47400, lr = 0.0288471
I0605 04:40:55.693640   904 solver.cpp:229] Iteration 47440, loss = 2.95709
I0605 04:40:55.693960   904 solver.cpp:245]     Train net output #0: loss = 3.01493 (* 1 = 3.01493 loss)
I0605 04:40:55.694006   904 sgd_solver.cpp:106] Iteration 47440, lr = 0.0288376
I0605 04:41:16.334323   904 solver.cpp:229] Iteration 47480, loss = 2.9789
I0605 04:41:16.334383   904 solver.cpp:245]     Train net output #0: loss = 3.16914 (* 1 = 3.16914 loss)
I0605 04:41:16.334393   904 sgd_solver.cpp:106] Iteration 47480, lr = 0.0288282
I0605 04:41:36.702033   904 solver.cpp:229] Iteration 47520, loss = 2.97369
I0605 04:41:36.702203   904 solver.cpp:245]     Train net output #0: loss = 3.21225 (* 1 = 3.21225 loss)
I0605 04:41:36.702215   904 sgd_solver.cpp:106] Iteration 47520, lr = 0.0288188
I0605 04:41:56.957878   904 solver.cpp:229] Iteration 47560, loss = 2.98977
I0605 04:41:56.957926   904 solver.cpp:245]     Train net output #0: loss = 2.97619 (* 1 = 2.97619 loss)
I0605 04:41:56.957937   904 sgd_solver.cpp:106] Iteration 47560, lr = 0.0288094
I0605 04:42:17.098150   904 solver.cpp:229] Iteration 47600, loss = 2.98946
I0605 04:42:17.098371   904 solver.cpp:245]     Train net output #0: loss = 3.03295 (* 1 = 3.03295 loss)
I0605 04:42:17.098394   904 sgd_solver.cpp:106] Iteration 47600, lr = 0.0288
I0605 04:42:28.813133   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 04:42:37.026666   904 solver.cpp:229] Iteration 47640, loss = 2.9671
I0605 04:42:37.026710   904 solver.cpp:245]     Train net output #0: loss = 2.932 (* 1 = 2.932 loss)
I0605 04:42:37.026721   904 sgd_solver.cpp:106] Iteration 47640, lr = 0.0287906
I0605 04:42:56.970227   904 solver.cpp:229] Iteration 47680, loss = 2.97229
I0605 04:42:56.970463   904 solver.cpp:245]     Train net output #0: loss = 2.81539 (* 1 = 2.81539 loss)
I0605 04:42:56.970492   904 sgd_solver.cpp:106] Iteration 47680, lr = 0.0287812
I0605 04:43:16.934914   904 solver.cpp:229] Iteration 47720, loss = 3.01098
I0605 04:43:16.934983   904 solver.cpp:245]     Train net output #0: loss = 3.07734 (* 1 = 3.07734 loss)
I0605 04:43:16.934991   904 sgd_solver.cpp:106] Iteration 47720, lr = 0.0287718
I0605 04:43:36.892463   904 solver.cpp:229] Iteration 47760, loss = 2.95659
I0605 04:43:36.892683   904 solver.cpp:245]     Train net output #0: loss = 2.8583 (* 1 = 2.8583 loss)
I0605 04:43:36.892693   904 sgd_solver.cpp:106] Iteration 47760, lr = 0.0287624
I0605 04:43:56.847800   904 solver.cpp:229] Iteration 47800, loss = 2.96025
I0605 04:43:56.847849   904 solver.cpp:245]     Train net output #0: loss = 3.13526 (* 1 = 3.13526 loss)
I0605 04:43:56.847861   904 sgd_solver.cpp:106] Iteration 47800, lr = 0.0287529
I0605 04:44:16.831858   904 solver.cpp:229] Iteration 47840, loss = 3.03543
I0605 04:44:16.832074   904 solver.cpp:245]     Train net output #0: loss = 3.15235 (* 1 = 3.15235 loss)
I0605 04:44:16.832094   904 sgd_solver.cpp:106] Iteration 47840, lr = 0.0287435
I0605 04:44:37.043629   904 solver.cpp:229] Iteration 47880, loss = 2.92933
I0605 04:44:37.043663   904 solver.cpp:245]     Train net output #0: loss = 2.55942 (* 1 = 2.55942 loss)
I0605 04:44:37.043671   904 sgd_solver.cpp:106] Iteration 47880, lr = 0.0287341
I0605 04:44:57.214687   904 solver.cpp:229] Iteration 47920, loss = 2.94931
I0605 04:44:57.214886   904 solver.cpp:245]     Train net output #0: loss = 3.18753 (* 1 = 3.18753 loss)
I0605 04:44:57.214905   904 sgd_solver.cpp:106] Iteration 47920, lr = 0.0287247
I0605 04:45:17.355808   904 solver.cpp:229] Iteration 47960, loss = 2.96507
I0605 04:45:17.355851   904 solver.cpp:245]     Train net output #0: loss = 2.94883 (* 1 = 2.94883 loss)
I0605 04:45:17.355859   904 sgd_solver.cpp:106] Iteration 47960, lr = 0.0287153
I0605 04:45:37.003870   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_48000.caffemodel
I0605 04:45:37.263099   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_48000.solverstate
I0605 04:45:37.346808   904 solver.cpp:338] Iteration 48000, Testing net (#0)
I0605 04:45:37.346886   904 net.cpp:748] Ignoring source layer loss
I0605 04:45:47.258030   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 04:46:20.711892   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 04:46:44.844415   904 solver.cpp:406]     Test net output #0: accuracy = 0.385821
I0605 04:46:44.844462   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.635619
I0605 04:46:45.157549   904 solver.cpp:229] Iteration 48000, loss = 2.98156
I0605 04:46:45.157590   904 solver.cpp:245]     Train net output #0: loss = 2.88725 (* 1 = 2.88725 loss)
I0605 04:46:45.157599   904 sgd_solver.cpp:106] Iteration 48000, lr = 0.0287059
I0605 04:47:04.431851   904 solver.cpp:229] Iteration 48040, loss = 2.99905
I0605 04:47:04.432088   904 solver.cpp:245]     Train net output #0: loss = 3.11091 (* 1 = 3.11091 loss)
I0605 04:47:04.432116   904 sgd_solver.cpp:106] Iteration 48040, lr = 0.0286965
I0605 04:47:25.685195   904 solver.cpp:229] Iteration 48080, loss = 2.94402
I0605 04:47:25.685248   904 solver.cpp:245]     Train net output #0: loss = 2.93394 (* 1 = 2.93394 loss)
I0605 04:47:25.685271   904 sgd_solver.cpp:106] Iteration 48080, lr = 0.0286871
I0605 04:47:47.242750   904 solver.cpp:229] Iteration 48120, loss = 2.95768
I0605 04:47:47.242878   904 solver.cpp:245]     Train net output #0: loss = 2.83803 (* 1 = 2.83803 loss)
I0605 04:47:47.242887   904 sgd_solver.cpp:106] Iteration 48120, lr = 0.0286776
I0605 04:48:05.165887   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 04:48:08.316879   904 solver.cpp:229] Iteration 48160, loss = 2.96958
I0605 04:48:08.316926   904 solver.cpp:245]     Train net output #0: loss = 3.06924 (* 1 = 3.06924 loss)
I0605 04:48:08.316946   904 sgd_solver.cpp:106] Iteration 48160, lr = 0.0286682
I0605 04:48:29.329367   904 solver.cpp:229] Iteration 48200, loss = 2.95761
I0605 04:48:29.329601   904 solver.cpp:245]     Train net output #0: loss = 3.12439 (* 1 = 3.12439 loss)
I0605 04:48:29.329628   904 sgd_solver.cpp:106] Iteration 48200, lr = 0.0286588
I0605 04:48:50.346875   904 solver.cpp:229] Iteration 48240, loss = 2.95059
I0605 04:48:50.346920   904 solver.cpp:245]     Train net output #0: loss = 2.86973 (* 1 = 2.86973 loss)
I0605 04:48:50.346928   904 sgd_solver.cpp:106] Iteration 48240, lr = 0.0286494
I0605 04:49:11.360102   904 solver.cpp:229] Iteration 48280, loss = 2.9641
I0605 04:49:11.360358   904 solver.cpp:245]     Train net output #0: loss = 2.91634 (* 1 = 2.91634 loss)
I0605 04:49:11.360391   904 sgd_solver.cpp:106] Iteration 48280, lr = 0.02864
I0605 04:49:32.201741   904 solver.cpp:229] Iteration 48320, loss = 2.99442
I0605 04:49:32.201787   904 solver.cpp:245]     Train net output #0: loss = 3.07463 (* 1 = 3.07463 loss)
I0605 04:49:32.201797   904 sgd_solver.cpp:106] Iteration 48320, lr = 0.0286306
I0605 04:49:52.925853   904 solver.cpp:229] Iteration 48360, loss = 2.92168
I0605 04:49:52.925992   904 solver.cpp:245]     Train net output #0: loss = 2.97497 (* 1 = 2.97497 loss)
I0605 04:49:52.926003   904 sgd_solver.cpp:106] Iteration 48360, lr = 0.0286212
I0605 04:50:13.637717   904 solver.cpp:229] Iteration 48400, loss = 2.93351
I0605 04:50:13.637768   904 solver.cpp:245]     Train net output #0: loss = 2.95122 (* 1 = 2.95122 loss)
I0605 04:50:13.637778   904 sgd_solver.cpp:106] Iteration 48400, lr = 0.0286118
I0605 04:50:34.381088   904 solver.cpp:229] Iteration 48440, loss = 2.97399
I0605 04:50:34.381242   904 solver.cpp:245]     Train net output #0: loss = 2.94852 (* 1 = 2.94852 loss)
I0605 04:50:34.381259   904 sgd_solver.cpp:106] Iteration 48440, lr = 0.0286024
I0605 04:50:55.025035   904 solver.cpp:229] Iteration 48480, loss = 2.9014
I0605 04:50:55.025089   904 solver.cpp:245]     Train net output #0: loss = 3.0785 (* 1 = 3.0785 loss)
I0605 04:50:55.025101   904 sgd_solver.cpp:106] Iteration 48480, lr = 0.0285929
I0605 04:51:15.584777   904 solver.cpp:229] Iteration 48520, loss = 2.93379
I0605 04:51:15.584930   904 solver.cpp:245]     Train net output #0: loss = 3.00565 (* 1 = 3.00565 loss)
I0605 04:51:15.584939   904 sgd_solver.cpp:106] Iteration 48520, lr = 0.0285835
I0605 04:51:36.112706   904 solver.cpp:229] Iteration 48560, loss = 2.91543
I0605 04:51:36.112773   904 solver.cpp:245]     Train net output #0: loss = 3.18564 (* 1 = 3.18564 loss)
I0605 04:51:36.112782   904 sgd_solver.cpp:106] Iteration 48560, lr = 0.0285741
I0605 04:51:56.649780   904 solver.cpp:229] Iteration 48600, loss = 2.97147
I0605 04:51:56.649910   904 solver.cpp:245]     Train net output #0: loss = 2.86055 (* 1 = 2.86055 loss)
I0605 04:51:56.649920   904 sgd_solver.cpp:106] Iteration 48600, lr = 0.0285647
I0605 04:52:17.181923   904 solver.cpp:229] Iteration 48640, loss = 2.92267
I0605 04:52:17.181979   904 solver.cpp:245]     Train net output #0: loss = 2.91483 (* 1 = 2.91483 loss)
I0605 04:52:17.181988   904 sgd_solver.cpp:106] Iteration 48640, lr = 0.0285553
I0605 04:52:37.740619   904 solver.cpp:229] Iteration 48680, loss = 2.93535
I0605 04:52:37.740784   904 solver.cpp:245]     Train net output #0: loss = 2.68665 (* 1 = 2.68665 loss)
I0605 04:52:37.740793   904 sgd_solver.cpp:106] Iteration 48680, lr = 0.0285459
I0605 04:52:53.089141   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 04:52:58.183059   904 solver.cpp:229] Iteration 48720, loss = 2.95105
I0605 04:52:58.183107   904 solver.cpp:245]     Train net output #0: loss = 3.38195 (* 1 = 3.38195 loss)
I0605 04:52:58.183116   904 sgd_solver.cpp:106] Iteration 48720, lr = 0.0285365
I0605 04:53:18.501617   904 solver.cpp:229] Iteration 48760, loss = 2.97136
I0605 04:53:18.501832   904 solver.cpp:245]     Train net output #0: loss = 2.94452 (* 1 = 2.94452 loss)
I0605 04:53:18.501857   904 sgd_solver.cpp:106] Iteration 48760, lr = 0.0285271
I0605 04:53:38.838876   904 solver.cpp:229] Iteration 48800, loss = 2.9317
I0605 04:53:38.838925   904 solver.cpp:245]     Train net output #0: loss = 2.86618 (* 1 = 2.86618 loss)
I0605 04:53:38.838933   904 sgd_solver.cpp:106] Iteration 48800, lr = 0.0285176
I0605 04:53:59.191822   904 solver.cpp:229] Iteration 48840, loss = 2.91856
I0605 04:53:59.192096   904 solver.cpp:245]     Train net output #0: loss = 2.77042 (* 1 = 2.77042 loss)
I0605 04:53:59.192121   904 sgd_solver.cpp:106] Iteration 48840, lr = 0.0285082
I0605 04:54:19.541411   904 solver.cpp:229] Iteration 48880, loss = 2.9469
I0605 04:54:19.541468   904 solver.cpp:245]     Train net output #0: loss = 2.87827 (* 1 = 2.87827 loss)
I0605 04:54:19.541481   904 sgd_solver.cpp:106] Iteration 48880, lr = 0.0284988
I0605 04:54:39.901504   904 solver.cpp:229] Iteration 48920, loss = 2.96476
I0605 04:54:39.901691   904 solver.cpp:245]     Train net output #0: loss = 3.30678 (* 1 = 3.30678 loss)
I0605 04:54:39.901717   904 sgd_solver.cpp:106] Iteration 48920, lr = 0.0284894
I0605 04:55:00.246577   904 solver.cpp:229] Iteration 48960, loss = 2.96477
I0605 04:55:00.246629   904 solver.cpp:245]     Train net output #0: loss = 3.29951 (* 1 = 3.29951 loss)
I0605 04:55:00.246639   904 sgd_solver.cpp:106] Iteration 48960, lr = 0.02848
I0605 04:55:20.101323   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_49000.caffemodel
I0605 04:55:20.370543   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_49000.solverstate
I0605 04:55:20.442909   904 solver.cpp:338] Iteration 49000, Testing net (#0)
I0605 04:55:20.442986   904 net.cpp:748] Ignoring source layer loss
I0605 04:55:37.225275   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 04:56:11.633637   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 04:56:28.188586   904 solver.cpp:406]     Test net output #0: accuracy = 0.379941
I0605 04:56:28.188642   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.63166
I0605 04:56:28.503324   904 solver.cpp:229] Iteration 49000, loss = 2.99388
I0605 04:56:28.503365   904 solver.cpp:245]     Train net output #0: loss = 2.69058 (* 1 = 2.69058 loss)
I0605 04:56:28.503374   904 sgd_solver.cpp:106] Iteration 49000, lr = 0.0284706
I0605 04:56:47.722697   904 solver.cpp:229] Iteration 49040, loss = 2.93762
I0605 04:56:47.722851   904 solver.cpp:245]     Train net output #0: loss = 2.97483 (* 1 = 2.97483 loss)
I0605 04:56:47.722862   904 sgd_solver.cpp:106] Iteration 49040, lr = 0.0284612
I0605 04:57:09.112246   904 solver.cpp:229] Iteration 49080, loss = 2.94416
I0605 04:57:09.112295   904 solver.cpp:245]     Train net output #0: loss = 2.85519 (* 1 = 2.85519 loss)
I0605 04:57:09.112303   904 sgd_solver.cpp:106] Iteration 49080, lr = 0.0284518
I0605 04:57:30.628435   904 solver.cpp:229] Iteration 49120, loss = 2.97576
I0605 04:57:30.628585   904 solver.cpp:245]     Train net output #0: loss = 2.87151 (* 1 = 2.87151 loss)
I0605 04:57:30.628605   904 sgd_solver.cpp:106] Iteration 49120, lr = 0.0284424
I0605 04:57:51.705780   904 solver.cpp:229] Iteration 49160, loss = 2.94782
I0605 04:57:51.705829   904 solver.cpp:245]     Train net output #0: loss = 2.93302 (* 1 = 2.93302 loss)
I0605 04:57:51.705837   904 sgd_solver.cpp:106] Iteration 49160, lr = 0.0284329
I0605 04:58:12.717608   904 solver.cpp:229] Iteration 49200, loss = 2.96516
I0605 04:58:12.717818   904 solver.cpp:245]     Train net output #0: loss = 2.84107 (* 1 = 2.84107 loss)
I0605 04:58:12.717844   904 sgd_solver.cpp:106] Iteration 49200, lr = 0.0284235
I0605 04:58:33.704566   904 solver.cpp:229] Iteration 49240, loss = 2.97914
I0605 04:58:33.704614   904 solver.cpp:245]     Train net output #0: loss = 2.97575 (* 1 = 2.97575 loss)
I0605 04:58:33.704627   904 sgd_solver.cpp:106] Iteration 49240, lr = 0.0284141
I0605 04:58:52.862848   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 04:58:54.695713   904 solver.cpp:229] Iteration 49280, loss = 2.90541
I0605 04:58:54.695758   904 solver.cpp:245]     Train net output #0: loss = 2.88356 (* 1 = 2.88356 loss)
I0605 04:58:54.695770   904 sgd_solver.cpp:106] Iteration 49280, lr = 0.0284047
I0605 04:59:15.667609   904 solver.cpp:229] Iteration 49320, loss = 2.93375
I0605 04:59:15.667671   904 solver.cpp:245]     Train net output #0: loss = 2.87412 (* 1 = 2.87412 loss)
I0605 04:59:15.667692   904 sgd_solver.cpp:106] Iteration 49320, lr = 0.0283953
I0605 04:59:36.585404   904 solver.cpp:229] Iteration 49360, loss = 2.94246
I0605 04:59:36.585558   904 solver.cpp:245]     Train net output #0: loss = 2.86065 (* 1 = 2.86065 loss)
I0605 04:59:36.585588   904 sgd_solver.cpp:106] Iteration 49360, lr = 0.0283859
I0605 04:59:57.403542   904 solver.cpp:229] Iteration 49400, loss = 2.9181
I0605 04:59:57.403592   904 solver.cpp:245]     Train net output #0: loss = 3.38019 (* 1 = 3.38019 loss)
I0605 04:59:57.403601   904 sgd_solver.cpp:106] Iteration 49400, lr = 0.0283765
I0605 05:00:18.189074   904 solver.cpp:229] Iteration 49440, loss = 2.91206
I0605 05:00:18.189249   904 solver.cpp:245]     Train net output #0: loss = 2.91061 (* 1 = 2.91061 loss)
I0605 05:00:18.189259   904 sgd_solver.cpp:106] Iteration 49440, lr = 0.0283671
I0605 05:00:38.842095   904 solver.cpp:229] Iteration 49480, loss = 2.89483
I0605 05:00:38.842134   904 solver.cpp:245]     Train net output #0: loss = 2.86064 (* 1 = 2.86064 loss)
I0605 05:00:38.842144   904 sgd_solver.cpp:106] Iteration 49480, lr = 0.0283576
I0605 05:00:59.531715   904 solver.cpp:229] Iteration 49520, loss = 2.96239
I0605 05:00:59.531919   904 solver.cpp:245]     Train net output #0: loss = 2.8002 (* 1 = 2.8002 loss)
I0605 05:00:59.531942   904 sgd_solver.cpp:106] Iteration 49520, lr = 0.0283482
I0605 05:01:20.204979   904 solver.cpp:229] Iteration 49560, loss = 2.93524
I0605 05:01:20.205025   904 solver.cpp:245]     Train net output #0: loss = 2.87294 (* 1 = 2.87294 loss)
I0605 05:01:20.205034   904 sgd_solver.cpp:106] Iteration 49560, lr = 0.0283388
I0605 05:01:40.896102   904 solver.cpp:229] Iteration 49600, loss = 2.9295
I0605 05:01:40.896255   904 solver.cpp:245]     Train net output #0: loss = 2.98872 (* 1 = 2.98872 loss)
I0605 05:01:40.896275   904 sgd_solver.cpp:106] Iteration 49600, lr = 0.0283294
I0605 05:02:01.575791   904 solver.cpp:229] Iteration 49640, loss = 2.95927
I0605 05:02:01.575844   904 solver.cpp:245]     Train net output #0: loss = 3.12657 (* 1 = 3.12657 loss)
I0605 05:02:01.575851   904 sgd_solver.cpp:106] Iteration 49640, lr = 0.02832
I0605 05:02:22.263841   904 solver.cpp:229] Iteration 49680, loss = 2.92564
I0605 05:02:22.263980   904 solver.cpp:245]     Train net output #0: loss = 2.96503 (* 1 = 2.96503 loss)
I0605 05:02:22.263990   904 sgd_solver.cpp:106] Iteration 49680, lr = 0.0283106
I0605 05:02:42.866786   904 solver.cpp:229] Iteration 49720, loss = 2.98211
I0605 05:02:42.866833   904 solver.cpp:245]     Train net output #0: loss = 3.07655 (* 1 = 3.07655 loss)
I0605 05:02:42.866842   904 sgd_solver.cpp:106] Iteration 49720, lr = 0.0283012
I0605 05:03:04.142158   904 solver.cpp:229] Iteration 49760, loss = 2.88946
I0605 05:03:04.142288   904 solver.cpp:245]     Train net output #0: loss = 3.11533 (* 1 = 3.11533 loss)
I0605 05:03:04.142302   904 sgd_solver.cpp:106] Iteration 49760, lr = 0.0282918
I0605 05:03:24.637492   904 solver.cpp:229] Iteration 49800, loss = 2.95273
I0605 05:03:24.637547   904 solver.cpp:245]     Train net output #0: loss = 2.92611 (* 1 = 2.92611 loss)
I0605 05:03:24.637555   904 sgd_solver.cpp:106] Iteration 49800, lr = 0.0282824
I0605 05:03:45.143832   904 solver.cpp:229] Iteration 49840, loss = 2.90603
I0605 05:03:45.144014   904 solver.cpp:245]     Train net output #0: loss = 2.82936 (* 1 = 2.82936 loss)
I0605 05:03:45.144039   904 sgd_solver.cpp:106] Iteration 49840, lr = 0.0282729
I0605 05:04:05.709408   904 solver.cpp:229] Iteration 49880, loss = 2.8938
I0605 05:04:05.709453   904 solver.cpp:245]     Train net output #0: loss = 2.77377 (* 1 = 2.77377 loss)
I0605 05:04:05.709462   904 sgd_solver.cpp:106] Iteration 49880, lr = 0.0282635
I0605 05:04:05.710701   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 05:04:26.218502   904 solver.cpp:229] Iteration 49920, loss = 2.92656
I0605 05:04:26.218695   904 solver.cpp:245]     Train net output #0: loss = 3.07834 (* 1 = 3.07834 loss)
I0605 05:04:26.218740   904 sgd_solver.cpp:106] Iteration 49920, lr = 0.0282541
I0605 05:04:46.726140   904 solver.cpp:229] Iteration 49960, loss = 2.94758
I0605 05:04:46.726203   904 solver.cpp:245]     Train net output #0: loss = 2.71845 (* 1 = 2.71845 loss)
I0605 05:04:46.726212   904 sgd_solver.cpp:106] Iteration 49960, lr = 0.0282447
I0605 05:05:06.710269   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_50000.caffemodel
I0605 05:05:06.981398   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_50000.solverstate
I0605 05:05:07.059505   904 solver.cpp:338] Iteration 50000, Testing net (#0)
I0605 05:05:07.059590   904 net.cpp:748] Ignoring source layer loss
I0605 05:05:34.926292   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 05:06:08.799866   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 05:06:14.777490   904 solver.cpp:406]     Test net output #0: accuracy = 0.377941
I0605 05:06:14.777534   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.629659
I0605 05:06:15.091542   904 solver.cpp:229] Iteration 50000, loss = 2.98647
I0605 05:06:15.091603   904 solver.cpp:245]     Train net output #0: loss = 2.8373 (* 1 = 2.8373 loss)
I0605 05:06:15.091614   904 sgd_solver.cpp:106] Iteration 50000, lr = 0.0282353
I0605 05:06:34.291568   904 solver.cpp:229] Iteration 50040, loss = 2.94712
I0605 05:06:34.291620   904 solver.cpp:245]     Train net output #0: loss = 2.88681 (* 1 = 2.88681 loss)
I0605 05:06:34.291628   904 sgd_solver.cpp:106] Iteration 50040, lr = 0.0282259
I0605 05:06:55.687377   904 solver.cpp:229] Iteration 50080, loss = 2.96374
I0605 05:06:55.687582   904 solver.cpp:245]     Train net output #0: loss = 2.94347 (* 1 = 2.94347 loss)
I0605 05:06:55.687608   904 sgd_solver.cpp:106] Iteration 50080, lr = 0.0282165
I0605 05:07:17.130947   904 solver.cpp:229] Iteration 50120, loss = 2.91167
I0605 05:07:17.131003   904 solver.cpp:245]     Train net output #0: loss = 2.90085 (* 1 = 2.90085 loss)
I0605 05:07:17.131013   904 sgd_solver.cpp:106] Iteration 50120, lr = 0.0282071
I0605 05:07:38.125166   904 solver.cpp:229] Iteration 50160, loss = 2.9127
I0605 05:07:38.125326   904 solver.cpp:245]     Train net output #0: loss = 3.05975 (* 1 = 3.05975 loss)
I0605 05:07:38.125336   904 sgd_solver.cpp:106] Iteration 50160, lr = 0.0281976
I0605 05:07:59.111812   904 solver.cpp:229] Iteration 50200, loss = 2.92234
I0605 05:07:59.111882   904 solver.cpp:245]     Train net output #0: loss = 2.86462 (* 1 = 2.86462 loss)
I0605 05:07:59.111896   904 sgd_solver.cpp:106] Iteration 50200, lr = 0.0281882
I0605 05:08:20.126637   904 solver.cpp:229] Iteration 50240, loss = 2.95309
I0605 05:08:20.126832   904 solver.cpp:245]     Train net output #0: loss = 2.62736 (* 1 = 2.62736 loss)
I0605 05:08:20.126858   904 sgd_solver.cpp:106] Iteration 50240, lr = 0.0281788
I0605 05:08:40.932703   904 solver.cpp:229] Iteration 50280, loss = 2.90991
I0605 05:08:40.932755   904 solver.cpp:245]     Train net output #0: loss = 3.0258 (* 1 = 3.0258 loss)
I0605 05:08:40.932765   904 sgd_solver.cpp:106] Iteration 50280, lr = 0.0281694
I0605 05:09:01.637820   904 solver.cpp:229] Iteration 50320, loss = 2.9772
I0605 05:09:01.638036   904 solver.cpp:245]     Train net output #0: loss = 2.73768 (* 1 = 2.73768 loss)
I0605 05:09:01.638063   904 sgd_solver.cpp:106] Iteration 50320, lr = 0.02816
I0605 05:09:22.349474   904 solver.cpp:229] Iteration 50360, loss = 2.95651
I0605 05:09:22.349514   904 solver.cpp:245]     Train net output #0: loss = 2.90055 (* 1 = 2.90055 loss)
I0605 05:09:22.349522   904 sgd_solver.cpp:106] Iteration 50360, lr = 0.0281506
I0605 05:09:43.072130   904 solver.cpp:229] Iteration 50400, loss = 2.92897
I0605 05:09:43.072310   904 solver.cpp:245]     Train net output #0: loss = 2.77477 (* 1 = 2.77477 loss)
I0605 05:09:43.072336   904 sgd_solver.cpp:106] Iteration 50400, lr = 0.0281412
I0605 05:10:03.770732   904 solver.cpp:229] Iteration 50440, loss = 2.93982
I0605 05:10:03.770786   904 solver.cpp:245]     Train net output #0: loss = 3.01324 (* 1 = 3.01324 loss)
I0605 05:10:03.770794   904 sgd_solver.cpp:106] Iteration 50440, lr = 0.0281318
I0605 05:10:15.368643   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 05:10:24.345680   904 solver.cpp:229] Iteration 50480, loss = 2.92283
I0605 05:10:24.345728   904 solver.cpp:245]     Train net output #0: loss = 3.02378 (* 1 = 3.02378 loss)
I0605 05:10:24.345737   904 sgd_solver.cpp:106] Iteration 50480, lr = 0.0281224
I0605 05:10:44.857625   904 solver.cpp:229] Iteration 50520, loss = 2.94949
I0605 05:10:44.857678   904 solver.cpp:245]     Train net output #0: loss = 3.03493 (* 1 = 3.03493 loss)
I0605 05:10:44.857687   904 sgd_solver.cpp:106] Iteration 50520, lr = 0.0281129
I0605 05:11:05.361529   904 solver.cpp:229] Iteration 50560, loss = 2.93019
I0605 05:11:05.361744   904 solver.cpp:245]     Train net output #0: loss = 2.77765 (* 1 = 2.77765 loss)
I0605 05:11:05.361769   904 sgd_solver.cpp:106] Iteration 50560, lr = 0.0281035
I0605 05:11:25.900660   904 solver.cpp:229] Iteration 50600, loss = 2.90729
I0605 05:11:25.900717   904 solver.cpp:245]     Train net output #0: loss = 3.15661 (* 1 = 3.15661 loss)
I0605 05:11:25.900738   904 sgd_solver.cpp:106] Iteration 50600, lr = 0.0280941
I0605 05:11:46.296211   904 solver.cpp:229] Iteration 50640, loss = 2.93001
I0605 05:11:46.296447   904 solver.cpp:245]     Train net output #0: loss = 2.8594 (* 1 = 2.8594 loss)
I0605 05:11:46.296473   904 sgd_solver.cpp:106] Iteration 50640, lr = 0.0280847
I0605 05:12:06.581867   904 solver.cpp:229] Iteration 50680, loss = 2.94128
I0605 05:12:06.581918   904 solver.cpp:245]     Train net output #0: loss = 3.12216 (* 1 = 3.12216 loss)
I0605 05:12:06.581926   904 sgd_solver.cpp:106] Iteration 50680, lr = 0.0280753
I0605 05:12:26.868744   904 solver.cpp:229] Iteration 50720, loss = 2.9681
I0605 05:12:26.868851   904 solver.cpp:245]     Train net output #0: loss = 2.90323 (* 1 = 2.90323 loss)
I0605 05:12:26.868862   904 sgd_solver.cpp:106] Iteration 50720, lr = 0.0280659
I0605 05:12:47.166321   904 solver.cpp:229] Iteration 50760, loss = 2.9024
I0605 05:12:47.166364   904 solver.cpp:245]     Train net output #0: loss = 2.84384 (* 1 = 2.84384 loss)
I0605 05:12:47.166373   904 sgd_solver.cpp:106] Iteration 50760, lr = 0.0280565
I0605 05:13:07.445039   904 solver.cpp:229] Iteration 50800, loss = 2.93527
I0605 05:13:07.445255   904 solver.cpp:245]     Train net output #0: loss = 2.91414 (* 1 = 2.91414 loss)
I0605 05:13:07.445282   904 sgd_solver.cpp:106] Iteration 50800, lr = 0.0280471
I0605 05:13:27.747597   904 solver.cpp:229] Iteration 50840, loss = 2.94738
I0605 05:13:27.747661   904 solver.cpp:245]     Train net output #0: loss = 2.95244 (* 1 = 2.95244 loss)
I0605 05:13:27.747674   904 sgd_solver.cpp:106] Iteration 50840, lr = 0.0280376
I0605 05:13:48.036033   904 solver.cpp:229] Iteration 50880, loss = 2.92914
I0605 05:13:48.036125   904 solver.cpp:245]     Train net output #0: loss = 2.77487 (* 1 = 2.77487 loss)
I0605 05:13:48.036134   904 sgd_solver.cpp:106] Iteration 50880, lr = 0.0280282
I0605 05:14:08.325479   904 solver.cpp:229] Iteration 50920, loss = 2.93792
I0605 05:14:08.325518   904 solver.cpp:245]     Train net output #0: loss = 3.07033 (* 1 = 3.07033 loss)
I0605 05:14:08.325527   904 sgd_solver.cpp:106] Iteration 50920, lr = 0.0280188
I0605 05:14:28.600626   904 solver.cpp:229] Iteration 50960, loss = 2.93062
I0605 05:14:28.600879   904 solver.cpp:245]     Train net output #0: loss = 2.68667 (* 1 = 2.68667 loss)
I0605 05:14:28.600905   904 sgd_solver.cpp:106] Iteration 50960, lr = 0.0280094
I0605 05:14:38.988925   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 05:14:48.295317   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_51000.caffemodel
I0605 05:14:48.549769   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_51000.solverstate
I0605 05:14:48.628454   904 solver.cpp:338] Iteration 51000, Testing net (#0)
I0605 05:14:48.628517   904 net.cpp:748] Ignoring source layer loss
I0605 05:15:22.412892   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 05:15:57.011956   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 05:15:58.054636   904 solver.cpp:406]     Test net output #0: accuracy = 0.390401
I0605 05:15:58.054673   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.64424
I0605 05:15:58.368113   904 solver.cpp:229] Iteration 51000, loss = 2.89672
I0605 05:15:58.368154   904 solver.cpp:245]     Train net output #0: loss = 2.56808 (* 1 = 2.56808 loss)
I0605 05:15:58.368161   904 sgd_solver.cpp:106] Iteration 51000, lr = 0.028
I0605 05:16:17.520442   904 solver.cpp:229] Iteration 51040, loss = 2.93233
I0605 05:16:17.520479   904 solver.cpp:245]     Train net output #0: loss = 2.90999 (* 1 = 2.90999 loss)
I0605 05:16:17.520498   904 sgd_solver.cpp:106] Iteration 51040, lr = 0.0279906
I0605 05:16:38.801128   904 solver.cpp:229] Iteration 51080, loss = 2.91766
I0605 05:16:38.801251   904 solver.cpp:245]     Train net output #0: loss = 3.01818 (* 1 = 3.01818 loss)
I0605 05:16:38.801271   904 sgd_solver.cpp:106] Iteration 51080, lr = 0.0279812
I0605 05:17:00.280810   904 solver.cpp:229] Iteration 51120, loss = 2.95201
I0605 05:17:00.280858   904 solver.cpp:245]     Train net output #0: loss = 3.03155 (* 1 = 3.03155 loss)
I0605 05:17:00.280870   904 sgd_solver.cpp:106] Iteration 51120, lr = 0.0279718
I0605 05:17:21.340481   904 solver.cpp:229] Iteration 51160, loss = 2.90242
I0605 05:17:21.340695   904 solver.cpp:245]     Train net output #0: loss = 2.86069 (* 1 = 2.86069 loss)
I0605 05:17:21.340721   904 sgd_solver.cpp:106] Iteration 51160, lr = 0.0279624
I0605 05:17:42.265688   904 solver.cpp:229] Iteration 51200, loss = 2.97227
I0605 05:17:42.265724   904 solver.cpp:245]     Train net output #0: loss = 2.85622 (* 1 = 2.85622 loss)
I0605 05:17:42.265733   904 sgd_solver.cpp:106] Iteration 51200, lr = 0.0279529
I0605 05:18:03.201710   904 solver.cpp:229] Iteration 51240, loss = 2.91467
I0605 05:18:03.201867   904 solver.cpp:245]     Train net output #0: loss = 2.80491 (* 1 = 2.80491 loss)
I0605 05:18:03.201896   904 sgd_solver.cpp:106] Iteration 51240, lr = 0.0279435
I0605 05:18:24.121649   904 solver.cpp:229] Iteration 51280, loss = 2.9065
I0605 05:18:24.121697   904 solver.cpp:245]     Train net output #0: loss = 2.58203 (* 1 = 2.58203 loss)
I0605 05:18:24.121717   904 sgd_solver.cpp:106] Iteration 51280, lr = 0.0279341
I0605 05:18:45.009574   904 solver.cpp:229] Iteration 51320, loss = 2.90833
I0605 05:18:45.009775   904 solver.cpp:245]     Train net output #0: loss = 2.99138 (* 1 = 2.99138 loss)
I0605 05:18:45.009799   904 sgd_solver.cpp:106] Iteration 51320, lr = 0.0279247
I0605 05:19:05.555847   904 solver.cpp:229] Iteration 51360, loss = 2.89582
I0605 05:19:05.555903   904 solver.cpp:245]     Train net output #0: loss = 2.99423 (* 1 = 2.99423 loss)
I0605 05:19:05.555912   904 sgd_solver.cpp:106] Iteration 51360, lr = 0.0279153
I0605 05:19:26.282850   904 solver.cpp:229] Iteration 51400, loss = 2.94131
I0605 05:19:26.282966   904 solver.cpp:245]     Train net output #0: loss = 2.8348 (* 1 = 2.8348 loss)
I0605 05:19:26.282975   904 sgd_solver.cpp:106] Iteration 51400, lr = 0.0279059
I0605 05:19:46.906795   904 solver.cpp:229] Iteration 51440, loss = 2.93118
I0605 05:19:46.906834   904 solver.cpp:245]     Train net output #0: loss = 3.02639 (* 1 = 3.02639 loss)
I0605 05:19:46.906843   904 sgd_solver.cpp:106] Iteration 51440, lr = 0.0278965
I0605 05:20:07.379709   904 solver.cpp:229] Iteration 51480, loss = 2.94643
I0605 05:20:07.379915   904 solver.cpp:245]     Train net output #0: loss = 3.12564 (* 1 = 3.12564 loss)
I0605 05:20:07.379942   904 sgd_solver.cpp:106] Iteration 51480, lr = 0.0278871
I0605 05:20:19.907878   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 05:20:27.832844   904 solver.cpp:229] Iteration 51520, loss = 2.93639
I0605 05:20:27.832906   904 solver.cpp:245]     Train net output #0: loss = 2.9777 (* 1 = 2.9777 loss)
I0605 05:20:27.832926   904 sgd_solver.cpp:106] Iteration 51520, lr = 0.0278776
I0605 05:20:48.291091   904 solver.cpp:229] Iteration 51560, loss = 2.89232
I0605 05:20:48.291225   904 solver.cpp:245]     Train net output #0: loss = 2.91152 (* 1 = 2.91152 loss)
I0605 05:20:48.291234   904 sgd_solver.cpp:106] Iteration 51560, lr = 0.0278682
I0605 05:21:08.723150   904 solver.cpp:229] Iteration 51600, loss = 2.94212
I0605 05:21:08.723214   904 solver.cpp:245]     Train net output #0: loss = 2.75798 (* 1 = 2.75798 loss)
I0605 05:21:08.723224   904 sgd_solver.cpp:106] Iteration 51600, lr = 0.0278588
I0605 05:21:29.161805   904 solver.cpp:229] Iteration 51640, loss = 2.92448
I0605 05:21:29.162045   904 solver.cpp:245]     Train net output #0: loss = 2.64956 (* 1 = 2.64956 loss)
I0605 05:21:29.162058   904 sgd_solver.cpp:106] Iteration 51640, lr = 0.0278494
I0605 05:21:49.589460   904 solver.cpp:229] Iteration 51680, loss = 2.92482
I0605 05:21:49.589512   904 solver.cpp:245]     Train net output #0: loss = 2.99023 (* 1 = 2.99023 loss)
I0605 05:21:49.589521   904 sgd_solver.cpp:106] Iteration 51680, lr = 0.02784
I0605 05:22:09.887915   904 solver.cpp:229] Iteration 51720, loss = 2.89399
I0605 05:22:09.888074   904 solver.cpp:245]     Train net output #0: loss = 2.89375 (* 1 = 2.89375 loss)
I0605 05:22:09.888097   904 sgd_solver.cpp:106] Iteration 51720, lr = 0.0278306
I0605 05:22:30.126754   904 solver.cpp:229] Iteration 51760, loss = 2.93366
I0605 05:22:30.126801   904 solver.cpp:245]     Train net output #0: loss = 2.91961 (* 1 = 2.91961 loss)
I0605 05:22:30.126811   904 sgd_solver.cpp:106] Iteration 51760, lr = 0.0278212
I0605 05:22:50.343127   904 solver.cpp:229] Iteration 51800, loss = 2.90746
I0605 05:22:50.343271   904 solver.cpp:245]     Train net output #0: loss = 3.14418 (* 1 = 3.14418 loss)
I0605 05:22:50.343282   904 sgd_solver.cpp:106] Iteration 51800, lr = 0.0278118
I0605 05:23:10.575865   904 solver.cpp:229] Iteration 51840, loss = 2.93183
I0605 05:23:10.575916   904 solver.cpp:245]     Train net output #0: loss = 2.89223 (* 1 = 2.89223 loss)
I0605 05:23:10.575927   904 sgd_solver.cpp:106] Iteration 51840, lr = 0.0278024
I0605 05:23:30.801656   904 solver.cpp:229] Iteration 51880, loss = 2.89827
I0605 05:23:30.801856   904 solver.cpp:245]     Train net output #0: loss = 2.66896 (* 1 = 2.66896 loss)
I0605 05:23:30.801880   904 sgd_solver.cpp:106] Iteration 51880, lr = 0.0277929
I0605 05:23:51.006155   904 solver.cpp:229] Iteration 51920, loss = 2.91616
I0605 05:23:51.006211   904 solver.cpp:245]     Train net output #0: loss = 2.65001 (* 1 = 2.65001 loss)
I0605 05:23:51.006220   904 sgd_solver.cpp:106] Iteration 51920, lr = 0.0277835
I0605 05:24:11.239465   904 solver.cpp:229] Iteration 51960, loss = 2.88016
I0605 05:24:11.239657   904 solver.cpp:245]     Train net output #0: loss = 2.9869 (* 1 = 2.9869 loss)
I0605 05:24:11.239691   904 sgd_solver.cpp:106] Iteration 51960, lr = 0.0277741
I0605 05:24:30.958524   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_52000.caffemodel
I0605 05:24:31.218081   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_52000.solverstate
I0605 05:24:31.298964   904 solver.cpp:338] Iteration 52000, Testing net (#0)
I0605 05:24:31.299052   904 net.cpp:748] Ignoring source layer loss
I0605 05:24:31.938261   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 05:25:05.700438   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 05:25:38.116487   904 solver.cpp:406]     Test net output #0: accuracy = 0.386201
I0605 05:25:38.116581   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.633459
I0605 05:25:38.432086   904 solver.cpp:229] Iteration 52000, loss = 2.90533
I0605 05:25:38.432132   904 solver.cpp:245]     Train net output #0: loss = 3.03332 (* 1 = 3.03332 loss)
I0605 05:25:38.432142   904 sgd_solver.cpp:106] Iteration 52000, lr = 0.0277647
I0605 05:25:43.730068   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 05:25:57.693382   904 solver.cpp:229] Iteration 52040, loss = 2.90578
I0605 05:25:57.693437   904 solver.cpp:245]     Train net output #0: loss = 2.66254 (* 1 = 2.66254 loss)
I0605 05:25:57.693447   904 sgd_solver.cpp:106] Iteration 52040, lr = 0.0277553
I0605 05:26:19.140367   904 solver.cpp:229] Iteration 52080, loss = 2.89216
I0605 05:26:19.140602   904 solver.cpp:245]     Train net output #0: loss = 2.5438 (* 1 = 2.5438 loss)
I0605 05:26:19.140614   904 sgd_solver.cpp:106] Iteration 52080, lr = 0.0277459
I0605 05:26:40.758224   904 solver.cpp:229] Iteration 52120, loss = 2.88223
I0605 05:26:40.758272   904 solver.cpp:245]     Train net output #0: loss = 2.96239 (* 1 = 2.96239 loss)
I0605 05:26:40.758283   904 sgd_solver.cpp:106] Iteration 52120, lr = 0.0277365
I0605 05:27:01.938068   904 solver.cpp:229] Iteration 52160, loss = 2.90244
I0605 05:27:01.938230   904 solver.cpp:245]     Train net output #0: loss = 2.95454 (* 1 = 2.95454 loss)
I0605 05:27:01.938258   904 sgd_solver.cpp:106] Iteration 52160, lr = 0.0277271
I0605 05:27:22.945138   904 solver.cpp:229] Iteration 52200, loss = 2.91354
I0605 05:27:22.945178   904 solver.cpp:245]     Train net output #0: loss = 2.92555 (* 1 = 2.92555 loss)
I0605 05:27:22.945186   904 sgd_solver.cpp:106] Iteration 52200, lr = 0.0277176
I0605 05:27:43.974401   904 solver.cpp:229] Iteration 52240, loss = 2.92092
I0605 05:27:43.974612   904 solver.cpp:245]     Train net output #0: loss = 2.76852 (* 1 = 2.76852 loss)
I0605 05:27:43.974640   904 sgd_solver.cpp:106] Iteration 52240, lr = 0.0277082
I0605 05:28:04.975873   904 solver.cpp:229] Iteration 52280, loss = 2.87936
I0605 05:28:04.975939   904 solver.cpp:245]     Train net output #0: loss = 2.97894 (* 1 = 2.97894 loss)
I0605 05:28:04.975957   904 sgd_solver.cpp:106] Iteration 52280, lr = 0.0276988
I0605 05:28:26.005146   904 solver.cpp:229] Iteration 52320, loss = 2.93837
I0605 05:28:26.005292   904 solver.cpp:245]     Train net output #0: loss = 2.98632 (* 1 = 2.98632 loss)
I0605 05:28:26.005300   904 sgd_solver.cpp:106] Iteration 52320, lr = 0.0276894
I0605 05:28:46.991662   904 solver.cpp:229] Iteration 52360, loss = 2.91146
I0605 05:28:46.991717   904 solver.cpp:245]     Train net output #0: loss = 2.63211 (* 1 = 2.63211 loss)
I0605 05:28:46.991724   904 sgd_solver.cpp:106] Iteration 52360, lr = 0.02768
I0605 05:29:07.647076   904 solver.cpp:229] Iteration 52400, loss = 2.88073
I0605 05:29:07.647223   904 solver.cpp:245]     Train net output #0: loss = 2.93178 (* 1 = 2.93178 loss)
I0605 05:29:07.647231   904 sgd_solver.cpp:106] Iteration 52400, lr = 0.0276706
I0605 05:29:28.289423   904 solver.cpp:229] Iteration 52440, loss = 2.87288
I0605 05:29:28.289477   904 solver.cpp:245]     Train net output #0: loss = 2.82684 (* 1 = 2.82684 loss)
I0605 05:29:28.289484   904 sgd_solver.cpp:106] Iteration 52440, lr = 0.0276612
I0605 05:29:48.978533   904 solver.cpp:229] Iteration 52480, loss = 2.919
I0605 05:29:48.978672   904 solver.cpp:245]     Train net output #0: loss = 3.31278 (* 1 = 3.31278 loss)
I0605 05:29:48.978684   904 sgd_solver.cpp:106] Iteration 52480, lr = 0.0276518
I0605 05:30:05.252331   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 05:30:09.648952   904 solver.cpp:229] Iteration 52520, loss = 2.90447
I0605 05:30:09.649006   904 solver.cpp:245]     Train net output #0: loss = 2.92314 (* 1 = 2.92314 loss)
I0605 05:30:09.649016   904 sgd_solver.cpp:106] Iteration 52520, lr = 0.0276424
I0605 05:30:30.301242   904 solver.cpp:229] Iteration 52560, loss = 2.95038
I0605 05:30:30.301391   904 solver.cpp:245]     Train net output #0: loss = 2.84841 (* 1 = 2.84841 loss)
I0605 05:30:30.301403   904 sgd_solver.cpp:106] Iteration 52560, lr = 0.0276329
I0605 05:30:50.942245   904 solver.cpp:229] Iteration 52600, loss = 2.92888
I0605 05:30:50.942301   904 solver.cpp:245]     Train net output #0: loss = 2.74497 (* 1 = 2.74497 loss)
I0605 05:30:50.942311   904 sgd_solver.cpp:106] Iteration 52600, lr = 0.0276235
I0605 05:31:11.605571   904 solver.cpp:229] Iteration 52640, loss = 2.93342
I0605 05:31:11.605693   904 solver.cpp:245]     Train net output #0: loss = 2.96425 (* 1 = 2.96425 loss)
I0605 05:31:11.605705   904 sgd_solver.cpp:106] Iteration 52640, lr = 0.0276141
I0605 05:31:32.134480   904 solver.cpp:229] Iteration 52680, loss = 2.89663
I0605 05:31:32.134522   904 solver.cpp:245]     Train net output #0: loss = 2.8096 (* 1 = 2.8096 loss)
I0605 05:31:32.134531   904 sgd_solver.cpp:106] Iteration 52680, lr = 0.0276047
I0605 05:31:52.679880   904 solver.cpp:229] Iteration 52720, loss = 2.92678
I0605 05:31:52.680165   904 solver.cpp:245]     Train net output #0: loss = 2.86098 (* 1 = 2.86098 loss)
I0605 05:31:52.680193   904 sgd_solver.cpp:106] Iteration 52720, lr = 0.0275953
I0605 05:32:13.362311   904 solver.cpp:229] Iteration 52760, loss = 2.89354
I0605 05:32:13.362352   904 solver.cpp:245]     Train net output #0: loss = 2.83133 (* 1 = 2.83133 loss)
I0605 05:32:13.362361   904 sgd_solver.cpp:106] Iteration 52760, lr = 0.0275859
I0605 05:32:33.979358   904 solver.cpp:229] Iteration 52800, loss = 2.90789
I0605 05:32:33.979605   904 solver.cpp:245]     Train net output #0: loss = 2.96965 (* 1 = 2.96965 loss)
I0605 05:32:33.979632   904 sgd_solver.cpp:106] Iteration 52800, lr = 0.0275765
I0605 05:32:54.502590   904 solver.cpp:229] Iteration 52840, loss = 2.93167
I0605 05:32:54.502631   904 solver.cpp:245]     Train net output #0: loss = 2.87337 (* 1 = 2.87337 loss)
I0605 05:32:54.502640   904 sgd_solver.cpp:106] Iteration 52840, lr = 0.0275671
I0605 05:33:15.031004   904 solver.cpp:229] Iteration 52880, loss = 2.91359
I0605 05:33:15.031193   904 solver.cpp:245]     Train net output #0: loss = 2.86846 (* 1 = 2.86846 loss)
I0605 05:33:15.031213   904 sgd_solver.cpp:106] Iteration 52880, lr = 0.0275576
I0605 05:33:35.531888   904 solver.cpp:229] Iteration 52920, loss = 2.88365
I0605 05:33:35.531962   904 solver.cpp:245]     Train net output #0: loss = 2.86755 (* 1 = 2.86755 loss)
I0605 05:33:35.531971   904 sgd_solver.cpp:106] Iteration 52920, lr = 0.0275482
I0605 05:33:56.051604   904 solver.cpp:229] Iteration 52960, loss = 2.87042
I0605 05:33:56.051772   904 solver.cpp:245]     Train net output #0: loss = 2.75959 (* 1 = 2.75959 loss)
I0605 05:33:56.051812   904 sgd_solver.cpp:106] Iteration 52960, lr = 0.0275388
I0605 05:34:16.056273   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_53000.caffemodel
I0605 05:34:16.320755   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_53000.solverstate
I0605 05:34:16.400187   904 solver.cpp:338] Iteration 53000, Testing net (#0)
I0605 05:34:16.400264   904 net.cpp:748] Ignoring source layer loss
I0605 05:34:17.502809   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 05:34:50.669327   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 05:35:22.912528   904 solver.cpp:406]     Test net output #0: accuracy = 0.387801
I0605 05:35:22.912710   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.638879
I0605 05:35:23.226753   904 solver.cpp:229] Iteration 53000, loss = 2.93076
I0605 05:35:23.226794   904 solver.cpp:245]     Train net output #0: loss = 3.27927 (* 1 = 3.27927 loss)
I0605 05:35:23.226804   904 sgd_solver.cpp:106] Iteration 53000, lr = 0.0275294
I0605 05:35:31.620932   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 05:35:42.449586   904 solver.cpp:229] Iteration 53040, loss = 2.96091
I0605 05:35:42.449625   904 solver.cpp:245]     Train net output #0: loss = 3.11976 (* 1 = 3.11976 loss)
I0605 05:35:42.449645   904 sgd_solver.cpp:106] Iteration 53040, lr = 0.02752
I0605 05:36:03.932824   904 solver.cpp:229] Iteration 53080, loss = 2.90235
I0605 05:36:03.932984   904 solver.cpp:245]     Train net output #0: loss = 2.76655 (* 1 = 2.76655 loss)
I0605 05:36:03.932996   904 sgd_solver.cpp:106] Iteration 53080, lr = 0.0275106
I0605 05:36:25.470639   904 solver.cpp:229] Iteration 53120, loss = 2.89175
I0605 05:36:25.470693   904 solver.cpp:245]     Train net output #0: loss = 2.95378 (* 1 = 2.95378 loss)
I0605 05:36:25.470705   904 sgd_solver.cpp:106] Iteration 53120, lr = 0.0275012
I0605 05:36:46.947358   904 solver.cpp:229] Iteration 53160, loss = 2.89696
I0605 05:36:46.947568   904 solver.cpp:245]     Train net output #0: loss = 3.11197 (* 1 = 3.11197 loss)
I0605 05:36:46.947594   904 sgd_solver.cpp:106] Iteration 53160, lr = 0.0274918
I0605 05:37:08.078107   904 solver.cpp:229] Iteration 53200, loss = 2.93263
I0605 05:37:08.078164   904 solver.cpp:245]     Train net output #0: loss = 2.99599 (* 1 = 2.99599 loss)
I0605 05:37:08.078176   904 sgd_solver.cpp:106] Iteration 53200, lr = 0.0274824
I0605 05:37:29.047525   904 solver.cpp:229] Iteration 53240, loss = 2.91221
I0605 05:37:29.047761   904 solver.cpp:245]     Train net output #0: loss = 2.86817 (* 1 = 2.86817 loss)
I0605 05:37:29.047788   904 sgd_solver.cpp:106] Iteration 53240, lr = 0.0274729
I0605 05:37:50.048450   904 solver.cpp:229] Iteration 53280, loss = 2.89375
I0605 05:37:50.048496   904 solver.cpp:245]     Train net output #0: loss = 2.7352 (* 1 = 2.7352 loss)
I0605 05:37:50.048507   904 sgd_solver.cpp:106] Iteration 53280, lr = 0.0274635
I0605 05:38:11.047767   904 solver.cpp:229] Iteration 53320, loss = 2.92821
I0605 05:38:11.047991   904 solver.cpp:245]     Train net output #0: loss = 2.90174 (* 1 = 2.90174 loss)
I0605 05:38:11.048019   904 sgd_solver.cpp:106] Iteration 53320, lr = 0.0274541
I0605 05:38:31.967530   904 solver.cpp:229] Iteration 53360, loss = 2.91199
I0605 05:38:31.967574   904 solver.cpp:245]     Train net output #0: loss = 3.00823 (* 1 = 3.00823 loss)
I0605 05:38:31.967583   904 sgd_solver.cpp:106] Iteration 53360, lr = 0.0274447
I0605 05:38:52.758877   904 solver.cpp:229] Iteration 53400, loss = 2.85971
I0605 05:38:52.759047   904 solver.cpp:245]     Train net output #0: loss = 2.85268 (* 1 = 2.85268 loss)
I0605 05:38:52.759075   904 sgd_solver.cpp:106] Iteration 53400, lr = 0.0274353
I0605 05:39:13.525974   904 solver.cpp:229] Iteration 53440, loss = 2.93451
I0605 05:39:13.526026   904 solver.cpp:245]     Train net output #0: loss = 2.74683 (* 1 = 2.74683 loss)
I0605 05:39:13.526036   904 sgd_solver.cpp:106] Iteration 53440, lr = 0.0274259
I0605 05:39:34.202877   904 solver.cpp:229] Iteration 53480, loss = 2.84263
I0605 05:39:34.203034   904 solver.cpp:245]     Train net output #0: loss = 2.98615 (* 1 = 2.98615 loss)
I0605 05:39:34.203058   904 sgd_solver.cpp:106] Iteration 53480, lr = 0.0274165
I0605 05:39:53.868198   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 05:39:54.900236   904 solver.cpp:229] Iteration 53520, loss = 2.91202
I0605 05:39:54.900295   904 solver.cpp:245]     Train net output #0: loss = 2.89315 (* 1 = 2.89315 loss)
I0605 05:39:54.900307   904 sgd_solver.cpp:106] Iteration 53520, lr = 0.0274071
I0605 05:40:15.552206   904 solver.cpp:229] Iteration 53560, loss = 2.87932
I0605 05:40:15.552394   904 solver.cpp:245]     Train net output #0: loss = 2.94583 (* 1 = 2.94583 loss)
I0605 05:40:15.552423   904 sgd_solver.cpp:106] Iteration 53560, lr = 0.0273976
I0605 05:40:36.229101   904 solver.cpp:229] Iteration 53600, loss = 2.90143
I0605 05:40:36.229154   904 solver.cpp:245]     Train net output #0: loss = 3.13953 (* 1 = 3.13953 loss)
I0605 05:40:36.229174   904 sgd_solver.cpp:106] Iteration 53600, lr = 0.0273882
I0605 05:40:56.753485   904 solver.cpp:229] Iteration 53640, loss = 2.88596
I0605 05:40:56.753718   904 solver.cpp:245]     Train net output #0: loss = 3.04243 (* 1 = 3.04243 loss)
I0605 05:40:56.753752   904 sgd_solver.cpp:106] Iteration 53640, lr = 0.0273788
I0605 05:41:17.246731   904 solver.cpp:229] Iteration 53680, loss = 2.89903
I0605 05:41:17.246790   904 solver.cpp:245]     Train net output #0: loss = 2.81251 (* 1 = 2.81251 loss)
I0605 05:41:17.246801   904 sgd_solver.cpp:106] Iteration 53680, lr = 0.0273694
I0605 05:41:37.722429   904 solver.cpp:229] Iteration 53720, loss = 2.92424
I0605 05:41:37.722635   904 solver.cpp:245]     Train net output #0: loss = 2.73033 (* 1 = 2.73033 loss)
I0605 05:41:37.722666   904 sgd_solver.cpp:106] Iteration 53720, lr = 0.02736
I0605 05:41:58.221923   904 solver.cpp:229] Iteration 53760, loss = 2.90756
I0605 05:41:58.221976   904 solver.cpp:245]     Train net output #0: loss = 2.95314 (* 1 = 2.95314 loss)
I0605 05:41:58.221987   904 sgd_solver.cpp:106] Iteration 53760, lr = 0.0273506
I0605 05:42:18.695425   904 solver.cpp:229] Iteration 53800, loss = 2.87629
I0605 05:42:18.695648   904 solver.cpp:245]     Train net output #0: loss = 3.13271 (* 1 = 3.13271 loss)
I0605 05:42:18.695674   904 sgd_solver.cpp:106] Iteration 53800, lr = 0.0273412
I0605 05:42:39.201373   904 solver.cpp:229] Iteration 53840, loss = 2.88886
I0605 05:42:39.201419   904 solver.cpp:245]     Train net output #0: loss = 2.82298 (* 1 = 2.82298 loss)
I0605 05:42:39.201428   904 sgd_solver.cpp:106] Iteration 53840, lr = 0.0273318
I0605 05:42:59.689270   904 solver.cpp:229] Iteration 53880, loss = 2.88429
I0605 05:42:59.689486   904 solver.cpp:245]     Train net output #0: loss = 3.14863 (* 1 = 3.14863 loss)
I0605 05:42:59.689512   904 sgd_solver.cpp:106] Iteration 53880, lr = 0.0273224
I0605 05:43:20.137965   904 solver.cpp:229] Iteration 53920, loss = 2.95215
I0605 05:43:20.138011   904 solver.cpp:245]     Train net output #0: loss = 3.04034 (* 1 = 3.04034 loss)
I0605 05:43:20.138020   904 sgd_solver.cpp:106] Iteration 53920, lr = 0.0273129
I0605 05:43:40.354969   904 solver.cpp:229] Iteration 53960, loss = 2.91969
I0605 05:43:40.355197   904 solver.cpp:245]     Train net output #0: loss = 2.90662 (* 1 = 2.90662 loss)
I0605 05:43:40.355227   904 sgd_solver.cpp:106] Iteration 53960, lr = 0.0273035
I0605 05:43:59.971149   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_54000.caffemodel
I0605 05:44:00.236273   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_54000.solverstate
I0605 05:44:00.310622   904 solver.cpp:338] Iteration 54000, Testing net (#0)
I0605 05:44:00.310791   904 net.cpp:748] Ignoring source layer loss
I0605 05:44:02.895180   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 05:44:36.297102   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 05:45:07.491919   904 solver.cpp:406]     Test net output #0: accuracy = 0.386081
I0605 05:45:07.492125   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.640899
I0605 05:45:07.805063   904 solver.cpp:229] Iteration 54000, loss = 2.92346
I0605 05:45:07.805119   904 solver.cpp:245]     Train net output #0: loss = 2.85007 (* 1 = 2.85007 loss)
I0605 05:45:07.805131   904 sgd_solver.cpp:106] Iteration 54000, lr = 0.0272941
I0605 05:45:26.480190   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 05:45:26.956094   904 solver.cpp:229] Iteration 54040, loss = 2.90834
I0605 05:45:26.956151   904 solver.cpp:245]     Train net output #0: loss = 2.58247 (* 1 = 2.58247 loss)
I0605 05:45:26.956163   904 sgd_solver.cpp:106] Iteration 54040, lr = 0.0272847
I0605 05:45:47.479079   904 solver.cpp:229] Iteration 54080, loss = 2.89688
I0605 05:45:47.479282   904 solver.cpp:245]     Train net output #0: loss = 3.11927 (* 1 = 3.11927 loss)
I0605 05:45:47.479306   904 sgd_solver.cpp:106] Iteration 54080, lr = 0.0272753
I0605 05:46:08.327107   904 solver.cpp:229] Iteration 54120, loss = 2.89937
I0605 05:46:08.327157   904 solver.cpp:245]     Train net output #0: loss = 2.89833 (* 1 = 2.89833 loss)
I0605 05:46:08.327165   904 sgd_solver.cpp:106] Iteration 54120, lr = 0.0272659
I0605 05:46:28.844058   904 solver.cpp:229] Iteration 54160, loss = 2.91975
I0605 05:46:28.844293   904 solver.cpp:245]     Train net output #0: loss = 2.88853 (* 1 = 2.88853 loss)
I0605 05:46:28.844316   904 sgd_solver.cpp:106] Iteration 54160, lr = 0.0272565
I0605 05:46:49.474324   904 solver.cpp:229] Iteration 54200, loss = 2.89885
I0605 05:46:49.474385   904 solver.cpp:245]     Train net output #0: loss = 3.0883 (* 1 = 3.0883 loss)
I0605 05:46:49.474405   904 sgd_solver.cpp:106] Iteration 54200, lr = 0.0272471
I0605 05:47:10.254226   904 solver.cpp:229] Iteration 54240, loss = 2.89983
I0605 05:47:10.254338   904 solver.cpp:245]     Train net output #0: loss = 2.97381 (* 1 = 2.97381 loss)
I0605 05:47:10.254348   904 sgd_solver.cpp:106] Iteration 54240, lr = 0.0272376
I0605 05:47:30.914506   904 solver.cpp:229] Iteration 54280, loss = 2.86175
I0605 05:47:30.914556   904 solver.cpp:245]     Train net output #0: loss = 2.93858 (* 1 = 2.93858 loss)
I0605 05:47:30.914577   904 sgd_solver.cpp:106] Iteration 54280, lr = 0.0272282
I0605 05:47:51.383635   904 solver.cpp:229] Iteration 54320, loss = 2.89321
I0605 05:47:51.383894   904 solver.cpp:245]     Train net output #0: loss = 2.9865 (* 1 = 2.9865 loss)
I0605 05:47:51.383926   904 sgd_solver.cpp:106] Iteration 54320, lr = 0.0272188
I0605 05:48:11.867004   904 solver.cpp:229] Iteration 54360, loss = 2.8875
I0605 05:48:11.867056   904 solver.cpp:245]     Train net output #0: loss = 2.7153 (* 1 = 2.7153 loss)
I0605 05:48:11.867079   904 sgd_solver.cpp:106] Iteration 54360, lr = 0.0272094
I0605 05:48:32.439018   904 solver.cpp:229] Iteration 54400, loss = 2.88367
I0605 05:48:32.439203   904 solver.cpp:245]     Train net output #0: loss = 2.94462 (* 1 = 2.94462 loss)
I0605 05:48:32.439226   904 sgd_solver.cpp:106] Iteration 54400, lr = 0.0272
I0605 05:48:52.992558   904 solver.cpp:229] Iteration 54440, loss = 2.86596
I0605 05:48:52.992601   904 solver.cpp:245]     Train net output #0: loss = 2.96384 (* 1 = 2.96384 loss)
I0605 05:48:52.992621   904 sgd_solver.cpp:106] Iteration 54440, lr = 0.0271906
I0605 05:49:13.476775   904 solver.cpp:229] Iteration 54480, loss = 2.86087
I0605 05:49:13.476950   904 solver.cpp:245]     Train net output #0: loss = 2.75359 (* 1 = 2.75359 loss)
I0605 05:49:13.476972   904 sgd_solver.cpp:106] Iteration 54480, lr = 0.0271812
I0605 05:49:33.953320   904 solver.cpp:229] Iteration 54520, loss = 2.88747
I0605 05:49:33.953368   904 solver.cpp:245]     Train net output #0: loss = 2.91423 (* 1 = 2.91423 loss)
I0605 05:49:33.953377   904 sgd_solver.cpp:106] Iteration 54520, lr = 0.0271718
I0605 05:49:54.165307   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 05:49:54.425413   904 solver.cpp:229] Iteration 54560, loss = 2.89258
I0605 05:49:54.425454   904 solver.cpp:245]     Train net output #0: loss = 3.0691 (* 1 = 3.0691 loss)
I0605 05:49:54.425469   904 sgd_solver.cpp:106] Iteration 54560, lr = 0.0271624
I0605 05:50:14.931521   904 solver.cpp:229] Iteration 54600, loss = 2.89101
I0605 05:50:14.931574   904 solver.cpp:245]     Train net output #0: loss = 2.793 (* 1 = 2.793 loss)
I0605 05:50:14.931593   904 sgd_solver.cpp:106] Iteration 54600, lr = 0.0271529
I0605 05:50:35.411700   904 solver.cpp:229] Iteration 54640, loss = 2.90003
I0605 05:50:35.411907   904 solver.cpp:245]     Train net output #0: loss = 2.84054 (* 1 = 2.84054 loss)
I0605 05:50:35.411942   904 sgd_solver.cpp:106] Iteration 54640, lr = 0.0271435
I0605 05:50:55.800165   904 solver.cpp:229] Iteration 54680, loss = 2.86028
I0605 05:50:55.800225   904 solver.cpp:245]     Train net output #0: loss = 2.67772 (* 1 = 2.67772 loss)
I0605 05:50:55.800235   904 sgd_solver.cpp:106] Iteration 54680, lr = 0.0271341
I0605 05:51:16.058351   904 solver.cpp:229] Iteration 54720, loss = 2.91259
I0605 05:51:16.058538   904 solver.cpp:245]     Train net output #0: loss = 2.97657 (* 1 = 2.97657 loss)
I0605 05:51:16.058563   904 sgd_solver.cpp:106] Iteration 54720, lr = 0.0271247
I0605 05:51:36.346318   904 solver.cpp:229] Iteration 54760, loss = 2.85505
I0605 05:51:36.346374   904 solver.cpp:245]     Train net output #0: loss = 2.90174 (* 1 = 2.90174 loss)
I0605 05:51:36.346386   904 sgd_solver.cpp:106] Iteration 54760, lr = 0.0271153
I0605 05:51:56.613504   904 solver.cpp:229] Iteration 54800, loss = 2.89819
I0605 05:51:56.613706   904 solver.cpp:245]     Train net output #0: loss = 2.90344 (* 1 = 2.90344 loss)
I0605 05:51:56.613723   904 sgd_solver.cpp:106] Iteration 54800, lr = 0.0271059
I0605 05:52:16.841897   904 solver.cpp:229] Iteration 54840, loss = 2.91022
I0605 05:52:16.841931   904 solver.cpp:245]     Train net output #0: loss = 3.33717 (* 1 = 3.33717 loss)
I0605 05:52:16.841944   904 sgd_solver.cpp:106] Iteration 54840, lr = 0.0270965
I0605 05:52:37.073869   904 solver.cpp:229] Iteration 54880, loss = 2.86869
I0605 05:52:37.073997   904 solver.cpp:245]     Train net output #0: loss = 2.92364 (* 1 = 2.92364 loss)
I0605 05:52:37.074007   904 sgd_solver.cpp:106] Iteration 54880, lr = 0.0270871
I0605 05:52:57.331223   904 solver.cpp:229] Iteration 54920, loss = 2.87609
I0605 05:52:57.331261   904 solver.cpp:245]     Train net output #0: loss = 2.84372 (* 1 = 2.84372 loss)
I0605 05:52:57.331269   904 sgd_solver.cpp:106] Iteration 54920, lr = 0.0270776
I0605 05:53:17.562191   904 solver.cpp:229] Iteration 54960, loss = 2.91526
I0605 05:53:17.562440   904 solver.cpp:245]     Train net output #0: loss = 3.09753 (* 1 = 3.09753 loss)
I0605 05:53:17.562476   904 sgd_solver.cpp:106] Iteration 54960, lr = 0.0270682
I0605 05:53:37.317353   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_55000.caffemodel
I0605 05:53:37.575739   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_55000.solverstate
I0605 05:53:37.652981   904 solver.cpp:338] Iteration 55000, Testing net (#0)
I0605 05:53:37.653062   904 net.cpp:748] Ignoring source layer loss
I0605 05:53:44.554471   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 05:54:22.897243   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 05:54:49.787379   904 solver.cpp:406]     Test net output #0: accuracy = 0.394542
I0605 05:54:49.787420   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.643919
I0605 05:54:50.101892   904 solver.cpp:229] Iteration 55000, loss = 2.91591
I0605 05:54:50.101939   904 solver.cpp:245]     Train net output #0: loss = 2.88733 (* 1 = 2.88733 loss)
I0605 05:54:50.101948   904 sgd_solver.cpp:106] Iteration 55000, lr = 0.0270588
I0605 05:55:09.318851   904 solver.cpp:229] Iteration 55040, loss = 2.89917
I0605 05:55:09.319041   904 solver.cpp:245]     Train net output #0: loss = 2.82115 (* 1 = 2.82115 loss)
I0605 05:55:09.319064   904 sgd_solver.cpp:106] Iteration 55040, lr = 0.0270494
I0605 05:55:30.772586   904 solver.cpp:229] Iteration 55080, loss = 2.89951
I0605 05:55:30.772620   904 solver.cpp:245]     Train net output #0: loss = 2.78499 (* 1 = 2.78499 loss)
I0605 05:55:30.772627   904 sgd_solver.cpp:106] Iteration 55080, lr = 0.02704
I0605 05:55:48.762995   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 05:55:52.178797   904 solver.cpp:229] Iteration 55120, loss = 2.87254
I0605 05:55:52.178838   904 solver.cpp:245]     Train net output #0: loss = 2.76067 (* 1 = 2.76067 loss)
I0605 05:55:52.178844   904 sgd_solver.cpp:106] Iteration 55120, lr = 0.0270306
I0605 05:56:12.972653   904 solver.cpp:229] Iteration 55160, loss = 2.88904
I0605 05:56:12.972703   904 solver.cpp:245]     Train net output #0: loss = 2.80206 (* 1 = 2.80206 loss)
I0605 05:56:12.972713   904 sgd_solver.cpp:106] Iteration 55160, lr = 0.0270212
I0605 05:56:33.904094   904 solver.cpp:229] Iteration 55200, loss = 2.8724
I0605 05:56:33.904247   904 solver.cpp:245]     Train net output #0: loss = 2.8656 (* 1 = 2.8656 loss)
I0605 05:56:33.904259   904 sgd_solver.cpp:106] Iteration 55200, lr = 0.0270118
I0605 05:56:54.864364   904 solver.cpp:229] Iteration 55240, loss = 2.89901
I0605 05:56:54.864416   904 solver.cpp:245]     Train net output #0: loss = 3.30628 (* 1 = 3.30628 loss)
I0605 05:56:54.864423   904 sgd_solver.cpp:106] Iteration 55240, lr = 0.0270024
I0605 05:57:15.829908   904 solver.cpp:229] Iteration 55280, loss = 2.89697
I0605 05:57:15.830046   904 solver.cpp:245]     Train net output #0: loss = 2.90362 (* 1 = 2.90362 loss)
I0605 05:57:15.830055   904 sgd_solver.cpp:106] Iteration 55280, lr = 0.0269929
I0605 05:57:36.644541   904 solver.cpp:229] Iteration 55320, loss = 2.90286
I0605 05:57:36.644605   904 solver.cpp:245]     Train net output #0: loss = 2.81953 (* 1 = 2.81953 loss)
I0605 05:57:36.644613   904 sgd_solver.cpp:106] Iteration 55320, lr = 0.0269835
I0605 05:57:57.294927   904 solver.cpp:229] Iteration 55360, loss = 2.87511
I0605 05:57:57.295107   904 solver.cpp:245]     Train net output #0: loss = 3.04377 (* 1 = 3.04377 loss)
I0605 05:57:57.295142   904 sgd_solver.cpp:106] Iteration 55360, lr = 0.0269741
I0605 05:58:17.969100   904 solver.cpp:229] Iteration 55400, loss = 2.83994
I0605 05:58:17.969154   904 solver.cpp:245]     Train net output #0: loss = 2.67771 (* 1 = 2.67771 loss)
I0605 05:58:17.969163   904 sgd_solver.cpp:106] Iteration 55400, lr = 0.0269647
I0605 05:58:38.659178   904 solver.cpp:229] Iteration 55440, loss = 2.83927
I0605 05:58:38.659427   904 solver.cpp:245]     Train net output #0: loss = 3.05539 (* 1 = 3.05539 loss)
I0605 05:58:38.659438   904 sgd_solver.cpp:106] Iteration 55440, lr = 0.0269553
I0605 05:58:59.344189   904 solver.cpp:229] Iteration 55480, loss = 2.89831
I0605 05:58:59.344240   904 solver.cpp:245]     Train net output #0: loss = 2.80678 (* 1 = 2.80678 loss)
I0605 05:58:59.344249   904 sgd_solver.cpp:106] Iteration 55480, lr = 0.0269459
I0605 05:59:19.997002   904 solver.cpp:229] Iteration 55520, loss = 2.89084
I0605 05:59:19.997210   904 solver.cpp:245]     Train net output #0: loss = 2.88831 (* 1 = 2.88831 loss)
I0605 05:59:19.997239   904 sgd_solver.cpp:106] Iteration 55520, lr = 0.0269365
I0605 05:59:40.658231   904 solver.cpp:229] Iteration 55560, loss = 2.90824
I0605 05:59:40.658294   904 solver.cpp:245]     Train net output #0: loss = 2.8187 (* 1 = 2.8187 loss)
I0605 05:59:40.658303   904 sgd_solver.cpp:106] Iteration 55560, lr = 0.0269271
I0605 06:00:01.313267   904 solver.cpp:229] Iteration 55600, loss = 2.87321
I0605 06:00:01.313488   904 solver.cpp:245]     Train net output #0: loss = 2.93364 (* 1 = 2.93364 loss)
I0605 06:00:01.313511   904 sgd_solver.cpp:106] Iteration 55600, lr = 0.0269176
I0605 06:00:21.802678   904 solver.cpp:229] Iteration 55640, loss = 2.91241
I0605 06:00:21.802728   904 solver.cpp:245]     Train net output #0: loss = 2.90112 (* 1 = 2.90112 loss)
I0605 06:00:21.802737   904 sgd_solver.cpp:106] Iteration 55640, lr = 0.0269082
I0605 06:00:35.916306   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 06:00:42.366168   904 solver.cpp:229] Iteration 55680, loss = 2.95211
I0605 06:00:42.366222   904 solver.cpp:245]     Train net output #0: loss = 3.05525 (* 1 = 3.05525 loss)
I0605 06:00:42.366232   904 sgd_solver.cpp:106] Iteration 55680, lr = 0.0268988
I0605 06:01:03.015943   904 solver.cpp:229] Iteration 55720, loss = 2.8938
I0605 06:01:03.015993   904 solver.cpp:245]     Train net output #0: loss = 3.0906 (* 1 = 3.0906 loss)
I0605 06:01:03.016015   904 sgd_solver.cpp:106] Iteration 55720, lr = 0.0268894
I0605 06:01:23.550446   904 solver.cpp:229] Iteration 55760, loss = 2.85338
I0605 06:01:23.550648   904 solver.cpp:245]     Train net output #0: loss = 2.58015 (* 1 = 2.58015 loss)
I0605 06:01:23.550669   904 sgd_solver.cpp:106] Iteration 55760, lr = 0.02688
I0605 06:01:44.064276   904 solver.cpp:229] Iteration 55800, loss = 2.92689
I0605 06:01:44.064326   904 solver.cpp:245]     Train net output #0: loss = 2.76767 (* 1 = 2.76767 loss)
I0605 06:01:44.064334   904 sgd_solver.cpp:106] Iteration 55800, lr = 0.0268706
I0605 06:02:04.561588   904 solver.cpp:229] Iteration 55840, loss = 2.85288
I0605 06:02:04.561790   904 solver.cpp:245]     Train net output #0: loss = 2.86775 (* 1 = 2.86775 loss)
I0605 06:02:04.561821   904 sgd_solver.cpp:106] Iteration 55840, lr = 0.0268612
I0605 06:02:25.054519   904 solver.cpp:229] Iteration 55880, loss = 2.84711
I0605 06:02:25.054560   904 solver.cpp:245]     Train net output #0: loss = 2.82245 (* 1 = 2.82245 loss)
I0605 06:02:25.054569   904 sgd_solver.cpp:106] Iteration 55880, lr = 0.0268518
I0605 06:02:45.551776   904 solver.cpp:229] Iteration 55920, loss = 2.89508
I0605 06:02:45.551964   904 solver.cpp:245]     Train net output #0: loss = 2.88232 (* 1 = 2.88232 loss)
I0605 06:02:45.551986   904 sgd_solver.cpp:106] Iteration 55920, lr = 0.0268424
I0605 06:03:06.076017   904 solver.cpp:229] Iteration 55960, loss = 2.88842
I0605 06:03:06.076081   904 solver.cpp:245]     Train net output #0: loss = 2.7717 (* 1 = 2.7717 loss)
I0605 06:03:06.076102   904 sgd_solver.cpp:106] Iteration 55960, lr = 0.0268329
I0605 06:03:26.067972   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_56000.caffemodel
I0605 06:03:26.334843   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_56000.solverstate
I0605 06:03:26.411880   904 solver.cpp:338] Iteration 56000, Testing net (#0)
I0605 06:03:26.411962   904 net.cpp:748] Ignoring source layer loss
I0605 06:03:39.600601   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 06:04:13.161164   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 06:04:33.159400   904 solver.cpp:406]     Test net output #0: accuracy = 0.387281
I0605 06:04:33.159438   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.643339
I0605 06:04:33.474908   904 solver.cpp:229] Iteration 56000, loss = 2.8712
I0605 06:04:33.474953   904 solver.cpp:245]     Train net output #0: loss = 2.80806 (* 1 = 2.80806 loss)
I0605 06:04:33.474962   904 sgd_solver.cpp:106] Iteration 56000, lr = 0.0268235
I0605 06:04:52.671118   904 solver.cpp:229] Iteration 56040, loss = 2.86992
I0605 06:04:52.671243   904 solver.cpp:245]     Train net output #0: loss = 2.60655 (* 1 = 2.60655 loss)
I0605 06:04:52.671253   904 sgd_solver.cpp:106] Iteration 56040, lr = 0.0268141
I0605 06:05:14.079315   904 solver.cpp:229] Iteration 56080, loss = 2.85015
I0605 06:05:14.079360   904 solver.cpp:245]     Train net output #0: loss = 2.82783 (* 1 = 2.82783 loss)
I0605 06:05:14.079370   904 sgd_solver.cpp:106] Iteration 56080, lr = 0.0268047
I0605 06:05:35.427812   904 solver.cpp:229] Iteration 56120, loss = 2.86769
I0605 06:05:35.428053   904 solver.cpp:245]     Train net output #0: loss = 2.88417 (* 1 = 2.88417 loss)
I0605 06:05:35.428078   904 sgd_solver.cpp:106] Iteration 56120, lr = 0.0267953
I0605 06:05:56.732764   904 solver.cpp:229] Iteration 56160, loss = 2.87082
I0605 06:05:56.732812   904 solver.cpp:245]     Train net output #0: loss = 3.21038 (* 1 = 3.21038 loss)
I0605 06:05:56.732821   904 sgd_solver.cpp:106] Iteration 56160, lr = 0.0267859
I0605 06:06:17.679064   904 solver.cpp:229] Iteration 56200, loss = 2.88966
I0605 06:06:17.679257   904 solver.cpp:245]     Train net output #0: loss = 2.96832 (* 1 = 2.96832 loss)
I0605 06:06:17.679282   904 sgd_solver.cpp:106] Iteration 56200, lr = 0.0267765
I0605 06:06:38.611266   904 solver.cpp:229] Iteration 56240, loss = 2.89391
I0605 06:06:38.611310   904 solver.cpp:245]     Train net output #0: loss = 3.17743 (* 1 = 3.17743 loss)
I0605 06:06:38.611317   904 sgd_solver.cpp:106] Iteration 56240, lr = 0.0267671
I0605 06:06:41.224161   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 06:06:59.515095   904 solver.cpp:229] Iteration 56280, loss = 2.90022
I0605 06:06:59.515260   904 solver.cpp:245]     Train net output #0: loss = 2.9812 (* 1 = 2.9812 loss)
I0605 06:06:59.515271   904 sgd_solver.cpp:106] Iteration 56280, lr = 0.0267576
I0605 06:07:20.435263   904 solver.cpp:229] Iteration 56320, loss = 2.84541
I0605 06:07:20.435314   904 solver.cpp:245]     Train net output #0: loss = 2.74189 (* 1 = 2.74189 loss)
I0605 06:07:20.435326   904 sgd_solver.cpp:106] Iteration 56320, lr = 0.0267482
I0605 06:07:41.424227   904 solver.cpp:229] Iteration 56360, loss = 2.82173
I0605 06:07:41.424437   904 solver.cpp:245]     Train net output #0: loss = 3.13222 (* 1 = 3.13222 loss)
I0605 06:07:41.424458   904 sgd_solver.cpp:106] Iteration 56360, lr = 0.0267388
I0605 06:08:01.968199   904 solver.cpp:229] Iteration 56400, loss = 2.88576
I0605 06:08:01.968243   904 solver.cpp:245]     Train net output #0: loss = 2.81535 (* 1 = 2.81535 loss)
I0605 06:08:01.968253   904 sgd_solver.cpp:106] Iteration 56400, lr = 0.0267294
I0605 06:08:22.544941   904 solver.cpp:229] Iteration 56440, loss = 2.90264
I0605 06:08:22.545126   904 solver.cpp:245]     Train net output #0: loss = 2.78579 (* 1 = 2.78579 loss)
I0605 06:08:22.545156   904 sgd_solver.cpp:106] Iteration 56440, lr = 0.02672
I0605 06:08:43.133294   904 solver.cpp:229] Iteration 56480, loss = 2.89897
I0605 06:08:43.133342   904 solver.cpp:245]     Train net output #0: loss = 2.96038 (* 1 = 2.96038 loss)
I0605 06:08:43.133352   904 sgd_solver.cpp:106] Iteration 56480, lr = 0.0267106
I0605 06:09:03.738034   904 solver.cpp:229] Iteration 56520, loss = 2.91198
I0605 06:09:03.738215   904 solver.cpp:245]     Train net output #0: loss = 3.01882 (* 1 = 3.01882 loss)
I0605 06:09:03.738235   904 sgd_solver.cpp:106] Iteration 56520, lr = 0.0267012
I0605 06:09:24.206280   904 solver.cpp:229] Iteration 56560, loss = 2.85892
I0605 06:09:24.206322   904 solver.cpp:245]     Train net output #0: loss = 2.90904 (* 1 = 2.90904 loss)
I0605 06:09:24.206331   904 sgd_solver.cpp:106] Iteration 56560, lr = 0.0266918
I0605 06:09:44.666461   904 solver.cpp:229] Iteration 56600, loss = 2.85029
I0605 06:09:44.666730   904 solver.cpp:245]     Train net output #0: loss = 2.89501 (* 1 = 2.89501 loss)
I0605 06:09:44.666752   904 sgd_solver.cpp:106] Iteration 56600, lr = 0.0266824
I0605 06:10:05.115509   904 solver.cpp:229] Iteration 56640, loss = 2.86859
I0605 06:10:05.115550   904 solver.cpp:245]     Train net output #0: loss = 2.9594 (* 1 = 2.9594 loss)
I0605 06:10:05.115558   904 sgd_solver.cpp:106] Iteration 56640, lr = 0.0266729
I0605 06:10:25.542294   904 solver.cpp:229] Iteration 56680, loss = 2.8516
I0605 06:10:25.542465   904 solver.cpp:245]     Train net output #0: loss = 2.81108 (* 1 = 2.81108 loss)
I0605 06:10:25.542474   904 sgd_solver.cpp:106] Iteration 56680, lr = 0.0266635
I0605 06:10:45.988924   904 solver.cpp:229] Iteration 56720, loss = 2.8878
I0605 06:10:45.988965   904 solver.cpp:245]     Train net output #0: loss = 2.68459 (* 1 = 2.68459 loss)
I0605 06:10:45.988984   904 sgd_solver.cpp:106] Iteration 56720, lr = 0.0266541
I0605 06:11:06.407989   904 solver.cpp:229] Iteration 56760, loss = 2.85834
I0605 06:11:06.408226   904 solver.cpp:245]     Train net output #0: loss = 2.84298 (* 1 = 2.84298 loss)
I0605 06:11:06.408252   904 sgd_solver.cpp:106] Iteration 56760, lr = 0.0266447
I0605 06:11:14.583971   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 06:11:26.851886   904 solver.cpp:229] Iteration 56800, loss = 2.83312
I0605 06:11:26.851922   904 solver.cpp:245]     Train net output #0: loss = 2.74967 (* 1 = 2.74967 loss)
I0605 06:11:26.851930   904 sgd_solver.cpp:106] Iteration 56800, lr = 0.0266353
I0605 06:11:47.102751   904 solver.cpp:229] Iteration 56840, loss = 2.87655
I0605 06:11:47.102918   904 solver.cpp:245]     Train net output #0: loss = 2.86203 (* 1 = 2.86203 loss)
I0605 06:11:47.102944   904 sgd_solver.cpp:106] Iteration 56840, lr = 0.0266259
I0605 06:12:07.348899   904 solver.cpp:229] Iteration 56880, loss = 2.84431
I0605 06:12:07.348940   904 solver.cpp:245]     Train net output #0: loss = 2.81688 (* 1 = 2.81688 loss)
I0605 06:12:07.348949   904 sgd_solver.cpp:106] Iteration 56880, lr = 0.0266165
I0605 06:12:27.570830   904 solver.cpp:229] Iteration 56920, loss = 2.87097
I0605 06:12:27.571045   904 solver.cpp:245]     Train net output #0: loss = 2.91842 (* 1 = 2.91842 loss)
I0605 06:12:27.571079   904 sgd_solver.cpp:106] Iteration 56920, lr = 0.0266071
I0605 06:12:47.782871   904 solver.cpp:229] Iteration 56960, loss = 2.83379
I0605 06:12:47.782922   904 solver.cpp:245]     Train net output #0: loss = 2.89571 (* 1 = 2.89571 loss)
I0605 06:12:47.782930   904 sgd_solver.cpp:106] Iteration 56960, lr = 0.0265976
I0605 06:13:07.506455   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_57000.caffemodel
I0605 06:13:07.774718   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_57000.solverstate
I0605 06:13:07.855849   904 solver.cpp:338] Iteration 57000, Testing net (#0)
I0605 06:13:07.855923   904 net.cpp:748] Ignoring source layer loss
I0605 06:13:34.917217   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 06:14:08.513692   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 06:14:23.739287   904 solver.cpp:406]     Test net output #0: accuracy = 0.396621
I0605 06:14:23.739328   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.648499
I0605 06:14:24.053449   904 solver.cpp:229] Iteration 57000, loss = 2.83225
I0605 06:14:24.053489   904 solver.cpp:245]     Train net output #0: loss = 2.86175 (* 1 = 2.86175 loss)
I0605 06:14:24.053498   904 sgd_solver.cpp:106] Iteration 57000, lr = 0.0265882
I0605 06:14:43.561370   904 solver.cpp:229] Iteration 57040, loss = 2.81657
I0605 06:14:43.561586   904 solver.cpp:245]     Train net output #0: loss = 2.95183 (* 1 = 2.95183 loss)
I0605 06:14:43.561614   904 sgd_solver.cpp:106] Iteration 57040, lr = 0.0265788
I0605 06:15:05.107128   904 solver.cpp:229] Iteration 57080, loss = 2.85577
I0605 06:15:05.107184   904 solver.cpp:245]     Train net output #0: loss = 2.83155 (* 1 = 2.83155 loss)
I0605 06:15:05.107194   904 sgd_solver.cpp:106] Iteration 57080, lr = 0.0265694
I0605 06:15:26.201738   904 solver.cpp:229] Iteration 57120, loss = 2.84274
I0605 06:15:26.201858   904 solver.cpp:245]     Train net output #0: loss = 2.78646 (* 1 = 2.78646 loss)
I0605 06:15:26.201867   904 sgd_solver.cpp:106] Iteration 57120, lr = 0.02656
I0605 06:15:47.022187   904 solver.cpp:229] Iteration 57160, loss = 2.87904
I0605 06:15:47.022235   904 solver.cpp:245]     Train net output #0: loss = 2.54134 (* 1 = 2.54134 loss)
I0605 06:15:47.022248   904 sgd_solver.cpp:106] Iteration 57160, lr = 0.0265506
I0605 06:16:07.857959   904 solver.cpp:229] Iteration 57200, loss = 2.85807
I0605 06:16:07.858095   904 solver.cpp:245]     Train net output #0: loss = 2.78973 (* 1 = 2.78973 loss)
I0605 06:16:07.858105   904 sgd_solver.cpp:106] Iteration 57200, lr = 0.0265412
I0605 06:16:28.695071   904 solver.cpp:229] Iteration 57240, loss = 2.86032
I0605 06:16:28.695179   904 solver.cpp:245]     Train net output #0: loss = 2.81421 (* 1 = 2.81421 loss)
I0605 06:16:28.695204   904 sgd_solver.cpp:106] Iteration 57240, lr = 0.0265318
I0605 06:16:49.440228   904 solver.cpp:229] Iteration 57280, loss = 2.83688
I0605 06:16:49.440444   904 solver.cpp:245]     Train net output #0: loss = 2.73884 (* 1 = 2.73884 loss)
I0605 06:16:49.440476   904 sgd_solver.cpp:106] Iteration 57280, lr = 0.0265224
I0605 06:16:56.163832   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 06:17:10.124058   904 solver.cpp:229] Iteration 57320, loss = 2.89261
I0605 06:17:10.124094   904 solver.cpp:245]     Train net output #0: loss = 2.83098 (* 1 = 2.83098 loss)
I0605 06:17:10.124101   904 sgd_solver.cpp:106] Iteration 57320, lr = 0.0265129
I0605 06:17:30.789446   904 solver.cpp:229] Iteration 57360, loss = 2.84618
I0605 06:17:30.789679   904 solver.cpp:245]     Train net output #0: loss = 2.8741 (* 1 = 2.8741 loss)
I0605 06:17:30.789705   904 sgd_solver.cpp:106] Iteration 57360, lr = 0.0265035
I0605 06:17:51.490425   904 solver.cpp:229] Iteration 57400, loss = 2.83861
I0605 06:17:51.490468   904 solver.cpp:245]     Train net output #0: loss = 3.0142 (* 1 = 3.0142 loss)
I0605 06:17:51.490474   904 sgd_solver.cpp:106] Iteration 57400, lr = 0.0264941
I0605 06:18:12.058853   904 solver.cpp:229] Iteration 57440, loss = 2.8705
I0605 06:18:12.059000   904 solver.cpp:245]     Train net output #0: loss = 2.86051 (* 1 = 2.86051 loss)
I0605 06:18:12.059015   904 sgd_solver.cpp:106] Iteration 57440, lr = 0.0264847
I0605 06:18:32.558348   904 solver.cpp:229] Iteration 57480, loss = 2.84188
I0605 06:18:32.558396   904 solver.cpp:245]     Train net output #0: loss = 2.77241 (* 1 = 2.77241 loss)
I0605 06:18:32.558408   904 sgd_solver.cpp:106] Iteration 57480, lr = 0.0264753
I0605 06:18:53.063868   904 solver.cpp:229] Iteration 57520, loss = 2.84514
I0605 06:18:53.064080   904 solver.cpp:245]     Train net output #0: loss = 2.74053 (* 1 = 2.74053 loss)
I0605 06:18:53.064108   904 sgd_solver.cpp:106] Iteration 57520, lr = 0.0264659
I0605 06:19:13.714082   904 solver.cpp:229] Iteration 57560, loss = 2.89667
I0605 06:19:13.714118   904 solver.cpp:245]     Train net output #0: loss = 2.58033 (* 1 = 2.58033 loss)
I0605 06:19:13.714125   904 sgd_solver.cpp:106] Iteration 57560, lr = 0.0264565
I0605 06:19:34.280946   904 solver.cpp:229] Iteration 57600, loss = 2.89945
I0605 06:19:34.281131   904 solver.cpp:245]     Train net output #0: loss = 2.88867 (* 1 = 2.88867 loss)
I0605 06:19:34.281157   904 sgd_solver.cpp:106] Iteration 57600, lr = 0.0264471
I0605 06:19:54.794093   904 solver.cpp:229] Iteration 57640, loss = 2.87605
I0605 06:19:54.794137   904 solver.cpp:245]     Train net output #0: loss = 2.7826 (* 1 = 2.7826 loss)
I0605 06:19:54.794147   904 sgd_solver.cpp:106] Iteration 57640, lr = 0.0264376
I0605 06:20:15.306565   904 solver.cpp:229] Iteration 57680, loss = 2.85688
I0605 06:20:15.306864   904 solver.cpp:245]     Train net output #0: loss = 2.78251 (* 1 = 2.78251 loss)
I0605 06:20:15.306891   904 sgd_solver.cpp:106] Iteration 57680, lr = 0.0264282
I0605 06:20:35.792178   904 solver.cpp:229] Iteration 57720, loss = 2.86706
I0605 06:20:35.792217   904 solver.cpp:245]     Train net output #0: loss = 2.98925 (* 1 = 2.98925 loss)
I0605 06:20:35.792227   904 sgd_solver.cpp:106] Iteration 57720, lr = 0.0264188
I0605 06:20:56.302376   904 solver.cpp:229] Iteration 57760, loss = 2.86364
I0605 06:20:56.302563   904 solver.cpp:245]     Train net output #0: loss = 2.89066 (* 1 = 2.89066 loss)
I0605 06:20:56.302584   904 sgd_solver.cpp:106] Iteration 57760, lr = 0.0264094
I0605 06:21:13.996683   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 06:21:16.819550   904 solver.cpp:229] Iteration 57800, loss = 2.86486
I0605 06:21:16.819608   904 solver.cpp:245]     Train net output #0: loss = 2.9988 (* 1 = 2.9988 loss)
I0605 06:21:16.819619   904 sgd_solver.cpp:106] Iteration 57800, lr = 0.0264
I0605 06:21:37.125053   904 solver.cpp:229] Iteration 57840, loss = 2.88331
I0605 06:21:37.125185   904 solver.cpp:245]     Train net output #0: loss = 3.11395 (* 1 = 3.11395 loss)
I0605 06:21:37.125195   904 sgd_solver.cpp:106] Iteration 57840, lr = 0.0263906
I0605 06:21:57.553691   904 solver.cpp:229] Iteration 57880, loss = 2.85951
I0605 06:21:57.553738   904 solver.cpp:245]     Train net output #0: loss = 2.89424 (* 1 = 2.89424 loss)
I0605 06:21:57.553746   904 sgd_solver.cpp:106] Iteration 57880, lr = 0.0263812
I0605 06:22:18.044909   904 solver.cpp:229] Iteration 57920, loss = 2.82102
I0605 06:22:18.045049   904 solver.cpp:245]     Train net output #0: loss = 2.82774 (* 1 = 2.82774 loss)
I0605 06:22:18.045063   904 sgd_solver.cpp:106] Iteration 57920, lr = 0.0263718
I0605 06:22:38.547674   904 solver.cpp:229] Iteration 57960, loss = 2.91504
I0605 06:22:38.547729   904 solver.cpp:245]     Train net output #0: loss = 2.89734 (* 1 = 2.89734 loss)
I0605 06:22:38.547739   904 sgd_solver.cpp:106] Iteration 57960, lr = 0.0263624
I0605 06:22:58.524312   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_58000.caffemodel
I0605 06:22:58.789875   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_58000.solverstate
I0605 06:22:58.869424   904 solver.cpp:338] Iteration 58000, Testing net (#0)
I0605 06:22:58.869498   904 net.cpp:748] Ignoring source layer loss
I0605 06:23:18.450074   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 06:23:50.813452   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 06:24:03.612848   904 solver.cpp:406]     Test net output #0: accuracy = 0.396161
I0605 06:24:03.612896   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.64636
I0605 06:24:03.925793   904 solver.cpp:229] Iteration 58000, loss = 2.90394
I0605 06:24:03.925834   904 solver.cpp:245]     Train net output #0: loss = 3.18273 (* 1 = 3.18273 loss)
I0605 06:24:03.925848   904 sgd_solver.cpp:106] Iteration 58000, lr = 0.0263529
I0605 06:24:23.195519   904 solver.cpp:229] Iteration 58040, loss = 2.88632
I0605 06:24:23.195731   904 solver.cpp:245]     Train net output #0: loss = 2.82299 (* 1 = 2.82299 loss)
I0605 06:24:23.195756   904 sgd_solver.cpp:106] Iteration 58040, lr = 0.0263435
I0605 06:24:44.717093   904 solver.cpp:229] Iteration 58080, loss = 2.84539
I0605 06:24:44.717140   904 solver.cpp:245]     Train net output #0: loss = 2.91594 (* 1 = 2.91594 loss)
I0605 06:24:44.717150   904 sgd_solver.cpp:106] Iteration 58080, lr = 0.0263341
I0605 06:25:06.288807   904 solver.cpp:229] Iteration 58120, loss = 2.86238
I0605 06:25:06.289000   904 solver.cpp:245]     Train net output #0: loss = 3.13095 (* 1 = 3.13095 loss)
I0605 06:25:06.289026   904 sgd_solver.cpp:106] Iteration 58120, lr = 0.0263247
I0605 06:25:27.629647   904 solver.cpp:229] Iteration 58160, loss = 2.86926
I0605 06:25:27.629689   904 solver.cpp:245]     Train net output #0: loss = 2.64236 (* 1 = 2.64236 loss)
I0605 06:25:27.629698   904 sgd_solver.cpp:106] Iteration 58160, lr = 0.0263153
I0605 06:25:48.778882   904 solver.cpp:229] Iteration 58200, loss = 2.85682
I0605 06:25:48.779109   904 solver.cpp:245]     Train net output #0: loss = 2.86401 (* 1 = 2.86401 loss)
I0605 06:25:48.779134   904 sgd_solver.cpp:106] Iteration 58200, lr = 0.0263059
I0605 06:26:09.965777   904 solver.cpp:229] Iteration 58240, loss = 2.88633
I0605 06:26:09.965832   904 solver.cpp:245]     Train net output #0: loss = 2.85877 (* 1 = 2.85877 loss)
I0605 06:26:09.965842   904 sgd_solver.cpp:106] Iteration 58240, lr = 0.0262965
I0605 06:26:30.988559   904 solver.cpp:229] Iteration 58280, loss = 2.85899
I0605 06:26:30.988759   904 solver.cpp:245]     Train net output #0: loss = 3.10679 (* 1 = 3.10679 loss)
I0605 06:26:30.988786   904 sgd_solver.cpp:106] Iteration 58280, lr = 0.0262871
I0605 06:26:43.598250   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 06:26:51.982981   904 solver.cpp:229] Iteration 58320, loss = 2.90489
I0605 06:26:51.983026   904 solver.cpp:245]     Train net output #0: loss = 2.71762 (* 1 = 2.71762 loss)
I0605 06:26:51.983037   904 sgd_solver.cpp:106] Iteration 58320, lr = 0.0262776
I0605 06:27:12.975091   904 solver.cpp:229] Iteration 58360, loss = 2.84049
I0605 06:27:12.975329   904 solver.cpp:245]     Train net output #0: loss = 2.87859 (* 1 = 2.87859 loss)
I0605 06:27:12.975356   904 sgd_solver.cpp:106] Iteration 58360, lr = 0.0262682
I0605 06:27:33.971133   904 solver.cpp:229] Iteration 58400, loss = 2.80107
I0605 06:27:33.971174   904 solver.cpp:245]     Train net output #0: loss = 2.71485 (* 1 = 2.71485 loss)
I0605 06:27:33.971182   904 sgd_solver.cpp:106] Iteration 58400, lr = 0.0262588
I0605 06:27:54.883744   904 solver.cpp:229] Iteration 58440, loss = 2.89085
I0605 06:27:54.883949   904 solver.cpp:245]     Train net output #0: loss = 2.89217 (* 1 = 2.89217 loss)
I0605 06:27:54.883975   904 sgd_solver.cpp:106] Iteration 58440, lr = 0.0262494
I0605 06:28:15.707514   904 solver.cpp:229] Iteration 58480, loss = 2.82647
I0605 06:28:15.707553   904 solver.cpp:245]     Train net output #0: loss = 2.6682 (* 1 = 2.6682 loss)
I0605 06:28:15.707562   904 sgd_solver.cpp:106] Iteration 58480, lr = 0.02624
I0605 06:28:36.532557   904 solver.cpp:229] Iteration 58520, loss = 2.81625
I0605 06:28:36.532778   904 solver.cpp:245]     Train net output #0: loss = 2.86675 (* 1 = 2.86675 loss)
I0605 06:28:36.532804   904 sgd_solver.cpp:106] Iteration 58520, lr = 0.0262306
I0605 06:28:57.353341   904 solver.cpp:229] Iteration 58560, loss = 2.84536
I0605 06:28:57.353389   904 solver.cpp:245]     Train net output #0: loss = 3.11768 (* 1 = 3.11768 loss)
I0605 06:28:57.353400   904 sgd_solver.cpp:106] Iteration 58560, lr = 0.0262212
I0605 06:29:18.104825   904 solver.cpp:229] Iteration 58600, loss = 2.87006
I0605 06:29:18.104941   904 solver.cpp:245]     Train net output #0: loss = 2.8405 (* 1 = 2.8405 loss)
I0605 06:29:18.104954   904 sgd_solver.cpp:106] Iteration 58600, lr = 0.0262118
I0605 06:29:38.788321   904 solver.cpp:229] Iteration 58640, loss = 2.83446
I0605 06:29:38.788395   904 solver.cpp:245]     Train net output #0: loss = 2.7202 (* 1 = 2.7202 loss)
I0605 06:29:38.788406   904 sgd_solver.cpp:106] Iteration 58640, lr = 0.0262024
I0605 06:29:59.480999   904 solver.cpp:229] Iteration 58680, loss = 2.85422
I0605 06:29:59.481168   904 solver.cpp:245]     Train net output #0: loss = 2.79911 (* 1 = 2.79911 loss)
I0605 06:29:59.481190   904 sgd_solver.cpp:106] Iteration 58680, lr = 0.0261929
I0605 06:30:20.156131   904 solver.cpp:229] Iteration 58720, loss = 2.83739
I0605 06:30:20.156170   904 solver.cpp:245]     Train net output #0: loss = 2.76529 (* 1 = 2.76529 loss)
I0605 06:30:20.156179   904 sgd_solver.cpp:106] Iteration 58720, lr = 0.0261835
I0605 06:30:40.836220   904 solver.cpp:229] Iteration 58760, loss = 2.87115
I0605 06:30:40.836395   904 solver.cpp:245]     Train net output #0: loss = 2.69844 (* 1 = 2.69844 loss)
I0605 06:30:40.836410   904 sgd_solver.cpp:106] Iteration 58760, lr = 0.0261741
I0605 06:31:01.497380   904 solver.cpp:229] Iteration 58800, loss = 2.8347
I0605 06:31:01.497424   904 solver.cpp:245]     Train net output #0: loss = 2.63952 (* 1 = 2.63952 loss)
I0605 06:31:01.497436   904 sgd_solver.cpp:106] Iteration 58800, lr = 0.0261647
I0605 06:31:05.087034   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 06:31:21.997021   904 solver.cpp:229] Iteration 58840, loss = 2.83783
I0605 06:31:21.997195   904 solver.cpp:245]     Train net output #0: loss = 2.83571 (* 1 = 2.83571 loss)
I0605 06:31:21.997208   904 sgd_solver.cpp:106] Iteration 58840, lr = 0.0261553
I0605 06:31:42.494479   904 solver.cpp:229] Iteration 58880, loss = 2.8334
I0605 06:31:42.494529   904 solver.cpp:245]     Train net output #0: loss = 2.73293 (* 1 = 2.73293 loss)
I0605 06:31:42.494540   904 sgd_solver.cpp:106] Iteration 58880, lr = 0.0261459
I0605 06:32:03.019973   904 solver.cpp:229] Iteration 58920, loss = 2.88808
I0605 06:32:03.020159   904 solver.cpp:245]     Train net output #0: loss = 2.82266 (* 1 = 2.82266 loss)
I0605 06:32:03.020185   904 sgd_solver.cpp:106] Iteration 58920, lr = 0.0261365
I0605 06:32:23.596703   904 solver.cpp:229] Iteration 58960, loss = 2.84428
I0605 06:32:23.596741   904 solver.cpp:245]     Train net output #0: loss = 2.93101 (* 1 = 2.93101 loss)
I0605 06:32:23.596750   904 sgd_solver.cpp:106] Iteration 58960, lr = 0.0261271
I0605 06:32:43.589066   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_59000.caffemodel
I0605 06:32:43.851213   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_59000.solverstate
I0605 06:32:43.928063   904 solver.cpp:338] Iteration 59000, Testing net (#0)
I0605 06:32:43.928138   904 net.cpp:748] Ignoring source layer loss
I0605 06:33:04.586881   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 06:33:38.266412   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 06:33:50.685513   904 solver.cpp:406]     Test net output #0: accuracy = 0.382281
I0605 06:33:50.685680   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.634759
I0605 06:33:51.003027   904 solver.cpp:229] Iteration 59000, loss = 2.8461
I0605 06:33:51.003073   904 solver.cpp:245]     Train net output #0: loss = 2.81926 (* 1 = 2.81926 loss)
I0605 06:33:51.003083   904 sgd_solver.cpp:106] Iteration 59000, lr = 0.0261176
I0605 06:34:10.202069   904 solver.cpp:229] Iteration 59040, loss = 2.8561
I0605 06:34:10.202220   904 solver.cpp:245]     Train net output #0: loss = 3.02034 (* 1 = 3.02034 loss)
I0605 06:34:10.202239   904 sgd_solver.cpp:106] Iteration 59040, lr = 0.0261082
I0605 06:34:31.396301   904 solver.cpp:229] Iteration 59080, loss = 2.82793
I0605 06:34:31.396363   904 solver.cpp:245]     Train net output #0: loss = 2.7116 (* 1 = 2.7116 loss)
I0605 06:34:31.396379   904 sgd_solver.cpp:106] Iteration 59080, lr = 0.0260988
I0605 06:34:52.387998   904 solver.cpp:229] Iteration 59120, loss = 2.89508
I0605 06:34:52.388226   904 solver.cpp:245]     Train net output #0: loss = 2.80477 (* 1 = 2.80477 loss)
I0605 06:34:52.388250   904 sgd_solver.cpp:106] Iteration 59120, lr = 0.0260894
I0605 06:35:13.050650   904 solver.cpp:229] Iteration 59160, loss = 2.85191
I0605 06:35:13.050701   904 solver.cpp:245]     Train net output #0: loss = 2.92138 (* 1 = 2.92138 loss)
I0605 06:35:13.050714   904 sgd_solver.cpp:106] Iteration 59160, lr = 0.02608
I0605 06:35:33.685405   904 solver.cpp:229] Iteration 59200, loss = 2.85979
I0605 06:35:33.685638   904 solver.cpp:245]     Train net output #0: loss = 2.97407 (* 1 = 2.97407 loss)
I0605 06:35:33.685664   904 sgd_solver.cpp:106] Iteration 59200, lr = 0.0260706
I0605 06:35:54.055651   904 solver.cpp:229] Iteration 59240, loss = 2.9001
I0605 06:35:54.055697   904 solver.cpp:245]     Train net output #0: loss = 3.09288 (* 1 = 3.09288 loss)
I0605 06:35:54.055706   904 sgd_solver.cpp:106] Iteration 59240, lr = 0.0260612
I0605 06:36:14.345924   904 solver.cpp:229] Iteration 59280, loss = 2.81547
I0605 06:36:14.346199   904 solver.cpp:245]     Train net output #0: loss = 2.72397 (* 1 = 2.72397 loss)
I0605 06:36:14.346223   904 sgd_solver.cpp:106] Iteration 59280, lr = 0.0260518
I0605 06:36:34.969838   904 solver.cpp:229] Iteration 59320, loss = 2.80833
I0605 06:36:34.969895   904 solver.cpp:245]     Train net output #0: loss = 2.88149 (* 1 = 2.88149 loss)
I0605 06:36:34.969905   904 sgd_solver.cpp:106] Iteration 59320, lr = 0.0260424
I0605 06:36:55.540802   904 solver.cpp:229] Iteration 59360, loss = 2.81739
I0605 06:36:55.541054   904 solver.cpp:245]     Train net output #0: loss = 2.81933 (* 1 = 2.81933 loss)
I0605 06:36:55.541074   904 sgd_solver.cpp:106] Iteration 59360, lr = 0.0260329
I0605 06:36:59.387011   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 06:37:16.070513   904 solver.cpp:229] Iteration 59400, loss = 2.81263
I0605 06:37:16.070562   904 solver.cpp:245]     Train net output #0: loss = 2.64725 (* 1 = 2.64725 loss)
I0605 06:37:16.070572   904 sgd_solver.cpp:106] Iteration 59400, lr = 0.0260235
I0605 06:37:36.607764   904 solver.cpp:229] Iteration 59440, loss = 2.87429
I0605 06:37:36.607939   904 solver.cpp:245]     Train net output #0: loss = 2.78169 (* 1 = 2.78169 loss)
I0605 06:37:36.607969   904 sgd_solver.cpp:106] Iteration 59440, lr = 0.0260141
I0605 06:37:57.124305   904 solver.cpp:229] Iteration 59480, loss = 2.83172
I0605 06:37:57.124352   904 solver.cpp:245]     Train net output #0: loss = 2.79695 (* 1 = 2.79695 loss)
I0605 06:37:57.124362   904 sgd_solver.cpp:106] Iteration 59480, lr = 0.0260047
I0605 06:38:17.656736   904 solver.cpp:229] Iteration 59520, loss = 2.88942
I0605 06:38:17.656939   904 solver.cpp:245]     Train net output #0: loss = 2.83396 (* 1 = 2.83396 loss)
I0605 06:38:17.656967   904 sgd_solver.cpp:106] Iteration 59520, lr = 0.0259953
I0605 06:38:38.176945   904 solver.cpp:229] Iteration 59560, loss = 2.84264
I0605 06:38:38.176998   904 solver.cpp:245]     Train net output #0: loss = 2.84288 (* 1 = 2.84288 loss)
I0605 06:38:38.177007   904 sgd_solver.cpp:106] Iteration 59560, lr = 0.0259859
I0605 06:38:58.671342   904 solver.cpp:229] Iteration 59600, loss = 2.85358
I0605 06:38:58.671509   904 solver.cpp:245]     Train net output #0: loss = 2.9629 (* 1 = 2.9629 loss)
I0605 06:38:58.671532   904 sgd_solver.cpp:106] Iteration 59600, lr = 0.0259765
I0605 06:39:19.169270   904 solver.cpp:229] Iteration 59640, loss = 2.81315
I0605 06:39:19.169314   904 solver.cpp:245]     Train net output #0: loss = 3.18522 (* 1 = 3.18522 loss)
I0605 06:39:19.169324   904 sgd_solver.cpp:106] Iteration 59640, lr = 0.0259671
I0605 06:39:39.666080   904 solver.cpp:229] Iteration 59680, loss = 2.82791
I0605 06:39:39.666272   904 solver.cpp:245]     Train net output #0: loss = 2.82117 (* 1 = 2.82117 loss)
I0605 06:39:39.666298   904 sgd_solver.cpp:106] Iteration 59680, lr = 0.0259576
I0605 06:40:00.124280   904 solver.cpp:229] Iteration 59720, loss = 2.85583
I0605 06:40:00.124328   904 solver.cpp:245]     Train net output #0: loss = 3.07171 (* 1 = 3.07171 loss)
I0605 06:40:00.124336   904 sgd_solver.cpp:106] Iteration 59720, lr = 0.0259482
I0605 06:40:20.392246   904 solver.cpp:229] Iteration 59760, loss = 2.79853
I0605 06:40:20.392426   904 solver.cpp:245]     Train net output #0: loss = 2.686 (* 1 = 2.686 loss)
I0605 06:40:20.392448   904 sgd_solver.cpp:106] Iteration 59760, lr = 0.0259388
I0605 06:40:40.679728   904 solver.cpp:229] Iteration 59800, loss = 2.85995
I0605 06:40:40.679780   904 solver.cpp:245]     Train net output #0: loss = 2.89171 (* 1 = 2.89171 loss)
I0605 06:40:40.679787   904 sgd_solver.cpp:106] Iteration 59800, lr = 0.0259294
I0605 06:41:00.999696   904 solver.cpp:229] Iteration 59840, loss = 2.83211
I0605 06:41:00.999882   904 solver.cpp:245]     Train net output #0: loss = 3.07094 (* 1 = 3.07094 loss)
I0605 06:41:00.999904   904 sgd_solver.cpp:106] Iteration 59840, lr = 0.02592
I0605 06:41:21.496307   904 solver.cpp:229] Iteration 59880, loss = 2.85317
I0605 06:41:21.496348   904 solver.cpp:245]     Train net output #0: loss = 2.53917 (* 1 = 2.53917 loss)
I0605 06:41:21.496356   904 sgd_solver.cpp:106] Iteration 59880, lr = 0.0259106
I0605 06:41:33.454360   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 06:41:41.808835   904 solver.cpp:229] Iteration 59920, loss = 2.81546
I0605 06:41:41.808882   904 solver.cpp:245]     Train net output #0: loss = 2.77121 (* 1 = 2.77121 loss)
I0605 06:41:41.808890   904 sgd_solver.cpp:106] Iteration 59920, lr = 0.0259012
I0605 06:42:02.092644   904 solver.cpp:229] Iteration 59960, loss = 2.8561
I0605 06:42:02.092694   904 solver.cpp:245]     Train net output #0: loss = 2.79496 (* 1 = 2.79496 loss)
I0605 06:42:02.092702   904 sgd_solver.cpp:106] Iteration 59960, lr = 0.0258918
I0605 06:42:21.864310   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_60000.caffemodel
I0605 06:42:22.136117   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_60000.solverstate
I0605 06:42:22.225441   904 solver.cpp:338] Iteration 60000, Testing net (#0)
I0605 06:42:22.225517   904 net.cpp:748] Ignoring source layer loss
I0605 06:42:50.423871   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 06:43:25.631376   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 06:43:30.468859   904 solver.cpp:406]     Test net output #0: accuracy = 0.395721
I0605 06:43:30.468899   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.648739
I0605 06:43:30.782567   904 solver.cpp:229] Iteration 60000, loss = 2.8694
I0605 06:43:30.782606   904 solver.cpp:245]     Train net output #0: loss = 3.06096 (* 1 = 3.06096 loss)
I0605 06:43:30.782615   904 sgd_solver.cpp:106] Iteration 60000, lr = 0.0258824
I0605 06:43:50.024833   904 solver.cpp:229] Iteration 60040, loss = 2.83449
I0605 06:43:50.024878   904 solver.cpp:245]     Train net output #0: loss = 2.90287 (* 1 = 2.90287 loss)
I0605 06:43:50.024884   904 sgd_solver.cpp:106] Iteration 60040, lr = 0.0258729
I0605 06:44:11.274025   904 solver.cpp:229] Iteration 60080, loss = 2.87485
I0605 06:44:11.274221   904 solver.cpp:245]     Train net output #0: loss = 3.03303 (* 1 = 3.03303 loss)
I0605 06:44:11.274246   904 sgd_solver.cpp:106] Iteration 60080, lr = 0.0258635
I0605 06:44:32.573571   904 solver.cpp:229] Iteration 60120, loss = 2.86147
I0605 06:44:32.573616   904 solver.cpp:245]     Train net output #0: loss = 2.72281 (* 1 = 2.72281 loss)
I0605 06:44:32.573624   904 sgd_solver.cpp:106] Iteration 60120, lr = 0.0258541
I0605 06:44:53.443577   904 solver.cpp:229] Iteration 60160, loss = 2.82222
I0605 06:44:53.443765   904 solver.cpp:245]     Train net output #0: loss = 2.61086 (* 1 = 2.61086 loss)
I0605 06:44:53.443794   904 sgd_solver.cpp:106] Iteration 60160, lr = 0.0258447
I0605 06:45:14.299394   904 solver.cpp:229] Iteration 60200, loss = 2.80842
I0605 06:45:14.299453   904 solver.cpp:245]     Train net output #0: loss = 2.61519 (* 1 = 2.61519 loss)
I0605 06:45:14.299463   904 sgd_solver.cpp:106] Iteration 60200, lr = 0.0258353
I0605 06:45:35.151291   904 solver.cpp:229] Iteration 60240, loss = 2.87866
I0605 06:45:35.151480   904 solver.cpp:245]     Train net output #0: loss = 2.82735 (* 1 = 2.82735 loss)
I0605 06:45:35.151506   904 sgd_solver.cpp:106] Iteration 60240, lr = 0.0258259
I0605 06:45:56.005741   904 solver.cpp:229] Iteration 60280, loss = 2.82962
I0605 06:45:56.005795   904 solver.cpp:245]     Train net output #0: loss = 2.78308 (* 1 = 2.78308 loss)
I0605 06:45:56.005805   904 sgd_solver.cpp:106] Iteration 60280, lr = 0.0258165
I0605 06:46:16.787982   904 solver.cpp:229] Iteration 60320, loss = 2.87487
I0605 06:46:16.788190   904 solver.cpp:245]     Train net output #0: loss = 2.83621 (* 1 = 2.83621 loss)
I0605 06:46:16.788215   904 sgd_solver.cpp:106] Iteration 60320, lr = 0.0258071
I0605 06:46:37.493789   904 solver.cpp:229] Iteration 60360, loss = 2.8566
I0605 06:46:37.493842   904 solver.cpp:245]     Train net output #0: loss = 2.99378 (* 1 = 2.99378 loss)
I0605 06:46:37.493851   904 sgd_solver.cpp:106] Iteration 60360, lr = 0.0257976
I0605 06:46:58.026475   904 solver.cpp:229] Iteration 60400, loss = 2.83856
I0605 06:46:58.026697   904 solver.cpp:245]     Train net output #0: loss = 3.01593 (* 1 = 3.01593 loss)
I0605 06:46:58.026723   904 sgd_solver.cpp:106] Iteration 60400, lr = 0.0257882
I0605 06:47:18.682270   904 solver.cpp:229] Iteration 60440, loss = 2.81975
I0605 06:47:18.682306   904 solver.cpp:245]     Train net output #0: loss = 2.86467 (* 1 = 2.86467 loss)
I0605 06:47:18.682314   904 sgd_solver.cpp:106] Iteration 60440, lr = 0.0257788
I0605 06:47:24.374080   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 06:47:39.376773   904 solver.cpp:229] Iteration 60480, loss = 2.86211
I0605 06:47:39.376996   904 solver.cpp:245]     Train net output #0: loss = 2.5872 (* 1 = 2.5872 loss)
I0605 06:47:39.377022   904 sgd_solver.cpp:106] Iteration 60480, lr = 0.0257694
I0605 06:47:59.938549   904 solver.cpp:229] Iteration 60520, loss = 2.89742
I0605 06:47:59.938611   904 solver.cpp:245]     Train net output #0: loss = 2.91541 (* 1 = 2.91541 loss)
I0605 06:47:59.938632   904 sgd_solver.cpp:106] Iteration 60520, lr = 0.02576
I0605 06:48:20.497460   904 solver.cpp:229] Iteration 60560, loss = 2.87138
I0605 06:48:20.497644   904 solver.cpp:245]     Train net output #0: loss = 2.88991 (* 1 = 2.88991 loss)
I0605 06:48:20.497678   904 sgd_solver.cpp:106] Iteration 60560, lr = 0.0257506
I0605 06:48:41.158870   904 solver.cpp:229] Iteration 60600, loss = 2.78088
I0605 06:48:41.158921   904 solver.cpp:245]     Train net output #0: loss = 2.65117 (* 1 = 2.65117 loss)
I0605 06:48:41.158933   904 sgd_solver.cpp:106] Iteration 60600, lr = 0.0257412
I0605 06:49:01.542804   904 solver.cpp:229] Iteration 60640, loss = 2.87731
I0605 06:49:01.543018   904 solver.cpp:245]     Train net output #0: loss = 2.79765 (* 1 = 2.79765 loss)
I0605 06:49:01.543042   904 sgd_solver.cpp:106] Iteration 60640, lr = 0.0257318
I0605 06:49:22.077783   904 solver.cpp:229] Iteration 60680, loss = 2.82192
I0605 06:49:22.077826   904 solver.cpp:245]     Train net output #0: loss = 2.71252 (* 1 = 2.71252 loss)
I0605 06:49:22.077836   904 sgd_solver.cpp:106] Iteration 60680, lr = 0.0257224
I0605 06:49:42.604746   904 solver.cpp:229] Iteration 60720, loss = 2.87537
I0605 06:49:42.604887   904 solver.cpp:245]     Train net output #0: loss = 2.86646 (* 1 = 2.86646 loss)
I0605 06:49:42.604893   904 sgd_solver.cpp:106] Iteration 60720, lr = 0.0257129
I0605 06:50:03.128006   904 solver.cpp:229] Iteration 60760, loss = 2.82097
I0605 06:50:03.128057   904 solver.cpp:245]     Train net output #0: loss = 2.87695 (* 1 = 2.87695 loss)
I0605 06:50:03.128064   904 sgd_solver.cpp:106] Iteration 60760, lr = 0.0257035
I0605 06:50:23.681694   904 solver.cpp:229] Iteration 60800, loss = 2.86091
I0605 06:50:23.681906   904 solver.cpp:245]     Train net output #0: loss = 2.76801 (* 1 = 2.76801 loss)
I0605 06:50:23.681934   904 sgd_solver.cpp:106] Iteration 60800, lr = 0.0256941
I0605 06:50:44.378239   904 solver.cpp:229] Iteration 60840, loss = 2.85949
I0605 06:50:44.378290   904 solver.cpp:245]     Train net output #0: loss = 2.80341 (* 1 = 2.80341 loss)
I0605 06:50:44.378301   904 sgd_solver.cpp:106] Iteration 60840, lr = 0.0256847
I0605 06:51:04.768882   904 solver.cpp:229] Iteration 60880, loss = 2.7973
I0605 06:51:04.769109   904 solver.cpp:245]     Train net output #0: loss = 2.99837 (* 1 = 2.99837 loss)
I0605 06:51:04.769135   904 sgd_solver.cpp:106] Iteration 60880, lr = 0.0256753
I0605 06:51:25.128083   904 solver.cpp:229] Iteration 60920, loss = 2.8147
I0605 06:51:25.128142   904 solver.cpp:245]     Train net output #0: loss = 2.97841 (* 1 = 2.97841 loss)
I0605 06:51:25.128150   904 sgd_solver.cpp:106] Iteration 60920, lr = 0.0256659
I0605 06:51:45.472833   904 solver.cpp:229] Iteration 60960, loss = 2.86301
I0605 06:51:45.473001   904 solver.cpp:245]     Train net output #0: loss = 3.02495 (* 1 = 3.02495 loss)
I0605 06:51:45.473011   904 sgd_solver.cpp:106] Iteration 60960, lr = 0.0256565
I0605 06:52:05.459326   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_61000.caffemodel
I0605 06:52:05.717079   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_61000.solverstate
I0605 06:52:05.796893   904 solver.cpp:338] Iteration 61000, Testing net (#0)
I0605 06:52:05.796974   904 net.cpp:748] Ignoring source layer loss
I0605 06:52:07.171671   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 06:52:41.011524   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 06:53:12.002863   904 solver.cpp:406]     Test net output #0: accuracy = 0.390002
I0605 06:53:12.003063   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.645999
I0605 06:53:12.317582   904 solver.cpp:229] Iteration 61000, loss = 2.80374
I0605 06:53:12.317611   904 solver.cpp:245]     Train net output #0: loss = 2.56832 (* 1 = 2.56832 loss)
I0605 06:53:12.317621   904 sgd_solver.cpp:106] Iteration 61000, lr = 0.0256471
I0605 06:53:23.134759   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 06:53:31.795478   904 solver.cpp:229] Iteration 61040, loss = 2.84368
I0605 06:53:31.795547   904 solver.cpp:245]     Train net output #0: loss = 2.66079 (* 1 = 2.66079 loss)
I0605 06:53:31.795559   904 sgd_solver.cpp:106] Iteration 61040, lr = 0.0256376
I0605 06:53:53.214334   904 solver.cpp:229] Iteration 61080, loss = 2.77993
I0605 06:53:53.214504   904 solver.cpp:245]     Train net output #0: loss = 3.04762 (* 1 = 3.04762 loss)
I0605 06:53:53.214530   904 sgd_solver.cpp:106] Iteration 61080, lr = 0.0256282
I0605 06:54:14.784610   904 solver.cpp:229] Iteration 61120, loss = 2.82512
I0605 06:54:14.784682   904 solver.cpp:245]     Train net output #0: loss = 2.80274 (* 1 = 2.80274 loss)
I0605 06:54:14.784694   904 sgd_solver.cpp:106] Iteration 61120, lr = 0.0256188
I0605 06:54:35.972422   904 solver.cpp:229] Iteration 61160, loss = 2.83697
I0605 06:54:35.972597   904 solver.cpp:245]     Train net output #0: loss = 3.20592 (* 1 = 3.20592 loss)
I0605 06:54:35.972625   904 sgd_solver.cpp:106] Iteration 61160, lr = 0.0256094
I0605 06:54:56.945178   904 solver.cpp:229] Iteration 61200, loss = 2.86883
I0605 06:54:56.945217   904 solver.cpp:245]     Train net output #0: loss = 3.16138 (* 1 = 3.16138 loss)
I0605 06:54:56.945225   904 sgd_solver.cpp:106] Iteration 61200, lr = 0.0256
I0605 06:55:18.047093   904 solver.cpp:229] Iteration 61240, loss = 2.83041
I0605 06:55:18.047260   904 solver.cpp:245]     Train net output #0: loss = 2.52695 (* 1 = 2.52695 loss)
I0605 06:55:18.047289   904 sgd_solver.cpp:106] Iteration 61240, lr = 0.0255906
I0605 06:55:39.114485   904 solver.cpp:229] Iteration 61280, loss = 2.82287
I0605 06:55:39.114562   904 solver.cpp:245]     Train net output #0: loss = 2.82029 (* 1 = 2.82029 loss)
I0605 06:55:39.114573   904 sgd_solver.cpp:106] Iteration 61280, lr = 0.0255812
I0605 06:55:59.920274   904 solver.cpp:229] Iteration 61320, loss = 2.81567
I0605 06:55:59.920477   904 solver.cpp:245]     Train net output #0: loss = 2.53486 (* 1 = 2.53486 loss)
I0605 06:55:59.920500   904 sgd_solver.cpp:106] Iteration 61320, lr = 0.0255718
I0605 06:56:20.733903   904 solver.cpp:229] Iteration 61360, loss = 2.80485
I0605 06:56:20.733959   904 solver.cpp:245]     Train net output #0: loss = 2.86571 (* 1 = 2.86571 loss)
I0605 06:56:20.733968   904 sgd_solver.cpp:106] Iteration 61360, lr = 0.0255624
I0605 06:56:41.565074   904 solver.cpp:229] Iteration 61400, loss = 2.87567
I0605 06:56:41.565279   904 solver.cpp:245]     Train net output #0: loss = 2.91169 (* 1 = 2.91169 loss)
I0605 06:56:41.565309   904 sgd_solver.cpp:106] Iteration 61400, lr = 0.0255529
I0605 06:57:02.386083   904 solver.cpp:229] Iteration 61440, loss = 2.87074
I0605 06:57:02.386144   904 solver.cpp:245]     Train net output #0: loss = 2.90254 (* 1 = 2.90254 loss)
I0605 06:57:02.386154   904 sgd_solver.cpp:106] Iteration 61440, lr = 0.0255435
I0605 06:57:23.279613   904 solver.cpp:229] Iteration 61480, loss = 2.85396
I0605 06:57:23.279826   904 solver.cpp:245]     Train net output #0: loss = 3.2794 (* 1 = 3.2794 loss)
I0605 06:57:23.279870   904 sgd_solver.cpp:106] Iteration 61480, lr = 0.0255341
I0605 06:57:43.775822   904 solver.cpp:229] Iteration 61520, loss = 2.85298
I0605 06:57:43.775877   904 solver.cpp:245]     Train net output #0: loss = 2.99803 (* 1 = 2.99803 loss)
I0605 06:57:43.775884   904 sgd_solver.cpp:106] Iteration 61520, lr = 0.0255247
I0605 06:57:59.777108   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 06:58:04.426199   904 solver.cpp:229] Iteration 61560, loss = 2.81957
I0605 06:58:04.426268   904 solver.cpp:245]     Train net output #0: loss = 2.73323 (* 1 = 2.73323 loss)
I0605 06:58:04.426280   904 sgd_solver.cpp:106] Iteration 61560, lr = 0.0255153
I0605 06:58:25.082634   904 solver.cpp:229] Iteration 61600, loss = 2.86036
I0605 06:58:25.082693   904 solver.cpp:245]     Train net output #0: loss = 2.62671 (* 1 = 2.62671 loss)
I0605 06:58:25.082707   904 sgd_solver.cpp:106] Iteration 61600, lr = 0.0255059
I0605 06:58:45.636634   904 solver.cpp:229] Iteration 61640, loss = 2.84003
I0605 06:58:45.636857   904 solver.cpp:245]     Train net output #0: loss = 2.95422 (* 1 = 2.95422 loss)
I0605 06:58:45.636884   904 sgd_solver.cpp:106] Iteration 61640, lr = 0.0254965
I0605 06:59:06.149791   904 solver.cpp:229] Iteration 61680, loss = 2.85717
I0605 06:59:06.149847   904 solver.cpp:245]     Train net output #0: loss = 3.01311 (* 1 = 3.01311 loss)
I0605 06:59:06.149858   904 sgd_solver.cpp:106] Iteration 61680, lr = 0.0254871
I0605 06:59:26.694789   904 solver.cpp:229] Iteration 61720, loss = 2.83942
I0605 06:59:26.694916   904 solver.cpp:245]     Train net output #0: loss = 3.06296 (* 1 = 3.06296 loss)
I0605 06:59:26.694924   904 sgd_solver.cpp:106] Iteration 61720, lr = 0.0254776
I0605 06:59:47.343292   904 solver.cpp:229] Iteration 61760, loss = 2.82534
I0605 06:59:47.343339   904 solver.cpp:245]     Train net output #0: loss = 2.79038 (* 1 = 2.79038 loss)
I0605 06:59:47.343350   904 sgd_solver.cpp:106] Iteration 61760, lr = 0.0254682
I0605 07:00:07.836663   904 solver.cpp:229] Iteration 61800, loss = 2.79423
I0605 07:00:07.836906   904 solver.cpp:245]     Train net output #0: loss = 2.78455 (* 1 = 2.78455 loss)
I0605 07:00:07.836941   904 sgd_solver.cpp:106] Iteration 61800, lr = 0.0254588
I0605 07:00:28.147506   904 solver.cpp:229] Iteration 61840, loss = 2.82244
I0605 07:00:28.147562   904 solver.cpp:245]     Train net output #0: loss = 2.7959 (* 1 = 2.7959 loss)
I0605 07:00:28.147573   904 sgd_solver.cpp:106] Iteration 61840, lr = 0.0254494
I0605 07:00:48.555842   904 solver.cpp:229] Iteration 61880, loss = 2.81184
I0605 07:00:48.556027   904 solver.cpp:245]     Train net output #0: loss = 2.68141 (* 1 = 2.68141 loss)
I0605 07:00:48.556049   904 sgd_solver.cpp:106] Iteration 61880, lr = 0.02544
I0605 07:01:09.032640   904 solver.cpp:229] Iteration 61920, loss = 2.85417
I0605 07:01:09.032687   904 solver.cpp:245]     Train net output #0: loss = 3.17798 (* 1 = 3.17798 loss)
I0605 07:01:09.032699   904 sgd_solver.cpp:106] Iteration 61920, lr = 0.0254306
I0605 07:01:29.529561   904 solver.cpp:229] Iteration 61960, loss = 2.80235
I0605 07:01:29.529800   904 solver.cpp:245]     Train net output #0: loss = 2.7501 (* 1 = 2.7501 loss)
I0605 07:01:29.529826   904 sgd_solver.cpp:106] Iteration 61960, lr = 0.0254212
I0605 07:01:49.493022   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_62000.caffemodel
I0605 07:01:49.760650   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_62000.solverstate
I0605 07:01:49.834879   904 solver.cpp:338] Iteration 62000, Testing net (#0)
I0605 07:01:49.834949   904 net.cpp:748] Ignoring source layer loss
I0605 07:01:53.828868   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 07:02:27.093291   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 07:02:55.990280   904 solver.cpp:406]     Test net output #0: accuracy = 0.400462
I0605 07:02:55.990322   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.65338
I0605 07:02:56.305696   904 solver.cpp:229] Iteration 62000, loss = 2.76775
I0605 07:02:56.305740   904 solver.cpp:245]     Train net output #0: loss = 2.69165 (* 1 = 2.69165 loss)
I0605 07:02:56.305752   904 sgd_solver.cpp:106] Iteration 62000, lr = 0.0254118
I0605 07:03:15.529047   904 solver.cpp:229] Iteration 62040, loss = 2.7843
I0605 07:03:15.529239   904 solver.cpp:245]     Train net output #0: loss = 2.79945 (* 1 = 2.79945 loss)
I0605 07:03:15.529247   904 sgd_solver.cpp:106] Iteration 62040, lr = 0.0254024
I0605 07:03:25.702962   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 07:03:37.023296   904 solver.cpp:229] Iteration 62080, loss = 2.83186
I0605 07:03:37.023345   904 solver.cpp:245]     Train net output #0: loss = 2.93777 (* 1 = 2.93777 loss)
I0605 07:03:37.023356   904 sgd_solver.cpp:106] Iteration 62080, lr = 0.0253929
I0605 07:03:58.556638   904 solver.cpp:229] Iteration 62120, loss = 2.83682
I0605 07:03:58.556787   904 solver.cpp:245]     Train net output #0: loss = 2.76547 (* 1 = 2.76547 loss)
I0605 07:03:58.556797   904 sgd_solver.cpp:106] Iteration 62120, lr = 0.0253835
I0605 07:04:19.723708   904 solver.cpp:229] Iteration 62160, loss = 2.81484
I0605 07:04:19.723759   904 solver.cpp:245]     Train net output #0: loss = 2.79691 (* 1 = 2.79691 loss)
I0605 07:04:19.723768   904 sgd_solver.cpp:106] Iteration 62160, lr = 0.0253741
I0605 07:04:40.709478   904 solver.cpp:229] Iteration 62200, loss = 2.79689
I0605 07:04:40.709692   904 solver.cpp:245]     Train net output #0: loss = 2.63921 (* 1 = 2.63921 loss)
I0605 07:04:40.709719   904 sgd_solver.cpp:106] Iteration 62200, lr = 0.0253647
I0605 07:05:01.698267   904 solver.cpp:229] Iteration 62240, loss = 2.84519
I0605 07:05:01.698323   904 solver.cpp:245]     Train net output #0: loss = 2.95571 (* 1 = 2.95571 loss)
I0605 07:05:01.698333   904 sgd_solver.cpp:106] Iteration 62240, lr = 0.0253553
I0605 07:05:22.702430   904 solver.cpp:229] Iteration 62280, loss = 2.75785
I0605 07:05:22.702574   904 solver.cpp:245]     Train net output #0: loss = 2.98513 (* 1 = 2.98513 loss)
I0605 07:05:22.702586   904 sgd_solver.cpp:106] Iteration 62280, lr = 0.0253459
I0605 07:05:43.601128   904 solver.cpp:229] Iteration 62320, loss = 2.86341
I0605 07:05:43.601186   904 solver.cpp:245]     Train net output #0: loss = 3.1974 (* 1 = 3.1974 loss)
I0605 07:05:43.601196   904 sgd_solver.cpp:106] Iteration 62320, lr = 0.0253365
I0605 07:06:04.270916   904 solver.cpp:229] Iteration 62360, loss = 2.81509
I0605 07:06:04.271070   904 solver.cpp:245]     Train net output #0: loss = 2.94206 (* 1 = 2.94206 loss)
I0605 07:06:04.271092   904 sgd_solver.cpp:106] Iteration 62360, lr = 0.0253271
I0605 07:06:24.961603   904 solver.cpp:229] Iteration 62400, loss = 2.77655
I0605 07:06:24.961647   904 solver.cpp:245]     Train net output #0: loss = 2.54185 (* 1 = 2.54185 loss)
I0605 07:06:24.961654   904 sgd_solver.cpp:106] Iteration 62400, lr = 0.0253176
I0605 07:06:45.634596   904 solver.cpp:229] Iteration 62440, loss = 2.79535
I0605 07:06:45.634701   904 solver.cpp:245]     Train net output #0: loss = 2.91101 (* 1 = 2.91101 loss)
I0605 07:06:45.634711   904 sgd_solver.cpp:106] Iteration 62440, lr = 0.0253082
I0605 07:07:06.309134   904 solver.cpp:229] Iteration 62480, loss = 2.81782
I0605 07:07:06.309175   904 solver.cpp:245]     Train net output #0: loss = 2.47875 (* 1 = 2.47875 loss)
I0605 07:07:06.309183   904 sgd_solver.cpp:106] Iteration 62480, lr = 0.0252988
I0605 07:07:26.805749   904 solver.cpp:229] Iteration 62520, loss = 2.8401
I0605 07:07:26.805949   904 solver.cpp:245]     Train net output #0: loss = 2.76198 (* 1 = 2.76198 loss)
I0605 07:07:26.805976   904 sgd_solver.cpp:106] Iteration 62520, lr = 0.0252894
I0605 07:07:47.319430   904 solver.cpp:229] Iteration 62560, loss = 2.8336
I0605 07:07:47.319480   904 solver.cpp:245]     Train net output #0: loss = 2.94113 (* 1 = 2.94113 loss)
I0605 07:07:47.319489   904 sgd_solver.cpp:106] Iteration 62560, lr = 0.02528
I0605 07:07:49.889680   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 07:08:07.794412   904 solver.cpp:229] Iteration 62600, loss = 2.83335
I0605 07:08:07.794705   904 solver.cpp:245]     Train net output #0: loss = 2.88398 (* 1 = 2.88398 loss)
I0605 07:08:07.794733   904 sgd_solver.cpp:106] Iteration 62600, lr = 0.0252706
I0605 07:08:28.250954   904 solver.cpp:229] Iteration 62640, loss = 2.80891
I0605 07:08:28.251003   904 solver.cpp:245]     Train net output #0: loss = 2.80425 (* 1 = 2.80425 loss)
I0605 07:08:28.251013   904 sgd_solver.cpp:106] Iteration 62640, lr = 0.0252612
I0605 07:08:48.717281   904 solver.cpp:229] Iteration 62680, loss = 2.81252
I0605 07:08:48.717490   904 solver.cpp:245]     Train net output #0: loss = 2.72912 (* 1 = 2.72912 loss)
I0605 07:08:48.717517   904 sgd_solver.cpp:106] Iteration 62680, lr = 0.0252518
I0605 07:09:09.192634   904 solver.cpp:229] Iteration 62720, loss = 2.8256
I0605 07:09:09.192684   904 solver.cpp:245]     Train net output #0: loss = 2.95094 (* 1 = 2.95094 loss)
I0605 07:09:09.192693   904 sgd_solver.cpp:106] Iteration 62720, lr = 0.0252424
I0605 07:09:29.539731   904 solver.cpp:229] Iteration 62760, loss = 2.84845
I0605 07:09:29.539938   904 solver.cpp:245]     Train net output #0: loss = 2.70091 (* 1 = 2.70091 loss)
I0605 07:09:29.539966   904 sgd_solver.cpp:106] Iteration 62760, lr = 0.0252329
I0605 07:09:49.832876   904 solver.cpp:229] Iteration 62800, loss = 2.82569
I0605 07:09:49.832919   904 solver.cpp:245]     Train net output #0: loss = 3.02817 (* 1 = 3.02817 loss)
I0605 07:09:49.832929   904 sgd_solver.cpp:106] Iteration 62800, lr = 0.0252235
I0605 07:10:10.132731   904 solver.cpp:229] Iteration 62840, loss = 2.84536
I0605 07:10:10.132931   904 solver.cpp:245]     Train net output #0: loss = 2.75503 (* 1 = 2.75503 loss)
I0605 07:10:10.132957   904 sgd_solver.cpp:106] Iteration 62840, lr = 0.0252141
I0605 07:10:30.529587   904 solver.cpp:229] Iteration 62880, loss = 2.81497
I0605 07:10:30.529626   904 solver.cpp:245]     Train net output #0: loss = 2.72107 (* 1 = 2.72107 loss)
I0605 07:10:30.529634   904 sgd_solver.cpp:106] Iteration 62880, lr = 0.0252047
I0605 07:10:50.820840   904 solver.cpp:229] Iteration 62920, loss = 2.79215
I0605 07:10:50.821017   904 solver.cpp:245]     Train net output #0: loss = 2.608 (* 1 = 2.608 loss)
I0605 07:10:50.821044   904 sgd_solver.cpp:106] Iteration 62920, lr = 0.0251953
I0605 07:11:11.082763   904 solver.cpp:229] Iteration 62960, loss = 2.81545
I0605 07:11:11.082819   904 solver.cpp:245]     Train net output #0: loss = 2.87164 (* 1 = 2.87164 loss)
I0605 07:11:11.082829   904 sgd_solver.cpp:106] Iteration 62960, lr = 0.0251859
I0605 07:11:30.836541   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_63000.caffemodel
I0605 07:11:31.095784   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_63000.solverstate
I0605 07:11:31.169692   904 solver.cpp:338] Iteration 63000, Testing net (#0)
I0605 07:11:31.169782   904 net.cpp:748] Ignoring source layer loss
I0605 07:11:35.921319   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 07:12:08.978816   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 07:12:37.739717   904 solver.cpp:406]     Test net output #0: accuracy = 0.404261
I0605 07:12:37.739761   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.654959
I0605 07:12:38.053252   904 solver.cpp:229] Iteration 63000, loss = 2.83403
I0605 07:12:38.053297   904 solver.cpp:245]     Train net output #0: loss = 2.77247 (* 1 = 2.77247 loss)
I0605 07:12:38.053308   904 sgd_solver.cpp:106] Iteration 63000, lr = 0.0251765
I0605 07:12:57.220805   904 solver.cpp:229] Iteration 63040, loss = 2.84082
I0605 07:12:57.220999   904 solver.cpp:245]     Train net output #0: loss = 2.44034 (* 1 = 2.44034 loss)
I0605 07:12:57.221024   904 sgd_solver.cpp:106] Iteration 63040, lr = 0.0251671
I0605 07:13:15.220468   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 07:13:18.426548   904 solver.cpp:229] Iteration 63080, loss = 2.8326
I0605 07:13:18.426590   904 solver.cpp:245]     Train net output #0: loss = 2.69833 (* 1 = 2.69833 loss)
I0605 07:13:18.426599   904 sgd_solver.cpp:106] Iteration 63080, lr = 0.0251576
I0605 07:13:39.802654   904 solver.cpp:229] Iteration 63120, loss = 2.77657
I0605 07:13:39.802913   904 solver.cpp:245]     Train net output #0: loss = 2.78212 (* 1 = 2.78212 loss)
I0605 07:13:39.802942   904 sgd_solver.cpp:106] Iteration 63120, lr = 0.0251482
I0605 07:14:00.842875   904 solver.cpp:229] Iteration 63160, loss = 2.83227
I0605 07:14:00.842916   904 solver.cpp:245]     Train net output #0: loss = 2.66383 (* 1 = 2.66383 loss)
I0605 07:14:00.842924   904 sgd_solver.cpp:106] Iteration 63160, lr = 0.0251388
I0605 07:14:21.772797   904 solver.cpp:229] Iteration 63200, loss = 2.81296
I0605 07:14:21.772940   904 solver.cpp:245]     Train net output #0: loss = 2.86993 (* 1 = 2.86993 loss)
I0605 07:14:21.772953   904 sgd_solver.cpp:106] Iteration 63200, lr = 0.0251294
I0605 07:14:42.705834   904 solver.cpp:229] Iteration 63240, loss = 2.83209
I0605 07:14:42.705879   904 solver.cpp:245]     Train net output #0: loss = 2.90198 (* 1 = 2.90198 loss)
I0605 07:14:42.705889   904 sgd_solver.cpp:106] Iteration 63240, lr = 0.02512
I0605 07:15:03.645059   904 solver.cpp:229] Iteration 63280, loss = 2.80284
I0605 07:15:03.645206   904 solver.cpp:245]     Train net output #0: loss = 2.59378 (* 1 = 2.59378 loss)
I0605 07:15:03.645220   904 sgd_solver.cpp:106] Iteration 63280, lr = 0.0251106
I0605 07:15:24.439661   904 solver.cpp:229] Iteration 63320, loss = 2.83698
I0605 07:15:24.439713   904 solver.cpp:245]     Train net output #0: loss = 2.89157 (* 1 = 2.89157 loss)
I0605 07:15:24.439724   904 sgd_solver.cpp:106] Iteration 63320, lr = 0.0251012
I0605 07:15:44.955878   904 solver.cpp:229] Iteration 63360, loss = 2.83011
I0605 07:15:44.956039   904 solver.cpp:245]     Train net output #0: loss = 2.84698 (* 1 = 2.84698 loss)
I0605 07:15:44.956051   904 sgd_solver.cpp:106] Iteration 63360, lr = 0.0250918
I0605 07:16:05.541213   904 solver.cpp:229] Iteration 63400, loss = 2.78301
I0605 07:16:05.541266   904 solver.cpp:245]     Train net output #0: loss = 2.55606 (* 1 = 2.55606 loss)
I0605 07:16:05.541273   904 sgd_solver.cpp:106] Iteration 63400, lr = 0.0250824
I0605 07:16:26.094077   904 solver.cpp:229] Iteration 63440, loss = 2.82815
I0605 07:16:26.094254   904 solver.cpp:245]     Train net output #0: loss = 2.98836 (* 1 = 2.98836 loss)
I0605 07:16:26.094287   904 sgd_solver.cpp:106] Iteration 63440, lr = 0.0250729
I0605 07:16:46.693748   904 solver.cpp:229] Iteration 63480, loss = 2.80659
I0605 07:16:46.693801   904 solver.cpp:245]     Train net output #0: loss = 2.63289 (* 1 = 2.63289 loss)
I0605 07:16:46.693811   904 sgd_solver.cpp:106] Iteration 63480, lr = 0.0250635
I0605 07:17:07.277180   904 solver.cpp:229] Iteration 63520, loss = 2.79475
I0605 07:17:07.277281   904 solver.cpp:245]     Train net output #0: loss = 2.9616 (* 1 = 2.9616 loss)
I0605 07:17:07.277289   904 sgd_solver.cpp:106] Iteration 63520, lr = 0.0250541
I0605 07:17:27.724485   904 solver.cpp:229] Iteration 63560, loss = 2.79139
I0605 07:17:27.724548   904 solver.cpp:245]     Train net output #0: loss = 2.73608 (* 1 = 2.73608 loss)
I0605 07:17:27.724561   904 sgd_solver.cpp:106] Iteration 63560, lr = 0.0250447
I0605 07:17:36.904263   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 07:17:48.141242   904 solver.cpp:229] Iteration 63600, loss = 2.82673
I0605 07:17:48.141391   904 solver.cpp:245]     Train net output #0: loss = 2.64642 (* 1 = 2.64642 loss)
I0605 07:17:48.141402   904 sgd_solver.cpp:106] Iteration 63600, lr = 0.0250353
I0605 07:18:08.602628   904 solver.cpp:229] Iteration 63640, loss = 2.81813
I0605 07:18:08.602671   904 solver.cpp:245]     Train net output #0: loss = 2.75138 (* 1 = 2.75138 loss)
I0605 07:18:08.602679   904 sgd_solver.cpp:106] Iteration 63640, lr = 0.0250259
I0605 07:18:29.049715   904 solver.cpp:229] Iteration 63680, loss = 2.81074
I0605 07:18:29.049837   904 solver.cpp:245]     Train net output #0: loss = 2.93312 (* 1 = 2.93312 loss)
I0605 07:18:29.049847   904 sgd_solver.cpp:106] Iteration 63680, lr = 0.0250165
I0605 07:18:49.513617   904 solver.cpp:229] Iteration 63720, loss = 2.79227
I0605 07:18:49.513664   904 solver.cpp:245]     Train net output #0: loss = 2.81927 (* 1 = 2.81927 loss)
I0605 07:18:49.513674   904 sgd_solver.cpp:106] Iteration 63720, lr = 0.0250071
I0605 07:19:09.953675   904 solver.cpp:229] Iteration 63760, loss = 2.83276
I0605 07:19:09.953889   904 solver.cpp:245]     Train net output #0: loss = 2.90633 (* 1 = 2.90633 loss)
I0605 07:19:09.953902   904 sgd_solver.cpp:106] Iteration 63760, lr = 0.0249976
I0605 07:19:30.364845   904 solver.cpp:229] Iteration 63800, loss = 2.80082
I0605 07:19:30.364902   904 solver.cpp:245]     Train net output #0: loss = 2.79771 (* 1 = 2.79771 loss)
I0605 07:19:30.364914   904 sgd_solver.cpp:106] Iteration 63800, lr = 0.0249882
I0605 07:19:50.799809   904 solver.cpp:229] Iteration 63840, loss = 2.78109
I0605 07:19:50.799937   904 solver.cpp:245]     Train net output #0: loss = 2.66149 (* 1 = 2.66149 loss)
I0605 07:19:50.799947   904 sgd_solver.cpp:106] Iteration 63840, lr = 0.0249788
I0605 07:20:11.235657   904 solver.cpp:229] Iteration 63880, loss = 2.77165
I0605 07:20:11.235713   904 solver.cpp:245]     Train net output #0: loss = 2.58255 (* 1 = 2.58255 loss)
I0605 07:20:11.235723   904 sgd_solver.cpp:106] Iteration 63880, lr = 0.0249694
I0605 07:20:31.666337   904 solver.cpp:229] Iteration 63920, loss = 2.8325
I0605 07:20:31.666566   904 solver.cpp:245]     Train net output #0: loss = 2.76768 (* 1 = 2.76768 loss)
I0605 07:20:31.666592   904 sgd_solver.cpp:106] Iteration 63920, lr = 0.02496
I0605 07:20:51.971562   904 solver.cpp:229] Iteration 63960, loss = 2.83325
I0605 07:20:51.971632   904 solver.cpp:245]     Train net output #0: loss = 2.63349 (* 1 = 2.63349 loss)
I0605 07:20:51.971642   904 sgd_solver.cpp:106] Iteration 63960, lr = 0.0249506
I0605 07:21:11.696844   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_64000.caffemodel
I0605 07:21:11.967592   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_64000.solverstate
I0605 07:21:12.046237   904 solver.cpp:338] Iteration 64000, Testing net (#0)
I0605 07:21:12.046320   904 net.cpp:748] Ignoring source layer loss
I0605 07:21:17.624498   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 07:21:50.315199   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 07:22:17.335747   904 solver.cpp:406]     Test net output #0: accuracy = 0.392101
I0605 07:22:17.335779   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.643699
I0605 07:22:17.650348   904 solver.cpp:229] Iteration 64000, loss = 2.83382
I0605 07:22:17.650394   904 solver.cpp:245]     Train net output #0: loss = 2.71792 (* 1 = 2.71792 loss)
I0605 07:22:17.650405   904 sgd_solver.cpp:106] Iteration 64000, lr = 0.0249412
I0605 07:22:36.895752   904 solver.cpp:229] Iteration 64040, loss = 2.8368
I0605 07:22:36.895982   904 solver.cpp:245]     Train net output #0: loss = 2.72154 (* 1 = 2.72154 loss)
I0605 07:22:36.896008   904 sgd_solver.cpp:106] Iteration 64040, lr = 0.0249318
I0605 07:22:58.352089   904 solver.cpp:229] Iteration 64080, loss = 2.82202
I0605 07:22:58.352144   904 solver.cpp:245]     Train net output #0: loss = 2.94933 (* 1 = 2.94933 loss)
I0605 07:22:58.352154   904 sgd_solver.cpp:106] Iteration 64080, lr = 0.0249224
I0605 07:23:01.863066   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 07:23:19.919006   904 solver.cpp:229] Iteration 64120, loss = 2.83482
I0605 07:23:19.919116   904 solver.cpp:245]     Train net output #0: loss = 2.79817 (* 1 = 2.79817 loss)
I0605 07:23:19.919131   904 sgd_solver.cpp:106] Iteration 64120, lr = 0.0249129
I0605 07:23:41.138180   904 solver.cpp:229] Iteration 64160, loss = 2.77819
I0605 07:23:41.138236   904 solver.cpp:245]     Train net output #0: loss = 2.78124 (* 1 = 2.78124 loss)
I0605 07:23:41.138244   904 sgd_solver.cpp:106] Iteration 64160, lr = 0.0249035
I0605 07:24:02.129863   904 solver.cpp:229] Iteration 64200, loss = 2.79158
I0605 07:24:02.130097   904 solver.cpp:245]     Train net output #0: loss = 2.77785 (* 1 = 2.77785 loss)
I0605 07:24:02.130125   904 sgd_solver.cpp:106] Iteration 64200, lr = 0.0248941
I0605 07:24:23.044885   904 solver.cpp:229] Iteration 64240, loss = 2.82676
I0605 07:24:23.044930   904 solver.cpp:245]     Train net output #0: loss = 3.08339 (* 1 = 3.08339 loss)
I0605 07:24:23.044951   904 sgd_solver.cpp:106] Iteration 64240, lr = 0.0248847
I0605 07:24:43.698866   904 solver.cpp:229] Iteration 64280, loss = 2.75466
I0605 07:24:43.699177   904 solver.cpp:245]     Train net output #0: loss = 2.66932 (* 1 = 2.66932 loss)
I0605 07:24:43.699213   904 sgd_solver.cpp:106] Iteration 64280, lr = 0.0248753
I0605 07:25:04.174336   904 solver.cpp:229] Iteration 64320, loss = 2.77167
I0605 07:25:04.174383   904 solver.cpp:245]     Train net output #0: loss = 3.05333 (* 1 = 3.05333 loss)
I0605 07:25:04.174394   904 sgd_solver.cpp:106] Iteration 64320, lr = 0.0248659
I0605 07:25:24.689678   904 solver.cpp:229] Iteration 64360, loss = 2.77307
I0605 07:25:24.689889   904 solver.cpp:245]     Train net output #0: loss = 2.92381 (* 1 = 2.92381 loss)
I0605 07:25:24.689918   904 sgd_solver.cpp:106] Iteration 64360, lr = 0.0248565
I0605 07:25:45.001843   904 solver.cpp:229] Iteration 64400, loss = 2.77587
I0605 07:25:45.001893   904 solver.cpp:245]     Train net output #0: loss = 2.72657 (* 1 = 2.72657 loss)
I0605 07:25:45.001901   904 sgd_solver.cpp:106] Iteration 64400, lr = 0.0248471
I0605 07:26:05.203433   904 solver.cpp:229] Iteration 64440, loss = 2.79589
I0605 07:26:05.203584   904 solver.cpp:245]     Train net output #0: loss = 2.66412 (* 1 = 2.66412 loss)
I0605 07:26:05.203591   904 sgd_solver.cpp:106] Iteration 64440, lr = 0.0248376
I0605 07:26:25.489565   904 solver.cpp:229] Iteration 64480, loss = 2.78813
I0605 07:26:25.489604   904 solver.cpp:245]     Train net output #0: loss = 2.62596 (* 1 = 2.62596 loss)
I0605 07:26:25.489611   904 sgd_solver.cpp:106] Iteration 64480, lr = 0.0248282
I0605 07:26:45.758533   904 solver.cpp:229] Iteration 64520, loss = 2.76958
I0605 07:26:45.758671   904 solver.cpp:245]     Train net output #0: loss = 2.75973 (* 1 = 2.75973 loss)
I0605 07:26:45.758682   904 sgd_solver.cpp:106] Iteration 64520, lr = 0.0248188
I0605 07:27:06.028682   904 solver.cpp:229] Iteration 64560, loss = 2.77202
I0605 07:27:06.028734   904 solver.cpp:245]     Train net output #0: loss = 2.78283 (* 1 = 2.78283 loss)
I0605 07:27:06.028743   904 sgd_solver.cpp:106] Iteration 64560, lr = 0.0248094
I0605 07:27:26.282163   904 solver.cpp:229] Iteration 64600, loss = 2.80197
I0605 07:27:26.282333   904 solver.cpp:245]     Train net output #0: loss = 2.58398 (* 1 = 2.58398 loss)
I0605 07:27:26.282369   904 sgd_solver.cpp:106] Iteration 64600, lr = 0.0248
I0605 07:27:39.459590   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 07:27:46.563851   904 solver.cpp:229] Iteration 64640, loss = 2.7941
I0605 07:27:46.563902   904 solver.cpp:245]     Train net output #0: loss = 2.83653 (* 1 = 2.83653 loss)
I0605 07:27:46.563911   904 sgd_solver.cpp:106] Iteration 64640, lr = 0.0247906
I0605 07:28:06.856581   904 solver.cpp:229] Iteration 64680, loss = 2.80835
I0605 07:28:06.856796   904 solver.cpp:245]     Train net output #0: loss = 2.92395 (* 1 = 2.92395 loss)
I0605 07:28:06.856820   904 sgd_solver.cpp:106] Iteration 64680, lr = 0.0247812
I0605 07:28:27.144182   904 solver.cpp:229] Iteration 64720, loss = 2.80316
I0605 07:28:27.144242   904 solver.cpp:245]     Train net output #0: loss = 2.71861 (* 1 = 2.71861 loss)
I0605 07:28:27.144253   904 sgd_solver.cpp:106] Iteration 64720, lr = 0.0247718
I0605 07:28:47.454871   904 solver.cpp:229] Iteration 64760, loss = 2.77525
I0605 07:28:47.455044   904 solver.cpp:245]     Train net output #0: loss = 2.75253 (* 1 = 2.75253 loss)
I0605 07:28:47.455054   904 sgd_solver.cpp:106] Iteration 64760, lr = 0.0247624
I0605 07:29:07.728528   904 solver.cpp:229] Iteration 64800, loss = 2.80076
I0605 07:29:07.728576   904 solver.cpp:245]     Train net output #0: loss = 2.78659 (* 1 = 2.78659 loss)
I0605 07:29:07.728595   904 sgd_solver.cpp:106] Iteration 64800, lr = 0.0247529
I0605 07:29:28.012502   904 solver.cpp:229] Iteration 64840, loss = 2.8228
I0605 07:29:28.012742   904 solver.cpp:245]     Train net output #0: loss = 2.6401 (* 1 = 2.6401 loss)
I0605 07:29:28.012766   904 sgd_solver.cpp:106] Iteration 64840, lr = 0.0247435
I0605 07:29:48.310196   904 solver.cpp:229] Iteration 64880, loss = 2.7833
I0605 07:29:48.310246   904 solver.cpp:245]     Train net output #0: loss = 2.7277 (* 1 = 2.7277 loss)
I0605 07:29:48.310255   904 sgd_solver.cpp:106] Iteration 64880, lr = 0.0247341
I0605 07:30:08.572846   904 solver.cpp:229] Iteration 64920, loss = 2.77958
I0605 07:30:08.573036   904 solver.cpp:245]     Train net output #0: loss = 2.91852 (* 1 = 2.91852 loss)
I0605 07:30:08.573061   904 sgd_solver.cpp:106] Iteration 64920, lr = 0.0247247
I0605 07:30:28.849400   904 solver.cpp:229] Iteration 64960, loss = 2.82189
I0605 07:30:28.849442   904 solver.cpp:245]     Train net output #0: loss = 2.96809 (* 1 = 2.96809 loss)
I0605 07:30:28.849463   904 sgd_solver.cpp:106] Iteration 64960, lr = 0.0247153
I0605 07:30:48.631497   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_65000.caffemodel
I0605 07:30:48.896697   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_65000.solverstate
I0605 07:30:48.974153   904 solver.cpp:338] Iteration 65000, Testing net (#0)
I0605 07:30:48.974247   904 net.cpp:748] Ignoring source layer loss
I0605 07:30:59.796329   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 07:31:35.013438   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 07:31:58.357393   904 solver.cpp:406]     Test net output #0: accuracy = 0.406321
I0605 07:31:58.357429   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.65678
I0605 07:31:58.670617   904 solver.cpp:229] Iteration 65000, loss = 2.8286
I0605 07:31:58.670658   904 solver.cpp:245]     Train net output #0: loss = 2.87754 (* 1 = 2.87754 loss)
I0605 07:31:58.670667   904 sgd_solver.cpp:106] Iteration 65000, lr = 0.0247059
I0605 07:32:17.909238   904 solver.cpp:229] Iteration 65040, loss = 2.78531
I0605 07:32:17.909451   904 solver.cpp:245]     Train net output #0: loss = 2.85034 (* 1 = 2.85034 loss)
I0605 07:32:17.909481   904 sgd_solver.cpp:106] Iteration 65040, lr = 0.0246965
I0605 07:32:39.326385   904 solver.cpp:229] Iteration 65080, loss = 2.83988
I0605 07:32:39.326436   904 solver.cpp:245]     Train net output #0: loss = 2.87196 (* 1 = 2.87196 loss)
I0605 07:32:39.326445   904 sgd_solver.cpp:106] Iteration 65080, lr = 0.0246871
I0605 07:33:00.812266   904 solver.cpp:229] Iteration 65120, loss = 2.82452
I0605 07:33:00.812486   904 solver.cpp:245]     Train net output #0: loss = 2.25621 (* 1 = 2.25621 loss)
I0605 07:33:00.812515   904 sgd_solver.cpp:106] Iteration 65120, lr = 0.0246776
I0605 07:33:21.885275   904 solver.cpp:229] Iteration 65160, loss = 2.81595
I0605 07:33:21.885321   904 solver.cpp:245]     Train net output #0: loss = 2.95568 (* 1 = 2.95568 loss)
I0605 07:33:21.885344   904 sgd_solver.cpp:106] Iteration 65160, lr = 0.0246682
I0605 07:33:23.461163   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 07:33:42.866847   904 solver.cpp:229] Iteration 65200, loss = 2.78713
I0605 07:33:42.867053   904 solver.cpp:245]     Train net output #0: loss = 2.76341 (* 1 = 2.76341 loss)
I0605 07:33:42.867086   904 sgd_solver.cpp:106] Iteration 65200, lr = 0.0246588
I0605 07:34:03.836513   904 solver.cpp:229] Iteration 65240, loss = 2.80884
I0605 07:34:03.836557   904 solver.cpp:245]     Train net output #0: loss = 2.86167 (* 1 = 2.86167 loss)
I0605 07:34:03.836575   904 sgd_solver.cpp:106] Iteration 65240, lr = 0.0246494
I0605 07:34:24.819458   904 solver.cpp:229] Iteration 65280, loss = 2.80775
I0605 07:34:24.819645   904 solver.cpp:245]     Train net output #0: loss = 2.79707 (* 1 = 2.79707 loss)
I0605 07:34:24.819669   904 sgd_solver.cpp:106] Iteration 65280, lr = 0.02464
I0605 07:34:45.793608   904 solver.cpp:229] Iteration 65320, loss = 2.80973
I0605 07:34:45.793663   904 solver.cpp:245]     Train net output #0: loss = 2.85325 (* 1 = 2.85325 loss)
I0605 07:34:45.793671   904 sgd_solver.cpp:106] Iteration 65320, lr = 0.0246306
I0605 07:35:06.580117   904 solver.cpp:229] Iteration 65360, loss = 2.82329
I0605 07:35:06.580353   904 solver.cpp:245]     Train net output #0: loss = 2.7503 (* 1 = 2.7503 loss)
I0605 07:35:06.580365   904 sgd_solver.cpp:106] Iteration 65360, lr = 0.0246212
I0605 07:35:27.291738   904 solver.cpp:229] Iteration 65400, loss = 2.77942
I0605 07:35:27.291790   904 solver.cpp:245]     Train net output #0: loss = 2.6961 (* 1 = 2.6961 loss)
I0605 07:35:27.291800   904 sgd_solver.cpp:106] Iteration 65400, lr = 0.0246118
I0605 07:35:47.957864   904 solver.cpp:229] Iteration 65440, loss = 2.77192
I0605 07:35:47.958092   904 solver.cpp:245]     Train net output #0: loss = 2.76519 (* 1 = 2.76519 loss)
I0605 07:35:47.958119   904 sgd_solver.cpp:106] Iteration 65440, lr = 0.0246023
I0605 07:36:08.610085   904 solver.cpp:229] Iteration 65480, loss = 2.77728
I0605 07:36:08.610137   904 solver.cpp:245]     Train net output #0: loss = 2.96072 (* 1 = 2.96072 loss)
I0605 07:36:08.610146   904 sgd_solver.cpp:106] Iteration 65480, lr = 0.0245929
I0605 07:36:29.289598   904 solver.cpp:229] Iteration 65520, loss = 2.80912
I0605 07:36:29.289824   904 solver.cpp:245]     Train net output #0: loss = 3.07071 (* 1 = 3.07071 loss)
I0605 07:36:29.289849   904 sgd_solver.cpp:106] Iteration 65520, lr = 0.0245835
I0605 07:36:49.803971   904 solver.cpp:229] Iteration 65560, loss = 2.82996
I0605 07:36:49.804000   904 solver.cpp:245]     Train net output #0: loss = 3.05069 (* 1 = 3.05069 loss)
I0605 07:36:49.804006   904 sgd_solver.cpp:106] Iteration 65560, lr = 0.0245741
I0605 07:37:10.328207   904 solver.cpp:229] Iteration 65600, loss = 2.78331
I0605 07:37:10.328392   904 solver.cpp:245]     Train net output #0: loss = 2.84264 (* 1 = 2.84264 loss)
I0605 07:37:10.328423   904 sgd_solver.cpp:106] Iteration 65600, lr = 0.0245647
I0605 07:37:30.792148   904 solver.cpp:229] Iteration 65640, loss = 2.82511
I0605 07:37:30.792196   904 solver.cpp:245]     Train net output #0: loss = 2.75872 (* 1 = 2.75872 loss)
I0605 07:37:30.792204   904 sgd_solver.cpp:106] Iteration 65640, lr = 0.0245553
I0605 07:37:51.279450   904 solver.cpp:229] Iteration 65680, loss = 2.83397
I0605 07:37:51.279621   904 solver.cpp:245]     Train net output #0: loss = 2.89224 (* 1 = 2.89224 loss)
I0605 07:37:51.279649   904 sgd_solver.cpp:106] Iteration 65680, lr = 0.0245459
I0605 07:38:11.770126   904 solver.cpp:229] Iteration 65720, loss = 2.82034
I0605 07:38:11.770179   904 solver.cpp:245]     Train net output #0: loss = 2.88479 (* 1 = 2.88479 loss)
I0605 07:38:11.770187   904 sgd_solver.cpp:106] Iteration 65720, lr = 0.0245365
I0605 07:38:22.276700   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 07:38:32.455076   904 solver.cpp:229] Iteration 65760, loss = 2.7896
I0605 07:38:32.455123   904 solver.cpp:245]     Train net output #0: loss = 2.62354 (* 1 = 2.62354 loss)
I0605 07:38:32.455133   904 sgd_solver.cpp:106] Iteration 65760, lr = 0.0245271
I0605 07:38:52.742866   904 solver.cpp:229] Iteration 65800, loss = 2.80683
I0605 07:38:52.743027   904 solver.cpp:245]     Train net output #0: loss = 2.74524 (* 1 = 2.74524 loss)
I0605 07:38:52.743053   904 sgd_solver.cpp:106] Iteration 65800, lr = 0.0245176
I0605 07:39:13.225539   904 solver.cpp:229] Iteration 65840, loss = 2.81183
I0605 07:39:13.225585   904 solver.cpp:245]     Train net output #0: loss = 3.05736 (* 1 = 3.05736 loss)
I0605 07:39:13.225594   904 sgd_solver.cpp:106] Iteration 65840, lr = 0.0245082
I0605 07:39:33.628913   904 solver.cpp:229] Iteration 65880, loss = 2.7601
I0605 07:39:33.629123   904 solver.cpp:245]     Train net output #0: loss = 2.51146 (* 1 = 2.51146 loss)
I0605 07:39:33.629148   904 sgd_solver.cpp:106] Iteration 65880, lr = 0.0244988
I0605 07:39:53.894175   904 solver.cpp:229] Iteration 65920, loss = 2.76145
I0605 07:39:53.894225   904 solver.cpp:245]     Train net output #0: loss = 2.8388 (* 1 = 2.8388 loss)
I0605 07:39:53.894234   904 sgd_solver.cpp:106] Iteration 65920, lr = 0.0244894
I0605 07:40:14.094033   904 solver.cpp:229] Iteration 65960, loss = 2.79137
I0605 07:40:14.094238   904 solver.cpp:245]     Train net output #0: loss = 2.59653 (* 1 = 2.59653 loss)
I0605 07:40:14.094265   904 sgd_solver.cpp:106] Iteration 65960, lr = 0.02448
I0605 07:40:33.849941   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_66000.caffemodel
I0605 07:40:34.114778   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_66000.solverstate
I0605 07:40:34.188163   904 solver.cpp:338] Iteration 66000, Testing net (#0)
I0605 07:40:34.188235   904 net.cpp:748] Ignoring source layer loss
I0605 07:40:51.906770   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 07:41:25.500361   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 07:41:41.324959   904 solver.cpp:406]     Test net output #0: accuracy = 0.406602
I0605 07:41:41.324992   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.66016
I0605 07:41:41.641263   904 solver.cpp:229] Iteration 66000, loss = 2.74216
I0605 07:41:41.641309   904 solver.cpp:245]     Train net output #0: loss = 2.63585 (* 1 = 2.63585 loss)
I0605 07:41:41.641320   904 sgd_solver.cpp:106] Iteration 66000, lr = 0.0244706
I0605 07:42:00.813602   904 solver.cpp:229] Iteration 66040, loss = 2.78114
I0605 07:42:00.813729   904 solver.cpp:245]     Train net output #0: loss = 2.68375 (* 1 = 2.68375 loss)
I0605 07:42:00.813740   904 sgd_solver.cpp:106] Iteration 66040, lr = 0.0244612
I0605 07:42:22.037739   904 solver.cpp:229] Iteration 66080, loss = 2.78293
I0605 07:42:22.037775   904 solver.cpp:245]     Train net output #0: loss = 2.92446 (* 1 = 2.92446 loss)
I0605 07:42:22.037783   904 sgd_solver.cpp:106] Iteration 66080, lr = 0.0244518
I0605 07:42:43.297535   904 solver.cpp:229] Iteration 66120, loss = 2.7808
I0605 07:42:43.297713   904 solver.cpp:245]     Train net output #0: loss = 2.62221 (* 1 = 2.62221 loss)
I0605 07:42:43.297740   904 sgd_solver.cpp:106] Iteration 66120, lr = 0.0244424
I0605 07:43:04.249611   904 solver.cpp:229] Iteration 66160, loss = 2.7695
I0605 07:43:04.249665   904 solver.cpp:245]     Train net output #0: loss = 2.83205 (* 1 = 2.83205 loss)
I0605 07:43:04.249672   904 sgd_solver.cpp:106] Iteration 66160, lr = 0.0244329
I0605 07:43:25.227036   904 solver.cpp:229] Iteration 66200, loss = 2.80218
I0605 07:43:25.227190   904 solver.cpp:245]     Train net output #0: loss = 2.9226 (* 1 = 2.9226 loss)
I0605 07:43:25.227201   904 sgd_solver.cpp:106] Iteration 66200, lr = 0.0244235
I0605 07:43:46.163539   904 solver.cpp:229] Iteration 66240, loss = 2.79105
I0605 07:43:46.163588   904 solver.cpp:245]     Train net output #0: loss = 3.03219 (* 1 = 3.03219 loss)
I0605 07:43:46.163595   904 sgd_solver.cpp:106] Iteration 66240, lr = 0.0244141
I0605 07:44:07.381454   904 solver.cpp:229] Iteration 66280, loss = 2.76897
I0605 07:44:07.381661   904 solver.cpp:245]     Train net output #0: loss = 2.78977 (* 1 = 2.78977 loss)
I0605 07:44:07.381686   904 sgd_solver.cpp:106] Iteration 66280, lr = 0.0244047
I0605 07:44:12.255111   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 07:44:27.986588   904 solver.cpp:229] Iteration 66320, loss = 2.79972
I0605 07:44:27.986645   904 solver.cpp:245]     Train net output #0: loss = 2.75629 (* 1 = 2.75629 loss)
I0605 07:44:27.986654   904 sgd_solver.cpp:106] Iteration 66320, lr = 0.0243953
I0605 07:44:48.628455   904 solver.cpp:229] Iteration 66360, loss = 2.79492
I0605 07:44:48.628645   904 solver.cpp:245]     Train net output #0: loss = 2.5201 (* 1 = 2.5201 loss)
I0605 07:44:48.628674   904 sgd_solver.cpp:106] Iteration 66360, lr = 0.0243859
I0605 07:45:09.235568   904 solver.cpp:229] Iteration 66400, loss = 2.82469
I0605 07:45:09.235605   904 solver.cpp:245]     Train net output #0: loss = 2.92585 (* 1 = 2.92585 loss)
I0605 07:45:09.235612   904 sgd_solver.cpp:106] Iteration 66400, lr = 0.0243765
I0605 07:45:29.841038   904 solver.cpp:229] Iteration 66440, loss = 2.79029
I0605 07:45:29.841336   904 solver.cpp:245]     Train net output #0: loss = 2.58775 (* 1 = 2.58775 loss)
I0605 07:45:29.841361   904 sgd_solver.cpp:106] Iteration 66440, lr = 0.0243671
I0605 07:45:50.379890   904 solver.cpp:229] Iteration 66480, loss = 2.82056
I0605 07:45:50.379951   904 solver.cpp:245]     Train net output #0: loss = 2.70409 (* 1 = 2.70409 loss)
I0605 07:45:50.379963   904 sgd_solver.cpp:106] Iteration 66480, lr = 0.0243576
I0605 07:46:10.860126   904 solver.cpp:229] Iteration 66520, loss = 2.8242
I0605 07:46:10.860276   904 solver.cpp:245]     Train net output #0: loss = 2.73233 (* 1 = 2.73233 loss)
I0605 07:46:10.860286   904 sgd_solver.cpp:106] Iteration 66520, lr = 0.0243482
I0605 07:46:31.333267   904 solver.cpp:229] Iteration 66560, loss = 2.76565
I0605 07:46:31.333312   904 solver.cpp:245]     Train net output #0: loss = 2.69546 (* 1 = 2.69546 loss)
I0605 07:46:31.333323   904 sgd_solver.cpp:106] Iteration 66560, lr = 0.0243388
I0605 07:46:51.807818   904 solver.cpp:229] Iteration 66600, loss = 2.77833
I0605 07:46:51.808040   904 solver.cpp:245]     Train net output #0: loss = 2.81194 (* 1 = 2.81194 loss)
I0605 07:46:51.808064   904 sgd_solver.cpp:106] Iteration 66600, lr = 0.0243294
I0605 07:47:12.264149   904 solver.cpp:229] Iteration 66640, loss = 2.79888
I0605 07:47:12.264206   904 solver.cpp:245]     Train net output #0: loss = 2.81389 (* 1 = 2.81389 loss)
I0605 07:47:12.264216   904 sgd_solver.cpp:106] Iteration 66640, lr = 0.02432
I0605 07:47:32.718240   904 solver.cpp:229] Iteration 66680, loss = 2.78985
I0605 07:47:32.718417   904 solver.cpp:245]     Train net output #0: loss = 2.84207 (* 1 = 2.84207 loss)
I0605 07:47:32.718448   904 sgd_solver.cpp:106] Iteration 66680, lr = 0.0243106
I0605 07:47:53.247474   904 solver.cpp:229] Iteration 66720, loss = 2.8061
I0605 07:47:53.247524   904 solver.cpp:245]     Train net output #0: loss = 2.63744 (* 1 = 2.63744 loss)
I0605 07:47:53.247531   904 sgd_solver.cpp:106] Iteration 66720, lr = 0.0243012
I0605 07:48:13.739522   904 solver.cpp:229] Iteration 66760, loss = 2.79475
I0605 07:48:13.739707   904 solver.cpp:245]     Train net output #0: loss = 2.62032 (* 1 = 2.62032 loss)
I0605 07:48:13.739723   904 sgd_solver.cpp:106] Iteration 66760, lr = 0.0242918
I0605 07:48:34.198920   904 solver.cpp:229] Iteration 66800, loss = 2.77395
I0605 07:48:34.198978   904 solver.cpp:245]     Train net output #0: loss = 2.70607 (* 1 = 2.70607 loss)
I0605 07:48:34.198988   904 sgd_solver.cpp:106] Iteration 66800, lr = 0.0242824
I0605 07:48:54.545064   904 solver.cpp:229] Iteration 66840, loss = 2.7478
I0605 07:48:54.545255   904 solver.cpp:245]     Train net output #0: loss = 2.67044 (* 1 = 2.67044 loss)
I0605 07:48:54.545284   904 sgd_solver.cpp:106] Iteration 66840, lr = 0.0242729
I0605 07:49:06.206655   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 07:49:14.804981   904 solver.cpp:229] Iteration 66880, loss = 2.77849
I0605 07:49:14.805032   904 solver.cpp:245]     Train net output #0: loss = 2.58458 (* 1 = 2.58458 loss)
I0605 07:49:14.805040   904 sgd_solver.cpp:106] Iteration 66880, lr = 0.0242635
I0605 07:49:35.201475   904 solver.cpp:229] Iteration 66920, loss = 2.76753
I0605 07:49:35.201604   904 solver.cpp:245]     Train net output #0: loss = 2.81213 (* 1 = 2.81213 loss)
I0605 07:49:35.201614   904 sgd_solver.cpp:106] Iteration 66920, lr = 0.0242541
I0605 07:49:55.698329   904 solver.cpp:229] Iteration 66960, loss = 2.75362
I0605 07:49:55.698365   904 solver.cpp:245]     Train net output #0: loss = 2.73724 (* 1 = 2.73724 loss)
I0605 07:49:55.698372   904 sgd_solver.cpp:106] Iteration 66960, lr = 0.0242447
I0605 07:50:15.625296   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_67000.caffemodel
I0605 07:50:15.888624   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_67000.solverstate
I0605 07:50:15.963359   904 solver.cpp:338] Iteration 67000, Testing net (#0)
I0605 07:50:15.963438   904 net.cpp:748] Ignoring source layer loss
I0605 07:50:42.187496   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 07:51:16.728164   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 07:51:25.218765   904 solver.cpp:406]     Test net output #0: accuracy = 0.391101
I0605 07:51:25.218807   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.645779
I0605 07:51:25.532724   904 solver.cpp:229] Iteration 67000, loss = 2.75337
I0605 07:51:25.532771   904 solver.cpp:245]     Train net output #0: loss = 2.62525 (* 1 = 2.62525 loss)
I0605 07:51:25.532780   904 sgd_solver.cpp:106] Iteration 67000, lr = 0.0242353
I0605 07:51:44.712951   904 solver.cpp:229] Iteration 67040, loss = 2.76973
I0605 07:51:44.713002   904 solver.cpp:245]     Train net output #0: loss = 2.93961 (* 1 = 2.93961 loss)
I0605 07:51:44.713011   904 sgd_solver.cpp:106] Iteration 67040, lr = 0.0242259
I0605 07:52:06.157059   904 solver.cpp:229] Iteration 67080, loss = 2.76294
I0605 07:52:06.157181   904 solver.cpp:245]     Train net output #0: loss = 2.81642 (* 1 = 2.81642 loss)
I0605 07:52:06.157193   904 sgd_solver.cpp:106] Iteration 67080, lr = 0.0242165
I0605 07:52:27.680584   904 solver.cpp:229] Iteration 67120, loss = 2.7718
I0605 07:52:27.680622   904 solver.cpp:245]     Train net output #0: loss = 2.98247 (* 1 = 2.98247 loss)
I0605 07:52:27.680629   904 sgd_solver.cpp:106] Iteration 67120, lr = 0.0242071
I0605 07:52:49.161098   904 solver.cpp:229] Iteration 67160, loss = 2.78707
I0605 07:52:49.161299   904 solver.cpp:245]     Train net output #0: loss = 2.8618 (* 1 = 2.8618 loss)
I0605 07:52:49.161325   904 sgd_solver.cpp:106] Iteration 67160, lr = 0.0241976
I0605 07:53:10.189316   904 solver.cpp:229] Iteration 67200, loss = 2.7682
I0605 07:53:10.189360   904 solver.cpp:245]     Train net output #0: loss = 2.7962 (* 1 = 2.7962 loss)
I0605 07:53:10.189371   904 sgd_solver.cpp:106] Iteration 67200, lr = 0.0241882
I0605 07:53:31.191385   904 solver.cpp:229] Iteration 67240, loss = 2.81108
I0605 07:53:31.191587   904 solver.cpp:245]     Train net output #0: loss = 2.82137 (* 1 = 2.82137 loss)
I0605 07:53:31.191617   904 sgd_solver.cpp:106] Iteration 67240, lr = 0.0241788
I0605 07:53:52.305644   904 solver.cpp:229] Iteration 67280, loss = 2.74554
I0605 07:53:52.305693   904 solver.cpp:245]     Train net output #0: loss = 2.81659 (* 1 = 2.81659 loss)
I0605 07:53:52.305702   904 sgd_solver.cpp:106] Iteration 67280, lr = 0.0241694
I0605 07:54:13.204464   904 solver.cpp:229] Iteration 67320, loss = 2.79071
I0605 07:54:13.204648   904 solver.cpp:245]     Train net output #0: loss = 2.65981 (* 1 = 2.65981 loss)
I0605 07:54:13.204675   904 sgd_solver.cpp:106] Iteration 67320, lr = 0.02416
I0605 07:54:33.979513   904 solver.cpp:229] Iteration 67360, loss = 2.78483
I0605 07:54:33.979559   904 solver.cpp:245]     Train net output #0: loss = 2.64612 (* 1 = 2.64612 loss)
I0605 07:54:33.979568   904 sgd_solver.cpp:106] Iteration 67360, lr = 0.0241506
I0605 07:54:48.025423   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 07:54:54.797554   904 solver.cpp:229] Iteration 67400, loss = 2.75077
I0605 07:54:54.797600   904 solver.cpp:245]     Train net output #0: loss = 2.88396 (* 1 = 2.88396 loss)
I0605 07:54:54.797611   904 sgd_solver.cpp:106] Iteration 67400, lr = 0.0241412
I0605 07:55:15.610055   904 solver.cpp:229] Iteration 67440, loss = 2.77601
I0605 07:55:15.610105   904 solver.cpp:245]     Train net output #0: loss = 2.91553 (* 1 = 2.91553 loss)
I0605 07:55:15.610116   904 sgd_solver.cpp:106] Iteration 67440, lr = 0.0241318
I0605 07:55:36.412578   904 solver.cpp:229] Iteration 67480, loss = 2.75157
I0605 07:55:36.412771   904 solver.cpp:245]     Train net output #0: loss = 2.82836 (* 1 = 2.82836 loss)
I0605 07:55:36.412804   904 sgd_solver.cpp:106] Iteration 67480, lr = 0.0241224
I0605 07:55:57.205828   904 solver.cpp:229] Iteration 67520, loss = 2.78679
I0605 07:55:57.205884   904 solver.cpp:245]     Train net output #0: loss = 2.79417 (* 1 = 2.79417 loss)
I0605 07:55:57.205895   904 sgd_solver.cpp:106] Iteration 67520, lr = 0.0241129
I0605 07:56:17.778138   904 solver.cpp:229] Iteration 67560, loss = 2.78038
I0605 07:56:17.778414   904 solver.cpp:245]     Train net output #0: loss = 2.84142 (* 1 = 2.84142 loss)
I0605 07:56:17.778440   904 sgd_solver.cpp:106] Iteration 67560, lr = 0.0241035
I0605 07:56:38.415172   904 solver.cpp:229] Iteration 67600, loss = 2.81439
I0605 07:56:38.415228   904 solver.cpp:245]     Train net output #0: loss = 2.5034 (* 1 = 2.5034 loss)
I0605 07:56:38.415240   904 sgd_solver.cpp:106] Iteration 67600, lr = 0.0240941
I0605 07:56:59.051115   904 solver.cpp:229] Iteration 67640, loss = 2.77037
I0605 07:56:59.051254   904 solver.cpp:245]     Train net output #0: loss = 2.75505 (* 1 = 2.75505 loss)
I0605 07:56:59.051266   904 sgd_solver.cpp:106] Iteration 67640, lr = 0.0240847
I0605 07:57:19.663626   904 solver.cpp:229] Iteration 67680, loss = 2.77455
I0605 07:57:19.663678   904 solver.cpp:245]     Train net output #0: loss = 2.57894 (* 1 = 2.57894 loss)
I0605 07:57:19.663687   904 sgd_solver.cpp:106] Iteration 67680, lr = 0.0240753
I0605 07:57:40.151952   904 solver.cpp:229] Iteration 67720, loss = 2.78777
I0605 07:57:40.152127   904 solver.cpp:245]     Train net output #0: loss = 2.76709 (* 1 = 2.76709 loss)
I0605 07:57:40.152154   904 sgd_solver.cpp:106] Iteration 67720, lr = 0.0240659
I0605 07:58:00.653929   904 solver.cpp:229] Iteration 67760, loss = 2.79287
I0605 07:58:00.653985   904 solver.cpp:245]     Train net output #0: loss = 2.60352 (* 1 = 2.60352 loss)
I0605 07:58:00.653995   904 sgd_solver.cpp:106] Iteration 67760, lr = 0.0240565
I0605 07:58:21.161717   904 solver.cpp:229] Iteration 67800, loss = 2.78196
I0605 07:58:21.161913   904 solver.cpp:245]     Train net output #0: loss = 2.9621 (* 1 = 2.9621 loss)
I0605 07:58:21.161938   904 sgd_solver.cpp:106] Iteration 67800, lr = 0.0240471
I0605 07:58:41.644727   904 solver.cpp:229] Iteration 67840, loss = 2.7897
I0605 07:58:41.644767   904 solver.cpp:245]     Train net output #0: loss = 2.78252 (* 1 = 2.78252 loss)
I0605 07:58:41.644776   904 sgd_solver.cpp:106] Iteration 67840, lr = 0.0240376
I0605 07:59:02.128490   904 solver.cpp:229] Iteration 67880, loss = 2.76545
I0605 07:59:02.128702   904 solver.cpp:245]     Train net output #0: loss = 2.58399 (* 1 = 2.58399 loss)
I0605 07:59:02.128727   904 sgd_solver.cpp:106] Iteration 67880, lr = 0.0240282
I0605 07:59:08.263672   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 07:59:22.595038   904 solver.cpp:229] Iteration 67920, loss = 2.76441
I0605 07:59:22.595079   904 solver.cpp:245]     Train net output #0: loss = 2.95544 (* 1 = 2.95544 loss)
I0605 07:59:22.595088   904 sgd_solver.cpp:106] Iteration 67920, lr = 0.0240188
I0605 07:59:43.099978   904 solver.cpp:229] Iteration 67960, loss = 2.77767
I0605 07:59:43.100175   904 solver.cpp:245]     Train net output #0: loss = 2.77507 (* 1 = 2.77507 loss)
I0605 07:59:43.100196   904 sgd_solver.cpp:106] Iteration 67960, lr = 0.0240094
I0605 08:00:02.930681   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_68000.caffemodel
I0605 08:00:03.200572   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_68000.solverstate
I0605 08:00:03.279192   904 solver.cpp:338] Iteration 68000, Testing net (#0)
I0605 08:00:03.279276   904 net.cpp:748] Ignoring source layer loss
I0605 08:00:30.721293   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 08:01:04.975728   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 08:01:12.158530   904 solver.cpp:406]     Test net output #0: accuracy = 0.405941
I0605 08:01:12.158570   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.660139
I0605 08:01:12.469871   904 solver.cpp:229] Iteration 68000, loss = 2.77619
I0605 08:01:12.469913   904 solver.cpp:245]     Train net output #0: loss = 2.82485 (* 1 = 2.82485 loss)
I0605 08:01:12.469921   904 sgd_solver.cpp:106] Iteration 68000, lr = 0.024
I0605 08:01:31.603620   904 solver.cpp:229] Iteration 68040, loss = 2.80521
I0605 08:01:31.603659   904 solver.cpp:245]     Train net output #0: loss = 3.186 (* 1 = 3.186 loss)
I0605 08:01:31.603668   904 sgd_solver.cpp:106] Iteration 68040, lr = 0.0239906
I0605 08:01:52.928048   904 solver.cpp:229] Iteration 68080, loss = 2.79517
I0605 08:01:52.928328   904 solver.cpp:245]     Train net output #0: loss = 2.98456 (* 1 = 2.98456 loss)
I0605 08:01:52.928356   904 sgd_solver.cpp:106] Iteration 68080, lr = 0.0239812
I0605 08:02:14.342491   904 solver.cpp:229] Iteration 68120, loss = 2.7403
I0605 08:02:14.342548   904 solver.cpp:245]     Train net output #0: loss = 2.62768 (* 1 = 2.62768 loss)
I0605 08:02:14.342560   904 sgd_solver.cpp:106] Iteration 68120, lr = 0.0239718
I0605 08:02:35.174708   904 solver.cpp:229] Iteration 68160, loss = 2.80801
I0605 08:02:35.174862   904 solver.cpp:245]     Train net output #0: loss = 2.84712 (* 1 = 2.84712 loss)
I0605 08:02:35.174873   904 sgd_solver.cpp:106] Iteration 68160, lr = 0.0239624
I0605 08:02:55.948578   904 solver.cpp:229] Iteration 68200, loss = 2.80416
I0605 08:02:55.948632   904 solver.cpp:245]     Train net output #0: loss = 2.9651 (* 1 = 2.9651 loss)
I0605 08:02:55.948639   904 sgd_solver.cpp:106] Iteration 68200, lr = 0.0239529
I0605 08:03:16.834429   904 solver.cpp:229] Iteration 68240, loss = 2.79258
I0605 08:03:16.834640   904 solver.cpp:245]     Train net output #0: loss = 2.88004 (* 1 = 2.88004 loss)
I0605 08:03:16.834666   904 sgd_solver.cpp:106] Iteration 68240, lr = 0.0239435
I0605 08:03:37.722451   904 solver.cpp:229] Iteration 68280, loss = 2.75879
I0605 08:03:37.722494   904 solver.cpp:245]     Train net output #0: loss = 2.80952 (* 1 = 2.80952 loss)
I0605 08:03:37.722503   904 sgd_solver.cpp:106] Iteration 68280, lr = 0.0239341
I0605 08:03:58.451220   904 solver.cpp:229] Iteration 68320, loss = 2.79463
I0605 08:03:58.451429   904 solver.cpp:245]     Train net output #0: loss = 2.74699 (* 1 = 2.74699 loss)
I0605 08:03:58.451452   904 sgd_solver.cpp:106] Iteration 68320, lr = 0.0239247
I0605 08:04:19.170929   904 solver.cpp:229] Iteration 68360, loss = 2.78457
I0605 08:04:19.170974   904 solver.cpp:245]     Train net output #0: loss = 2.70342 (* 1 = 2.70342 loss)
I0605 08:04:19.170984   904 sgd_solver.cpp:106] Iteration 68360, lr = 0.0239153
I0605 08:04:39.631113   904 solver.cpp:229] Iteration 68400, loss = 2.75435
I0605 08:04:39.631294   904 solver.cpp:245]     Train net output #0: loss = 2.73686 (* 1 = 2.73686 loss)
I0605 08:04:39.631301   904 sgd_solver.cpp:106] Iteration 68400, lr = 0.0239059
I0605 08:04:41.923180   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 08:05:00.144248   904 solver.cpp:229] Iteration 68440, loss = 2.75742
I0605 08:05:00.144286   904 solver.cpp:245]     Train net output #0: loss = 2.78534 (* 1 = 2.78534 loss)
I0605 08:05:00.144299   904 sgd_solver.cpp:106] Iteration 68440, lr = 0.0238965
I0605 08:05:20.733114   904 solver.cpp:229] Iteration 68480, loss = 2.79601
I0605 08:05:20.733252   904 solver.cpp:245]     Train net output #0: loss = 2.74881 (* 1 = 2.74881 loss)
I0605 08:05:20.733263   904 sgd_solver.cpp:106] Iteration 68480, lr = 0.0238871
I0605 08:05:41.289418   904 solver.cpp:229] Iteration 68520, loss = 2.70901
I0605 08:05:41.289474   904 solver.cpp:245]     Train net output #0: loss = 2.83788 (* 1 = 2.83788 loss)
I0605 08:05:41.289484   904 sgd_solver.cpp:106] Iteration 68520, lr = 0.0238776
I0605 08:06:01.730062   904 solver.cpp:229] Iteration 68560, loss = 2.7483
I0605 08:06:01.730267   904 solver.cpp:245]     Train net output #0: loss = 2.59458 (* 1 = 2.59458 loss)
I0605 08:06:01.730293   904 sgd_solver.cpp:106] Iteration 68560, lr = 0.0238682
I0605 08:06:22.170197   904 solver.cpp:229] Iteration 68600, loss = 2.75944
I0605 08:06:22.170245   904 solver.cpp:245]     Train net output #0: loss = 2.53607 (* 1 = 2.53607 loss)
I0605 08:06:22.170256   904 sgd_solver.cpp:106] Iteration 68600, lr = 0.0238588
I0605 08:06:42.607879   904 solver.cpp:229] Iteration 68640, loss = 2.76091
I0605 08:06:42.608037   904 solver.cpp:245]     Train net output #0: loss = 2.72065 (* 1 = 2.72065 loss)
I0605 08:06:42.608068   904 sgd_solver.cpp:106] Iteration 68640, lr = 0.0238494
I0605 08:07:03.035830   904 solver.cpp:229] Iteration 68680, loss = 2.78539
I0605 08:07:03.035873   904 solver.cpp:245]     Train net output #0: loss = 3.07092 (* 1 = 3.07092 loss)
I0605 08:07:03.035883   904 sgd_solver.cpp:106] Iteration 68680, lr = 0.02384
I0605 08:07:23.465275   904 solver.cpp:229] Iteration 68720, loss = 2.75771
I0605 08:07:23.465507   904 solver.cpp:245]     Train net output #0: loss = 2.81784 (* 1 = 2.81784 loss)
I0605 08:07:23.465523   904 sgd_solver.cpp:106] Iteration 68720, lr = 0.0238306
I0605 08:07:43.901137   904 solver.cpp:229] Iteration 68760, loss = 2.7681
I0605 08:07:43.901185   904 solver.cpp:245]     Train net output #0: loss = 2.75676 (* 1 = 2.75676 loss)
I0605 08:07:43.901196   904 sgd_solver.cpp:106] Iteration 68760, lr = 0.0238212
I0605 08:08:04.347564   904 solver.cpp:229] Iteration 68800, loss = 2.75372
I0605 08:08:04.347707   904 solver.cpp:245]     Train net output #0: loss = 2.64298 (* 1 = 2.64298 loss)
I0605 08:08:04.347717   904 sgd_solver.cpp:106] Iteration 68800, lr = 0.0238118
I0605 08:08:24.598789   904 solver.cpp:229] Iteration 68840, loss = 2.7367
I0605 08:08:24.598830   904 solver.cpp:245]     Train net output #0: loss = 2.60183 (* 1 = 2.60183 loss)
I0605 08:08:24.598839   904 sgd_solver.cpp:106] Iteration 68840, lr = 0.0238024
I0605 08:08:44.826438   904 solver.cpp:229] Iteration 68880, loss = 2.73729
I0605 08:08:44.826656   904 solver.cpp:245]     Train net output #0: loss = 2.79595 (* 1 = 2.79595 loss)
I0605 08:08:44.826685   904 sgd_solver.cpp:106] Iteration 68880, lr = 0.0237929
I0605 08:08:58.946652   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 08:09:05.234679   904 solver.cpp:229] Iteration 68920, loss = 2.78934
I0605 08:09:05.234745   904 solver.cpp:245]     Train net output #0: loss = 2.76199 (* 1 = 2.76199 loss)
I0605 08:09:05.234752   904 sgd_solver.cpp:106] Iteration 68920, lr = 0.0237835
I0605 08:09:25.453424   904 solver.cpp:229] Iteration 68960, loss = 2.77234
I0605 08:09:25.453636   904 solver.cpp:245]     Train net output #0: loss = 2.92326 (* 1 = 2.92326 loss)
I0605 08:09:25.453672   904 sgd_solver.cpp:106] Iteration 68960, lr = 0.0237741
I0605 08:09:45.161126   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_69000.caffemodel
I0605 08:09:45.423982   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_69000.solverstate
I0605 08:09:45.501823   904 solver.cpp:338] Iteration 69000, Testing net (#0)
I0605 08:09:45.501915   904 net.cpp:748] Ignoring source layer loss
I0605 08:10:14.077083   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 08:10:47.346148   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 08:10:53.228438   904 solver.cpp:406]     Test net output #0: accuracy = 0.407681
I0605 08:10:53.228480   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.661799
I0605 08:10:53.543383   904 solver.cpp:229] Iteration 69000, loss = 2.79287
I0605 08:10:53.543428   904 solver.cpp:245]     Train net output #0: loss = 2.89871 (* 1 = 2.89871 loss)
I0605 08:10:53.543439   904 sgd_solver.cpp:106] Iteration 69000, lr = 0.0237647
I0605 08:11:12.772727   904 solver.cpp:229] Iteration 69040, loss = 2.81424
I0605 08:11:12.772802   904 solver.cpp:245]     Train net output #0: loss = 2.91388 (* 1 = 2.91388 loss)
I0605 08:11:12.772814   904 sgd_solver.cpp:106] Iteration 69040, lr = 0.0237553
I0605 08:11:34.112946   904 solver.cpp:229] Iteration 69080, loss = 2.75462
I0605 08:11:34.113090   904 solver.cpp:245]     Train net output #0: loss = 2.68618 (* 1 = 2.68618 loss)
I0605 08:11:34.113101   904 sgd_solver.cpp:106] Iteration 69080, lr = 0.0237459
I0605 08:11:55.469878   904 solver.cpp:229] Iteration 69120, loss = 2.79611
I0605 08:11:55.469913   904 solver.cpp:245]     Train net output #0: loss = 2.82965 (* 1 = 2.82965 loss)
I0605 08:11:55.469919   904 sgd_solver.cpp:106] Iteration 69120, lr = 0.0237365
I0605 08:12:16.297025   904 solver.cpp:229] Iteration 69160, loss = 2.77407
I0605 08:12:16.297251   904 solver.cpp:245]     Train net output #0: loss = 2.85519 (* 1 = 2.85519 loss)
I0605 08:12:16.297281   904 sgd_solver.cpp:106] Iteration 69160, lr = 0.0237271
I0605 08:12:37.239614   904 solver.cpp:229] Iteration 69200, loss = 2.78551
I0605 08:12:37.239666   904 solver.cpp:245]     Train net output #0: loss = 2.93116 (* 1 = 2.93116 loss)
I0605 08:12:37.239677   904 sgd_solver.cpp:106] Iteration 69200, lr = 0.0237176
I0605 08:12:58.200923   904 solver.cpp:229] Iteration 69240, loss = 2.76101
I0605 08:12:58.201185   904 solver.cpp:245]     Train net output #0: loss = 2.91157 (* 1 = 2.91157 loss)
I0605 08:12:58.201210   904 sgd_solver.cpp:106] Iteration 69240, lr = 0.0237082
I0605 08:13:19.025830   904 solver.cpp:229] Iteration 69280, loss = 2.73652
I0605 08:13:19.025883   904 solver.cpp:245]     Train net output #0: loss = 2.48487 (* 1 = 2.48487 loss)
I0605 08:13:19.025893   904 sgd_solver.cpp:106] Iteration 69280, lr = 0.0236988
I0605 08:13:39.701982   904 solver.cpp:229] Iteration 69320, loss = 2.75442
I0605 08:13:39.702253   904 solver.cpp:245]     Train net output #0: loss = 2.59031 (* 1 = 2.59031 loss)
I0605 08:13:39.702289   904 sgd_solver.cpp:106] Iteration 69320, lr = 0.0236894
I0605 08:14:00.340760   904 solver.cpp:229] Iteration 69360, loss = 2.75299
I0605 08:14:00.340817   904 solver.cpp:245]     Train net output #0: loss = 2.8432 (* 1 = 2.8432 loss)
I0605 08:14:00.340827   904 sgd_solver.cpp:106] Iteration 69360, lr = 0.02368
I0605 08:14:20.842567   904 solver.cpp:229] Iteration 69400, loss = 2.74131
I0605 08:14:20.842720   904 solver.cpp:245]     Train net output #0: loss = 2.89166 (* 1 = 2.89166 loss)
I0605 08:14:20.842732   904 sgd_solver.cpp:106] Iteration 69400, lr = 0.0236706
I0605 08:14:34.649917   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 08:14:41.202394   904 solver.cpp:229] Iteration 69440, loss = 2.75501
I0605 08:14:41.202463   904 solver.cpp:245]     Train net output #0: loss = 2.6933 (* 1 = 2.6933 loss)
I0605 08:14:41.202476   904 sgd_solver.cpp:106] Iteration 69440, lr = 0.0236612
I0605 08:15:01.325328   904 solver.cpp:229] Iteration 69480, loss = 2.755
I0605 08:15:01.325587   904 solver.cpp:245]     Train net output #0: loss = 2.54757 (* 1 = 2.54757 loss)
I0605 08:15:01.325610   904 sgd_solver.cpp:106] Iteration 69480, lr = 0.0236518
I0605 08:15:21.438388   904 solver.cpp:229] Iteration 69520, loss = 2.74157
I0605 08:15:21.438436   904 solver.cpp:245]     Train net output #0: loss = 2.59065 (* 1 = 2.59065 loss)
I0605 08:15:21.438448   904 sgd_solver.cpp:106] Iteration 69520, lr = 0.0236424
I0605 08:15:41.568030   904 solver.cpp:229] Iteration 69560, loss = 2.75077
I0605 08:15:41.568270   904 solver.cpp:245]     Train net output #0: loss = 3.06917 (* 1 = 3.06917 loss)
I0605 08:15:41.568295   904 sgd_solver.cpp:106] Iteration 69560, lr = 0.0236329
I0605 08:16:01.487578   904 solver.cpp:229] Iteration 69600, loss = 2.75055
I0605 08:16:01.487620   904 solver.cpp:245]     Train net output #0: loss = 2.98387 (* 1 = 2.98387 loss)
I0605 08:16:01.487629   904 sgd_solver.cpp:106] Iteration 69600, lr = 0.0236235
I0605 08:16:21.510215   904 solver.cpp:229] Iteration 69640, loss = 2.71715
I0605 08:16:21.510421   904 solver.cpp:245]     Train net output #0: loss = 2.80477 (* 1 = 2.80477 loss)
I0605 08:16:21.510443   904 sgd_solver.cpp:106] Iteration 69640, lr = 0.0236141
I0605 08:16:41.682618   904 solver.cpp:229] Iteration 69680, loss = 2.78875
I0605 08:16:41.682668   904 solver.cpp:245]     Train net output #0: loss = 2.83685 (* 1 = 2.83685 loss)
I0605 08:16:41.682677   904 sgd_solver.cpp:106] Iteration 69680, lr = 0.0236047
I0605 08:17:01.822722   904 solver.cpp:229] Iteration 69720, loss = 2.74306
I0605 08:17:01.822896   904 solver.cpp:245]     Train net output #0: loss = 2.80698 (* 1 = 2.80698 loss)
I0605 08:17:01.822906   904 sgd_solver.cpp:106] Iteration 69720, lr = 0.0235953
I0605 08:17:21.980504   904 solver.cpp:229] Iteration 69760, loss = 2.71551
I0605 08:17:21.980552   904 solver.cpp:245]     Train net output #0: loss = 2.73494 (* 1 = 2.73494 loss)
I0605 08:17:21.980561   904 sgd_solver.cpp:106] Iteration 69760, lr = 0.0235859
I0605 08:17:42.141928   904 solver.cpp:229] Iteration 69800, loss = 2.73397
I0605 08:17:42.142225   904 solver.cpp:245]     Train net output #0: loss = 2.65577 (* 1 = 2.65577 loss)
I0605 08:17:42.142252   904 sgd_solver.cpp:106] Iteration 69800, lr = 0.0235765
I0605 08:18:02.324585   904 solver.cpp:229] Iteration 69840, loss = 2.76963
I0605 08:18:02.324625   904 solver.cpp:245]     Train net output #0: loss = 2.94669 (* 1 = 2.94669 loss)
I0605 08:18:02.324635   904 sgd_solver.cpp:106] Iteration 69840, lr = 0.0235671
I0605 08:18:22.594895   904 solver.cpp:229] Iteration 69880, loss = 2.76213
I0605 08:18:22.595104   904 solver.cpp:245]     Train net output #0: loss = 2.78035 (* 1 = 2.78035 loss)
I0605 08:18:22.595126   904 sgd_solver.cpp:106] Iteration 69880, lr = 0.0235576
I0605 08:18:42.878638   904 solver.cpp:229] Iteration 69920, loss = 2.71926
I0605 08:18:42.878674   904 solver.cpp:245]     Train net output #0: loss = 2.567 (* 1 = 2.567 loss)
I0605 08:18:42.878681   904 sgd_solver.cpp:106] Iteration 69920, lr = 0.0235482
I0605 08:19:03.178469   904 solver.cpp:229] Iteration 69960, loss = 2.73248
I0605 08:19:03.178683   904 solver.cpp:245]     Train net output #0: loss = 2.77047 (* 1 = 2.77047 loss)
I0605 08:19:03.178706   904 sgd_solver.cpp:106] Iteration 69960, lr = 0.0235388
I0605 08:19:04.703235   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 08:19:22.922972   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_70000.caffemodel
I0605 08:19:23.189260   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_70000.solverstate
I0605 08:19:23.270282   904 solver.cpp:338] Iteration 70000, Testing net (#0)
I0605 08:19:23.270373   904 net.cpp:748] Ignoring source layer loss
I0605 08:19:54.396375   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 08:20:29.644966   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 08:20:31.601619   904 solver.cpp:406]     Test net output #0: accuracy = 0.408881
I0605 08:20:31.601727   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.662079
I0605 08:20:31.917443   904 solver.cpp:229] Iteration 70000, loss = 2.79141
I0605 08:20:31.917489   904 solver.cpp:245]     Train net output #0: loss = 2.67135 (* 1 = 2.67135 loss)
I0605 08:20:31.917498   904 sgd_solver.cpp:106] Iteration 70000, lr = 0.0235294
I0605 08:20:51.533296   904 solver.cpp:229] Iteration 70040, loss = 2.78553
I0605 08:20:51.533347   904 solver.cpp:245]     Train net output #0: loss = 2.78414 (* 1 = 2.78414 loss)
I0605 08:20:51.533356   904 sgd_solver.cpp:106] Iteration 70040, lr = 0.02352
I0605 08:21:12.943922   904 solver.cpp:229] Iteration 70080, loss = 2.78943
I0605 08:21:12.944109   904 solver.cpp:245]     Train net output #0: loss = 2.66747 (* 1 = 2.66747 loss)
I0605 08:21:12.944141   904 sgd_solver.cpp:106] Iteration 70080, lr = 0.0235106
I0605 08:21:34.484381   904 solver.cpp:229] Iteration 70120, loss = 2.8004
I0605 08:21:34.484426   904 solver.cpp:245]     Train net output #0: loss = 2.90116 (* 1 = 2.90116 loss)
I0605 08:21:34.484434   904 sgd_solver.cpp:106] Iteration 70120, lr = 0.0235012
I0605 08:21:55.775677   904 solver.cpp:229] Iteration 70160, loss = 2.76495
I0605 08:21:55.775892   904 solver.cpp:245]     Train net output #0: loss = 2.6747 (* 1 = 2.6747 loss)
I0605 08:21:55.775920   904 sgd_solver.cpp:106] Iteration 70160, lr = 0.0234918
I0605 08:22:16.735281   904 solver.cpp:229] Iteration 70200, loss = 2.73896
I0605 08:22:16.735330   904 solver.cpp:245]     Train net output #0: loss = 2.85337 (* 1 = 2.85337 loss)
I0605 08:22:16.735337   904 sgd_solver.cpp:106] Iteration 70200, lr = 0.0234824
I0605 08:22:37.832041   904 solver.cpp:229] Iteration 70240, loss = 2.77897
I0605 08:22:37.832253   904 solver.cpp:245]     Train net output #0: loss = 2.61793 (* 1 = 2.61793 loss)
I0605 08:22:37.832283   904 sgd_solver.cpp:106] Iteration 70240, lr = 0.0234729
I0605 08:22:58.961072   904 solver.cpp:229] Iteration 70280, loss = 2.75072
I0605 08:22:58.961125   904 solver.cpp:245]     Train net output #0: loss = 2.70879 (* 1 = 2.70879 loss)
I0605 08:22:58.961134   904 sgd_solver.cpp:106] Iteration 70280, lr = 0.0234635
I0605 08:23:19.951413   904 solver.cpp:229] Iteration 70320, loss = 2.77005
I0605 08:23:19.951679   904 solver.cpp:245]     Train net output #0: loss = 2.74 (* 1 = 2.74 loss)
I0605 08:23:19.951705   904 sgd_solver.cpp:106] Iteration 70320, lr = 0.0234541
I0605 08:23:40.878651   904 solver.cpp:229] Iteration 70360, loss = 2.79362
I0605 08:23:40.878695   904 solver.cpp:245]     Train net output #0: loss = 2.89018 (* 1 = 2.89018 loss)
I0605 08:23:40.878703   904 sgd_solver.cpp:106] Iteration 70360, lr = 0.0234447
I0605 08:24:01.715292   904 solver.cpp:229] Iteration 70400, loss = 2.73776
I0605 08:24:01.715461   904 solver.cpp:245]     Train net output #0: loss = 2.87237 (* 1 = 2.87237 loss)
I0605 08:24:01.715482   904 sgd_solver.cpp:106] Iteration 70400, lr = 0.0234353
I0605 08:24:22.517956   904 solver.cpp:229] Iteration 70440, loss = 2.73585
I0605 08:24:22.517997   904 solver.cpp:245]     Train net output #0: loss = 2.59883 (* 1 = 2.59883 loss)
I0605 08:24:22.518007   904 sgd_solver.cpp:106] Iteration 70440, lr = 0.0234259
I0605 08:24:43.329923   904 solver.cpp:229] Iteration 70480, loss = 2.76102
I0605 08:24:43.330133   904 solver.cpp:245]     Train net output #0: loss = 2.91434 (* 1 = 2.91434 loss)
I0605 08:24:43.330160   904 sgd_solver.cpp:106] Iteration 70480, lr = 0.0234165
I0605 08:25:04.167459   904 solver.cpp:229] Iteration 70520, loss = 2.77179
I0605 08:25:04.167505   904 solver.cpp:245]     Train net output #0: loss = 2.62922 (* 1 = 2.62922 loss)
I0605 08:25:04.167515   904 sgd_solver.cpp:106] Iteration 70520, lr = 0.0234071
I0605 08:25:15.044878   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 08:25:24.873394   904 solver.cpp:229] Iteration 70560, loss = 2.7997
I0605 08:25:24.873445   904 solver.cpp:245]     Train net output #0: loss = 2.90678 (* 1 = 2.90678 loss)
I0605 08:25:24.873453   904 sgd_solver.cpp:106] Iteration 70560, lr = 0.0233976
I0605 08:25:45.557848   904 solver.cpp:229] Iteration 70600, loss = 2.71697
I0605 08:25:45.558027   904 solver.cpp:245]     Train net output #0: loss = 2.73651 (* 1 = 2.73651 loss)
I0605 08:25:45.558048   904 sgd_solver.cpp:106] Iteration 70600, lr = 0.0233882
I0605 08:26:06.253262   904 solver.cpp:229] Iteration 70640, loss = 2.74834
I0605 08:26:06.253298   904 solver.cpp:245]     Train net output #0: loss = 2.88447 (* 1 = 2.88447 loss)
I0605 08:26:06.253306   904 sgd_solver.cpp:106] Iteration 70640, lr = 0.0233788
I0605 08:26:26.925204   904 solver.cpp:229] Iteration 70680, loss = 2.75368
I0605 08:26:26.925418   904 solver.cpp:245]     Train net output #0: loss = 2.83004 (* 1 = 2.83004 loss)
I0605 08:26:26.925442   904 sgd_solver.cpp:106] Iteration 70680, lr = 0.0233694
I0605 08:26:47.431833   904 solver.cpp:229] Iteration 70720, loss = 2.76982
I0605 08:26:47.431870   904 solver.cpp:245]     Train net output #0: loss = 2.97067 (* 1 = 2.97067 loss)
I0605 08:26:47.431879   904 sgd_solver.cpp:106] Iteration 70720, lr = 0.02336
I0605 08:27:08.027146   904 solver.cpp:229] Iteration 70760, loss = 2.75615
I0605 08:27:08.027348   904 solver.cpp:245]     Train net output #0: loss = 2.66747 (* 1 = 2.66747 loss)
I0605 08:27:08.027369   904 sgd_solver.cpp:106] Iteration 70760, lr = 0.0233506
I0605 08:27:28.605820   904 solver.cpp:229] Iteration 70800, loss = 2.75561
I0605 08:27:28.605870   904 solver.cpp:245]     Train net output #0: loss = 3.07359 (* 1 = 3.07359 loss)
I0605 08:27:28.605880   904 sgd_solver.cpp:106] Iteration 70800, lr = 0.0233412
I0605 08:27:49.131592   904 solver.cpp:229] Iteration 70840, loss = 2.77761
I0605 08:27:49.131822   904 solver.cpp:245]     Train net output #0: loss = 2.58523 (* 1 = 2.58523 loss)
I0605 08:27:49.131846   904 sgd_solver.cpp:106] Iteration 70840, lr = 0.0233318
I0605 08:28:09.665724   904 solver.cpp:229] Iteration 70880, loss = 2.74032
I0605 08:28:09.665793   904 solver.cpp:245]     Train net output #0: loss = 2.82892 (* 1 = 2.82892 loss)
I0605 08:28:09.665817   904 sgd_solver.cpp:106] Iteration 70880, lr = 0.0233224
I0605 08:28:30.184844   904 solver.cpp:229] Iteration 70920, loss = 2.72885
I0605 08:28:30.185174   904 solver.cpp:245]     Train net output #0: loss = 2.86022 (* 1 = 2.86022 loss)
I0605 08:28:30.185201   904 sgd_solver.cpp:106] Iteration 70920, lr = 0.0233129
I0605 08:28:50.701678   904 solver.cpp:229] Iteration 70960, loss = 2.7648
I0605 08:28:50.701731   904 solver.cpp:245]     Train net output #0: loss = 2.4863 (* 1 = 2.4863 loss)
I0605 08:28:50.701740   904 sgd_solver.cpp:106] Iteration 70960, lr = 0.0233035
I0605 08:29:10.696669   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_71000.caffemodel
I0605 08:29:10.962756   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_71000.solverstate
I0605 08:29:11.031390   904 solver.cpp:338] Iteration 71000, Testing net (#0)
I0605 08:29:11.031464   904 net.cpp:748] Ignoring source layer loss
I0605 08:29:17.686420   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 08:29:50.595532   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 08:30:16.507341   904 solver.cpp:406]     Test net output #0: accuracy = 0.413201
I0605 08:30:16.507375   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.667719
I0605 08:30:16.822871   904 solver.cpp:229] Iteration 71000, loss = 2.71171
I0605 08:30:16.822913   904 solver.cpp:245]     Train net output #0: loss = 2.88662 (* 1 = 2.88662 loss)
I0605 08:30:16.822922   904 sgd_solver.cpp:106] Iteration 71000, lr = 0.0232941
I0605 08:30:36.212375   904 solver.cpp:229] Iteration 71040, loss = 2.7565
I0605 08:30:36.212579   904 solver.cpp:245]     Train net output #0: loss = 2.57037 (* 1 = 2.57037 loss)
I0605 08:30:36.212600   904 sgd_solver.cpp:106] Iteration 71040, lr = 0.0232847
I0605 08:30:57.611202   904 solver.cpp:229] Iteration 71080, loss = 2.7127
I0605 08:30:57.611253   904 solver.cpp:245]     Train net output #0: loss = 2.54725 (* 1 = 2.54725 loss)
I0605 08:30:57.611261   904 sgd_solver.cpp:106] Iteration 71080, lr = 0.0232753
I0605 08:31:19.118182   904 solver.cpp:229] Iteration 71120, loss = 2.76095
I0605 08:31:19.118326   904 solver.cpp:245]     Train net output #0: loss = 2.6048 (* 1 = 2.6048 loss)
I0605 08:31:19.118336   904 sgd_solver.cpp:106] Iteration 71120, lr = 0.0232659
I0605 08:31:19.654309   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 08:31:40.288964   904 solver.cpp:229] Iteration 71160, loss = 2.72755
I0605 08:31:40.289007   904 solver.cpp:245]     Train net output #0: loss = 2.63311 (* 1 = 2.63311 loss)
I0605 08:31:40.289014   904 sgd_solver.cpp:106] Iteration 71160, lr = 0.0232565
I0605 08:32:01.258437   904 solver.cpp:229] Iteration 71200, loss = 2.75583
I0605 08:32:01.258596   904 solver.cpp:245]     Train net output #0: loss = 2.76479 (* 1 = 2.76479 loss)
I0605 08:32:01.258616   904 sgd_solver.cpp:106] Iteration 71200, lr = 0.0232471
I0605 08:32:22.212208   904 solver.cpp:229] Iteration 71240, loss = 2.74797
I0605 08:32:22.212261   904 solver.cpp:245]     Train net output #0: loss = 2.68725 (* 1 = 2.68725 loss)
I0605 08:32:22.212271   904 sgd_solver.cpp:106] Iteration 71240, lr = 0.0232376
I0605 08:32:43.179620   904 solver.cpp:229] Iteration 71280, loss = 2.75064
I0605 08:32:43.179811   904 solver.cpp:245]     Train net output #0: loss = 3.12603 (* 1 = 3.12603 loss)
I0605 08:32:43.179841   904 sgd_solver.cpp:106] Iteration 71280, lr = 0.0232282
I0605 08:33:04.069414   904 solver.cpp:229] Iteration 71320, loss = 2.71409
I0605 08:33:04.069468   904 solver.cpp:245]     Train net output #0: loss = 2.73812 (* 1 = 2.73812 loss)
I0605 08:33:04.069478   904 sgd_solver.cpp:106] Iteration 71320, lr = 0.0232188
I0605 08:33:24.877363   904 solver.cpp:229] Iteration 71360, loss = 2.70676
I0605 08:33:24.877569   904 solver.cpp:245]     Train net output #0: loss = 2.77025 (* 1 = 2.77025 loss)
I0605 08:33:24.877598   904 sgd_solver.cpp:106] Iteration 71360, lr = 0.0232094
I0605 08:33:45.586957   904 solver.cpp:229] Iteration 71400, loss = 2.73608
I0605 08:33:45.587007   904 solver.cpp:245]     Train net output #0: loss = 2.5014 (* 1 = 2.5014 loss)
I0605 08:33:45.587015   904 sgd_solver.cpp:106] Iteration 71400, lr = 0.0232
I0605 08:34:06.273476   904 solver.cpp:229] Iteration 71440, loss = 2.7472
I0605 08:34:06.273741   904 solver.cpp:245]     Train net output #0: loss = 2.70396 (* 1 = 2.70396 loss)
I0605 08:34:06.273771   904 sgd_solver.cpp:106] Iteration 71440, lr = 0.0231906
I0605 08:34:26.966644   904 solver.cpp:229] Iteration 71480, loss = 2.75245
I0605 08:34:26.966693   904 solver.cpp:245]     Train net output #0: loss = 2.82825 (* 1 = 2.82825 loss)
I0605 08:34:26.966701   904 sgd_solver.cpp:106] Iteration 71480, lr = 0.0231812
I0605 08:34:47.925899   904 solver.cpp:229] Iteration 71520, loss = 2.79177
I0605 08:34:47.926100   904 solver.cpp:245]     Train net output #0: loss = 2.97476 (* 1 = 2.97476 loss)
I0605 08:34:47.926128   904 sgd_solver.cpp:106] Iteration 71520, lr = 0.0231718
I0605 08:35:08.608142   904 solver.cpp:229] Iteration 71560, loss = 2.75744
I0605 08:35:08.608197   904 solver.cpp:245]     Train net output #0: loss = 2.72939 (* 1 = 2.72939 loss)
I0605 08:35:08.608208   904 sgd_solver.cpp:106] Iteration 71560, lr = 0.0231624
I0605 08:35:29.161011   904 solver.cpp:229] Iteration 71600, loss = 2.74689
I0605 08:35:29.161257   904 solver.cpp:245]     Train net output #0: loss = 2.63598 (* 1 = 2.63598 loss)
I0605 08:35:29.161284   904 sgd_solver.cpp:106] Iteration 71600, lr = 0.0231529
I0605 08:35:49.424654   904 solver.cpp:229] Iteration 71640, loss = 2.7797
I0605 08:35:49.424705   904 solver.cpp:245]     Train net output #0: loss = 2.63598 (* 1 = 2.63598 loss)
I0605 08:35:49.424716   904 sgd_solver.cpp:106] Iteration 71640, lr = 0.0231435
I0605 08:36:09.862972   904 solver.cpp:229] Iteration 71680, loss = 2.75105
I0605 08:36:09.863106   904 solver.cpp:245]     Train net output #0: loss = 2.8014 (* 1 = 2.8014 loss)
I0605 08:36:09.863116   904 sgd_solver.cpp:106] Iteration 71680, lr = 0.0231341
I0605 08:36:28.725816   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 08:36:30.522008   904 solver.cpp:229] Iteration 71720, loss = 2.75818
I0605 08:36:30.522047   904 solver.cpp:245]     Train net output #0: loss = 2.77728 (* 1 = 2.77728 loss)
I0605 08:36:30.522053   904 sgd_solver.cpp:106] Iteration 71720, lr = 0.0231247
I0605 08:36:51.011802   904 solver.cpp:229] Iteration 71760, loss = 2.791
I0605 08:36:51.012013   904 solver.cpp:245]     Train net output #0: loss = 2.59799 (* 1 = 2.59799 loss)
I0605 08:36:51.012043   904 sgd_solver.cpp:106] Iteration 71760, lr = 0.0231153
I0605 08:37:11.345005   904 solver.cpp:229] Iteration 71800, loss = 2.72605
I0605 08:37:11.345048   904 solver.cpp:245]     Train net output #0: loss = 2.61438 (* 1 = 2.61438 loss)
I0605 08:37:11.345059   904 sgd_solver.cpp:106] Iteration 71800, lr = 0.0231059
I0605 08:37:31.605898   904 solver.cpp:229] Iteration 71840, loss = 2.74191
I0605 08:37:31.606050   904 solver.cpp:245]     Train net output #0: loss = 2.91662 (* 1 = 2.91662 loss)
I0605 08:37:31.606060   904 sgd_solver.cpp:106] Iteration 71840, lr = 0.0230965
I0605 08:37:52.085188   904 solver.cpp:229] Iteration 71880, loss = 2.70823
I0605 08:37:52.085229   904 solver.cpp:245]     Train net output #0: loss = 3.0677 (* 1 = 3.0677 loss)
I0605 08:37:52.085237   904 sgd_solver.cpp:106] Iteration 71880, lr = 0.0230871
I0605 08:38:12.331363   904 solver.cpp:229] Iteration 71920, loss = 2.73807
I0605 08:38:12.331579   904 solver.cpp:245]     Train net output #0: loss = 2.72836 (* 1 = 2.72836 loss)
I0605 08:38:12.331609   904 sgd_solver.cpp:106] Iteration 71920, lr = 0.0230776
I0605 08:38:32.822188   904 solver.cpp:229] Iteration 71960, loss = 2.72713
I0605 08:38:32.822235   904 solver.cpp:245]     Train net output #0: loss = 2.61075 (* 1 = 2.61075 loss)
I0605 08:38:32.822244   904 sgd_solver.cpp:106] Iteration 71960, lr = 0.0230682
I0605 08:38:52.601122   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_72000.caffemodel
I0605 08:38:52.868680   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_72000.solverstate
I0605 08:38:52.943239   904 solver.cpp:338] Iteration 72000, Testing net (#0)
I0605 08:38:52.943311   904 net.cpp:748] Ignoring source layer loss
I0605 08:39:08.522527   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 08:39:40.687201   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 08:39:58.372527   904 solver.cpp:406]     Test net output #0: accuracy = 0.406201
I0605 08:39:58.372570   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.6601
I0605 08:39:58.686823   904 solver.cpp:229] Iteration 72000, loss = 2.74178
I0605 08:39:58.686866   904 solver.cpp:245]     Train net output #0: loss = 2.71724 (* 1 = 2.71724 loss)
I0605 08:39:58.686874   904 sgd_solver.cpp:106] Iteration 72000, lr = 0.0230588
I0605 08:40:17.948341   904 solver.cpp:229] Iteration 72040, loss = 2.71534
I0605 08:40:17.948513   904 solver.cpp:245]     Train net output #0: loss = 2.45542 (* 1 = 2.45542 loss)
I0605 08:40:17.948525   904 sgd_solver.cpp:106] Iteration 72040, lr = 0.0230494
I0605 08:40:39.250581   904 solver.cpp:229] Iteration 72080, loss = 2.76024
I0605 08:40:39.250627   904 solver.cpp:245]     Train net output #0: loss = 3.00159 (* 1 = 3.00159 loss)
I0605 08:40:39.250635   904 sgd_solver.cpp:106] Iteration 72080, lr = 0.02304
I0605 08:41:00.721349   904 solver.cpp:229] Iteration 72120, loss = 2.71727
I0605 08:41:00.721488   904 solver.cpp:245]     Train net output #0: loss = 2.60581 (* 1 = 2.60581 loss)
I0605 08:41:00.721498   904 sgd_solver.cpp:106] Iteration 72120, lr = 0.0230306
I0605 08:41:21.853778   904 solver.cpp:229] Iteration 72160, loss = 2.74063
I0605 08:41:21.853817   904 solver.cpp:245]     Train net output #0: loss = 2.76275 (* 1 = 2.76275 loss)
I0605 08:41:21.853826   904 sgd_solver.cpp:106] Iteration 72160, lr = 0.0230212
I0605 08:41:42.882257   904 solver.cpp:229] Iteration 72200, loss = 2.72337
I0605 08:41:42.882436   904 solver.cpp:245]     Train net output #0: loss = 3.0277 (* 1 = 3.0277 loss)
I0605 08:41:42.882463   904 sgd_solver.cpp:106] Iteration 72200, lr = 0.0230118
I0605 08:42:03.926102   904 solver.cpp:229] Iteration 72240, loss = 2.75766
I0605 08:42:03.926151   904 solver.cpp:245]     Train net output #0: loss = 2.7481 (* 1 = 2.7481 loss)
I0605 08:42:03.926170   904 sgd_solver.cpp:106] Iteration 72240, lr = 0.0230024
I0605 08:42:16.327441   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 08:42:24.855888   904 solver.cpp:229] Iteration 72280, loss = 2.71125
I0605 08:42:24.855924   904 solver.cpp:245]     Train net output #0: loss = 2.57854 (* 1 = 2.57854 loss)
I0605 08:42:24.855932   904 sgd_solver.cpp:106] Iteration 72280, lr = 0.0229929
I0605 08:42:45.655740   904 solver.cpp:229] Iteration 72320, loss = 2.75227
I0605 08:42:45.655786   904 solver.cpp:245]     Train net output #0: loss = 2.8227 (* 1 = 2.8227 loss)
I0605 08:42:45.655792   904 sgd_solver.cpp:106] Iteration 72320, lr = 0.0229835
I0605 08:43:06.476752   904 solver.cpp:229] Iteration 72360, loss = 2.75493
I0605 08:43:06.476946   904 solver.cpp:245]     Train net output #0: loss = 3.03007 (* 1 = 3.03007 loss)
I0605 08:43:06.476972   904 sgd_solver.cpp:106] Iteration 72360, lr = 0.0229741
I0605 08:43:27.308521   904 solver.cpp:229] Iteration 72400, loss = 2.70952
I0605 08:43:27.308579   904 solver.cpp:245]     Train net output #0: loss = 2.60561 (* 1 = 2.60561 loss)
I0605 08:43:27.308589   904 sgd_solver.cpp:106] Iteration 72400, lr = 0.0229647
I0605 08:43:48.016572   904 solver.cpp:229] Iteration 72440, loss = 2.72746
I0605 08:43:48.016798   904 solver.cpp:245]     Train net output #0: loss = 2.76809 (* 1 = 2.76809 loss)
I0605 08:43:48.016827   904 sgd_solver.cpp:106] Iteration 72440, lr = 0.0229553
I0605 08:44:08.550662   904 solver.cpp:229] Iteration 72480, loss = 2.72854
I0605 08:44:08.550712   904 solver.cpp:245]     Train net output #0: loss = 2.57027 (* 1 = 2.57027 loss)
I0605 08:44:08.550722   904 sgd_solver.cpp:106] Iteration 72480, lr = 0.0229459
I0605 08:44:29.128945   904 solver.cpp:229] Iteration 72520, loss = 2.7446
I0605 08:44:29.129112   904 solver.cpp:245]     Train net output #0: loss = 2.5724 (* 1 = 2.5724 loss)
I0605 08:44:29.129129   904 sgd_solver.cpp:106] Iteration 72520, lr = 0.0229365
I0605 08:44:49.807196   904 solver.cpp:229] Iteration 72560, loss = 2.73208
I0605 08:44:49.807240   904 solver.cpp:245]     Train net output #0: loss = 2.77404 (* 1 = 2.77404 loss)
I0605 08:44:49.807252   904 sgd_solver.cpp:106] Iteration 72560, lr = 0.0229271
I0605 08:45:10.363739   904 solver.cpp:229] Iteration 72600, loss = 2.78048
I0605 08:45:10.363878   904 solver.cpp:245]     Train net output #0: loss = 2.76587 (* 1 = 2.76587 loss)
I0605 08:45:10.363888   904 sgd_solver.cpp:106] Iteration 72600, lr = 0.0229176
I0605 08:45:30.705250   904 solver.cpp:229] Iteration 72640, loss = 2.73737
I0605 08:45:30.705287   904 solver.cpp:245]     Train net output #0: loss = 2.89119 (* 1 = 2.89119 loss)
I0605 08:45:30.705294   904 sgd_solver.cpp:106] Iteration 72640, lr = 0.0229082
I0605 08:45:51.293325   904 solver.cpp:229] Iteration 72680, loss = 2.75504
I0605 08:45:51.293485   904 solver.cpp:245]     Train net output #0: loss = 2.93735 (* 1 = 2.93735 loss)
I0605 08:45:51.293496   904 sgd_solver.cpp:106] Iteration 72680, lr = 0.0228988
I0605 08:46:12.100363   904 solver.cpp:229] Iteration 72720, loss = 2.76132
I0605 08:46:12.100407   904 solver.cpp:245]     Train net output #0: loss = 2.81055 (* 1 = 2.81055 loss)
I0605 08:46:12.100427   904 sgd_solver.cpp:106] Iteration 72720, lr = 0.0228894
I0605 08:46:32.531872   904 solver.cpp:229] Iteration 72760, loss = 2.77263
I0605 08:46:32.532085   904 solver.cpp:245]     Train net output #0: loss = 2.45895 (* 1 = 2.45895 loss)
I0605 08:46:32.532114   904 sgd_solver.cpp:106] Iteration 72760, lr = 0.02288
I0605 08:46:35.864125   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 08:46:53.058616   904 solver.cpp:229] Iteration 72800, loss = 2.74442
I0605 08:46:53.058658   904 solver.cpp:245]     Train net output #0: loss = 2.64589 (* 1 = 2.64589 loss)
I0605 08:46:53.058666   904 sgd_solver.cpp:106] Iteration 72800, lr = 0.0228706
I0605 08:47:13.586339   904 solver.cpp:229] Iteration 72840, loss = 2.7623
I0605 08:47:13.586467   904 solver.cpp:245]     Train net output #0: loss = 2.58305 (* 1 = 2.58305 loss)
I0605 08:47:13.586482   904 sgd_solver.cpp:106] Iteration 72840, lr = 0.0228612
I0605 08:47:34.114142   904 solver.cpp:229] Iteration 72880, loss = 2.75423
I0605 08:47:34.114203   904 solver.cpp:245]     Train net output #0: loss = 2.81166 (* 1 = 2.81166 loss)
I0605 08:47:34.114217   904 sgd_solver.cpp:106] Iteration 72880, lr = 0.0228518
I0605 08:47:54.679970   904 solver.cpp:229] Iteration 72920, loss = 2.68791
I0605 08:47:54.680168   904 solver.cpp:245]     Train net output #0: loss = 2.47439 (* 1 = 2.47439 loss)
I0605 08:47:54.680196   904 sgd_solver.cpp:106] Iteration 72920, lr = 0.0228424
I0605 08:48:15.230875   904 solver.cpp:229] Iteration 72960, loss = 2.74237
I0605 08:48:15.230922   904 solver.cpp:245]     Train net output #0: loss = 2.9658 (* 1 = 2.9658 loss)
I0605 08:48:15.230931   904 sgd_solver.cpp:106] Iteration 72960, lr = 0.0228329
I0605 08:48:35.250272   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_73000.caffemodel
I0605 08:48:35.519556   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_73000.solverstate
I0605 08:48:35.600553   904 solver.cpp:338] Iteration 73000, Testing net (#0)
I0605 08:48:35.600630   904 net.cpp:748] Ignoring source layer loss
I0605 08:48:53.353358   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 08:49:25.490761   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 08:49:40.433481   904 solver.cpp:406]     Test net output #0: accuracy = 0.405901
I0605 08:49:40.433522   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.660259
I0605 08:49:40.748034   904 solver.cpp:229] Iteration 73000, loss = 2.76724
I0605 08:49:40.748077   904 solver.cpp:245]     Train net output #0: loss = 2.7086 (* 1 = 2.7086 loss)
I0605 08:49:40.748088   904 sgd_solver.cpp:106] Iteration 73000, lr = 0.0228235
I0605 08:50:00.032955   904 solver.cpp:229] Iteration 73040, loss = 2.75487
I0605 08:50:00.033141   904 solver.cpp:245]     Train net output #0: loss = 2.76766 (* 1 = 2.76766 loss)
I0605 08:50:00.033155   904 sgd_solver.cpp:106] Iteration 73040, lr = 0.0228141
I0605 08:50:21.521241   904 solver.cpp:229] Iteration 73080, loss = 2.73944
I0605 08:50:21.521296   904 solver.cpp:245]     Train net output #0: loss = 2.80124 (* 1 = 2.80124 loss)
I0605 08:50:21.521306   904 sgd_solver.cpp:106] Iteration 73080, lr = 0.0228047
I0605 08:50:43.052798   904 solver.cpp:229] Iteration 73120, loss = 2.73019
I0605 08:50:43.053038   904 solver.cpp:245]     Train net output #0: loss = 2.91498 (* 1 = 2.91498 loss)
I0605 08:50:43.053066   904 sgd_solver.cpp:106] Iteration 73120, lr = 0.0227953
I0605 08:51:04.308751   904 solver.cpp:229] Iteration 73160, loss = 2.74924
I0605 08:51:04.308784   904 solver.cpp:245]     Train net output #0: loss = 2.92021 (* 1 = 2.92021 loss)
I0605 08:51:04.308792   904 sgd_solver.cpp:106] Iteration 73160, lr = 0.0227859
I0605 08:51:25.466032   904 solver.cpp:229] Iteration 73200, loss = 2.75342
I0605 08:51:25.466156   904 solver.cpp:245]     Train net output #0: loss = 2.58638 (* 1 = 2.58638 loss)
I0605 08:51:25.466171   904 sgd_solver.cpp:106] Iteration 73200, lr = 0.0227765
I0605 08:51:46.501330   904 solver.cpp:229] Iteration 73240, loss = 2.77635
I0605 08:51:46.501385   904 solver.cpp:245]     Train net output #0: loss = 2.84117 (* 1 = 2.84117 loss)
I0605 08:51:46.501400   904 sgd_solver.cpp:106] Iteration 73240, lr = 0.0227671
I0605 08:52:07.479362   904 solver.cpp:229] Iteration 73280, loss = 2.72769
I0605 08:52:07.479578   904 solver.cpp:245]     Train net output #0: loss = 2.56844 (* 1 = 2.56844 loss)
I0605 08:52:07.479626   904 sgd_solver.cpp:106] Iteration 73280, lr = 0.0227576
I0605 08:52:08.261608   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 08:52:28.449879   904 solver.cpp:229] Iteration 73320, loss = 2.7567
I0605 08:52:28.449924   904 solver.cpp:245]     Train net output #0: loss = 2.87407 (* 1 = 2.87407 loss)
I0605 08:52:28.449934   904 sgd_solver.cpp:106] Iteration 73320, lr = 0.0227482
I0605 08:52:49.431071   904 solver.cpp:229] Iteration 73360, loss = 2.7296
I0605 08:52:49.431211   904 solver.cpp:245]     Train net output #0: loss = 2.57981 (* 1 = 2.57981 loss)
I0605 08:52:49.431224   904 sgd_solver.cpp:106] Iteration 73360, lr = 0.0227388
I0605 08:53:10.378034   904 solver.cpp:229] Iteration 73400, loss = 2.70255
I0605 08:53:10.378090   904 solver.cpp:245]     Train net output #0: loss = 2.70338 (* 1 = 2.70338 loss)
I0605 08:53:10.378101   904 sgd_solver.cpp:106] Iteration 73400, lr = 0.0227294
I0605 08:53:31.097877   904 solver.cpp:229] Iteration 73440, loss = 2.72377
I0605 08:53:31.098070   904 solver.cpp:245]     Train net output #0: loss = 2.80904 (* 1 = 2.80904 loss)
I0605 08:53:31.098098   904 sgd_solver.cpp:106] Iteration 73440, lr = 0.02272
I0605 08:53:51.786185   904 solver.cpp:229] Iteration 73480, loss = 2.72611
I0605 08:53:51.786232   904 solver.cpp:245]     Train net output #0: loss = 2.69373 (* 1 = 2.69373 loss)
I0605 08:53:51.786247   904 sgd_solver.cpp:106] Iteration 73480, lr = 0.0227106
I0605 08:54:12.471000   904 solver.cpp:229] Iteration 73520, loss = 2.68087
I0605 08:54:12.471150   904 solver.cpp:245]     Train net output #0: loss = 2.72943 (* 1 = 2.72943 loss)
I0605 08:54:12.471164   904 sgd_solver.cpp:106] Iteration 73520, lr = 0.0227012
I0605 08:54:33.148057   904 solver.cpp:229] Iteration 73560, loss = 2.71145
I0605 08:54:33.148114   904 solver.cpp:245]     Train net output #0: loss = 2.57633 (* 1 = 2.57633 loss)
I0605 08:54:33.148125   904 sgd_solver.cpp:106] Iteration 73560, lr = 0.0226918
I0605 08:54:53.850721   904 solver.cpp:229] Iteration 73600, loss = 2.70933
I0605 08:54:53.850872   904 solver.cpp:245]     Train net output #0: loss = 2.69833 (* 1 = 2.69833 loss)
I0605 08:54:53.850884   904 sgd_solver.cpp:106] Iteration 73600, lr = 0.0226824
I0605 08:55:14.412771   904 solver.cpp:229] Iteration 73640, loss = 2.68716
I0605 08:55:14.412820   904 solver.cpp:245]     Train net output #0: loss = 2.63567 (* 1 = 2.63567 loss)
I0605 08:55:14.412827   904 sgd_solver.cpp:106] Iteration 73640, lr = 0.0226729
I0605 08:55:34.924134   904 solver.cpp:229] Iteration 73680, loss = 2.7138
I0605 08:55:34.924494   904 solver.cpp:245]     Train net output #0: loss = 2.49231 (* 1 = 2.49231 loss)
I0605 08:55:34.924527   904 sgd_solver.cpp:106] Iteration 73680, lr = 0.0226635
I0605 08:55:55.395912   904 solver.cpp:229] Iteration 73720, loss = 2.72373
I0605 08:55:55.395949   904 solver.cpp:245]     Train net output #0: loss = 2.63536 (* 1 = 2.63536 loss)
I0605 08:55:55.395958   904 sgd_solver.cpp:106] Iteration 73720, lr = 0.0226541
I0605 08:56:15.895509   904 solver.cpp:229] Iteration 73760, loss = 2.7418
I0605 08:56:15.895704   904 solver.cpp:245]     Train net output #0: loss = 3.08527 (* 1 = 3.08527 loss)
I0605 08:56:15.895737   904 sgd_solver.cpp:106] Iteration 73760, lr = 0.0226447
I0605 08:56:28.962062   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 08:56:36.388912   904 solver.cpp:229] Iteration 73800, loss = 2.71841
I0605 08:56:36.388962   904 solver.cpp:245]     Train net output #0: loss = 2.63669 (* 1 = 2.63669 loss)
I0605 08:56:36.388974   904 sgd_solver.cpp:106] Iteration 73800, lr = 0.0226353
I0605 08:56:56.896949   904 solver.cpp:229] Iteration 73840, loss = 2.70814
I0605 08:56:56.897166   904 solver.cpp:245]     Train net output #0: loss = 2.65539 (* 1 = 2.65539 loss)
I0605 08:56:56.897192   904 sgd_solver.cpp:106] Iteration 73840, lr = 0.0226259
I0605 08:57:17.399750   904 solver.cpp:229] Iteration 73880, loss = 2.72546
I0605 08:57:17.399792   904 solver.cpp:245]     Train net output #0: loss = 2.71328 (* 1 = 2.71328 loss)
I0605 08:57:17.399801   904 sgd_solver.cpp:106] Iteration 73880, lr = 0.0226165
I0605 08:57:37.866641   904 solver.cpp:229] Iteration 73920, loss = 2.74301
I0605 08:57:37.866873   904 solver.cpp:245]     Train net output #0: loss = 2.94922 (* 1 = 2.94922 loss)
I0605 08:57:37.866901   904 sgd_solver.cpp:106] Iteration 73920, lr = 0.0226071
I0605 08:57:58.157500   904 solver.cpp:229] Iteration 73960, loss = 2.75848
I0605 08:57:58.157552   904 solver.cpp:245]     Train net output #0: loss = 3.06255 (* 1 = 3.06255 loss)
I0605 08:57:58.157573   904 sgd_solver.cpp:106] Iteration 73960, lr = 0.0225976
I0605 08:58:17.926846   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_74000.caffemodel
I0605 08:58:18.193142   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_74000.solverstate
I0605 08:58:18.270267   904 solver.cpp:338] Iteration 74000, Testing net (#0)
I0605 08:58:18.270359   904 net.cpp:748] Ignoring source layer loss
I0605 08:58:37.589171   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 08:59:11.773880   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 08:59:26.526232   904 solver.cpp:406]     Test net output #0: accuracy = 0.416161
I0605 08:59:26.526275   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.666359
I0605 08:59:26.840641   904 solver.cpp:229] Iteration 74000, loss = 2.73761
I0605 08:59:26.840694   904 solver.cpp:245]     Train net output #0: loss = 2.50202 (* 1 = 2.50202 loss)
I0605 08:59:26.840704   904 sgd_solver.cpp:106] Iteration 74000, lr = 0.0225882
I0605 08:59:46.039850   904 solver.cpp:229] Iteration 74040, loss = 2.73289
I0605 08:59:46.040005   904 solver.cpp:245]     Train net output #0: loss = 2.68253 (* 1 = 2.68253 loss)
I0605 08:59:46.040016   904 sgd_solver.cpp:106] Iteration 74040, lr = 0.0225788
I0605 09:00:07.432893   904 solver.cpp:229] Iteration 74080, loss = 2.72528
I0605 09:00:07.432946   904 solver.cpp:245]     Train net output #0: loss = 2.92871 (* 1 = 2.92871 loss)
I0605 09:00:07.432955   904 sgd_solver.cpp:106] Iteration 74080, lr = 0.0225694
I0605 09:00:28.873009   904 solver.cpp:229] Iteration 74120, loss = 2.77262
I0605 09:00:28.873208   904 solver.cpp:245]     Train net output #0: loss = 2.88118 (* 1 = 2.88118 loss)
I0605 09:00:28.873232   904 sgd_solver.cpp:106] Iteration 74120, lr = 0.02256
I0605 09:00:49.842278   904 solver.cpp:229] Iteration 74160, loss = 2.71502
I0605 09:00:49.842332   904 solver.cpp:245]     Train net output #0: loss = 2.60506 (* 1 = 2.60506 loss)
I0605 09:00:49.842340   904 sgd_solver.cpp:106] Iteration 74160, lr = 0.0225506
I0605 09:01:10.849417   904 solver.cpp:229] Iteration 74200, loss = 2.72528
I0605 09:01:10.849647   904 solver.cpp:245]     Train net output #0: loss = 2.78436 (* 1 = 2.78436 loss)
I0605 09:01:10.849684   904 sgd_solver.cpp:106] Iteration 74200, lr = 0.0225412
I0605 09:01:31.840324   904 solver.cpp:229] Iteration 74240, loss = 2.72696
I0605 09:01:31.840383   904 solver.cpp:245]     Train net output #0: loss = 2.65334 (* 1 = 2.65334 loss)
I0605 09:01:31.840409   904 sgd_solver.cpp:106] Iteration 74240, lr = 0.0225318
I0605 09:01:52.842190   904 solver.cpp:229] Iteration 74280, loss = 2.71403
I0605 09:01:52.842406   904 solver.cpp:245]     Train net output #0: loss = 2.30634 (* 1 = 2.30634 loss)
I0605 09:01:52.842417   904 sgd_solver.cpp:106] Iteration 74280, lr = 0.0225224
I0605 09:01:58.831409   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 09:02:13.640679   904 solver.cpp:229] Iteration 74320, loss = 2.70906
I0605 09:02:13.640735   904 solver.cpp:245]     Train net output #0: loss = 2.69142 (* 1 = 2.69142 loss)
I0605 09:02:13.640744   904 sgd_solver.cpp:106] Iteration 74320, lr = 0.0225129
I0605 09:02:34.337013   904 solver.cpp:229] Iteration 74360, loss = 2.72531
I0605 09:02:34.337224   904 solver.cpp:245]     Train net output #0: loss = 2.60001 (* 1 = 2.60001 loss)
I0605 09:02:34.337251   904 sgd_solver.cpp:106] Iteration 74360, lr = 0.0225035
I0605 09:02:55.013139   904 solver.cpp:229] Iteration 74400, loss = 2.7123
I0605 09:02:55.013185   904 solver.cpp:245]     Train net output #0: loss = 2.54802 (* 1 = 2.54802 loss)
I0605 09:02:55.013197   904 sgd_solver.cpp:106] Iteration 74400, lr = 0.0224941
I0605 09:03:15.665174   904 solver.cpp:229] Iteration 74440, loss = 2.73006
I0605 09:03:15.665334   904 solver.cpp:245]     Train net output #0: loss = 2.6551 (* 1 = 2.6551 loss)
I0605 09:03:15.665361   904 sgd_solver.cpp:106] Iteration 74440, lr = 0.0224847
I0605 09:03:36.337426   904 solver.cpp:229] Iteration 74480, loss = 2.68725
I0605 09:03:36.337466   904 solver.cpp:245]     Train net output #0: loss = 2.75988 (* 1 = 2.75988 loss)
I0605 09:03:36.337474   904 sgd_solver.cpp:106] Iteration 74480, lr = 0.0224753
I0605 09:03:56.826663   904 solver.cpp:229] Iteration 74520, loss = 2.70566
I0605 09:03:56.826922   904 solver.cpp:245]     Train net output #0: loss = 2.43891 (* 1 = 2.43891 loss)
I0605 09:03:56.826951   904 sgd_solver.cpp:106] Iteration 74520, lr = 0.0224659
I0605 09:04:17.222522   904 solver.cpp:229] Iteration 74560, loss = 2.70483
I0605 09:04:17.222584   904 solver.cpp:245]     Train net output #0: loss = 2.77678 (* 1 = 2.77678 loss)
I0605 09:04:17.222594   904 sgd_solver.cpp:106] Iteration 74560, lr = 0.0224565
I0605 09:04:37.454674   904 solver.cpp:229] Iteration 74600, loss = 2.73509
I0605 09:04:37.454896   904 solver.cpp:245]     Train net output #0: loss = 2.49107 (* 1 = 2.49107 loss)
I0605 09:04:37.454918   904 sgd_solver.cpp:106] Iteration 74600, lr = 0.0224471
I0605 09:04:57.576364   904 solver.cpp:229] Iteration 74640, loss = 2.68902
I0605 09:04:57.576418   904 solver.cpp:245]     Train net output #0: loss = 2.90368 (* 1 = 2.90368 loss)
I0605 09:04:57.576429   904 sgd_solver.cpp:106] Iteration 74640, lr = 0.0224376
I0605 09:05:17.632293   904 solver.cpp:229] Iteration 74680, loss = 2.73092
I0605 09:05:17.632490   904 solver.cpp:245]     Train net output #0: loss = 2.42845 (* 1 = 2.42845 loss)
I0605 09:05:17.632500   904 sgd_solver.cpp:106] Iteration 74680, lr = 0.0224282
I0605 09:05:37.576238   904 solver.cpp:229] Iteration 74720, loss = 2.73839
I0605 09:05:37.576282   904 solver.cpp:245]     Train net output #0: loss = 2.80584 (* 1 = 2.80584 loss)
I0605 09:05:37.576292   904 sgd_solver.cpp:106] Iteration 74720, lr = 0.0224188
I0605 09:05:57.433745   904 solver.cpp:229] Iteration 74760, loss = 2.71669
I0605 09:05:57.433992   904 solver.cpp:245]     Train net output #0: loss = 2.66325 (* 1 = 2.66325 loss)
I0605 09:05:57.434017   904 sgd_solver.cpp:106] Iteration 74760, lr = 0.0224094
I0605 09:06:17.324780   904 solver.cpp:229] Iteration 74800, loss = 2.70717
I0605 09:06:17.324836   904 solver.cpp:245]     Train net output #0: loss = 2.84644 (* 1 = 2.84644 loss)
I0605 09:06:17.324846   904 sgd_solver.cpp:106] Iteration 74800, lr = 0.0224
I0605 09:06:32.304435   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 09:06:37.302902   904 solver.cpp:229] Iteration 74840, loss = 2.72643
I0605 09:06:37.302948   904 solver.cpp:245]     Train net output #0: loss = 2.44168 (* 1 = 2.44168 loss)
I0605 09:06:37.302960   904 sgd_solver.cpp:106] Iteration 74840, lr = 0.0223906
I0605 09:06:57.275149   904 solver.cpp:229] Iteration 74880, loss = 2.71111
I0605 09:06:57.275187   904 solver.cpp:245]     Train net output #0: loss = 2.93721 (* 1 = 2.93721 loss)
I0605 09:06:57.275198   904 sgd_solver.cpp:106] Iteration 74880, lr = 0.0223812
I0605 09:07:17.452321   904 solver.cpp:229] Iteration 74920, loss = 2.69577
I0605 09:07:17.452487   904 solver.cpp:245]     Train net output #0: loss = 2.70214 (* 1 = 2.70214 loss)
I0605 09:07:17.452497   904 sgd_solver.cpp:106] Iteration 74920, lr = 0.0223718
I0605 09:07:37.607035   904 solver.cpp:229] Iteration 74960, loss = 2.73871
I0605 09:07:37.607085   904 solver.cpp:245]     Train net output #0: loss = 2.50829 (* 1 = 2.50829 loss)
I0605 09:07:37.607094   904 sgd_solver.cpp:106] Iteration 74960, lr = 0.0223624
I0605 09:07:57.241700   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_75000.caffemodel
I0605 09:07:57.502671   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_75000.solverstate
I0605 09:07:57.579666   904 solver.cpp:338] Iteration 75000, Testing net (#0)
I0605 09:07:57.579722   904 net.cpp:748] Ignoring source layer loss
I0605 09:08:19.181653   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 09:08:51.765774   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 09:09:02.552882   904 solver.cpp:406]     Test net output #0: accuracy = 0.411741
I0605 09:09:02.552924   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.66466
I0605 09:09:02.866120   904 solver.cpp:229] Iteration 75000, loss = 2.7083
I0605 09:09:02.866180   904 solver.cpp:245]     Train net output #0: loss = 2.91215 (* 1 = 2.91215 loss)
I0605 09:09:02.866191   904 sgd_solver.cpp:106] Iteration 75000, lr = 0.0223529
I0605 09:09:22.047441   904 solver.cpp:229] Iteration 75040, loss = 2.70492
I0605 09:09:22.047616   904 solver.cpp:245]     Train net output #0: loss = 2.86985 (* 1 = 2.86985 loss)
I0605 09:09:22.047637   904 sgd_solver.cpp:106] Iteration 75040, lr = 0.0223435
I0605 09:09:43.185437   904 solver.cpp:229] Iteration 75080, loss = 2.75628
I0605 09:09:43.185473   904 solver.cpp:245]     Train net output #0: loss = 2.63958 (* 1 = 2.63958 loss)
I0605 09:09:43.185480   904 sgd_solver.cpp:106] Iteration 75080, lr = 0.0223341
I0605 09:10:04.529134   904 solver.cpp:229] Iteration 75120, loss = 2.74439
I0605 09:10:04.529321   904 solver.cpp:245]     Train net output #0: loss = 2.62402 (* 1 = 2.62402 loss)
I0605 09:10:04.529347   904 sgd_solver.cpp:106] Iteration 75120, lr = 0.0223247
I0605 09:10:25.450840   904 solver.cpp:229] Iteration 75160, loss = 2.71729
I0605 09:10:25.450886   904 solver.cpp:245]     Train net output #0: loss = 2.97235 (* 1 = 2.97235 loss)
I0605 09:10:25.450896   904 sgd_solver.cpp:106] Iteration 75160, lr = 0.0223153
I0605 09:10:46.396482   904 solver.cpp:229] Iteration 75200, loss = 2.71499
I0605 09:10:46.396693   904 solver.cpp:245]     Train net output #0: loss = 2.94093 (* 1 = 2.94093 loss)
I0605 09:10:46.396718   904 sgd_solver.cpp:106] Iteration 75200, lr = 0.0223059
I0605 09:11:07.320318   904 solver.cpp:229] Iteration 75240, loss = 2.72726
I0605 09:11:07.320376   904 solver.cpp:245]     Train net output #0: loss = 2.97172 (* 1 = 2.97172 loss)
I0605 09:11:07.320397   904 sgd_solver.cpp:106] Iteration 75240, lr = 0.0222965
I0605 09:11:28.260643   904 solver.cpp:229] Iteration 75280, loss = 2.71346
I0605 09:11:28.260903   904 solver.cpp:245]     Train net output #0: loss = 2.75666 (* 1 = 2.75666 loss)
I0605 09:11:28.260937   904 sgd_solver.cpp:106] Iteration 75280, lr = 0.0222871
I0605 09:11:49.173449   904 solver.cpp:229] Iteration 75320, loss = 2.74986
I0605 09:11:49.173501   904 solver.cpp:245]     Train net output #0: loss = 2.73841 (* 1 = 2.73841 loss)
I0605 09:11:49.173511   904 sgd_solver.cpp:106] Iteration 75320, lr = 0.0222776
I0605 09:12:10.013808   904 solver.cpp:229] Iteration 75360, loss = 2.72596
I0605 09:12:10.013960   904 solver.cpp:245]     Train net output #0: loss = 2.63928 (* 1 = 2.63928 loss)
I0605 09:12:10.013979   904 sgd_solver.cpp:106] Iteration 75360, lr = 0.0222682
I0605 09:12:30.779208   904 solver.cpp:229] Iteration 75400, loss = 2.7057
I0605 09:12:30.779258   904 solver.cpp:245]     Train net output #0: loss = 2.94143 (* 1 = 2.94143 loss)
I0605 09:12:30.779268   904 sgd_solver.cpp:106] Iteration 75400, lr = 0.0222588
I0605 09:12:31.038488   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 09:12:51.520519   904 solver.cpp:229] Iteration 75440, loss = 2.67207
I0605 09:12:51.520720   904 solver.cpp:245]     Train net output #0: loss = 2.36625 (* 1 = 2.36625 loss)
I0605 09:12:51.520740   904 sgd_solver.cpp:106] Iteration 75440, lr = 0.0222494
I0605 09:13:12.282596   904 solver.cpp:229] Iteration 75480, loss = 2.70646
I0605 09:13:12.282647   904 solver.cpp:245]     Train net output #0: loss = 2.70449 (* 1 = 2.70449 loss)
I0605 09:13:12.282655   904 sgd_solver.cpp:106] Iteration 75480, lr = 0.02224
I0605 09:13:33.022052   904 solver.cpp:229] Iteration 75520, loss = 2.72169
I0605 09:13:33.022261   904 solver.cpp:245]     Train net output #0: loss = 2.58881 (* 1 = 2.58881 loss)
I0605 09:13:33.022289   904 sgd_solver.cpp:106] Iteration 75520, lr = 0.0222306
I0605 09:13:53.648741   904 solver.cpp:229] Iteration 75560, loss = 2.73835
I0605 09:13:53.648787   904 solver.cpp:245]     Train net output #0: loss = 2.62105 (* 1 = 2.62105 loss)
I0605 09:13:53.648794   904 sgd_solver.cpp:106] Iteration 75560, lr = 0.0222212
I0605 09:14:14.264753   904 solver.cpp:229] Iteration 75600, loss = 2.72437
I0605 09:14:14.264947   904 solver.cpp:245]     Train net output #0: loss = 2.71756 (* 1 = 2.71756 loss)
I0605 09:14:14.264971   904 sgd_solver.cpp:106] Iteration 75600, lr = 0.0222118
I0605 09:14:34.890594   904 solver.cpp:229] Iteration 75640, loss = 2.70893
I0605 09:14:34.890635   904 solver.cpp:245]     Train net output #0: loss = 2.73706 (* 1 = 2.73706 loss)
I0605 09:14:34.890643   904 sgd_solver.cpp:106] Iteration 75640, lr = 0.0222024
I0605 09:14:55.514215   904 solver.cpp:229] Iteration 75680, loss = 2.72839
I0605 09:14:55.514403   904 solver.cpp:245]     Train net output #0: loss = 2.64539 (* 1 = 2.64539 loss)
I0605 09:14:55.514427   904 sgd_solver.cpp:106] Iteration 75680, lr = 0.0221929
I0605 09:15:16.123011   904 solver.cpp:229] Iteration 75720, loss = 2.73104
I0605 09:15:16.123065   904 solver.cpp:245]     Train net output #0: loss = 2.66414 (* 1 = 2.66414 loss)
I0605 09:15:16.123086   904 sgd_solver.cpp:106] Iteration 75720, lr = 0.0221835
I0605 09:15:36.745702   904 solver.cpp:229] Iteration 75760, loss = 2.73867
I0605 09:15:36.745892   904 solver.cpp:245]     Train net output #0: loss = 2.75012 (* 1 = 2.75012 loss)
I0605 09:15:36.745916   904 sgd_solver.cpp:106] Iteration 75760, lr = 0.0221741
I0605 09:15:57.363212   904 solver.cpp:229] Iteration 75800, loss = 2.72696
I0605 09:15:57.363251   904 solver.cpp:245]     Train net output #0: loss = 2.66243 (* 1 = 2.66243 loss)
I0605 09:15:57.363260   904 sgd_solver.cpp:106] Iteration 75800, lr = 0.0221647
I0605 09:16:17.986866   904 solver.cpp:229] Iteration 75840, loss = 2.75034
I0605 09:16:17.987093   904 solver.cpp:245]     Train net output #0: loss = 2.55667 (* 1 = 2.55667 loss)
I0605 09:16:17.987120   904 sgd_solver.cpp:106] Iteration 75840, lr = 0.0221553
I0605 09:16:38.455785   904 solver.cpp:229] Iteration 75880, loss = 2.71126
I0605 09:16:38.455827   904 solver.cpp:245]     Train net output #0: loss = 2.72215 (* 1 = 2.72215 loss)
I0605 09:16:38.455837   904 sgd_solver.cpp:106] Iteration 75880, lr = 0.0221459
I0605 09:16:58.950932   904 solver.cpp:229] Iteration 75920, loss = 2.68237
I0605 09:16:58.951294   904 solver.cpp:245]     Train net output #0: loss = 2.5549 (* 1 = 2.5549 loss)
I0605 09:16:58.951306   904 sgd_solver.cpp:106] Iteration 75920, lr = 0.0221365
I0605 09:17:07.458811   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 09:17:19.555335   904 solver.cpp:229] Iteration 75960, loss = 2.74124
I0605 09:17:19.555373   904 solver.cpp:245]     Train net output #0: loss = 2.74717 (* 1 = 2.74717 loss)
I0605 09:17:19.555382   904 sgd_solver.cpp:106] Iteration 75960, lr = 0.0221271
I0605 09:17:39.526842   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_76000.caffemodel
I0605 09:17:39.786773   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_76000.solverstate
I0605 09:17:39.867789   904 solver.cpp:338] Iteration 76000, Testing net (#0)
I0605 09:17:39.867869   904 net.cpp:748] Ignoring source layer loss
I0605 09:18:09.960800   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 09:18:43.462754   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 09:18:47.253371   904 solver.cpp:406]     Test net output #0: accuracy = 0.416541
I0605 09:18:47.253420   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.669539
I0605 09:18:47.567983   904 solver.cpp:229] Iteration 76000, loss = 2.67115
I0605 09:18:47.568025   904 solver.cpp:245]     Train net output #0: loss = 2.69594 (* 1 = 2.69594 loss)
I0605 09:18:47.568034   904 sgd_solver.cpp:106] Iteration 76000, lr = 0.0221176
I0605 09:19:06.835136   904 solver.cpp:229] Iteration 76040, loss = 2.71442
I0605 09:19:06.835186   904 solver.cpp:245]     Train net output #0: loss = 2.70003 (* 1 = 2.70003 loss)
I0605 09:19:06.835194   904 sgd_solver.cpp:106] Iteration 76040, lr = 0.0221082
I0605 09:19:28.358541   904 solver.cpp:229] Iteration 76080, loss = 2.69288
I0605 09:19:28.358677   904 solver.cpp:245]     Train net output #0: loss = 2.61031 (* 1 = 2.61031 loss)
I0605 09:19:28.358690   904 sgd_solver.cpp:106] Iteration 76080, lr = 0.0220988
I0605 09:19:49.894314   904 solver.cpp:229] Iteration 76120, loss = 2.7005
I0605 09:19:49.894366   904 solver.cpp:245]     Train net output #0: loss = 2.45612 (* 1 = 2.45612 loss)
I0605 09:19:49.894374   904 sgd_solver.cpp:106] Iteration 76120, lr = 0.0220894
I0605 09:20:11.170729   904 solver.cpp:229] Iteration 76160, loss = 2.69468
I0605 09:20:11.170936   904 solver.cpp:245]     Train net output #0: loss = 2.78722 (* 1 = 2.78722 loss)
I0605 09:20:11.170974   904 sgd_solver.cpp:106] Iteration 76160, lr = 0.02208
I0605 09:20:32.172546   904 solver.cpp:229] Iteration 76200, loss = 2.72443
I0605 09:20:32.172603   904 solver.cpp:245]     Train net output #0: loss = 2.52242 (* 1 = 2.52242 loss)
I0605 09:20:32.172610   904 sgd_solver.cpp:106] Iteration 76200, lr = 0.0220706
I0605 09:20:53.187089   904 solver.cpp:229] Iteration 76240, loss = 2.71
I0605 09:20:53.187253   904 solver.cpp:245]     Train net output #0: loss = 2.61699 (* 1 = 2.61699 loss)
I0605 09:20:53.187278   904 sgd_solver.cpp:106] Iteration 76240, lr = 0.0220612
I0605 09:21:14.200788   904 solver.cpp:229] Iteration 76280, loss = 2.71079
I0605 09:21:14.200824   904 solver.cpp:245]     Train net output #0: loss = 2.70441 (* 1 = 2.70441 loss)
I0605 09:21:14.200831   904 sgd_solver.cpp:106] Iteration 76280, lr = 0.0220518
I0605 09:21:35.228314   904 solver.cpp:229] Iteration 76320, loss = 2.71379
I0605 09:21:35.228497   904 solver.cpp:245]     Train net output #0: loss = 2.68663 (* 1 = 2.68663 loss)
I0605 09:21:35.228524   904 sgd_solver.cpp:106] Iteration 76320, lr = 0.0220424
I0605 09:21:56.091918   904 solver.cpp:229] Iteration 76360, loss = 2.68822
I0605 09:21:56.091963   904 solver.cpp:245]     Train net output #0: loss = 2.68281 (* 1 = 2.68281 loss)
I0605 09:21:56.091981   904 sgd_solver.cpp:106] Iteration 76360, lr = 0.0220329
I0605 09:22:16.817524   904 solver.cpp:229] Iteration 76400, loss = 2.7186
I0605 09:22:16.817798   904 solver.cpp:245]     Train net output #0: loss = 2.84299 (* 1 = 2.84299 loss)
I0605 09:22:16.817826   904 sgd_solver.cpp:106] Iteration 76400, lr = 0.0220235
I0605 09:22:37.504443   904 solver.cpp:229] Iteration 76440, loss = 2.71353
I0605 09:22:37.504492   904 solver.cpp:245]     Train net output #0: loss = 2.77769 (* 1 = 2.77769 loss)
I0605 09:22:37.504499   904 sgd_solver.cpp:106] Iteration 76440, lr = 0.0220141
I0605 09:22:58.221393   904 solver.cpp:229] Iteration 76480, loss = 2.71999
I0605 09:22:58.221561   904 solver.cpp:245]     Train net output #0: loss = 2.90441 (* 1 = 2.90441 loss)
I0605 09:22:58.221571   904 sgd_solver.cpp:106] Iteration 76480, lr = 0.0220047
I0605 09:23:18.926093   904 solver.cpp:229] Iteration 76520, loss = 2.71977
I0605 09:23:18.926136   904 solver.cpp:245]     Train net output #0: loss = 2.74139 (* 1 = 2.74139 loss)
I0605 09:23:18.926144   904 sgd_solver.cpp:106] Iteration 76520, lr = 0.0219953
I0605 09:23:33.174865   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 09:23:39.600410   904 solver.cpp:229] Iteration 76560, loss = 2.71309
I0605 09:23:39.600457   904 solver.cpp:245]     Train net output #0: loss = 2.97081 (* 1 = 2.97081 loss)
I0605 09:23:39.600466   904 sgd_solver.cpp:106] Iteration 76560, lr = 0.0219859
I0605 09:24:00.132053   904 solver.cpp:229] Iteration 76600, loss = 2.70813
I0605 09:24:00.132117   904 solver.cpp:245]     Train net output #0: loss = 2.74398 (* 1 = 2.74398 loss)
I0605 09:24:00.132138   904 sgd_solver.cpp:106] Iteration 76600, lr = 0.0219765
I0605 09:24:20.655978   904 solver.cpp:229] Iteration 76640, loss = 2.74171
I0605 09:24:20.656105   904 solver.cpp:245]     Train net output #0: loss = 2.58488 (* 1 = 2.58488 loss)
I0605 09:24:20.656114   904 sgd_solver.cpp:106] Iteration 76640, lr = 0.0219671
I0605 09:24:41.191351   904 solver.cpp:229] Iteration 76680, loss = 2.70979
I0605 09:24:41.191411   904 solver.cpp:245]     Train net output #0: loss = 2.94452 (* 1 = 2.94452 loss)
I0605 09:24:41.191419   904 sgd_solver.cpp:106] Iteration 76680, lr = 0.0219576
I0605 09:25:01.712788   904 solver.cpp:229] Iteration 76720, loss = 2.73198
I0605 09:25:01.712909   904 solver.cpp:245]     Train net output #0: loss = 2.79966 (* 1 = 2.79966 loss)
I0605 09:25:01.712916   904 sgd_solver.cpp:106] Iteration 76720, lr = 0.0219482
I0605 09:25:22.216725   904 solver.cpp:229] Iteration 76760, loss = 2.74567
I0605 09:25:22.216775   904 solver.cpp:245]     Train net output #0: loss = 2.70528 (* 1 = 2.70528 loss)
I0605 09:25:22.216784   904 sgd_solver.cpp:106] Iteration 76760, lr = 0.0219388
I0605 09:25:42.732843   904 solver.cpp:229] Iteration 76800, loss = 2.69012
I0605 09:25:42.733052   904 solver.cpp:245]     Train net output #0: loss = 2.72667 (* 1 = 2.72667 loss)
I0605 09:25:42.733078   904 sgd_solver.cpp:106] Iteration 76800, lr = 0.0219294
I0605 09:26:03.219261   904 solver.cpp:229] Iteration 76840, loss = 2.6853
I0605 09:26:03.219315   904 solver.cpp:245]     Train net output #0: loss = 2.52507 (* 1 = 2.52507 loss)
I0605 09:26:03.219323   904 sgd_solver.cpp:106] Iteration 76840, lr = 0.02192
I0605 09:26:23.543491   904 solver.cpp:229] Iteration 76880, loss = 2.65721
I0605 09:26:23.552475   904 solver.cpp:245]     Train net output #0: loss = 2.70669 (* 1 = 2.70669 loss)
I0605 09:26:23.552492   904 sgd_solver.cpp:106] Iteration 76880, lr = 0.0219106
I0605 09:26:43.874011   904 solver.cpp:229] Iteration 76920, loss = 2.70246
I0605 09:26:43.874050   904 solver.cpp:245]     Train net output #0: loss = 2.614 (* 1 = 2.614 loss)
I0605 09:26:43.874058   904 sgd_solver.cpp:106] Iteration 76920, lr = 0.0219012
I0605 09:27:04.190347   904 solver.cpp:229] Iteration 76960, loss = 2.70542
I0605 09:27:04.190534   904 solver.cpp:245]     Train net output #0: loss = 2.77512 (* 1 = 2.77512 loss)
I0605 09:27:04.190560   904 sgd_solver.cpp:106] Iteration 76960, lr = 0.0218918
I0605 09:27:23.971309   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_77000.caffemodel
I0605 09:27:24.240628   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_77000.solverstate
I0605 09:27:24.321189   904 solver.cpp:338] Iteration 77000, Testing net (#0)
I0605 09:27:24.321269   904 net.cpp:748] Ignoring source layer loss
I0605 09:27:31.092525   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 09:28:02.096221   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 09:28:28.489012   904 solver.cpp:406]     Test net output #0: accuracy = 0.420381
I0605 09:28:28.489053   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.67308
I0605 09:28:28.807788   904 solver.cpp:229] Iteration 77000, loss = 2.68862
I0605 09:28:28.807837   904 solver.cpp:245]     Train net output #0: loss = 2.89683 (* 1 = 2.89683 loss)
I0605 09:28:28.807848   904 sgd_solver.cpp:106] Iteration 77000, lr = 0.0218824
I0605 09:28:48.056535   904 solver.cpp:229] Iteration 77040, loss = 2.70716
I0605 09:28:48.056679   904 solver.cpp:245]     Train net output #0: loss = 2.67841 (* 1 = 2.67841 loss)
I0605 09:28:48.056691   904 sgd_solver.cpp:106] Iteration 77040, lr = 0.0218729
I0605 09:29:09.376715   904 solver.cpp:229] Iteration 77080, loss = 2.67774
I0605 09:29:09.376775   904 solver.cpp:245]     Train net output #0: loss = 2.52869 (* 1 = 2.52869 loss)
I0605 09:29:09.376785   904 sgd_solver.cpp:106] Iteration 77080, lr = 0.0218635
I0605 09:29:22.580643   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 09:29:30.871902   904 solver.cpp:229] Iteration 77120, loss = 2.71362
I0605 09:29:30.871960   904 solver.cpp:245]     Train net output #0: loss = 2.7402 (* 1 = 2.7402 loss)
I0605 09:29:30.871969   904 sgd_solver.cpp:106] Iteration 77120, lr = 0.0218541
I0605 09:29:51.956270   904 solver.cpp:229] Iteration 77160, loss = 2.68371
I0605 09:29:51.956320   904 solver.cpp:245]     Train net output #0: loss = 2.50001 (* 1 = 2.50001 loss)
I0605 09:29:51.956327   904 sgd_solver.cpp:106] Iteration 77160, lr = 0.0218447
I0605 09:30:12.936753   904 solver.cpp:229] Iteration 77200, loss = 2.6851
I0605 09:30:12.936959   904 solver.cpp:245]     Train net output #0: loss = 2.64161 (* 1 = 2.64161 loss)
I0605 09:30:12.936980   904 sgd_solver.cpp:106] Iteration 77200, lr = 0.0218353
I0605 09:30:33.921942   904 solver.cpp:229] Iteration 77240, loss = 2.73781
I0605 09:30:33.921989   904 solver.cpp:245]     Train net output #0: loss = 2.77302 (* 1 = 2.77302 loss)
I0605 09:30:33.921998   904 sgd_solver.cpp:106] Iteration 77240, lr = 0.0218259
I0605 09:30:54.862063   904 solver.cpp:229] Iteration 77280, loss = 2.66355
I0605 09:30:54.862274   904 solver.cpp:245]     Train net output #0: loss = 2.81557 (* 1 = 2.81557 loss)
I0605 09:30:54.862301   904 sgd_solver.cpp:106] Iteration 77280, lr = 0.0218165
I0605 09:31:15.659548   904 solver.cpp:229] Iteration 77320, loss = 2.72325
I0605 09:31:15.659597   904 solver.cpp:245]     Train net output #0: loss = 2.83914 (* 1 = 2.83914 loss)
I0605 09:31:15.659606   904 sgd_solver.cpp:106] Iteration 77320, lr = 0.0218071
I0605 09:31:36.475725   904 solver.cpp:229] Iteration 77360, loss = 2.70098
I0605 09:31:36.475922   904 solver.cpp:245]     Train net output #0: loss = 2.50974 (* 1 = 2.50974 loss)
I0605 09:31:36.475950   904 sgd_solver.cpp:106] Iteration 77360, lr = 0.0217976
I0605 09:31:57.129855   904 solver.cpp:229] Iteration 77400, loss = 2.66542
I0605 09:31:57.129897   904 solver.cpp:245]     Train net output #0: loss = 2.61392 (* 1 = 2.61392 loss)
I0605 09:31:57.129906   904 sgd_solver.cpp:106] Iteration 77400, lr = 0.0217882
I0605 09:32:17.802551   904 solver.cpp:229] Iteration 77440, loss = 2.68142
I0605 09:32:17.802705   904 solver.cpp:245]     Train net output #0: loss = 2.87937 (* 1 = 2.87937 loss)
I0605 09:32:17.802716   904 sgd_solver.cpp:106] Iteration 77440, lr = 0.0217788
I0605 09:32:38.329192   904 solver.cpp:229] Iteration 77480, loss = 2.69655
I0605 09:32:38.329246   904 solver.cpp:245]     Train net output #0: loss = 2.69922 (* 1 = 2.69922 loss)
I0605 09:32:38.329255   904 sgd_solver.cpp:106] Iteration 77480, lr = 0.0217694
I0605 09:32:58.920677   904 solver.cpp:229] Iteration 77520, loss = 2.71923
I0605 09:32:58.921025   904 solver.cpp:245]     Train net output #0: loss = 2.58966 (* 1 = 2.58966 loss)
I0605 09:32:58.921051   904 sgd_solver.cpp:106] Iteration 77520, lr = 0.02176
I0605 09:33:19.454589   904 solver.cpp:229] Iteration 77560, loss = 2.67132
I0605 09:33:19.454637   904 solver.cpp:245]     Train net output #0: loss = 2.83652 (* 1 = 2.83652 loss)
I0605 09:33:19.454645   904 sgd_solver.cpp:106] Iteration 77560, lr = 0.0217506
I0605 09:33:39.942976   904 solver.cpp:229] Iteration 77600, loss = 2.72421
I0605 09:33:39.943156   904 solver.cpp:245]     Train net output #0: loss = 2.75439 (* 1 = 2.75439 loss)
I0605 09:33:39.943168   904 sgd_solver.cpp:106] Iteration 77600, lr = 0.0217412
I0605 09:34:00.477815   904 solver.cpp:229] Iteration 77640, loss = 2.69014
I0605 09:34:00.477859   904 solver.cpp:245]     Train net output #0: loss = 2.63442 (* 1 = 2.63442 loss)
I0605 09:34:00.477867   904 sgd_solver.cpp:106] Iteration 77640, lr = 0.0217318
I0605 09:34:03.558887   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 09:34:21.006844   904 solver.cpp:229] Iteration 77680, loss = 2.75006
I0605 09:34:21.006978   904 solver.cpp:245]     Train net output #0: loss = 2.75303 (* 1 = 2.75303 loss)
I0605 09:34:21.006989   904 sgd_solver.cpp:106] Iteration 77680, lr = 0.0217224
I0605 09:34:41.450806   904 solver.cpp:229] Iteration 77720, loss = 2.71122
I0605 09:34:41.450851   904 solver.cpp:245]     Train net output #0: loss = 3.0716 (* 1 = 3.0716 loss)
I0605 09:34:41.450863   904 sgd_solver.cpp:106] Iteration 77720, lr = 0.0217129
I0605 09:35:01.716871   904 solver.cpp:229] Iteration 77760, loss = 2.70848
I0605 09:35:01.717066   904 solver.cpp:245]     Train net output #0: loss = 2.78758 (* 1 = 2.78758 loss)
I0605 09:35:01.717089   904 sgd_solver.cpp:106] Iteration 77760, lr = 0.0217035
I0605 09:35:22.022455   904 solver.cpp:229] Iteration 77800, loss = 2.718
I0605 09:35:22.022500   904 solver.cpp:245]     Train net output #0: loss = 2.69064 (* 1 = 2.69064 loss)
I0605 09:35:22.022510   904 sgd_solver.cpp:106] Iteration 77800, lr = 0.0216941
I0605 09:35:42.275530   904 solver.cpp:229] Iteration 77840, loss = 2.72784
I0605 09:35:42.275744   904 solver.cpp:245]     Train net output #0: loss = 2.69446 (* 1 = 2.69446 loss)
I0605 09:35:42.275769   904 sgd_solver.cpp:106] Iteration 77840, lr = 0.0216847
I0605 09:36:02.585822   904 solver.cpp:229] Iteration 77880, loss = 2.71326
I0605 09:36:02.585878   904 solver.cpp:245]     Train net output #0: loss = 2.42774 (* 1 = 2.42774 loss)
I0605 09:36:02.585901   904 sgd_solver.cpp:106] Iteration 77880, lr = 0.0216753
I0605 09:36:22.864398   904 solver.cpp:229] Iteration 77920, loss = 2.68438
I0605 09:36:22.864614   904 solver.cpp:245]     Train net output #0: loss = 2.61933 (* 1 = 2.61933 loss)
I0605 09:36:22.864639   904 sgd_solver.cpp:106] Iteration 77920, lr = 0.0216659
I0605 09:36:43.174121   904 solver.cpp:229] Iteration 77960, loss = 2.67088
I0605 09:36:43.174160   904 solver.cpp:245]     Train net output #0: loss = 2.64128 (* 1 = 2.64128 loss)
I0605 09:36:43.174167   904 sgd_solver.cpp:106] Iteration 77960, lr = 0.0216565
I0605 09:37:02.942504   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_78000.caffemodel
I0605 09:37:03.213194   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_78000.solverstate
I0605 09:37:03.288228   904 solver.cpp:338] Iteration 78000, Testing net (#0)
I0605 09:37:03.288290   904 net.cpp:748] Ignoring source layer loss
I0605 09:37:14.516079   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 09:37:48.383033   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 09:38:10.920248   904 solver.cpp:406]     Test net output #0: accuracy = 0.417781
I0605 09:38:10.920285   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.670659
I0605 09:38:11.233633   904 solver.cpp:229] Iteration 78000, loss = 2.71877
I0605 09:38:11.233667   904 solver.cpp:245]     Train net output #0: loss = 2.7889 (* 1 = 2.7889 loss)
I0605 09:38:11.233675   904 sgd_solver.cpp:106] Iteration 78000, lr = 0.0216471
I0605 09:38:30.444512   904 solver.cpp:229] Iteration 78040, loss = 2.70446
I0605 09:38:30.444730   904 solver.cpp:245]     Train net output #0: loss = 3.08851 (* 1 = 3.08851 loss)
I0605 09:38:30.444742   904 sgd_solver.cpp:106] Iteration 78040, lr = 0.0216376
I0605 09:38:51.778286   904 solver.cpp:229] Iteration 78080, loss = 2.74783
I0605 09:38:51.778353   904 solver.cpp:245]     Train net output #0: loss = 2.78382 (* 1 = 2.78382 loss)
I0605 09:38:51.778364   904 sgd_solver.cpp:106] Iteration 78080, lr = 0.0216282
I0605 09:39:13.243196   904 solver.cpp:229] Iteration 78120, loss = 2.70583
I0605 09:39:13.243396   904 solver.cpp:245]     Train net output #0: loss = 2.56558 (* 1 = 2.56558 loss)
I0605 09:39:13.243422   904 sgd_solver.cpp:106] Iteration 78120, lr = 0.0216188
I0605 09:39:34.214617   904 solver.cpp:229] Iteration 78160, loss = 2.71836
I0605 09:39:34.214666   904 solver.cpp:245]     Train net output #0: loss = 2.89984 (* 1 = 2.89984 loss)
I0605 09:39:34.214678   904 sgd_solver.cpp:106] Iteration 78160, lr = 0.0216094
I0605 09:39:40.764700   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 09:39:55.177150   904 solver.cpp:229] Iteration 78200, loss = 2.72903
I0605 09:39:55.177337   904 solver.cpp:245]     Train net output #0: loss = 2.81238 (* 1 = 2.81238 loss)
I0605 09:39:55.177374   904 sgd_solver.cpp:106] Iteration 78200, lr = 0.0216
I0605 09:40:16.138952   904 solver.cpp:229] Iteration 78240, loss = 2.74406
I0605 09:40:16.139005   904 solver.cpp:245]     Train net output #0: loss = 2.85916 (* 1 = 2.85916 loss)
I0605 09:40:16.139020   904 sgd_solver.cpp:106] Iteration 78240, lr = 0.0215906
I0605 09:40:37.110230   904 solver.cpp:229] Iteration 78280, loss = 2.69994
I0605 09:40:37.110394   904 solver.cpp:245]     Train net output #0: loss = 2.65256 (* 1 = 2.65256 loss)
I0605 09:40:37.110404   904 sgd_solver.cpp:106] Iteration 78280, lr = 0.0215812
I0605 09:40:58.077258   904 solver.cpp:229] Iteration 78320, loss = 2.73827
I0605 09:40:58.077325   904 solver.cpp:245]     Train net output #0: loss = 2.87887 (* 1 = 2.87887 loss)
I0605 09:40:58.077337   904 sgd_solver.cpp:106] Iteration 78320, lr = 0.0215718
I0605 09:41:18.741129   904 solver.cpp:229] Iteration 78360, loss = 2.69969
I0605 09:41:18.741261   904 solver.cpp:245]     Train net output #0: loss = 2.58222 (* 1 = 2.58222 loss)
I0605 09:41:18.741273   904 sgd_solver.cpp:106] Iteration 78360, lr = 0.0215624
I0605 09:41:39.409991   904 solver.cpp:229] Iteration 78400, loss = 2.65015
I0605 09:41:39.410042   904 solver.cpp:245]     Train net output #0: loss = 2.814 (* 1 = 2.814 loss)
I0605 09:41:39.410053   904 sgd_solver.cpp:106] Iteration 78400, lr = 0.0215529
I0605 09:42:00.191408   904 solver.cpp:229] Iteration 78440, loss = 2.69051
I0605 09:42:00.191599   904 solver.cpp:245]     Train net output #0: loss = 2.72783 (* 1 = 2.72783 loss)
I0605 09:42:00.191627   904 sgd_solver.cpp:106] Iteration 78440, lr = 0.0215435
I0605 09:42:20.964571   904 solver.cpp:229] Iteration 78480, loss = 2.70076
I0605 09:42:20.964614   904 solver.cpp:245]     Train net output #0: loss = 2.53453 (* 1 = 2.53453 loss)
I0605 09:42:20.964623   904 sgd_solver.cpp:106] Iteration 78480, lr = 0.0215341
I0605 09:42:41.595121   904 solver.cpp:229] Iteration 78520, loss = 2.65564
I0605 09:42:41.595340   904 solver.cpp:245]     Train net output #0: loss = 2.74576 (* 1 = 2.74576 loss)
I0605 09:42:41.595367   904 sgd_solver.cpp:106] Iteration 78520, lr = 0.0215247
I0605 09:43:02.258931   904 solver.cpp:229] Iteration 78560, loss = 2.66706
I0605 09:43:02.258972   904 solver.cpp:245]     Train net output #0: loss = 2.6199 (* 1 = 2.6199 loss)
I0605 09:43:02.258981   904 sgd_solver.cpp:106] Iteration 78560, lr = 0.0215153
I0605 09:43:22.927333   904 solver.cpp:229] Iteration 78600, loss = 2.6743
I0605 09:43:22.927532   904 solver.cpp:245]     Train net output #0: loss = 2.75445 (* 1 = 2.75445 loss)
I0605 09:43:22.927542   904 sgd_solver.cpp:106] Iteration 78600, lr = 0.0215059
I0605 09:43:43.567957   904 solver.cpp:229] Iteration 78640, loss = 2.68815
I0605 09:43:43.568006   904 solver.cpp:245]     Train net output #0: loss = 2.74584 (* 1 = 2.74584 loss)
I0605 09:43:43.568017   904 sgd_solver.cpp:106] Iteration 78640, lr = 0.0214965
I0605 09:44:04.037889   904 solver.cpp:229] Iteration 78680, loss = 2.69464
I0605 09:44:04.038102   904 solver.cpp:245]     Train net output #0: loss = 2.7681 (* 1 = 2.7681 loss)
I0605 09:44:04.038130   904 sgd_solver.cpp:106] Iteration 78680, lr = 0.0214871
I0605 09:44:12.238592   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 09:44:24.664196   904 solver.cpp:229] Iteration 78720, loss = 2.69957
I0605 09:44:24.664243   904 solver.cpp:245]     Train net output #0: loss = 2.55163 (* 1 = 2.55163 loss)
I0605 09:44:24.664252   904 sgd_solver.cpp:106] Iteration 78720, lr = 0.0214776
I0605 09:44:45.271690   904 solver.cpp:229] Iteration 78760, loss = 2.68007
I0605 09:44:45.271822   904 solver.cpp:245]     Train net output #0: loss = 2.72124 (* 1 = 2.72124 loss)
I0605 09:44:45.271832   904 sgd_solver.cpp:106] Iteration 78760, lr = 0.0214682
I0605 09:45:05.751086   904 solver.cpp:229] Iteration 78800, loss = 2.69869
I0605 09:45:05.751126   904 solver.cpp:245]     Train net output #0: loss = 2.87091 (* 1 = 2.87091 loss)
I0605 09:45:05.751134   904 sgd_solver.cpp:106] Iteration 78800, lr = 0.0214588
I0605 09:45:26.192574   904 solver.cpp:229] Iteration 78840, loss = 2.68294
I0605 09:45:26.192754   904 solver.cpp:245]     Train net output #0: loss = 2.55259 (* 1 = 2.55259 loss)
I0605 09:45:26.192780   904 sgd_solver.cpp:106] Iteration 78840, lr = 0.0214494
I0605 09:45:46.679743   904 solver.cpp:229] Iteration 78880, loss = 2.65964
I0605 09:45:46.679797   904 solver.cpp:245]     Train net output #0: loss = 2.77053 (* 1 = 2.77053 loss)
I0605 09:45:46.679811   904 sgd_solver.cpp:106] Iteration 78880, lr = 0.02144
I0605 09:46:07.152333   904 solver.cpp:229] Iteration 78920, loss = 2.72122
I0605 09:46:07.152506   904 solver.cpp:245]     Train net output #0: loss = 2.66868 (* 1 = 2.66868 loss)
I0605 09:46:07.152518   904 sgd_solver.cpp:106] Iteration 78920, lr = 0.0214306
I0605 09:46:27.623052   904 solver.cpp:229] Iteration 78960, loss = 2.73497
I0605 09:46:27.623096   904 solver.cpp:245]     Train net output #0: loss = 2.8901 (* 1 = 2.8901 loss)
I0605 09:46:27.623106   904 sgd_solver.cpp:106] Iteration 78960, lr = 0.0214212
I0605 09:46:47.602280   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_79000.caffemodel
I0605 09:46:47.870658   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_79000.solverstate
I0605 09:46:47.951664   904 solver.cpp:338] Iteration 79000, Testing net (#0)
I0605 09:46:47.951769   904 net.cpp:748] Ignoring source layer loss
I0605 09:47:01.132593   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 09:47:34.497264   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 09:47:54.292901   904 solver.cpp:406]     Test net output #0: accuracy = 0.410321
I0605 09:47:54.292935   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.662039
I0605 09:47:54.606664   904 solver.cpp:229] Iteration 79000, loss = 2.71875
I0605 09:47:54.606714   904 solver.cpp:245]     Train net output #0: loss = 3.04944 (* 1 = 3.04944 loss)
I0605 09:47:54.606725   904 sgd_solver.cpp:106] Iteration 79000, lr = 0.0214118
I0605 09:48:13.826026   904 solver.cpp:229] Iteration 79040, loss = 2.71336
I0605 09:48:13.826213   904 solver.cpp:245]     Train net output #0: loss = 2.60816 (* 1 = 2.60816 loss)
I0605 09:48:13.826241   904 sgd_solver.cpp:106] Iteration 79040, lr = 0.0214024
I0605 09:48:35.217363   904 solver.cpp:229] Iteration 79080, loss = 2.66681
I0605 09:48:35.217402   904 solver.cpp:245]     Train net output #0: loss = 2.73433 (* 1 = 2.73433 loss)
I0605 09:48:35.217411   904 sgd_solver.cpp:106] Iteration 79080, lr = 0.0213929
I0605 09:48:56.749666   904 solver.cpp:229] Iteration 79120, loss = 2.70762
I0605 09:48:56.749994   904 solver.cpp:245]     Train net output #0: loss = 2.77759 (* 1 = 2.77759 loss)
I0605 09:48:56.750041   904 sgd_solver.cpp:106] Iteration 79120, lr = 0.0213835
I0605 09:49:18.044131   904 solver.cpp:229] Iteration 79160, loss = 2.67804
I0605 09:49:18.044169   904 solver.cpp:245]     Train net output #0: loss = 2.59623 (* 1 = 2.59623 loss)
I0605 09:49:18.044178   904 sgd_solver.cpp:106] Iteration 79160, lr = 0.0213741
I0605 09:49:39.014556   904 solver.cpp:229] Iteration 79200, loss = 2.70694
I0605 09:49:39.014767   904 solver.cpp:245]     Train net output #0: loss = 2.48663 (* 1 = 2.48663 loss)
I0605 09:49:39.014793   904 sgd_solver.cpp:106] Iteration 79200, lr = 0.0213647
I0605 09:49:41.371104   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 09:49:59.993001   904 solver.cpp:229] Iteration 79240, loss = 2.69346
I0605 09:49:59.993049   904 solver.cpp:245]     Train net output #0: loss = 2.36893 (* 1 = 2.36893 loss)
I0605 09:49:59.993060   904 sgd_solver.cpp:106] Iteration 79240, lr = 0.0213553
I0605 09:50:20.958168   904 solver.cpp:229] Iteration 79280, loss = 2.69225
I0605 09:50:20.958369   904 solver.cpp:245]     Train net output #0: loss = 2.57442 (* 1 = 2.57442 loss)
I0605 09:50:20.958397   904 sgd_solver.cpp:106] Iteration 79280, lr = 0.0213459
I0605 09:50:42.021122   904 solver.cpp:229] Iteration 79320, loss = 2.64181
I0605 09:50:42.021169   904 solver.cpp:245]     Train net output #0: loss = 2.40515 (* 1 = 2.40515 loss)
I0605 09:50:42.021180   904 sgd_solver.cpp:106] Iteration 79320, lr = 0.0213365
I0605 09:51:02.773519   904 solver.cpp:229] Iteration 79360, loss = 2.73598
I0605 09:51:02.773674   904 solver.cpp:245]     Train net output #0: loss = 2.57146 (* 1 = 2.57146 loss)
I0605 09:51:02.773701   904 sgd_solver.cpp:106] Iteration 79360, lr = 0.0213271
I0605 09:51:23.419936   904 solver.cpp:229] Iteration 79400, loss = 2.67928
I0605 09:51:23.419976   904 solver.cpp:245]     Train net output #0: loss = 2.79376 (* 1 = 2.79376 loss)
I0605 09:51:23.419986   904 sgd_solver.cpp:106] Iteration 79400, lr = 0.0213176
I0605 09:51:44.085043   904 solver.cpp:229] Iteration 79440, loss = 2.69512
I0605 09:51:44.085194   904 solver.cpp:245]     Train net output #0: loss = 2.86955 (* 1 = 2.86955 loss)
I0605 09:51:44.085203   904 sgd_solver.cpp:106] Iteration 79440, lr = 0.0213082
I0605 09:52:04.753224   904 solver.cpp:229] Iteration 79480, loss = 2.68214
I0605 09:52:04.753291   904 solver.cpp:245]     Train net output #0: loss = 2.47373 (* 1 = 2.47373 loss)
I0605 09:52:04.753301   904 sgd_solver.cpp:106] Iteration 79480, lr = 0.0212988
I0605 09:52:25.422425   904 solver.cpp:229] Iteration 79520, loss = 2.69189
I0605 09:52:25.422547   904 solver.cpp:245]     Train net output #0: loss = 2.78103 (* 1 = 2.78103 loss)
I0605 09:52:25.422556   904 sgd_solver.cpp:106] Iteration 79520, lr = 0.0212894
I0605 09:52:45.991972   904 solver.cpp:229] Iteration 79560, loss = 2.66965
I0605 09:52:45.992022   904 solver.cpp:245]     Train net output #0: loss = 2.70132 (* 1 = 2.70132 loss)
I0605 09:52:45.992030   904 sgd_solver.cpp:106] Iteration 79560, lr = 0.02128
I0605 09:53:06.471711   904 solver.cpp:229] Iteration 79600, loss = 2.71477
I0605 09:53:06.471848   904 solver.cpp:245]     Train net output #0: loss = 2.58499 (* 1 = 2.58499 loss)
I0605 09:53:06.471858   904 sgd_solver.cpp:106] Iteration 79600, lr = 0.0212706
I0605 09:53:26.962227   904 solver.cpp:229] Iteration 79640, loss = 2.65806
I0605 09:53:26.962280   904 solver.cpp:245]     Train net output #0: loss = 2.40805 (* 1 = 2.40805 loss)
I0605 09:53:26.962286   904 sgd_solver.cpp:106] Iteration 79640, lr = 0.0212612
I0605 09:53:47.428557   904 solver.cpp:229] Iteration 79680, loss = 2.6506
I0605 09:53:47.428725   904 solver.cpp:245]     Train net output #0: loss = 2.45303 (* 1 = 2.45303 loss)
I0605 09:53:47.428750   904 sgd_solver.cpp:106] Iteration 79680, lr = 0.0212518
I0605 09:54:02.027830   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 09:54:07.915810   904 solver.cpp:229] Iteration 79720, loss = 2.66473
I0605 09:54:07.915860   904 solver.cpp:245]     Train net output #0: loss = 2.77511 (* 1 = 2.77511 loss)
I0605 09:54:07.915868   904 sgd_solver.cpp:106] Iteration 79720, lr = 0.0212424
I0605 09:54:28.390123   904 solver.cpp:229] Iteration 79760, loss = 2.70329
I0605 09:54:28.390333   904 solver.cpp:245]     Train net output #0: loss = 2.76957 (* 1 = 2.76957 loss)
I0605 09:54:28.390348   904 sgd_solver.cpp:106] Iteration 79760, lr = 0.0212329
I0605 09:54:48.869472   904 solver.cpp:229] Iteration 79800, loss = 2.67863
I0605 09:54:48.869521   904 solver.cpp:245]     Train net output #0: loss = 2.37714 (* 1 = 2.37714 loss)
I0605 09:54:48.869531   904 sgd_solver.cpp:106] Iteration 79800, lr = 0.0212235
I0605 09:55:09.360762   904 solver.cpp:229] Iteration 79840, loss = 2.7067
I0605 09:55:09.360878   904 solver.cpp:245]     Train net output #0: loss = 2.68602 (* 1 = 2.68602 loss)
I0605 09:55:09.360890   904 sgd_solver.cpp:106] Iteration 79840, lr = 0.0212141
I0605 09:55:29.676583   904 solver.cpp:229] Iteration 79880, loss = 2.67787
I0605 09:55:29.676630   904 solver.cpp:245]     Train net output #0: loss = 2.68838 (* 1 = 2.68838 loss)
I0605 09:55:29.676645   904 sgd_solver.cpp:106] Iteration 79880, lr = 0.0212047
I0605 09:55:49.960163   904 solver.cpp:229] Iteration 79920, loss = 2.68486
I0605 09:55:49.960350   904 solver.cpp:245]     Train net output #0: loss = 2.67736 (* 1 = 2.67736 loss)
I0605 09:55:49.960391   904 sgd_solver.cpp:106] Iteration 79920, lr = 0.0211953
I0605 09:56:10.227085   904 solver.cpp:229] Iteration 79960, loss = 2.67313
I0605 09:56:10.227125   904 solver.cpp:245]     Train net output #0: loss = 2.54155 (* 1 = 2.54155 loss)
I0605 09:56:10.227134   904 sgd_solver.cpp:106] Iteration 79960, lr = 0.0211859
I0605 09:56:30.015669   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_80000.caffemodel
I0605 09:56:30.283771   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_80000.solverstate
I0605 09:56:30.363008   904 solver.cpp:338] Iteration 80000, Testing net (#0)
I0605 09:56:30.363093   904 net.cpp:748] Ignoring source layer loss
I0605 09:56:44.288774   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 09:57:16.813563   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 09:57:36.096921   904 solver.cpp:406]     Test net output #0: accuracy = 0.418361
I0605 09:57:36.096969   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.66976
I0605 09:57:36.413676   904 solver.cpp:229] Iteration 80000, loss = 2.67606
I0605 09:57:36.413720   904 solver.cpp:245]     Train net output #0: loss = 2.47448 (* 1 = 2.47448 loss)
I0605 09:57:36.413730   904 sgd_solver.cpp:106] Iteration 80000, lr = 0.0211765
I0605 09:57:55.560309   904 solver.cpp:229] Iteration 80040, loss = 2.69343
I0605 09:57:55.560472   904 solver.cpp:245]     Train net output #0: loss = 2.38769 (* 1 = 2.38769 loss)
I0605 09:57:55.560483   904 sgd_solver.cpp:106] Iteration 80040, lr = 0.0211671
I0605 09:58:16.742326   904 solver.cpp:229] Iteration 80080, loss = 2.72184
I0605 09:58:16.742386   904 solver.cpp:245]     Train net output #0: loss = 2.86613 (* 1 = 2.86613 loss)
I0605 09:58:16.742396   904 sgd_solver.cpp:106] Iteration 80080, lr = 0.0211576
I0605 09:58:38.093065   904 solver.cpp:229] Iteration 80120, loss = 2.70122
I0605 09:58:38.093266   904 solver.cpp:245]     Train net output #0: loss = 2.68438 (* 1 = 2.68438 loss)
I0605 09:58:38.093291   904 sgd_solver.cpp:106] Iteration 80120, lr = 0.0211482
I0605 09:58:59.129376   904 solver.cpp:229] Iteration 80160, loss = 2.67504
I0605 09:58:59.129428   904 solver.cpp:245]     Train net output #0: loss = 2.66108 (* 1 = 2.66108 loss)
I0605 09:58:59.129437   904 sgd_solver.cpp:106] Iteration 80160, lr = 0.0211388
I0605 09:59:20.535151   904 solver.cpp:229] Iteration 80200, loss = 2.68616
I0605 09:59:20.535337   904 solver.cpp:245]     Train net output #0: loss = 2.6636 (* 1 = 2.6636 loss)
I0605 09:59:20.535367   904 sgd_solver.cpp:106] Iteration 80200, lr = 0.0211294
I0605 09:59:29.668730   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 09:59:41.413707   904 solver.cpp:229] Iteration 80240, loss = 2.68813
I0605 09:59:41.413759   904 solver.cpp:245]     Train net output #0: loss = 2.99137 (* 1 = 2.99137 loss)
I0605 09:59:41.413770   904 sgd_solver.cpp:106] Iteration 80240, lr = 0.02112
I0605 10:00:02.312255   904 solver.cpp:229] Iteration 80280, loss = 2.70821
I0605 10:00:02.312468   904 solver.cpp:245]     Train net output #0: loss = 2.67872 (* 1 = 2.67872 loss)
I0605 10:00:02.312481   904 sgd_solver.cpp:106] Iteration 80280, lr = 0.0211106
I0605 10:00:23.119213   904 solver.cpp:229] Iteration 80320, loss = 2.68611
I0605 10:00:23.119259   904 solver.cpp:245]     Train net output #0: loss = 2.56568 (* 1 = 2.56568 loss)
I0605 10:00:23.119271   904 sgd_solver.cpp:106] Iteration 80320, lr = 0.0211012
I0605 10:00:43.756371   904 solver.cpp:229] Iteration 80360, loss = 2.71927
I0605 10:00:43.756575   904 solver.cpp:245]     Train net output #0: loss = 2.85557 (* 1 = 2.85557 loss)
I0605 10:00:43.756598   904 sgd_solver.cpp:106] Iteration 80360, lr = 0.0210918
I0605 10:01:04.358160   904 solver.cpp:229] Iteration 80400, loss = 2.67547
I0605 10:01:04.358199   904 solver.cpp:245]     Train net output #0: loss = 2.6589 (* 1 = 2.6589 loss)
I0605 10:01:04.358208   904 sgd_solver.cpp:106] Iteration 80400, lr = 0.0210824
I0605 10:01:24.947715   904 solver.cpp:229] Iteration 80440, loss = 2.64494
I0605 10:01:24.947835   904 solver.cpp:245]     Train net output #0: loss = 2.62949 (* 1 = 2.62949 loss)
I0605 10:01:24.947849   904 sgd_solver.cpp:106] Iteration 80440, lr = 0.0210729
I0605 10:01:45.453542   904 solver.cpp:229] Iteration 80480, loss = 2.68846
I0605 10:01:45.453595   904 solver.cpp:245]     Train net output #0: loss = 2.75826 (* 1 = 2.75826 loss)
I0605 10:01:45.453608   904 sgd_solver.cpp:106] Iteration 80480, lr = 0.0210635
I0605 10:02:05.858634   904 solver.cpp:229] Iteration 80520, loss = 2.69323
I0605 10:02:05.858806   904 solver.cpp:245]     Train net output #0: loss = 2.66939 (* 1 = 2.66939 loss)
I0605 10:02:05.858832   904 sgd_solver.cpp:106] Iteration 80520, lr = 0.0210541
I0605 10:02:26.277667   904 solver.cpp:229] Iteration 80560, loss = 2.71929
I0605 10:02:26.277707   904 solver.cpp:245]     Train net output #0: loss = 2.78902 (* 1 = 2.78902 loss)
I0605 10:02:26.277717   904 sgd_solver.cpp:106] Iteration 80560, lr = 0.0210447
I0605 10:02:46.847280   904 solver.cpp:229] Iteration 80600, loss = 2.68109
I0605 10:02:46.847409   904 solver.cpp:245]     Train net output #0: loss = 2.8655 (* 1 = 2.8655 loss)
I0605 10:02:46.847417   904 sgd_solver.cpp:106] Iteration 80600, lr = 0.0210353
I0605 10:03:07.274960   904 solver.cpp:229] Iteration 80640, loss = 2.67854
I0605 10:03:07.274992   904 solver.cpp:245]     Train net output #0: loss = 2.58861 (* 1 = 2.58861 loss)
I0605 10:03:07.274999   904 sgd_solver.cpp:106] Iteration 80640, lr = 0.0210259
I0605 10:03:27.564826   904 solver.cpp:229] Iteration 80680, loss = 2.69799
I0605 10:03:27.565032   904 solver.cpp:245]     Train net output #0: loss = 2.6359 (* 1 = 2.6359 loss)
I0605 10:03:27.565058   904 sgd_solver.cpp:106] Iteration 80680, lr = 0.0210165
I0605 10:03:47.784521   904 solver.cpp:229] Iteration 80720, loss = 2.70008
I0605 10:03:47.784579   904 solver.cpp:245]     Train net output #0: loss = 2.75214 (* 1 = 2.75214 loss)
I0605 10:03:47.784590   904 sgd_solver.cpp:106] Iteration 80720, lr = 0.0210071
I0605 10:03:50.566401   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 10:04:08.098840   904 solver.cpp:229] Iteration 80760, loss = 2.66287
I0605 10:04:08.099043   904 solver.cpp:245]     Train net output #0: loss = 2.70224 (* 1 = 2.70224 loss)
I0605 10:04:08.099071   904 sgd_solver.cpp:106] Iteration 80760, lr = 0.0209976
I0605 10:04:28.504282   904 solver.cpp:229] Iteration 80800, loss = 2.68514
I0605 10:04:28.504323   904 solver.cpp:245]     Train net output #0: loss = 2.68663 (* 1 = 2.68663 loss)
I0605 10:04:28.504331   904 sgd_solver.cpp:106] Iteration 80800, lr = 0.0209882
I0605 10:04:48.882521   904 solver.cpp:229] Iteration 80840, loss = 2.69615
I0605 10:04:48.882776   904 solver.cpp:245]     Train net output #0: loss = 2.63942 (* 1 = 2.63942 loss)
I0605 10:04:48.882802   904 sgd_solver.cpp:106] Iteration 80840, lr = 0.0209788
I0605 10:05:09.291646   904 solver.cpp:229] Iteration 80880, loss = 2.6826
I0605 10:05:09.291687   904 solver.cpp:245]     Train net output #0: loss = 2.85258 (* 1 = 2.85258 loss)
I0605 10:05:09.291702   904 sgd_solver.cpp:106] Iteration 80880, lr = 0.0209694
I0605 10:05:29.607746   904 solver.cpp:229] Iteration 80920, loss = 2.66795
I0605 10:05:29.607976   904 solver.cpp:245]     Train net output #0: loss = 2.53488 (* 1 = 2.53488 loss)
I0605 10:05:29.608002   904 sgd_solver.cpp:106] Iteration 80920, lr = 0.02096
I0605 10:05:49.764612   904 solver.cpp:229] Iteration 80960, loss = 2.68481
I0605 10:05:49.764657   904 solver.cpp:245]     Train net output #0: loss = 2.78353 (* 1 = 2.78353 loss)
I0605 10:05:49.764667   904 sgd_solver.cpp:106] Iteration 80960, lr = 0.0209506
I0605 10:06:09.482615   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_81000.caffemodel
I0605 10:06:09.744491   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_81000.solverstate
I0605 10:06:09.817348   904 solver.cpp:338] Iteration 81000, Testing net (#0)
I0605 10:06:09.817440   904 net.cpp:748] Ignoring source layer loss
I0605 10:06:25.293709   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 10:06:58.749459   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 10:07:16.497753   904 solver.cpp:406]     Test net output #0: accuracy = 0.427041
I0605 10:07:16.497797   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.679278
I0605 10:07:16.813315   904 solver.cpp:229] Iteration 81000, loss = 2.6492
I0605 10:07:16.813362   904 solver.cpp:245]     Train net output #0: loss = 2.47549 (* 1 = 2.47549 loss)
I0605 10:07:16.813374   904 sgd_solver.cpp:106] Iteration 81000, lr = 0.0209412
I0605 10:07:36.027572   904 solver.cpp:229] Iteration 81040, loss = 2.66625
I0605 10:07:36.027883   904 solver.cpp:245]     Train net output #0: loss = 2.76819 (* 1 = 2.76819 loss)
I0605 10:07:36.027914   904 sgd_solver.cpp:106] Iteration 81040, lr = 0.0209318
I0605 10:07:56.964926   904 solver.cpp:229] Iteration 81080, loss = 2.64891
I0605 10:07:56.964974   904 solver.cpp:245]     Train net output #0: loss = 2.8673 (* 1 = 2.8673 loss)
I0605 10:07:56.964983   904 sgd_solver.cpp:106] Iteration 81080, lr = 0.0209224
I0605 10:08:17.792004   904 solver.cpp:229] Iteration 81120, loss = 2.69718
I0605 10:08:17.792234   904 solver.cpp:245]     Train net output #0: loss = 2.72035 (* 1 = 2.72035 loss)
I0605 10:08:17.792265   904 sgd_solver.cpp:106] Iteration 81120, lr = 0.0209129
I0605 10:08:38.458302   904 solver.cpp:229] Iteration 81160, loss = 2.65357
I0605 10:08:38.458346   904 solver.cpp:245]     Train net output #0: loss = 2.73277 (* 1 = 2.73277 loss)
I0605 10:08:38.458354   904 sgd_solver.cpp:106] Iteration 81160, lr = 0.0209035
I0605 10:08:59.058459   904 solver.cpp:229] Iteration 81200, loss = 2.6885
I0605 10:08:59.058653   904 solver.cpp:245]     Train net output #0: loss = 2.58154 (* 1 = 2.58154 loss)
I0605 10:08:59.058678   904 sgd_solver.cpp:106] Iteration 81200, lr = 0.0208941
I0605 10:09:19.587622   904 solver.cpp:229] Iteration 81240, loss = 2.67355
I0605 10:09:19.587684   904 solver.cpp:245]     Train net output #0: loss = 2.68861 (* 1 = 2.68861 loss)
I0605 10:09:19.587692   904 sgd_solver.cpp:106] Iteration 81240, lr = 0.0208847
I0605 10:09:40.262850   904 solver.cpp:229] Iteration 81280, loss = 2.67833
I0605 10:09:40.263007   904 solver.cpp:245]     Train net output #0: loss = 2.86779 (* 1 = 2.86779 loss)
I0605 10:09:40.263030   904 sgd_solver.cpp:106] Iteration 81280, lr = 0.0208753
I0605 10:09:40.524343   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 10:10:00.928472   904 solver.cpp:229] Iteration 81320, loss = 2.68963
I0605 10:10:00.928524   904 solver.cpp:245]     Train net output #0: loss = 2.39284 (* 1 = 2.39284 loss)
I0605 10:10:00.928532   904 sgd_solver.cpp:106] Iteration 81320, lr = 0.0208659
I0605 10:10:21.560271   904 solver.cpp:229] Iteration 81360, loss = 2.66007
I0605 10:10:21.560597   904 solver.cpp:245]     Train net output #0: loss = 2.6418 (* 1 = 2.6418 loss)
I0605 10:10:21.560621   904 sgd_solver.cpp:106] Iteration 81360, lr = 0.0208565
I0605 10:10:42.215080   904 solver.cpp:229] Iteration 81400, loss = 2.61794
I0605 10:10:42.215131   904 solver.cpp:245]     Train net output #0: loss = 2.16074 (* 1 = 2.16074 loss)
I0605 10:10:42.215140   904 sgd_solver.cpp:106] Iteration 81400, lr = 0.0208471
I0605 10:11:02.855540   904 solver.cpp:229] Iteration 81440, loss = 2.69907
I0605 10:11:02.855692   904 solver.cpp:245]     Train net output #0: loss = 2.92983 (* 1 = 2.92983 loss)
I0605 10:11:02.855702   904 sgd_solver.cpp:106] Iteration 81440, lr = 0.0208376
I0605 10:11:23.517902   904 solver.cpp:229] Iteration 81480, loss = 2.68884
I0605 10:11:23.517942   904 solver.cpp:245]     Train net output #0: loss = 2.56461 (* 1 = 2.56461 loss)
I0605 10:11:23.517952   904 sgd_solver.cpp:106] Iteration 81480, lr = 0.0208282
I0605 10:11:44.039049   904 solver.cpp:229] Iteration 81520, loss = 2.69715
I0605 10:11:44.039273   904 solver.cpp:245]     Train net output #0: loss = 2.7238 (* 1 = 2.7238 loss)
I0605 10:11:44.039301   904 sgd_solver.cpp:106] Iteration 81520, lr = 0.0208188
I0605 10:12:04.608031   904 solver.cpp:229] Iteration 81560, loss = 2.68429
I0605 10:12:04.608105   904 solver.cpp:245]     Train net output #0: loss = 2.68931 (* 1 = 2.68931 loss)
I0605 10:12:04.608119   904 sgd_solver.cpp:106] Iteration 81560, lr = 0.0208094
I0605 10:12:25.265971   904 solver.cpp:229] Iteration 81600, loss = 2.6976
I0605 10:12:25.266183   904 solver.cpp:245]     Train net output #0: loss = 2.94027 (* 1 = 2.94027 loss)
I0605 10:12:25.266206   904 sgd_solver.cpp:106] Iteration 81600, lr = 0.0208
I0605 10:12:45.922940   904 solver.cpp:229] Iteration 81640, loss = 2.69781
I0605 10:12:45.922988   904 solver.cpp:245]     Train net output #0: loss = 2.68349 (* 1 = 2.68349 loss)
I0605 10:12:45.922996   904 sgd_solver.cpp:106] Iteration 81640, lr = 0.0207906
I0605 10:13:06.481237   904 solver.cpp:229] Iteration 81680, loss = 2.65692
I0605 10:13:06.481431   904 solver.cpp:245]     Train net output #0: loss = 3.02757 (* 1 = 3.02757 loss)
I0605 10:13:06.481454   904 sgd_solver.cpp:106] Iteration 81680, lr = 0.0207812
I0605 10:13:26.999590   904 solver.cpp:229] Iteration 81720, loss = 2.6826
I0605 10:13:26.999641   904 solver.cpp:245]     Train net output #0: loss = 2.45161 (* 1 = 2.45161 loss)
I0605 10:13:26.999650   904 sgd_solver.cpp:106] Iteration 81720, lr = 0.0207718
I0605 10:13:47.577944   904 solver.cpp:229] Iteration 81760, loss = 2.70244
I0605 10:13:47.578130   904 solver.cpp:245]     Train net output #0: loss = 2.76513 (* 1 = 2.76513 loss)
I0605 10:13:47.578153   904 sgd_solver.cpp:106] Iteration 81760, lr = 0.0207624
I0605 10:14:08.234382   904 solver.cpp:229] Iteration 81800, loss = 2.66264
I0605 10:14:08.234419   904 solver.cpp:245]     Train net output #0: loss = 2.53965 (* 1 = 2.53965 loss)
I0605 10:14:08.234428   904 sgd_solver.cpp:106] Iteration 81800, lr = 0.0207529
I0605 10:14:28.828238   904 solver.cpp:229] Iteration 81840, loss = 2.66241
I0605 10:14:28.828415   904 solver.cpp:245]     Train net output #0: loss = 2.80611 (* 1 = 2.80611 loss)
I0605 10:14:28.828439   904 sgd_solver.cpp:106] Iteration 81840, lr = 0.0207435
I0605 10:14:40.612629   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 10:14:49.327144   904 solver.cpp:229] Iteration 81880, loss = 2.65909
I0605 10:14:49.327196   904 solver.cpp:245]     Train net output #0: loss = 2.54545 (* 1 = 2.54545 loss)
I0605 10:14:49.327205   904 sgd_solver.cpp:106] Iteration 81880, lr = 0.0207341
I0605 10:15:09.810997   904 solver.cpp:229] Iteration 81920, loss = 2.65349
I0605 10:15:09.811123   904 solver.cpp:245]     Train net output #0: loss = 2.70314 (* 1 = 2.70314 loss)
I0605 10:15:09.811133   904 sgd_solver.cpp:106] Iteration 81920, lr = 0.0207247
I0605 10:15:30.332120   904 solver.cpp:229] Iteration 81960, loss = 2.6742
I0605 10:15:30.332170   904 solver.cpp:245]     Train net output #0: loss = 2.5522 (* 1 = 2.5522 loss)
I0605 10:15:30.332177   904 sgd_solver.cpp:106] Iteration 81960, lr = 0.0207153
I0605 10:15:50.325881   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_82000.caffemodel
I0605 10:15:50.592061   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_82000.solverstate
I0605 10:15:50.669872   904 solver.cpp:338] Iteration 82000, Testing net (#0)
I0605 10:15:50.669939   904 net.cpp:748] Ignoring source layer loss
I0605 10:16:14.793754   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 10:16:47.542547   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 10:16:55.446609   904 solver.cpp:406]     Test net output #0: accuracy = 0.426321
I0605 10:16:55.446651   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.67762
I0605 10:16:55.760809   904 solver.cpp:229] Iteration 82000, loss = 2.66348
I0605 10:16:55.760844   904 solver.cpp:245]     Train net output #0: loss = 2.63057 (* 1 = 2.63057 loss)
I0605 10:16:55.760854   904 sgd_solver.cpp:106] Iteration 82000, lr = 0.0207059
I0605 10:17:15.019467   904 solver.cpp:229] Iteration 82040, loss = 2.65746
I0605 10:17:15.019515   904 solver.cpp:245]     Train net output #0: loss = 2.79944 (* 1 = 2.79944 loss)
I0605 10:17:15.019526   904 sgd_solver.cpp:106] Iteration 82040, lr = 0.0206965
I0605 10:17:36.515921   904 solver.cpp:229] Iteration 82080, loss = 2.6617
I0605 10:17:36.516139   904 solver.cpp:245]     Train net output #0: loss = 2.74505 (* 1 = 2.74505 loss)
I0605 10:17:36.516165   904 sgd_solver.cpp:106] Iteration 82080, lr = 0.0206871
I0605 10:17:58.023632   904 solver.cpp:229] Iteration 82120, loss = 2.66408
I0605 10:17:58.023677   904 solver.cpp:245]     Train net output #0: loss = 2.69255 (* 1 = 2.69255 loss)
I0605 10:17:58.023687   904 sgd_solver.cpp:106] Iteration 82120, lr = 0.0206776
I0605 10:18:19.282919   904 solver.cpp:229] Iteration 82160, loss = 2.6578
I0605 10:18:19.283110   904 solver.cpp:245]     Train net output #0: loss = 2.5414 (* 1 = 2.5414 loss)
I0605 10:18:19.283138   904 sgd_solver.cpp:106] Iteration 82160, lr = 0.0206682
I0605 10:18:40.317474   904 solver.cpp:229] Iteration 82200, loss = 2.67692
I0605 10:18:40.317534   904 solver.cpp:245]     Train net output #0: loss = 2.765 (* 1 = 2.765 loss)
I0605 10:18:40.317543   904 sgd_solver.cpp:106] Iteration 82200, lr = 0.0206588
I0605 10:19:01.978530   904 solver.cpp:229] Iteration 82240, loss = 2.64872
I0605 10:19:01.978721   904 solver.cpp:245]     Train net output #0: loss = 2.8941 (* 1 = 2.8941 loss)
I0605 10:19:01.978741   904 sgd_solver.cpp:106] Iteration 82240, lr = 0.0206494
I0605 10:19:22.797729   904 solver.cpp:229] Iteration 82280, loss = 2.61614
I0605 10:19:22.797783   904 solver.cpp:245]     Train net output #0: loss = 2.44651 (* 1 = 2.44651 loss)
I0605 10:19:22.797792   904 sgd_solver.cpp:106] Iteration 82280, lr = 0.02064
I0605 10:19:43.719676   904 solver.cpp:229] Iteration 82320, loss = 2.6541
I0605 10:19:43.719859   904 solver.cpp:245]     Train net output #0: loss = 2.55424 (* 1 = 2.55424 loss)
I0605 10:19:43.719882   904 sgd_solver.cpp:106] Iteration 82320, lr = 0.0206306
I0605 10:20:04.748793   904 solver.cpp:229] Iteration 82360, loss = 2.68401
I0605 10:20:04.748843   904 solver.cpp:245]     Train net output #0: loss = 2.56851 (* 1 = 2.56851 loss)
I0605 10:20:04.748852   904 sgd_solver.cpp:106] Iteration 82360, lr = 0.0206212
I0605 10:20:25.581519   904 solver.cpp:229] Iteration 82400, loss = 2.66972
I0605 10:20:25.581665   904 solver.cpp:245]     Train net output #0: loss = 2.71227 (* 1 = 2.71227 loss)
I0605 10:20:25.581676   904 sgd_solver.cpp:106] Iteration 82400, lr = 0.0206118
I0605 10:20:33.836587   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 10:20:46.168136   904 solver.cpp:229] Iteration 82440, loss = 2.61916
I0605 10:20:46.168179   904 solver.cpp:245]     Train net output #0: loss = 2.66801 (* 1 = 2.66801 loss)
I0605 10:20:46.168187   904 sgd_solver.cpp:106] Iteration 82440, lr = 0.0206024
I0605 10:21:06.810024   904 solver.cpp:229] Iteration 82480, loss = 2.66568
I0605 10:21:06.810287   904 solver.cpp:245]     Train net output #0: loss = 2.54872 (* 1 = 2.54872 loss)
I0605 10:21:06.810317   904 sgd_solver.cpp:106] Iteration 82480, lr = 0.0205929
I0605 10:21:27.527972   904 solver.cpp:229] Iteration 82520, loss = 2.68288
I0605 10:21:27.528023   904 solver.cpp:245]     Train net output #0: loss = 2.87538 (* 1 = 2.87538 loss)
I0605 10:21:27.528030   904 sgd_solver.cpp:106] Iteration 82520, lr = 0.0205835
I0605 10:21:48.177783   904 solver.cpp:229] Iteration 82560, loss = 2.68516
I0605 10:21:48.177985   904 solver.cpp:245]     Train net output #0: loss = 2.5564 (* 1 = 2.5564 loss)
I0605 10:21:48.178006   904 sgd_solver.cpp:106] Iteration 82560, lr = 0.0205741
I0605 10:22:08.691952   904 solver.cpp:229] Iteration 82600, loss = 2.69939
I0605 10:22:08.692004   904 solver.cpp:245]     Train net output #0: loss = 2.76057 (* 1 = 2.76057 loss)
I0605 10:22:08.692013   904 sgd_solver.cpp:106] Iteration 82600, lr = 0.0205647
I0605 10:22:29.223412   904 solver.cpp:229] Iteration 82640, loss = 2.69637
I0605 10:22:29.223587   904 solver.cpp:245]     Train net output #0: loss = 2.61226 (* 1 = 2.61226 loss)
I0605 10:22:29.223609   904 sgd_solver.cpp:106] Iteration 82640, lr = 0.0205553
I0605 10:22:49.746675   904 solver.cpp:229] Iteration 82680, loss = 2.6809
I0605 10:22:49.746731   904 solver.cpp:245]     Train net output #0: loss = 2.64875 (* 1 = 2.64875 loss)
I0605 10:22:49.746740   904 sgd_solver.cpp:106] Iteration 82680, lr = 0.0205459
I0605 10:23:10.402747   904 solver.cpp:229] Iteration 82720, loss = 2.64762
I0605 10:23:10.402890   904 solver.cpp:245]     Train net output #0: loss = 2.41194 (* 1 = 2.41194 loss)
I0605 10:23:10.402900   904 sgd_solver.cpp:106] Iteration 82720, lr = 0.0205365
I0605 10:23:30.941620   904 solver.cpp:229] Iteration 82760, loss = 2.68295
I0605 10:23:30.941668   904 solver.cpp:245]     Train net output #0: loss = 2.67221 (* 1 = 2.67221 loss)
I0605 10:23:30.941676   904 sgd_solver.cpp:106] Iteration 82760, lr = 0.0205271
I0605 10:23:51.475646   904 solver.cpp:229] Iteration 82800, loss = 2.66915
I0605 10:23:51.475806   904 solver.cpp:245]     Train net output #0: loss = 2.3866 (* 1 = 2.3866 loss)
I0605 10:23:51.475827   904 sgd_solver.cpp:106] Iteration 82800, lr = 0.0205176
I0605 10:24:11.831425   904 solver.cpp:229] Iteration 82840, loss = 2.7011
I0605 10:24:11.831487   904 solver.cpp:245]     Train net output #0: loss = 2.89643 (* 1 = 2.89643 loss)
I0605 10:24:11.831508   904 sgd_solver.cpp:106] Iteration 82840, lr = 0.0205082
I0605 10:24:32.123726   904 solver.cpp:229] Iteration 82880, loss = 2.67213
I0605 10:24:32.123903   904 solver.cpp:245]     Train net output #0: loss = 2.34293 (* 1 = 2.34293 loss)
I0605 10:24:32.123930   904 sgd_solver.cpp:106] Iteration 82880, lr = 0.0204988
I0605 10:24:52.422226   904 solver.cpp:229] Iteration 82920, loss = 2.63082
I0605 10:24:52.422269   904 solver.cpp:245]     Train net output #0: loss = 2.50281 (* 1 = 2.50281 loss)
I0605 10:24:52.422279   904 sgd_solver.cpp:106] Iteration 82920, lr = 0.0204894
I0605 10:25:12.735337   904 solver.cpp:229] Iteration 82960, loss = 2.63103
I0605 10:25:12.735502   904 solver.cpp:245]     Train net output #0: loss = 2.40804 (* 1 = 2.40804 loss)
I0605 10:25:12.735517   904 sgd_solver.cpp:106] Iteration 82960, lr = 0.02048
I0605 10:25:24.145871   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 10:25:32.521421   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_83000.caffemodel
I0605 10:25:32.806324   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_83000.solverstate
I0605 10:25:32.895128   904 solver.cpp:338] Iteration 83000, Testing net (#0)
I0605 10:25:32.895212   904 net.cpp:748] Ignoring source layer loss
I0605 10:26:04.826526   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 10:26:38.574908   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 10:26:39.552809   904 solver.cpp:406]     Test net output #0: accuracy = 0.424381
I0605 10:26:39.552834   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.671659
I0605 10:26:39.866519   904 solver.cpp:229] Iteration 83000, loss = 2.6484
I0605 10:26:39.866557   904 solver.cpp:245]     Train net output #0: loss = 2.7366 (* 1 = 2.7366 loss)
I0605 10:26:39.866567   904 sgd_solver.cpp:106] Iteration 83000, lr = 0.0204706
I0605 10:26:59.088531   904 solver.cpp:229] Iteration 83040, loss = 2.70048
I0605 10:26:59.088582   904 solver.cpp:245]     Train net output #0: loss = 2.55488 (* 1 = 2.55488 loss)
I0605 10:26:59.088592   904 sgd_solver.cpp:106] Iteration 83040, lr = 0.0204612
I0605 10:27:20.359988   904 solver.cpp:229] Iteration 83080, loss = 2.68843
I0605 10:27:20.360147   904 solver.cpp:245]     Train net output #0: loss = 2.79787 (* 1 = 2.79787 loss)
I0605 10:27:20.360172   904 sgd_solver.cpp:106] Iteration 83080, lr = 0.0204518
I0605 10:27:41.704151   904 solver.cpp:229] Iteration 83120, loss = 2.63516
I0605 10:27:41.704200   904 solver.cpp:245]     Train net output #0: loss = 2.59344 (* 1 = 2.59344 loss)
I0605 10:27:41.704208   904 sgd_solver.cpp:106] Iteration 83120, lr = 0.0204424
I0605 10:28:02.678606   904 solver.cpp:229] Iteration 83160, loss = 2.67751
I0605 10:28:02.678784   904 solver.cpp:245]     Train net output #0: loss = 2.7296 (* 1 = 2.7296 loss)
I0605 10:28:02.678808   904 sgd_solver.cpp:106] Iteration 83160, lr = 0.0204329
I0605 10:28:23.685003   904 solver.cpp:229] Iteration 83200, loss = 2.68894
I0605 10:28:23.685045   904 solver.cpp:245]     Train net output #0: loss = 2.69126 (* 1 = 2.69126 loss)
I0605 10:28:23.685053   904 sgd_solver.cpp:106] Iteration 83200, lr = 0.0204235
I0605 10:28:44.657191   904 solver.cpp:229] Iteration 83240, loss = 2.69153
I0605 10:28:44.657387   904 solver.cpp:245]     Train net output #0: loss = 2.4427 (* 1 = 2.4427 loss)
I0605 10:28:44.657409   904 sgd_solver.cpp:106] Iteration 83240, lr = 0.0204141
I0605 10:29:05.500283   904 solver.cpp:229] Iteration 83280, loss = 2.64048
I0605 10:29:05.500344   904 solver.cpp:245]     Train net output #0: loss = 2.76334 (* 1 = 2.76334 loss)
I0605 10:29:05.500354   904 sgd_solver.cpp:106] Iteration 83280, lr = 0.0204047
I0605 10:29:26.318927   904 solver.cpp:229] Iteration 83320, loss = 2.68711
I0605 10:29:26.319082   904 solver.cpp:245]     Train net output #0: loss = 2.82411 (* 1 = 2.82411 loss)
I0605 10:29:26.319092   904 sgd_solver.cpp:106] Iteration 83320, lr = 0.0203953
I0605 10:29:47.007522   904 solver.cpp:229] Iteration 83360, loss = 2.67771
I0605 10:29:47.007570   904 solver.cpp:245]     Train net output #0: loss = 2.668 (* 1 = 2.668 loss)
I0605 10:29:47.007578   904 sgd_solver.cpp:106] Iteration 83360, lr = 0.0203859
I0605 10:30:07.703259   904 solver.cpp:229] Iteration 83400, loss = 2.62801
I0605 10:30:07.703513   904 solver.cpp:245]     Train net output #0: loss = 2.66579 (* 1 = 2.66579 loss)
I0605 10:30:07.703541   904 sgd_solver.cpp:106] Iteration 83400, lr = 0.0203765
I0605 10:30:28.394412   904 solver.cpp:229] Iteration 83440, loss = 2.63632
I0605 10:30:28.394453   904 solver.cpp:245]     Train net output #0: loss = 2.56233 (* 1 = 2.56233 loss)
I0605 10:30:28.394460   904 sgd_solver.cpp:106] Iteration 83440, lr = 0.0203671
I0605 10:30:48.894904   904 solver.cpp:229] Iteration 83480, loss = 2.69536
I0605 10:30:48.895109   904 solver.cpp:245]     Train net output #0: loss = 2.77926 (* 1 = 2.77926 loss)
I0605 10:30:48.895145   904 sgd_solver.cpp:106] Iteration 83480, lr = 0.0203576
I0605 10:31:09.386303   904 solver.cpp:229] Iteration 83520, loss = 2.65435
I0605 10:31:09.386361   904 solver.cpp:245]     Train net output #0: loss = 3.022 (* 1 = 3.022 loss)
I0605 10:31:09.386373   904 sgd_solver.cpp:106] Iteration 83520, lr = 0.0203482
I0605 10:31:29.011670   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 10:31:30.040297   904 solver.cpp:229] Iteration 83560, loss = 2.68518
I0605 10:31:30.040347   904 solver.cpp:245]     Train net output #0: loss = 2.50749 (* 1 = 2.50749 loss)
I0605 10:31:30.040359   904 sgd_solver.cpp:106] Iteration 83560, lr = 0.0203388
I0605 10:31:50.557350   904 solver.cpp:229] Iteration 83600, loss = 2.61726
I0605 10:31:50.557404   904 solver.cpp:245]     Train net output #0: loss = 2.61445 (* 1 = 2.61445 loss)
I0605 10:31:50.557411   904 sgd_solver.cpp:106] Iteration 83600, lr = 0.0203294
I0605 10:32:11.065230   904 solver.cpp:229] Iteration 83640, loss = 2.65075
I0605 10:32:11.065462   904 solver.cpp:245]     Train net output #0: loss = 2.64945 (* 1 = 2.64945 loss)
I0605 10:32:11.065490   904 sgd_solver.cpp:106] Iteration 83640, lr = 0.02032
I0605 10:32:31.580891   904 solver.cpp:229] Iteration 83680, loss = 2.64049
I0605 10:32:31.580929   904 solver.cpp:245]     Train net output #0: loss = 2.69998 (* 1 = 2.69998 loss)
I0605 10:32:31.580936   904 sgd_solver.cpp:106] Iteration 83680, lr = 0.0203106
I0605 10:32:52.094218   904 solver.cpp:229] Iteration 83720, loss = 2.67284
I0605 10:32:52.094415   904 solver.cpp:245]     Train net output #0: loss = 2.71231 (* 1 = 2.71231 loss)
I0605 10:32:52.094436   904 sgd_solver.cpp:106] Iteration 83720, lr = 0.0203012
I0605 10:33:12.616477   904 solver.cpp:229] Iteration 83760, loss = 2.6654
I0605 10:33:12.616528   904 solver.cpp:245]     Train net output #0: loss = 2.62522 (* 1 = 2.62522 loss)
I0605 10:33:12.616536   904 sgd_solver.cpp:106] Iteration 83760, lr = 0.0202918
I0605 10:33:33.121456   904 solver.cpp:229] Iteration 83800, loss = 2.67322
I0605 10:33:33.121701   904 solver.cpp:245]     Train net output #0: loss = 2.74877 (* 1 = 2.74877 loss)
I0605 10:33:33.121729   904 sgd_solver.cpp:106] Iteration 83800, lr = 0.0202824
I0605 10:33:53.624609   904 solver.cpp:229] Iteration 83840, loss = 2.65174
I0605 10:33:53.624658   904 solver.cpp:245]     Train net output #0: loss = 2.63243 (* 1 = 2.63243 loss)
I0605 10:33:53.624670   904 sgd_solver.cpp:106] Iteration 83840, lr = 0.0202729
I0605 10:34:14.103996   904 solver.cpp:229] Iteration 83880, loss = 2.6086
I0605 10:34:14.104209   904 solver.cpp:245]     Train net output #0: loss = 2.56643 (* 1 = 2.56643 loss)
I0605 10:34:14.104229   904 sgd_solver.cpp:106] Iteration 83880, lr = 0.0202635
I0605 10:34:34.596985   904 solver.cpp:229] Iteration 83920, loss = 2.67315
I0605 10:34:34.597043   904 solver.cpp:245]     Train net output #0: loss = 2.76322 (* 1 = 2.76322 loss)
I0605 10:34:34.597054   904 sgd_solver.cpp:106] Iteration 83920, lr = 0.0202541
I0605 10:34:55.086766   904 solver.cpp:229] Iteration 83960, loss = 2.64961
I0605 10:34:55.086985   904 solver.cpp:245]     Train net output #0: loss = 2.68702 (* 1 = 2.68702 loss)
I0605 10:34:55.086997   904 sgd_solver.cpp:106] Iteration 83960, lr = 0.0202447
I0605 10:35:15.107661   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_84000.caffemodel
I0605 10:35:15.367370   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_84000.solverstate
I0605 10:35:15.446125   904 solver.cpp:338] Iteration 84000, Testing net (#0)
I0605 10:35:15.446210   904 net.cpp:748] Ignoring source layer loss
I0605 10:35:25.213758   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 10:35:58.553755   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 10:36:21.745625   904 solver.cpp:406]     Test net output #0: accuracy = 0.425001
I0605 10:36:21.745671   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.677519
I0605 10:36:22.062526   904 solver.cpp:229] Iteration 84000, loss = 2.66965
I0605 10:36:22.062568   904 solver.cpp:245]     Train net output #0: loss = 2.83113 (* 1 = 2.83113 loss)
I0605 10:36:22.062578   904 sgd_solver.cpp:106] Iteration 84000, lr = 0.0202353
I0605 10:36:41.379357   904 solver.cpp:229] Iteration 84040, loss = 2.66465
I0605 10:36:41.379555   904 solver.cpp:245]     Train net output #0: loss = 2.41128 (* 1 = 2.41128 loss)
I0605 10:36:41.379583   904 sgd_solver.cpp:106] Iteration 84040, lr = 0.0202259
I0605 10:37:02.919488   904 solver.cpp:229] Iteration 84080, loss = 2.65118
I0605 10:37:02.919543   904 solver.cpp:245]     Train net output #0: loss = 2.71277 (* 1 = 2.71277 loss)
I0605 10:37:02.919553   904 sgd_solver.cpp:106] Iteration 84080, lr = 0.0202165
I0605 10:37:24.489629   904 solver.cpp:229] Iteration 84120, loss = 2.68764
I0605 10:37:24.489815   904 solver.cpp:245]     Train net output #0: loss = 2.6848 (* 1 = 2.6848 loss)
I0605 10:37:24.489826   904 sgd_solver.cpp:106] Iteration 84120, lr = 0.0202071
I0605 10:37:37.011139   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 10:37:45.674810   904 solver.cpp:229] Iteration 84160, loss = 2.6534
I0605 10:37:45.674855   904 solver.cpp:245]     Train net output #0: loss = 2.53714 (* 1 = 2.53714 loss)
I0605 10:37:45.674867   904 sgd_solver.cpp:106] Iteration 84160, lr = 0.0201976
I0605 10:38:06.705145   904 solver.cpp:229] Iteration 84200, loss = 2.66168
I0605 10:38:06.705344   904 solver.cpp:245]     Train net output #0: loss = 2.95256 (* 1 = 2.95256 loss)
I0605 10:38:06.705369   904 sgd_solver.cpp:106] Iteration 84200, lr = 0.0201882
I0605 10:38:27.731926   904 solver.cpp:229] Iteration 84240, loss = 2.6605
I0605 10:38:27.731987   904 solver.cpp:245]     Train net output #0: loss = 2.61311 (* 1 = 2.61311 loss)
I0605 10:38:27.732002   904 sgd_solver.cpp:106] Iteration 84240, lr = 0.0201788
I0605 10:38:48.768390   904 solver.cpp:229] Iteration 84280, loss = 2.64595
I0605 10:38:48.768580   904 solver.cpp:245]     Train net output #0: loss = 2.3767 (* 1 = 2.3767 loss)
I0605 10:38:48.768609   904 sgd_solver.cpp:106] Iteration 84280, lr = 0.0201694
I0605 10:39:09.742813   904 solver.cpp:229] Iteration 84320, loss = 2.61379
I0605 10:39:09.742852   904 solver.cpp:245]     Train net output #0: loss = 2.48056 (* 1 = 2.48056 loss)
I0605 10:39:09.742861   904 sgd_solver.cpp:106] Iteration 84320, lr = 0.02016
I0605 10:39:30.727118   904 solver.cpp:229] Iteration 84360, loss = 2.61918
I0605 10:39:30.727335   904 solver.cpp:245]     Train net output #0: loss = 2.51237 (* 1 = 2.51237 loss)
I0605 10:39:30.727360   904 sgd_solver.cpp:106] Iteration 84360, lr = 0.0201506
I0605 10:39:51.574223   904 solver.cpp:229] Iteration 84400, loss = 2.60034
I0605 10:39:51.574265   904 solver.cpp:245]     Train net output #0: loss = 2.58163 (* 1 = 2.58163 loss)
I0605 10:39:51.574272   904 sgd_solver.cpp:106] Iteration 84400, lr = 0.0201412
I0605 10:40:12.407094   904 solver.cpp:229] Iteration 84440, loss = 2.64242
I0605 10:40:12.407301   904 solver.cpp:245]     Train net output #0: loss = 2.59625 (* 1 = 2.59625 loss)
I0605 10:40:12.407328   904 sgd_solver.cpp:106] Iteration 84440, lr = 0.0201318
I0605 10:40:33.211781   904 solver.cpp:229] Iteration 84480, loss = 2.64422
I0605 10:40:33.211825   904 solver.cpp:245]     Train net output #0: loss = 2.81453 (* 1 = 2.81453 loss)
I0605 10:40:33.211838   904 sgd_solver.cpp:106] Iteration 84480, lr = 0.0201224
I0605 10:40:53.916215   904 solver.cpp:229] Iteration 84520, loss = 2.63948
I0605 10:40:53.916436   904 solver.cpp:245]     Train net output #0: loss = 2.70563 (* 1 = 2.70563 loss)
I0605 10:40:53.916467   904 sgd_solver.cpp:106] Iteration 84520, lr = 0.0201129
I0605 10:41:14.694403   904 solver.cpp:229] Iteration 84560, loss = 2.63702
I0605 10:41:14.694458   904 solver.cpp:245]     Train net output #0: loss = 2.41711 (* 1 = 2.41711 loss)
I0605 10:41:14.694468   904 sgd_solver.cpp:106] Iteration 84560, lr = 0.0201035
I0605 10:41:35.422740   904 solver.cpp:229] Iteration 84600, loss = 2.63435
I0605 10:41:35.422935   904 solver.cpp:245]     Train net output #0: loss = 2.68524 (* 1 = 2.68524 loss)
I0605 10:41:35.422960   904 sgd_solver.cpp:106] Iteration 84600, lr = 0.0200941
I0605 10:41:56.140388   904 solver.cpp:229] Iteration 84640, loss = 2.63614
I0605 10:41:56.140431   904 solver.cpp:245]     Train net output #0: loss = 2.60451 (* 1 = 2.60451 loss)
I0605 10:41:56.140439   904 sgd_solver.cpp:106] Iteration 84640, lr = 0.0200847
I0605 10:41:59.768044   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 10:42:16.820861   904 solver.cpp:229] Iteration 84680, loss = 2.66832
I0605 10:42:16.821107   904 solver.cpp:245]     Train net output #0: loss = 2.77992 (* 1 = 2.77992 loss)
I0605 10:42:16.821132   904 sgd_solver.cpp:106] Iteration 84680, lr = 0.0200753
I0605 10:42:37.372804   904 solver.cpp:229] Iteration 84720, loss = 2.64156
I0605 10:42:37.372848   904 solver.cpp:245]     Train net output #0: loss = 2.71596 (* 1 = 2.71596 loss)
I0605 10:42:37.372856   904 sgd_solver.cpp:106] Iteration 84720, lr = 0.0200659
I0605 10:42:58.004947   904 solver.cpp:229] Iteration 84760, loss = 2.70203
I0605 10:42:58.005100   904 solver.cpp:245]     Train net output #0: loss = 2.6717 (* 1 = 2.6717 loss)
I0605 10:42:58.005110   904 sgd_solver.cpp:106] Iteration 84760, lr = 0.0200565
I0605 10:43:18.693771   904 solver.cpp:229] Iteration 84800, loss = 2.62469
I0605 10:43:18.693822   904 solver.cpp:245]     Train net output #0: loss = 2.59081 (* 1 = 2.59081 loss)
I0605 10:43:18.693831   904 sgd_solver.cpp:106] Iteration 84800, lr = 0.0200471
I0605 10:43:39.278805   904 solver.cpp:229] Iteration 84840, loss = 2.66811
I0605 10:43:39.278995   904 solver.cpp:245]     Train net output #0: loss = 2.47307 (* 1 = 2.47307 loss)
I0605 10:43:39.279023   904 sgd_solver.cpp:106] Iteration 84840, lr = 0.0200376
I0605 10:43:59.830663   904 solver.cpp:229] Iteration 84880, loss = 2.64864
I0605 10:43:59.830718   904 solver.cpp:245]     Train net output #0: loss = 2.56939 (* 1 = 2.56939 loss)
I0605 10:43:59.830729   904 sgd_solver.cpp:106] Iteration 84880, lr = 0.0200282
I0605 10:44:20.395081   904 solver.cpp:229] Iteration 84920, loss = 2.61913
I0605 10:44:20.395318   904 solver.cpp:245]     Train net output #0: loss = 2.72057 (* 1 = 2.72057 loss)
I0605 10:44:20.395344   904 sgd_solver.cpp:106] Iteration 84920, lr = 0.0200188
I0605 10:44:40.918476   904 solver.cpp:229] Iteration 84960, loss = 2.61814
I0605 10:44:40.918529   904 solver.cpp:245]     Train net output #0: loss = 2.5776 (* 1 = 2.5776 loss)
I0605 10:44:40.918536   904 sgd_solver.cpp:106] Iteration 84960, lr = 0.0200094
I0605 10:45:00.965546   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_85000.caffemodel
I0605 10:45:01.229233   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_85000.solverstate
I0605 10:45:01.308162   904 solver.cpp:338] Iteration 85000, Testing net (#0)
I0605 10:45:01.308243   904 net.cpp:748] Ignoring source layer loss
I0605 10:45:11.356370   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 10:45:44.648883   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 10:46:08.192160   904 solver.cpp:406]     Test net output #0: accuracy = 0.421502
I0605 10:46:08.192220   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.67088
I0605 10:46:08.506551   904 solver.cpp:229] Iteration 85000, loss = 2.6296
I0605 10:46:08.506595   904 solver.cpp:245]     Train net output #0: loss = 2.55614 (* 1 = 2.55614 loss)
I0605 10:46:08.506604   904 sgd_solver.cpp:106] Iteration 85000, lr = 0.02
I0605 10:46:27.735432   904 solver.cpp:229] Iteration 85040, loss = 2.65116
I0605 10:46:27.735646   904 solver.cpp:245]     Train net output #0: loss = 2.6262 (* 1 = 2.6262 loss)
I0605 10:46:27.735674   904 sgd_solver.cpp:106] Iteration 85040, lr = 0.0199906
I0605 10:46:49.117336   904 solver.cpp:229] Iteration 85080, loss = 2.66021
I0605 10:46:49.117390   904 solver.cpp:245]     Train net output #0: loss = 2.66461 (* 1 = 2.66461 loss)
I0605 10:46:49.117400   904 sgd_solver.cpp:106] Iteration 85080, lr = 0.0199812
I0605 10:47:10.632639   904 solver.cpp:229] Iteration 85120, loss = 2.68439
I0605 10:47:10.632774   904 solver.cpp:245]     Train net output #0: loss = 2.48451 (* 1 = 2.48451 loss)
I0605 10:47:10.632788   904 sgd_solver.cpp:106] Iteration 85120, lr = 0.0199718
I0605 10:47:28.392051   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 10:47:31.795264   904 solver.cpp:229] Iteration 85160, loss = 2.65573
I0605 10:47:31.795318   904 solver.cpp:245]     Train net output #0: loss = 2.75806 (* 1 = 2.75806 loss)
I0605 10:47:31.795331   904 sgd_solver.cpp:106] Iteration 85160, lr = 0.0199624
I0605 10:47:52.773950   904 solver.cpp:229] Iteration 85200, loss = 2.6637
I0605 10:47:52.774134   904 solver.cpp:245]     Train net output #0: loss = 2.84077 (* 1 = 2.84077 loss)
I0605 10:47:52.774147   904 sgd_solver.cpp:106] Iteration 85200, lr = 0.0199529
I0605 10:48:13.767876   904 solver.cpp:229] Iteration 85240, loss = 2.66072
I0605 10:48:13.767942   904 solver.cpp:245]     Train net output #0: loss = 2.74678 (* 1 = 2.74678 loss)
I0605 10:48:13.767956   904 sgd_solver.cpp:106] Iteration 85240, lr = 0.0199435
I0605 10:48:34.744117   904 solver.cpp:229] Iteration 85280, loss = 2.67573
I0605 10:48:34.744225   904 solver.cpp:245]     Train net output #0: loss = 2.68911 (* 1 = 2.68911 loss)
I0605 10:48:34.744236   904 sgd_solver.cpp:106] Iteration 85280, lr = 0.0199341
I0605 10:48:55.685961   904 solver.cpp:229] Iteration 85320, loss = 2.66279
I0605 10:48:55.686012   904 solver.cpp:245]     Train net output #0: loss = 2.71431 (* 1 = 2.71431 loss)
I0605 10:48:55.686023   904 sgd_solver.cpp:106] Iteration 85320, lr = 0.0199247
I0605 10:49:16.502928   904 solver.cpp:229] Iteration 85360, loss = 2.64827
I0605 10:49:16.503125   904 solver.cpp:245]     Train net output #0: loss = 2.50555 (* 1 = 2.50555 loss)
I0605 10:49:16.503151   904 sgd_solver.cpp:106] Iteration 85360, lr = 0.0199153
I0605 10:49:37.278744   904 solver.cpp:229] Iteration 85400, loss = 2.63254
I0605 10:49:37.278796   904 solver.cpp:245]     Train net output #0: loss = 2.54439 (* 1 = 2.54439 loss)
I0605 10:49:37.278807   904 sgd_solver.cpp:106] Iteration 85400, lr = 0.0199059
I0605 10:49:57.951606   904 solver.cpp:229] Iteration 85440, loss = 2.63198
I0605 10:49:57.951738   904 solver.cpp:245]     Train net output #0: loss = 2.55645 (* 1 = 2.55645 loss)
I0605 10:49:57.951750   904 sgd_solver.cpp:106] Iteration 85440, lr = 0.0198965
I0605 10:50:18.638702   904 solver.cpp:229] Iteration 85480, loss = 2.65786
I0605 10:50:18.638770   904 solver.cpp:245]     Train net output #0: loss = 2.59294 (* 1 = 2.59294 loss)
I0605 10:50:18.638780   904 sgd_solver.cpp:106] Iteration 85480, lr = 0.0198871
I0605 10:50:39.301682   904 solver.cpp:229] Iteration 85520, loss = 2.65482
I0605 10:50:39.301815   904 solver.cpp:245]     Train net output #0: loss = 2.78184 (* 1 = 2.78184 loss)
I0605 10:50:39.301827   904 sgd_solver.cpp:106] Iteration 85520, lr = 0.0198776
I0605 10:50:59.945494   904 solver.cpp:229] Iteration 85560, loss = 2.67932
I0605 10:50:59.945550   904 solver.cpp:245]     Train net output #0: loss = 2.55584 (* 1 = 2.55584 loss)
I0605 10:50:59.945561   904 sgd_solver.cpp:106] Iteration 85560, lr = 0.0198682
I0605 10:51:20.458606   904 solver.cpp:229] Iteration 85600, loss = 2.65193
I0605 10:51:20.458808   904 solver.cpp:245]     Train net output #0: loss = 2.46815 (* 1 = 2.46815 loss)
I0605 10:51:20.458833   904 sgd_solver.cpp:106] Iteration 85600, lr = 0.0198588
I0605 10:51:41.001940   904 solver.cpp:229] Iteration 85640, loss = 2.62449
I0605 10:51:41.001996   904 solver.cpp:245]     Train net output #0: loss = 2.70878 (* 1 = 2.70878 loss)
I0605 10:51:41.002007   904 sgd_solver.cpp:106] Iteration 85640, lr = 0.0198494
I0605 10:51:47.965024   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 10:52:01.608080   904 solver.cpp:229] Iteration 85680, loss = 2.64632
I0605 10:52:01.608212   904 solver.cpp:245]     Train net output #0: loss = 2.66352 (* 1 = 2.66352 loss)
I0605 10:52:01.608224   904 sgd_solver.cpp:106] Iteration 85680, lr = 0.01984
I0605 10:52:22.107349   904 solver.cpp:229] Iteration 85720, loss = 2.66513
I0605 10:52:22.107405   904 solver.cpp:245]     Train net output #0: loss = 2.63636 (* 1 = 2.63636 loss)
I0605 10:52:22.107416   904 sgd_solver.cpp:106] Iteration 85720, lr = 0.0198306
I0605 10:52:42.635949   904 solver.cpp:229] Iteration 85760, loss = 2.67848
I0605 10:52:42.636121   904 solver.cpp:245]     Train net output #0: loss = 2.70502 (* 1 = 2.70502 loss)
I0605 10:52:42.636154   904 sgd_solver.cpp:106] Iteration 85760, lr = 0.0198212
I0605 10:53:03.147874   904 solver.cpp:229] Iteration 85800, loss = 2.65904
I0605 10:53:03.147912   904 solver.cpp:245]     Train net output #0: loss = 2.80472 (* 1 = 2.80472 loss)
I0605 10:53:03.147920   904 sgd_solver.cpp:106] Iteration 85800, lr = 0.0198118
I0605 10:53:23.416470   904 solver.cpp:229] Iteration 85840, loss = 2.65748
I0605 10:53:23.416700   904 solver.cpp:245]     Train net output #0: loss = 2.51194 (* 1 = 2.51194 loss)
I0605 10:53:23.416709   904 sgd_solver.cpp:106] Iteration 85840, lr = 0.0198024
I0605 10:53:43.692734   904 solver.cpp:229] Iteration 85880, loss = 2.62842
I0605 10:53:43.692787   904 solver.cpp:245]     Train net output #0: loss = 2.52999 (* 1 = 2.52999 loss)
I0605 10:53:43.692807   904 sgd_solver.cpp:106] Iteration 85880, lr = 0.0197929
I0605 10:54:03.997449   904 solver.cpp:229] Iteration 85920, loss = 2.63372
I0605 10:54:03.997660   904 solver.cpp:245]     Train net output #0: loss = 2.46959 (* 1 = 2.46959 loss)
I0605 10:54:03.997686   904 sgd_solver.cpp:106] Iteration 85920, lr = 0.0197835
I0605 10:54:24.284556   904 solver.cpp:229] Iteration 85960, loss = 2.67261
I0605 10:54:24.284605   904 solver.cpp:245]     Train net output #0: loss = 2.84625 (* 1 = 2.84625 loss)
I0605 10:54:24.284613   904 sgd_solver.cpp:106] Iteration 85960, lr = 0.0197741
I0605 10:54:44.078842   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_86000.caffemodel
I0605 10:54:44.351343   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_86000.solverstate
I0605 10:54:44.424650   904 solver.cpp:338] Iteration 86000, Testing net (#0)
I0605 10:54:44.424741   904 net.cpp:748] Ignoring source layer loss
I0605 10:54:55.187816   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 10:55:29.739455   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 10:55:52.178280   904 solver.cpp:406]     Test net output #0: accuracy = 0.427861
I0605 10:55:52.178316   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.681819
I0605 10:55:52.494251   904 solver.cpp:229] Iteration 86000, loss = 2.64076
I0605 10:55:52.494292   904 solver.cpp:245]     Train net output #0: loss = 2.57219 (* 1 = 2.57219 loss)
I0605 10:55:52.494302   904 sgd_solver.cpp:106] Iteration 86000, lr = 0.0197647
I0605 10:56:11.683457   904 solver.cpp:229] Iteration 86040, loss = 2.60526
I0605 10:56:11.683701   904 solver.cpp:245]     Train net output #0: loss = 2.82175 (* 1 = 2.82175 loss)
I0605 10:56:11.683733   904 sgd_solver.cpp:106] Iteration 86040, lr = 0.0197553
I0605 10:56:33.041324   904 solver.cpp:229] Iteration 86080, loss = 2.60667
I0605 10:56:33.041379   904 solver.cpp:245]     Train net output #0: loss = 2.63483 (* 1 = 2.63483 loss)
I0605 10:56:33.041393   904 sgd_solver.cpp:106] Iteration 86080, lr = 0.0197459
I0605 10:56:54.405004   904 solver.cpp:229] Iteration 86120, loss = 2.63017
I0605 10:56:54.405283   904 solver.cpp:245]     Train net output #0: loss = 2.82184 (* 1 = 2.82184 loss)
I0605 10:56:54.405309   904 sgd_solver.cpp:106] Iteration 86120, lr = 0.0197365
I0605 10:57:15.117930   904 solver.cpp:229] Iteration 86160, loss = 2.64114
I0605 10:57:15.117986   904 solver.cpp:245]     Train net output #0: loss = 2.56473 (* 1 = 2.56473 loss)
I0605 10:57:15.117995   904 sgd_solver.cpp:106] Iteration 86160, lr = 0.0197271
I0605 10:57:19.776386   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 10:57:35.672983   904 solver.cpp:229] Iteration 86200, loss = 2.63191
I0605 10:57:35.673182   904 solver.cpp:245]     Train net output #0: loss = 2.80076 (* 1 = 2.80076 loss)
I0605 10:57:35.673218   904 sgd_solver.cpp:106] Iteration 86200, lr = 0.0197176
I0605 10:57:56.183976   904 solver.cpp:229] Iteration 86240, loss = 2.6184
I0605 10:57:56.184031   904 solver.cpp:245]     Train net output #0: loss = 2.45414 (* 1 = 2.45414 loss)
I0605 10:57:56.184041   904 sgd_solver.cpp:106] Iteration 86240, lr = 0.0197082
I0605 10:58:16.621990   904 solver.cpp:229] Iteration 86280, loss = 2.64012
I0605 10:58:16.622298   904 solver.cpp:245]     Train net output #0: loss = 2.68322 (* 1 = 2.68322 loss)
I0605 10:58:16.622334   904 sgd_solver.cpp:106] Iteration 86280, lr = 0.0196988
I0605 10:58:36.680940   904 solver.cpp:229] Iteration 86320, loss = 2.65459
I0605 10:58:36.680989   904 solver.cpp:245]     Train net output #0: loss = 2.7636 (* 1 = 2.7636 loss)
I0605 10:58:36.680999   904 sgd_solver.cpp:106] Iteration 86320, lr = 0.0196894
I0605 10:58:56.785619   904 solver.cpp:229] Iteration 86360, loss = 2.61179
I0605 10:58:56.785811   904 solver.cpp:245]     Train net output #0: loss = 2.50568 (* 1 = 2.50568 loss)
I0605 10:58:56.785832   904 sgd_solver.cpp:106] Iteration 86360, lr = 0.01968
I0605 10:59:17.056609   904 solver.cpp:229] Iteration 86400, loss = 2.61928
I0605 10:59:17.056666   904 solver.cpp:245]     Train net output #0: loss = 2.66092 (* 1 = 2.66092 loss)
I0605 10:59:17.056677   904 sgd_solver.cpp:106] Iteration 86400, lr = 0.0196706
I0605 10:59:37.335661   904 solver.cpp:229] Iteration 86440, loss = 2.67973
I0605 10:59:37.335829   904 solver.cpp:245]     Train net output #0: loss = 2.62562 (* 1 = 2.62562 loss)
I0605 10:59:37.335851   904 sgd_solver.cpp:106] Iteration 86440, lr = 0.0196612
I0605 10:59:57.550567   904 solver.cpp:229] Iteration 86480, loss = 2.68505
I0605 10:59:57.550616   904 solver.cpp:245]     Train net output #0: loss = 2.81118 (* 1 = 2.81118 loss)
I0605 10:59:57.550623   904 sgd_solver.cpp:106] Iteration 86480, lr = 0.0196518
I0605 11:00:17.723289   904 solver.cpp:229] Iteration 86520, loss = 2.64151
I0605 11:00:17.723495   904 solver.cpp:245]     Train net output #0: loss = 2.56372 (* 1 = 2.56372 loss)
I0605 11:00:17.723531   904 sgd_solver.cpp:106] Iteration 86520, lr = 0.0196424
I0605 11:00:38.002660   904 solver.cpp:229] Iteration 86560, loss = 2.65198
I0605 11:00:38.002715   904 solver.cpp:245]     Train net output #0: loss = 2.56535 (* 1 = 2.56535 loss)
I0605 11:00:38.002724   904 sgd_solver.cpp:106] Iteration 86560, lr = 0.0196329
I0605 11:00:58.258710   904 solver.cpp:229] Iteration 86600, loss = 2.62117
I0605 11:00:58.258901   904 solver.cpp:245]     Train net output #0: loss = 2.60813 (* 1 = 2.60813 loss)
I0605 11:00:58.258924   904 sgd_solver.cpp:106] Iteration 86600, lr = 0.0196235
I0605 11:01:18.523941   904 solver.cpp:229] Iteration 86640, loss = 2.63612
I0605 11:01:18.523986   904 solver.cpp:245]     Train net output #0: loss = 2.62129 (* 1 = 2.62129 loss)
I0605 11:01:18.523993   904 sgd_solver.cpp:106] Iteration 86640, lr = 0.0196141
I0605 11:01:38.781961   904 solver.cpp:229] Iteration 86680, loss = 2.62709
I0605 11:01:38.782155   904 solver.cpp:245]     Train net output #0: loss = 2.93432 (* 1 = 2.93432 loss)
I0605 11:01:38.782178   904 sgd_solver.cpp:106] Iteration 86680, lr = 0.0196047
I0605 11:01:49.430528   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 11:01:59.051328   904 solver.cpp:229] Iteration 86720, loss = 2.65799
I0605 11:01:59.051365   904 solver.cpp:245]     Train net output #0: loss = 2.83083 (* 1 = 2.83083 loss)
I0605 11:01:59.051374   904 sgd_solver.cpp:106] Iteration 86720, lr = 0.0195953
I0605 11:02:19.289469   904 solver.cpp:229] Iteration 86760, loss = 2.64715
I0605 11:02:19.289659   904 solver.cpp:245]     Train net output #0: loss = 2.51021 (* 1 = 2.51021 loss)
I0605 11:02:19.289690   904 sgd_solver.cpp:106] Iteration 86760, lr = 0.0195859
I0605 11:02:39.545292   904 solver.cpp:229] Iteration 86800, loss = 2.60292
I0605 11:02:39.545333   904 solver.cpp:245]     Train net output #0: loss = 2.39892 (* 1 = 2.39892 loss)
I0605 11:02:39.545342   904 sgd_solver.cpp:106] Iteration 86800, lr = 0.0195765
I0605 11:02:59.829115   904 solver.cpp:229] Iteration 86840, loss = 2.60786
I0605 11:02:59.829306   904 solver.cpp:245]     Train net output #0: loss = 2.56185 (* 1 = 2.56185 loss)
I0605 11:02:59.829346   904 sgd_solver.cpp:106] Iteration 86840, lr = 0.0195671
I0605 11:03:20.106180   904 solver.cpp:229] Iteration 86880, loss = 2.62603
I0605 11:03:20.106223   904 solver.cpp:245]     Train net output #0: loss = 2.66004 (* 1 = 2.66004 loss)
I0605 11:03:20.106232   904 sgd_solver.cpp:106] Iteration 86880, lr = 0.0195576
I0605 11:03:40.409265   904 solver.cpp:229] Iteration 86920, loss = 2.63194
I0605 11:03:40.409509   904 solver.cpp:245]     Train net output #0: loss = 2.51634 (* 1 = 2.51634 loss)
I0605 11:03:40.409533   904 sgd_solver.cpp:106] Iteration 86920, lr = 0.0195482
I0605 11:04:00.687554   904 solver.cpp:229] Iteration 86960, loss = 2.6589
I0605 11:04:00.687608   904 solver.cpp:245]     Train net output #0: loss = 2.49282 (* 1 = 2.49282 loss)
I0605 11:04:00.687628   904 sgd_solver.cpp:106] Iteration 86960, lr = 0.0195388
I0605 11:04:20.452519   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_87000.caffemodel
I0605 11:04:20.722385   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_87000.solverstate
I0605 11:04:20.791573   904 solver.cpp:338] Iteration 87000, Testing net (#0)
I0605 11:04:20.791652   904 net.cpp:748] Ignoring source layer loss
I0605 11:04:35.543998   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 11:05:09.578379   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 11:05:28.523489   904 solver.cpp:406]     Test net output #0: accuracy = 0.429541
I0605 11:05:28.523519   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.68304
I0605 11:05:28.836537   904 solver.cpp:229] Iteration 87000, loss = 2.62711
I0605 11:05:28.836590   904 solver.cpp:245]     Train net output #0: loss = 2.62926 (* 1 = 2.62926 loss)
I0605 11:05:28.836601   904 sgd_solver.cpp:106] Iteration 87000, lr = 0.0195294
I0605 11:05:48.023231   904 solver.cpp:229] Iteration 87040, loss = 2.61979
I0605 11:05:48.023442   904 solver.cpp:245]     Train net output #0: loss = 2.54587 (* 1 = 2.54587 loss)
I0605 11:05:48.023470   904 sgd_solver.cpp:106] Iteration 87040, lr = 0.01952
I0605 11:06:09.305975   904 solver.cpp:229] Iteration 87080, loss = 2.58175
I0605 11:06:09.306026   904 solver.cpp:245]     Train net output #0: loss = 2.36385 (* 1 = 2.36385 loss)
I0605 11:06:09.306035   904 sgd_solver.cpp:106] Iteration 87080, lr = 0.0195106
I0605 11:06:30.778841   904 solver.cpp:229] Iteration 87120, loss = 2.60382
I0605 11:06:30.779031   904 solver.cpp:245]     Train net output #0: loss = 2.55204 (* 1 = 2.55204 loss)
I0605 11:06:30.779054   904 sgd_solver.cpp:106] Iteration 87120, lr = 0.0195012
I0605 11:06:52.188136   904 solver.cpp:229] Iteration 87160, loss = 2.61434
I0605 11:06:52.188195   904 solver.cpp:245]     Train net output #0: loss = 2.77622 (* 1 = 2.77622 loss)
I0605 11:06:52.188205   904 sgd_solver.cpp:106] Iteration 87160, lr = 0.0194918
I0605 11:07:13.072605   904 solver.cpp:229] Iteration 87200, loss = 2.63349
I0605 11:07:13.072801   904 solver.cpp:245]     Train net output #0: loss = 2.47383 (* 1 = 2.47383 loss)
I0605 11:07:13.072827   904 sgd_solver.cpp:106] Iteration 87200, lr = 0.0194824
I0605 11:07:34.153054   904 solver.cpp:229] Iteration 87240, loss = 2.62313
I0605 11:07:34.153112   904 solver.cpp:245]     Train net output #0: loss = 2.65203 (* 1 = 2.65203 loss)
I0605 11:07:34.153120   904 sgd_solver.cpp:106] Iteration 87240, lr = 0.0194729
I0605 11:07:46.815186   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 11:07:55.197515   904 solver.cpp:229] Iteration 87280, loss = 2.61891
I0605 11:07:55.197554   904 solver.cpp:245]     Train net output #0: loss = 2.53154 (* 1 = 2.53154 loss)
I0605 11:07:55.197563   904 sgd_solver.cpp:106] Iteration 87280, lr = 0.0194635
I0605 11:08:16.122730   904 solver.cpp:229] Iteration 87320, loss = 2.64349
I0605 11:08:16.122781   904 solver.cpp:245]     Train net output #0: loss = 2.74765 (* 1 = 2.74765 loss)
I0605 11:08:16.122789   904 sgd_solver.cpp:106] Iteration 87320, lr = 0.0194541
I0605 11:08:37.071028   904 solver.cpp:229] Iteration 87360, loss = 2.65631
I0605 11:08:37.071239   904 solver.cpp:245]     Train net output #0: loss = 2.7003 (* 1 = 2.7003 loss)
I0605 11:08:37.071260   904 sgd_solver.cpp:106] Iteration 87360, lr = 0.0194447
I0605 11:08:58.016091   904 solver.cpp:229] Iteration 87400, loss = 2.6393
I0605 11:08:58.016142   904 solver.cpp:245]     Train net output #0: loss = 2.62977 (* 1 = 2.62977 loss)
I0605 11:08:58.016150   904 sgd_solver.cpp:106] Iteration 87400, lr = 0.0194353
I0605 11:09:18.816150   904 solver.cpp:229] Iteration 87440, loss = 2.59547
I0605 11:09:18.816365   904 solver.cpp:245]     Train net output #0: loss = 2.47812 (* 1 = 2.47812 loss)
I0605 11:09:18.816390   904 sgd_solver.cpp:106] Iteration 87440, lr = 0.0194259
I0605 11:09:39.579215   904 solver.cpp:229] Iteration 87480, loss = 2.62837
I0605 11:09:39.579263   904 solver.cpp:245]     Train net output #0: loss = 2.70598 (* 1 = 2.70598 loss)
I0605 11:09:39.579272   904 sgd_solver.cpp:106] Iteration 87480, lr = 0.0194165
I0605 11:10:00.377581   904 solver.cpp:229] Iteration 87520, loss = 2.65546
I0605 11:10:00.377802   904 solver.cpp:245]     Train net output #0: loss = 2.34863 (* 1 = 2.34863 loss)
I0605 11:10:00.377827   904 sgd_solver.cpp:106] Iteration 87520, lr = 0.0194071
I0605 11:10:21.156520   904 solver.cpp:229] Iteration 87560, loss = 2.63467
I0605 11:10:21.156580   904 solver.cpp:245]     Train net output #0: loss = 2.6759 (* 1 = 2.6759 loss)
I0605 11:10:21.156590   904 sgd_solver.cpp:106] Iteration 87560, lr = 0.0193976
I0605 11:10:41.838579   904 solver.cpp:229] Iteration 87600, loss = 2.65321
I0605 11:10:41.838737   904 solver.cpp:245]     Train net output #0: loss = 2.73165 (* 1 = 2.73165 loss)
I0605 11:10:41.838754   904 sgd_solver.cpp:106] Iteration 87600, lr = 0.0193882
I0605 11:11:02.487778   904 solver.cpp:229] Iteration 87640, loss = 2.67458
I0605 11:11:02.487815   904 solver.cpp:245]     Train net output #0: loss = 2.56914 (* 1 = 2.56914 loss)
I0605 11:11:02.487824   904 sgd_solver.cpp:106] Iteration 87640, lr = 0.0193788
I0605 11:11:23.115959   904 solver.cpp:229] Iteration 87680, loss = 2.64349
I0605 11:11:23.116134   904 solver.cpp:245]     Train net output #0: loss = 2.62727 (* 1 = 2.62727 loss)
I0605 11:11:23.116156   904 sgd_solver.cpp:106] Iteration 87680, lr = 0.0193694
I0605 11:11:43.871240   904 solver.cpp:229] Iteration 87720, loss = 2.63583
I0605 11:11:43.871278   904 solver.cpp:245]     Train net output #0: loss = 2.53675 (* 1 = 2.53675 loss)
I0605 11:11:43.871284   904 sgd_solver.cpp:106] Iteration 87720, lr = 0.01936
I0605 11:12:04.339570   904 solver.cpp:229] Iteration 87760, loss = 2.64253
I0605 11:12:04.339759   904 solver.cpp:245]     Train net output #0: loss = 2.49807 (* 1 = 2.49807 loss)
I0605 11:12:04.339793   904 sgd_solver.cpp:106] Iteration 87760, lr = 0.0193506
I0605 11:12:24.894235   904 solver.cpp:229] Iteration 87800, loss = 2.62037
I0605 11:12:24.894280   904 solver.cpp:245]     Train net output #0: loss = 3.04945 (* 1 = 3.04945 loss)
I0605 11:12:24.894289   904 sgd_solver.cpp:106] Iteration 87800, lr = 0.0193412
I0605 11:12:31.073829   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 11:12:45.429675   904 solver.cpp:229] Iteration 87840, loss = 2.64363
I0605 11:12:45.429796   904 solver.cpp:245]     Train net output #0: loss = 2.7362 (* 1 = 2.7362 loss)
I0605 11:12:45.429807   904 sgd_solver.cpp:106] Iteration 87840, lr = 0.0193318
I0605 11:13:05.893240   904 solver.cpp:229] Iteration 87880, loss = 2.63345
I0605 11:13:05.893287   904 solver.cpp:245]     Train net output #0: loss = 2.6179 (* 1 = 2.6179 loss)
I0605 11:13:05.893299   904 sgd_solver.cpp:106] Iteration 87880, lr = 0.0193224
I0605 11:13:26.338505   904 solver.cpp:229] Iteration 87920, loss = 2.60318
I0605 11:13:26.338639   904 solver.cpp:245]     Train net output #0: loss = 2.4263 (* 1 = 2.4263 loss)
I0605 11:13:26.338649   904 sgd_solver.cpp:106] Iteration 87920, lr = 0.0193129
I0605 11:13:46.795336   904 solver.cpp:229] Iteration 87960, loss = 2.6134
I0605 11:13:46.795375   904 solver.cpp:245]     Train net output #0: loss = 2.67863 (* 1 = 2.67863 loss)
I0605 11:13:46.795383   904 sgd_solver.cpp:106] Iteration 87960, lr = 0.0193035
I0605 11:14:06.726251   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_88000.caffemodel
I0605 11:14:06.994560   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_88000.solverstate
I0605 11:14:07.075451   904 solver.cpp:338] Iteration 88000, Testing net (#0)
I0605 11:14:07.075526   904 net.cpp:748] Ignoring source layer loss
I0605 11:14:32.957470   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 11:15:06.655087   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 11:15:14.534219   904 solver.cpp:406]     Test net output #0: accuracy = 0.435781
I0605 11:15:14.534262   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.685359
I0605 11:15:14.849206   904 solver.cpp:229] Iteration 88000, loss = 2.59824
I0605 11:15:14.849254   904 solver.cpp:245]     Train net output #0: loss = 2.75131 (* 1 = 2.75131 loss)
I0605 11:15:14.849267   904 sgd_solver.cpp:106] Iteration 88000, lr = 0.0192941
I0605 11:15:34.086645   904 solver.cpp:229] Iteration 88040, loss = 2.64282
I0605 11:15:34.086699   904 solver.cpp:245]     Train net output #0: loss = 2.58869 (* 1 = 2.58869 loss)
I0605 11:15:34.086709   904 sgd_solver.cpp:106] Iteration 88040, lr = 0.0192847
I0605 11:15:55.534448   904 solver.cpp:229] Iteration 88080, loss = 2.6934
I0605 11:15:55.534592   904 solver.cpp:245]     Train net output #0: loss = 2.25368 (* 1 = 2.25368 loss)
I0605 11:15:55.534608   904 sgd_solver.cpp:106] Iteration 88080, lr = 0.0192753
I0605 11:16:17.081480   904 solver.cpp:229] Iteration 88120, loss = 2.61097
I0605 11:16:17.081604   904 solver.cpp:245]     Train net output #0: loss = 2.63134 (* 1 = 2.63134 loss)
I0605 11:16:17.081629   904 sgd_solver.cpp:106] Iteration 88120, lr = 0.0192659
I0605 11:16:38.197842   904 solver.cpp:229] Iteration 88160, loss = 2.59455
I0605 11:16:38.208461   904 solver.cpp:245]     Train net output #0: loss = 2.54736 (* 1 = 2.54736 loss)
I0605 11:16:38.208474   904 sgd_solver.cpp:106] Iteration 88160, lr = 0.0192565
I0605 11:16:59.211540   904 solver.cpp:229] Iteration 88200, loss = 2.61369
I0605 11:16:59.211586   904 solver.cpp:245]     Train net output #0: loss = 2.67578 (* 1 = 2.67578 loss)
I0605 11:16:59.211596   904 sgd_solver.cpp:106] Iteration 88200, lr = 0.0192471
I0605 11:17:20.182095   904 solver.cpp:229] Iteration 88240, loss = 2.62843
I0605 11:17:20.182272   904 solver.cpp:245]     Train net output #0: loss = 2.68292 (* 1 = 2.68292 loss)
I0605 11:17:20.182284   904 sgd_solver.cpp:106] Iteration 88240, lr = 0.0192376
I0605 11:17:41.187861   904 solver.cpp:229] Iteration 88280, loss = 2.58853
I0605 11:17:41.187917   904 solver.cpp:245]     Train net output #0: loss = 2.60631 (* 1 = 2.60631 loss)
I0605 11:17:41.187928   904 sgd_solver.cpp:106] Iteration 88280, lr = 0.0192282
I0605 11:18:02.089026   904 solver.cpp:229] Iteration 88320, loss = 2.64785
I0605 11:18:02.089171   904 solver.cpp:245]     Train net output #0: loss = 2.65206 (* 1 = 2.65206 loss)
I0605 11:18:02.089184   904 sgd_solver.cpp:106] Iteration 88320, lr = 0.0192188
I0605 11:18:22.947178   904 solver.cpp:229] Iteration 88360, loss = 2.64219
I0605 11:18:22.947235   904 solver.cpp:245]     Train net output #0: loss = 2.44122 (* 1 = 2.44122 loss)
I0605 11:18:22.947245   904 sgd_solver.cpp:106] Iteration 88360, lr = 0.0192094
I0605 11:18:43.637712   904 solver.cpp:229] Iteration 88400, loss = 2.59572
I0605 11:18:43.637918   904 solver.cpp:245]     Train net output #0: loss = 2.58105 (* 1 = 2.58105 loss)
I0605 11:18:43.637944   904 sgd_solver.cpp:106] Iteration 88400, lr = 0.0192
I0605 11:18:54.423974   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 11:19:04.228467   904 solver.cpp:229] Iteration 88440, loss = 2.60109
I0605 11:19:04.228516   904 solver.cpp:245]     Train net output #0: loss = 2.71645 (* 1 = 2.71645 loss)
I0605 11:19:04.228536   904 sgd_solver.cpp:106] Iteration 88440, lr = 0.0191906
I0605 11:19:24.924312   904 solver.cpp:229] Iteration 88480, loss = 2.59868
I0605 11:19:24.924546   904 solver.cpp:245]     Train net output #0: loss = 2.4291 (* 1 = 2.4291 loss)
I0605 11:19:24.924572   904 sgd_solver.cpp:106] Iteration 88480, lr = 0.0191812
I0605 11:19:45.588048   904 solver.cpp:229] Iteration 88520, loss = 2.57879
I0605 11:19:45.588110   904 solver.cpp:245]     Train net output #0: loss = 2.47276 (* 1 = 2.47276 loss)
I0605 11:19:45.588119   904 sgd_solver.cpp:106] Iteration 88520, lr = 0.0191718
I0605 11:20:06.124461   904 solver.cpp:229] Iteration 88560, loss = 2.63151
I0605 11:20:06.124670   904 solver.cpp:245]     Train net output #0: loss = 2.36942 (* 1 = 2.36942 loss)
I0605 11:20:06.124682   904 sgd_solver.cpp:106] Iteration 88560, lr = 0.0191624
I0605 11:20:26.659561   904 solver.cpp:229] Iteration 88600, loss = 2.58223
I0605 11:20:26.659612   904 solver.cpp:245]     Train net output #0: loss = 2.4776 (* 1 = 2.4776 loss)
I0605 11:20:26.659621   904 sgd_solver.cpp:106] Iteration 88600, lr = 0.0191529
I0605 11:20:47.178333   904 solver.cpp:229] Iteration 88640, loss = 2.64442
I0605 11:20:47.178565   904 solver.cpp:245]     Train net output #0: loss = 2.47747 (* 1 = 2.47747 loss)
I0605 11:20:47.178592   904 sgd_solver.cpp:106] Iteration 88640, lr = 0.0191435
I0605 11:21:07.717361   904 solver.cpp:229] Iteration 88680, loss = 2.61137
I0605 11:21:07.717401   904 solver.cpp:245]     Train net output #0: loss = 2.63477 (* 1 = 2.63477 loss)
I0605 11:21:07.717408   904 sgd_solver.cpp:106] Iteration 88680, lr = 0.0191341
I0605 11:21:28.225615   904 solver.cpp:229] Iteration 88720, loss = 2.644
I0605 11:21:28.225862   904 solver.cpp:245]     Train net output #0: loss = 2.63259 (* 1 = 2.63259 loss)
I0605 11:21:28.225881   904 sgd_solver.cpp:106] Iteration 88720, lr = 0.0191247
I0605 11:21:48.757716   904 solver.cpp:229] Iteration 88760, loss = 2.64048
I0605 11:21:48.757774   904 solver.cpp:245]     Train net output #0: loss = 2.6959 (* 1 = 2.6959 loss)
I0605 11:21:48.757789   904 sgd_solver.cpp:106] Iteration 88760, lr = 0.0191153
I0605 11:22:09.292459   904 solver.cpp:229] Iteration 88800, loss = 2.61345
I0605 11:22:09.292598   904 solver.cpp:245]     Train net output #0: loss = 2.54775 (* 1 = 2.54775 loss)
I0605 11:22:09.292609   904 sgd_solver.cpp:106] Iteration 88800, lr = 0.0191059
I0605 11:22:29.808447   904 solver.cpp:229] Iteration 88840, loss = 2.58994
I0605 11:22:29.808522   904 solver.cpp:245]     Train net output #0: loss = 2.57404 (* 1 = 2.57404 loss)
I0605 11:22:29.808543   904 sgd_solver.cpp:106] Iteration 88840, lr = 0.0190965
I0605 11:22:50.115859   904 solver.cpp:229] Iteration 88880, loss = 2.57277
I0605 11:22:50.116089   904 solver.cpp:245]     Train net output #0: loss = 2.58213 (* 1 = 2.58213 loss)
I0605 11:22:50.116112   904 sgd_solver.cpp:106] Iteration 88880, lr = 0.0190871
I0605 11:23:10.435838   904 solver.cpp:229] Iteration 88920, loss = 2.61187
I0605 11:23:10.435889   904 solver.cpp:245]     Train net output #0: loss = 2.59838 (* 1 = 2.59838 loss)
I0605 11:23:10.435900   904 sgd_solver.cpp:106] Iteration 88920, lr = 0.0190776
I0605 11:23:21.610896   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 11:23:30.747563   904 solver.cpp:229] Iteration 88960, loss = 2.60762
I0605 11:23:30.747623   904 solver.cpp:245]     Train net output #0: loss = 2.91868 (* 1 = 2.91868 loss)
I0605 11:23:30.747634   904 sgd_solver.cpp:106] Iteration 88960, lr = 0.0190682
I0605 11:23:50.597069   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_89000.caffemodel
I0605 11:23:50.864083   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_89000.solverstate
I0605 11:23:50.941159   904 solver.cpp:338] Iteration 89000, Testing net (#0)
I0605 11:23:50.941241   904 net.cpp:748] Ignoring source layer loss
I0605 11:24:21.808190   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 11:24:56.811874   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 11:25:00.429651   904 solver.cpp:406]     Test net output #0: accuracy = 0.432861
I0605 11:25:00.429704   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.682399
I0605 11:25:00.745584   904 solver.cpp:229] Iteration 89000, loss = 2.63891
I0605 11:25:00.745625   904 solver.cpp:245]     Train net output #0: loss = 2.64867 (* 1 = 2.64867 loss)
I0605 11:25:00.745632   904 sgd_solver.cpp:106] Iteration 89000, lr = 0.0190588
I0605 11:25:19.945437   904 solver.cpp:229] Iteration 89040, loss = 2.63813
I0605 11:25:19.945485   904 solver.cpp:245]     Train net output #0: loss = 2.42866 (* 1 = 2.42866 loss)
I0605 11:25:19.945497   904 sgd_solver.cpp:106] Iteration 89040, lr = 0.0190494
I0605 11:25:41.243342   904 solver.cpp:229] Iteration 89080, loss = 2.59904
I0605 11:25:41.243635   904 solver.cpp:245]     Train net output #0: loss = 2.3705 (* 1 = 2.3705 loss)
I0605 11:25:41.243659   904 sgd_solver.cpp:106] Iteration 89080, lr = 0.01904
I0605 11:26:02.763943   904 solver.cpp:229] Iteration 89120, loss = 2.63206
I0605 11:26:02.763988   904 solver.cpp:245]     Train net output #0: loss = 2.65996 (* 1 = 2.65996 loss)
I0605 11:26:02.763998   904 sgd_solver.cpp:106] Iteration 89120, lr = 0.0190306
I0605 11:26:23.706826   904 solver.cpp:229] Iteration 89160, loss = 2.63143
I0605 11:26:23.706995   904 solver.cpp:245]     Train net output #0: loss = 2.54314 (* 1 = 2.54314 loss)
I0605 11:26:23.707006   904 sgd_solver.cpp:106] Iteration 89160, lr = 0.0190212
I0605 11:26:44.633687   904 solver.cpp:229] Iteration 89200, loss = 2.63243
I0605 11:26:44.633747   904 solver.cpp:245]     Train net output #0: loss = 2.72443 (* 1 = 2.72443 loss)
I0605 11:26:44.633757   904 sgd_solver.cpp:106] Iteration 89200, lr = 0.0190118
I0605 11:27:05.584131   904 solver.cpp:229] Iteration 89240, loss = 2.6206
I0605 11:27:05.584285   904 solver.cpp:245]     Train net output #0: loss = 2.56551 (* 1 = 2.56551 loss)
I0605 11:27:05.584311   904 sgd_solver.cpp:106] Iteration 89240, lr = 0.0190024
I0605 11:27:26.576772   904 solver.cpp:229] Iteration 89280, loss = 2.64384
I0605 11:27:26.576829   904 solver.cpp:245]     Train net output #0: loss = 2.7855 (* 1 = 2.7855 loss)
I0605 11:27:26.576841   904 sgd_solver.cpp:106] Iteration 89280, lr = 0.0189929
I0605 11:27:47.345496   904 solver.cpp:229] Iteration 89320, loss = 2.58229
I0605 11:27:47.345679   904 solver.cpp:245]     Train net output #0: loss = 2.79395 (* 1 = 2.79395 loss)
I0605 11:27:47.345696   904 sgd_solver.cpp:106] Iteration 89320, lr = 0.0189835
I0605 11:28:08.033473   904 solver.cpp:229] Iteration 89360, loss = 2.61059
I0605 11:28:08.033515   904 solver.cpp:245]     Train net output #0: loss = 2.84483 (* 1 = 2.84483 loss)
I0605 11:28:08.033524   904 sgd_solver.cpp:106] Iteration 89360, lr = 0.0189741
I0605 11:28:28.718201   904 solver.cpp:229] Iteration 89400, loss = 2.60121
I0605 11:28:28.718340   904 solver.cpp:245]     Train net output #0: loss = 2.84724 (* 1 = 2.84724 loss)
I0605 11:28:28.718353   904 sgd_solver.cpp:106] Iteration 89400, lr = 0.0189647
I0605 11:28:49.439342   904 solver.cpp:229] Iteration 89440, loss = 2.63988
I0605 11:28:49.439393   904 solver.cpp:245]     Train net output #0: loss = 2.63498 (* 1 = 2.63498 loss)
I0605 11:28:49.439401   904 sgd_solver.cpp:106] Iteration 89440, lr = 0.0189553
I0605 11:29:02.544482   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 11:29:09.977007   904 solver.cpp:229] Iteration 89480, loss = 2.60294
I0605 11:29:09.977062   904 solver.cpp:245]     Train net output #0: loss = 2.70966 (* 1 = 2.70966 loss)
I0605 11:29:09.977075   904 sgd_solver.cpp:106] Iteration 89480, lr = 0.0189459
I0605 11:29:30.455987   904 solver.cpp:229] Iteration 89520, loss = 2.61392
I0605 11:29:30.456065   904 solver.cpp:245]     Train net output #0: loss = 2.77607 (* 1 = 2.77607 loss)
I0605 11:29:30.456075   904 sgd_solver.cpp:106] Iteration 89520, lr = 0.0189365
I0605 11:29:51.051947   904 solver.cpp:229] Iteration 89560, loss = 2.59068
I0605 11:29:51.052139   904 solver.cpp:245]     Train net output #0: loss = 2.79429 (* 1 = 2.79429 loss)
I0605 11:29:51.052166   904 sgd_solver.cpp:106] Iteration 89560, lr = 0.0189271
I0605 11:30:11.557756   904 solver.cpp:229] Iteration 89600, loss = 2.61571
I0605 11:30:11.557809   904 solver.cpp:245]     Train net output #0: loss = 2.82329 (* 1 = 2.82329 loss)
I0605 11:30:11.557819   904 sgd_solver.cpp:106] Iteration 89600, lr = 0.0189176
I0605 11:30:32.065976   904 solver.cpp:229] Iteration 89640, loss = 2.59073
I0605 11:30:32.066165   904 solver.cpp:245]     Train net output #0: loss = 2.52086 (* 1 = 2.52086 loss)
I0605 11:30:32.066177   904 sgd_solver.cpp:106] Iteration 89640, lr = 0.0189082
I0605 11:30:52.694715   904 solver.cpp:229] Iteration 89680, loss = 2.59512
I0605 11:30:52.694763   904 solver.cpp:245]     Train net output #0: loss = 2.63642 (* 1 = 2.63642 loss)
I0605 11:30:52.694773   904 sgd_solver.cpp:106] Iteration 89680, lr = 0.0188988
I0605 11:31:13.071559   904 solver.cpp:229] Iteration 89720, loss = 2.61278
I0605 11:31:13.071780   904 solver.cpp:245]     Train net output #0: loss = 2.52458 (* 1 = 2.52458 loss)
I0605 11:31:13.071807   904 sgd_solver.cpp:106] Iteration 89720, lr = 0.0188894
I0605 11:31:33.333053   904 solver.cpp:229] Iteration 89760, loss = 2.64744
I0605 11:31:33.333122   904 solver.cpp:245]     Train net output #0: loss = 2.38528 (* 1 = 2.38528 loss)
I0605 11:31:33.333144   904 sgd_solver.cpp:106] Iteration 89760, lr = 0.01888
I0605 11:31:53.728471   904 solver.cpp:229] Iteration 89800, loss = 2.57437
I0605 11:31:53.728693   904 solver.cpp:245]     Train net output #0: loss = 2.54133 (* 1 = 2.54133 loss)
I0605 11:31:53.728723   904 sgd_solver.cpp:106] Iteration 89800, lr = 0.0188706
I0605 11:32:14.226502   904 solver.cpp:229] Iteration 89840, loss = 2.66038
I0605 11:32:14.226552   904 solver.cpp:245]     Train net output #0: loss = 2.71349 (* 1 = 2.71349 loss)
I0605 11:32:14.226560   904 sgd_solver.cpp:106] Iteration 89840, lr = 0.0188612
I0605 11:32:34.552391   904 solver.cpp:229] Iteration 89880, loss = 2.64473
I0605 11:32:34.552597   904 solver.cpp:245]     Train net output #0: loss = 2.48985 (* 1 = 2.48985 loss)
I0605 11:32:34.552623   904 sgd_solver.cpp:106] Iteration 89880, lr = 0.0188518
I0605 11:32:54.829504   904 solver.cpp:229] Iteration 89920, loss = 2.59377
I0605 11:32:54.829572   904 solver.cpp:245]     Train net output #0: loss = 2.81981 (* 1 = 2.81981 loss)
I0605 11:32:54.829582   904 sgd_solver.cpp:106] Iteration 89920, lr = 0.0188424
I0605 11:33:15.105382   904 solver.cpp:229] Iteration 89960, loss = 2.63602
I0605 11:33:15.105522   904 solver.cpp:245]     Train net output #0: loss = 2.65224 (* 1 = 2.65224 loss)
I0605 11:33:15.105535   904 sgd_solver.cpp:106] Iteration 89960, lr = 0.0188329
I0605 11:33:25.254253   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 11:33:34.888532   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_90000.caffemodel
I0605 11:33:35.153713   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_90000.solverstate
I0605 11:33:35.230875   904 solver.cpp:338] Iteration 90000, Testing net (#0)
I0605 11:33:35.230952   904 net.cpp:748] Ignoring source layer loss
I0605 11:34:11.733785   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 11:34:49.789613   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 11:34:50.983989   904 solver.cpp:406]     Test net output #0: accuracy = 0.422761
I0605 11:34:50.984028   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.67454
I0605 11:34:51.300865   904 solver.cpp:229] Iteration 90000, loss = 2.63613
I0605 11:34:51.300916   904 solver.cpp:245]     Train net output #0: loss = 2.83313 (* 1 = 2.83313 loss)
I0605 11:34:51.300925   904 sgd_solver.cpp:106] Iteration 90000, lr = 0.0188235
I0605 11:35:10.468302   904 solver.cpp:229] Iteration 90040, loss = 2.6577
I0605 11:35:10.468355   904 solver.cpp:245]     Train net output #0: loss = 3.04867 (* 1 = 3.04867 loss)
I0605 11:35:10.468365   904 sgd_solver.cpp:106] Iteration 90040, lr = 0.0188141
I0605 11:35:31.855520   904 solver.cpp:229] Iteration 90080, loss = 2.62355
I0605 11:35:31.855628   904 solver.cpp:245]     Train net output #0: loss = 2.70804 (* 1 = 2.70804 loss)
I0605 11:35:31.855640   904 sgd_solver.cpp:106] Iteration 90080, lr = 0.0188047
I0605 11:35:53.177676   904 solver.cpp:229] Iteration 90120, loss = 2.62408
I0605 11:35:53.177727   904 solver.cpp:245]     Train net output #0: loss = 2.73672 (* 1 = 2.73672 loss)
I0605 11:35:53.177738   904 sgd_solver.cpp:106] Iteration 90120, lr = 0.0187953
I0605 11:36:14.085129   904 solver.cpp:229] Iteration 90160, loss = 2.62138
I0605 11:36:14.085419   904 solver.cpp:245]     Train net output #0: loss = 2.44064 (* 1 = 2.44064 loss)
I0605 11:36:14.085445   904 sgd_solver.cpp:106] Iteration 90160, lr = 0.0187859
I0605 11:36:34.869537   904 solver.cpp:229] Iteration 90200, loss = 2.63327
I0605 11:36:34.869655   904 solver.cpp:245]     Train net output #0: loss = 2.45454 (* 1 = 2.45454 loss)
I0605 11:36:34.869678   904 sgd_solver.cpp:106] Iteration 90200, lr = 0.0187765
I0605 11:36:55.644778   904 solver.cpp:229] Iteration 90240, loss = 2.61638
I0605 11:36:55.645032   904 solver.cpp:245]     Train net output #0: loss = 2.82426 (* 1 = 2.82426 loss)
I0605 11:36:55.645069   904 sgd_solver.cpp:106] Iteration 90240, lr = 0.0187671
I0605 11:37:16.404111   904 solver.cpp:229] Iteration 90280, loss = 2.64334
I0605 11:37:16.404161   904 solver.cpp:245]     Train net output #0: loss = 2.75982 (* 1 = 2.75982 loss)
I0605 11:37:16.404172   904 sgd_solver.cpp:106] Iteration 90280, lr = 0.0187576
I0605 11:37:37.193470   904 solver.cpp:229] Iteration 90320, loss = 2.62828
I0605 11:37:37.193707   904 solver.cpp:245]     Train net output #0: loss = 2.82373 (* 1 = 2.82373 loss)
I0605 11:37:37.193734   904 sgd_solver.cpp:106] Iteration 90320, lr = 0.0187482
I0605 11:37:58.039511   904 solver.cpp:229] Iteration 90360, loss = 2.61907
I0605 11:37:58.039563   904 solver.cpp:245]     Train net output #0: loss = 2.76096 (* 1 = 2.76096 loss)
I0605 11:37:58.039572   904 sgd_solver.cpp:106] Iteration 90360, lr = 0.0187388
I0605 11:38:18.780774   904 solver.cpp:229] Iteration 90400, loss = 2.61192
I0605 11:38:18.780932   904 solver.cpp:245]     Train net output #0: loss = 2.74513 (* 1 = 2.74513 loss)
I0605 11:38:18.780944   904 sgd_solver.cpp:106] Iteration 90400, lr = 0.0187294
I0605 11:38:39.440822   904 solver.cpp:229] Iteration 90440, loss = 2.5695
I0605 11:38:39.440871   904 solver.cpp:245]     Train net output #0: loss = 2.78675 (* 1 = 2.78675 loss)
I0605 11:38:39.440882   904 sgd_solver.cpp:106] Iteration 90440, lr = 0.01872
I0605 11:39:00.102978   904 solver.cpp:229] Iteration 90480, loss = 2.57765
I0605 11:39:00.103158   904 solver.cpp:245]     Train net output #0: loss = 2.85643 (* 1 = 2.85643 loss)
I0605 11:39:00.103186   904 sgd_solver.cpp:106] Iteration 90480, lr = 0.0187106
I0605 11:39:08.103564   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 11:39:20.745939   904 solver.cpp:229] Iteration 90520, loss = 2.60601
I0605 11:39:20.745996   904 solver.cpp:245]     Train net output #0: loss = 2.5505 (* 1 = 2.5505 loss)
I0605 11:39:20.746006   904 sgd_solver.cpp:106] Iteration 90520, lr = 0.0187012
I0605 11:39:41.413344   904 solver.cpp:229] Iteration 90560, loss = 2.6497
I0605 11:39:41.413532   904 solver.cpp:245]     Train net output #0: loss = 2.59014 (* 1 = 2.59014 loss)
I0605 11:39:41.413557   904 sgd_solver.cpp:106] Iteration 90560, lr = 0.0186918
I0605 11:40:01.943899   904 solver.cpp:229] Iteration 90600, loss = 2.62154
I0605 11:40:01.943969   904 solver.cpp:245]     Train net output #0: loss = 2.43323 (* 1 = 2.43323 loss)
I0605 11:40:01.943979   904 sgd_solver.cpp:106] Iteration 90600, lr = 0.0186824
I0605 11:40:22.517110   904 solver.cpp:229] Iteration 90640, loss = 2.58722
I0605 11:40:22.517364   904 solver.cpp:245]     Train net output #0: loss = 2.49526 (* 1 = 2.49526 loss)
I0605 11:40:22.517391   904 sgd_solver.cpp:106] Iteration 90640, lr = 0.0186729
I0605 11:40:43.134651   904 solver.cpp:229] Iteration 90680, loss = 2.599
I0605 11:40:43.134707   904 solver.cpp:245]     Train net output #0: loss = 2.32111 (* 1 = 2.32111 loss)
I0605 11:40:43.134721   904 sgd_solver.cpp:106] Iteration 90680, lr = 0.0186635
I0605 11:41:03.690692   904 solver.cpp:229] Iteration 90720, loss = 2.62019
I0605 11:41:03.690887   904 solver.cpp:245]     Train net output #0: loss = 2.92877 (* 1 = 2.92877 loss)
I0605 11:41:03.690913   904 sgd_solver.cpp:106] Iteration 90720, lr = 0.0186541
I0605 11:41:24.201161   904 solver.cpp:229] Iteration 90760, loss = 2.62089
I0605 11:41:24.201208   904 solver.cpp:245]     Train net output #0: loss = 2.53965 (* 1 = 2.53965 loss)
I0605 11:41:24.201221   904 sgd_solver.cpp:106] Iteration 90760, lr = 0.0186447
I0605 11:41:44.659109   904 solver.cpp:229] Iteration 90800, loss = 2.61204
I0605 11:41:44.659387   904 solver.cpp:245]     Train net output #0: loss = 2.87001 (* 1 = 2.87001 loss)
I0605 11:41:44.659415   904 sgd_solver.cpp:106] Iteration 90800, lr = 0.0186353
I0605 11:42:05.149286   904 solver.cpp:229] Iteration 90840, loss = 2.6341
I0605 11:42:05.149325   904 solver.cpp:245]     Train net output #0: loss = 2.68975 (* 1 = 2.68975 loss)
I0605 11:42:05.149334   904 sgd_solver.cpp:106] Iteration 90840, lr = 0.0186259
I0605 11:42:25.631829   904 solver.cpp:229] Iteration 90880, loss = 2.61569
I0605 11:42:25.632052   904 solver.cpp:245]     Train net output #0: loss = 2.49091 (* 1 = 2.49091 loss)
I0605 11:42:25.632079   904 sgd_solver.cpp:106] Iteration 90880, lr = 0.0186165
I0605 11:42:46.110610   904 solver.cpp:229] Iteration 90920, loss = 2.58426
I0605 11:42:46.110656   904 solver.cpp:245]     Train net output #0: loss = 2.45872 (* 1 = 2.45872 loss)
I0605 11:42:46.110666   904 sgd_solver.cpp:106] Iteration 90920, lr = 0.0186071
I0605 11:43:06.677301   904 solver.cpp:229] Iteration 90960, loss = 2.57164
I0605 11:43:06.677513   904 solver.cpp:245]     Train net output #0: loss = 2.40408 (* 1 = 2.40408 loss)
I0605 11:43:06.677536   904 sgd_solver.cpp:106] Iteration 90960, lr = 0.0185976
I0605 11:43:26.512367   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_91000.caffemodel
I0605 11:43:26.775681   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_91000.solverstate
I0605 11:43:26.855224   904 solver.cpp:338] Iteration 91000, Testing net (#0)
I0605 11:43:26.855304   904 net.cpp:748] Ignoring source layer loss
I0605 11:43:28.121845   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 11:44:03.070677   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 11:44:37.428282   904 solver.cpp:406]     Test net output #0: accuracy = 0.429961
I0605 11:44:37.428443   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.6833
I0605 11:44:37.743859   904 solver.cpp:229] Iteration 91000, loss = 2.58526
I0605 11:44:37.743899   904 solver.cpp:245]     Train net output #0: loss = 2.49489 (* 1 = 2.49489 loss)
I0605 11:44:37.743907   904 sgd_solver.cpp:106] Iteration 91000, lr = 0.0185882
I0605 11:44:46.407660   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 11:44:56.983011   904 solver.cpp:229] Iteration 91040, loss = 2.575
I0605 11:44:56.983057   904 solver.cpp:245]     Train net output #0: loss = 2.55001 (* 1 = 2.55001 loss)
I0605 11:44:56.983068   904 sgd_solver.cpp:106] Iteration 91040, lr = 0.0185788
I0605 11:45:18.356902   904 solver.cpp:229] Iteration 91080, loss = 2.60908
I0605 11:45:18.357058   904 solver.cpp:245]     Train net output #0: loss = 2.55762 (* 1 = 2.55762 loss)
I0605 11:45:18.357069   904 sgd_solver.cpp:106] Iteration 91080, lr = 0.0185694
I0605 11:45:39.777747   904 solver.cpp:229] Iteration 91120, loss = 2.57872
I0605 11:45:39.777806   904 solver.cpp:245]     Train net output #0: loss = 2.56344 (* 1 = 2.56344 loss)
I0605 11:45:39.777817   904 sgd_solver.cpp:106] Iteration 91120, lr = 0.01856
I0605 11:46:00.764972   904 solver.cpp:229] Iteration 91160, loss = 2.58556
I0605 11:46:00.765156   904 solver.cpp:245]     Train net output #0: loss = 2.30623 (* 1 = 2.30623 loss)
I0605 11:46:00.765173   904 sgd_solver.cpp:106] Iteration 91160, lr = 0.0185506
I0605 11:46:21.760329   904 solver.cpp:229] Iteration 91200, loss = 2.59551
I0605 11:46:21.760370   904 solver.cpp:245]     Train net output #0: loss = 2.85013 (* 1 = 2.85013 loss)
I0605 11:46:21.760385   904 sgd_solver.cpp:106] Iteration 91200, lr = 0.0185412
I0605 11:46:42.751415   904 solver.cpp:229] Iteration 91240, loss = 2.63371
I0605 11:46:42.751673   904 solver.cpp:245]     Train net output #0: loss = 2.64063 (* 1 = 2.64063 loss)
I0605 11:46:42.751699   904 sgd_solver.cpp:106] Iteration 91240, lr = 0.0185318
I0605 11:47:03.796916   904 solver.cpp:229] Iteration 91280, loss = 2.63145
I0605 11:47:03.796965   904 solver.cpp:245]     Train net output #0: loss = 2.77214 (* 1 = 2.77214 loss)
I0605 11:47:03.796977   904 sgd_solver.cpp:106] Iteration 91280, lr = 0.0185224
I0605 11:47:24.647083   904 solver.cpp:229] Iteration 91320, loss = 2.60329
I0605 11:47:24.647264   904 solver.cpp:245]     Train net output #0: loss = 2.6705 (* 1 = 2.6705 loss)
I0605 11:47:24.647287   904 sgd_solver.cpp:106] Iteration 91320, lr = 0.0185129
I0605 11:47:45.337075   904 solver.cpp:229] Iteration 91360, loss = 2.60033
I0605 11:47:45.337144   904 solver.cpp:245]     Train net output #0: loss = 2.49152 (* 1 = 2.49152 loss)
I0605 11:47:45.337157   904 sgd_solver.cpp:106] Iteration 91360, lr = 0.0185035
I0605 11:48:05.972723   904 solver.cpp:229] Iteration 91400, loss = 2.55368
I0605 11:48:05.972935   904 solver.cpp:245]     Train net output #0: loss = 2.26673 (* 1 = 2.26673 loss)
I0605 11:48:05.972961   904 sgd_solver.cpp:106] Iteration 91400, lr = 0.0184941
I0605 11:48:26.445183   904 solver.cpp:229] Iteration 91440, loss = 2.63907
I0605 11:48:26.445245   904 solver.cpp:245]     Train net output #0: loss = 2.70666 (* 1 = 2.70666 loss)
I0605 11:48:26.445257   904 sgd_solver.cpp:106] Iteration 91440, lr = 0.0184847
I0605 11:48:46.725924   904 solver.cpp:229] Iteration 91480, loss = 2.64415
I0605 11:48:46.726111   904 solver.cpp:245]     Train net output #0: loss = 2.92718 (* 1 = 2.92718 loss)
I0605 11:48:46.726133   904 sgd_solver.cpp:106] Iteration 91480, lr = 0.0184753
I0605 11:49:06.854964   904 solver.cpp:229] Iteration 91520, loss = 2.58925
I0605 11:49:06.855031   904 solver.cpp:245]     Train net output #0: loss = 2.51232 (* 1 = 2.51232 loss)
I0605 11:49:06.855042   904 sgd_solver.cpp:106] Iteration 91520, lr = 0.0184659
I0605 11:49:19.170140   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 11:49:26.923982   904 solver.cpp:229] Iteration 91560, loss = 2.63675
I0605 11:49:26.924084   904 solver.cpp:245]     Train net output #0: loss = 2.60543 (* 1 = 2.60543 loss)
I0605 11:49:26.924100   904 sgd_solver.cpp:106] Iteration 91560, lr = 0.0184565
I0605 11:49:46.914338   904 solver.cpp:229] Iteration 91600, loss = 2.58589
I0605 11:49:46.914399   904 solver.cpp:245]     Train net output #0: loss = 2.57416 (* 1 = 2.57416 loss)
I0605 11:49:46.914410   904 sgd_solver.cpp:106] Iteration 91600, lr = 0.0184471
I0605 11:50:06.921703   904 solver.cpp:229] Iteration 91640, loss = 2.64685
I0605 11:50:06.921843   904 solver.cpp:245]     Train net output #0: loss = 2.41963 (* 1 = 2.41963 loss)
I0605 11:50:06.921855   904 sgd_solver.cpp:106] Iteration 91640, lr = 0.0184376
I0605 11:50:26.943414   904 solver.cpp:229] Iteration 91680, loss = 2.58654
I0605 11:50:26.943469   904 solver.cpp:245]     Train net output #0: loss = 2.52478 (* 1 = 2.52478 loss)
I0605 11:50:26.943481   904 sgd_solver.cpp:106] Iteration 91680, lr = 0.0184282
I0605 11:50:47.036875   904 solver.cpp:229] Iteration 91720, loss = 2.61607
I0605 11:50:47.037101   904 solver.cpp:245]     Train net output #0: loss = 2.59225 (* 1 = 2.59225 loss)
I0605 11:50:47.037127   904 sgd_solver.cpp:106] Iteration 91720, lr = 0.0184188
I0605 11:51:07.112049   904 solver.cpp:229] Iteration 91760, loss = 2.60729
I0605 11:51:07.112099   904 solver.cpp:245]     Train net output #0: loss = 2.57351 (* 1 = 2.57351 loss)
I0605 11:51:07.112112   904 sgd_solver.cpp:106] Iteration 91760, lr = 0.0184094
I0605 11:51:27.269309   904 solver.cpp:229] Iteration 91800, loss = 2.56958
I0605 11:51:27.269443   904 solver.cpp:245]     Train net output #0: loss = 2.54792 (* 1 = 2.54792 loss)
I0605 11:51:27.269454   904 sgd_solver.cpp:106] Iteration 91800, lr = 0.0184
I0605 11:51:47.490428   904 solver.cpp:229] Iteration 91840, loss = 2.57416
I0605 11:51:47.490475   904 solver.cpp:245]     Train net output #0: loss = 2.43793 (* 1 = 2.43793 loss)
I0605 11:51:47.490483   904 sgd_solver.cpp:106] Iteration 91840, lr = 0.0183906
I0605 11:52:07.743535   904 solver.cpp:229] Iteration 91880, loss = 2.58479
I0605 11:52:07.743811   904 solver.cpp:245]     Train net output #0: loss = 2.70807 (* 1 = 2.70807 loss)
I0605 11:52:07.743834   904 sgd_solver.cpp:106] Iteration 91880, lr = 0.0183812
I0605 11:52:27.891160   904 solver.cpp:229] Iteration 91920, loss = 2.59871
I0605 11:52:27.891219   904 solver.cpp:245]     Train net output #0: loss = 2.65926 (* 1 = 2.65926 loss)
I0605 11:52:27.891237   904 sgd_solver.cpp:106] Iteration 91920, lr = 0.0183718
I0605 11:52:48.088891   904 solver.cpp:229] Iteration 91960, loss = 2.61006
I0605 11:52:48.089097   904 solver.cpp:245]     Train net output #0: loss = 2.82518 (* 1 = 2.82518 loss)
I0605 11:52:48.089126   904 sgd_solver.cpp:106] Iteration 91960, lr = 0.0183624
I0605 11:53:07.852915   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_92000.caffemodel
I0605 11:53:08.112902   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_92000.solverstate
I0605 11:53:08.197917   904 solver.cpp:338] Iteration 92000, Testing net (#0)
I0605 11:53:08.198019   904 net.cpp:748] Ignoring source layer loss
I0605 11:53:12.941862   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 11:53:47.546543   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 11:54:17.355964   904 solver.cpp:406]     Test net output #0: accuracy = 0.432441
I0605 11:54:17.355998   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.685379
I0605 11:54:17.672175   904 solver.cpp:229] Iteration 92000, loss = 2.61448
I0605 11:54:17.672391   904 solver.cpp:245]     Train net output #0: loss = 2.73507 (* 1 = 2.73507 loss)
I0605 11:54:17.672426   904 sgd_solver.cpp:106] Iteration 92000, lr = 0.0183529
I0605 11:54:36.902596   904 solver.cpp:229] Iteration 92040, loss = 2.57814
I0605 11:54:36.902648   904 solver.cpp:245]     Train net output #0: loss = 2.58749 (* 1 = 2.58749 loss)
I0605 11:54:36.902657   904 sgd_solver.cpp:106] Iteration 92040, lr = 0.0183435
I0605 11:54:53.762236   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 11:54:58.059175   904 solver.cpp:229] Iteration 92080, loss = 2.57541
I0605 11:54:58.059223   904 solver.cpp:245]     Train net output #0: loss = 2.65935 (* 1 = 2.65935 loss)
I0605 11:54:58.059234   904 sgd_solver.cpp:106] Iteration 92080, lr = 0.0183341
I0605 11:55:19.127480   904 solver.cpp:229] Iteration 92120, loss = 2.57813
I0605 11:55:19.127526   904 solver.cpp:245]     Train net output #0: loss = 2.41752 (* 1 = 2.41752 loss)
I0605 11:55:19.127534   904 sgd_solver.cpp:106] Iteration 92120, lr = 0.0183247
I0605 11:55:39.901093   904 solver.cpp:229] Iteration 92160, loss = 2.58972
I0605 11:55:39.901332   904 solver.cpp:245]     Train net output #0: loss = 2.51135 (* 1 = 2.51135 loss)
I0605 11:55:39.901365   904 sgd_solver.cpp:106] Iteration 92160, lr = 0.0183153
I0605 11:56:00.644155   904 solver.cpp:229] Iteration 92200, loss = 2.59102
I0605 11:56:00.644203   904 solver.cpp:245]     Train net output #0: loss = 2.5412 (* 1 = 2.5412 loss)
I0605 11:56:00.644214   904 sgd_solver.cpp:106] Iteration 92200, lr = 0.0183059
I0605 11:56:21.266567   904 solver.cpp:229] Iteration 92240, loss = 2.57477
I0605 11:56:21.266705   904 solver.cpp:245]     Train net output #0: loss = 2.57542 (* 1 = 2.57542 loss)
I0605 11:56:21.266716   904 sgd_solver.cpp:106] Iteration 92240, lr = 0.0182965
I0605 11:56:41.901906   904 solver.cpp:229] Iteration 92280, loss = 2.58934
I0605 11:56:41.901964   904 solver.cpp:245]     Train net output #0: loss = 2.48755 (* 1 = 2.48755 loss)
I0605 11:56:41.901974   904 sgd_solver.cpp:106] Iteration 92280, lr = 0.0182871
I0605 11:57:02.524507   904 solver.cpp:229] Iteration 92320, loss = 2.5899
I0605 11:57:02.524690   904 solver.cpp:245]     Train net output #0: loss = 2.49907 (* 1 = 2.49907 loss)
I0605 11:57:02.524715   904 sgd_solver.cpp:106] Iteration 92320, lr = 0.0182776
I0605 11:57:23.161943   904 solver.cpp:229] Iteration 92360, loss = 2.60332
I0605 11:57:23.162005   904 solver.cpp:245]     Train net output #0: loss = 2.54068 (* 1 = 2.54068 loss)
I0605 11:57:23.162016   904 sgd_solver.cpp:106] Iteration 92360, lr = 0.0182682
I0605 11:57:43.723009   904 solver.cpp:229] Iteration 92400, loss = 2.58746
I0605 11:57:43.723206   904 solver.cpp:245]     Train net output #0: loss = 2.58775 (* 1 = 2.58775 loss)
I0605 11:57:43.723219   904 sgd_solver.cpp:106] Iteration 92400, lr = 0.0182588
I0605 11:58:04.174829   904 solver.cpp:229] Iteration 92440, loss = 2.54563
I0605 11:58:04.174868   904 solver.cpp:245]     Train net output #0: loss = 2.85115 (* 1 = 2.85115 loss)
I0605 11:58:04.174877   904 sgd_solver.cpp:106] Iteration 92440, lr = 0.0182494
I0605 11:58:24.628782   904 solver.cpp:229] Iteration 92480, loss = 2.60094
I0605 11:58:24.628952   904 solver.cpp:245]     Train net output #0: loss = 2.47703 (* 1 = 2.47703 loss)
I0605 11:58:24.628962   904 sgd_solver.cpp:106] Iteration 92480, lr = 0.01824
I0605 11:58:45.160301   904 solver.cpp:229] Iteration 92520, loss = 2.62785
I0605 11:58:45.160349   904 solver.cpp:245]     Train net output #0: loss = 2.65124 (* 1 = 2.65124 loss)
I0605 11:58:45.160363   904 sgd_solver.cpp:106] Iteration 92520, lr = 0.0182306
I0605 11:59:05.770969   904 solver.cpp:229] Iteration 92560, loss = 2.60301
I0605 11:59:05.771190   904 solver.cpp:245]     Train net output #0: loss = 2.30138 (* 1 = 2.30138 loss)
I0605 11:59:05.771216   904 sgd_solver.cpp:106] Iteration 92560, lr = 0.0182212
I0605 11:59:21.877190   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 11:59:26.231366   904 solver.cpp:229] Iteration 92600, loss = 2.61779
I0605 11:59:26.231426   904 solver.cpp:245]     Train net output #0: loss = 2.49953 (* 1 = 2.49953 loss)
I0605 11:59:26.231437   904 sgd_solver.cpp:106] Iteration 92600, lr = 0.0182118
I0605 11:59:46.681983   904 solver.cpp:229] Iteration 92640, loss = 2.65006
I0605 11:59:46.682148   904 solver.cpp:245]     Train net output #0: loss = 2.54984 (* 1 = 2.54984 loss)
I0605 11:59:46.682158   904 sgd_solver.cpp:106] Iteration 92640, lr = 0.0182024
I0605 12:00:07.138748   904 solver.cpp:229] Iteration 92680, loss = 2.60272
I0605 12:00:07.138799   904 solver.cpp:245]     Train net output #0: loss = 2.67698 (* 1 = 2.67698 loss)
I0605 12:00:07.138808   904 sgd_solver.cpp:106] Iteration 92680, lr = 0.0181929
I0605 12:00:27.564229   904 solver.cpp:229] Iteration 92720, loss = 2.60202
I0605 12:00:27.564484   904 solver.cpp:245]     Train net output #0: loss = 2.36843 (* 1 = 2.36843 loss)
I0605 12:00:27.564512   904 sgd_solver.cpp:106] Iteration 92720, lr = 0.0181835
I0605 12:00:48.003165   904 solver.cpp:229] Iteration 92760, loss = 2.61229
I0605 12:00:48.003211   904 solver.cpp:245]     Train net output #0: loss = 2.54401 (* 1 = 2.54401 loss)
I0605 12:00:48.003221   904 sgd_solver.cpp:106] Iteration 92760, lr = 0.0181741
I0605 12:01:08.453641   904 solver.cpp:229] Iteration 92800, loss = 2.56806
I0605 12:01:08.453807   904 solver.cpp:245]     Train net output #0: loss = 2.4858 (* 1 = 2.4858 loss)
I0605 12:01:08.453819   904 sgd_solver.cpp:106] Iteration 92800, lr = 0.0181647
I0605 12:01:28.885764   904 solver.cpp:229] Iteration 92840, loss = 2.59194
I0605 12:01:28.885809   904 solver.cpp:245]     Train net output #0: loss = 2.51708 (* 1 = 2.51708 loss)
I0605 12:01:28.885819   904 sgd_solver.cpp:106] Iteration 92840, lr = 0.0181553
I0605 12:01:49.303730   904 solver.cpp:229] Iteration 92880, loss = 2.61647
I0605 12:01:49.303944   904 solver.cpp:245]     Train net output #0: loss = 2.6148 (* 1 = 2.6148 loss)
I0605 12:01:49.303972   904 sgd_solver.cpp:106] Iteration 92880, lr = 0.0181459
I0605 12:02:09.873401   904 solver.cpp:229] Iteration 92920, loss = 2.57446
I0605 12:02:09.873448   904 solver.cpp:245]     Train net output #0: loss = 2.52129 (* 1 = 2.52129 loss)
I0605 12:02:09.873459   904 sgd_solver.cpp:106] Iteration 92920, lr = 0.0181365
I0605 12:02:30.095438   904 solver.cpp:229] Iteration 92960, loss = 2.55982
I0605 12:02:30.095731   904 solver.cpp:245]     Train net output #0: loss = 2.92342 (* 1 = 2.92342 loss)
I0605 12:02:30.095762   904 sgd_solver.cpp:106] Iteration 92960, lr = 0.0181271
I0605 12:02:50.040166   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_93000.caffemodel
I0605 12:02:50.305502   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_93000.solverstate
I0605 12:02:50.382875   904 solver.cpp:338] Iteration 93000, Testing net (#0)
I0605 12:02:50.382951   904 net.cpp:748] Ignoring source layer loss
I0605 12:02:57.476976   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 12:03:32.046005   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 12:03:59.533399   904 solver.cpp:406]     Test net output #0: accuracy = 0.432181
I0605 12:03:59.533444   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.68694
I0605 12:03:59.849076   904 solver.cpp:229] Iteration 93000, loss = 2.57537
I0605 12:03:59.849128   904 solver.cpp:245]     Train net output #0: loss = 2.44213 (* 1 = 2.44213 loss)
I0605 12:03:59.849140   904 sgd_solver.cpp:106] Iteration 93000, lr = 0.0181176
I0605 12:04:19.088696   904 solver.cpp:229] Iteration 93040, loss = 2.62673
I0605 12:04:19.088887   904 solver.cpp:245]     Train net output #0: loss = 2.49147 (* 1 = 2.49147 loss)
I0605 12:04:19.088913   904 sgd_solver.cpp:106] Iteration 93040, lr = 0.0181082
I0605 12:04:40.463207   904 solver.cpp:229] Iteration 93080, loss = 2.60693
I0605 12:04:40.463261   904 solver.cpp:245]     Train net output #0: loss = 2.59908 (* 1 = 2.59908 loss)
I0605 12:04:40.463270   904 sgd_solver.cpp:106] Iteration 93080, lr = 0.0180988
I0605 12:05:01.242938   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 12:05:02.045902   904 solver.cpp:229] Iteration 93120, loss = 2.55795
I0605 12:05:02.045955   904 solver.cpp:245]     Train net output #0: loss = 2.65825 (* 1 = 2.65825 loss)
I0605 12:05:02.045970   904 sgd_solver.cpp:106] Iteration 93120, lr = 0.0180894
I0605 12:05:23.433120   904 solver.cpp:229] Iteration 93160, loss = 2.58177
I0605 12:05:23.433168   904 solver.cpp:245]     Train net output #0: loss = 2.53339 (* 1 = 2.53339 loss)
I0605 12:05:23.433181   904 sgd_solver.cpp:106] Iteration 93160, lr = 0.01808
I0605 12:05:44.489351   904 solver.cpp:229] Iteration 93200, loss = 2.59576
I0605 12:05:44.489522   904 solver.cpp:245]     Train net output #0: loss = 2.85129 (* 1 = 2.85129 loss)
I0605 12:05:44.489533   904 sgd_solver.cpp:106] Iteration 93200, lr = 0.0180706
I0605 12:06:05.483530   904 solver.cpp:229] Iteration 93240, loss = 2.59983
I0605 12:06:05.483587   904 solver.cpp:245]     Train net output #0: loss = 2.37016 (* 1 = 2.37016 loss)
I0605 12:06:05.483603   904 sgd_solver.cpp:106] Iteration 93240, lr = 0.0180612
I0605 12:06:26.496248   904 solver.cpp:229] Iteration 93280, loss = 2.58998
I0605 12:06:26.496431   904 solver.cpp:245]     Train net output #0: loss = 2.59457 (* 1 = 2.59457 loss)
I0605 12:06:26.496444   904 sgd_solver.cpp:106] Iteration 93280, lr = 0.0180518
I0605 12:06:47.478889   904 solver.cpp:229] Iteration 93320, loss = 2.63194
I0605 12:06:47.478950   904 solver.cpp:245]     Train net output #0: loss = 2.77152 (* 1 = 2.77152 loss)
I0605 12:06:47.478958   904 sgd_solver.cpp:106] Iteration 93320, lr = 0.0180424
I0605 12:07:08.489778   904 solver.cpp:229] Iteration 93360, loss = 2.63503
I0605 12:07:08.489943   904 solver.cpp:245]     Train net output #0: loss = 2.68566 (* 1 = 2.68566 loss)
I0605 12:07:08.489958   904 sgd_solver.cpp:106] Iteration 93360, lr = 0.0180329
I0605 12:07:29.373359   904 solver.cpp:229] Iteration 93400, loss = 2.60005
I0605 12:07:29.373405   904 solver.cpp:245]     Train net output #0: loss = 2.58688 (* 1 = 2.58688 loss)
I0605 12:07:29.373414   904 sgd_solver.cpp:106] Iteration 93400, lr = 0.0180235
I0605 12:07:50.155419   904 solver.cpp:229] Iteration 93440, loss = 2.55706
I0605 12:07:50.155638   904 solver.cpp:245]     Train net output #0: loss = 2.70753 (* 1 = 2.70753 loss)
I0605 12:07:50.155665   904 sgd_solver.cpp:106] Iteration 93440, lr = 0.0180141
I0605 12:08:10.874802   904 solver.cpp:229] Iteration 93480, loss = 2.61382
I0605 12:08:10.874871   904 solver.cpp:245]     Train net output #0: loss = 2.61906 (* 1 = 2.61906 loss)
I0605 12:08:10.874882   904 sgd_solver.cpp:106] Iteration 93480, lr = 0.0180047
I0605 12:08:31.539788   904 solver.cpp:229] Iteration 93520, loss = 2.54582
I0605 12:08:31.540041   904 solver.cpp:245]     Train net output #0: loss = 2.4134 (* 1 = 2.4134 loss)
I0605 12:08:31.540067   904 sgd_solver.cpp:106] Iteration 93520, lr = 0.0179953
I0605 12:08:52.331148   904 solver.cpp:229] Iteration 93560, loss = 2.56582
I0605 12:08:52.331205   904 solver.cpp:245]     Train net output #0: loss = 2.57563 (* 1 = 2.57563 loss)
I0605 12:08:52.331217   904 sgd_solver.cpp:106] Iteration 93560, lr = 0.0179859
I0605 12:09:12.964632   904 solver.cpp:229] Iteration 93600, loss = 2.53608
I0605 12:09:12.964825   904 solver.cpp:245]     Train net output #0: loss = 2.47082 (* 1 = 2.47082 loss)
I0605 12:09:12.964854   904 sgd_solver.cpp:106] Iteration 93600, lr = 0.0179765
I0605 12:09:33.477463   904 solver.cpp:229] Iteration 93640, loss = 2.59627
I0605 12:09:33.477519   904 solver.cpp:245]     Train net output #0: loss = 2.24271 (* 1 = 2.24271 loss)
I0605 12:09:33.477531   904 sgd_solver.cpp:106] Iteration 93640, lr = 0.0179671
I0605 12:09:39.365296   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 12:09:53.974448   904 solver.cpp:229] Iteration 93680, loss = 2.54697
I0605 12:09:53.974630   904 solver.cpp:245]     Train net output #0: loss = 2.49901 (* 1 = 2.49901 loss)
I0605 12:09:53.974663   904 sgd_solver.cpp:106] Iteration 93680, lr = 0.0179576
I0605 12:10:14.466960   904 solver.cpp:229] Iteration 93720, loss = 2.59835
I0605 12:10:14.467016   904 solver.cpp:245]     Train net output #0: loss = 2.60547 (* 1 = 2.60547 loss)
I0605 12:10:14.467037   904 sgd_solver.cpp:106] Iteration 93720, lr = 0.0179482
I0605 12:10:34.989042   904 solver.cpp:229] Iteration 93760, loss = 2.6078
I0605 12:10:34.989262   904 solver.cpp:245]     Train net output #0: loss = 2.88584 (* 1 = 2.88584 loss)
I0605 12:10:34.989284   904 sgd_solver.cpp:106] Iteration 93760, lr = 0.0179388
I0605 12:10:55.494246   904 solver.cpp:229] Iteration 93800, loss = 2.60395
I0605 12:10:55.494312   904 solver.cpp:245]     Train net output #0: loss = 2.47894 (* 1 = 2.47894 loss)
I0605 12:10:55.494326   904 sgd_solver.cpp:106] Iteration 93800, lr = 0.0179294
I0605 12:11:15.856175   904 solver.cpp:229] Iteration 93840, loss = 2.5962
I0605 12:11:15.856290   904 solver.cpp:245]     Train net output #0: loss = 2.61949 (* 1 = 2.61949 loss)
I0605 12:11:15.856300   904 sgd_solver.cpp:106] Iteration 93840, lr = 0.01792
I0605 12:11:36.180099   904 solver.cpp:229] Iteration 93880, loss = 2.57225
I0605 12:11:36.180166   904 solver.cpp:245]     Train net output #0: loss = 2.62491 (* 1 = 2.62491 loss)
I0605 12:11:36.180174   904 sgd_solver.cpp:106] Iteration 93880, lr = 0.0179106
I0605 12:11:56.484066   904 solver.cpp:229] Iteration 93920, loss = 2.57917
I0605 12:11:56.484268   904 solver.cpp:245]     Train net output #0: loss = 2.56484 (* 1 = 2.56484 loss)
I0605 12:11:56.484294   904 sgd_solver.cpp:106] Iteration 93920, lr = 0.0179012
I0605 12:12:16.802248   904 solver.cpp:229] Iteration 93960, loss = 2.56822
I0605 12:12:16.802299   904 solver.cpp:245]     Train net output #0: loss = 2.59538 (* 1 = 2.59538 loss)
I0605 12:12:16.802333   904 sgd_solver.cpp:106] Iteration 93960, lr = 0.0178918
I0605 12:12:36.633762   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_94000.caffemodel
I0605 12:12:36.887042   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_94000.solverstate
I0605 12:12:36.956408   904 solver.cpp:338] Iteration 94000, Testing net (#0)
I0605 12:12:36.956487   904 net.cpp:748] Ignoring source layer loss
I0605 12:12:47.924825   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 12:13:22.664281   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 12:13:45.479876   904 solver.cpp:406]     Test net output #0: accuracy = 0.433361
I0605 12:13:45.479928   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.683639
I0605 12:13:45.796290   904 solver.cpp:229] Iteration 94000, loss = 2.58928
I0605 12:13:45.796347   904 solver.cpp:245]     Train net output #0: loss = 2.47573 (* 1 = 2.47573 loss)
I0605 12:13:45.796362   904 sgd_solver.cpp:106] Iteration 94000, lr = 0.0178824
I0605 12:14:05.008252   904 solver.cpp:229] Iteration 94040, loss = 2.60686
I0605 12:14:05.008527   904 solver.cpp:245]     Train net output #0: loss = 2.7259 (* 1 = 2.7259 loss)
I0605 12:14:05.008548   904 sgd_solver.cpp:106] Iteration 94040, lr = 0.0178729
I0605 12:14:26.243541   904 solver.cpp:229] Iteration 94080, loss = 2.57531
I0605 12:14:26.243614   904 solver.cpp:245]     Train net output #0: loss = 2.42619 (* 1 = 2.42619 loss)
I0605 12:14:26.243623   904 sgd_solver.cpp:106] Iteration 94080, lr = 0.0178635
I0605 12:14:47.590153   904 solver.cpp:229] Iteration 94120, loss = 2.57634
I0605 12:14:47.590337   904 solver.cpp:245]     Train net output #0: loss = 2.74992 (* 1 = 2.74992 loss)
I0605 12:14:47.590361   904 sgd_solver.cpp:106] Iteration 94120, lr = 0.0178541
I0605 12:15:08.427988   904 solver.cpp:229] Iteration 94160, loss = 2.59669
I0605 12:15:08.428036   904 solver.cpp:245]     Train net output #0: loss = 2.91008 (* 1 = 2.91008 loss)
I0605 12:15:08.428045   904 sgd_solver.cpp:106] Iteration 94160, lr = 0.0178447
I0605 12:15:19.375185   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 12:15:29.270550   904 solver.cpp:229] Iteration 94200, loss = 2.59274
I0605 12:15:29.270607   904 solver.cpp:245]     Train net output #0: loss = 2.69704 (* 1 = 2.69704 loss)
I0605 12:15:29.270614   904 sgd_solver.cpp:106] Iteration 94200, lr = 0.0178353
I0605 12:15:50.114214   904 solver.cpp:229] Iteration 94240, loss = 2.58171
I0605 12:15:50.114435   904 solver.cpp:245]     Train net output #0: loss = 2.6172 (* 1 = 2.6172 loss)
I0605 12:15:50.114460   904 sgd_solver.cpp:106] Iteration 94240, lr = 0.0178259
I0605 12:16:10.958015   904 solver.cpp:229] Iteration 94280, loss = 2.60693
I0605 12:16:10.958068   904 solver.cpp:245]     Train net output #0: loss = 2.51607 (* 1 = 2.51607 loss)
I0605 12:16:10.958079   904 sgd_solver.cpp:106] Iteration 94280, lr = 0.0178165
I0605 12:16:31.738432   904 solver.cpp:229] Iteration 94320, loss = 2.55206
I0605 12:16:31.738615   904 solver.cpp:245]     Train net output #0: loss = 2.75108 (* 1 = 2.75108 loss)
I0605 12:16:31.738636   904 sgd_solver.cpp:106] Iteration 94320, lr = 0.0178071
I0605 12:16:52.322893   904 solver.cpp:229] Iteration 94360, loss = 2.57194
I0605 12:16:52.322938   904 solver.cpp:245]     Train net output #0: loss = 2.75278 (* 1 = 2.75278 loss)
I0605 12:16:52.322950   904 sgd_solver.cpp:106] Iteration 94360, lr = 0.0177976
I0605 12:17:12.845855   904 solver.cpp:229] Iteration 94400, loss = 2.56522
I0605 12:17:12.845999   904 solver.cpp:245]     Train net output #0: loss = 2.72451 (* 1 = 2.72451 loss)
I0605 12:17:12.846020   904 sgd_solver.cpp:106] Iteration 94400, lr = 0.0177882
I0605 12:17:33.498327   904 solver.cpp:229] Iteration 94440, loss = 2.55952
I0605 12:17:33.498391   904 solver.cpp:245]     Train net output #0: loss = 2.30549 (* 1 = 2.30549 loss)
I0605 12:17:33.498402   904 sgd_solver.cpp:106] Iteration 94440, lr = 0.0177788
I0605 12:17:54.164597   904 solver.cpp:229] Iteration 94480, loss = 2.5731
I0605 12:17:54.164774   904 solver.cpp:245]     Train net output #0: loss = 2.59172 (* 1 = 2.59172 loss)
I0605 12:17:54.164798   904 sgd_solver.cpp:106] Iteration 94480, lr = 0.0177694
I0605 12:18:14.696946   904 solver.cpp:229] Iteration 94520, loss = 2.61016
I0605 12:18:14.696992   904 solver.cpp:245]     Train net output #0: loss = 2.46821 (* 1 = 2.46821 loss)
I0605 12:18:14.697001   904 sgd_solver.cpp:106] Iteration 94520, lr = 0.01776
I0605 12:18:35.218343   904 solver.cpp:229] Iteration 94560, loss = 2.58441
I0605 12:18:35.218511   904 solver.cpp:245]     Train net output #0: loss = 2.65862 (* 1 = 2.65862 loss)
I0605 12:18:35.218547   904 sgd_solver.cpp:106] Iteration 94560, lr = 0.0177506
I0605 12:18:55.716488   904 solver.cpp:229] Iteration 94600, loss = 2.56008
I0605 12:18:55.716541   904 solver.cpp:245]     Train net output #0: loss = 2.6078 (* 1 = 2.6078 loss)
I0605 12:18:55.716550   904 sgd_solver.cpp:106] Iteration 94600, lr = 0.0177412
I0605 12:19:16.234975   904 solver.cpp:229] Iteration 94640, loss = 2.53964
I0605 12:19:16.235165   904 solver.cpp:245]     Train net output #0: loss = 2.58105 (* 1 = 2.58105 loss)
I0605 12:19:16.235180   904 sgd_solver.cpp:106] Iteration 94640, lr = 0.0177318
I0605 12:19:36.721832   904 solver.cpp:229] Iteration 94680, loss = 2.56833
I0605 12:19:36.721881   904 solver.cpp:245]     Train net output #0: loss = 2.69789 (* 1 = 2.69789 loss)
I0605 12:19:36.721891   904 sgd_solver.cpp:106] Iteration 94680, lr = 0.0177224
I0605 12:19:47.505554   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 12:19:57.262343   904 solver.cpp:229] Iteration 94720, loss = 2.57344
I0605 12:19:57.262387   904 solver.cpp:245]     Train net output #0: loss = 2.67623 (* 1 = 2.67623 loss)
I0605 12:19:57.262398   904 sgd_solver.cpp:106] Iteration 94720, lr = 0.0177129
I0605 12:20:17.579463   904 solver.cpp:229] Iteration 94760, loss = 2.60732
I0605 12:20:17.579692   904 solver.cpp:245]     Train net output #0: loss = 2.83681 (* 1 = 2.83681 loss)
I0605 12:20:17.579725   904 sgd_solver.cpp:106] Iteration 94760, lr = 0.0177035
I0605 12:20:37.865520   904 solver.cpp:229] Iteration 94800, loss = 2.53414
I0605 12:20:37.865567   904 solver.cpp:245]     Train net output #0: loss = 2.78507 (* 1 = 2.78507 loss)
I0605 12:20:37.865579   904 sgd_solver.cpp:106] Iteration 94800, lr = 0.0176941
I0605 12:20:58.132673   904 solver.cpp:229] Iteration 94840, loss = 2.58001
I0605 12:20:58.132863   904 solver.cpp:245]     Train net output #0: loss = 2.77842 (* 1 = 2.77842 loss)
I0605 12:20:58.132895   904 sgd_solver.cpp:106] Iteration 94840, lr = 0.0176847
I0605 12:21:18.436208   904 solver.cpp:229] Iteration 94880, loss = 2.58798
I0605 12:21:18.436266   904 solver.cpp:245]     Train net output #0: loss = 2.51058 (* 1 = 2.51058 loss)
I0605 12:21:18.436277   904 sgd_solver.cpp:106] Iteration 94880, lr = 0.0176753
I0605 12:21:38.761713   904 solver.cpp:229] Iteration 94920, loss = 2.5424
I0605 12:21:38.761917   904 solver.cpp:245]     Train net output #0: loss = 2.23865 (* 1 = 2.23865 loss)
I0605 12:21:38.761940   904 sgd_solver.cpp:106] Iteration 94920, lr = 0.0176659
I0605 12:21:59.043563   904 solver.cpp:229] Iteration 94960, loss = 2.58053
I0605 12:21:59.043606   904 solver.cpp:245]     Train net output #0: loss = 2.7962 (* 1 = 2.7962 loss)
I0605 12:21:59.043617   904 sgd_solver.cpp:106] Iteration 94960, lr = 0.0176565
I0605 12:22:18.825670   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_95000.caffemodel
I0605 12:22:19.095860   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_95000.solverstate
I0605 12:22:19.175786   904 solver.cpp:338] Iteration 95000, Testing net (#0)
I0605 12:22:19.175869   904 net.cpp:748] Ignoring source layer loss
I0605 12:22:34.031070   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 12:23:09.469561   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 12:23:29.525532   904 solver.cpp:406]     Test net output #0: accuracy = 0.427621
I0605 12:23:29.525578   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.68162
I0605 12:23:29.842238   904 solver.cpp:229] Iteration 95000, loss = 2.58884
I0605 12:23:29.842281   904 solver.cpp:245]     Train net output #0: loss = 2.5177 (* 1 = 2.5177 loss)
I0605 12:23:29.842293   904 sgd_solver.cpp:106] Iteration 95000, lr = 0.0176471
I0605 12:23:49.093883   904 solver.cpp:229] Iteration 95040, loss = 2.59239
I0605 12:23:49.094085   904 solver.cpp:245]     Train net output #0: loss = 2.36064 (* 1 = 2.36064 loss)
I0605 12:23:49.094108   904 sgd_solver.cpp:106] Iteration 95040, lr = 0.0176376
I0605 12:24:10.394731   904 solver.cpp:229] Iteration 95080, loss = 2.57983
I0605 12:24:10.394773   904 solver.cpp:245]     Train net output #0: loss = 2.68867 (* 1 = 2.68867 loss)
I0605 12:24:10.394781   904 sgd_solver.cpp:106] Iteration 95080, lr = 0.0176282
I0605 12:24:31.764582   904 solver.cpp:229] Iteration 95120, loss = 2.58644
I0605 12:24:31.764873   904 solver.cpp:245]     Train net output #0: loss = 2.63066 (* 1 = 2.63066 loss)
I0605 12:24:31.764897   904 sgd_solver.cpp:106] Iteration 95120, lr = 0.0176188
I0605 12:24:52.741129   904 solver.cpp:229] Iteration 95160, loss = 2.55716
I0605 12:24:52.741173   904 solver.cpp:245]     Train net output #0: loss = 2.46007 (* 1 = 2.46007 loss)
I0605 12:24:52.741183   904 sgd_solver.cpp:106] Iteration 95160, lr = 0.0176094
I0605 12:25:13.717056   904 solver.cpp:229] Iteration 95200, loss = 2.58457
I0605 12:25:13.717205   904 solver.cpp:245]     Train net output #0: loss = 2.75293 (* 1 = 2.75293 loss)
I0605 12:25:13.717216   904 sgd_solver.cpp:106] Iteration 95200, lr = 0.0176
I0605 12:25:28.950597   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 12:25:34.710775   904 solver.cpp:229] Iteration 95240, loss = 2.57398
I0605 12:25:34.710827   904 solver.cpp:245]     Train net output #0: loss = 2.64961 (* 1 = 2.64961 loss)
I0605 12:25:34.710841   904 sgd_solver.cpp:106] Iteration 95240, lr = 0.0175906
I0605 12:25:55.688071   904 solver.cpp:229] Iteration 95280, loss = 2.60828
I0605 12:25:55.688274   904 solver.cpp:245]     Train net output #0: loss = 2.44726 (* 1 = 2.44726 loss)
I0605 12:25:55.688290   904 sgd_solver.cpp:106] Iteration 95280, lr = 0.0175812
I0605 12:26:16.241737   904 solver.cpp:229] Iteration 95320, loss = 2.56259
I0605 12:26:16.241791   904 solver.cpp:245]     Train net output #0: loss = 2.54409 (* 1 = 2.54409 loss)
I0605 12:26:16.241801   904 sgd_solver.cpp:106] Iteration 95320, lr = 0.0175718
I0605 12:26:36.914718   904 solver.cpp:229] Iteration 95360, loss = 2.59571
I0605 12:26:36.914856   904 solver.cpp:245]     Train net output #0: loss = 2.9322 (* 1 = 2.9322 loss)
I0605 12:26:36.914870   904 sgd_solver.cpp:106] Iteration 95360, lr = 0.0175624
I0605 12:26:57.689704   904 solver.cpp:229] Iteration 95400, loss = 2.57158
I0605 12:26:57.689751   904 solver.cpp:245]     Train net output #0: loss = 2.66199 (* 1 = 2.66199 loss)
I0605 12:26:57.689761   904 sgd_solver.cpp:106] Iteration 95400, lr = 0.0175529
I0605 12:27:18.412724   904 solver.cpp:229] Iteration 95440, loss = 2.55014
I0605 12:27:18.412878   904 solver.cpp:245]     Train net output #0: loss = 2.85658 (* 1 = 2.85658 loss)
I0605 12:27:18.412894   904 sgd_solver.cpp:106] Iteration 95440, lr = 0.0175435
I0605 12:27:38.943487   904 solver.cpp:229] Iteration 95480, loss = 2.55677
I0605 12:27:38.943532   904 solver.cpp:245]     Train net output #0: loss = 2.78034 (* 1 = 2.78034 loss)
I0605 12:27:38.943542   904 sgd_solver.cpp:106] Iteration 95480, lr = 0.0175341
I0605 12:27:59.427147   904 solver.cpp:229] Iteration 95520, loss = 2.57805
I0605 12:27:59.427274   904 solver.cpp:245]     Train net output #0: loss = 2.77573 (* 1 = 2.77573 loss)
I0605 12:27:59.427287   904 sgd_solver.cpp:106] Iteration 95520, lr = 0.0175247
I0605 12:28:20.092264   904 solver.cpp:229] Iteration 95560, loss = 2.61519
I0605 12:28:20.092309   904 solver.cpp:245]     Train net output #0: loss = 2.52482 (* 1 = 2.52482 loss)
I0605 12:28:20.092320   904 sgd_solver.cpp:106] Iteration 95560, lr = 0.0175153
I0605 12:28:40.736073   904 solver.cpp:229] Iteration 95600, loss = 2.60859
I0605 12:28:40.736268   904 solver.cpp:245]     Train net output #0: loss = 2.59169 (* 1 = 2.59169 loss)
I0605 12:28:40.736296   904 sgd_solver.cpp:106] Iteration 95600, lr = 0.0175059
I0605 12:29:01.285125   904 solver.cpp:229] Iteration 95640, loss = 2.53971
I0605 12:29:01.285176   904 solver.cpp:245]     Train net output #0: loss = 2.63808 (* 1 = 2.63808 loss)
I0605 12:29:01.285188   904 sgd_solver.cpp:106] Iteration 95640, lr = 0.0174965
I0605 12:29:21.791993   904 solver.cpp:229] Iteration 95680, loss = 2.56371
I0605 12:29:21.792199   904 solver.cpp:245]     Train net output #0: loss = 2.71228 (* 1 = 2.71228 loss)
I0605 12:29:21.792224   904 sgd_solver.cpp:106] Iteration 95680, lr = 0.0174871
I0605 12:29:42.321027   904 solver.cpp:229] Iteration 95720, loss = 2.59281
I0605 12:29:42.321080   904 solver.cpp:245]     Train net output #0: loss = 2.49186 (* 1 = 2.49186 loss)
I0605 12:29:42.321089   904 sgd_solver.cpp:106] Iteration 95720, lr = 0.0174776
I0605 12:29:58.967486   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 12:30:02.809265   904 solver.cpp:229] Iteration 95760, loss = 2.58378
I0605 12:30:02.809317   904 solver.cpp:245]     Train net output #0: loss = 2.18274 (* 1 = 2.18274 loss)
I0605 12:30:02.809329   904 sgd_solver.cpp:106] Iteration 95760, lr = 0.0174682
I0605 12:30:23.333938   904 solver.cpp:229] Iteration 95800, loss = 2.54733
I0605 12:30:23.333984   904 solver.cpp:245]     Train net output #0: loss = 2.62467 (* 1 = 2.62467 loss)
I0605 12:30:23.333997   904 sgd_solver.cpp:106] Iteration 95800, lr = 0.0174588
I0605 12:30:43.823040   904 solver.cpp:229] Iteration 95840, loss = 2.59162
I0605 12:30:43.823212   904 solver.cpp:245]     Train net output #0: loss = 2.69132 (* 1 = 2.69132 loss)
I0605 12:30:43.823225   904 sgd_solver.cpp:106] Iteration 95840, lr = 0.0174494
I0605 12:31:04.328259   904 solver.cpp:229] Iteration 95880, loss = 2.58242
I0605 12:31:04.328310   904 solver.cpp:245]     Train net output #0: loss = 2.4772 (* 1 = 2.4772 loss)
I0605 12:31:04.328320   904 sgd_solver.cpp:106] Iteration 95880, lr = 0.01744
I0605 12:31:24.832152   904 solver.cpp:229] Iteration 95920, loss = 2.55582
I0605 12:31:24.832337   904 solver.cpp:245]     Train net output #0: loss = 2.78701 (* 1 = 2.78701 loss)
I0605 12:31:24.832347   904 sgd_solver.cpp:106] Iteration 95920, lr = 0.0174306
I0605 12:31:45.350242   904 solver.cpp:229] Iteration 95960, loss = 2.55422
I0605 12:31:45.350291   904 solver.cpp:245]     Train net output #0: loss = 2.38273 (* 1 = 2.38273 loss)
I0605 12:31:45.350301   904 sgd_solver.cpp:106] Iteration 95960, lr = 0.0174212
I0605 12:32:05.361814   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_96000.caffemodel
I0605 12:32:05.636201   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_96000.solverstate
I0605 12:32:05.725306   904 solver.cpp:338] Iteration 96000, Testing net (#0)
I0605 12:32:05.725381   904 net.cpp:748] Ignoring source layer loss
I0605 12:32:24.279395   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 12:33:00.153007   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 12:33:16.639194   904 solver.cpp:406]     Test net output #0: accuracy = 0.440541
I0605 12:33:16.639236   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.69186
I0605 12:33:16.952110   904 solver.cpp:229] Iteration 96000, loss = 2.57636
I0605 12:33:16.952172   904 solver.cpp:245]     Train net output #0: loss = 2.37355 (* 1 = 2.37355 loss)
I0605 12:33:16.952186   904 sgd_solver.cpp:106] Iteration 96000, lr = 0.0174118
I0605 12:33:36.222429   904 solver.cpp:229] Iteration 96040, loss = 2.55883
I0605 12:33:36.222549   904 solver.cpp:245]     Train net output #0: loss = 2.24593 (* 1 = 2.24593 loss)
I0605 12:33:36.222561   904 sgd_solver.cpp:106] Iteration 96040, lr = 0.0174024
I0605 12:33:57.764345   904 solver.cpp:229] Iteration 96080, loss = 2.57543
I0605 12:33:57.764405   904 solver.cpp:245]     Train net output #0: loss = 2.51934 (* 1 = 2.51934 loss)
I0605 12:33:57.764415   904 sgd_solver.cpp:106] Iteration 96080, lr = 0.0173929
I0605 12:34:19.392725   904 solver.cpp:229] Iteration 96120, loss = 2.55861
I0605 12:34:19.392945   904 solver.cpp:245]     Train net output #0: loss = 2.58767 (* 1 = 2.58767 loss)
I0605 12:34:19.392972   904 sgd_solver.cpp:106] Iteration 96120, lr = 0.0173835
I0605 12:34:40.847666   904 solver.cpp:229] Iteration 96160, loss = 2.55935
I0605 12:34:40.847725   904 solver.cpp:245]     Train net output #0: loss = 2.62911 (* 1 = 2.62911 loss)
I0605 12:34:40.847738   904 sgd_solver.cpp:106] Iteration 96160, lr = 0.0173741
I0605 12:35:02.078322   904 solver.cpp:229] Iteration 96200, loss = 2.57628
I0605 12:35:02.078582   904 solver.cpp:245]     Train net output #0: loss = 2.72971 (* 1 = 2.72971 loss)
I0605 12:35:02.078605   904 sgd_solver.cpp:106] Iteration 96200, lr = 0.0173647
I0605 12:35:23.112270   904 solver.cpp:229] Iteration 96240, loss = 2.56566
I0605 12:35:23.112323   904 solver.cpp:245]     Train net output #0: loss = 2.544 (* 1 = 2.544 loss)
I0605 12:35:23.112334   904 sgd_solver.cpp:106] Iteration 96240, lr = 0.0173553
I0605 12:35:40.206920   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 12:35:44.143990   904 solver.cpp:229] Iteration 96280, loss = 2.53587
I0605 12:35:44.144034   904 solver.cpp:245]     Train net output #0: loss = 2.61874 (* 1 = 2.61874 loss)
I0605 12:35:44.144044   904 sgd_solver.cpp:106] Iteration 96280, lr = 0.0173459
I0605 12:36:05.168607   904 solver.cpp:229] Iteration 96320, loss = 2.54825
I0605 12:36:05.168653   904 solver.cpp:245]     Train net output #0: loss = 2.48356 (* 1 = 2.48356 loss)
I0605 12:36:05.168664   904 sgd_solver.cpp:106] Iteration 96320, lr = 0.0173365
I0605 12:36:26.215492   904 solver.cpp:229] Iteration 96360, loss = 2.55317
I0605 12:36:26.215649   904 solver.cpp:245]     Train net output #0: loss = 2.33555 (* 1 = 2.33555 loss)
I0605 12:36:26.215662   904 sgd_solver.cpp:106] Iteration 96360, lr = 0.0173271
I0605 12:36:47.131434   904 solver.cpp:229] Iteration 96400, loss = 2.54212
I0605 12:36:47.131496   904 solver.cpp:245]     Train net output #0: loss = 2.64746 (* 1 = 2.64746 loss)
I0605 12:36:47.131513   904 sgd_solver.cpp:106] Iteration 96400, lr = 0.0173176
I0605 12:37:07.881466   904 solver.cpp:229] Iteration 96440, loss = 2.57106
I0605 12:37:07.881646   904 solver.cpp:245]     Train net output #0: loss = 2.80369 (* 1 = 2.80369 loss)
I0605 12:37:07.881675   904 sgd_solver.cpp:106] Iteration 96440, lr = 0.0173082
I0605 12:37:28.592030   904 solver.cpp:229] Iteration 96480, loss = 2.58136
I0605 12:37:28.592068   904 solver.cpp:245]     Train net output #0: loss = 2.47779 (* 1 = 2.47779 loss)
I0605 12:37:28.592077   904 sgd_solver.cpp:106] Iteration 96480, lr = 0.0172988
I0605 12:37:49.321565   904 solver.cpp:229] Iteration 96520, loss = 2.56739
I0605 12:37:49.321709   904 solver.cpp:245]     Train net output #0: loss = 2.509 (* 1 = 2.509 loss)
I0605 12:37:49.321720   904 sgd_solver.cpp:106] Iteration 96520, lr = 0.0172894
I0605 12:38:10.053997   904 solver.cpp:229] Iteration 96560, loss = 2.59415
I0605 12:38:10.054054   904 solver.cpp:245]     Train net output #0: loss = 2.62646 (* 1 = 2.62646 loss)
I0605 12:38:10.054066   904 sgd_solver.cpp:106] Iteration 96560, lr = 0.01728
I0605 12:38:30.720614   904 solver.cpp:229] Iteration 96600, loss = 2.54683
I0605 12:38:30.720808   904 solver.cpp:245]     Train net output #0: loss = 2.55218 (* 1 = 2.55218 loss)
I0605 12:38:30.720824   904 sgd_solver.cpp:106] Iteration 96600, lr = 0.0172706
I0605 12:38:51.268177   904 solver.cpp:229] Iteration 96640, loss = 2.60585
I0605 12:38:51.268234   904 solver.cpp:245]     Train net output #0: loss = 2.71109 (* 1 = 2.71109 loss)
I0605 12:38:51.268246   904 sgd_solver.cpp:106] Iteration 96640, lr = 0.0172612
I0605 12:39:11.824666   904 solver.cpp:229] Iteration 96680, loss = 2.56527
I0605 12:39:11.824827   904 solver.cpp:245]     Train net output #0: loss = 2.77089 (* 1 = 2.77089 loss)
I0605 12:39:11.824839   904 sgd_solver.cpp:106] Iteration 96680, lr = 0.0172518
I0605 12:39:32.367384   904 solver.cpp:229] Iteration 96720, loss = 2.56251
I0605 12:39:32.367455   904 solver.cpp:245]     Train net output #0: loss = 2.71711 (* 1 = 2.71711 loss)
I0605 12:39:32.367470   904 sgd_solver.cpp:106] Iteration 96720, lr = 0.0172424
I0605 12:39:52.895526   904 solver.cpp:229] Iteration 96760, loss = 2.55115
I0605 12:39:52.895751   904 solver.cpp:245]     Train net output #0: loss = 2.53633 (* 1 = 2.53633 loss)
I0605 12:39:52.895761   904 sgd_solver.cpp:106] Iteration 96760, lr = 0.0172329
I0605 12:40:05.460786   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 12:40:13.409798   904 solver.cpp:229] Iteration 96800, loss = 2.56166
I0605 12:40:13.409855   904 solver.cpp:245]     Train net output #0: loss = 2.73087 (* 1 = 2.73087 loss)
I0605 12:40:13.409865   904 sgd_solver.cpp:106] Iteration 96800, lr = 0.0172235
I0605 12:40:33.614713   904 solver.cpp:229] Iteration 96840, loss = 2.52631
I0605 12:40:33.615010   904 solver.cpp:245]     Train net output #0: loss = 2.8111 (* 1 = 2.8111 loss)
I0605 12:40:33.615033   904 sgd_solver.cpp:106] Iteration 96840, lr = 0.0172141
I0605 12:40:53.629760   904 solver.cpp:229] Iteration 96880, loss = 2.56153
I0605 12:40:53.629829   904 solver.cpp:245]     Train net output #0: loss = 2.54311 (* 1 = 2.54311 loss)
I0605 12:40:53.629842   904 sgd_solver.cpp:106] Iteration 96880, lr = 0.0172047
I0605 12:41:13.640233   904 solver.cpp:229] Iteration 96920, loss = 2.52884
I0605 12:41:13.640411   904 solver.cpp:245]     Train net output #0: loss = 2.38609 (* 1 = 2.38609 loss)
I0605 12:41:13.640422   904 sgd_solver.cpp:106] Iteration 96920, lr = 0.0171953
I0605 12:41:33.640266   904 solver.cpp:229] Iteration 96960, loss = 2.56451
I0605 12:41:33.640328   904 solver.cpp:245]     Train net output #0: loss = 2.34004 (* 1 = 2.34004 loss)
I0605 12:41:33.640338   904 sgd_solver.cpp:106] Iteration 96960, lr = 0.0171859
I0605 12:41:53.095544   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_97000.caffemodel
I0605 12:41:53.361646   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_97000.solverstate
I0605 12:41:53.439942   904 solver.cpp:338] Iteration 97000, Testing net (#0)
I0605 12:41:53.440040   904 net.cpp:748] Ignoring source layer loss
I0605 12:42:16.297504   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 12:42:51.296823   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 12:43:04.665940   904 solver.cpp:406]     Test net output #0: accuracy = 0.431541
I0605 12:43:04.665987   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.682699
I0605 12:43:04.979642   904 solver.cpp:229] Iteration 97000, loss = 2.54316
I0605 12:43:04.979691   904 solver.cpp:245]     Train net output #0: loss = 2.37618 (* 1 = 2.37618 loss)
I0605 12:43:04.979701   904 sgd_solver.cpp:106] Iteration 97000, lr = 0.0171765
I0605 12:43:24.271042   904 solver.cpp:229] Iteration 97040, loss = 2.57125
I0605 12:43:24.271260   904 solver.cpp:245]     Train net output #0: loss = 2.54543 (* 1 = 2.54543 loss)
I0605 12:43:24.271298   904 sgd_solver.cpp:106] Iteration 97040, lr = 0.0171671
I0605 12:43:45.444959   904 solver.cpp:229] Iteration 97080, loss = 2.54074
I0605 12:43:45.445008   904 solver.cpp:245]     Train net output #0: loss = 2.3209 (* 1 = 2.3209 loss)
I0605 12:43:45.445019   904 sgd_solver.cpp:106] Iteration 97080, lr = 0.0171576
I0605 12:44:06.658862   904 solver.cpp:229] Iteration 97120, loss = 2.53305
I0605 12:44:06.658994   904 solver.cpp:245]     Train net output #0: loss = 2.74117 (* 1 = 2.74117 loss)
I0605 12:44:06.659005   904 sgd_solver.cpp:106] Iteration 97120, lr = 0.0171482
I0605 12:44:27.670738   904 solver.cpp:229] Iteration 97160, loss = 2.5185
I0605 12:44:27.670812   904 solver.cpp:245]     Train net output #0: loss = 2.46081 (* 1 = 2.46081 loss)
I0605 12:44:27.670830   904 sgd_solver.cpp:106] Iteration 97160, lr = 0.0171388
I0605 12:44:48.564641   904 solver.cpp:229] Iteration 97200, loss = 2.55927
I0605 12:44:48.564774   904 solver.cpp:245]     Train net output #0: loss = 2.51525 (* 1 = 2.51525 loss)
I0605 12:44:48.564785   904 sgd_solver.cpp:106] Iteration 97200, lr = 0.0171294
I0605 12:45:09.492192   904 solver.cpp:229] Iteration 97240, loss = 2.53733
I0605 12:45:09.492236   904 solver.cpp:245]     Train net output #0: loss = 2.54453 (* 1 = 2.54453 loss)
I0605 12:45:09.492249   904 sgd_solver.cpp:106] Iteration 97240, lr = 0.01712
I0605 12:45:30.479619   904 solver.cpp:229] Iteration 97280, loss = 2.54469
I0605 12:45:30.479847   904 solver.cpp:245]     Train net output #0: loss = 2.39294 (* 1 = 2.39294 loss)
I0605 12:45:30.479892   904 sgd_solver.cpp:106] Iteration 97280, lr = 0.0171106
I0605 12:45:51.148918   904 solver.cpp:229] Iteration 97320, loss = 2.54595
I0605 12:45:51.148968   904 solver.cpp:245]     Train net output #0: loss = 2.69284 (* 1 = 2.69284 loss)
I0605 12:45:51.148978   904 sgd_solver.cpp:106] Iteration 97320, lr = 0.0171012
I0605 12:45:51.914764   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 12:46:11.762889   904 solver.cpp:229] Iteration 97360, loss = 2.58381
I0605 12:46:11.763124   904 solver.cpp:245]     Train net output #0: loss = 2.41882 (* 1 = 2.41882 loss)
I0605 12:46:11.763140   904 sgd_solver.cpp:106] Iteration 97360, lr = 0.0170918
I0605 12:46:32.446646   904 solver.cpp:229] Iteration 97400, loss = 2.56228
I0605 12:46:32.446693   904 solver.cpp:245]     Train net output #0: loss = 2.54933 (* 1 = 2.54933 loss)
I0605 12:46:32.446702   904 sgd_solver.cpp:106] Iteration 97400, lr = 0.0170824
I0605 12:46:53.082674   904 solver.cpp:229] Iteration 97440, loss = 2.53781
I0605 12:46:53.082841   904 solver.cpp:245]     Train net output #0: loss = 2.48395 (* 1 = 2.48395 loss)
I0605 12:46:53.082854   904 sgd_solver.cpp:106] Iteration 97440, lr = 0.0170729
I0605 12:47:13.674907   904 solver.cpp:229] Iteration 97480, loss = 2.56376
I0605 12:47:13.674957   904 solver.cpp:245]     Train net output #0: loss = 2.55543 (* 1 = 2.55543 loss)
I0605 12:47:13.674974   904 sgd_solver.cpp:106] Iteration 97480, lr = 0.0170635
I0605 12:47:34.303086   904 solver.cpp:229] Iteration 97520, loss = 2.57122
I0605 12:47:34.303248   904 solver.cpp:245]     Train net output #0: loss = 2.6086 (* 1 = 2.6086 loss)
I0605 12:47:34.303261   904 sgd_solver.cpp:106] Iteration 97520, lr = 0.0170541
I0605 12:47:54.808140   904 solver.cpp:229] Iteration 97560, loss = 2.56872
I0605 12:47:54.808187   904 solver.cpp:245]     Train net output #0: loss = 2.56304 (* 1 = 2.56304 loss)
I0605 12:47:54.808208   904 sgd_solver.cpp:106] Iteration 97560, lr = 0.0170447
I0605 12:48:15.339691   904 solver.cpp:229] Iteration 97600, loss = 2.5784
I0605 12:48:15.339903   904 solver.cpp:245]     Train net output #0: loss = 2.33628 (* 1 = 2.33628 loss)
I0605 12:48:15.339918   904 sgd_solver.cpp:106] Iteration 97600, lr = 0.0170353
I0605 12:48:35.862864   904 solver.cpp:229] Iteration 97640, loss = 2.59275
I0605 12:48:35.862911   904 solver.cpp:245]     Train net output #0: loss = 2.64098 (* 1 = 2.64098 loss)
I0605 12:48:35.862920   904 sgd_solver.cpp:106] Iteration 97640, lr = 0.0170259
I0605 12:48:56.370697   904 solver.cpp:229] Iteration 97680, loss = 2.57797
I0605 12:48:56.370867   904 solver.cpp:245]     Train net output #0: loss = 2.60667 (* 1 = 2.60667 loss)
I0605 12:48:56.370878   904 sgd_solver.cpp:106] Iteration 97680, lr = 0.0170165
I0605 12:49:16.818073   904 solver.cpp:229] Iteration 97720, loss = 2.56905
I0605 12:49:16.818142   904 solver.cpp:245]     Train net output #0: loss = 2.85926 (* 1 = 2.85926 loss)
I0605 12:49:16.818153   904 sgd_solver.cpp:106] Iteration 97720, lr = 0.0170071
I0605 12:49:37.094179   904 solver.cpp:229] Iteration 97760, loss = 2.55152
I0605 12:49:37.094341   904 solver.cpp:245]     Train net output #0: loss = 2.59447 (* 1 = 2.59447 loss)
I0605 12:49:37.094353   904 sgd_solver.cpp:106] Iteration 97760, lr = 0.0169976
I0605 12:49:57.385933   904 solver.cpp:229] Iteration 97800, loss = 2.56689
I0605 12:49:57.385988   904 solver.cpp:245]     Train net output #0: loss = 2.5145 (* 1 = 2.5145 loss)
I0605 12:49:57.385998   904 sgd_solver.cpp:106] Iteration 97800, lr = 0.0169882
I0605 12:50:17.663425   904 solver.cpp:229] Iteration 97840, loss = 2.54714
I0605 12:50:17.663663   904 solver.cpp:245]     Train net output #0: loss = 2.68805 (* 1 = 2.68805 loss)
I0605 12:50:17.663689   904 sgd_solver.cpp:106] Iteration 97840, lr = 0.0169788
I0605 12:50:28.573029   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 12:50:37.976567   904 solver.cpp:229] Iteration 97880, loss = 2.56872
I0605 12:50:37.976609   904 solver.cpp:245]     Train net output #0: loss = 2.81714 (* 1 = 2.81714 loss)
I0605 12:50:37.976620   904 sgd_solver.cpp:106] Iteration 97880, lr = 0.0169694
I0605 12:50:58.239092   904 solver.cpp:229] Iteration 97920, loss = 2.56843
I0605 12:50:58.239372   904 solver.cpp:245]     Train net output #0: loss = 2.8299 (* 1 = 2.8299 loss)
I0605 12:50:58.239406   904 sgd_solver.cpp:106] Iteration 97920, lr = 0.01696
I0605 12:51:18.498734   904 solver.cpp:229] Iteration 97960, loss = 2.52498
I0605 12:51:18.498800   904 solver.cpp:245]     Train net output #0: loss = 2.46545 (* 1 = 2.46545 loss)
I0605 12:51:18.498811   904 sgd_solver.cpp:106] Iteration 97960, lr = 0.0169506
I0605 12:51:38.245396   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_98000.caffemodel
I0605 12:51:38.512575   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_98000.solverstate
I0605 12:51:38.596096   904 solver.cpp:338] Iteration 98000, Testing net (#0)
I0605 12:51:38.596173   904 net.cpp:748] Ignoring source layer loss
I0605 12:52:05.123698   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 12:52:39.652142   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 12:52:48.868291   904 solver.cpp:406]     Test net output #0: accuracy = 0.445941
I0605 12:52:48.868324   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.69792
I0605 12:52:49.185370   904 solver.cpp:229] Iteration 98000, loss = 2.54638
I0605 12:52:49.185421   904 solver.cpp:245]     Train net output #0: loss = 2.46177 (* 1 = 2.46177 loss)
I0605 12:52:49.185434   904 sgd_solver.cpp:106] Iteration 98000, lr = 0.0169412
I0605 12:53:08.421839   904 solver.cpp:229] Iteration 98040, loss = 2.56139
I0605 12:53:08.421880   904 solver.cpp:245]     Train net output #0: loss = 2.55754 (* 1 = 2.55754 loss)
I0605 12:53:08.421890   904 sgd_solver.cpp:106] Iteration 98040, lr = 0.0169318
I0605 12:53:29.816093   904 solver.cpp:229] Iteration 98080, loss = 2.57668
I0605 12:53:29.816310   904 solver.cpp:245]     Train net output #0: loss = 2.55431 (* 1 = 2.55431 loss)
I0605 12:53:29.816329   904 sgd_solver.cpp:106] Iteration 98080, lr = 0.0169224
I0605 12:53:51.362330   904 solver.cpp:229] Iteration 98120, loss = 2.52415
I0605 12:53:51.362370   904 solver.cpp:245]     Train net output #0: loss = 2.54264 (* 1 = 2.54264 loss)
I0605 12:53:51.362378   904 sgd_solver.cpp:106] Iteration 98120, lr = 0.0169129
I0605 12:54:12.207151   904 solver.cpp:229] Iteration 98160, loss = 2.54214
I0605 12:54:12.207365   904 solver.cpp:245]     Train net output #0: loss = 2.51437 (* 1 = 2.51437 loss)
I0605 12:54:12.207393   904 sgd_solver.cpp:106] Iteration 98160, lr = 0.0169035
I0605 12:54:33.115407   904 solver.cpp:229] Iteration 98200, loss = 2.57496
I0605 12:54:33.115450   904 solver.cpp:245]     Train net output #0: loss = 2.68285 (* 1 = 2.68285 loss)
I0605 12:54:33.115468   904 sgd_solver.cpp:106] Iteration 98200, lr = 0.0168941
I0605 12:54:54.096011   904 solver.cpp:229] Iteration 98240, loss = 2.56456
I0605 12:54:54.096187   904 solver.cpp:245]     Train net output #0: loss = 2.5619 (* 1 = 2.5619 loss)
I0605 12:54:54.096213   904 sgd_solver.cpp:106] Iteration 98240, lr = 0.0168847
I0605 12:55:15.070614   904 solver.cpp:229] Iteration 98280, loss = 2.51904
I0605 12:55:15.070659   904 solver.cpp:245]     Train net output #0: loss = 2.52656 (* 1 = 2.52656 loss)
I0605 12:55:15.070669   904 sgd_solver.cpp:106] Iteration 98280, lr = 0.0168753
I0605 12:55:35.973425   904 solver.cpp:229] Iteration 98320, loss = 2.55898
I0605 12:55:35.973639   904 solver.cpp:245]     Train net output #0: loss = 2.31845 (* 1 = 2.31845 loss)
I0605 12:55:35.973664   904 sgd_solver.cpp:106] Iteration 98320, lr = 0.0168659
I0605 12:55:56.608541   904 solver.cpp:229] Iteration 98360, loss = 2.57952
I0605 12:55:56.608613   904 solver.cpp:245]     Train net output #0: loss = 2.47289 (* 1 = 2.47289 loss)
I0605 12:55:56.608629   904 sgd_solver.cpp:106] Iteration 98360, lr = 0.0168565
I0605 12:56:10.079535   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 12:56:17.327751   904 solver.cpp:229] Iteration 98400, loss = 2.51104
I0605 12:56:17.327805   904 solver.cpp:245]     Train net output #0: loss = 2.79424 (* 1 = 2.79424 loss)
I0605 12:56:17.327814   904 sgd_solver.cpp:106] Iteration 98400, lr = 0.0168471
I0605 12:56:38.005022   904 solver.cpp:229] Iteration 98440, loss = 2.53963
I0605 12:56:38.005089   904 solver.cpp:245]     Train net output #0: loss = 2.25122 (* 1 = 2.25122 loss)
I0605 12:56:38.005100   904 sgd_solver.cpp:106] Iteration 98440, lr = 0.0168376
I0605 12:56:58.648350   904 solver.cpp:229] Iteration 98480, loss = 2.56615
I0605 12:56:58.648584   904 solver.cpp:245]     Train net output #0: loss = 2.58895 (* 1 = 2.58895 loss)
I0605 12:56:58.648597   904 sgd_solver.cpp:106] Iteration 98480, lr = 0.0168282
I0605 12:57:19.179038   904 solver.cpp:229] Iteration 98520, loss = 2.53296
I0605 12:57:19.179105   904 solver.cpp:245]     Train net output #0: loss = 2.53001 (* 1 = 2.53001 loss)
I0605 12:57:19.179117   904 sgd_solver.cpp:106] Iteration 98520, lr = 0.0168188
I0605 12:57:39.890347   904 solver.cpp:229] Iteration 98560, loss = 2.56123
I0605 12:57:39.890540   904 solver.cpp:245]     Train net output #0: loss = 2.69688 (* 1 = 2.69688 loss)
I0605 12:57:39.890564   904 sgd_solver.cpp:106] Iteration 98560, lr = 0.0168094
I0605 12:58:00.554651   904 solver.cpp:229] Iteration 98600, loss = 2.53789
I0605 12:58:00.554694   904 solver.cpp:245]     Train net output #0: loss = 2.76194 (* 1 = 2.76194 loss)
I0605 12:58:00.554705   904 sgd_solver.cpp:106] Iteration 98600, lr = 0.0168
I0605 12:58:21.089705   904 solver.cpp:229] Iteration 98640, loss = 2.58194
I0605 12:58:21.089879   904 solver.cpp:245]     Train net output #0: loss = 2.51841 (* 1 = 2.51841 loss)
I0605 12:58:21.089907   904 sgd_solver.cpp:106] Iteration 98640, lr = 0.0167906
I0605 12:58:41.613775   904 solver.cpp:229] Iteration 98680, loss = 2.54162
I0605 12:58:41.613829   904 solver.cpp:245]     Train net output #0: loss = 2.52763 (* 1 = 2.52763 loss)
I0605 12:58:41.613838   904 sgd_solver.cpp:106] Iteration 98680, lr = 0.0167812
I0605 12:59:02.219831   904 solver.cpp:229] Iteration 98720, loss = 2.56899
I0605 12:59:02.219997   904 solver.cpp:245]     Train net output #0: loss = 2.2047 (* 1 = 2.2047 loss)
I0605 12:59:02.220012   904 sgd_solver.cpp:106] Iteration 98720, lr = 0.0167718
I0605 12:59:22.757416   904 solver.cpp:229] Iteration 98760, loss = 2.55259
I0605 12:59:22.757472   904 solver.cpp:245]     Train net output #0: loss = 2.58489 (* 1 = 2.58489 loss)
I0605 12:59:22.757480   904 sgd_solver.cpp:106] Iteration 98760, lr = 0.0167624
I0605 12:59:43.100136   904 solver.cpp:229] Iteration 98800, loss = 2.541
I0605 12:59:43.100307   904 solver.cpp:245]     Train net output #0: loss = 2.85236 (* 1 = 2.85236 loss)
I0605 12:59:43.100322   904 sgd_solver.cpp:106] Iteration 98800, lr = 0.0167529
I0605 13:00:03.600442   904 solver.cpp:229] Iteration 98840, loss = 2.54632
I0605 13:00:03.600484   904 solver.cpp:245]     Train net output #0: loss = 2.44992 (* 1 = 2.44992 loss)
I0605 13:00:03.600494   904 sgd_solver.cpp:106] Iteration 98840, lr = 0.0167435
I0605 13:00:24.093350   904 solver.cpp:229] Iteration 98880, loss = 2.51541
I0605 13:00:24.093526   904 solver.cpp:245]     Train net output #0: loss = 2.35881 (* 1 = 2.35881 loss)
I0605 13:00:24.093539   904 sgd_solver.cpp:106] Iteration 98880, lr = 0.0167341
I0605 13:00:44.115031   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 13:00:44.621611   904 solver.cpp:229] Iteration 98920, loss = 2.51042
I0605 13:00:44.621660   904 solver.cpp:245]     Train net output #0: loss = 2.76117 (* 1 = 2.76117 loss)
I0605 13:00:44.621672   904 sgd_solver.cpp:106] Iteration 98920, lr = 0.0167247
I0605 13:01:04.924217   904 solver.cpp:229] Iteration 98960, loss = 2.55652
I0605 13:01:04.924439   904 solver.cpp:245]     Train net output #0: loss = 2.67889 (* 1 = 2.67889 loss)
I0605 13:01:04.924463   904 sgd_solver.cpp:106] Iteration 98960, lr = 0.0167153
I0605 13:01:24.934270   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_99000.caffemodel
I0605 13:01:25.203783   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_99000.solverstate
I0605 13:01:25.286183   904 solver.cpp:338] Iteration 99000, Testing net (#0)
I0605 13:01:25.286255   904 net.cpp:748] Ignoring source layer loss
I0605 13:01:54.822413   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 13:02:28.714665   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 13:02:33.509104   904 solver.cpp:406]     Test net output #0: accuracy = 0.445201
I0605 13:02:33.509141   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.694639
I0605 13:02:33.825371   904 solver.cpp:229] Iteration 99000, loss = 2.56368
I0605 13:02:33.825434   904 solver.cpp:245]     Train net output #0: loss = 2.39799 (* 1 = 2.39799 loss)
I0605 13:02:33.825453   904 sgd_solver.cpp:106] Iteration 99000, lr = 0.0167059
I0605 13:02:53.025069   904 solver.cpp:229] Iteration 99040, loss = 2.56592
I0605 13:02:53.025123   904 solver.cpp:245]     Train net output #0: loss = 2.80665 (* 1 = 2.80665 loss)
I0605 13:02:53.025143   904 sgd_solver.cpp:106] Iteration 99040, lr = 0.0166965
I0605 13:03:14.432235   904 solver.cpp:229] Iteration 99080, loss = 2.55376
I0605 13:03:14.432453   904 solver.cpp:245]     Train net output #0: loss = 2.50733 (* 1 = 2.50733 loss)
I0605 13:03:14.432482   904 sgd_solver.cpp:106] Iteration 99080, lr = 0.0166871
I0605 13:03:35.926319   904 solver.cpp:229] Iteration 99120, loss = 2.54736
I0605 13:03:35.926374   904 solver.cpp:245]     Train net output #0: loss = 2.53209 (* 1 = 2.53209 loss)
I0605 13:03:35.926383   904 sgd_solver.cpp:106] Iteration 99120, lr = 0.0166776
I0605 13:03:57.113307   904 solver.cpp:229] Iteration 99160, loss = 2.5753
I0605 13:03:57.113507   904 solver.cpp:245]     Train net output #0: loss = 2.59223 (* 1 = 2.59223 loss)
I0605 13:03:57.113533   904 sgd_solver.cpp:106] Iteration 99160, lr = 0.0166682
I0605 13:04:18.130139   904 solver.cpp:229] Iteration 99200, loss = 2.53606
I0605 13:04:18.130203   904 solver.cpp:245]     Train net output #0: loss = 2.56225 (* 1 = 2.56225 loss)
I0605 13:04:18.130216   904 sgd_solver.cpp:106] Iteration 99200, lr = 0.0166588
I0605 13:04:39.057073   904 solver.cpp:229] Iteration 99240, loss = 2.56252
I0605 13:04:39.057306   904 solver.cpp:245]     Train net output #0: loss = 2.48415 (* 1 = 2.48415 loss)
I0605 13:04:39.057329   904 sgd_solver.cpp:106] Iteration 99240, lr = 0.0166494
I0605 13:04:59.986207   904 solver.cpp:229] Iteration 99280, loss = 2.54158
I0605 13:04:59.986263   904 solver.cpp:245]     Train net output #0: loss = 2.91846 (* 1 = 2.91846 loss)
I0605 13:04:59.986274   904 sgd_solver.cpp:106] Iteration 99280, lr = 0.01664
I0605 13:05:20.919368   904 solver.cpp:229] Iteration 99320, loss = 2.51827
I0605 13:05:20.919512   904 solver.cpp:245]     Train net output #0: loss = 2.62106 (* 1 = 2.62106 loss)
I0605 13:05:20.919524   904 sgd_solver.cpp:106] Iteration 99320, lr = 0.0166306
I0605 13:05:41.802186   904 solver.cpp:229] Iteration 99360, loss = 2.53533
I0605 13:05:41.802238   904 solver.cpp:245]     Train net output #0: loss = 2.63516 (* 1 = 2.63516 loss)
I0605 13:05:41.802248   904 sgd_solver.cpp:106] Iteration 99360, lr = 0.0166212
I0605 13:06:02.545141   904 solver.cpp:229] Iteration 99400, loss = 2.53366
I0605 13:06:02.545276   904 solver.cpp:245]     Train net output #0: loss = 2.59391 (* 1 = 2.59391 loss)
I0605 13:06:02.545292   904 sgd_solver.cpp:106] Iteration 99400, lr = 0.0166118
I0605 13:06:23.174484   904 solver.cpp:229] Iteration 99440, loss = 2.54862
I0605 13:06:23.174588   904 solver.cpp:245]     Train net output #0: loss = 2.50064 (* 1 = 2.50064 loss)
I0605 13:06:23.174613   904 sgd_solver.cpp:106] Iteration 99440, lr = 0.0166024
I0605 13:06:29.349889   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 13:06:43.779151   904 solver.cpp:229] Iteration 99480, loss = 2.51824
I0605 13:06:43.779395   904 solver.cpp:245]     Train net output #0: loss = 2.6461 (* 1 = 2.6461 loss)
I0605 13:06:43.779427   904 sgd_solver.cpp:106] Iteration 99480, lr = 0.0165929
I0605 13:07:04.402215   904 solver.cpp:229] Iteration 99520, loss = 2.56103
I0605 13:07:04.402271   904 solver.cpp:245]     Train net output #0: loss = 2.52361 (* 1 = 2.52361 loss)
I0605 13:07:04.402281   904 sgd_solver.cpp:106] Iteration 99520, lr = 0.0165835
I0605 13:07:24.996507   904 solver.cpp:229] Iteration 99560, loss = 2.55248
I0605 13:07:24.996718   904 solver.cpp:245]     Train net output #0: loss = 2.76053 (* 1 = 2.76053 loss)
I0605 13:07:24.996731   904 sgd_solver.cpp:106] Iteration 99560, lr = 0.0165741
I0605 13:07:45.429272   904 solver.cpp:229] Iteration 99600, loss = 2.49959
I0605 13:07:45.429318   904 solver.cpp:245]     Train net output #0: loss = 2.51855 (* 1 = 2.51855 loss)
I0605 13:07:45.429328   904 sgd_solver.cpp:106] Iteration 99600, lr = 0.0165647
I0605 13:08:06.008366   904 solver.cpp:229] Iteration 99640, loss = 2.53076
I0605 13:08:06.008524   904 solver.cpp:245]     Train net output #0: loss = 2.44322 (* 1 = 2.44322 loss)
I0605 13:08:06.008538   904 sgd_solver.cpp:106] Iteration 99640, lr = 0.0165553
I0605 13:08:26.589650   904 solver.cpp:229] Iteration 99680, loss = 2.52741
I0605 13:08:26.589702   904 solver.cpp:245]     Train net output #0: loss = 2.67919 (* 1 = 2.67919 loss)
I0605 13:08:26.589712   904 sgd_solver.cpp:106] Iteration 99680, lr = 0.0165459
I0605 13:08:46.936414   904 solver.cpp:229] Iteration 99720, loss = 2.50856
I0605 13:08:46.936622   904 solver.cpp:245]     Train net output #0: loss = 2.51874 (* 1 = 2.51874 loss)
I0605 13:08:46.936650   904 sgd_solver.cpp:106] Iteration 99720, lr = 0.0165365
I0605 13:09:07.405486   904 solver.cpp:229] Iteration 99760, loss = 2.57236
I0605 13:09:07.405542   904 solver.cpp:245]     Train net output #0: loss = 2.65324 (* 1 = 2.65324 loss)
I0605 13:09:07.405555   904 sgd_solver.cpp:106] Iteration 99760, lr = 0.0165271
I0605 13:09:27.841804   904 solver.cpp:229] Iteration 99800, loss = 2.48888
I0605 13:09:27.841954   904 solver.cpp:245]     Train net output #0: loss = 2.5806 (* 1 = 2.5806 loss)
I0605 13:09:27.841965   904 sgd_solver.cpp:106] Iteration 99800, lr = 0.0165176
I0605 13:09:48.205330   904 solver.cpp:229] Iteration 99840, loss = 2.54351
I0605 13:09:48.205385   904 solver.cpp:245]     Train net output #0: loss = 2.59436 (* 1 = 2.59436 loss)
I0605 13:09:48.205395   904 sgd_solver.cpp:106] Iteration 99840, lr = 0.0165082
I0605 13:10:08.438951   904 solver.cpp:229] Iteration 99880, loss = 2.55572
I0605 13:10:08.439106   904 solver.cpp:245]     Train net output #0: loss = 2.41185 (* 1 = 2.41185 loss)
I0605 13:10:08.439126   904 sgd_solver.cpp:106] Iteration 99880, lr = 0.0164988
I0605 13:10:28.656891   904 solver.cpp:229] Iteration 99920, loss = 2.53658
I0605 13:10:28.656951   904 solver.cpp:245]     Train net output #0: loss = 2.44622 (* 1 = 2.44622 loss)
I0605 13:10:28.656961   904 sgd_solver.cpp:106] Iteration 99920, lr = 0.0164894
I0605 13:10:48.878259   904 solver.cpp:229] Iteration 99960, loss = 2.5389
I0605 13:10:48.878473   904 solver.cpp:245]     Train net output #0: loss = 2.48882 (* 1 = 2.48882 loss)
I0605 13:10:48.878499   904 sgd_solver.cpp:106] Iteration 99960, lr = 0.01648
I0605 13:11:02.041332   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 13:11:08.612216   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_100000.caffemodel
I0605 13:11:08.875361   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_100000.solverstate
I0605 13:11:08.954393   904 solver.cpp:338] Iteration 100000, Testing net (#0)
I0605 13:11:08.954473   904 net.cpp:748] Ignoring source layer loss
I0605 13:11:43.237362   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 13:12:19.974370   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 13:12:20.729463   904 solver.cpp:406]     Test net output #0: accuracy = 0.443721
I0605 13:12:20.729539   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.6944
I0605 13:12:21.043411   904 solver.cpp:229] Iteration 100000, loss = 2.55246
I0605 13:12:21.043469   904 solver.cpp:245]     Train net output #0: loss = 2.56325 (* 1 = 2.56325 loss)
I0605 13:12:21.043480   904 sgd_solver.cpp:106] Iteration 100000, lr = 0.0164706
I0605 13:12:40.261534   904 solver.cpp:229] Iteration 100040, loss = 2.57274
I0605 13:12:40.261579   904 solver.cpp:245]     Train net output #0: loss = 2.77536 (* 1 = 2.77536 loss)
I0605 13:12:40.261590   904 sgd_solver.cpp:106] Iteration 100040, lr = 0.0164612
I0605 13:13:01.683984   904 solver.cpp:229] Iteration 100080, loss = 2.53376
I0605 13:13:01.684247   904 solver.cpp:245]     Train net output #0: loss = 2.70941 (* 1 = 2.70941 loss)
I0605 13:13:01.684272   904 sgd_solver.cpp:106] Iteration 100080, lr = 0.0164518
I0605 13:13:23.186942   904 solver.cpp:229] Iteration 100120, loss = 2.56341
I0605 13:13:23.186998   904 solver.cpp:245]     Train net output #0: loss = 2.65385 (* 1 = 2.65385 loss)
I0605 13:13:23.187008   904 sgd_solver.cpp:106] Iteration 100120, lr = 0.0164424
I0605 13:13:44.219347   904 solver.cpp:229] Iteration 100160, loss = 2.56616
I0605 13:13:44.219578   904 solver.cpp:245]     Train net output #0: loss = 2.64518 (* 1 = 2.64518 loss)
I0605 13:13:44.219600   904 sgd_solver.cpp:106] Iteration 100160, lr = 0.0164329
I0605 13:14:05.219728   904 solver.cpp:229] Iteration 100200, loss = 2.58622
I0605 13:14:05.219769   904 solver.cpp:245]     Train net output #0: loss = 2.13038 (* 1 = 2.13038 loss)
I0605 13:14:05.219777   904 sgd_solver.cpp:106] Iteration 100200, lr = 0.0164235
I0605 13:14:26.223357   904 solver.cpp:229] Iteration 100240, loss = 2.52505
I0605 13:14:26.223574   904 solver.cpp:245]     Train net output #0: loss = 2.6851 (* 1 = 2.6851 loss)
I0605 13:14:26.223599   904 sgd_solver.cpp:106] Iteration 100240, lr = 0.0164141
I0605 13:14:47.239589   904 solver.cpp:229] Iteration 100280, loss = 2.56744
I0605 13:14:47.239637   904 solver.cpp:245]     Train net output #0: loss = 2.54843 (* 1 = 2.54843 loss)
I0605 13:14:47.239648   904 sgd_solver.cpp:106] Iteration 100280, lr = 0.0164047
I0605 13:15:08.040808   904 solver.cpp:229] Iteration 100320, loss = 2.54463
I0605 13:15:08.040973   904 solver.cpp:245]     Train net output #0: loss = 2.7566 (* 1 = 2.7566 loss)
I0605 13:15:08.040989   904 sgd_solver.cpp:106] Iteration 100320, lr = 0.0163953
I0605 13:15:28.855317   904 solver.cpp:229] Iteration 100360, loss = 2.54979
I0605 13:15:28.855376   904 solver.cpp:245]     Train net output #0: loss = 2.70716 (* 1 = 2.70716 loss)
I0605 13:15:28.855387   904 sgd_solver.cpp:106] Iteration 100360, lr = 0.0163859
I0605 13:15:49.543900   904 solver.cpp:229] Iteration 100400, loss = 2.57024
I0605 13:15:49.544087   904 solver.cpp:245]     Train net output #0: loss = 2.61173 (* 1 = 2.61173 loss)
I0605 13:15:49.544100   904 sgd_solver.cpp:106] Iteration 100400, lr = 0.0163765
I0605 13:16:10.229282   904 solver.cpp:229] Iteration 100440, loss = 2.53668
I0605 13:16:10.229343   904 solver.cpp:245]     Train net output #0: loss = 2.5719 (* 1 = 2.5719 loss)
I0605 13:16:10.229359   904 sgd_solver.cpp:106] Iteration 100440, lr = 0.0163671
I0605 13:16:30.972884   904 solver.cpp:229] Iteration 100480, loss = 2.51931
I0605 13:16:30.973036   904 solver.cpp:245]     Train net output #0: loss = 2.60746 (* 1 = 2.60746 loss)
I0605 13:16:30.973047   904 sgd_solver.cpp:106] Iteration 100480, lr = 0.0163576
I0605 13:16:46.367919   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 13:16:51.489490   904 solver.cpp:229] Iteration 100520, loss = 2.54972
I0605 13:16:51.489543   904 solver.cpp:245]     Train net output #0: loss = 2.78337 (* 1 = 2.78337 loss)
I0605 13:16:51.489552   904 sgd_solver.cpp:106] Iteration 100520, lr = 0.0163482
I0605 13:17:12.004019   904 solver.cpp:229] Iteration 100560, loss = 2.54903
I0605 13:17:12.004282   904 solver.cpp:245]     Train net output #0: loss = 2.65951 (* 1 = 2.65951 loss)
I0605 13:17:12.004323   904 sgd_solver.cpp:106] Iteration 100560, lr = 0.0163388
I0605 13:17:32.527081   904 solver.cpp:229] Iteration 100600, loss = 2.56771
I0605 13:17:32.527138   904 solver.cpp:245]     Train net output #0: loss = 2.56547 (* 1 = 2.56547 loss)
I0605 13:17:32.527148   904 sgd_solver.cpp:106] Iteration 100600, lr = 0.0163294
I0605 13:17:53.137980   904 solver.cpp:229] Iteration 100640, loss = 2.49131
I0605 13:17:53.138231   904 solver.cpp:245]     Train net output #0: loss = 2.46782 (* 1 = 2.46782 loss)
I0605 13:17:53.138252   904 sgd_solver.cpp:106] Iteration 100640, lr = 0.01632
I0605 13:18:13.604627   904 solver.cpp:229] Iteration 100680, loss = 2.54962
I0605 13:18:13.604682   904 solver.cpp:245]     Train net output #0: loss = 2.50961 (* 1 = 2.50961 loss)
I0605 13:18:13.604691   904 sgd_solver.cpp:106] Iteration 100680, lr = 0.0163106
I0605 13:18:33.887724   904 solver.cpp:229] Iteration 100720, loss = 2.54995
I0605 13:18:33.887950   904 solver.cpp:245]     Train net output #0: loss = 2.62086 (* 1 = 2.62086 loss)
I0605 13:18:33.887974   904 sgd_solver.cpp:106] Iteration 100720, lr = 0.0163012
I0605 13:18:54.188938   904 solver.cpp:229] Iteration 100760, loss = 2.5558
I0605 13:18:54.188982   904 solver.cpp:245]     Train net output #0: loss = 2.50528 (* 1 = 2.50528 loss)
I0605 13:18:54.188992   904 sgd_solver.cpp:106] Iteration 100760, lr = 0.0162918
I0605 13:19:14.590934   904 solver.cpp:229] Iteration 100800, loss = 2.51957
I0605 13:19:14.591137   904 solver.cpp:245]     Train net output #0: loss = 2.31738 (* 1 = 2.31738 loss)
I0605 13:19:14.591162   904 sgd_solver.cpp:106] Iteration 100800, lr = 0.0162824
I0605 13:19:35.100477   904 solver.cpp:229] Iteration 100840, loss = 2.58251
I0605 13:19:35.100517   904 solver.cpp:245]     Train net output #0: loss = 2.67465 (* 1 = 2.67465 loss)
I0605 13:19:35.100525   904 sgd_solver.cpp:106] Iteration 100840, lr = 0.0162729
I0605 13:19:55.484411   904 solver.cpp:229] Iteration 100880, loss = 2.52747
I0605 13:19:55.484639   904 solver.cpp:245]     Train net output #0: loss = 2.79661 (* 1 = 2.79661 loss)
I0605 13:19:55.484660   904 sgd_solver.cpp:106] Iteration 100880, lr = 0.0162635
I0605 13:20:15.785434   904 solver.cpp:229] Iteration 100920, loss = 2.49468
I0605 13:20:15.785477   904 solver.cpp:245]     Train net output #0: loss = 2.30689 (* 1 = 2.30689 loss)
I0605 13:20:15.785487   904 sgd_solver.cpp:106] Iteration 100920, lr = 0.0162541
I0605 13:20:36.090167   904 solver.cpp:229] Iteration 100960, loss = 2.53917
I0605 13:20:36.090401   904 solver.cpp:245]     Train net output #0: loss = 2.8163 (* 1 = 2.8163 loss)
I0605 13:20:36.090427   904 sgd_solver.cpp:106] Iteration 100960, lr = 0.0162447
I0605 13:20:55.887984   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_101000.caffemodel
I0605 13:20:56.150501   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_101000.solverstate
I0605 13:20:56.229493   904 solver.cpp:338] Iteration 101000, Testing net (#0)
I0605 13:20:56.229576   904 net.cpp:748] Ignoring source layer loss
I0605 13:20:58.541093   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 13:21:33.054278   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 13:22:06.217038   904 solver.cpp:406]     Test net output #0: accuracy = 0.445161
I0605 13:22:06.217236   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.695979
I0605 13:22:06.530429   904 solver.cpp:229] Iteration 101000, loss = 2.53348
I0605 13:22:06.530473   904 solver.cpp:245]     Train net output #0: loss = 2.52497 (* 1 = 2.52497 loss)
I0605 13:22:06.530484   904 sgd_solver.cpp:106] Iteration 101000, lr = 0.0162353
I0605 13:22:23.327356   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 13:22:25.722942   904 solver.cpp:229] Iteration 101040, loss = 2.5022
I0605 13:22:25.722986   904 solver.cpp:245]     Train net output #0: loss = 2.52497 (* 1 = 2.52497 loss)
I0605 13:22:25.722995   904 sgd_solver.cpp:106] Iteration 101040, lr = 0.0162259
I0605 13:22:47.159330   904 solver.cpp:229] Iteration 101080, loss = 2.50879
I0605 13:22:47.159479   904 solver.cpp:245]     Train net output #0: loss = 2.54843 (* 1 = 2.54843 loss)
I0605 13:22:47.159492   904 sgd_solver.cpp:106] Iteration 101080, lr = 0.0162165
I0605 13:23:08.760691   904 solver.cpp:229] Iteration 101120, loss = 2.50969
I0605 13:23:08.760751   904 solver.cpp:245]     Train net output #0: loss = 2.49736 (* 1 = 2.49736 loss)
I0605 13:23:08.760764   904 sgd_solver.cpp:106] Iteration 101120, lr = 0.0162071
I0605 13:23:30.111695   904 solver.cpp:229] Iteration 101160, loss = 2.51868
I0605 13:23:30.111933   904 solver.cpp:245]     Train net output #0: loss = 2.41473 (* 1 = 2.41473 loss)
I0605 13:23:30.111953   904 sgd_solver.cpp:106] Iteration 101160, lr = 0.0161976
I0605 13:23:51.110193   904 solver.cpp:229] Iteration 101200, loss = 2.50225
I0605 13:23:51.110234   904 solver.cpp:245]     Train net output #0: loss = 2.72511 (* 1 = 2.72511 loss)
I0605 13:23:51.110244   904 sgd_solver.cpp:106] Iteration 101200, lr = 0.0161882
I0605 13:24:12.257541   904 solver.cpp:229] Iteration 101240, loss = 2.55773
I0605 13:24:12.257747   904 solver.cpp:245]     Train net output #0: loss = 2.61112 (* 1 = 2.61112 loss)
I0605 13:24:12.257776   904 sgd_solver.cpp:106] Iteration 101240, lr = 0.0161788
I0605 13:24:33.377192   904 solver.cpp:229] Iteration 101280, loss = 2.51883
I0605 13:24:33.377236   904 solver.cpp:245]     Train net output #0: loss = 2.50754 (* 1 = 2.50754 loss)
I0605 13:24:33.377250   904 sgd_solver.cpp:106] Iteration 101280, lr = 0.0161694
I0605 13:24:54.372797   904 solver.cpp:229] Iteration 101320, loss = 2.5438
I0605 13:24:54.373023   904 solver.cpp:245]     Train net output #0: loss = 2.7107 (* 1 = 2.7107 loss)
I0605 13:24:54.373051   904 sgd_solver.cpp:106] Iteration 101320, lr = 0.01616
I0605 13:25:15.356940   904 solver.cpp:229] Iteration 101360, loss = 2.50401
I0605 13:25:15.356984   904 solver.cpp:245]     Train net output #0: loss = 2.6891 (* 1 = 2.6891 loss)
I0605 13:25:15.356994   904 sgd_solver.cpp:106] Iteration 101360, lr = 0.0161506
I0605 13:25:36.167333   904 solver.cpp:229] Iteration 101400, loss = 2.47889
I0605 13:25:36.167462   904 solver.cpp:245]     Train net output #0: loss = 2.56215 (* 1 = 2.56215 loss)
I0605 13:25:36.167479   904 sgd_solver.cpp:106] Iteration 101400, lr = 0.0161412
I0605 13:25:56.992053   904 solver.cpp:229] Iteration 101440, loss = 2.52538
I0605 13:25:56.992110   904 solver.cpp:245]     Train net output #0: loss = 2.6942 (* 1 = 2.6942 loss)
I0605 13:25:56.992118   904 sgd_solver.cpp:106] Iteration 101440, lr = 0.0161318
I0605 13:26:17.795186   904 solver.cpp:229] Iteration 101480, loss = 2.52712
I0605 13:26:17.795465   904 solver.cpp:245]     Train net output #0: loss = 2.52459 (* 1 = 2.52459 loss)
I0605 13:26:17.795490   904 sgd_solver.cpp:106] Iteration 101480, lr = 0.0161224
I0605 13:26:38.614006   904 solver.cpp:229] Iteration 101520, loss = 2.54468
I0605 13:26:38.614053   904 solver.cpp:245]     Train net output #0: loss = 2.41776 (* 1 = 2.41776 loss)
I0605 13:26:38.614064   904 sgd_solver.cpp:106] Iteration 101520, lr = 0.0161129
I0605 13:26:55.780827   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 13:26:59.423704   904 solver.cpp:229] Iteration 101560, loss = 2.53589
I0605 13:26:59.423758   904 solver.cpp:245]     Train net output #0: loss = 2.74195 (* 1 = 2.74195 loss)
I0605 13:26:59.423768   904 sgd_solver.cpp:106] Iteration 101560, lr = 0.0161035
I0605 13:27:20.191650   904 solver.cpp:229] Iteration 101600, loss = 2.49366
I0605 13:27:20.191709   904 solver.cpp:245]     Train net output #0: loss = 2.48473 (* 1 = 2.48473 loss)
I0605 13:27:20.191720   904 sgd_solver.cpp:106] Iteration 101600, lr = 0.0160941
I0605 13:27:40.860453   904 solver.cpp:229] Iteration 101640, loss = 2.55002
I0605 13:27:40.860697   904 solver.cpp:245]     Train net output #0: loss = 2.42753 (* 1 = 2.42753 loss)
I0605 13:27:40.860708   904 sgd_solver.cpp:106] Iteration 101640, lr = 0.0160847
I0605 13:28:01.541646   904 solver.cpp:229] Iteration 101680, loss = 2.5167
I0605 13:28:01.541692   904 solver.cpp:245]     Train net output #0: loss = 2.25819 (* 1 = 2.25819 loss)
I0605 13:28:01.541702   904 sgd_solver.cpp:106] Iteration 101680, lr = 0.0160753
I0605 13:28:22.206861   904 solver.cpp:229] Iteration 101720, loss = 2.54701
I0605 13:28:22.207082   904 solver.cpp:245]     Train net output #0: loss = 2.74541 (* 1 = 2.74541 loss)
I0605 13:28:22.207104   904 sgd_solver.cpp:106] Iteration 101720, lr = 0.0160659
I0605 13:28:42.845027   904 solver.cpp:229] Iteration 101760, loss = 2.54161
I0605 13:28:42.845068   904 solver.cpp:245]     Train net output #0: loss = 2.71811 (* 1 = 2.71811 loss)
I0605 13:28:42.845077   904 sgd_solver.cpp:106] Iteration 101760, lr = 0.0160565
I0605 13:29:03.488831   904 solver.cpp:229] Iteration 101800, loss = 2.51917
I0605 13:29:03.489195   904 solver.cpp:245]     Train net output #0: loss = 2.39268 (* 1 = 2.39268 loss)
I0605 13:29:03.489236   904 sgd_solver.cpp:106] Iteration 101800, lr = 0.0160471
I0605 13:29:24.140544   904 solver.cpp:229] Iteration 101840, loss = 2.49477
I0605 13:29:24.140593   904 solver.cpp:245]     Train net output #0: loss = 2.45044 (* 1 = 2.45044 loss)
I0605 13:29:24.140604   904 sgd_solver.cpp:106] Iteration 101840, lr = 0.0160376
I0605 13:29:44.645097   904 solver.cpp:229] Iteration 101880, loss = 2.54188
I0605 13:29:44.645321   904 solver.cpp:245]     Train net output #0: loss = 2.45504 (* 1 = 2.45504 loss)
I0605 13:29:44.645347   904 sgd_solver.cpp:106] Iteration 101880, lr = 0.0160282
I0605 13:30:05.143348   904 solver.cpp:229] Iteration 101920, loss = 2.48228
I0605 13:30:05.143401   904 solver.cpp:245]     Train net output #0: loss = 2.5127 (* 1 = 2.5127 loss)
I0605 13:30:05.143411   904 sgd_solver.cpp:106] Iteration 101920, lr = 0.0160188
I0605 13:30:25.660303   904 solver.cpp:229] Iteration 101960, loss = 2.50955
I0605 13:30:25.660452   904 solver.cpp:245]     Train net output #0: loss = 2.22975 (* 1 = 2.22975 loss)
I0605 13:30:25.660465   904 sgd_solver.cpp:106] Iteration 101960, lr = 0.0160094
I0605 13:30:45.662665   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_102000.caffemodel
I0605 13:30:45.937127   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_102000.solverstate
I0605 13:30:46.014211   904 solver.cpp:338] Iteration 102000, Testing net (#0)
I0605 13:30:46.014287   904 net.cpp:748] Ignoring source layer loss
I0605 13:30:51.094483   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 13:31:27.510421   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 13:31:57.904248   904 solver.cpp:406]     Test net output #0: accuracy = 0.443601
I0605 13:31:57.904507   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.692599
I0605 13:31:58.220451   904 solver.cpp:229] Iteration 102000, loss = 2.51891
I0605 13:31:58.220499   904 solver.cpp:245]     Train net output #0: loss = 2.44313 (* 1 = 2.44313 loss)
I0605 13:31:58.220510   904 sgd_solver.cpp:106] Iteration 102000, lr = 0.016
I0605 13:32:17.393892   904 solver.cpp:229] Iteration 102040, loss = 2.50077
I0605 13:32:17.393954   904 solver.cpp:245]     Train net output #0: loss = 2.6006 (* 1 = 2.6006 loss)
I0605 13:32:17.393964   904 sgd_solver.cpp:106] Iteration 102040, lr = 0.0159906
I0605 13:32:38.243590   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 13:32:38.776757   904 solver.cpp:229] Iteration 102080, loss = 2.50822
I0605 13:32:38.776816   904 solver.cpp:245]     Train net output #0: loss = 2.52623 (* 1 = 2.52623 loss)
I0605 13:32:38.776828   904 sgd_solver.cpp:106] Iteration 102080, lr = 0.0159812
I0605 13:32:59.829838   904 solver.cpp:229] Iteration 102120, loss = 2.52351
I0605 13:32:59.829890   904 solver.cpp:245]     Train net output #0: loss = 2.43685 (* 1 = 2.43685 loss)
I0605 13:32:59.829900   904 sgd_solver.cpp:106] Iteration 102120, lr = 0.0159718
I0605 13:33:20.366328   904 solver.cpp:229] Iteration 102160, loss = 2.50401
I0605 13:33:20.366555   904 solver.cpp:245]     Train net output #0: loss = 2.57264 (* 1 = 2.57264 loss)
I0605 13:33:20.366585   904 sgd_solver.cpp:106] Iteration 102160, lr = 0.0159624
I0605 13:33:40.864804   904 solver.cpp:229] Iteration 102200, loss = 2.53757
I0605 13:33:40.864859   904 solver.cpp:245]     Train net output #0: loss = 2.60174 (* 1 = 2.60174 loss)
I0605 13:33:40.864871   904 sgd_solver.cpp:106] Iteration 102200, lr = 0.0159529
I0605 13:34:01.350410   904 solver.cpp:229] Iteration 102240, loss = 2.50495
I0605 13:34:01.350563   904 solver.cpp:245]     Train net output #0: loss = 2.32948 (* 1 = 2.32948 loss)
I0605 13:34:01.350574   904 sgd_solver.cpp:106] Iteration 102240, lr = 0.0159435
I0605 13:34:21.692791   904 solver.cpp:229] Iteration 102280, loss = 2.56225
I0605 13:34:21.692839   904 solver.cpp:245]     Train net output #0: loss = 2.37511 (* 1 = 2.37511 loss)
I0605 13:34:21.692848   904 sgd_solver.cpp:106] Iteration 102280, lr = 0.0159341
I0605 13:34:41.978606   904 solver.cpp:229] Iteration 102320, loss = 2.49211
I0605 13:34:41.978881   904 solver.cpp:245]     Train net output #0: loss = 2.37875 (* 1 = 2.37875 loss)
I0605 13:34:41.978907   904 sgd_solver.cpp:106] Iteration 102320, lr = 0.0159247
I0605 13:35:02.252408   904 solver.cpp:229] Iteration 102360, loss = 2.54245
I0605 13:35:02.252461   904 solver.cpp:245]     Train net output #0: loss = 2.75447 (* 1 = 2.75447 loss)
I0605 13:35:02.252470   904 sgd_solver.cpp:106] Iteration 102360, lr = 0.0159153
I0605 13:35:22.554121   904 solver.cpp:229] Iteration 102400, loss = 2.51013
I0605 13:35:22.554311   904 solver.cpp:245]     Train net output #0: loss = 2.47978 (* 1 = 2.47978 loss)
I0605 13:35:22.554338   904 sgd_solver.cpp:106] Iteration 102400, lr = 0.0159059
I0605 13:35:42.932396   904 solver.cpp:229] Iteration 102440, loss = 2.50055
I0605 13:35:42.932438   904 solver.cpp:245]     Train net output #0: loss = 2.66308 (* 1 = 2.66308 loss)
I0605 13:35:42.932447   904 sgd_solver.cpp:106] Iteration 102440, lr = 0.0158965
I0605 13:36:03.431314   904 solver.cpp:229] Iteration 102480, loss = 2.53651
I0605 13:36:03.431485   904 solver.cpp:245]     Train net output #0: loss = 2.4995 (* 1 = 2.4995 loss)
I0605 13:36:03.431498   904 sgd_solver.cpp:106] Iteration 102480, lr = 0.0158871
I0605 13:36:23.904085   904 solver.cpp:229] Iteration 102520, loss = 2.51087
I0605 13:36:23.904130   904 solver.cpp:245]     Train net output #0: loss = 2.43923 (* 1 = 2.43923 loss)
I0605 13:36:23.904139   904 sgd_solver.cpp:106] Iteration 102520, lr = 0.0158776
I0605 13:36:44.397272   904 solver.cpp:229] Iteration 102560, loss = 2.51593
I0605 13:36:44.397418   904 solver.cpp:245]     Train net output #0: loss = 2.48546 (* 1 = 2.48546 loss)
I0605 13:36:44.397426   904 sgd_solver.cpp:106] Iteration 102560, lr = 0.0158682
I0605 13:37:04.890710   904 solver.cpp:229] Iteration 102600, loss = 2.549
I0605 13:37:04.890758   904 solver.cpp:245]     Train net output #0: loss = 2.885 (* 1 = 2.885 loss)
I0605 13:37:04.890769   904 sgd_solver.cpp:106] Iteration 102600, lr = 0.0158588
I0605 13:37:07.455394   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 13:37:25.372709   904 solver.cpp:229] Iteration 102640, loss = 2.52973
I0605 13:37:25.372931   904 solver.cpp:245]     Train net output #0: loss = 2.62344 (* 1 = 2.62344 loss)
I0605 13:37:25.372956   904 sgd_solver.cpp:106] Iteration 102640, lr = 0.0158494
I0605 13:37:45.875294   904 solver.cpp:229] Iteration 102680, loss = 2.53225
I0605 13:37:45.875346   904 solver.cpp:245]     Train net output #0: loss = 2.79923 (* 1 = 2.79923 loss)
I0605 13:37:45.875355   904 sgd_solver.cpp:106] Iteration 102680, lr = 0.01584
I0605 13:38:06.248975   904 solver.cpp:229] Iteration 102720, loss = 2.5216
I0605 13:38:06.249110   904 solver.cpp:245]     Train net output #0: loss = 2.44709 (* 1 = 2.44709 loss)
I0605 13:38:06.249124   904 sgd_solver.cpp:106] Iteration 102720, lr = 0.0158306
I0605 13:38:26.515326   904 solver.cpp:229] Iteration 102760, loss = 2.53466
I0605 13:38:26.515378   904 solver.cpp:245]     Train net output #0: loss = 2.6793 (* 1 = 2.6793 loss)
I0605 13:38:26.515398   904 sgd_solver.cpp:106] Iteration 102760, lr = 0.0158212
I0605 13:38:46.823534   904 solver.cpp:229] Iteration 102800, loss = 2.53844
I0605 13:38:46.823678   904 solver.cpp:245]     Train net output #0: loss = 2.63719 (* 1 = 2.63719 loss)
I0605 13:38:46.823691   904 sgd_solver.cpp:106] Iteration 102800, lr = 0.0158118
I0605 13:39:07.218935   904 solver.cpp:229] Iteration 102840, loss = 2.52548
I0605 13:39:07.218986   904 solver.cpp:245]     Train net output #0: loss = 2.48892 (* 1 = 2.48892 loss)
I0605 13:39:07.218998   904 sgd_solver.cpp:106] Iteration 102840, lr = 0.0158024
I0605 13:39:27.633903   904 solver.cpp:229] Iteration 102880, loss = 2.56223
I0605 13:39:27.634155   904 solver.cpp:245]     Train net output #0: loss = 2.2968 (* 1 = 2.2968 loss)
I0605 13:39:27.634184   904 sgd_solver.cpp:106] Iteration 102880, lr = 0.0157929
I0605 13:39:47.910022   904 solver.cpp:229] Iteration 102920, loss = 2.51221
I0605 13:39:47.910073   904 solver.cpp:245]     Train net output #0: loss = 2.41587 (* 1 = 2.41587 loss)
I0605 13:39:47.910082   904 sgd_solver.cpp:106] Iteration 102920, lr = 0.0157835
I0605 13:40:08.201433   904 solver.cpp:229] Iteration 102960, loss = 2.51
I0605 13:40:08.201581   904 solver.cpp:245]     Train net output #0: loss = 2.39858 (* 1 = 2.39858 loss)
I0605 13:40:08.201592   904 sgd_solver.cpp:106] Iteration 102960, lr = 0.0157741
I0605 13:40:27.984670   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_103000.caffemodel
I0605 13:40:28.243312   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_103000.solverstate
I0605 13:40:28.324697   904 solver.cpp:338] Iteration 103000, Testing net (#0)
I0605 13:40:28.324774   904 net.cpp:748] Ignoring source layer loss
I0605 13:40:37.406904   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 13:41:11.374012   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 13:41:37.156471   904 solver.cpp:406]     Test net output #0: accuracy = 0.450101
I0605 13:41:37.156518   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.7022
I0605 13:41:37.469986   904 solver.cpp:229] Iteration 103000, loss = 2.50731
I0605 13:41:37.470031   904 solver.cpp:245]     Train net output #0: loss = 2.28395 (* 1 = 2.28395 loss)
I0605 13:41:37.470041   904 sgd_solver.cpp:106] Iteration 103000, lr = 0.0157647
I0605 13:41:56.667278   904 solver.cpp:229] Iteration 103040, loss = 2.54657
I0605 13:41:56.667505   904 solver.cpp:245]     Train net output #0: loss = 2.59387 (* 1 = 2.59387 loss)
I0605 13:41:56.667531   904 sgd_solver.cpp:106] Iteration 103040, lr = 0.0157553
I0605 13:42:18.053585   904 solver.cpp:229] Iteration 103080, loss = 2.56497
I0605 13:42:18.053639   904 solver.cpp:245]     Train net output #0: loss = 2.32595 (* 1 = 2.32595 loss)
I0605 13:42:18.053650   904 sgd_solver.cpp:106] Iteration 103080, lr = 0.0157459
I0605 13:42:39.522727   904 solver.cpp:229] Iteration 103120, loss = 2.50525
I0605 13:42:39.522884   904 solver.cpp:245]     Train net output #0: loss = 2.281 (* 1 = 2.281 loss)
I0605 13:42:39.522896   904 sgd_solver.cpp:106] Iteration 103120, lr = 0.0157365
I0605 13:42:50.020300   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 13:43:00.510248   904 solver.cpp:229] Iteration 103160, loss = 2.50782
I0605 13:43:00.510304   904 solver.cpp:245]     Train net output #0: loss = 2.56481 (* 1 = 2.56481 loss)
I0605 13:43:00.510314   904 sgd_solver.cpp:106] Iteration 103160, lr = 0.0157271
I0605 13:43:21.488102   904 solver.cpp:229] Iteration 103200, loss = 2.53648
I0605 13:43:21.488293   904 solver.cpp:245]     Train net output #0: loss = 2.39201 (* 1 = 2.39201 loss)
I0605 13:43:21.488317   904 sgd_solver.cpp:106] Iteration 103200, lr = 0.0157176
I0605 13:43:42.478291   904 solver.cpp:229] Iteration 103240, loss = 2.55262
I0605 13:43:42.478327   904 solver.cpp:245]     Train net output #0: loss = 2.48072 (* 1 = 2.48072 loss)
I0605 13:43:42.478334   904 sgd_solver.cpp:106] Iteration 103240, lr = 0.0157082
I0605 13:44:03.633275   904 solver.cpp:229] Iteration 103280, loss = 2.50087
I0605 13:44:03.633457   904 solver.cpp:245]     Train net output #0: loss = 2.39808 (* 1 = 2.39808 loss)
I0605 13:44:03.633488   904 sgd_solver.cpp:106] Iteration 103280, lr = 0.0156988
I0605 13:44:24.269755   904 solver.cpp:229] Iteration 103320, loss = 2.51345
I0605 13:44:24.269816   904 solver.cpp:245]     Train net output #0: loss = 2.08064 (* 1 = 2.08064 loss)
I0605 13:44:24.269827   904 sgd_solver.cpp:106] Iteration 103320, lr = 0.0156894
I0605 13:44:45.131955   904 solver.cpp:229] Iteration 103360, loss = 2.55875
I0605 13:44:45.132151   904 solver.cpp:245]     Train net output #0: loss = 2.4794 (* 1 = 2.4794 loss)
I0605 13:44:45.132164   904 sgd_solver.cpp:106] Iteration 103360, lr = 0.01568
I0605 13:45:05.646965   904 solver.cpp:229] Iteration 103400, loss = 2.50435
I0605 13:45:05.647011   904 solver.cpp:245]     Train net output #0: loss = 2.38236 (* 1 = 2.38236 loss)
I0605 13:45:05.647019   904 sgd_solver.cpp:106] Iteration 103400, lr = 0.0156706
I0605 13:45:26.245262   904 solver.cpp:229] Iteration 103440, loss = 2.5279
I0605 13:45:26.245419   904 solver.cpp:245]     Train net output #0: loss = 2.41023 (* 1 = 2.41023 loss)
I0605 13:45:26.245430   904 sgd_solver.cpp:106] Iteration 103440, lr = 0.0156612
I0605 13:45:46.889173   904 solver.cpp:229] Iteration 103480, loss = 2.54011
I0605 13:45:46.889217   904 solver.cpp:245]     Train net output #0: loss = 2.45489 (* 1 = 2.45489 loss)
I0605 13:45:46.889226   904 sgd_solver.cpp:106] Iteration 103480, lr = 0.0156518
I0605 13:46:07.410343   904 solver.cpp:229] Iteration 103520, loss = 2.52425
I0605 13:46:07.410552   904 solver.cpp:245]     Train net output #0: loss = 2.27847 (* 1 = 2.27847 loss)
I0605 13:46:07.410570   904 sgd_solver.cpp:106] Iteration 103520, lr = 0.0156424
I0605 13:46:27.942728   904 solver.cpp:229] Iteration 103560, loss = 2.511
I0605 13:46:27.942778   904 solver.cpp:245]     Train net output #0: loss = 2.6577 (* 1 = 2.6577 loss)
I0605 13:46:27.942788   904 sgd_solver.cpp:106] Iteration 103560, lr = 0.0156329
I0605 13:46:48.457231   904 solver.cpp:229] Iteration 103600, loss = 2.49577
I0605 13:46:48.457422   904 solver.cpp:245]     Train net output #0: loss = 2.29758 (* 1 = 2.29758 loss)
I0605 13:46:48.457448   904 sgd_solver.cpp:106] Iteration 103600, lr = 0.0156235
I0605 13:47:08.967057   904 solver.cpp:229] Iteration 103640, loss = 2.53226
I0605 13:47:08.967152   904 solver.cpp:245]     Train net output #0: loss = 2.77718 (* 1 = 2.77718 loss)
I0605 13:47:08.967173   904 sgd_solver.cpp:106] Iteration 103640, lr = 0.0156141
I0605 13:47:21.964023   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 13:47:29.338325   904 solver.cpp:229] Iteration 103680, loss = 2.50389
I0605 13:47:29.338382   904 solver.cpp:245]     Train net output #0: loss = 2.29062 (* 1 = 2.29062 loss)
I0605 13:47:29.338392   904 sgd_solver.cpp:106] Iteration 103680, lr = 0.0156047
I0605 13:47:49.637679   904 solver.cpp:229] Iteration 103720, loss = 2.52094
I0605 13:47:49.637732   904 solver.cpp:245]     Train net output #0: loss = 2.51945 (* 1 = 2.51945 loss)
I0605 13:47:49.637740   904 sgd_solver.cpp:106] Iteration 103720, lr = 0.0155953
I0605 13:48:10.152786   904 solver.cpp:229] Iteration 103760, loss = 2.48992
I0605 13:48:10.152925   904 solver.cpp:245]     Train net output #0: loss = 2.32304 (* 1 = 2.32304 loss)
I0605 13:48:10.152936   904 sgd_solver.cpp:106] Iteration 103760, lr = 0.0155859
I0605 13:48:30.568436   904 solver.cpp:229] Iteration 103800, loss = 2.49455
I0605 13:48:30.568485   904 solver.cpp:245]     Train net output #0: loss = 2.46401 (* 1 = 2.46401 loss)
I0605 13:48:30.568492   904 sgd_solver.cpp:106] Iteration 103800, lr = 0.0155765
I0605 13:48:50.855901   904 solver.cpp:229] Iteration 103840, loss = 2.52905
I0605 13:48:50.856113   904 solver.cpp:245]     Train net output #0: loss = 2.44201 (* 1 = 2.44201 loss)
I0605 13:48:50.856134   904 sgd_solver.cpp:106] Iteration 103840, lr = 0.0155671
I0605 13:49:11.151419   904 solver.cpp:229] Iteration 103880, loss = 2.48716
I0605 13:49:11.151461   904 solver.cpp:245]     Train net output #0: loss = 2.19343 (* 1 = 2.19343 loss)
I0605 13:49:11.151471   904 sgd_solver.cpp:106] Iteration 103880, lr = 0.0155576
I0605 13:49:31.428695   904 solver.cpp:229] Iteration 103920, loss = 2.50806
I0605 13:49:31.428908   904 solver.cpp:245]     Train net output #0: loss = 2.58103 (* 1 = 2.58103 loss)
I0605 13:49:31.428935   904 sgd_solver.cpp:106] Iteration 103920, lr = 0.0155482
I0605 13:49:51.754619   904 solver.cpp:229] Iteration 103960, loss = 2.54013
I0605 13:49:51.754672   904 solver.cpp:245]     Train net output #0: loss = 2.42387 (* 1 = 2.42387 loss)
I0605 13:49:51.754684   904 sgd_solver.cpp:106] Iteration 103960, lr = 0.0155388
I0605 13:50:11.559962   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_104000.caffemodel
I0605 13:50:11.833644   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_104000.solverstate
I0605 13:50:11.912534   904 solver.cpp:338] Iteration 104000, Testing net (#0)
I0605 13:50:11.912616   904 net.cpp:748] Ignoring source layer loss
I0605 13:50:24.535560   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 13:51:00.177120   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 13:51:22.655360   904 solver.cpp:406]     Test net output #0: accuracy = 0.449501
I0605 13:51:22.655407   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.697899
I0605 13:51:22.971420   904 solver.cpp:229] Iteration 104000, loss = 2.52724
I0605 13:51:22.971527   904 solver.cpp:245]     Train net output #0: loss = 2.54946 (* 1 = 2.54946 loss)
I0605 13:51:22.971542   904 sgd_solver.cpp:106] Iteration 104000, lr = 0.0155294
I0605 13:51:42.137290   904 solver.cpp:229] Iteration 104040, loss = 2.50896
I0605 13:51:42.137516   904 solver.cpp:245]     Train net output #0: loss = 2.81051 (* 1 = 2.81051 loss)
I0605 13:51:42.137550   904 sgd_solver.cpp:106] Iteration 104040, lr = 0.01552
I0605 13:52:03.513276   904 solver.cpp:229] Iteration 104080, loss = 2.53128
I0605 13:52:03.513326   904 solver.cpp:245]     Train net output #0: loss = 2.34989 (* 1 = 2.34989 loss)
I0605 13:52:03.513339   904 sgd_solver.cpp:106] Iteration 104080, lr = 0.0155106
I0605 13:52:25.024561   904 solver.cpp:229] Iteration 104120, loss = 2.52295
I0605 13:52:25.024782   904 solver.cpp:245]     Train net output #0: loss = 2.32617 (* 1 = 2.32617 loss)
I0605 13:52:25.024809   904 sgd_solver.cpp:106] Iteration 104120, lr = 0.0155012
I0605 13:52:46.013571   904 solver.cpp:229] Iteration 104160, loss = 2.53976
I0605 13:52:46.013622   904 solver.cpp:245]     Train net output #0: loss = 2.40029 (* 1 = 2.40029 loss)
I0605 13:52:46.013634   904 sgd_solver.cpp:106] Iteration 104160, lr = 0.0154918
I0605 13:52:59.505259   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 13:53:06.781129   904 solver.cpp:229] Iteration 104200, loss = 2.50612
I0605 13:53:06.781179   904 solver.cpp:245]     Train net output #0: loss = 2.36752 (* 1 = 2.36752 loss)
I0605 13:53:06.781188   904 sgd_solver.cpp:106] Iteration 104200, lr = 0.0154824
I0605 13:53:27.613093   904 solver.cpp:229] Iteration 104240, loss = 2.51639
I0605 13:53:27.613143   904 solver.cpp:245]     Train net output #0: loss = 2.70152 (* 1 = 2.70152 loss)
I0605 13:53:27.613150   904 sgd_solver.cpp:106] Iteration 104240, lr = 0.0154729
I0605 13:53:48.615694   904 solver.cpp:229] Iteration 104280, loss = 2.508
I0605 13:53:48.615861   904 solver.cpp:245]     Train net output #0: loss = 2.38052 (* 1 = 2.38052 loss)
I0605 13:53:48.615885   904 sgd_solver.cpp:106] Iteration 104280, lr = 0.0154635
I0605 13:54:09.555459   904 solver.cpp:229] Iteration 104320, loss = 2.47316
I0605 13:54:09.555513   904 solver.cpp:245]     Train net output #0: loss = 2.485 (* 1 = 2.485 loss)
I0605 13:54:09.555526   904 sgd_solver.cpp:106] Iteration 104320, lr = 0.0154541
I0605 13:54:30.359614   904 solver.cpp:229] Iteration 104360, loss = 2.50599
I0605 13:54:30.359843   904 solver.cpp:245]     Train net output #0: loss = 2.57788 (* 1 = 2.57788 loss)
I0605 13:54:30.359870   904 sgd_solver.cpp:106] Iteration 104360, lr = 0.0154447
I0605 13:54:50.982306   904 solver.cpp:229] Iteration 104400, loss = 2.50439
I0605 13:54:50.982359   904 solver.cpp:245]     Train net output #0: loss = 2.54062 (* 1 = 2.54062 loss)
I0605 13:54:50.982367   904 sgd_solver.cpp:106] Iteration 104400, lr = 0.0154353
I0605 13:55:11.575835   904 solver.cpp:229] Iteration 104440, loss = 2.49668
I0605 13:55:11.576004   904 solver.cpp:245]     Train net output #0: loss = 2.67061 (* 1 = 2.67061 loss)
I0605 13:55:11.576017   904 sgd_solver.cpp:106] Iteration 104440, lr = 0.0154259
I0605 13:55:32.226523   904 solver.cpp:229] Iteration 104480, loss = 2.5158
I0605 13:55:32.226572   904 solver.cpp:245]     Train net output #0: loss = 2.38538 (* 1 = 2.38538 loss)
I0605 13:55:32.226583   904 sgd_solver.cpp:106] Iteration 104480, lr = 0.0154165
I0605 13:55:52.927244   904 solver.cpp:229] Iteration 104520, loss = 2.49215
I0605 13:55:52.927551   904 solver.cpp:245]     Train net output #0: loss = 2.58868 (* 1 = 2.58868 loss)
I0605 13:55:52.927577   904 sgd_solver.cpp:106] Iteration 104520, lr = 0.0154071
I0605 13:56:13.540045   904 solver.cpp:229] Iteration 104560, loss = 2.53506
I0605 13:56:13.540088   904 solver.cpp:245]     Train net output #0: loss = 2.47762 (* 1 = 2.47762 loss)
I0605 13:56:13.540099   904 sgd_solver.cpp:106] Iteration 104560, lr = 0.0153976
I0605 13:56:34.128945   904 solver.cpp:229] Iteration 104600, loss = 2.48033
I0605 13:56:34.129112   904 solver.cpp:245]     Train net output #0: loss = 2.66244 (* 1 = 2.66244 loss)
I0605 13:56:34.129123   904 sgd_solver.cpp:106] Iteration 104600, lr = 0.0153882
I0605 13:56:54.733332   904 solver.cpp:229] Iteration 104640, loss = 2.47854
I0605 13:56:54.733381   904 solver.cpp:245]     Train net output #0: loss = 2.40632 (* 1 = 2.40632 loss)
I0605 13:56:54.733393   904 sgd_solver.cpp:106] Iteration 104640, lr = 0.0153788
I0605 13:57:15.330095   904 solver.cpp:229] Iteration 104680, loss = 2.48805
I0605 13:57:15.330235   904 solver.cpp:245]     Train net output #0: loss = 2.4617 (* 1 = 2.4617 loss)
I0605 13:57:15.330245   904 sgd_solver.cpp:106] Iteration 104680, lr = 0.0153694
I0605 13:57:34.073504   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 13:57:35.869248   904 solver.cpp:229] Iteration 104720, loss = 2.47755
I0605 13:57:35.869313   904 solver.cpp:245]     Train net output #0: loss = 2.10785 (* 1 = 2.10785 loss)
I0605 13:57:35.869328   904 sgd_solver.cpp:106] Iteration 104720, lr = 0.01536
I0605 13:57:56.345885   904 solver.cpp:229] Iteration 104760, loss = 2.52439
I0605 13:57:56.346102   904 solver.cpp:245]     Train net output #0: loss = 2.56882 (* 1 = 2.56882 loss)
I0605 13:57:56.346129   904 sgd_solver.cpp:106] Iteration 104760, lr = 0.0153506
I0605 13:58:16.802156   904 solver.cpp:229] Iteration 104800, loss = 2.49875
I0605 13:58:16.802206   904 solver.cpp:245]     Train net output #0: loss = 2.63834 (* 1 = 2.63834 loss)
I0605 13:58:16.802219   904 sgd_solver.cpp:106] Iteration 104800, lr = 0.0153412
I0605 13:58:37.267166   904 solver.cpp:229] Iteration 104840, loss = 2.53407
I0605 13:58:37.267385   904 solver.cpp:245]     Train net output #0: loss = 2.78106 (* 1 = 2.78106 loss)
I0605 13:58:37.267412   904 sgd_solver.cpp:106] Iteration 104840, lr = 0.0153318
I0605 13:58:57.702471   904 solver.cpp:229] Iteration 104880, loss = 2.52537
I0605 13:58:57.702524   904 solver.cpp:245]     Train net output #0: loss = 2.43124 (* 1 = 2.43124 loss)
I0605 13:58:57.702534   904 sgd_solver.cpp:106] Iteration 104880, lr = 0.0153224
I0605 13:59:18.151404   904 solver.cpp:229] Iteration 104920, loss = 2.49572
I0605 13:59:18.151597   904 solver.cpp:245]     Train net output #0: loss = 2.37683 (* 1 = 2.37683 loss)
I0605 13:59:18.151623   904 sgd_solver.cpp:106] Iteration 104920, lr = 0.0153129
I0605 13:59:38.604081   904 solver.cpp:229] Iteration 104960, loss = 2.47151
I0605 13:59:38.604140   904 solver.cpp:245]     Train net output #0: loss = 2.36005 (* 1 = 2.36005 loss)
I0605 13:59:38.604149   904 sgd_solver.cpp:106] Iteration 104960, lr = 0.0153035
I0605 13:59:58.554201   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_105000.caffemodel
I0605 13:59:58.810438   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_105000.solverstate
I0605 13:59:58.880950   904 solver.cpp:338] Iteration 105000, Testing net (#0)
I0605 13:59:58.881027   904 net.cpp:748] Ignoring source layer loss
I0605 14:00:15.653779   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 14:00:50.296799   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 14:01:07.822741   904 solver.cpp:406]     Test net output #0: accuracy = 0.450561
I0605 14:01:07.822785   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.700499
I0605 14:01:08.140136   904 solver.cpp:229] Iteration 105000, loss = 2.49172
I0605 14:01:08.140179   904 solver.cpp:245]     Train net output #0: loss = 2.61009 (* 1 = 2.61009 loss)
I0605 14:01:08.140188   904 sgd_solver.cpp:106] Iteration 105000, lr = 0.0152941
I0605 14:01:27.419234   904 solver.cpp:229] Iteration 105040, loss = 2.53702
I0605 14:01:27.419386   904 solver.cpp:245]     Train net output #0: loss = 2.33533 (* 1 = 2.33533 loss)
I0605 14:01:27.419399   904 sgd_solver.cpp:106] Iteration 105040, lr = 0.0152847
I0605 14:01:48.893440   904 solver.cpp:229] Iteration 105080, loss = 2.50863
I0605 14:01:48.893498   904 solver.cpp:245]     Train net output #0: loss = 2.56322 (* 1 = 2.56322 loss)
I0605 14:01:48.893508   904 sgd_solver.cpp:106] Iteration 105080, lr = 0.0152753
I0605 14:02:10.387898   904 solver.cpp:229] Iteration 105120, loss = 2.52245
I0605 14:02:10.388042   904 solver.cpp:245]     Train net output #0: loss = 2.41851 (* 1 = 2.41851 loss)
I0605 14:02:10.388056   904 sgd_solver.cpp:106] Iteration 105120, lr = 0.0152659
I0605 14:02:31.445184   904 solver.cpp:229] Iteration 105160, loss = 2.51539
I0605 14:02:31.445241   904 solver.cpp:245]     Train net output #0: loss = 2.65297 (* 1 = 2.65297 loss)
I0605 14:02:31.445250   904 sgd_solver.cpp:106] Iteration 105160, lr = 0.0152565
I0605 14:02:52.441336   904 solver.cpp:229] Iteration 105200, loss = 2.54105
I0605 14:02:52.441474   904 solver.cpp:245]     Train net output #0: loss = 2.62872 (* 1 = 2.62872 loss)
I0605 14:02:52.441488   904 sgd_solver.cpp:106] Iteration 105200, lr = 0.0152471
I0605 14:03:13.449553   904 solver.cpp:229] Iteration 105240, loss = 2.50409
I0605 14:03:13.449611   904 solver.cpp:245]     Train net output #0: loss = 2.66682 (* 1 = 2.66682 loss)
I0605 14:03:13.449625   904 sgd_solver.cpp:106] Iteration 105240, lr = 0.0152376
I0605 14:03:20.802582   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 14:03:34.443126   904 solver.cpp:229] Iteration 105280, loss = 2.52053
I0605 14:03:34.443310   904 solver.cpp:245]     Train net output #0: loss = 2.26087 (* 1 = 2.26087 loss)
I0605 14:03:34.443321   904 sgd_solver.cpp:106] Iteration 105280, lr = 0.0152282
I0605 14:03:55.364186   904 solver.cpp:229] Iteration 105320, loss = 2.50004
I0605 14:03:55.364250   904 solver.cpp:245]     Train net output #0: loss = 2.19461 (* 1 = 2.19461 loss)
I0605 14:03:55.364261   904 sgd_solver.cpp:106] Iteration 105320, lr = 0.0152188
I0605 14:04:16.209295   904 solver.cpp:229] Iteration 105360, loss = 2.52472
I0605 14:04:16.209498   904 solver.cpp:245]     Train net output #0: loss = 2.61678 (* 1 = 2.61678 loss)
I0605 14:04:16.209525   904 sgd_solver.cpp:106] Iteration 105360, lr = 0.0152094
I0605 14:04:36.995437   904 solver.cpp:229] Iteration 105400, loss = 2.53161
I0605 14:04:36.995479   904 solver.cpp:245]     Train net output #0: loss = 2.4587 (* 1 = 2.4587 loss)
I0605 14:04:36.995487   904 sgd_solver.cpp:106] Iteration 105400, lr = 0.0152
I0605 14:04:57.696905   904 solver.cpp:229] Iteration 105440, loss = 2.49932
I0605 14:04:57.697060   904 solver.cpp:245]     Train net output #0: loss = 2.40592 (* 1 = 2.40592 loss)
I0605 14:04:57.697074   904 sgd_solver.cpp:106] Iteration 105440, lr = 0.0151906
I0605 14:05:18.394299   904 solver.cpp:229] Iteration 105480, loss = 2.50119
I0605 14:05:18.394362   904 solver.cpp:245]     Train net output #0: loss = 2.31898 (* 1 = 2.31898 loss)
I0605 14:05:18.394377   904 sgd_solver.cpp:106] Iteration 105480, lr = 0.0151812
I0605 14:05:39.099925   904 solver.cpp:229] Iteration 105520, loss = 2.47244
I0605 14:05:39.100113   904 solver.cpp:245]     Train net output #0: loss = 2.64748 (* 1 = 2.64748 loss)
I0605 14:05:39.100123   904 sgd_solver.cpp:106] Iteration 105520, lr = 0.0151718
I0605 14:05:59.791707   904 solver.cpp:229] Iteration 105560, loss = 2.52336
I0605 14:05:59.791777   904 solver.cpp:245]     Train net output #0: loss = 2.68752 (* 1 = 2.68752 loss)
I0605 14:05:59.791795   904 sgd_solver.cpp:106] Iteration 105560, lr = 0.0151624
I0605 14:06:20.386142   904 solver.cpp:229] Iteration 105600, loss = 2.51483
I0605 14:06:20.386296   904 solver.cpp:245]     Train net output #0: loss = 2.64188 (* 1 = 2.64188 loss)
I0605 14:06:20.386346   904 sgd_solver.cpp:106] Iteration 105600, lr = 0.0151529
I0605 14:06:40.912540   904 solver.cpp:229] Iteration 105640, loss = 2.48935
I0605 14:06:40.912586   904 solver.cpp:245]     Train net output #0: loss = 2.49752 (* 1 = 2.49752 loss)
I0605 14:06:40.912598   904 sgd_solver.cpp:106] Iteration 105640, lr = 0.0151435
I0605 14:07:01.440476   904 solver.cpp:229] Iteration 105680, loss = 2.50986
I0605 14:07:01.440691   904 solver.cpp:245]     Train net output #0: loss = 2.67239 (* 1 = 2.67239 loss)
I0605 14:07:01.440717   904 sgd_solver.cpp:106] Iteration 105680, lr = 0.0151341
I0605 14:07:21.961612   904 solver.cpp:229] Iteration 105720, loss = 2.4965
I0605 14:07:21.961654   904 solver.cpp:245]     Train net output #0: loss = 2.45975 (* 1 = 2.45975 loss)
I0605 14:07:21.961664   904 sgd_solver.cpp:106] Iteration 105720, lr = 0.0151247
I0605 14:07:42.470482   904 solver.cpp:229] Iteration 105760, loss = 2.52313
I0605 14:07:42.470667   904 solver.cpp:245]     Train net output #0: loss = 2.71973 (* 1 = 2.71973 loss)
I0605 14:07:42.470692   904 sgd_solver.cpp:106] Iteration 105760, lr = 0.0151153
I0605 14:07:55.066438   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 14:08:03.017395   904 solver.cpp:229] Iteration 105800, loss = 2.46748
I0605 14:08:03.017446   904 solver.cpp:245]     Train net output #0: loss = 2.37452 (* 1 = 2.37452 loss)
I0605 14:08:03.017457   904 sgd_solver.cpp:106] Iteration 105800, lr = 0.0151059
I0605 14:08:23.563515   904 solver.cpp:229] Iteration 105840, loss = 2.53592
I0605 14:08:23.563741   904 solver.cpp:245]     Train net output #0: loss = 2.76427 (* 1 = 2.76427 loss)
I0605 14:08:23.563767   904 sgd_solver.cpp:106] Iteration 105840, lr = 0.0150965
I0605 14:08:44.052278   904 solver.cpp:229] Iteration 105880, loss = 2.50956
I0605 14:08:44.052330   904 solver.cpp:245]     Train net output #0: loss = 2.64101 (* 1 = 2.64101 loss)
I0605 14:08:44.052338   904 sgd_solver.cpp:106] Iteration 105880, lr = 0.0150871
I0605 14:09:04.385011   904 solver.cpp:229] Iteration 105920, loss = 2.4691
I0605 14:09:04.385228   904 solver.cpp:245]     Train net output #0: loss = 2.44086 (* 1 = 2.44086 loss)
I0605 14:09:04.385253   904 sgd_solver.cpp:106] Iteration 105920, lr = 0.0150776
I0605 14:09:24.699695   904 solver.cpp:229] Iteration 105960, loss = 2.46619
I0605 14:09:24.699746   904 solver.cpp:245]     Train net output #0: loss = 2.38156 (* 1 = 2.38156 loss)
I0605 14:09:24.699754   904 sgd_solver.cpp:106] Iteration 105960, lr = 0.0150682
I0605 14:09:44.560281   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_106000.caffemodel
I0605 14:09:44.859295   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_106000.solverstate
I0605 14:09:44.936297   904 solver.cpp:338] Iteration 106000, Testing net (#0)
I0605 14:09:44.936403   904 net.cpp:748] Ignoring source layer loss
I0605 14:10:05.795300   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 14:10:41.578907   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 14:10:55.730618   904 solver.cpp:406]     Test net output #0: accuracy = 0.450321
I0605 14:10:55.730669   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.700199
I0605 14:10:56.045284   904 solver.cpp:229] Iteration 106000, loss = 2.48246
I0605 14:10:56.045325   904 solver.cpp:245]     Train net output #0: loss = 2.48122 (* 1 = 2.48122 loss)
I0605 14:10:56.045334   904 sgd_solver.cpp:106] Iteration 106000, lr = 0.0150588
I0605 14:11:15.290846   904 solver.cpp:229] Iteration 106040, loss = 2.4783
I0605 14:11:15.291064   904 solver.cpp:245]     Train net output #0: loss = 2.51751 (* 1 = 2.51751 loss)
I0605 14:11:15.291079   904 sgd_solver.cpp:106] Iteration 106040, lr = 0.0150494
I0605 14:11:36.642702   904 solver.cpp:229] Iteration 106080, loss = 2.5338
I0605 14:11:36.642762   904 solver.cpp:245]     Train net output #0: loss = 2.55736 (* 1 = 2.55736 loss)
I0605 14:11:36.642773   904 sgd_solver.cpp:106] Iteration 106080, lr = 0.01504
I0605 14:11:58.130528   904 solver.cpp:229] Iteration 106120, loss = 2.45628
I0605 14:11:58.130717   904 solver.cpp:245]     Train net output #0: loss = 2.70714 (* 1 = 2.70714 loss)
I0605 14:11:58.130727   904 sgd_solver.cpp:106] Iteration 106120, lr = 0.0150306
I0605 14:12:19.149925   904 solver.cpp:229] Iteration 106160, loss = 2.49185
I0605 14:12:19.149968   904 solver.cpp:245]     Train net output #0: loss = 2.72215 (* 1 = 2.72215 loss)
I0605 14:12:19.149977   904 sgd_solver.cpp:106] Iteration 106160, lr = 0.0150212
I0605 14:12:40.133072   904 solver.cpp:229] Iteration 106200, loss = 2.4791
I0605 14:12:40.133246   904 solver.cpp:245]     Train net output #0: loss = 2.4796 (* 1 = 2.4796 loss)
I0605 14:12:40.133267   904 sgd_solver.cpp:106] Iteration 106200, lr = 0.0150118
I0605 14:13:01.145835   904 solver.cpp:229] Iteration 106240, loss = 2.50946
I0605 14:13:01.145905   904 solver.cpp:245]     Train net output #0: loss = 2.24024 (* 1 = 2.24024 loss)
I0605 14:13:01.145915   904 sgd_solver.cpp:106] Iteration 106240, lr = 0.0150024
I0605 14:13:22.096421   904 solver.cpp:229] Iteration 106280, loss = 2.5032
I0605 14:13:22.096550   904 solver.cpp:245]     Train net output #0: loss = 2.55918 (* 1 = 2.55918 loss)
I0605 14:13:22.096560   904 sgd_solver.cpp:106] Iteration 106280, lr = 0.0149929
I0605 14:13:39.930001   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 14:13:42.774459   904 solver.cpp:229] Iteration 106320, loss = 2.47342
I0605 14:13:42.774515   904 solver.cpp:245]     Train net output #0: loss = 2.61965 (* 1 = 2.61965 loss)
I0605 14:13:42.774524   904 sgd_solver.cpp:106] Iteration 106320, lr = 0.0149835
I0605 14:14:03.472578   904 solver.cpp:229] Iteration 106360, loss = 2.49282
I0605 14:14:03.472764   904 solver.cpp:245]     Train net output #0: loss = 2.35154 (* 1 = 2.35154 loss)
I0605 14:14:03.472796   904 sgd_solver.cpp:106] Iteration 106360, lr = 0.0149741
I0605 14:14:24.156010   904 solver.cpp:229] Iteration 106400, loss = 2.45928
I0605 14:14:24.156059   904 solver.cpp:245]     Train net output #0: loss = 2.54972 (* 1 = 2.54972 loss)
I0605 14:14:24.156069   904 sgd_solver.cpp:106] Iteration 106400, lr = 0.0149647
I0605 14:14:44.855155   904 solver.cpp:229] Iteration 106440, loss = 2.53166
I0605 14:14:44.855392   904 solver.cpp:245]     Train net output #0: loss = 2.50334 (* 1 = 2.50334 loss)
I0605 14:14:44.855417   904 sgd_solver.cpp:106] Iteration 106440, lr = 0.0149553
I0605 14:15:05.519098   904 solver.cpp:229] Iteration 106480, loss = 2.51818
I0605 14:15:05.519182   904 solver.cpp:245]     Train net output #0: loss = 2.5148 (* 1 = 2.5148 loss)
I0605 14:15:05.519199   904 sgd_solver.cpp:106] Iteration 106480, lr = 0.0149459
I0605 14:15:26.073312   904 solver.cpp:229] Iteration 106520, loss = 2.51058
I0605 14:15:26.073475   904 solver.cpp:245]     Train net output #0: loss = 2.56121 (* 1 = 2.56121 loss)
I0605 14:15:26.073503   904 sgd_solver.cpp:106] Iteration 106520, lr = 0.0149365
I0605 14:15:46.606431   904 solver.cpp:229] Iteration 106560, loss = 2.51192
I0605 14:15:46.606475   904 solver.cpp:245]     Train net output #0: loss = 2.49039 (* 1 = 2.49039 loss)
I0605 14:15:46.606485   904 sgd_solver.cpp:106] Iteration 106560, lr = 0.0149271
I0605 14:16:07.255806   904 solver.cpp:229] Iteration 106600, loss = 2.50002
I0605 14:16:07.256350   904 solver.cpp:245]     Train net output #0: loss = 2.83128 (* 1 = 2.83128 loss)
I0605 14:16:07.256359   904 sgd_solver.cpp:106] Iteration 106600, lr = 0.0149176
I0605 14:16:27.835463   904 solver.cpp:229] Iteration 106640, loss = 2.49971
I0605 14:16:27.835510   904 solver.cpp:245]     Train net output #0: loss = 2.57698 (* 1 = 2.57698 loss)
I0605 14:16:27.835520   904 sgd_solver.cpp:106] Iteration 106640, lr = 0.0149082
I0605 14:16:48.353134   904 solver.cpp:229] Iteration 106680, loss = 2.49272
I0605 14:16:48.353299   904 solver.cpp:245]     Train net output #0: loss = 2.25005 (* 1 = 2.25005 loss)
I0605 14:16:48.353313   904 sgd_solver.cpp:106] Iteration 106680, lr = 0.0148988
I0605 14:17:08.882870   904 solver.cpp:229] Iteration 106720, loss = 2.50292
I0605 14:17:08.882930   904 solver.cpp:245]     Train net output #0: loss = 2.21209 (* 1 = 2.21209 loss)
I0605 14:17:08.882941   904 sgd_solver.cpp:106] Iteration 106720, lr = 0.0148894
I0605 14:17:29.420804   904 solver.cpp:229] Iteration 106760, loss = 2.50385
I0605 14:17:29.420987   904 solver.cpp:245]     Train net output #0: loss = 2.57134 (* 1 = 2.57134 loss)
I0605 14:17:29.421015   904 sgd_solver.cpp:106] Iteration 106760, lr = 0.01488
I0605 14:17:49.926295   904 solver.cpp:229] Iteration 106800, loss = 2.49734
I0605 14:17:49.926340   904 solver.cpp:245]     Train net output #0: loss = 2.42277 (* 1 = 2.42277 loss)
I0605 14:17:49.926348   904 sgd_solver.cpp:106] Iteration 106800, lr = 0.0148706
I0605 14:18:10.416111   904 solver.cpp:229] Iteration 106840, loss = 2.43758
I0605 14:18:10.416254   904 solver.cpp:245]     Train net output #0: loss = 2.13953 (* 1 = 2.13953 loss)
I0605 14:18:10.416265   904 sgd_solver.cpp:106] Iteration 106840, lr = 0.0148612
I0605 14:18:10.672055   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 14:18:30.910447   904 solver.cpp:229] Iteration 106880, loss = 2.51151
I0605 14:18:30.910506   904 solver.cpp:245]     Train net output #0: loss = 2.531 (* 1 = 2.531 loss)
I0605 14:18:30.910516   904 sgd_solver.cpp:106] Iteration 106880, lr = 0.0148518
I0605 14:18:51.435281   904 solver.cpp:229] Iteration 106920, loss = 2.47099
I0605 14:18:51.435421   904 solver.cpp:245]     Train net output #0: loss = 2.56775 (* 1 = 2.56775 loss)
I0605 14:18:51.435431   904 sgd_solver.cpp:106] Iteration 106920, lr = 0.0148424
I0605 14:19:11.945924   904 solver.cpp:229] Iteration 106960, loss = 2.50666
I0605 14:19:11.945969   904 solver.cpp:245]     Train net output #0: loss = 2.69124 (* 1 = 2.69124 loss)
I0605 14:19:11.945979   904 sgd_solver.cpp:106] Iteration 106960, lr = 0.0148329
I0605 14:19:31.936368   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_107000.caffemodel
I0605 14:19:32.206300   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_107000.solverstate
I0605 14:19:32.279866   904 solver.cpp:338] Iteration 107000, Testing net (#0)
I0605 14:19:32.279947   904 net.cpp:748] Ignoring source layer loss
I0605 14:19:56.224884   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 14:20:30.784667   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 14:20:41.591167   904 solver.cpp:406]     Test net output #0: accuracy = 0.441021
I0605 14:20:41.591214   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.69006
I0605 14:20:41.904817   904 solver.cpp:229] Iteration 107000, loss = 2.46691
I0605 14:20:41.904863   904 solver.cpp:245]     Train net output #0: loss = 2.51657 (* 1 = 2.51657 loss)
I0605 14:20:41.904873   904 sgd_solver.cpp:106] Iteration 107000, lr = 0.0148235
I0605 14:21:01.176050   904 solver.cpp:229] Iteration 107040, loss = 2.46656
I0605 14:21:01.176290   904 solver.cpp:245]     Train net output #0: loss = 2.52832 (* 1 = 2.52832 loss)
I0605 14:21:01.176316   904 sgd_solver.cpp:106] Iteration 107040, lr = 0.0148141
I0605 14:21:22.626776   904 solver.cpp:229] Iteration 107080, loss = 2.47167
I0605 14:21:22.626817   904 solver.cpp:245]     Train net output #0: loss = 2.4513 (* 1 = 2.4513 loss)
I0605 14:21:22.626827   904 sgd_solver.cpp:106] Iteration 107080, lr = 0.0148047
I0605 14:21:44.178609   904 solver.cpp:229] Iteration 107120, loss = 2.46141
I0605 14:21:44.178853   904 solver.cpp:245]     Train net output #0: loss = 2.53029 (* 1 = 2.53029 loss)
I0605 14:21:44.178881   904 sgd_solver.cpp:106] Iteration 107120, lr = 0.0147953
I0605 14:22:05.393919   904 solver.cpp:229] Iteration 107160, loss = 2.45939
I0605 14:22:05.393965   904 solver.cpp:245]     Train net output #0: loss = 2.49579 (* 1 = 2.49579 loss)
I0605 14:22:05.393976   904 sgd_solver.cpp:106] Iteration 107160, lr = 0.0147859
I0605 14:22:26.447000   904 solver.cpp:229] Iteration 107200, loss = 2.49602
I0605 14:22:26.447198   904 solver.cpp:245]     Train net output #0: loss = 2.46715 (* 1 = 2.46715 loss)
I0605 14:22:26.447211   904 sgd_solver.cpp:106] Iteration 107200, lr = 0.0147765
I0605 14:22:47.418771   904 solver.cpp:229] Iteration 107240, loss = 2.44438
I0605 14:22:47.418817   904 solver.cpp:245]     Train net output #0: loss = 2.29796 (* 1 = 2.29796 loss)
I0605 14:22:47.418828   904 sgd_solver.cpp:106] Iteration 107240, lr = 0.0147671
I0605 14:23:08.379791   904 solver.cpp:229] Iteration 107280, loss = 2.51379
I0605 14:23:08.379956   904 solver.cpp:245]     Train net output #0: loss = 2.83377 (* 1 = 2.83377 loss)
I0605 14:23:08.379977   904 sgd_solver.cpp:106] Iteration 107280, lr = 0.0147576
I0605 14:23:29.348515   904 solver.cpp:229] Iteration 107320, loss = 2.46245
I0605 14:23:29.348556   904 solver.cpp:245]     Train net output #0: loss = 2.61388 (* 1 = 2.61388 loss)
I0605 14:23:29.348564   904 sgd_solver.cpp:106] Iteration 107320, lr = 0.0147482
I0605 14:23:43.784936   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 14:23:50.322029   904 solver.cpp:229] Iteration 107360, loss = 2.48732
I0605 14:23:50.322069   904 solver.cpp:245]     Train net output #0: loss = 2.61258 (* 1 = 2.61258 loss)
I0605 14:23:50.322077   904 sgd_solver.cpp:106] Iteration 107360, lr = 0.0147388
I0605 14:24:11.167506   904 solver.cpp:229] Iteration 107400, loss = 2.49971
I0605 14:24:11.167541   904 solver.cpp:245]     Train net output #0: loss = 2.73839 (* 1 = 2.73839 loss)
I0605 14:24:11.167546   904 sgd_solver.cpp:106] Iteration 107400, lr = 0.0147294
I0605 14:24:31.965378   904 solver.cpp:229] Iteration 107440, loss = 2.44726
I0605 14:24:31.965589   904 solver.cpp:245]     Train net output #0: loss = 2.58314 (* 1 = 2.58314 loss)
I0605 14:24:31.965616   904 sgd_solver.cpp:106] Iteration 107440, lr = 0.01472
I0605 14:24:52.615547   904 solver.cpp:229] Iteration 107480, loss = 2.46753
I0605 14:24:52.615588   904 solver.cpp:245]     Train net output #0: loss = 2.32879 (* 1 = 2.32879 loss)
I0605 14:24:52.615598   904 sgd_solver.cpp:106] Iteration 107480, lr = 0.0147106
I0605 14:25:13.294256   904 solver.cpp:229] Iteration 107520, loss = 2.488
I0605 14:25:13.294491   904 solver.cpp:245]     Train net output #0: loss = 2.50172 (* 1 = 2.50172 loss)
I0605 14:25:13.294517   904 sgd_solver.cpp:106] Iteration 107520, lr = 0.0147012
I0605 14:25:33.963515   904 solver.cpp:229] Iteration 107560, loss = 2.48587
I0605 14:25:33.963557   904 solver.cpp:245]     Train net output #0: loss = 2.56876 (* 1 = 2.56876 loss)
I0605 14:25:33.963564   904 sgd_solver.cpp:106] Iteration 107560, lr = 0.0146918
I0605 14:25:54.539507   904 solver.cpp:229] Iteration 107600, loss = 2.49067
I0605 14:25:54.539656   904 solver.cpp:245]     Train net output #0: loss = 2.25718 (* 1 = 2.25718 loss)
I0605 14:25:54.539669   904 sgd_solver.cpp:106] Iteration 107600, lr = 0.0146824
I0605 14:26:15.032887   904 solver.cpp:229] Iteration 107640, loss = 2.49816
I0605 14:26:15.032939   904 solver.cpp:245]     Train net output #0: loss = 2.43578 (* 1 = 2.43578 loss)
I0605 14:26:15.032949   904 sgd_solver.cpp:106] Iteration 107640, lr = 0.0146729
I0605 14:26:35.593178   904 solver.cpp:229] Iteration 107680, loss = 2.52378
I0605 14:26:35.593395   904 solver.cpp:245]     Train net output #0: loss = 2.72215 (* 1 = 2.72215 loss)
I0605 14:26:35.593430   904 sgd_solver.cpp:106] Iteration 107680, lr = 0.0146635
I0605 14:26:56.125926   904 solver.cpp:229] Iteration 107720, loss = 2.47937
I0605 14:26:56.125977   904 solver.cpp:245]     Train net output #0: loss = 2.53732 (* 1 = 2.53732 loss)
I0605 14:26:56.125985   904 sgd_solver.cpp:106] Iteration 107720, lr = 0.0146541
I0605 14:27:16.636256   904 solver.cpp:229] Iteration 107760, loss = 2.46678
I0605 14:27:16.636446   904 solver.cpp:245]     Train net output #0: loss = 2.33251 (* 1 = 2.33251 loss)
I0605 14:27:16.636457   904 sgd_solver.cpp:106] Iteration 107760, lr = 0.0146447
I0605 14:27:37.139659   904 solver.cpp:229] Iteration 107800, loss = 2.49174
I0605 14:27:37.139700   904 solver.cpp:245]     Train net output #0: loss = 2.72789 (* 1 = 2.72789 loss)
I0605 14:27:37.139709   904 sgd_solver.cpp:106] Iteration 107800, lr = 0.0146353
I0605 14:27:57.643460   904 solver.cpp:229] Iteration 107840, loss = 2.47359
I0605 14:27:57.643725   904 solver.cpp:245]     Train net output #0: loss = 2.52261 (* 1 = 2.52261 loss)
I0605 14:27:57.643754   904 sgd_solver.cpp:106] Iteration 107840, lr = 0.0146259
I0605 14:28:03.008980   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 14:28:18.134085   904 solver.cpp:229] Iteration 107880, loss = 2.49643
I0605 14:28:18.134131   904 solver.cpp:245]     Train net output #0: loss = 2.50407 (* 1 = 2.50407 loss)
I0605 14:28:18.134140   904 sgd_solver.cpp:106] Iteration 107880, lr = 0.0146165
I0605 14:28:38.476034   904 solver.cpp:229] Iteration 107920, loss = 2.48531
I0605 14:28:38.476260   904 solver.cpp:245]     Train net output #0: loss = 2.80399 (* 1 = 2.80399 loss)
I0605 14:28:38.476287   904 sgd_solver.cpp:106] Iteration 107920, lr = 0.0146071
I0605 14:28:58.742215   904 solver.cpp:229] Iteration 107960, loss = 2.48733
I0605 14:28:58.742257   904 solver.cpp:245]     Train net output #0: loss = 2.12297 (* 1 = 2.12297 loss)
I0605 14:28:58.742266   904 sgd_solver.cpp:106] Iteration 107960, lr = 0.0145976
I0605 14:29:18.480474   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_108000.caffemodel
I0605 14:29:18.748196   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_108000.solverstate
I0605 14:29:18.827411   904 solver.cpp:338] Iteration 108000, Testing net (#0)
I0605 14:29:18.827487   904 net.cpp:748] Ignoring source layer loss
I0605 14:29:42.692462   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 14:30:16.582484   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 14:30:26.189761   904 solver.cpp:406]     Test net output #0: accuracy = 0.446521
I0605 14:30:26.189808   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.69932
I0605 14:30:26.504645   904 solver.cpp:229] Iteration 108000, loss = 2.49488
I0605 14:30:26.504699   904 solver.cpp:245]     Train net output #0: loss = 2.4392 (* 1 = 2.4392 loss)
I0605 14:30:26.504709   904 sgd_solver.cpp:106] Iteration 108000, lr = 0.0145882
I0605 14:30:45.750738   904 solver.cpp:229] Iteration 108040, loss = 2.49041
I0605 14:30:45.750793   904 solver.cpp:245]     Train net output #0: loss = 2.45291 (* 1 = 2.45291 loss)
I0605 14:30:45.750803   904 sgd_solver.cpp:106] Iteration 108040, lr = 0.0145788
I0605 14:31:07.105263   904 solver.cpp:229] Iteration 108080, loss = 2.53748
I0605 14:31:07.105456   904 solver.cpp:245]     Train net output #0: loss = 2.68072 (* 1 = 2.68072 loss)
I0605 14:31:07.105482   904 sgd_solver.cpp:106] Iteration 108080, lr = 0.0145694
I0605 14:31:28.673406   904 solver.cpp:229] Iteration 108120, loss = 2.48684
I0605 14:31:28.673442   904 solver.cpp:245]     Train net output #0: loss = 2.26332 (* 1 = 2.26332 loss)
I0605 14:31:28.673450   904 sgd_solver.cpp:106] Iteration 108120, lr = 0.01456
I0605 14:31:49.745249   904 solver.cpp:229] Iteration 108160, loss = 2.47312
I0605 14:31:49.745396   904 solver.cpp:245]     Train net output #0: loss = 2.62789 (* 1 = 2.62789 loss)
I0605 14:31:49.745404   904 sgd_solver.cpp:106] Iteration 108160, lr = 0.0145506
I0605 14:32:10.728853   904 solver.cpp:229] Iteration 108200, loss = 2.48751
I0605 14:32:10.728911   904 solver.cpp:245]     Train net output #0: loss = 2.43653 (* 1 = 2.43653 loss)
I0605 14:32:10.728921   904 sgd_solver.cpp:106] Iteration 108200, lr = 0.0145412
I0605 14:32:31.714540   904 solver.cpp:229] Iteration 108240, loss = 2.48497
I0605 14:32:31.714682   904 solver.cpp:245]     Train net output #0: loss = 2.3068 (* 1 = 2.3068 loss)
I0605 14:32:31.714694   904 sgd_solver.cpp:106] Iteration 108240, lr = 0.0145318
I0605 14:32:52.562692   904 solver.cpp:229] Iteration 108280, loss = 2.48835
I0605 14:32:52.562736   904 solver.cpp:245]     Train net output #0: loss = 2.49869 (* 1 = 2.49869 loss)
I0605 14:32:52.562747   904 sgd_solver.cpp:106] Iteration 108280, lr = 0.0145224
I0605 14:33:13.345369   904 solver.cpp:229] Iteration 108320, loss = 2.49319
I0605 14:33:13.345634   904 solver.cpp:245]     Train net output #0: loss = 2.80079 (* 1 = 2.80079 loss)
I0605 14:33:13.345667   904 sgd_solver.cpp:106] Iteration 108320, lr = 0.0145129
I0605 14:33:34.044646   904 solver.cpp:229] Iteration 108360, loss = 2.49848
I0605 14:33:34.044682   904 solver.cpp:245]     Train net output #0: loss = 2.32948 (* 1 = 2.32948 loss)
I0605 14:33:34.044690   904 sgd_solver.cpp:106] Iteration 108360, lr = 0.0145035
I0605 14:33:34.822844   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 14:33:54.736886   904 solver.cpp:229] Iteration 108400, loss = 2.45136
I0605 14:33:54.737114   904 solver.cpp:245]     Train net output #0: loss = 2.48119 (* 1 = 2.48119 loss)
I0605 14:33:54.737140   904 sgd_solver.cpp:106] Iteration 108400, lr = 0.0144941
I0605 14:34:15.456535   904 solver.cpp:229] Iteration 108440, loss = 2.46165
I0605 14:34:15.456588   904 solver.cpp:245]     Train net output #0: loss = 2.37136 (* 1 = 2.37136 loss)
I0605 14:34:15.456598   904 sgd_solver.cpp:106] Iteration 108440, lr = 0.0144847
I0605 14:34:35.960697   904 solver.cpp:229] Iteration 108480, loss = 2.47758
I0605 14:34:35.960903   904 solver.cpp:245]     Train net output #0: loss = 2.46523 (* 1 = 2.46523 loss)
I0605 14:34:35.960930   904 sgd_solver.cpp:106] Iteration 108480, lr = 0.0144753
I0605 14:34:56.506836   904 solver.cpp:229] Iteration 108520, loss = 2.48444
I0605 14:34:56.506877   904 solver.cpp:245]     Train net output #0: loss = 2.65975 (* 1 = 2.65975 loss)
I0605 14:34:56.506886   904 sgd_solver.cpp:106] Iteration 108520, lr = 0.0144659
I0605 14:35:17.173538   904 solver.cpp:229] Iteration 108560, loss = 2.47066
I0605 14:35:17.173729   904 solver.cpp:245]     Train net output #0: loss = 2.4371 (* 1 = 2.4371 loss)
I0605 14:35:17.173756   904 sgd_solver.cpp:106] Iteration 108560, lr = 0.0144565
I0605 14:35:37.658197   904 solver.cpp:229] Iteration 108600, loss = 2.47829
I0605 14:35:37.658239   904 solver.cpp:245]     Train net output #0: loss = 2.59188 (* 1 = 2.59188 loss)
I0605 14:35:37.658248   904 sgd_solver.cpp:106] Iteration 108600, lr = 0.0144471
I0605 14:35:58.006409   904 solver.cpp:229] Iteration 108640, loss = 2.47929
I0605 14:35:58.006628   904 solver.cpp:245]     Train net output #0: loss = 2.25656 (* 1 = 2.25656 loss)
I0605 14:35:58.006654   904 sgd_solver.cpp:106] Iteration 108640, lr = 0.0144376
I0605 14:36:18.550225   904 solver.cpp:229] Iteration 108680, loss = 2.45696
I0605 14:36:18.550266   904 solver.cpp:245]     Train net output #0: loss = 2.20603 (* 1 = 2.20603 loss)
I0605 14:36:18.550276   904 sgd_solver.cpp:106] Iteration 108680, lr = 0.0144282
I0605 14:36:39.044852   904 solver.cpp:229] Iteration 108720, loss = 2.47384
I0605 14:36:39.045037   904 solver.cpp:245]     Train net output #0: loss = 2.55247 (* 1 = 2.55247 loss)
I0605 14:36:39.045047   904 sgd_solver.cpp:106] Iteration 108720, lr = 0.0144188
I0605 14:36:59.265357   904 solver.cpp:229] Iteration 108760, loss = 2.48768
I0605 14:36:59.265403   904 solver.cpp:245]     Train net output #0: loss = 2.52297 (* 1 = 2.52297 loss)
I0605 14:36:59.265414   904 sgd_solver.cpp:106] Iteration 108760, lr = 0.0144094
I0605 14:37:19.402721   904 solver.cpp:229] Iteration 108800, loss = 2.48395
I0605 14:37:19.402966   904 solver.cpp:245]     Train net output #0: loss = 2.54666 (* 1 = 2.54666 loss)
I0605 14:37:19.403003   904 sgd_solver.cpp:106] Iteration 108800, lr = 0.0144
I0605 14:37:39.381968   904 solver.cpp:229] Iteration 108840, loss = 2.47383
I0605 14:37:39.382035   904 solver.cpp:245]     Train net output #0: loss = 2.39045 (* 1 = 2.39045 loss)
I0605 14:37:39.382045   904 sgd_solver.cpp:106] Iteration 108840, lr = 0.0143906
I0605 14:37:59.386983   904 solver.cpp:229] Iteration 108880, loss = 2.44581
I0605 14:37:59.387181   904 solver.cpp:245]     Train net output #0: loss = 2.35432 (* 1 = 2.35432 loss)
I0605 14:37:59.387195   904 sgd_solver.cpp:106] Iteration 108880, lr = 0.0143812
I0605 14:38:00.133225   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 14:38:19.303313   904 solver.cpp:229] Iteration 108920, loss = 2.4661
I0605 14:38:19.303376   904 solver.cpp:245]     Train net output #0: loss = 2.42042 (* 1 = 2.42042 loss)
I0605 14:38:19.303387   904 sgd_solver.cpp:106] Iteration 108920, lr = 0.0143718
I0605 14:38:39.202147   904 solver.cpp:229] Iteration 108960, loss = 2.51236
I0605 14:38:39.202337   904 solver.cpp:245]     Train net output #0: loss = 2.41744 (* 1 = 2.41744 loss)
I0605 14:38:39.202356   904 sgd_solver.cpp:106] Iteration 108960, lr = 0.0143624
I0605 14:38:58.596550   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_109000.caffemodel
I0605 14:38:58.847419   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_109000.solverstate
I0605 14:38:58.925269   904 solver.cpp:338] Iteration 109000, Testing net (#0)
I0605 14:38:58.925353   904 net.cpp:748] Ignoring source layer loss
I0605 14:39:24.105407   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 14:39:54.933728   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 14:40:01.338212   904 solver.cpp:406]     Test net output #0: accuracy = 0.454181
I0605 14:40:01.338258   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.700519
I0605 14:40:01.651996   904 solver.cpp:229] Iteration 109000, loss = 2.50835
I0605 14:40:01.652043   904 solver.cpp:245]     Train net output #0: loss = 2.62465 (* 1 = 2.62465 loss)
I0605 14:40:01.652052   904 sgd_solver.cpp:106] Iteration 109000, lr = 0.0143529
I0605 14:40:20.870975   904 solver.cpp:229] Iteration 109040, loss = 2.4632
I0605 14:40:20.871037   904 solver.cpp:245]     Train net output #0: loss = 2.23922 (* 1 = 2.23922 loss)
I0605 14:40:20.871044   904 sgd_solver.cpp:106] Iteration 109040, lr = 0.0143435
I0605 14:40:41.900454   904 solver.cpp:229] Iteration 109080, loss = 2.49134
I0605 14:40:41.900576   904 solver.cpp:245]     Train net output #0: loss = 2.40451 (* 1 = 2.40451 loss)
I0605 14:40:41.900586   904 sgd_solver.cpp:106] Iteration 109080, lr = 0.0143341
I0605 14:41:03.233849   904 solver.cpp:229] Iteration 109120, loss = 2.46315
I0605 14:41:03.233897   904 solver.cpp:245]     Train net output #0: loss = 2.33566 (* 1 = 2.33566 loss)
I0605 14:41:03.233917   904 sgd_solver.cpp:106] Iteration 109120, lr = 0.0143247
I0605 14:41:24.222975   904 solver.cpp:229] Iteration 109160, loss = 2.50841
I0605 14:41:24.223099   904 solver.cpp:245]     Train net output #0: loss = 2.34918 (* 1 = 2.34918 loss)
I0605 14:41:24.223109   904 sgd_solver.cpp:106] Iteration 109160, lr = 0.0143153
I0605 14:41:45.226069   904 solver.cpp:229] Iteration 109200, loss = 2.4866
I0605 14:41:45.226117   904 solver.cpp:245]     Train net output #0: loss = 2.64683 (* 1 = 2.64683 loss)
I0605 14:41:45.226126   904 sgd_solver.cpp:106] Iteration 109200, lr = 0.0143059
I0605 14:42:06.203645   904 solver.cpp:229] Iteration 109240, loss = 2.48037
I0605 14:42:06.203822   904 solver.cpp:245]     Train net output #0: loss = 2.21682 (* 1 = 2.21682 loss)
I0605 14:42:06.203845   904 sgd_solver.cpp:106] Iteration 109240, lr = 0.0142965
I0605 14:42:27.203752   904 solver.cpp:229] Iteration 109280, loss = 2.48218
I0605 14:42:27.203802   904 solver.cpp:245]     Train net output #0: loss = 2.41946 (* 1 = 2.41946 loss)
I0605 14:42:27.203810   904 sgd_solver.cpp:106] Iteration 109280, lr = 0.0142871
I0605 14:42:48.000684   904 solver.cpp:229] Iteration 109320, loss = 2.43372
I0605 14:42:48.000831   904 solver.cpp:245]     Train net output #0: loss = 2.30988 (* 1 = 2.30988 loss)
I0605 14:42:48.000841   904 sgd_solver.cpp:106] Iteration 109320, lr = 0.0142776
I0605 14:43:08.826437   904 solver.cpp:229] Iteration 109360, loss = 2.47022
I0605 14:43:08.826475   904 solver.cpp:245]     Train net output #0: loss = 2.33926 (* 1 = 2.33926 loss)
I0605 14:43:08.826484   904 sgd_solver.cpp:106] Iteration 109360, lr = 0.0142682
I0605 14:43:29.619938   904 solver.cpp:229] Iteration 109400, loss = 2.4977
I0605 14:43:29.620188   904 solver.cpp:245]     Train net output #0: loss = 2.43352 (* 1 = 2.43352 loss)
I0605 14:43:29.620210   904 sgd_solver.cpp:106] Iteration 109400, lr = 0.0142588
I0605 14:43:50.402716   904 solver.cpp:229] Iteration 109440, loss = 2.47311
I0605 14:43:50.402782   904 solver.cpp:245]     Train net output #0: loss = 2.31374 (* 1 = 2.31374 loss)
I0605 14:43:50.402792   904 sgd_solver.cpp:106] Iteration 109440, lr = 0.0142494
I0605 14:43:57.902688   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 14:44:11.090991   904 solver.cpp:229] Iteration 109480, loss = 2.48404
I0605 14:44:11.091156   904 solver.cpp:245]     Train net output #0: loss = 2.60558 (* 1 = 2.60558 loss)
I0605 14:44:11.091187   904 sgd_solver.cpp:106] Iteration 109480, lr = 0.01424
I0605 14:44:31.791553   904 solver.cpp:229] Iteration 109520, loss = 2.4441
I0605 14:44:31.791602   904 solver.cpp:245]     Train net output #0: loss = 2.3361 (* 1 = 2.3361 loss)
I0605 14:44:31.791611   904 sgd_solver.cpp:106] Iteration 109520, lr = 0.0142306
I0605 14:44:52.556505   904 solver.cpp:229] Iteration 109560, loss = 2.44145
I0605 14:44:52.556674   904 solver.cpp:245]     Train net output #0: loss = 2.04913 (* 1 = 2.04913 loss)
I0605 14:44:52.556686   904 sgd_solver.cpp:106] Iteration 109560, lr = 0.0142212
I0605 14:45:13.102319   904 solver.cpp:229] Iteration 109600, loss = 2.47421
I0605 14:45:13.102370   904 solver.cpp:245]     Train net output #0: loss = 2.40518 (* 1 = 2.40518 loss)
I0605 14:45:13.102377   904 sgd_solver.cpp:106] Iteration 109600, lr = 0.0142118
I0605 14:45:33.752244   904 solver.cpp:229] Iteration 109640, loss = 2.45138
I0605 14:45:33.752480   904 solver.cpp:245]     Train net output #0: loss = 2.32744 (* 1 = 2.32744 loss)
I0605 14:45:33.752511   904 sgd_solver.cpp:106] Iteration 109640, lr = 0.0142024
I0605 14:45:54.410641   904 solver.cpp:229] Iteration 109680, loss = 2.44757
I0605 14:45:54.410702   904 solver.cpp:245]     Train net output #0: loss = 2.40061 (* 1 = 2.40061 loss)
I0605 14:45:54.410712   904 sgd_solver.cpp:106] Iteration 109680, lr = 0.0141929
I0605 14:46:14.973654   904 solver.cpp:229] Iteration 109720, loss = 2.48377
I0605 14:46:14.973799   904 solver.cpp:245]     Train net output #0: loss = 2.50859 (* 1 = 2.50859 loss)
I0605 14:46:14.973809   904 sgd_solver.cpp:106] Iteration 109720, lr = 0.0141835
I0605 14:46:35.474647   904 solver.cpp:229] Iteration 109760, loss = 2.44278
I0605 14:46:35.474694   904 solver.cpp:245]     Train net output #0: loss = 2.57398 (* 1 = 2.57398 loss)
I0605 14:46:35.474704   904 sgd_solver.cpp:106] Iteration 109760, lr = 0.0141741
I0605 14:46:56.124343   904 solver.cpp:229] Iteration 109800, loss = 2.44137
I0605 14:46:56.124562   904 solver.cpp:245]     Train net output #0: loss = 2.56099 (* 1 = 2.56099 loss)
I0605 14:46:56.124591   904 sgd_solver.cpp:106] Iteration 109800, lr = 0.0141647
I0605 14:47:16.727715   904 solver.cpp:229] Iteration 109840, loss = 2.46749
I0605 14:47:16.727762   904 solver.cpp:245]     Train net output #0: loss = 2.37676 (* 1 = 2.37676 loss)
I0605 14:47:16.727769   904 sgd_solver.cpp:106] Iteration 109840, lr = 0.0141553
I0605 14:47:37.282135   904 solver.cpp:229] Iteration 109880, loss = 2.47108
I0605 14:47:37.282320   904 solver.cpp:245]     Train net output #0: loss = 2.50421 (* 1 = 2.50421 loss)
I0605 14:47:37.282343   904 sgd_solver.cpp:106] Iteration 109880, lr = 0.0141459
I0605 14:47:57.802005   904 solver.cpp:229] Iteration 109920, loss = 2.46271
I0605 14:47:57.802042   904 solver.cpp:245]     Train net output #0: loss = 2.48571 (* 1 = 2.48571 loss)
I0605 14:47:57.802052   904 sgd_solver.cpp:106] Iteration 109920, lr = 0.0141365
I0605 14:48:18.294468   904 solver.cpp:229] Iteration 109960, loss = 2.44071
I0605 14:48:18.294670   904 solver.cpp:245]     Train net output #0: loss = 2.33345 (* 1 = 2.33345 loss)
I0605 14:48:18.294699   904 sgd_solver.cpp:106] Iteration 109960, lr = 0.0141271
I0605 14:48:38.277593   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_110000.caffemodel
I0605 14:48:38.537662   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_110000.solverstate
I0605 14:48:38.616201   904 solver.cpp:338] Iteration 110000, Testing net (#0)
I0605 14:48:38.616286   904 net.cpp:748] Ignoring source layer loss
I0605 14:48:40.275435   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 14:49:14.465313   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 14:49:46.030169   904 solver.cpp:406]     Test net output #0: accuracy = 0.456981
I0605 14:49:46.030302   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.70714
I0605 14:49:46.344122   904 solver.cpp:229] Iteration 110000, loss = 2.45792
I0605 14:49:46.344164   904 solver.cpp:245]     Train net output #0: loss = 2.3313 (* 1 = 2.3313 loss)
I0605 14:49:46.344174   904 sgd_solver.cpp:106] Iteration 110000, lr = 0.0141176
I0605 14:49:58.808508   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 14:50:05.573153   904 solver.cpp:229] Iteration 110040, loss = 2.47198
I0605 14:50:05.573210   904 solver.cpp:245]     Train net output #0: loss = 2.48359 (* 1 = 2.48359 loss)
I0605 14:50:05.573220   904 sgd_solver.cpp:106] Iteration 110040, lr = 0.0141082
I0605 14:50:27.058957   904 solver.cpp:229] Iteration 110080, loss = 2.46452
I0605 14:50:27.059115   904 solver.cpp:245]     Train net output #0: loss = 2.3133 (* 1 = 2.3133 loss)
I0605 14:50:27.059128   904 sgd_solver.cpp:106] Iteration 110080, lr = 0.0140988
I0605 14:50:48.593248   904 solver.cpp:229] Iteration 110120, loss = 2.49772
I0605 14:50:48.593323   904 solver.cpp:245]     Train net output #0: loss = 2.42387 (* 1 = 2.42387 loss)
I0605 14:50:48.593333   904 sgd_solver.cpp:106] Iteration 110120, lr = 0.0140894
I0605 14:51:10.243965   904 solver.cpp:229] Iteration 110160, loss = 2.53232
I0605 14:51:10.244127   904 solver.cpp:245]     Train net output #0: loss = 2.50134 (* 1 = 2.50134 loss)
I0605 14:51:10.244148   904 sgd_solver.cpp:106] Iteration 110160, lr = 0.01408
I0605 14:51:31.381397   904 solver.cpp:229] Iteration 110200, loss = 2.46295
I0605 14:51:31.381445   904 solver.cpp:245]     Train net output #0: loss = 2.59131 (* 1 = 2.59131 loss)
I0605 14:51:31.381454   904 sgd_solver.cpp:106] Iteration 110200, lr = 0.0140706
I0605 14:51:52.488250   904 solver.cpp:229] Iteration 110240, loss = 2.44699
I0605 14:51:52.488433   904 solver.cpp:245]     Train net output #0: loss = 2.52787 (* 1 = 2.52787 loss)
I0605 14:51:52.488463   904 sgd_solver.cpp:106] Iteration 110240, lr = 0.0140612
I0605 14:52:13.479876   904 solver.cpp:229] Iteration 110280, loss = 2.46361
I0605 14:52:13.479924   904 solver.cpp:245]     Train net output #0: loss = 2.61619 (* 1 = 2.61619 loss)
I0605 14:52:13.479933   904 sgd_solver.cpp:106] Iteration 110280, lr = 0.0140518
I0605 14:52:34.472553   904 solver.cpp:229] Iteration 110320, loss = 2.43858
I0605 14:52:34.472766   904 solver.cpp:245]     Train net output #0: loss = 2.42424 (* 1 = 2.42424 loss)
I0605 14:52:34.472795   904 sgd_solver.cpp:106] Iteration 110320, lr = 0.0140424
I0605 14:52:55.246948   904 solver.cpp:229] Iteration 110360, loss = 2.46283
I0605 14:52:55.246991   904 solver.cpp:245]     Train net output #0: loss = 2.43496 (* 1 = 2.43496 loss)
I0605 14:52:55.246997   904 sgd_solver.cpp:106] Iteration 110360, lr = 0.0140329
I0605 14:53:15.920893   904 solver.cpp:229] Iteration 110400, loss = 2.4903
I0605 14:53:15.921073   904 solver.cpp:245]     Train net output #0: loss = 2.42107 (* 1 = 2.42107 loss)
I0605 14:53:15.921090   904 sgd_solver.cpp:106] Iteration 110400, lr = 0.0140235
I0605 14:53:36.604871   904 solver.cpp:229] Iteration 110440, loss = 2.47345
I0605 14:53:36.604935   904 solver.cpp:245]     Train net output #0: loss = 2.40191 (* 1 = 2.40191 loss)
I0605 14:53:36.604943   904 sgd_solver.cpp:106] Iteration 110440, lr = 0.0140141
I0605 14:53:57.309628   904 solver.cpp:229] Iteration 110480, loss = 2.44802
I0605 14:53:57.309813   904 solver.cpp:245]     Train net output #0: loss = 2.1907 (* 1 = 2.1907 loss)
I0605 14:53:57.309835   904 sgd_solver.cpp:106] Iteration 110480, lr = 0.0140047
I0605 14:54:18.008519   904 solver.cpp:229] Iteration 110520, loss = 2.45045
I0605 14:54:18.008568   904 solver.cpp:245]     Train net output #0: loss = 2.50159 (* 1 = 2.50159 loss)
I0605 14:54:18.008577   904 sgd_solver.cpp:106] Iteration 110520, lr = 0.0139953
I0605 14:54:38.685310   904 solver.cpp:229] Iteration 110560, loss = 2.48329
I0605 14:54:38.685550   904 solver.cpp:245]     Train net output #0: loss = 2.11267 (* 1 = 2.11267 loss)
I0605 14:54:38.685570   904 sgd_solver.cpp:106] Iteration 110560, lr = 0.0139859
I0605 14:54:45.909790   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 14:54:59.222208   904 solver.cpp:229] Iteration 110600, loss = 2.49387
I0605 14:54:59.222280   904 solver.cpp:245]     Train net output #0: loss = 2.39577 (* 1 = 2.39577 loss)
I0605 14:54:59.222291   904 sgd_solver.cpp:106] Iteration 110600, lr = 0.0139765
I0605 14:55:19.706462   904 solver.cpp:229] Iteration 110640, loss = 2.44557
I0605 14:55:19.706660   904 solver.cpp:245]     Train net output #0: loss = 2.36936 (* 1 = 2.36936 loss)
I0605 14:55:19.706692   904 sgd_solver.cpp:106] Iteration 110640, lr = 0.0139671
I0605 14:55:40.201990   904 solver.cpp:229] Iteration 110680, loss = 2.45388
I0605 14:55:40.202039   904 solver.cpp:245]     Train net output #0: loss = 2.54226 (* 1 = 2.54226 loss)
I0605 14:55:40.202049   904 sgd_solver.cpp:106] Iteration 110680, lr = 0.0139576
I0605 14:56:00.709877   904 solver.cpp:229] Iteration 110720, loss = 2.46161
I0605 14:56:00.710067   904 solver.cpp:245]     Train net output #0: loss = 2.67009 (* 1 = 2.67009 loss)
I0605 14:56:00.710093   904 sgd_solver.cpp:106] Iteration 110720, lr = 0.0139482
I0605 14:56:21.184907   904 solver.cpp:229] Iteration 110760, loss = 2.47408
I0605 14:56:21.184948   904 solver.cpp:245]     Train net output #0: loss = 2.28465 (* 1 = 2.28465 loss)
I0605 14:56:21.184957   904 sgd_solver.cpp:106] Iteration 110760, lr = 0.0139388
I0605 14:56:41.690522   904 solver.cpp:229] Iteration 110800, loss = 2.42409
I0605 14:56:41.690745   904 solver.cpp:245]     Train net output #0: loss = 2.5773 (* 1 = 2.5773 loss)
I0605 14:56:41.690778   904 sgd_solver.cpp:106] Iteration 110800, lr = 0.0139294
I0605 14:57:02.038625   904 solver.cpp:229] Iteration 110840, loss = 2.48658
I0605 14:57:02.038662   904 solver.cpp:245]     Train net output #0: loss = 2.58816 (* 1 = 2.58816 loss)
I0605 14:57:02.038671   904 sgd_solver.cpp:106] Iteration 110840, lr = 0.01392
I0605 14:57:22.340059   904 solver.cpp:229] Iteration 110880, loss = 2.48939
I0605 14:57:22.340236   904 solver.cpp:245]     Train net output #0: loss = 2.26034 (* 1 = 2.26034 loss)
I0605 14:57:22.340246   904 sgd_solver.cpp:106] Iteration 110880, lr = 0.0139106
I0605 14:57:42.628760   904 solver.cpp:229] Iteration 110920, loss = 2.44989
I0605 14:57:42.628828   904 solver.cpp:245]     Train net output #0: loss = 2.76215 (* 1 = 2.76215 loss)
I0605 14:57:42.628835   904 sgd_solver.cpp:106] Iteration 110920, lr = 0.0139012
I0605 14:58:02.923216   904 solver.cpp:229] Iteration 110960, loss = 2.45684
I0605 14:58:02.923432   904 solver.cpp:245]     Train net output #0: loss = 2.57231 (* 1 = 2.57231 loss)
I0605 14:58:02.923458   904 sgd_solver.cpp:106] Iteration 110960, lr = 0.0138918
I0605 14:58:22.677464   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_111000.caffemodel
I0605 14:58:22.942821   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_111000.solverstate
I0605 14:58:23.020953   904 solver.cpp:338] Iteration 111000, Testing net (#0)
I0605 14:58:23.021029   904 net.cpp:748] Ignoring source layer loss
I0605 14:58:34.576110   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 14:59:08.721804   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 14:59:30.895807   904 solver.cpp:406]     Test net output #0: accuracy = 0.456121
I0605 14:59:30.895844   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.710639
I0605 14:59:31.208405   904 solver.cpp:229] Iteration 111000, loss = 2.47183
I0605 14:59:31.208447   904 solver.cpp:245]     Train net output #0: loss = 2.59449 (* 1 = 2.59449 loss)
I0605 14:59:31.208456   904 sgd_solver.cpp:106] Iteration 111000, lr = 0.0138824
I0605 14:59:50.385491   904 solver.cpp:229] Iteration 111040, loss = 2.43841
I0605 14:59:50.385761   904 solver.cpp:245]     Train net output #0: loss = 2.52874 (* 1 = 2.52874 loss)
I0605 14:59:50.385789   904 sgd_solver.cpp:106] Iteration 111040, lr = 0.0138729
I0605 15:00:11.748764   904 solver.cpp:229] Iteration 111080, loss = 2.44411
I0605 15:00:11.748824   904 solver.cpp:245]     Train net output #0: loss = 2.49478 (* 1 = 2.49478 loss)
I0605 15:00:11.748837   904 sgd_solver.cpp:106] Iteration 111080, lr = 0.0138635
I0605 15:00:33.232764   904 solver.cpp:229] Iteration 111120, loss = 2.43685
I0605 15:00:33.232985   904 solver.cpp:245]     Train net output #0: loss = 2.54233 (* 1 = 2.54233 loss)
I0605 15:00:33.233006   904 sgd_solver.cpp:106] Iteration 111120, lr = 0.0138541
I0605 15:00:54.431885   904 solver.cpp:229] Iteration 111160, loss = 2.47749
I0605 15:00:54.431947   904 solver.cpp:245]     Train net output #0: loss = 2.42319 (* 1 = 2.42319 loss)
I0605 15:00:54.431957   904 sgd_solver.cpp:106] Iteration 111160, lr = 0.0138447
I0605 15:01:08.550729   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 15:01:15.353636   904 solver.cpp:229] Iteration 111200, loss = 2.44029
I0605 15:01:15.353677   904 solver.cpp:245]     Train net output #0: loss = 2.42186 (* 1 = 2.42186 loss)
I0605 15:01:15.353683   904 sgd_solver.cpp:106] Iteration 111200, lr = 0.0138353
I0605 15:01:36.325156   904 solver.cpp:229] Iteration 111240, loss = 2.46594
I0605 15:01:36.325209   904 solver.cpp:245]     Train net output #0: loss = 2.41586 (* 1 = 2.41586 loss)
I0605 15:01:36.325218   904 sgd_solver.cpp:106] Iteration 111240, lr = 0.0138259
I0605 15:01:57.263211   904 solver.cpp:229] Iteration 111280, loss = 2.44973
I0605 15:01:57.263381   904 solver.cpp:245]     Train net output #0: loss = 2.49796 (* 1 = 2.49796 loss)
I0605 15:01:57.263401   904 sgd_solver.cpp:106] Iteration 111280, lr = 0.0138165
I0605 15:02:18.078316   904 solver.cpp:229] Iteration 111320, loss = 2.45013
I0605 15:02:18.078374   904 solver.cpp:245]     Train net output #0: loss = 2.48093 (* 1 = 2.48093 loss)
I0605 15:02:18.078384   904 sgd_solver.cpp:106] Iteration 111320, lr = 0.0138071
I0605 15:02:38.837371   904 solver.cpp:229] Iteration 111360, loss = 2.46312
I0605 15:02:38.837553   904 solver.cpp:245]     Train net output #0: loss = 2.69012 (* 1 = 2.69012 loss)
I0605 15:02:38.837574   904 sgd_solver.cpp:106] Iteration 111360, lr = 0.0137976
I0605 15:02:59.307440   904 solver.cpp:229] Iteration 111400, loss = 2.4293
I0605 15:02:59.307481   904 solver.cpp:245]     Train net output #0: loss = 2.31922 (* 1 = 2.31922 loss)
I0605 15:02:59.307487   904 sgd_solver.cpp:106] Iteration 111400, lr = 0.0137882
I0605 15:03:19.864722   904 solver.cpp:229] Iteration 111440, loss = 2.45823
I0605 15:03:19.864934   904 solver.cpp:245]     Train net output #0: loss = 2.29288 (* 1 = 2.29288 loss)
I0605 15:03:19.864959   904 sgd_solver.cpp:106] Iteration 111440, lr = 0.0137788
I0605 15:03:40.775162   904 solver.cpp:229] Iteration 111480, loss = 2.44876
I0605 15:03:40.775207   904 solver.cpp:245]     Train net output #0: loss = 2.57639 (* 1 = 2.57639 loss)
I0605 15:03:40.775216   904 sgd_solver.cpp:106] Iteration 111480, lr = 0.0137694
I0605 15:04:01.049584   904 solver.cpp:229] Iteration 111520, loss = 2.50128
I0605 15:04:01.049811   904 solver.cpp:245]     Train net output #0: loss = 2.70654 (* 1 = 2.70654 loss)
I0605 15:04:01.049837   904 sgd_solver.cpp:106] Iteration 111520, lr = 0.01376
I0605 15:04:21.483862   904 solver.cpp:229] Iteration 111560, loss = 2.47194
I0605 15:04:21.483916   904 solver.cpp:245]     Train net output #0: loss = 2.55867 (* 1 = 2.55867 loss)
I0605 15:04:21.483927   904 sgd_solver.cpp:106] Iteration 111560, lr = 0.0137506
I0605 15:04:41.917208   904 solver.cpp:229] Iteration 111600, loss = 2.44788
I0605 15:04:41.917417   904 solver.cpp:245]     Train net output #0: loss = 2.4467 (* 1 = 2.4467 loss)
I0605 15:04:41.917441   904 sgd_solver.cpp:106] Iteration 111600, lr = 0.0137412
I0605 15:05:02.376005   904 solver.cpp:229] Iteration 111640, loss = 2.4926
I0605 15:05:02.376045   904 solver.cpp:245]     Train net output #0: loss = 2.45114 (* 1 = 2.45114 loss)
I0605 15:05:02.376051   904 sgd_solver.cpp:106] Iteration 111640, lr = 0.0137318
I0605 15:05:22.793310   904 solver.cpp:229] Iteration 111680, loss = 2.47912
I0605 15:05:22.793454   904 solver.cpp:245]     Train net output #0: loss = 2.40004 (* 1 = 2.40004 loss)
I0605 15:05:22.793462   904 sgd_solver.cpp:106] Iteration 111680, lr = 0.0137224
I0605 15:05:43.198488   904 solver.cpp:229] Iteration 111720, loss = 2.45149
I0605 15:05:43.198529   904 solver.cpp:245]     Train net output #0: loss = 2.29783 (* 1 = 2.29783 loss)
I0605 15:05:43.198536   904 sgd_solver.cpp:106] Iteration 111720, lr = 0.0137129
I0605 15:05:53.767606   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 15:06:03.328966   904 solver.cpp:229] Iteration 111760, loss = 2.45188
I0605 15:06:03.329012   904 solver.cpp:245]     Train net output #0: loss = 2.53394 (* 1 = 2.53394 loss)
I0605 15:06:03.329021   904 sgd_solver.cpp:106] Iteration 111760, lr = 0.0137035
I0605 15:06:23.548161   904 solver.cpp:229] Iteration 111800, loss = 2.45799
I0605 15:06:23.548208   904 solver.cpp:245]     Train net output #0: loss = 2.28978 (* 1 = 2.28978 loss)
I0605 15:06:23.548216   904 sgd_solver.cpp:106] Iteration 111800, lr = 0.0136941
I0605 15:06:43.751405   904 solver.cpp:229] Iteration 111840, loss = 2.41511
I0605 15:06:43.751610   904 solver.cpp:245]     Train net output #0: loss = 2.39562 (* 1 = 2.39562 loss)
I0605 15:06:43.751634   904 sgd_solver.cpp:106] Iteration 111840, lr = 0.0136847
I0605 15:07:03.980679   904 solver.cpp:229] Iteration 111880, loss = 2.4335
I0605 15:07:03.980734   904 solver.cpp:245]     Train net output #0: loss = 2.2878 (* 1 = 2.2878 loss)
I0605 15:07:03.980743   904 sgd_solver.cpp:106] Iteration 111880, lr = 0.0136753
I0605 15:07:24.173682   904 solver.cpp:229] Iteration 111920, loss = 2.41814
I0605 15:07:24.173877   904 solver.cpp:245]     Train net output #0: loss = 2.39588 (* 1 = 2.39588 loss)
I0605 15:07:24.173902   904 sgd_solver.cpp:106] Iteration 111920, lr = 0.0136659
I0605 15:07:44.365994   904 solver.cpp:229] Iteration 111960, loss = 2.44388
I0605 15:07:44.366044   904 solver.cpp:245]     Train net output #0: loss = 2.44803 (* 1 = 2.44803 loss)
I0605 15:07:44.366053   904 sgd_solver.cpp:106] Iteration 111960, lr = 0.0136565
I0605 15:08:04.069638   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_112000.caffemodel
I0605 15:08:04.334056   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_112000.solverstate
I0605 15:08:04.421056   904 solver.cpp:338] Iteration 112000, Testing net (#0)
I0605 15:08:04.421142   904 net.cpp:748] Ignoring source layer loss
I0605 15:08:20.845222   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 15:08:53.211413   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 15:09:10.066648   904 solver.cpp:406]     Test net output #0: accuracy = 0.458101
I0605 15:09:10.066691   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.70508
I0605 15:09:10.383579   904 solver.cpp:229] Iteration 112000, loss = 2.42031
I0605 15:09:10.383623   904 solver.cpp:245]     Train net output #0: loss = 2.42573 (* 1 = 2.42573 loss)
I0605 15:09:10.383635   904 sgd_solver.cpp:106] Iteration 112000, lr = 0.0136471
I0605 15:09:29.634286   904 solver.cpp:229] Iteration 112040, loss = 2.42819
I0605 15:09:29.634448   904 solver.cpp:245]     Train net output #0: loss = 2.51251 (* 1 = 2.51251 loss)
I0605 15:09:29.634461   904 sgd_solver.cpp:106] Iteration 112040, lr = 0.0136376
I0605 15:09:51.013926   904 solver.cpp:229] Iteration 112080, loss = 2.42631
I0605 15:09:51.013972   904 solver.cpp:245]     Train net output #0: loss = 2.35271 (* 1 = 2.35271 loss)
I0605 15:09:51.013983   904 sgd_solver.cpp:106] Iteration 112080, lr = 0.0136282
I0605 15:10:12.528966   904 solver.cpp:229] Iteration 112120, loss = 2.43521
I0605 15:10:12.529258   904 solver.cpp:245]     Train net output #0: loss = 2.44915 (* 1 = 2.44915 loss)
I0605 15:10:12.529294   904 sgd_solver.cpp:106] Iteration 112120, lr = 0.0136188
I0605 15:10:33.640477   904 solver.cpp:229] Iteration 112160, loss = 2.43184
I0605 15:10:33.640522   904 solver.cpp:245]     Train net output #0: loss = 2.49265 (* 1 = 2.49265 loss)
I0605 15:10:33.640533   904 sgd_solver.cpp:106] Iteration 112160, lr = 0.0136094
I0605 15:10:54.661391   904 solver.cpp:229] Iteration 112200, loss = 2.44073
I0605 15:10:54.661592   904 solver.cpp:245]     Train net output #0: loss = 2.50026 (* 1 = 2.50026 loss)
I0605 15:10:54.661605   904 sgd_solver.cpp:106] Iteration 112200, lr = 0.0136
I0605 15:11:15.705381   904 solver.cpp:229] Iteration 112240, loss = 2.43121
I0605 15:11:15.705441   904 solver.cpp:245]     Train net output #0: loss = 2.45065 (* 1 = 2.45065 loss)
I0605 15:11:15.705456   904 sgd_solver.cpp:106] Iteration 112240, lr = 0.0135906
I0605 15:11:20.966161   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 15:11:36.733971   904 solver.cpp:229] Iteration 112280, loss = 2.50283
I0605 15:11:36.734143   904 solver.cpp:245]     Train net output #0: loss = 2.40385 (* 1 = 2.40385 loss)
I0605 15:11:36.734158   904 sgd_solver.cpp:106] Iteration 112280, lr = 0.0135812
I0605 15:11:57.730250   904 solver.cpp:229] Iteration 112320, loss = 2.41216
I0605 15:11:57.730303   904 solver.cpp:245]     Train net output #0: loss = 2.42498 (* 1 = 2.42498 loss)
I0605 15:11:57.730314   904 sgd_solver.cpp:106] Iteration 112320, lr = 0.0135718
I0605 15:12:18.583907   904 solver.cpp:229] Iteration 112360, loss = 2.47661
I0605 15:12:18.584115   904 solver.cpp:245]     Train net output #0: loss = 2.60918 (* 1 = 2.60918 loss)
I0605 15:12:18.584141   904 sgd_solver.cpp:106] Iteration 112360, lr = 0.0135624
I0605 15:12:39.422384   904 solver.cpp:229] Iteration 112400, loss = 2.45353
I0605 15:12:39.422433   904 solver.cpp:245]     Train net output #0: loss = 2.54121 (* 1 = 2.54121 loss)
I0605 15:12:39.422444   904 sgd_solver.cpp:106] Iteration 112400, lr = 0.0135529
I0605 15:13:00.264451   904 solver.cpp:229] Iteration 112440, loss = 2.41644
I0605 15:13:00.264689   904 solver.cpp:245]     Train net output #0: loss = 2.2317 (* 1 = 2.2317 loss)
I0605 15:13:00.264717   904 sgd_solver.cpp:106] Iteration 112440, lr = 0.0135435
I0605 15:13:21.067703   904 solver.cpp:229] Iteration 112480, loss = 2.46422
I0605 15:13:21.067746   904 solver.cpp:245]     Train net output #0: loss = 2.47699 (* 1 = 2.47699 loss)
I0605 15:13:21.067756   904 sgd_solver.cpp:106] Iteration 112480, lr = 0.0135341
I0605 15:13:41.682342   904 solver.cpp:229] Iteration 112520, loss = 2.44915
I0605 15:13:41.682543   904 solver.cpp:245]     Train net output #0: loss = 2.67555 (* 1 = 2.67555 loss)
I0605 15:13:41.682569   904 sgd_solver.cpp:106] Iteration 112520, lr = 0.0135247
I0605 15:14:02.342437   904 solver.cpp:229] Iteration 112560, loss = 2.46087
I0605 15:14:02.342490   904 solver.cpp:245]     Train net output #0: loss = 2.50328 (* 1 = 2.50328 loss)
I0605 15:14:02.342500   904 sgd_solver.cpp:106] Iteration 112560, lr = 0.0135153
I0605 15:14:23.014322   904 solver.cpp:229] Iteration 112600, loss = 2.45441
I0605 15:14:23.014503   904 solver.cpp:245]     Train net output #0: loss = 2.53534 (* 1 = 2.53534 loss)
I0605 15:14:23.014536   904 sgd_solver.cpp:106] Iteration 112600, lr = 0.0135059
I0605 15:14:43.694355   904 solver.cpp:229] Iteration 112640, loss = 2.48106
I0605 15:14:43.694398   904 solver.cpp:245]     Train net output #0: loss = 2.75186 (* 1 = 2.75186 loss)
I0605 15:14:43.694407   904 sgd_solver.cpp:106] Iteration 112640, lr = 0.0134965
I0605 15:15:04.370117   904 solver.cpp:229] Iteration 112680, loss = 2.48881
I0605 15:15:04.370288   904 solver.cpp:245]     Train net output #0: loss = 2.70028 (* 1 = 2.70028 loss)
I0605 15:15:04.370301   904 sgd_solver.cpp:106] Iteration 112680, lr = 0.0134871
I0605 15:15:25.033361   904 solver.cpp:229] Iteration 112720, loss = 2.45577
I0605 15:15:25.033406   904 solver.cpp:245]     Train net output #0: loss = 2.53322 (* 1 = 2.53322 loss)
I0605 15:15:25.033412   904 sgd_solver.cpp:106] Iteration 112720, lr = 0.0134776
I0605 15:15:42.305065   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 15:15:45.640692   904 solver.cpp:229] Iteration 112760, loss = 2.45479
I0605 15:15:45.640735   904 solver.cpp:245]     Train net output #0: loss = 2.23796 (* 1 = 2.23796 loss)
I0605 15:15:45.640746   904 sgd_solver.cpp:106] Iteration 112760, lr = 0.0134682
I0605 15:16:06.170438   904 solver.cpp:229] Iteration 112800, loss = 2.46538
I0605 15:16:06.170497   904 solver.cpp:245]     Train net output #0: loss = 2.40997 (* 1 = 2.40997 loss)
I0605 15:16:06.170508   904 sgd_solver.cpp:106] Iteration 112800, lr = 0.0134588
I0605 15:16:26.804370   904 solver.cpp:229] Iteration 112840, loss = 2.45939
I0605 15:16:26.804553   904 solver.cpp:245]     Train net output #0: loss = 2.34219 (* 1 = 2.34219 loss)
I0605 15:16:26.804565   904 sgd_solver.cpp:106] Iteration 112840, lr = 0.0134494
I0605 15:16:47.467411   904 solver.cpp:229] Iteration 112880, loss = 2.47321
I0605 15:16:47.467452   904 solver.cpp:245]     Train net output #0: loss = 2.53328 (* 1 = 2.53328 loss)
I0605 15:16:47.467459   904 sgd_solver.cpp:106] Iteration 112880, lr = 0.01344
I0605 15:17:08.025506   904 solver.cpp:229] Iteration 112920, loss = 2.44014
I0605 15:17:08.025655   904 solver.cpp:245]     Train net output #0: loss = 2.57082 (* 1 = 2.57082 loss)
I0605 15:17:08.025665   904 sgd_solver.cpp:106] Iteration 112920, lr = 0.0134306
I0605 15:17:28.575167   904 solver.cpp:229] Iteration 112960, loss = 2.42266
I0605 15:17:28.575212   904 solver.cpp:245]     Train net output #0: loss = 2.28072 (* 1 = 2.28072 loss)
I0605 15:17:28.575220   904 sgd_solver.cpp:106] Iteration 112960, lr = 0.0134212
I0605 15:17:48.603011   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_113000.caffemodel
I0605 15:17:48.869747   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_113000.solverstate
I0605 15:17:48.951548   904 solver.cpp:338] Iteration 113000, Testing net (#0)
I0605 15:17:48.951642   904 net.cpp:748] Ignoring source layer loss
I0605 15:18:05.365218   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 15:18:37.902128   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 15:18:53.747306   904 solver.cpp:406]     Test net output #0: accuracy = 0.455221
I0605 15:18:53.747339   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.706999
I0605 15:18:54.061868   904 solver.cpp:229] Iteration 113000, loss = 2.43636
I0605 15:18:54.061915   904 solver.cpp:245]     Train net output #0: loss = 2.3161 (* 1 = 2.3161 loss)
I0605 15:18:54.061926   904 sgd_solver.cpp:106] Iteration 113000, lr = 0.0134118
I0605 15:19:13.350893   904 solver.cpp:229] Iteration 113040, loss = 2.47293
I0605 15:19:13.351068   904 solver.cpp:245]     Train net output #0: loss = 2.42553 (* 1 = 2.42553 loss)
I0605 15:19:13.351079   904 sgd_solver.cpp:106] Iteration 113040, lr = 0.0134024
I0605 15:19:34.806021   904 solver.cpp:229] Iteration 113080, loss = 2.49453
I0605 15:19:34.806078   904 solver.cpp:245]     Train net output #0: loss = 2.61841 (* 1 = 2.61841 loss)
I0605 15:19:34.806087   904 sgd_solver.cpp:106] Iteration 113080, lr = 0.0133929
I0605 15:19:56.375861   904 solver.cpp:229] Iteration 113120, loss = 2.4473
I0605 15:19:56.376010   904 solver.cpp:245]     Train net output #0: loss = 2.56549 (* 1 = 2.56549 loss)
I0605 15:19:56.376021   904 sgd_solver.cpp:106] Iteration 113120, lr = 0.0133835
I0605 15:20:17.761054   904 solver.cpp:229] Iteration 113160, loss = 2.43011
I0605 15:20:17.761098   904 solver.cpp:245]     Train net output #0: loss = 2.81968 (* 1 = 2.81968 loss)
I0605 15:20:17.761109   904 sgd_solver.cpp:106] Iteration 113160, lr = 0.0133741
I0605 15:20:38.745918   904 solver.cpp:229] Iteration 113200, loss = 2.46727
I0605 15:20:38.746141   904 solver.cpp:245]     Train net output #0: loss = 2.30588 (* 1 = 2.30588 loss)
I0605 15:20:38.746153   904 sgd_solver.cpp:106] Iteration 113200, lr = 0.0133647
I0605 15:20:59.898856   904 solver.cpp:229] Iteration 113240, loss = 2.45064
I0605 15:20:59.898905   904 solver.cpp:245]     Train net output #0: loss = 2.37953 (* 1 = 2.37953 loss)
I0605 15:20:59.898917   904 sgd_solver.cpp:106] Iteration 113240, lr = 0.0133553
I0605 15:21:10.200978   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 15:21:20.952847   904 solver.cpp:229] Iteration 113280, loss = 2.448
I0605 15:21:20.952885   904 solver.cpp:245]     Train net output #0: loss = 2.30227 (* 1 = 2.30227 loss)
I0605 15:21:20.952893   904 sgd_solver.cpp:106] Iteration 113280, lr = 0.0133459
I0605 15:21:41.980985   904 solver.cpp:229] Iteration 113320, loss = 2.45812
I0605 15:21:41.981168   904 solver.cpp:245]     Train net output #0: loss = 2.55131 (* 1 = 2.55131 loss)
I0605 15:21:41.981194   904 sgd_solver.cpp:106] Iteration 113320, lr = 0.0133365
I0605 15:22:02.973142   904 solver.cpp:229] Iteration 113360, loss = 2.46687
I0605 15:22:02.973186   904 solver.cpp:245]     Train net output #0: loss = 2.41366 (* 1 = 2.41366 loss)
I0605 15:22:02.973196   904 sgd_solver.cpp:106] Iteration 113360, lr = 0.0133271
I0605 15:22:23.781796   904 solver.cpp:229] Iteration 113400, loss = 2.44401
I0605 15:22:23.781950   904 solver.cpp:245]     Train net output #0: loss = 2.61426 (* 1 = 2.61426 loss)
I0605 15:22:23.781960   904 sgd_solver.cpp:106] Iteration 113400, lr = 0.0133176
I0605 15:22:44.583545   904 solver.cpp:229] Iteration 113440, loss = 2.42819
I0605 15:22:44.583593   904 solver.cpp:245]     Train net output #0: loss = 2.64167 (* 1 = 2.64167 loss)
I0605 15:22:44.583600   904 sgd_solver.cpp:106] Iteration 113440, lr = 0.0133082
I0605 15:23:05.403643   904 solver.cpp:229] Iteration 113480, loss = 2.4376
I0605 15:23:05.403888   904 solver.cpp:245]     Train net output #0: loss = 2.45571 (* 1 = 2.45571 loss)
I0605 15:23:05.403914   904 sgd_solver.cpp:106] Iteration 113480, lr = 0.0132988
I0605 15:23:26.168812   904 solver.cpp:229] Iteration 113520, loss = 2.44199
I0605 15:23:26.168859   904 solver.cpp:245]     Train net output #0: loss = 2.54081 (* 1 = 2.54081 loss)
I0605 15:23:26.168871   904 sgd_solver.cpp:106] Iteration 113520, lr = 0.0132894
I0605 15:23:46.855628   904 solver.cpp:229] Iteration 113560, loss = 2.39466
I0605 15:23:46.855763   904 solver.cpp:245]     Train net output #0: loss = 2.41796 (* 1 = 2.41796 loss)
I0605 15:23:46.855775   904 sgd_solver.cpp:106] Iteration 113560, lr = 0.01328
I0605 15:24:07.557598   904 solver.cpp:229] Iteration 113600, loss = 2.43993
I0605 15:24:07.557641   904 solver.cpp:245]     Train net output #0: loss = 2.46163 (* 1 = 2.46163 loss)
I0605 15:24:07.557651   904 sgd_solver.cpp:106] Iteration 113600, lr = 0.0132706
I0605 15:24:28.254012   904 solver.cpp:229] Iteration 113640, loss = 2.42979
I0605 15:24:28.254155   904 solver.cpp:245]     Train net output #0: loss = 2.31563 (* 1 = 2.31563 loss)
I0605 15:24:28.254168   904 sgd_solver.cpp:106] Iteration 113640, lr = 0.0132612
I0605 15:24:48.784685   904 solver.cpp:229] Iteration 113680, loss = 2.42376
I0605 15:24:48.784744   904 solver.cpp:245]     Train net output #0: loss = 2.45476 (* 1 = 2.45476 loss)
I0605 15:24:48.784754   904 sgd_solver.cpp:106] Iteration 113680, lr = 0.0132518
I0605 15:25:09.274616   904 solver.cpp:229] Iteration 113720, loss = 2.43798
I0605 15:25:09.274785   904 solver.cpp:245]     Train net output #0: loss = 2.44418 (* 1 = 2.44418 loss)
I0605 15:25:09.274811   904 sgd_solver.cpp:106] Iteration 113720, lr = 0.0132424
I0605 15:25:29.858995   904 solver.cpp:229] Iteration 113760, loss = 2.43683
I0605 15:25:29.859047   904 solver.cpp:245]     Train net output #0: loss = 2.63056 (* 1 = 2.63056 loss)
I0605 15:25:29.859056   904 sgd_solver.cpp:106] Iteration 113760, lr = 0.0132329
I0605 15:25:31.662081   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 15:25:50.500222   904 solver.cpp:229] Iteration 113800, loss = 2.42415
I0605 15:25:50.500427   904 solver.cpp:245]     Train net output #0: loss = 2.52196 (* 1 = 2.52196 loss)
I0605 15:25:50.500439   904 sgd_solver.cpp:106] Iteration 113800, lr = 0.0132235
I0605 15:26:11.018365   904 solver.cpp:229] Iteration 113840, loss = 2.43094
I0605 15:26:11.018411   904 solver.cpp:245]     Train net output #0: loss = 2.23403 (* 1 = 2.23403 loss)
I0605 15:26:11.018422   904 sgd_solver.cpp:106] Iteration 113840, lr = 0.0132141
I0605 15:26:31.542069   904 solver.cpp:229] Iteration 113880, loss = 2.42219
I0605 15:26:31.542330   904 solver.cpp:245]     Train net output #0: loss = 2.43787 (* 1 = 2.43787 loss)
I0605 15:26:31.542361   904 sgd_solver.cpp:106] Iteration 113880, lr = 0.0132047
I0605 15:26:52.040379   904 solver.cpp:229] Iteration 113920, loss = 2.41508
I0605 15:26:52.040433   904 solver.cpp:245]     Train net output #0: loss = 2.35079 (* 1 = 2.35079 loss)
I0605 15:26:52.040451   904 sgd_solver.cpp:106] Iteration 113920, lr = 0.0131953
I0605 15:27:12.339581   904 solver.cpp:229] Iteration 113960, loss = 2.46014
I0605 15:27:12.339731   904 solver.cpp:245]     Train net output #0: loss = 2.47931 (* 1 = 2.47931 loss)
I0605 15:27:12.339742   904 sgd_solver.cpp:106] Iteration 113960, lr = 0.0131859
I0605 15:27:31.981473   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_114000.caffemodel
I0605 15:27:32.245630   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_114000.solverstate
I0605 15:27:32.323308   904 solver.cpp:338] Iteration 114000, Testing net (#0)
I0605 15:27:32.323395   904 net.cpp:748] Ignoring source layer loss
I0605 15:27:52.326766   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 15:28:26.658912   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 15:28:40.897316   904 solver.cpp:406]     Test net output #0: accuracy = 0.451581
I0605 15:28:40.897354   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.701579
I0605 15:28:41.212354   904 solver.cpp:229] Iteration 114000, loss = 2.45017
I0605 15:28:41.212420   904 solver.cpp:245]     Train net output #0: loss = 2.62816 (* 1 = 2.62816 loss)
I0605 15:28:41.212433   904 sgd_solver.cpp:106] Iteration 114000, lr = 0.0131765
I0605 15:29:00.397599   904 solver.cpp:229] Iteration 114040, loss = 2.44699
I0605 15:29:00.397750   904 solver.cpp:245]     Train net output #0: loss = 2.48968 (* 1 = 2.48968 loss)
I0605 15:29:00.397761   904 sgd_solver.cpp:106] Iteration 114040, lr = 0.0131671
I0605 15:29:21.272524   904 solver.cpp:229] Iteration 114080, loss = 2.46832
I0605 15:29:21.272568   904 solver.cpp:245]     Train net output #0: loss = 2.51406 (* 1 = 2.51406 loss)
I0605 15:29:21.272577   904 sgd_solver.cpp:106] Iteration 114080, lr = 0.0131576
I0605 15:29:42.294399   904 solver.cpp:229] Iteration 114120, loss = 2.44393
I0605 15:29:42.294595   904 solver.cpp:245]     Train net output #0: loss = 2.57964 (* 1 = 2.57964 loss)
I0605 15:29:42.294621   904 sgd_solver.cpp:106] Iteration 114120, lr = 0.0131482
I0605 15:30:03.120172   904 solver.cpp:229] Iteration 114160, loss = 2.49394
I0605 15:30:03.120219   904 solver.cpp:245]     Train net output #0: loss = 2.61421 (* 1 = 2.61421 loss)
I0605 15:30:03.120229   904 sgd_solver.cpp:106] Iteration 114160, lr = 0.0131388
I0605 15:30:23.906421   904 solver.cpp:229] Iteration 114200, loss = 2.43579
I0605 15:30:23.906628   904 solver.cpp:245]     Train net output #0: loss = 2.41251 (* 1 = 2.41251 loss)
I0605 15:30:23.906652   904 sgd_solver.cpp:106] Iteration 114200, lr = 0.0131294
I0605 15:30:44.687386   904 solver.cpp:229] Iteration 114240, loss = 2.45237
I0605 15:30:44.687434   904 solver.cpp:245]     Train net output #0: loss = 2.5366 (* 1 = 2.5366 loss)
I0605 15:30:44.687448   904 sgd_solver.cpp:106] Iteration 114240, lr = 0.01312
I0605 15:31:05.473904   904 solver.cpp:229] Iteration 114280, loss = 2.43714
I0605 15:31:05.474095   904 solver.cpp:245]     Train net output #0: loss = 2.56073 (* 1 = 2.56073 loss)
I0605 15:31:05.474120   904 sgd_solver.cpp:106] Iteration 114280, lr = 0.0131106
I0605 15:31:26.128084   904 solver.cpp:229] Iteration 114320, loss = 2.42024
I0605 15:31:26.128156   904 solver.cpp:245]     Train net output #0: loss = 2.30809 (* 1 = 2.30809 loss)
I0605 15:31:26.128170   904 sgd_solver.cpp:106] Iteration 114320, lr = 0.0131012
I0605 15:31:46.637758   904 solver.cpp:229] Iteration 114360, loss = 2.41673
I0605 15:31:46.638041   904 solver.cpp:245]     Train net output #0: loss = 2.47986 (* 1 = 2.47986 loss)
I0605 15:31:46.638065   904 sgd_solver.cpp:106] Iteration 114360, lr = 0.0130918
I0605 15:31:49.730114   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 15:32:07.267954   904 solver.cpp:229] Iteration 114400, loss = 2.4351
I0605 15:32:07.268002   904 solver.cpp:245]     Train net output #0: loss = 2.34888 (* 1 = 2.34888 loss)
I0605 15:32:07.268012   904 sgd_solver.cpp:106] Iteration 114400, lr = 0.0130824
I0605 15:32:27.893007   904 solver.cpp:229] Iteration 114440, loss = 2.41044
I0605 15:32:27.893247   904 solver.cpp:245]     Train net output #0: loss = 2.01123 (* 1 = 2.01123 loss)
I0605 15:32:27.893273   904 sgd_solver.cpp:106] Iteration 114440, lr = 0.0130729
I0605 15:32:48.438382   904 solver.cpp:229] Iteration 114480, loss = 2.4531
I0605 15:32:48.438421   904 solver.cpp:245]     Train net output #0: loss = 2.40002 (* 1 = 2.40002 loss)
I0605 15:32:48.438429   904 sgd_solver.cpp:106] Iteration 114480, lr = 0.0130635
I0605 15:33:08.927750   904 solver.cpp:229] Iteration 114520, loss = 2.44856
I0605 15:33:08.927963   904 solver.cpp:245]     Train net output #0: loss = 2.29197 (* 1 = 2.29197 loss)
I0605 15:33:08.927986   904 sgd_solver.cpp:106] Iteration 114520, lr = 0.0130541
I0605 15:33:29.407227   904 solver.cpp:229] Iteration 114560, loss = 2.424
I0605 15:33:29.407277   904 solver.cpp:245]     Train net output #0: loss = 2.36435 (* 1 = 2.36435 loss)
I0605 15:33:29.407285   904 sgd_solver.cpp:106] Iteration 114560, lr = 0.0130447
I0605 15:33:49.891732   904 solver.cpp:229] Iteration 114600, loss = 2.40467
I0605 15:33:49.891968   904 solver.cpp:245]     Train net output #0: loss = 2.41231 (* 1 = 2.41231 loss)
I0605 15:33:49.891991   904 sgd_solver.cpp:106] Iteration 114600, lr = 0.0130353
I0605 15:34:10.369496   904 solver.cpp:229] Iteration 114640, loss = 2.38935
I0605 15:34:10.369556   904 solver.cpp:245]     Train net output #0: loss = 2.39916 (* 1 = 2.39916 loss)
I0605 15:34:10.369568   904 sgd_solver.cpp:106] Iteration 114640, lr = 0.0130259
I0605 15:34:30.869622   904 solver.cpp:229] Iteration 114680, loss = 2.43199
I0605 15:34:30.869830   904 solver.cpp:245]     Train net output #0: loss = 2.41264 (* 1 = 2.41264 loss)
I0605 15:34:30.869864   904 sgd_solver.cpp:106] Iteration 114680, lr = 0.0130165
I0605 15:34:51.212812   904 solver.cpp:229] Iteration 114720, loss = 2.42927
I0605 15:34:51.212872   904 solver.cpp:245]     Train net output #0: loss = 2.65008 (* 1 = 2.65008 loss)
I0605 15:34:51.212882   904 sgd_solver.cpp:106] Iteration 114720, lr = 0.0130071
I0605 15:35:11.488175   904 solver.cpp:229] Iteration 114760, loss = 2.42378
I0605 15:35:11.488397   904 solver.cpp:245]     Train net output #0: loss = 2.29509 (* 1 = 2.29509 loss)
I0605 15:35:11.488418   904 sgd_solver.cpp:106] Iteration 114760, lr = 0.0129976
I0605 15:35:31.970610   904 solver.cpp:229] Iteration 114800, loss = 2.41892
I0605 15:35:31.970679   904 solver.cpp:245]     Train net output #0: loss = 2.37824 (* 1 = 2.37824 loss)
I0605 15:35:31.970690   904 sgd_solver.cpp:106] Iteration 114800, lr = 0.0129882
I0605 15:35:52.450552   904 solver.cpp:229] Iteration 114840, loss = 2.43262
I0605 15:35:52.450778   904 solver.cpp:245]     Train net output #0: loss = 2.30667 (* 1 = 2.30667 loss)
I0605 15:35:52.450799   904 sgd_solver.cpp:106] Iteration 114840, lr = 0.0129788
I0605 15:36:12.914814   904 solver.cpp:229] Iteration 114880, loss = 2.4338
I0605 15:36:12.914855   904 solver.cpp:245]     Train net output #0: loss = 2.40913 (* 1 = 2.40913 loss)
I0605 15:36:12.914861   904 sgd_solver.cpp:106] Iteration 114880, lr = 0.0129694
I0605 15:36:14.449765   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 15:36:33.254498   904 solver.cpp:229] Iteration 114920, loss = 2.42958
I0605 15:36:33.254726   904 solver.cpp:245]     Train net output #0: loss = 2.1457 (* 1 = 2.1457 loss)
I0605 15:36:33.254739   904 sgd_solver.cpp:106] Iteration 114920, lr = 0.01296
I0605 15:36:53.556370   904 solver.cpp:229] Iteration 114960, loss = 2.40266
I0605 15:36:53.556423   904 solver.cpp:245]     Train net output #0: loss = 2.34967 (* 1 = 2.34967 loss)
I0605 15:36:53.556432   904 sgd_solver.cpp:106] Iteration 114960, lr = 0.0129506
I0605 15:37:13.516600   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_115000.caffemodel
I0605 15:37:13.786236   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_115000.solverstate
I0605 15:37:13.868583   904 solver.cpp:338] Iteration 115000, Testing net (#0)
I0605 15:37:13.868676   904 net.cpp:748] Ignoring source layer loss
I0605 15:37:41.275867   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 15:38:15.715756   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 15:38:23.123245   904 solver.cpp:406]     Test net output #0: accuracy = 0.465361
I0605 15:38:23.123288   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.71196
I0605 15:38:23.438983   904 solver.cpp:229] Iteration 115000, loss = 2.41167
I0605 15:38:23.439023   904 solver.cpp:245]     Train net output #0: loss = 2.27202 (* 1 = 2.27202 loss)
I0605 15:38:23.439033   904 sgd_solver.cpp:106] Iteration 115000, lr = 0.0129412
I0605 15:38:42.669513   904 solver.cpp:229] Iteration 115040, loss = 2.45947
I0605 15:38:42.669566   904 solver.cpp:245]     Train net output #0: loss = 2.39228 (* 1 = 2.39228 loss)
I0605 15:38:42.669577   904 sgd_solver.cpp:106] Iteration 115040, lr = 0.0129318
I0605 15:39:04.189293   904 solver.cpp:229] Iteration 115080, loss = 2.44239
I0605 15:39:04.189517   904 solver.cpp:245]     Train net output #0: loss = 2.60173 (* 1 = 2.60173 loss)
I0605 15:39:04.189543   904 sgd_solver.cpp:106] Iteration 115080, lr = 0.0129224
I0605 15:39:25.767364   904 solver.cpp:229] Iteration 115120, loss = 2.4509
I0605 15:39:25.767413   904 solver.cpp:245]     Train net output #0: loss = 2.62767 (* 1 = 2.62767 loss)
I0605 15:39:25.767422   904 sgd_solver.cpp:106] Iteration 115120, lr = 0.0129129
I0605 15:39:47.118160   904 solver.cpp:229] Iteration 115160, loss = 2.47397
I0605 15:39:47.118351   904 solver.cpp:245]     Train net output #0: loss = 2.50589 (* 1 = 2.50589 loss)
I0605 15:39:47.118382   904 sgd_solver.cpp:106] Iteration 115160, lr = 0.0129035
I0605 15:40:08.280182   904 solver.cpp:229] Iteration 115200, loss = 2.45717
I0605 15:40:08.280236   904 solver.cpp:245]     Train net output #0: loss = 2.73855 (* 1 = 2.73855 loss)
I0605 15:40:08.280244   904 sgd_solver.cpp:106] Iteration 115200, lr = 0.0128941
I0605 15:40:29.285398   904 solver.cpp:229] Iteration 115240, loss = 2.43263
I0605 15:40:29.285619   904 solver.cpp:245]     Train net output #0: loss = 2.4184 (* 1 = 2.4184 loss)
I0605 15:40:29.285652   904 sgd_solver.cpp:106] Iteration 115240, lr = 0.0128847
I0605 15:40:50.285925   904 solver.cpp:229] Iteration 115280, loss = 2.45826
I0605 15:40:50.285985   904 solver.cpp:245]     Train net output #0: loss = 2.38181 (* 1 = 2.38181 loss)
I0605 15:40:50.285997   904 sgd_solver.cpp:106] Iteration 115280, lr = 0.0128753
I0605 15:41:11.273772   904 solver.cpp:229] Iteration 115320, loss = 2.44179
I0605 15:41:11.273916   904 solver.cpp:245]     Train net output #0: loss = 2.37292 (* 1 = 2.37292 loss)
I0605 15:41:11.273926   904 sgd_solver.cpp:106] Iteration 115320, lr = 0.0128659
I0605 15:41:32.284302   904 solver.cpp:229] Iteration 115360, loss = 2.44924
I0605 15:41:32.284353   904 solver.cpp:245]     Train net output #0: loss = 2.66965 (* 1 = 2.66965 loss)
I0605 15:41:32.284363   904 sgd_solver.cpp:106] Iteration 115360, lr = 0.0128565
I0605 15:41:53.257611   904 solver.cpp:229] Iteration 115400, loss = 2.46838
I0605 15:41:53.257832   904 solver.cpp:245]     Train net output #0: loss = 2.76205 (* 1 = 2.76205 loss)
I0605 15:41:53.257848   904 sgd_solver.cpp:106] Iteration 115400, lr = 0.0128471
I0605 15:42:08.489872   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 15:42:14.203474   904 solver.cpp:229] Iteration 115440, loss = 2.44215
I0605 15:42:14.203517   904 solver.cpp:245]     Train net output #0: loss = 2.48334 (* 1 = 2.48334 loss)
I0605 15:42:14.203524   904 sgd_solver.cpp:106] Iteration 115440, lr = 0.0128376
I0605 15:42:35.027194   904 solver.cpp:229] Iteration 115480, loss = 2.41344
I0605 15:42:35.027443   904 solver.cpp:245]     Train net output #0: loss = 2.54352 (* 1 = 2.54352 loss)
I0605 15:42:35.027456   904 sgd_solver.cpp:106] Iteration 115480, lr = 0.0128282
I0605 15:42:55.698074   904 solver.cpp:229] Iteration 115520, loss = 2.42573
I0605 15:42:55.698125   904 solver.cpp:245]     Train net output #0: loss = 2.50039 (* 1 = 2.50039 loss)
I0605 15:42:55.698134   904 sgd_solver.cpp:106] Iteration 115520, lr = 0.0128188
I0605 15:43:16.365213   904 solver.cpp:229] Iteration 115560, loss = 2.43933
I0605 15:43:16.365375   904 solver.cpp:245]     Train net output #0: loss = 2.72056 (* 1 = 2.72056 loss)
I0605 15:43:16.365386   904 sgd_solver.cpp:106] Iteration 115560, lr = 0.0128094
I0605 15:43:37.021236   904 solver.cpp:229] Iteration 115600, loss = 2.43271
I0605 15:43:37.021287   904 solver.cpp:245]     Train net output #0: loss = 2.51171 (* 1 = 2.51171 loss)
I0605 15:43:37.021296   904 sgd_solver.cpp:106] Iteration 115600, lr = 0.0128
I0605 15:43:57.640563   904 solver.cpp:229] Iteration 115640, loss = 2.41008
I0605 15:43:57.640769   904 solver.cpp:245]     Train net output #0: loss = 2.28747 (* 1 = 2.28747 loss)
I0605 15:43:57.640802   904 sgd_solver.cpp:106] Iteration 115640, lr = 0.0127906
I0605 15:44:18.291275   904 solver.cpp:229] Iteration 115680, loss = 2.42192
I0605 15:44:18.291326   904 solver.cpp:245]     Train net output #0: loss = 2.40849 (* 1 = 2.40849 loss)
I0605 15:44:18.291335   904 sgd_solver.cpp:106] Iteration 115680, lr = 0.0127812
I0605 15:44:38.923784   904 solver.cpp:229] Iteration 115720, loss = 2.42697
I0605 15:44:38.923923   904 solver.cpp:245]     Train net output #0: loss = 2.46738 (* 1 = 2.46738 loss)
I0605 15:44:38.923933   904 sgd_solver.cpp:106] Iteration 115720, lr = 0.0127718
I0605 15:44:59.422677   904 solver.cpp:229] Iteration 115760, loss = 2.43246
I0605 15:44:59.422727   904 solver.cpp:245]     Train net output #0: loss = 2.43989 (* 1 = 2.43989 loss)
I0605 15:44:59.422735   904 sgd_solver.cpp:106] Iteration 115760, lr = 0.0127624
I0605 15:45:19.922498   904 solver.cpp:229] Iteration 115800, loss = 2.42686
I0605 15:45:19.922633   904 solver.cpp:245]     Train net output #0: loss = 2.3441 (* 1 = 2.3441 loss)
I0605 15:45:19.922655   904 sgd_solver.cpp:106] Iteration 115800, lr = 0.0127529
I0605 15:45:40.418711   904 solver.cpp:229] Iteration 115840, loss = 2.45381
I0605 15:45:40.418762   904 solver.cpp:245]     Train net output #0: loss = 2.39511 (* 1 = 2.39511 loss)
I0605 15:45:40.418771   904 sgd_solver.cpp:106] Iteration 115840, lr = 0.0127435
I0605 15:46:00.903941   904 solver.cpp:229] Iteration 115880, loss = 2.44863
I0605 15:46:00.904155   904 solver.cpp:245]     Train net output #0: loss = 2.26802 (* 1 = 2.26802 loss)
I0605 15:46:00.904188   904 sgd_solver.cpp:106] Iteration 115880, lr = 0.0127341
I0605 15:46:21.410696   904 solver.cpp:229] Iteration 115920, loss = 2.41375
I0605 15:46:21.410759   904 solver.cpp:245]     Train net output #0: loss = 2.45448 (* 1 = 2.45448 loss)
I0605 15:46:21.410769   904 sgd_solver.cpp:106] Iteration 115920, lr = 0.0127247
I0605 15:46:41.920490   904 solver.cpp:229] Iteration 115960, loss = 2.41875
I0605 15:46:41.920691   904 solver.cpp:245]     Train net output #0: loss = 2.70134 (* 1 = 2.70134 loss)
I0605 15:46:41.920718   904 sgd_solver.cpp:106] Iteration 115960, lr = 0.0127153
I0605 15:46:42.946107   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 15:47:01.906695   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_116000.caffemodel
I0605 15:47:02.170090   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_116000.solverstate
I0605 15:47:02.244542   904 solver.cpp:338] Iteration 116000, Testing net (#0)
I0605 15:47:02.244624   904 net.cpp:748] Ignoring source layer loss
I0605 15:47:32.073417   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 15:48:05.597518   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 15:48:07.643944   904 solver.cpp:406]     Test net output #0: accuracy = 0.458821
I0605 15:48:07.643987   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.708579
I0605 15:48:07.956734   904 solver.cpp:229] Iteration 116000, loss = 2.42537
I0605 15:48:07.956771   904 solver.cpp:245]     Train net output #0: loss = 2.55781 (* 1 = 2.55781 loss)
I0605 15:48:07.956781   904 sgd_solver.cpp:106] Iteration 116000, lr = 0.0127059
I0605 15:48:27.128279   904 solver.cpp:229] Iteration 116040, loss = 2.41466
I0605 15:48:27.128332   904 solver.cpp:245]     Train net output #0: loss = 2.38247 (* 1 = 2.38247 loss)
I0605 15:48:27.128342   904 sgd_solver.cpp:106] Iteration 116040, lr = 0.0126965
I0605 15:48:48.456403   904 solver.cpp:229] Iteration 116080, loss = 2.42055
I0605 15:48:48.456545   904 solver.cpp:245]     Train net output #0: loss = 2.60882 (* 1 = 2.60882 loss)
I0605 15:48:48.456558   904 sgd_solver.cpp:106] Iteration 116080, lr = 0.0126871
I0605 15:49:09.946480   904 solver.cpp:229] Iteration 116120, loss = 2.38889
I0605 15:49:09.946532   904 solver.cpp:245]     Train net output #0: loss = 2.58849 (* 1 = 2.58849 loss)
I0605 15:49:09.946553   904 sgd_solver.cpp:106] Iteration 116120, lr = 0.0126776
I0605 15:49:30.897967   904 solver.cpp:229] Iteration 116160, loss = 2.45865
I0605 15:49:30.898188   904 solver.cpp:245]     Train net output #0: loss = 2.62603 (* 1 = 2.62603 loss)
I0605 15:49:30.898214   904 sgd_solver.cpp:106] Iteration 116160, lr = 0.0126682
I0605 15:49:51.799193   904 solver.cpp:229] Iteration 116200, loss = 2.38194
I0605 15:49:51.799247   904 solver.cpp:245]     Train net output #0: loss = 2.61667 (* 1 = 2.61667 loss)
I0605 15:49:51.799257   904 sgd_solver.cpp:106] Iteration 116200, lr = 0.0126588
I0605 15:50:12.710597   904 solver.cpp:229] Iteration 116240, loss = 2.42751
I0605 15:50:12.710769   904 solver.cpp:245]     Train net output #0: loss = 2.47089 (* 1 = 2.47089 loss)
I0605 15:50:12.710793   904 sgd_solver.cpp:106] Iteration 116240, lr = 0.0126494
I0605 15:50:33.621036   904 solver.cpp:229] Iteration 116280, loss = 2.42369
I0605 15:50:33.621093   904 solver.cpp:245]     Train net output #0: loss = 2.43023 (* 1 = 2.43023 loss)
I0605 15:50:33.621103   904 sgd_solver.cpp:106] Iteration 116280, lr = 0.01264
I0605 15:50:54.455466   904 solver.cpp:229] Iteration 116320, loss = 2.41438
I0605 15:50:54.455672   904 solver.cpp:245]     Train net output #0: loss = 2.35393 (* 1 = 2.35393 loss)
I0605 15:50:54.455690   904 sgd_solver.cpp:106] Iteration 116320, lr = 0.0126306
I0605 15:51:15.161612   904 solver.cpp:229] Iteration 116360, loss = 2.44163
I0605 15:51:15.161667   904 solver.cpp:245]     Train net output #0: loss = 2.57594 (* 1 = 2.57594 loss)
I0605 15:51:15.161679   904 sgd_solver.cpp:106] Iteration 116360, lr = 0.0126212
I0605 15:51:35.757405   904 solver.cpp:229] Iteration 116400, loss = 2.39884
I0605 15:51:35.757616   904 solver.cpp:245]     Train net output #0: loss = 2.17307 (* 1 = 2.17307 loss)
I0605 15:51:35.757639   904 sgd_solver.cpp:106] Iteration 116400, lr = 0.0126118
I0605 15:51:56.387379   904 solver.cpp:229] Iteration 116440, loss = 2.44344
I0605 15:51:56.387449   904 solver.cpp:245]     Train net output #0: loss = 2.53242 (* 1 = 2.53242 loss)
I0605 15:51:56.387459   904 sgd_solver.cpp:106] Iteration 116440, lr = 0.0126024
I0605 15:52:16.989141   904 solver.cpp:229] Iteration 116480, loss = 2.42535
I0605 15:52:16.989259   904 solver.cpp:245]     Train net output #0: loss = 2.28866 (* 1 = 2.28866 loss)
I0605 15:52:16.989266   904 sgd_solver.cpp:106] Iteration 116480, lr = 0.0125929
I0605 15:52:37.599544   904 solver.cpp:229] Iteration 116520, loss = 2.46074
I0605 15:52:37.599593   904 solver.cpp:245]     Train net output #0: loss = 2.45586 (* 1 = 2.45586 loss)
I0605 15:52:37.599602   904 sgd_solver.cpp:106] Iteration 116520, lr = 0.0125835
I0605 15:52:39.645144   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 15:52:58.027112   904 solver.cpp:229] Iteration 116560, loss = 2.43991
I0605 15:52:58.027350   904 solver.cpp:245]     Train net output #0: loss = 2.55033 (* 1 = 2.55033 loss)
I0605 15:52:58.027374   904 sgd_solver.cpp:106] Iteration 116560, lr = 0.0125741
I0605 15:53:18.437479   904 solver.cpp:229] Iteration 116600, loss = 2.42243
I0605 15:53:18.437515   904 solver.cpp:245]     Train net output #0: loss = 2.41087 (* 1 = 2.41087 loss)
I0605 15:53:18.437523   904 sgd_solver.cpp:106] Iteration 116600, lr = 0.0125647
I0605 15:53:38.870411   904 solver.cpp:229] Iteration 116640, loss = 2.40605
I0605 15:53:38.870679   904 solver.cpp:245]     Train net output #0: loss = 2.41827 (* 1 = 2.41827 loss)
I0605 15:53:38.870704   904 sgd_solver.cpp:106] Iteration 116640, lr = 0.0125553
I0605 15:53:59.291419   904 solver.cpp:229] Iteration 116680, loss = 2.43429
I0605 15:53:59.291471   904 solver.cpp:245]     Train net output #0: loss = 2.51085 (* 1 = 2.51085 loss)
I0605 15:53:59.291481   904 sgd_solver.cpp:106] Iteration 116680, lr = 0.0125459
I0605 15:54:19.738029   904 solver.cpp:229] Iteration 116720, loss = 2.42199
I0605 15:54:19.738240   904 solver.cpp:245]     Train net output #0: loss = 2.22038 (* 1 = 2.22038 loss)
I0605 15:54:19.738273   904 sgd_solver.cpp:106] Iteration 116720, lr = 0.0125365
I0605 15:54:40.167915   904 solver.cpp:229] Iteration 116760, loss = 2.42925
I0605 15:54:40.167969   904 solver.cpp:245]     Train net output #0: loss = 2.51954 (* 1 = 2.51954 loss)
I0605 15:54:40.167982   904 sgd_solver.cpp:106] Iteration 116760, lr = 0.0125271
I0605 15:55:00.609776   904 solver.cpp:229] Iteration 116800, loss = 2.44194
I0605 15:55:00.609920   904 solver.cpp:245]     Train net output #0: loss = 2.41713 (* 1 = 2.41713 loss)
I0605 15:55:00.609932   904 sgd_solver.cpp:106] Iteration 116800, lr = 0.0125176
I0605 15:55:20.869946   904 solver.cpp:229] Iteration 116840, loss = 2.39319
I0605 15:55:20.869997   904 solver.cpp:245]     Train net output #0: loss = 2.5396 (* 1 = 2.5396 loss)
I0605 15:55:20.870009   904 sgd_solver.cpp:106] Iteration 116840, lr = 0.0125082
I0605 15:55:41.091087   904 solver.cpp:229] Iteration 116880, loss = 2.42688
I0605 15:55:41.091295   904 solver.cpp:245]     Train net output #0: loss = 2.47205 (* 1 = 2.47205 loss)
I0605 15:55:41.091318   904 sgd_solver.cpp:106] Iteration 116880, lr = 0.0124988
I0605 15:56:01.316712   904 solver.cpp:229] Iteration 116920, loss = 2.40563
I0605 15:56:01.316809   904 solver.cpp:245]     Train net output #0: loss = 2.50802 (* 1 = 2.50802 loss)
I0605 15:56:01.316826   904 sgd_solver.cpp:106] Iteration 116920, lr = 0.0124894
I0605 15:56:21.538589   904 solver.cpp:229] Iteration 116960, loss = 2.44715
I0605 15:56:21.538833   904 solver.cpp:245]     Train net output #0: loss = 2.47518 (* 1 = 2.47518 loss)
I0605 15:56:21.538866   904 sgd_solver.cpp:106] Iteration 116960, lr = 0.01248
I0605 15:56:41.238469   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_117000.caffemodel
I0605 15:56:41.502535   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_117000.solverstate
I0605 15:56:41.583359   904 solver.cpp:338] Iteration 117000, Testing net (#0)
I0605 15:56:41.583439   904 net.cpp:748] Ignoring source layer loss
I0605 15:56:45.141788   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 15:57:20.992162   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 15:57:52.808259   904 solver.cpp:406]     Test net output #0: accuracy = 0.460561
I0605 15:57:52.808471   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.70566
I0605 15:57:53.125661   904 solver.cpp:229] Iteration 117000, loss = 2.41184
I0605 15:57:53.125705   904 solver.cpp:245]     Train net output #0: loss = 2.18975 (* 1 = 2.18975 loss)
I0605 15:57:53.125715   904 sgd_solver.cpp:106] Iteration 117000, lr = 0.0124706
I0605 15:58:12.337527   904 solver.cpp:229] Iteration 117040, loss = 2.39767
I0605 15:58:12.337579   904 solver.cpp:245]     Train net output #0: loss = 2.39814 (* 1 = 2.39814 loss)
I0605 15:58:12.337587   904 sgd_solver.cpp:106] Iteration 117040, lr = 0.0124612
I0605 15:58:18.894923   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 15:58:33.741113   904 solver.cpp:229] Iteration 117080, loss = 2.41994
I0605 15:58:33.741376   904 solver.cpp:245]     Train net output #0: loss = 2.35507 (* 1 = 2.35507 loss)
I0605 15:58:33.741403   904 sgd_solver.cpp:106] Iteration 117080, lr = 0.0124518
I0605 15:58:55.267410   904 solver.cpp:229] Iteration 117120, loss = 2.40063
I0605 15:58:55.267462   904 solver.cpp:245]     Train net output #0: loss = 2.43705 (* 1 = 2.43705 loss)
I0605 15:58:55.267472   904 sgd_solver.cpp:106] Iteration 117120, lr = 0.0124424
I0605 15:59:16.434789   904 solver.cpp:229] Iteration 117160, loss = 2.39527
I0605 15:59:16.435034   904 solver.cpp:245]     Train net output #0: loss = 2.37322 (* 1 = 2.37322 loss)
I0605 15:59:16.435061   904 sgd_solver.cpp:106] Iteration 117160, lr = 0.0124329
I0605 15:59:37.319226   904 solver.cpp:229] Iteration 117200, loss = 2.41528
I0605 15:59:37.319277   904 solver.cpp:245]     Train net output #0: loss = 2.63926 (* 1 = 2.63926 loss)
I0605 15:59:37.319288   904 sgd_solver.cpp:106] Iteration 117200, lr = 0.0124235
I0605 15:59:58.291121   904 solver.cpp:229] Iteration 117240, loss = 2.38876
I0605 15:59:58.291324   904 solver.cpp:245]     Train net output #0: loss = 2.3226 (* 1 = 2.3226 loss)
I0605 15:59:58.291352   904 sgd_solver.cpp:106] Iteration 117240, lr = 0.0124141
I0605 16:00:19.287235   904 solver.cpp:229] Iteration 117280, loss = 2.44648
I0605 16:00:19.287282   904 solver.cpp:245]     Train net output #0: loss = 2.19699 (* 1 = 2.19699 loss)
I0605 16:00:19.287292   904 sgd_solver.cpp:106] Iteration 117280, lr = 0.0124047
I0605 16:00:40.209722   904 solver.cpp:229] Iteration 117320, loss = 2.37
I0605 16:00:40.209908   904 solver.cpp:245]     Train net output #0: loss = 2.21144 (* 1 = 2.21144 loss)
I0605 16:00:40.209940   904 sgd_solver.cpp:106] Iteration 117320, lr = 0.0123953
I0605 16:01:00.995069   904 solver.cpp:229] Iteration 117360, loss = 2.42381
I0605 16:01:00.995121   904 solver.cpp:245]     Train net output #0: loss = 2.32943 (* 1 = 2.32943 loss)
I0605 16:01:00.995133   904 sgd_solver.cpp:106] Iteration 117360, lr = 0.0123859
I0605 16:01:21.674717   904 solver.cpp:229] Iteration 117400, loss = 2.43913
I0605 16:01:21.674926   904 solver.cpp:245]     Train net output #0: loss = 2.36068 (* 1 = 2.36068 loss)
I0605 16:01:21.674953   904 sgd_solver.cpp:106] Iteration 117400, lr = 0.0123765
I0605 16:01:42.450429   904 solver.cpp:229] Iteration 117440, loss = 2.37248
I0605 16:01:42.450485   904 solver.cpp:245]     Train net output #0: loss = 2.5966 (* 1 = 2.5966 loss)
I0605 16:01:42.450500   904 sgd_solver.cpp:106] Iteration 117440, lr = 0.0123671
I0605 16:02:03.072767   904 solver.cpp:229] Iteration 117480, loss = 2.40139
I0605 16:02:03.073016   904 solver.cpp:245]     Train net output #0: loss = 2.45911 (* 1 = 2.45911 loss)
I0605 16:02:03.073043   904 sgd_solver.cpp:106] Iteration 117480, lr = 0.0123576
I0605 16:02:23.567441   904 solver.cpp:229] Iteration 117520, loss = 2.42096
I0605 16:02:23.567489   904 solver.cpp:245]     Train net output #0: loss = 2.43936 (* 1 = 2.43936 loss)
I0605 16:02:23.567502   904 sgd_solver.cpp:106] Iteration 117520, lr = 0.0123482
I0605 16:02:44.161380   904 solver.cpp:229] Iteration 117560, loss = 2.43538
I0605 16:02:44.161568   904 solver.cpp:245]     Train net output #0: loss = 2.46443 (* 1 = 2.46443 loss)
I0605 16:02:44.161593   904 sgd_solver.cpp:106] Iteration 117560, lr = 0.0123388
I0605 16:02:48.039844   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 16:03:04.840548   904 solver.cpp:229] Iteration 117600, loss = 2.4037
I0605 16:03:04.840603   904 solver.cpp:245]     Train net output #0: loss = 2.55717 (* 1 = 2.55717 loss)
I0605 16:03:04.840615   904 sgd_solver.cpp:106] Iteration 117600, lr = 0.0123294
I0605 16:03:25.361407   904 solver.cpp:229] Iteration 117640, loss = 2.42449
I0605 16:03:25.361696   904 solver.cpp:245]     Train net output #0: loss = 2.79032 (* 1 = 2.79032 loss)
I0605 16:03:25.361717   904 sgd_solver.cpp:106] Iteration 117640, lr = 0.01232
I0605 16:03:45.875591   904 solver.cpp:229] Iteration 117680, loss = 2.43081
I0605 16:03:45.875634   904 solver.cpp:245]     Train net output #0: loss = 2.64749 (* 1 = 2.64749 loss)
I0605 16:03:45.875644   904 sgd_solver.cpp:106] Iteration 117680, lr = 0.0123106
I0605 16:04:06.423748   904 solver.cpp:229] Iteration 117720, loss = 2.40218
I0605 16:04:06.423967   904 solver.cpp:245]     Train net output #0: loss = 2.31833 (* 1 = 2.31833 loss)
I0605 16:04:06.423995   904 sgd_solver.cpp:106] Iteration 117720, lr = 0.0123012
I0605 16:04:26.973558   904 solver.cpp:229] Iteration 117760, loss = 2.41878
I0605 16:04:26.973610   904 solver.cpp:245]     Train net output #0: loss = 2.78278 (* 1 = 2.78278 loss)
I0605 16:04:26.973708   904 sgd_solver.cpp:106] Iteration 117760, lr = 0.0122918
I0605 16:04:47.494349   904 solver.cpp:229] Iteration 117800, loss = 2.4178
I0605 16:04:47.494534   904 solver.cpp:245]     Train net output #0: loss = 2.52858 (* 1 = 2.52858 loss)
I0605 16:04:47.494559   904 sgd_solver.cpp:106] Iteration 117800, lr = 0.0122824
I0605 16:05:07.992096   904 solver.cpp:229] Iteration 117840, loss = 2.39088
I0605 16:05:07.992153   904 solver.cpp:245]     Train net output #0: loss = 2.40795 (* 1 = 2.40795 loss)
I0605 16:05:07.992164   904 sgd_solver.cpp:106] Iteration 117840, lr = 0.0122729
I0605 16:05:28.521278   904 solver.cpp:229] Iteration 117880, loss = 2.42812
I0605 16:05:28.521471   904 solver.cpp:245]     Train net output #0: loss = 2.16532 (* 1 = 2.16532 loss)
I0605 16:05:28.521497   904 sgd_solver.cpp:106] Iteration 117880, lr = 0.0122635
I0605 16:05:49.049072   904 solver.cpp:229] Iteration 117920, loss = 2.39874
I0605 16:05:49.049132   904 solver.cpp:245]     Train net output #0: loss = 2.27501 (* 1 = 2.27501 loss)
I0605 16:05:49.049144   904 sgd_solver.cpp:106] Iteration 117920, lr = 0.0122541
I0605 16:06:09.553712   904 solver.cpp:229] Iteration 117960, loss = 2.41571
I0605 16:06:09.553886   904 solver.cpp:245]     Train net output #0: loss = 2.36103 (* 1 = 2.36103 loss)
I0605 16:06:09.553901   904 sgd_solver.cpp:106] Iteration 117960, lr = 0.0122447
I0605 16:06:29.564561   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_118000.caffemodel
I0605 16:06:29.834344   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_118000.solverstate
I0605 16:06:29.935758   904 solver.cpp:338] Iteration 118000, Testing net (#0)
I0605 16:06:29.935853   904 net.cpp:748] Ignoring source layer loss
I0605 16:06:36.565083   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 16:07:11.763911   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 16:07:41.398903   904 solver.cpp:406]     Test net output #0: accuracy = 0.458841
I0605 16:07:41.398948   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.708178
I0605 16:07:41.715029   904 solver.cpp:229] Iteration 118000, loss = 2.39982
I0605 16:07:41.715080   904 solver.cpp:245]     Train net output #0: loss = 2.04754 (* 1 = 2.04754 loss)
I0605 16:07:41.715091   904 sgd_solver.cpp:106] Iteration 118000, lr = 0.0122353
I0605 16:08:00.984968   904 solver.cpp:229] Iteration 118040, loss = 2.42117
I0605 16:08:00.985209   904 solver.cpp:245]     Train net output #0: loss = 2.5197 (* 1 = 2.5197 loss)
I0605 16:08:00.985229   904 sgd_solver.cpp:106] Iteration 118040, lr = 0.0122259
I0605 16:08:22.476372   904 solver.cpp:229] Iteration 118080, loss = 2.44586
I0605 16:08:22.476464   904 solver.cpp:245]     Train net output #0: loss = 2.52246 (* 1 = 2.52246 loss)
I0605 16:08:22.476474   904 sgd_solver.cpp:106] Iteration 118080, lr = 0.0122165
I0605 16:08:27.868221   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 16:08:44.013825   904 solver.cpp:229] Iteration 118120, loss = 2.42438
I0605 16:08:44.014073   904 solver.cpp:245]     Train net output #0: loss = 2.29795 (* 1 = 2.29795 loss)
I0605 16:08:44.014097   904 sgd_solver.cpp:106] Iteration 118120, lr = 0.0122071
I0605 16:09:05.164196   904 solver.cpp:229] Iteration 118160, loss = 2.39845
I0605 16:09:05.164249   904 solver.cpp:245]     Train net output #0: loss = 2.56238 (* 1 = 2.56238 loss)
I0605 16:09:05.164258   904 sgd_solver.cpp:106] Iteration 118160, lr = 0.0121976
I0605 16:09:26.185128   904 solver.cpp:229] Iteration 118200, loss = 2.44415
I0605 16:09:26.185376   904 solver.cpp:245]     Train net output #0: loss = 2.44569 (* 1 = 2.44569 loss)
I0605 16:09:26.185402   904 sgd_solver.cpp:106] Iteration 118200, lr = 0.0121882
I0605 16:09:47.173254   904 solver.cpp:229] Iteration 118240, loss = 2.41548
I0605 16:09:47.173301   904 solver.cpp:245]     Train net output #0: loss = 2.44324 (* 1 = 2.44324 loss)
I0605 16:09:47.173312   904 sgd_solver.cpp:106] Iteration 118240, lr = 0.0121788
I0605 16:10:08.155397   904 solver.cpp:229] Iteration 118280, loss = 2.4162
I0605 16:10:08.155572   904 solver.cpp:245]     Train net output #0: loss = 2.52589 (* 1 = 2.52589 loss)
I0605 16:10:08.155586   904 sgd_solver.cpp:106] Iteration 118280, lr = 0.0121694
I0605 16:10:29.158572   904 solver.cpp:229] Iteration 118320, loss = 2.41018
I0605 16:10:29.158620   904 solver.cpp:245]     Train net output #0: loss = 2.49068 (* 1 = 2.49068 loss)
I0605 16:10:29.158632   904 sgd_solver.cpp:106] Iteration 118320, lr = 0.01216
I0605 16:10:50.126904   904 solver.cpp:229] Iteration 118360, loss = 2.44944
I0605 16:10:50.127151   904 solver.cpp:245]     Train net output #0: loss = 2.42609 (* 1 = 2.42609 loss)
I0605 16:10:50.127177   904 sgd_solver.cpp:106] Iteration 118360, lr = 0.0121506
I0605 16:11:11.044558   904 solver.cpp:229] Iteration 118400, loss = 2.41692
I0605 16:11:11.044601   904 solver.cpp:245]     Train net output #0: loss = 2.1713 (* 1 = 2.1713 loss)
I0605 16:11:11.044610   904 sgd_solver.cpp:106] Iteration 118400, lr = 0.0121412
I0605 16:11:31.860342   904 solver.cpp:229] Iteration 118440, loss = 2.39411
I0605 16:11:31.860584   904 solver.cpp:245]     Train net output #0: loss = 2.42515 (* 1 = 2.42515 loss)
I0605 16:11:31.860607   904 sgd_solver.cpp:106] Iteration 118440, lr = 0.0121318
I0605 16:11:52.727959   904 solver.cpp:229] Iteration 118480, loss = 2.38926
I0605 16:11:52.728003   904 solver.cpp:245]     Train net output #0: loss = 2.29388 (* 1 = 2.29388 loss)
I0605 16:11:52.728011   904 sgd_solver.cpp:106] Iteration 118480, lr = 0.0121224
I0605 16:12:13.475914   904 solver.cpp:229] Iteration 118520, loss = 2.39054
I0605 16:12:13.476112   904 solver.cpp:245]     Train net output #0: loss = 2.39956 (* 1 = 2.39956 loss)
I0605 16:12:13.476138   904 sgd_solver.cpp:106] Iteration 118520, lr = 0.0121129
I0605 16:12:34.180181   904 solver.cpp:229] Iteration 118560, loss = 2.39298
I0605 16:12:34.180230   904 solver.cpp:245]     Train net output #0: loss = 2.34031 (* 1 = 2.34031 loss)
I0605 16:12:34.180240   904 sgd_solver.cpp:106] Iteration 118560, lr = 0.0121035
I0605 16:12:54.841648   904 solver.cpp:229] Iteration 118600, loss = 2.43516
I0605 16:12:54.841897   904 solver.cpp:245]     Train net output #0: loss = 2.5554 (* 1 = 2.5554 loss)
I0605 16:12:54.841922   904 sgd_solver.cpp:106] Iteration 118600, lr = 0.0120941
I0605 16:12:56.394593   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 16:13:15.524062   904 solver.cpp:229] Iteration 118640, loss = 2.38047
I0605 16:13:15.524112   904 solver.cpp:245]     Train net output #0: loss = 2.37434 (* 1 = 2.37434 loss)
I0605 16:13:15.524121   904 sgd_solver.cpp:106] Iteration 118640, lr = 0.0120847
I0605 16:13:36.222512   904 solver.cpp:229] Iteration 118680, loss = 2.38597
I0605 16:13:36.222726   904 solver.cpp:245]     Train net output #0: loss = 2.49341 (* 1 = 2.49341 loss)
I0605 16:13:36.222753   904 sgd_solver.cpp:106] Iteration 118680, lr = 0.0120753
I0605 16:13:56.913369   904 solver.cpp:229] Iteration 118720, loss = 2.40366
I0605 16:13:56.913414   904 solver.cpp:245]     Train net output #0: loss = 2.24447 (* 1 = 2.24447 loss)
I0605 16:13:56.913424   904 sgd_solver.cpp:106] Iteration 118720, lr = 0.0120659
I0605 16:14:17.432499   904 solver.cpp:229] Iteration 118760, loss = 2.41176
I0605 16:14:17.432757   904 solver.cpp:245]     Train net output #0: loss = 2.55813 (* 1 = 2.55813 loss)
I0605 16:14:17.432770   904 sgd_solver.cpp:106] Iteration 118760, lr = 0.0120565
I0605 16:14:37.929919   904 solver.cpp:229] Iteration 118800, loss = 2.39536
I0605 16:14:37.929956   904 solver.cpp:245]     Train net output #0: loss = 2.54 (* 1 = 2.54 loss)
I0605 16:14:37.929965   904 sgd_solver.cpp:106] Iteration 118800, lr = 0.0120471
I0605 16:14:58.583170   904 solver.cpp:229] Iteration 118840, loss = 2.41432
I0605 16:14:58.583376   904 solver.cpp:245]     Train net output #0: loss = 2.40281 (* 1 = 2.40281 loss)
I0605 16:14:58.583403   904 sgd_solver.cpp:106] Iteration 118840, lr = 0.0120376
I0605 16:15:19.170334   904 solver.cpp:229] Iteration 118880, loss = 2.4087
I0605 16:15:19.170392   904 solver.cpp:245]     Train net output #0: loss = 2.43041 (* 1 = 2.43041 loss)
I0605 16:15:19.170404   904 sgd_solver.cpp:106] Iteration 118880, lr = 0.0120282
I0605 16:15:39.681568   904 solver.cpp:229] Iteration 118920, loss = 2.39965
I0605 16:15:39.681810   904 solver.cpp:245]     Train net output #0: loss = 2.46459 (* 1 = 2.46459 loss)
I0605 16:15:39.681836   904 sgd_solver.cpp:106] Iteration 118920, lr = 0.0120188
I0605 16:16:00.185684   904 solver.cpp:229] Iteration 118960, loss = 2.42084
I0605 16:16:00.185750   904 solver.cpp:245]     Train net output #0: loss = 2.50809 (* 1 = 2.50809 loss)
I0605 16:16:00.185762   904 sgd_solver.cpp:106] Iteration 118960, lr = 0.0120094
I0605 16:16:20.175106   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_119000.caffemodel
I0605 16:16:20.441826   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_119000.solverstate
I0605 16:16:20.521183   904 solver.cpp:338] Iteration 119000, Testing net (#0)
I0605 16:16:20.521261   904 net.cpp:748] Ignoring source layer loss
I0605 16:16:28.930156   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 16:17:03.445580   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 16:17:31.852401   904 solver.cpp:406]     Test net output #0: accuracy = 0.467241
I0605 16:17:31.852455   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.714819
I0605 16:17:32.170312   904 solver.cpp:229] Iteration 119000, loss = 2.42396
I0605 16:17:32.170358   904 solver.cpp:245]     Train net output #0: loss = 2.62888 (* 1 = 2.62888 loss)
I0605 16:17:32.170368   904 sgd_solver.cpp:106] Iteration 119000, lr = 0.012
I0605 16:17:51.405333   904 solver.cpp:229] Iteration 119040, loss = 2.41167
I0605 16:17:51.405573   904 solver.cpp:245]     Train net output #0: loss = 2.36918 (* 1 = 2.36918 loss)
I0605 16:17:51.405607   904 sgd_solver.cpp:106] Iteration 119040, lr = 0.0119906
I0605 16:18:12.670416   904 solver.cpp:229] Iteration 119080, loss = 2.41793
I0605 16:18:12.670487   904 solver.cpp:245]     Train net output #0: loss = 2.53197 (* 1 = 2.53197 loss)
I0605 16:18:12.670500   904 sgd_solver.cpp:106] Iteration 119080, lr = 0.0119812
I0605 16:18:33.665516   904 solver.cpp:229] Iteration 119120, loss = 2.37051
I0605 16:18:33.665781   904 solver.cpp:245]     Train net output #0: loss = 2.62565 (* 1 = 2.62565 loss)
I0605 16:18:33.665807   904 sgd_solver.cpp:106] Iteration 119120, lr = 0.0119718
I0605 16:18:39.335469   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 16:18:54.317780   904 solver.cpp:229] Iteration 119160, loss = 2.43008
I0605 16:18:54.317883   904 solver.cpp:245]     Train net output #0: loss = 2.33946 (* 1 = 2.33946 loss)
I0605 16:18:54.317900   904 sgd_solver.cpp:106] Iteration 119160, lr = 0.0119624
I0605 16:19:14.793223   904 solver.cpp:229] Iteration 119200, loss = 2.40467
I0605 16:19:14.793483   904 solver.cpp:245]     Train net output #0: loss = 2.34432 (* 1 = 2.34432 loss)
I0605 16:19:14.793510   904 sgd_solver.cpp:106] Iteration 119200, lr = 0.0119529
I0605 16:19:35.286181   904 solver.cpp:229] Iteration 119240, loss = 2.42638
I0605 16:19:35.286237   904 solver.cpp:245]     Train net output #0: loss = 2.59755 (* 1 = 2.59755 loss)
I0605 16:19:35.286247   904 sgd_solver.cpp:106] Iteration 119240, lr = 0.0119435
I0605 16:19:55.786913   904 solver.cpp:229] Iteration 119280, loss = 2.41079
I0605 16:19:55.787216   904 solver.cpp:245]     Train net output #0: loss = 2.56843 (* 1 = 2.56843 loss)
I0605 16:19:55.787238   904 sgd_solver.cpp:106] Iteration 119280, lr = 0.0119341
I0605 16:20:16.101985   904 solver.cpp:229] Iteration 119320, loss = 2.39298
I0605 16:20:16.102032   904 solver.cpp:245]     Train net output #0: loss = 2.27771 (* 1 = 2.27771 loss)
I0605 16:20:16.102041   904 sgd_solver.cpp:106] Iteration 119320, lr = 0.0119247
I0605 16:20:36.552067   904 solver.cpp:229] Iteration 119360, loss = 2.37177
I0605 16:20:36.552269   904 solver.cpp:245]     Train net output #0: loss = 2.42212 (* 1 = 2.42212 loss)
I0605 16:20:36.552286   904 sgd_solver.cpp:106] Iteration 119360, lr = 0.0119153
I0605 16:20:57.066944   904 solver.cpp:229] Iteration 119400, loss = 2.40299
I0605 16:20:57.067000   904 solver.cpp:245]     Train net output #0: loss = 2.30009 (* 1 = 2.30009 loss)
I0605 16:20:57.067011   904 sgd_solver.cpp:106] Iteration 119400, lr = 0.0119059
I0605 16:21:17.559454   904 solver.cpp:229] Iteration 119440, loss = 2.37923
I0605 16:21:17.559633   904 solver.cpp:245]     Train net output #0: loss = 2.38005 (* 1 = 2.38005 loss)
I0605 16:21:17.559645   904 sgd_solver.cpp:106] Iteration 119440, lr = 0.0118965
I0605 16:21:38.089072   904 solver.cpp:229] Iteration 119480, loss = 2.41289
I0605 16:21:38.089130   904 solver.cpp:245]     Train net output #0: loss = 2.37242 (* 1 = 2.37242 loss)
I0605 16:21:38.089141   904 sgd_solver.cpp:106] Iteration 119480, lr = 0.0118871
I0605 16:21:58.601768   904 solver.cpp:229] Iteration 119520, loss = 2.37563
I0605 16:21:58.601982   904 solver.cpp:245]     Train net output #0: loss = 2.47841 (* 1 = 2.47841 loss)
I0605 16:21:58.602008   904 sgd_solver.cpp:106] Iteration 119520, lr = 0.0118776
I0605 16:22:19.103984   904 solver.cpp:229] Iteration 119560, loss = 2.40469
I0605 16:22:19.104038   904 solver.cpp:245]     Train net output #0: loss = 2.46005 (* 1 = 2.46005 loss)
I0605 16:22:19.104045   904 sgd_solver.cpp:106] Iteration 119560, lr = 0.0118682
I0605 16:22:39.615921   904 solver.cpp:229] Iteration 119600, loss = 2.37396
I0605 16:22:39.616117   904 solver.cpp:245]     Train net output #0: loss = 2.14982 (* 1 = 2.14982 loss)
I0605 16:22:39.616143   904 sgd_solver.cpp:106] Iteration 119600, lr = 0.0118588
I0605 16:23:00.141816   904 solver.cpp:229] Iteration 119640, loss = 2.34678
I0605 16:23:00.141865   904 solver.cpp:245]     Train net output #0: loss = 2.24448 (* 1 = 2.24448 loss)
I0605 16:23:00.141873   904 sgd_solver.cpp:106] Iteration 119640, lr = 0.0118494
I0605 16:23:10.132876   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 16:23:20.645097   904 solver.cpp:229] Iteration 119680, loss = 2.36888
I0605 16:23:20.645148   904 solver.cpp:245]     Train net output #0: loss = 2.18087 (* 1 = 2.18087 loss)
I0605 16:23:20.645158   904 sgd_solver.cpp:106] Iteration 119680, lr = 0.01184
I0605 16:23:41.057895   904 solver.cpp:229] Iteration 119720, loss = 2.4219
I0605 16:23:41.058133   904 solver.cpp:245]     Train net output #0: loss = 2.73978 (* 1 = 2.73978 loss)
I0605 16:23:41.058159   904 sgd_solver.cpp:106] Iteration 119720, lr = 0.0118306
I0605 16:24:01.362746   904 solver.cpp:229] Iteration 119760, loss = 2.39113
I0605 16:24:01.362805   904 solver.cpp:245]     Train net output #0: loss = 2.49181 (* 1 = 2.49181 loss)
I0605 16:24:01.362817   904 sgd_solver.cpp:106] Iteration 119760, lr = 0.0118212
I0605 16:24:21.670317   904 solver.cpp:229] Iteration 119800, loss = 2.39207
I0605 16:24:21.670526   904 solver.cpp:245]     Train net output #0: loss = 2.38805 (* 1 = 2.38805 loss)
I0605 16:24:21.670536   904 sgd_solver.cpp:106] Iteration 119800, lr = 0.0118118
I0605 16:24:41.960407   904 solver.cpp:229] Iteration 119840, loss = 2.37825
I0605 16:24:41.960450   904 solver.cpp:245]     Train net output #0: loss = 2.31785 (* 1 = 2.31785 loss)
I0605 16:24:41.960461   904 sgd_solver.cpp:106] Iteration 119840, lr = 0.0118024
I0605 16:25:02.341595   904 solver.cpp:229] Iteration 119880, loss = 2.41181
I0605 16:25:02.341868   904 solver.cpp:245]     Train net output #0: loss = 2.68542 (* 1 = 2.68542 loss)
I0605 16:25:02.341883   904 sgd_solver.cpp:106] Iteration 119880, lr = 0.0117929
I0605 16:25:22.628701   904 solver.cpp:229] Iteration 119920, loss = 2.41787
I0605 16:25:22.628779   904 solver.cpp:245]     Train net output #0: loss = 2.44593 (* 1 = 2.44593 loss)
I0605 16:25:22.628790   904 sgd_solver.cpp:106] Iteration 119920, lr = 0.0117835
I0605 16:25:42.923298   904 solver.cpp:229] Iteration 119960, loss = 2.36145
I0605 16:25:42.923465   904 solver.cpp:245]     Train net output #0: loss = 2.33708 (* 1 = 2.33708 loss)
I0605 16:25:42.923476   904 sgd_solver.cpp:106] Iteration 119960, lr = 0.0117741
I0605 16:26:02.681661   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_120000.caffemodel
I0605 16:26:02.942821   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_120000.solverstate
I0605 16:26:03.028653   904 solver.cpp:338] Iteration 120000, Testing net (#0)
I0605 16:26:03.028736   904 net.cpp:748] Ignoring source layer loss
I0605 16:26:14.869848   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 16:26:50.087260   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 16:27:13.460484   904 solver.cpp:406]     Test net output #0: accuracy = 0.463621
I0605 16:27:13.460533   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.713259
I0605 16:27:13.774940   904 solver.cpp:229] Iteration 120000, loss = 2.4058
I0605 16:27:13.774989   904 solver.cpp:245]     Train net output #0: loss = 2.42151 (* 1 = 2.42151 loss)
I0605 16:27:13.775002   904 sgd_solver.cpp:106] Iteration 120000, lr = 0.0117647
I0605 16:27:33.013118   904 solver.cpp:229] Iteration 120040, loss = 2.38917
I0605 16:27:33.013293   904 solver.cpp:245]     Train net output #0: loss = 2.52325 (* 1 = 2.52325 loss)
I0605 16:27:33.013303   904 sgd_solver.cpp:106] Iteration 120040, lr = 0.0117553
I0605 16:27:54.382356   904 solver.cpp:229] Iteration 120080, loss = 2.38674
I0605 16:27:54.382403   904 solver.cpp:245]     Train net output #0: loss = 2.36126 (* 1 = 2.36126 loss)
I0605 16:27:54.382411   904 sgd_solver.cpp:106] Iteration 120080, lr = 0.0117459
I0605 16:28:15.852349   904 solver.cpp:229] Iteration 120120, loss = 2.40144
I0605 16:28:15.852627   904 solver.cpp:245]     Train net output #0: loss = 2.41504 (* 1 = 2.41504 loss)
I0605 16:28:15.852649   904 sgd_solver.cpp:106] Iteration 120120, lr = 0.0117365
I0605 16:28:36.893851   904 solver.cpp:229] Iteration 120160, loss = 2.40032
I0605 16:28:36.893906   904 solver.cpp:245]     Train net output #0: loss = 2.41773 (* 1 = 2.41773 loss)
I0605 16:28:36.893918   904 sgd_solver.cpp:106] Iteration 120160, lr = 0.0117271
I0605 16:28:48.468348   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 16:28:57.951210   904 solver.cpp:229] Iteration 120200, loss = 2.40442
I0605 16:28:57.951266   904 solver.cpp:245]     Train net output #0: loss = 2.51592 (* 1 = 2.51592 loss)
I0605 16:28:57.951285   904 sgd_solver.cpp:106] Iteration 120200, lr = 0.0117176
I0605 16:29:18.982237   904 solver.cpp:229] Iteration 120240, loss = 2.39234
I0605 16:29:18.982439   904 solver.cpp:245]     Train net output #0: loss = 2.52525 (* 1 = 2.52525 loss)
I0605 16:29:18.982466   904 sgd_solver.cpp:106] Iteration 120240, lr = 0.0117082
I0605 16:29:39.933085   904 solver.cpp:229] Iteration 120280, loss = 2.41506
I0605 16:29:39.933174   904 solver.cpp:245]     Train net output #0: loss = 2.43342 (* 1 = 2.43342 loss)
I0605 16:29:39.933192   904 sgd_solver.cpp:106] Iteration 120280, lr = 0.0116988
I0605 16:30:00.795755   904 solver.cpp:229] Iteration 120320, loss = 2.38101
I0605 16:30:00.796063   904 solver.cpp:245]     Train net output #0: loss = 2.60147 (* 1 = 2.60147 loss)
I0605 16:30:00.796084   904 sgd_solver.cpp:106] Iteration 120320, lr = 0.0116894
I0605 16:30:21.539077   904 solver.cpp:229] Iteration 120360, loss = 2.37386
I0605 16:30:21.539124   904 solver.cpp:245]     Train net output #0: loss = 2.29904 (* 1 = 2.29904 loss)
I0605 16:30:21.539135   904 sgd_solver.cpp:106] Iteration 120360, lr = 0.01168
I0605 16:30:42.290801   904 solver.cpp:229] Iteration 120400, loss = 2.41867
I0605 16:30:42.290987   904 solver.cpp:245]     Train net output #0: loss = 2.37713 (* 1 = 2.37713 loss)
I0605 16:30:42.291002   904 sgd_solver.cpp:106] Iteration 120400, lr = 0.0116706
I0605 16:31:02.850622   904 solver.cpp:229] Iteration 120440, loss = 2.39937
I0605 16:31:02.850677   904 solver.cpp:245]     Train net output #0: loss = 2.59497 (* 1 = 2.59497 loss)
I0605 16:31:02.850687   904 sgd_solver.cpp:106] Iteration 120440, lr = 0.0116612
I0605 16:31:23.494034   904 solver.cpp:229] Iteration 120480, loss = 2.37213
I0605 16:31:23.494220   904 solver.cpp:245]     Train net output #0: loss = 2.31371 (* 1 = 2.31371 loss)
I0605 16:31:23.494235   904 sgd_solver.cpp:106] Iteration 120480, lr = 0.0116518
I0605 16:31:44.171394   904 solver.cpp:229] Iteration 120520, loss = 2.38037
I0605 16:31:44.171447   904 solver.cpp:245]     Train net output #0: loss = 2.22633 (* 1 = 2.22633 loss)
I0605 16:31:44.171455   904 sgd_solver.cpp:106] Iteration 120520, lr = 0.0116424
I0605 16:32:04.590466   904 solver.cpp:229] Iteration 120560, loss = 2.42392
I0605 16:32:04.590637   904 solver.cpp:245]     Train net output #0: loss = 2.37482 (* 1 = 2.37482 loss)
I0605 16:32:04.590647   904 sgd_solver.cpp:106] Iteration 120560, lr = 0.0116329
I0605 16:32:25.141628   904 solver.cpp:229] Iteration 120600, loss = 2.41319
I0605 16:32:25.141691   904 solver.cpp:245]     Train net output #0: loss = 2.28629 (* 1 = 2.28629 loss)
I0605 16:32:25.141701   904 sgd_solver.cpp:106] Iteration 120600, lr = 0.0116235
I0605 16:32:45.705242   904 solver.cpp:229] Iteration 120640, loss = 2.36056
I0605 16:32:45.705502   904 solver.cpp:245]     Train net output #0: loss = 2.0532 (* 1 = 2.0532 loss)
I0605 16:32:45.705529   904 sgd_solver.cpp:106] Iteration 120640, lr = 0.0116141
I0605 16:33:06.228113   904 solver.cpp:229] Iteration 120680, loss = 2.39703
I0605 16:33:06.228168   904 solver.cpp:245]     Train net output #0: loss = 2.47951 (* 1 = 2.47951 loss)
I0605 16:33:06.228178   904 sgd_solver.cpp:106] Iteration 120680, lr = 0.0116047
I0605 16:33:22.675669   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 16:33:26.784087   904 solver.cpp:229] Iteration 120720, loss = 2.40212
I0605 16:33:26.784142   904 solver.cpp:245]     Train net output #0: loss = 2.2584 (* 1 = 2.2584 loss)
I0605 16:33:26.784152   904 sgd_solver.cpp:106] Iteration 120720, lr = 0.0115953
I0605 16:33:47.321277   904 solver.cpp:229] Iteration 120760, loss = 2.41038
I0605 16:33:47.321322   904 solver.cpp:245]     Train net output #0: loss = 2.69665 (* 1 = 2.69665 loss)
I0605 16:33:47.321331   904 sgd_solver.cpp:106] Iteration 120760, lr = 0.0115859
I0605 16:34:07.861752   904 solver.cpp:229] Iteration 120800, loss = 2.39329
I0605 16:34:07.861979   904 solver.cpp:245]     Train net output #0: loss = 2.48152 (* 1 = 2.48152 loss)
I0605 16:34:07.862009   904 sgd_solver.cpp:106] Iteration 120800, lr = 0.0115765
I0605 16:34:28.274340   904 solver.cpp:229] Iteration 120840, loss = 2.39768
I0605 16:34:28.274389   904 solver.cpp:245]     Train net output #0: loss = 2.47068 (* 1 = 2.47068 loss)
I0605 16:34:28.274399   904 sgd_solver.cpp:106] Iteration 120840, lr = 0.0115671
I0605 16:34:48.668555   904 solver.cpp:229] Iteration 120880, loss = 2.42699
I0605 16:34:48.668815   904 solver.cpp:245]     Train net output #0: loss = 2.2854 (* 1 = 2.2854 loss)
I0605 16:34:48.668840   904 sgd_solver.cpp:106] Iteration 120880, lr = 0.0115576
I0605 16:35:09.208453   904 solver.cpp:229] Iteration 120920, loss = 2.36559
I0605 16:35:09.208510   904 solver.cpp:245]     Train net output #0: loss = 2.34036 (* 1 = 2.34036 loss)
I0605 16:35:09.208519   904 sgd_solver.cpp:106] Iteration 120920, lr = 0.0115482
I0605 16:35:29.737275   904 solver.cpp:229] Iteration 120960, loss = 2.35203
I0605 16:35:29.737566   904 solver.cpp:245]     Train net output #0: loss = 2.63075 (* 1 = 2.63075 loss)
I0605 16:35:29.737578   904 sgd_solver.cpp:106] Iteration 120960, lr = 0.0115388
I0605 16:35:49.770172   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_121000.caffemodel
I0605 16:35:50.038877   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_121000.solverstate
I0605 16:35:50.115627   904 solver.cpp:338] Iteration 121000, Testing net (#0)
I0605 16:35:50.115707   904 net.cpp:748] Ignoring source layer loss
I0605 16:36:05.303722   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 16:36:40.132709   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 16:37:00.696020   904 solver.cpp:406]     Test net output #0: accuracy = 0.470321
I0605 16:37:00.696085   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.71886
I0605 16:37:01.011519   904 solver.cpp:229] Iteration 121000, loss = 2.37907
I0605 16:37:01.011561   904 solver.cpp:245]     Train net output #0: loss = 2.48582 (* 1 = 2.48582 loss)
I0605 16:37:01.011571   904 sgd_solver.cpp:106] Iteration 121000, lr = 0.0115294
I0605 16:37:20.272130   904 solver.cpp:229] Iteration 121040, loss = 2.37161
I0605 16:37:20.272351   904 solver.cpp:245]     Train net output #0: loss = 2.42105 (* 1 = 2.42105 loss)
I0605 16:37:20.272389   904 sgd_solver.cpp:106] Iteration 121040, lr = 0.01152
I0605 16:37:41.720475   904 solver.cpp:229] Iteration 121080, loss = 2.3964
I0605 16:37:41.720522   904 solver.cpp:245]     Train net output #0: loss = 2.3465 (* 1 = 2.3465 loss)
I0605 16:37:41.720532   904 sgd_solver.cpp:106] Iteration 121080, lr = 0.0115106
I0605 16:38:03.244428   904 solver.cpp:229] Iteration 121120, loss = 2.34359
I0605 16:38:03.244654   904 solver.cpp:245]     Train net output #0: loss = 2.45939 (* 1 = 2.45939 loss)
I0605 16:38:03.244680   904 sgd_solver.cpp:106] Iteration 121120, lr = 0.0115012
I0605 16:38:24.497119   904 solver.cpp:229] Iteration 121160, loss = 2.39386
I0605 16:38:24.497167   904 solver.cpp:245]     Train net output #0: loss = 2.41826 (* 1 = 2.41826 loss)
I0605 16:38:24.497179   904 sgd_solver.cpp:106] Iteration 121160, lr = 0.0114918
I0605 16:38:45.498057   904 solver.cpp:229] Iteration 121200, loss = 2.36756
I0605 16:38:45.498260   904 solver.cpp:245]     Train net output #0: loss = 2.32386 (* 1 = 2.32386 loss)
I0605 16:38:45.498268   904 sgd_solver.cpp:106] Iteration 121200, lr = 0.0114824
I0605 16:39:06.481354   904 solver.cpp:229] Iteration 121240, loss = 2.37787
I0605 16:39:06.481411   904 solver.cpp:245]     Train net output #0: loss = 2.23923 (* 1 = 2.23923 loss)
I0605 16:39:06.481422   904 sgd_solver.cpp:106] Iteration 121240, lr = 0.0114729
I0605 16:39:07.269330   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 16:39:27.483229   904 solver.cpp:229] Iteration 121280, loss = 2.38385
I0605 16:39:27.483419   904 solver.cpp:245]     Train net output #0: loss = 2.20618 (* 1 = 2.20618 loss)
I0605 16:39:27.483433   904 sgd_solver.cpp:106] Iteration 121280, lr = 0.0114635
I0605 16:39:48.458483   904 solver.cpp:229] Iteration 121320, loss = 2.38564
I0605 16:39:48.458526   904 solver.cpp:245]     Train net output #0: loss = 2.35443 (* 1 = 2.35443 loss)
I0605 16:39:48.458534   904 sgd_solver.cpp:106] Iteration 121320, lr = 0.0114541
I0605 16:40:09.289250   904 solver.cpp:229] Iteration 121360, loss = 2.39068
I0605 16:40:09.289465   904 solver.cpp:245]     Train net output #0: loss = 2.55717 (* 1 = 2.55717 loss)
I0605 16:40:09.289494   904 sgd_solver.cpp:106] Iteration 121360, lr = 0.0114447
I0605 16:40:30.099092   904 solver.cpp:229] Iteration 121400, loss = 2.36678
I0605 16:40:30.099146   904 solver.cpp:245]     Train net output #0: loss = 2.34175 (* 1 = 2.34175 loss)
I0605 16:40:30.099155   904 sgd_solver.cpp:106] Iteration 121400, lr = 0.0114353
I0605 16:40:50.920281   904 solver.cpp:229] Iteration 121440, loss = 2.40017
I0605 16:40:50.920609   904 solver.cpp:245]     Train net output #0: loss = 2.51857 (* 1 = 2.51857 loss)
I0605 16:40:50.920634   904 sgd_solver.cpp:106] Iteration 121440, lr = 0.0114259
I0605 16:41:11.690935   904 solver.cpp:229] Iteration 121480, loss = 2.39325
I0605 16:41:11.690987   904 solver.cpp:245]     Train net output #0: loss = 2.36191 (* 1 = 2.36191 loss)
I0605 16:41:11.691000   904 sgd_solver.cpp:106] Iteration 121480, lr = 0.0114165
I0605 16:41:32.372879   904 solver.cpp:229] Iteration 121520, loss = 2.40711
I0605 16:41:32.373047   904 solver.cpp:245]     Train net output #0: loss = 2.61289 (* 1 = 2.61289 loss)
I0605 16:41:32.373057   904 sgd_solver.cpp:106] Iteration 121520, lr = 0.0114071
I0605 16:41:53.063813   904 solver.cpp:229] Iteration 121560, loss = 2.3813
I0605 16:41:53.063858   904 solver.cpp:245]     Train net output #0: loss = 2.31479 (* 1 = 2.31479 loss)
I0605 16:41:53.063868   904 sgd_solver.cpp:106] Iteration 121560, lr = 0.0113976
I0605 16:42:13.757810   904 solver.cpp:229] Iteration 121600, loss = 2.42697
I0605 16:42:13.758018   904 solver.cpp:245]     Train net output #0: loss = 2.37028 (* 1 = 2.37028 loss)
I0605 16:42:13.758028   904 sgd_solver.cpp:106] Iteration 121600, lr = 0.0113882
I0605 16:42:34.425060   904 solver.cpp:229] Iteration 121640, loss = 2.38443
I0605 16:42:34.425117   904 solver.cpp:245]     Train net output #0: loss = 2.23317 (* 1 = 2.23317 loss)
I0605 16:42:34.425129   904 sgd_solver.cpp:106] Iteration 121640, lr = 0.0113788
I0605 16:42:54.936036   904 solver.cpp:229] Iteration 121680, loss = 2.40527
I0605 16:42:54.936272   904 solver.cpp:245]     Train net output #0: loss = 2.2712 (* 1 = 2.2712 loss)
I0605 16:42:54.936305   904 sgd_solver.cpp:106] Iteration 121680, lr = 0.0113694
I0605 16:43:15.500540   904 solver.cpp:229] Iteration 121720, loss = 2.37796
I0605 16:43:15.500581   904 solver.cpp:245]     Train net output #0: loss = 2.21525 (* 1 = 2.21525 loss)
I0605 16:43:15.500591   904 sgd_solver.cpp:106] Iteration 121720, lr = 0.01136
I0605 16:43:36.175489   904 solver.cpp:229] Iteration 121760, loss = 2.38303
I0605 16:43:36.175746   904 solver.cpp:245]     Train net output #0: loss = 2.67263 (* 1 = 2.67263 loss)
I0605 16:43:36.175770   904 sgd_solver.cpp:106] Iteration 121760, lr = 0.0113506
I0605 16:43:42.894239   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 16:43:56.803165   904 solver.cpp:229] Iteration 121800, loss = 2.38837
I0605 16:43:56.803238   904 solver.cpp:245]     Train net output #0: loss = 2.46435 (* 1 = 2.46435 loss)
I0605 16:43:56.803256   904 sgd_solver.cpp:106] Iteration 121800, lr = 0.0113412
I0605 16:44:17.330842   904 solver.cpp:229] Iteration 121840, loss = 2.37225
I0605 16:44:17.331023   904 solver.cpp:245]     Train net output #0: loss = 2.41534 (* 1 = 2.41534 loss)
I0605 16:44:17.331043   904 sgd_solver.cpp:106] Iteration 121840, lr = 0.0113318
I0605 16:44:37.862555   904 solver.cpp:229] Iteration 121880, loss = 2.36698
I0605 16:44:37.862608   904 solver.cpp:245]     Train net output #0: loss = 2.4012 (* 1 = 2.4012 loss)
I0605 16:44:37.862617   904 sgd_solver.cpp:106] Iteration 121880, lr = 0.0113224
I0605 16:44:58.412946   904 solver.cpp:229] Iteration 121920, loss = 2.35017
I0605 16:44:58.413110   904 solver.cpp:245]     Train net output #0: loss = 2.40231 (* 1 = 2.40231 loss)
I0605 16:44:58.413120   904 sgd_solver.cpp:106] Iteration 121920, lr = 0.0113129
I0605 16:45:18.948649   904 solver.cpp:229] Iteration 121960, loss = 2.40178
I0605 16:45:18.948696   904 solver.cpp:245]     Train net output #0: loss = 2.34695 (* 1 = 2.34695 loss)
I0605 16:45:18.948707   904 sgd_solver.cpp:106] Iteration 121960, lr = 0.0113035
I0605 16:45:38.970233   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_122000.caffemodel
I0605 16:45:39.235669   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_122000.solverstate
I0605 16:45:39.312592   904 solver.cpp:338] Iteration 122000, Testing net (#0)
I0605 16:45:39.312647   904 net.cpp:748] Ignoring source layer loss
I0605 16:45:59.459588   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 16:46:35.613946   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 16:46:50.752847   904 solver.cpp:406]     Test net output #0: accuracy = 0.465741
I0605 16:46:50.752894   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.711919
I0605 16:46:51.066097   904 solver.cpp:229] Iteration 122000, loss = 2.35423
I0605 16:46:51.066141   904 solver.cpp:245]     Train net output #0: loss = 2.48984 (* 1 = 2.48984 loss)
I0605 16:46:51.066153   904 sgd_solver.cpp:106] Iteration 122000, lr = 0.0112941
I0605 16:47:10.299819   904 solver.cpp:229] Iteration 122040, loss = 2.3609
I0605 16:47:10.300030   904 solver.cpp:245]     Train net output #0: loss = 2.51412 (* 1 = 2.51412 loss)
I0605 16:47:10.300056   904 sgd_solver.cpp:106] Iteration 122040, lr = 0.0112847
I0605 16:47:31.778496   904 solver.cpp:229] Iteration 122080, loss = 2.39605
I0605 16:47:31.778545   904 solver.cpp:245]     Train net output #0: loss = 2.58501 (* 1 = 2.58501 loss)
I0605 16:47:31.778555   904 sgd_solver.cpp:106] Iteration 122080, lr = 0.0112753
I0605 16:47:53.151326   904 solver.cpp:229] Iteration 122120, loss = 2.35469
I0605 16:47:53.151556   904 solver.cpp:245]     Train net output #0: loss = 2.44131 (* 1 = 2.44131 loss)
I0605 16:47:53.151582   904 sgd_solver.cpp:106] Iteration 122120, lr = 0.0112659
I0605 16:48:14.005605   904 solver.cpp:229] Iteration 122160, loss = 2.36322
I0605 16:48:14.005655   904 solver.cpp:245]     Train net output #0: loss = 2.25332 (* 1 = 2.25332 loss)
I0605 16:48:14.005666   904 sgd_solver.cpp:106] Iteration 122160, lr = 0.0112565
I0605 16:48:34.832304   904 solver.cpp:229] Iteration 122200, loss = 2.37757
I0605 16:48:34.832531   904 solver.cpp:245]     Train net output #0: loss = 2.27727 (* 1 = 2.27727 loss)
I0605 16:48:34.832556   904 sgd_solver.cpp:106] Iteration 122200, lr = 0.0112471
I0605 16:48:55.824309   904 solver.cpp:229] Iteration 122240, loss = 2.35323
I0605 16:48:55.824352   904 solver.cpp:245]     Train net output #0: loss = 2.4688 (* 1 = 2.4688 loss)
I0605 16:48:55.824362   904 sgd_solver.cpp:106] Iteration 122240, lr = 0.0112376
I0605 16:49:16.715644   904 solver.cpp:229] Iteration 122280, loss = 2.41098
I0605 16:49:16.715800   904 solver.cpp:245]     Train net output #0: loss = 2.36974 (* 1 = 2.36974 loss)
I0605 16:49:16.715811   904 sgd_solver.cpp:106] Iteration 122280, lr = 0.0112282
I0605 16:49:21.660735   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 16:49:37.470293   904 solver.cpp:229] Iteration 122320, loss = 2.35014
I0605 16:49:37.470351   904 solver.cpp:245]     Train net output #0: loss = 2.31727 (* 1 = 2.31727 loss)
I0605 16:49:37.470365   904 sgd_solver.cpp:106] Iteration 122320, lr = 0.0112188
I0605 16:49:58.160145   904 solver.cpp:229] Iteration 122360, loss = 2.3866
I0605 16:49:58.160406   904 solver.cpp:245]     Train net output #0: loss = 2.39327 (* 1 = 2.39327 loss)
I0605 16:49:58.160429   904 sgd_solver.cpp:106] Iteration 122360, lr = 0.0112094
I0605 16:50:18.860832   904 solver.cpp:229] Iteration 122400, loss = 2.40151
I0605 16:50:18.860877   904 solver.cpp:245]     Train net output #0: loss = 2.38155 (* 1 = 2.38155 loss)
I0605 16:50:18.860888   904 sgd_solver.cpp:106] Iteration 122400, lr = 0.0112
I0605 16:50:39.398069   904 solver.cpp:229] Iteration 122440, loss = 2.34194
I0605 16:50:39.398218   904 solver.cpp:245]     Train net output #0: loss = 2.06405 (* 1 = 2.06405 loss)
I0605 16:50:39.398229   904 sgd_solver.cpp:106] Iteration 122440, lr = 0.0111906
I0605 16:51:00.012974   904 solver.cpp:229] Iteration 122480, loss = 2.36938
I0605 16:51:00.013013   904 solver.cpp:245]     Train net output #0: loss = 2.42623 (* 1 = 2.42623 loss)
I0605 16:51:00.013021   904 sgd_solver.cpp:106] Iteration 122480, lr = 0.0111812
I0605 16:51:20.605696   904 solver.cpp:229] Iteration 122520, loss = 2.3617
I0605 16:51:20.605929   904 solver.cpp:245]     Train net output #0: loss = 2.26395 (* 1 = 2.26395 loss)
I0605 16:51:20.605957   904 sgd_solver.cpp:106] Iteration 122520, lr = 0.0111718
I0605 16:51:41.108222   904 solver.cpp:229] Iteration 122560, loss = 2.39492
I0605 16:51:41.108283   904 solver.cpp:245]     Train net output #0: loss = 2.20552 (* 1 = 2.20552 loss)
I0605 16:51:41.108304   904 sgd_solver.cpp:106] Iteration 122560, lr = 0.0111624
I0605 16:52:01.612901   904 solver.cpp:229] Iteration 122600, loss = 2.38319
I0605 16:52:01.613169   904 solver.cpp:245]     Train net output #0: loss = 2.44698 (* 1 = 2.44698 loss)
I0605 16:52:01.613180   904 sgd_solver.cpp:106] Iteration 122600, lr = 0.0111529
I0605 16:52:22.146486   904 solver.cpp:229] Iteration 122640, loss = 2.38932
I0605 16:52:22.146528   904 solver.cpp:245]     Train net output #0: loss = 2.37061 (* 1 = 2.37061 loss)
I0605 16:52:22.146536   904 sgd_solver.cpp:106] Iteration 122640, lr = 0.0111435
I0605 16:52:42.674031   904 solver.cpp:229] Iteration 122680, loss = 2.37593
I0605 16:52:42.674221   904 solver.cpp:245]     Train net output #0: loss = 2.30203 (* 1 = 2.30203 loss)
I0605 16:52:42.674245   904 sgd_solver.cpp:106] Iteration 122680, lr = 0.0111341
I0605 16:53:03.054636   904 solver.cpp:229] Iteration 122720, loss = 2.39031
I0605 16:53:03.054685   904 solver.cpp:245]     Train net output #0: loss = 2.30606 (* 1 = 2.30606 loss)
I0605 16:53:03.054697   904 sgd_solver.cpp:106] Iteration 122720, lr = 0.0111247
I0605 16:53:23.360715   904 solver.cpp:229] Iteration 122760, loss = 2.34826
I0605 16:53:23.360895   904 solver.cpp:245]     Train net output #0: loss = 2.38635 (* 1 = 2.38635 loss)
I0605 16:53:23.360914   904 sgd_solver.cpp:106] Iteration 122760, lr = 0.0111153
I0605 16:53:43.641371   904 solver.cpp:229] Iteration 122800, loss = 2.38737
I0605 16:53:43.641417   904 solver.cpp:245]     Train net output #0: loss = 2.28415 (* 1 = 2.28415 loss)
I0605 16:53:43.641427   904 sgd_solver.cpp:106] Iteration 122800, lr = 0.0111059
I0605 16:53:48.198953   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 16:54:03.915951   904 solver.cpp:229] Iteration 122840, loss = 2.36447
I0605 16:54:03.916090   904 solver.cpp:245]     Train net output #0: loss = 2.35626 (* 1 = 2.35626 loss)
I0605 16:54:03.916102   904 sgd_solver.cpp:106] Iteration 122840, lr = 0.0110965
I0605 16:54:24.196597   904 solver.cpp:229] Iteration 122880, loss = 2.39295
I0605 16:54:24.196641   904 solver.cpp:245]     Train net output #0: loss = 2.44291 (* 1 = 2.44291 loss)
I0605 16:54:24.196651   904 sgd_solver.cpp:106] Iteration 122880, lr = 0.0110871
I0605 16:54:44.490980   904 solver.cpp:229] Iteration 122920, loss = 2.36649
I0605 16:54:44.491211   904 solver.cpp:245]     Train net output #0: loss = 2.49268 (* 1 = 2.49268 loss)
I0605 16:54:44.491236   904 sgd_solver.cpp:106] Iteration 122920, lr = 0.0110776
I0605 16:55:04.780701   904 solver.cpp:229] Iteration 122960, loss = 2.37039
I0605 16:55:04.780750   904 solver.cpp:245]     Train net output #0: loss = 2.19175 (* 1 = 2.19175 loss)
I0605 16:55:04.780758   904 sgd_solver.cpp:106] Iteration 122960, lr = 0.0110682
I0605 16:55:24.527786   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_123000.caffemodel
I0605 16:55:24.787396   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_123000.solverstate
I0605 16:55:24.873862   904 solver.cpp:338] Iteration 123000, Testing net (#0)
I0605 16:55:24.873942   904 net.cpp:748] Ignoring source layer loss
I0605 16:55:46.850631   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 16:56:20.999716   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 16:56:33.293926   904 solver.cpp:406]     Test net output #0: accuracy = 0.469461
I0605 16:56:33.293967   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.7191
I0605 16:56:33.609505   904 solver.cpp:229] Iteration 123000, loss = 2.3515
I0605 16:56:33.609557   904 solver.cpp:245]     Train net output #0: loss = 2.50663 (* 1 = 2.50663 loss)
I0605 16:56:33.609570   904 sgd_solver.cpp:106] Iteration 123000, lr = 0.0110588
I0605 16:56:52.783352   904 solver.cpp:229] Iteration 123040, loss = 2.35932
I0605 16:56:52.783669   904 solver.cpp:245]     Train net output #0: loss = 2.39462 (* 1 = 2.39462 loss)
I0605 16:56:52.783694   904 sgd_solver.cpp:106] Iteration 123040, lr = 0.0110494
I0605 16:57:14.048741   904 solver.cpp:229] Iteration 123080, loss = 2.40537
I0605 16:57:14.048786   904 solver.cpp:245]     Train net output #0: loss = 2.39305 (* 1 = 2.39305 loss)
I0605 16:57:14.048796   904 sgd_solver.cpp:106] Iteration 123080, lr = 0.01104
I0605 16:57:35.508335   904 solver.cpp:229] Iteration 123120, loss = 2.38676
I0605 16:57:35.508533   904 solver.cpp:245]     Train net output #0: loss = 2.36013 (* 1 = 2.36013 loss)
I0605 16:57:35.508561   904 sgd_solver.cpp:106] Iteration 123120, lr = 0.0110306
I0605 16:57:56.553544   904 solver.cpp:229] Iteration 123160, loss = 2.36537
I0605 16:57:56.553596   904 solver.cpp:245]     Train net output #0: loss = 2.24982 (* 1 = 2.24982 loss)
I0605 16:57:56.553606   904 sgd_solver.cpp:106] Iteration 123160, lr = 0.0110212
I0605 16:58:17.472033   904 solver.cpp:229] Iteration 123200, loss = 2.37837
I0605 16:58:17.472229   904 solver.cpp:245]     Train net output #0: loss = 2.29556 (* 1 = 2.29556 loss)
I0605 16:58:17.472240   904 sgd_solver.cpp:106] Iteration 123200, lr = 0.0110118
I0605 16:58:38.403944   904 solver.cpp:229] Iteration 123240, loss = 2.37974
I0605 16:58:38.403983   904 solver.cpp:245]     Train net output #0: loss = 2.53885 (* 1 = 2.53885 loss)
I0605 16:58:38.403992   904 sgd_solver.cpp:106] Iteration 123240, lr = 0.0110024
I0605 16:58:59.337831   904 solver.cpp:229] Iteration 123280, loss = 2.3891
I0605 16:58:59.338006   904 solver.cpp:245]     Train net output #0: loss = 2.58168 (* 1 = 2.58168 loss)
I0605 16:58:59.338018   904 sgd_solver.cpp:106] Iteration 123280, lr = 0.0109929
I0605 16:59:20.201581   904 solver.cpp:229] Iteration 123320, loss = 2.3527
I0605 16:59:20.201639   904 solver.cpp:245]     Train net output #0: loss = 2.31278 (* 1 = 2.31278 loss)
I0605 16:59:20.201652   904 sgd_solver.cpp:106] Iteration 123320, lr = 0.0109835
I0605 16:59:26.447052   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 16:59:40.981606   904 solver.cpp:229] Iteration 123360, loss = 2.42463
I0605 16:59:40.981775   904 solver.cpp:245]     Train net output #0: loss = 2.4464 (* 1 = 2.4464 loss)
I0605 16:59:40.981786   904 sgd_solver.cpp:106] Iteration 123360, lr = 0.0109741
I0605 17:00:01.713374   904 solver.cpp:229] Iteration 123400, loss = 2.3719
I0605 17:00:01.713429   904 solver.cpp:245]     Train net output #0: loss = 2.20345 (* 1 = 2.20345 loss)
I0605 17:00:01.713439   904 sgd_solver.cpp:106] Iteration 123400, lr = 0.0109647
I0605 17:00:22.327461   904 solver.cpp:229] Iteration 123440, loss = 2.30674
I0605 17:00:22.327688   904 solver.cpp:245]     Train net output #0: loss = 2.21243 (* 1 = 2.21243 loss)
I0605 17:00:22.327723   904 sgd_solver.cpp:106] Iteration 123440, lr = 0.0109553
I0605 17:00:43.722839   904 solver.cpp:229] Iteration 123480, loss = 2.35254
I0605 17:00:43.722903   904 solver.cpp:245]     Train net output #0: loss = 2.17361 (* 1 = 2.17361 loss)
I0605 17:00:43.722918   904 sgd_solver.cpp:106] Iteration 123480, lr = 0.0109459
I0605 17:01:04.261004   904 solver.cpp:229] Iteration 123520, loss = 2.34609
I0605 17:01:04.261221   904 solver.cpp:245]     Train net output #0: loss = 2.20104 (* 1 = 2.20104 loss)
I0605 17:01:04.261246   904 sgd_solver.cpp:106] Iteration 123520, lr = 0.0109365
I0605 17:01:24.873039   904 solver.cpp:229] Iteration 123560, loss = 2.35753
I0605 17:01:24.873080   904 solver.cpp:245]     Train net output #0: loss = 2.25752 (* 1 = 2.25752 loss)
I0605 17:01:24.873087   904 sgd_solver.cpp:106] Iteration 123560, lr = 0.0109271
I0605 17:01:45.461263   904 solver.cpp:229] Iteration 123600, loss = 2.37199
I0605 17:01:45.461468   904 solver.cpp:245]     Train net output #0: loss = 2.08107 (* 1 = 2.08107 loss)
I0605 17:01:45.461494   904 sgd_solver.cpp:106] Iteration 123600, lr = 0.0109176
I0605 17:02:06.042052   904 solver.cpp:229] Iteration 123640, loss = 2.32663
I0605 17:02:06.042096   904 solver.cpp:245]     Train net output #0: loss = 2.29936 (* 1 = 2.29936 loss)
I0605 17:02:06.042107   904 sgd_solver.cpp:106] Iteration 123640, lr = 0.0109082
I0605 17:02:26.562985   904 solver.cpp:229] Iteration 123680, loss = 2.34039
I0605 17:02:26.563256   904 solver.cpp:245]     Train net output #0: loss = 2.00154 (* 1 = 2.00154 loss)
I0605 17:02:26.563282   904 sgd_solver.cpp:106] Iteration 123680, lr = 0.0108988
I0605 17:02:47.021625   904 solver.cpp:229] Iteration 123720, loss = 2.36048
I0605 17:02:47.021672   904 solver.cpp:245]     Train net output #0: loss = 2.16946 (* 1 = 2.16946 loss)
I0605 17:02:47.021683   904 sgd_solver.cpp:106] Iteration 123720, lr = 0.0108894
I0605 17:03:07.587121   904 solver.cpp:229] Iteration 123760, loss = 2.35152
I0605 17:03:07.587347   904 solver.cpp:245]     Train net output #0: loss = 2.41137 (* 1 = 2.41137 loss)
I0605 17:03:07.587375   904 sgd_solver.cpp:106] Iteration 123760, lr = 0.01088
I0605 17:03:28.181486   904 solver.cpp:229] Iteration 123800, loss = 2.35905
I0605 17:03:28.181540   904 solver.cpp:245]     Train net output #0: loss = 2.29398 (* 1 = 2.29398 loss)
I0605 17:03:28.181552   904 sgd_solver.cpp:106] Iteration 123800, lr = 0.0108706
I0605 17:03:48.418644   904 solver.cpp:229] Iteration 123840, loss = 2.35849
I0605 17:03:48.418867   904 solver.cpp:245]     Train net output #0: loss = 2.27938 (* 1 = 2.27938 loss)
I0605 17:03:48.418895   904 sgd_solver.cpp:106] Iteration 123840, lr = 0.0108612
I0605 17:03:50.694422   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 17:04:08.906518   904 solver.cpp:229] Iteration 123880, loss = 2.35761
I0605 17:04:08.906571   904 solver.cpp:245]     Train net output #0: loss = 2.16295 (* 1 = 2.16295 loss)
I0605 17:04:08.906586   904 sgd_solver.cpp:106] Iteration 123880, lr = 0.0108518
I0605 17:04:29.453339   904 solver.cpp:229] Iteration 123920, loss = 2.32532
I0605 17:04:29.453528   904 solver.cpp:245]     Train net output #0: loss = 2.26551 (* 1 = 2.26551 loss)
I0605 17:04:29.453547   904 sgd_solver.cpp:106] Iteration 123920, lr = 0.0108424
I0605 17:04:49.933416   904 solver.cpp:229] Iteration 123960, loss = 2.41271
I0605 17:04:49.933457   904 solver.cpp:245]     Train net output #0: loss = 2.23267 (* 1 = 2.23267 loss)
I0605 17:04:49.933467   904 sgd_solver.cpp:106] Iteration 123960, lr = 0.0108329
I0605 17:05:09.882355   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_124000.caffemodel
I0605 17:05:10.159435   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_124000.solverstate
I0605 17:05:10.245067   904 solver.cpp:338] Iteration 124000, Testing net (#0)
I0605 17:05:10.245151   904 net.cpp:748] Ignoring source layer loss
I0605 17:05:35.932240   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 17:06:11.690501   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 17:06:21.857826   904 solver.cpp:406]     Test net output #0: accuracy = 0.47588
I0605 17:06:21.857869   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.72232
I0605 17:06:22.170739   904 solver.cpp:229] Iteration 124000, loss = 2.3901
I0605 17:06:22.170784   904 solver.cpp:245]     Train net output #0: loss = 2.16882 (* 1 = 2.16882 loss)
I0605 17:06:22.170794   904 sgd_solver.cpp:106] Iteration 124000, lr = 0.0108235
I0605 17:06:41.655047   904 solver.cpp:229] Iteration 124040, loss = 2.39118
I0605 17:06:41.655104   904 solver.cpp:245]     Train net output #0: loss = 2.2279 (* 1 = 2.2279 loss)
I0605 17:06:41.655115   904 sgd_solver.cpp:106] Iteration 124040, lr = 0.0108141
I0605 17:07:03.200353   904 solver.cpp:229] Iteration 124080, loss = 2.39358
I0605 17:07:03.200599   904 solver.cpp:245]     Train net output #0: loss = 2.41926 (* 1 = 2.41926 loss)
I0605 17:07:03.200624   904 sgd_solver.cpp:106] Iteration 124080, lr = 0.0108047
I0605 17:07:24.771067   904 solver.cpp:229] Iteration 124120, loss = 2.35808
I0605 17:07:24.771111   904 solver.cpp:245]     Train net output #0: loss = 2.44912 (* 1 = 2.44912 loss)
I0605 17:07:24.771119   904 sgd_solver.cpp:106] Iteration 124120, lr = 0.0107953
I0605 17:07:45.916131   904 solver.cpp:229] Iteration 124160, loss = 2.36872
I0605 17:07:45.916460   904 solver.cpp:245]     Train net output #0: loss = 2.31039 (* 1 = 2.31039 loss)
I0605 17:07:45.916487   904 sgd_solver.cpp:106] Iteration 124160, lr = 0.0107859
I0605 17:08:06.927460   904 solver.cpp:229] Iteration 124200, loss = 2.36276
I0605 17:08:06.927498   904 solver.cpp:245]     Train net output #0: loss = 2.71484 (* 1 = 2.71484 loss)
I0605 17:08:06.927507   904 sgd_solver.cpp:106] Iteration 124200, lr = 0.0107765
I0605 17:08:27.955981   904 solver.cpp:229] Iteration 124240, loss = 2.36577
I0605 17:08:27.956153   904 solver.cpp:245]     Train net output #0: loss = 2.50551 (* 1 = 2.50551 loss)
I0605 17:08:27.956166   904 sgd_solver.cpp:106] Iteration 124240, lr = 0.0107671
I0605 17:08:48.976789   904 solver.cpp:229] Iteration 124280, loss = 2.38852
I0605 17:08:48.976886   904 solver.cpp:245]     Train net output #0: loss = 2.41513 (* 1 = 2.41513 loss)
I0605 17:08:48.976910   904 sgd_solver.cpp:106] Iteration 124280, lr = 0.0107576
I0605 17:09:09.992871   904 solver.cpp:229] Iteration 124320, loss = 2.35092
I0605 17:09:09.993144   904 solver.cpp:245]     Train net output #0: loss = 2.36982 (* 1 = 2.36982 loss)
I0605 17:09:09.993171   904 sgd_solver.cpp:106] Iteration 124320, lr = 0.0107482
I0605 17:09:30.888257   904 solver.cpp:229] Iteration 124360, loss = 2.35769
I0605 17:09:30.888312   904 solver.cpp:245]     Train net output #0: loss = 2.38386 (* 1 = 2.38386 loss)
I0605 17:09:30.888322   904 sgd_solver.cpp:106] Iteration 124360, lr = 0.0107388
I0605 17:09:38.658579   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 17:09:51.537160   904 solver.cpp:229] Iteration 124400, loss = 2.36428
I0605 17:09:51.548496   904 solver.cpp:245]     Train net output #0: loss = 2.50185 (* 1 = 2.50185 loss)
I0605 17:09:51.548519   904 sgd_solver.cpp:106] Iteration 124400, lr = 0.0107294
I0605 17:10:12.045934   904 solver.cpp:229] Iteration 124440, loss = 2.33175
I0605 17:10:12.045985   904 solver.cpp:245]     Train net output #0: loss = 2.43899 (* 1 = 2.43899 loss)
I0605 17:10:12.045995   904 sgd_solver.cpp:106] Iteration 124440, lr = 0.01072
I0605 17:10:32.542702   904 solver.cpp:229] Iteration 124480, loss = 2.37535
I0605 17:10:32.542875   904 solver.cpp:245]     Train net output #0: loss = 2.10862 (* 1 = 2.10862 loss)
I0605 17:10:32.542889   904 sgd_solver.cpp:106] Iteration 124480, lr = 0.0107106
I0605 17:10:52.759964   904 solver.cpp:229] Iteration 124520, loss = 2.36586
I0605 17:10:52.760016   904 solver.cpp:245]     Train net output #0: loss = 2.12163 (* 1 = 2.12163 loss)
I0605 17:10:52.760026   904 sgd_solver.cpp:106] Iteration 124520, lr = 0.0107012
I0605 17:11:12.916352   904 solver.cpp:229] Iteration 124560, loss = 2.32847
I0605 17:11:12.916570   904 solver.cpp:245]     Train net output #0: loss = 2.34591 (* 1 = 2.34591 loss)
I0605 17:11:12.916582   904 sgd_solver.cpp:106] Iteration 124560, lr = 0.0106918
I0605 17:11:33.089077   904 solver.cpp:229] Iteration 124600, loss = 2.33401
I0605 17:11:33.089136   904 solver.cpp:245]     Train net output #0: loss = 2.28596 (* 1 = 2.28596 loss)
I0605 17:11:33.089148   904 sgd_solver.cpp:106] Iteration 124600, lr = 0.0106824
I0605 17:11:53.268368   904 solver.cpp:229] Iteration 124640, loss = 2.3493
I0605 17:11:53.268595   904 solver.cpp:245]     Train net output #0: loss = 2.32657 (* 1 = 2.32657 loss)
I0605 17:11:53.268626   904 sgd_solver.cpp:106] Iteration 124640, lr = 0.0106729
I0605 17:12:13.460937   904 solver.cpp:229] Iteration 124680, loss = 2.34933
I0605 17:12:13.460979   904 solver.cpp:245]     Train net output #0: loss = 2.38499 (* 1 = 2.38499 loss)
I0605 17:12:13.460988   904 sgd_solver.cpp:106] Iteration 124680, lr = 0.0106635
I0605 17:12:33.849081   904 solver.cpp:229] Iteration 124720, loss = 2.35218
I0605 17:12:33.849336   904 solver.cpp:245]     Train net output #0: loss = 2.20182 (* 1 = 2.20182 loss)
I0605 17:12:33.849359   904 sgd_solver.cpp:106] Iteration 124720, lr = 0.0106541
I0605 17:12:54.152799   904 solver.cpp:229] Iteration 124760, loss = 2.33935
I0605 17:12:54.152840   904 solver.cpp:245]     Train net output #0: loss = 2.32039 (* 1 = 2.32039 loss)
I0605 17:12:54.152849   904 sgd_solver.cpp:106] Iteration 124760, lr = 0.0106447
I0605 17:13:14.454794   904 solver.cpp:229] Iteration 124800, loss = 2.39175
I0605 17:13:14.455025   904 solver.cpp:245]     Train net output #0: loss = 2.43926 (* 1 = 2.43926 loss)
I0605 17:13:14.455036   904 sgd_solver.cpp:106] Iteration 124800, lr = 0.0106353
I0605 17:13:34.752774   904 solver.cpp:229] Iteration 124840, loss = 2.33599
I0605 17:13:34.752815   904 solver.cpp:245]     Train net output #0: loss = 2.4733 (* 1 = 2.4733 loss)
I0605 17:13:34.752825   904 sgd_solver.cpp:106] Iteration 124840, lr = 0.0106259
I0605 17:13:55.063747   904 solver.cpp:229] Iteration 124880, loss = 2.37347
I0605 17:13:55.063889   904 solver.cpp:245]     Train net output #0: loss = 2.31874 (* 1 = 2.31874 loss)
I0605 17:13:55.063899   904 sgd_solver.cpp:106] Iteration 124880, lr = 0.0106165
I0605 17:14:11.320830   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 17:14:15.374025   904 solver.cpp:229] Iteration 124920, loss = 2.35636
I0605 17:14:15.374071   904 solver.cpp:245]     Train net output #0: loss = 2.30762 (* 1 = 2.30762 loss)
I0605 17:14:15.374083   904 sgd_solver.cpp:106] Iteration 124920, lr = 0.0106071
I0605 17:14:35.663717   904 solver.cpp:229] Iteration 124960, loss = 2.31517
I0605 17:14:35.663926   904 solver.cpp:245]     Train net output #0: loss = 2.32487 (* 1 = 2.32487 loss)
I0605 17:14:35.663954   904 sgd_solver.cpp:106] Iteration 124960, lr = 0.0105976
I0605 17:14:55.465684   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_125000.caffemodel
I0605 17:14:55.729492   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_125000.solverstate
I0605 17:14:55.810295   904 solver.cpp:338] Iteration 125000, Testing net (#0)
I0605 17:14:55.810385   904 net.cpp:748] Ignoring source layer loss
I0605 17:15:25.198915   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 17:16:00.048097   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 17:16:06.612737   904 solver.cpp:406]     Test net output #0: accuracy = 0.463261
I0605 17:16:06.612777   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.713599
I0605 17:16:06.928021   904 solver.cpp:229] Iteration 125000, loss = 2.33755
I0605 17:16:06.928074   904 solver.cpp:245]     Train net output #0: loss = 2.46471 (* 1 = 2.46471 loss)
I0605 17:16:06.928083   904 sgd_solver.cpp:106] Iteration 125000, lr = 0.0105882
I0605 17:16:26.142732   904 solver.cpp:229] Iteration 125040, loss = 2.35262
I0605 17:16:26.142784   904 solver.cpp:245]     Train net output #0: loss = 2.18066 (* 1 = 2.18066 loss)
I0605 17:16:26.142797   904 sgd_solver.cpp:106] Iteration 125040, lr = 0.0105788
I0605 17:16:47.520499   904 solver.cpp:229] Iteration 125080, loss = 2.36374
I0605 17:16:47.520719   904 solver.cpp:245]     Train net output #0: loss = 2.44264 (* 1 = 2.44264 loss)
I0605 17:16:47.520728   904 sgd_solver.cpp:106] Iteration 125080, lr = 0.0105694
I0605 17:17:08.878794   904 solver.cpp:229] Iteration 125120, loss = 2.3931
I0605 17:17:08.878852   904 solver.cpp:245]     Train net output #0: loss = 2.17297 (* 1 = 2.17297 loss)
I0605 17:17:08.878864   904 sgd_solver.cpp:106] Iteration 125120, lr = 0.01056
I0605 17:17:29.818341   904 solver.cpp:229] Iteration 125160, loss = 2.40613
I0605 17:17:29.818569   904 solver.cpp:245]     Train net output #0: loss = 2.40543 (* 1 = 2.40543 loss)
I0605 17:17:29.818593   904 sgd_solver.cpp:106] Iteration 125160, lr = 0.0105506
I0605 17:17:50.639974   904 solver.cpp:229] Iteration 125200, loss = 2.37278
I0605 17:17:50.640023   904 solver.cpp:245]     Train net output #0: loss = 2.45835 (* 1 = 2.45835 loss)
I0605 17:17:50.640045   904 sgd_solver.cpp:106] Iteration 125200, lr = 0.0105412
I0605 17:18:11.458914   904 solver.cpp:229] Iteration 125240, loss = 2.34681
I0605 17:18:11.459185   904 solver.cpp:245]     Train net output #0: loss = 2.14592 (* 1 = 2.14592 loss)
I0605 17:18:11.459198   904 sgd_solver.cpp:106] Iteration 125240, lr = 0.0105318
I0605 17:18:32.292007   904 solver.cpp:229] Iteration 125280, loss = 2.35035
I0605 17:18:32.292053   904 solver.cpp:245]     Train net output #0: loss = 2.29172 (* 1 = 2.29172 loss)
I0605 17:18:32.292064   904 sgd_solver.cpp:106] Iteration 125280, lr = 0.0105224
I0605 17:18:53.113306   904 solver.cpp:229] Iteration 125320, loss = 2.35181
I0605 17:18:53.113529   904 solver.cpp:245]     Train net output #0: loss = 2.32017 (* 1 = 2.32017 loss)
I0605 17:18:53.113554   904 sgd_solver.cpp:106] Iteration 125320, lr = 0.0105129
I0605 17:19:13.877086   904 solver.cpp:229] Iteration 125360, loss = 2.34728
I0605 17:19:13.877141   904 solver.cpp:245]     Train net output #0: loss = 2.2813 (* 1 = 2.2813 loss)
I0605 17:19:13.877153   904 sgd_solver.cpp:106] Iteration 125360, lr = 0.0105035
I0605 17:19:34.540223   904 solver.cpp:229] Iteration 125400, loss = 2.37985
I0605 17:19:34.548460   904 solver.cpp:245]     Train net output #0: loss = 2.39279 (* 1 = 2.39279 loss)
I0605 17:19:34.548472   904 sgd_solver.cpp:106] Iteration 125400, lr = 0.0104941
I0605 17:19:54.351011   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 17:19:55.121403   904 solver.cpp:229] Iteration 125440, loss = 2.34774
I0605 17:19:55.121448   904 solver.cpp:245]     Train net output #0: loss = 2.22417 (* 1 = 2.22417 loss)
I0605 17:19:55.121459   904 sgd_solver.cpp:106] Iteration 125440, lr = 0.0104847
I0605 17:20:15.736665   904 solver.cpp:229] Iteration 125480, loss = 2.35378
I0605 17:20:15.736860   904 solver.cpp:245]     Train net output #0: loss = 2.38613 (* 1 = 2.38613 loss)
I0605 17:20:15.736872   904 sgd_solver.cpp:106] Iteration 125480, lr = 0.0104753
I0605 17:20:36.370666   904 solver.cpp:229] Iteration 125520, loss = 2.31273
I0605 17:20:36.370723   904 solver.cpp:245]     Train net output #0: loss = 2.38117 (* 1 = 2.38117 loss)
I0605 17:20:36.370735   904 sgd_solver.cpp:106] Iteration 125520, lr = 0.0104659
I0605 17:20:56.881229   904 solver.cpp:229] Iteration 125560, loss = 2.36466
I0605 17:20:56.881458   904 solver.cpp:245]     Train net output #0: loss = 2.51341 (* 1 = 2.51341 loss)
I0605 17:20:56.881490   904 sgd_solver.cpp:106] Iteration 125560, lr = 0.0104565
I0605 17:21:17.395728   904 solver.cpp:229] Iteration 125600, loss = 2.3866
I0605 17:21:17.395792   904 solver.cpp:245]     Train net output #0: loss = 2.47688 (* 1 = 2.47688 loss)
I0605 17:21:17.395802   904 sgd_solver.cpp:106] Iteration 125600, lr = 0.0104471
I0605 17:21:37.894294   904 solver.cpp:229] Iteration 125640, loss = 2.32654
I0605 17:21:37.894479   904 solver.cpp:245]     Train net output #0: loss = 2.31135 (* 1 = 2.31135 loss)
I0605 17:21:37.894495   904 sgd_solver.cpp:106] Iteration 125640, lr = 0.0104376
I0605 17:21:58.399171   904 solver.cpp:229] Iteration 125680, loss = 2.33356
I0605 17:21:58.399219   904 solver.cpp:245]     Train net output #0: loss = 2.22007 (* 1 = 2.22007 loss)
I0605 17:21:58.399229   904 sgd_solver.cpp:106] Iteration 125680, lr = 0.0104282
I0605 17:22:18.896168   904 solver.cpp:229] Iteration 125720, loss = 2.37376
I0605 17:22:18.896368   904 solver.cpp:245]     Train net output #0: loss = 2.50386 (* 1 = 2.50386 loss)
I0605 17:22:18.896416   904 sgd_solver.cpp:106] Iteration 125720, lr = 0.0104188
I0605 17:22:39.401120   904 solver.cpp:229] Iteration 125760, loss = 2.36288
I0605 17:22:39.401175   904 solver.cpp:245]     Train net output #0: loss = 2.49738 (* 1 = 2.49738 loss)
I0605 17:22:39.401185   904 sgd_solver.cpp:106] Iteration 125760, lr = 0.0104094
I0605 17:22:59.926775   904 solver.cpp:229] Iteration 125800, loss = 2.34022
I0605 17:22:59.927012   904 solver.cpp:245]     Train net output #0: loss = 2.36256 (* 1 = 2.36256 loss)
I0605 17:22:59.927027   904 sgd_solver.cpp:106] Iteration 125800, lr = 0.0104
I0605 17:23:20.261477   904 solver.cpp:229] Iteration 125840, loss = 2.36148
I0605 17:23:20.261525   904 solver.cpp:245]     Train net output #0: loss = 2.45356 (* 1 = 2.45356 loss)
I0605 17:23:20.261536   904 sgd_solver.cpp:106] Iteration 125840, lr = 0.0103906
I0605 17:23:40.524386   904 solver.cpp:229] Iteration 125880, loss = 2.40113
I0605 17:23:40.524672   904 solver.cpp:245]     Train net output #0: loss = 2.52333 (* 1 = 2.52333 loss)
I0605 17:23:40.524694   904 sgd_solver.cpp:106] Iteration 125880, lr = 0.0103812
I0605 17:24:00.853754   904 solver.cpp:229] Iteration 125920, loss = 2.32011
I0605 17:24:00.853803   904 solver.cpp:245]     Train net output #0: loss = 2.25822 (* 1 = 2.25822 loss)
I0605 17:24:00.853816   904 sgd_solver.cpp:106] Iteration 125920, lr = 0.0103718
I0605 17:24:21.117524   904 solver.cpp:229] Iteration 125960, loss = 2.31214
I0605 17:24:21.117691   904 solver.cpp:245]     Train net output #0: loss = 2.52138 (* 1 = 2.52138 loss)
I0605 17:24:21.117702   904 sgd_solver.cpp:106] Iteration 125960, lr = 0.0103624
I0605 17:24:37.846818   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 17:24:40.864114   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_126000.caffemodel
I0605 17:24:41.131048   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_126000.solverstate
I0605 17:24:41.218629   904 solver.cpp:338] Iteration 126000, Testing net (#0)
I0605 17:24:41.218727   904 net.cpp:748] Ignoring source layer loss
I0605 17:25:15.113414   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 17:25:49.674181   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 17:25:49.951717   904 solver.cpp:406]     Test net output #0: accuracy = 0.47932
I0605 17:25:49.951769   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.72494
I0605 17:25:50.266958   904 solver.cpp:229] Iteration 126000, loss = 2.33769
I0605 17:25:50.266999   904 solver.cpp:245]     Train net output #0: loss = 2.19252 (* 1 = 2.19252 loss)
I0605 17:25:50.267007   904 sgd_solver.cpp:106] Iteration 126000, lr = 0.0103529
I0605 17:26:09.440423   904 solver.cpp:229] Iteration 126040, loss = 2.33957
I0605 17:26:09.440464   904 solver.cpp:245]     Train net output #0: loss = 2.18466 (* 1 = 2.18466 loss)
I0605 17:26:09.440474   904 sgd_solver.cpp:106] Iteration 126040, lr = 0.0103435
I0605 17:26:30.741240   904 solver.cpp:229] Iteration 126080, loss = 2.3433
I0605 17:26:30.741473   904 solver.cpp:245]     Train net output #0: loss = 2.55973 (* 1 = 2.55973 loss)
I0605 17:26:30.741497   904 sgd_solver.cpp:106] Iteration 126080, lr = 0.0103341
I0605 17:26:52.191201   904 solver.cpp:229] Iteration 126120, loss = 2.31493
I0605 17:26:52.191273   904 solver.cpp:245]     Train net output #0: loss = 2.28829 (* 1 = 2.28829 loss)
I0605 17:26:52.191287   904 sgd_solver.cpp:106] Iteration 126120, lr = 0.0103247
I0605 17:27:13.174903   904 solver.cpp:229] Iteration 126160, loss = 2.33384
I0605 17:27:13.175076   904 solver.cpp:245]     Train net output #0: loss = 2.58653 (* 1 = 2.58653 loss)
I0605 17:27:13.175097   904 sgd_solver.cpp:106] Iteration 126160, lr = 0.0103153
I0605 17:27:34.099467   904 solver.cpp:229] Iteration 126200, loss = 2.33968
I0605 17:27:34.099524   904 solver.cpp:245]     Train net output #0: loss = 2.40013 (* 1 = 2.40013 loss)
I0605 17:27:34.099534   904 sgd_solver.cpp:106] Iteration 126200, lr = 0.0103059
I0605 17:27:55.247272   904 solver.cpp:229] Iteration 126240, loss = 2.33869
I0605 17:27:55.247489   904 solver.cpp:245]     Train net output #0: loss = 2.40885 (* 1 = 2.40885 loss)
I0605 17:27:55.247514   904 sgd_solver.cpp:106] Iteration 126240, lr = 0.0102965
I0605 17:28:16.081717   904 solver.cpp:229] Iteration 126280, loss = 2.34016
I0605 17:28:16.081764   904 solver.cpp:245]     Train net output #0: loss = 2.59384 (* 1 = 2.59384 loss)
I0605 17:28:16.081773   904 sgd_solver.cpp:106] Iteration 126280, lr = 0.0102871
I0605 17:28:36.885556   904 solver.cpp:229] Iteration 126320, loss = 2.33875
I0605 17:28:36.885783   904 solver.cpp:245]     Train net output #0: loss = 2.40364 (* 1 = 2.40364 loss)
I0605 17:28:36.885808   904 sgd_solver.cpp:106] Iteration 126320, lr = 0.0102776
I0605 17:28:57.685359   904 solver.cpp:229] Iteration 126360, loss = 2.32813
I0605 17:28:57.685420   904 solver.cpp:245]     Train net output #0: loss = 2.21858 (* 1 = 2.21858 loss)
I0605 17:28:57.685430   904 sgd_solver.cpp:106] Iteration 126360, lr = 0.0102682
I0605 17:29:18.476825   904 solver.cpp:229] Iteration 126400, loss = 2.3109
I0605 17:29:18.477097   904 solver.cpp:245]     Train net output #0: loss = 2.47691 (* 1 = 2.47691 loss)
I0605 17:29:18.477110   904 sgd_solver.cpp:106] Iteration 126400, lr = 0.0102588
I0605 17:29:39.282511   904 solver.cpp:229] Iteration 126440, loss = 2.32302
I0605 17:29:39.282570   904 solver.cpp:245]     Train net output #0: loss = 2.38453 (* 1 = 2.38453 loss)
I0605 17:29:39.282582   904 sgd_solver.cpp:106] Iteration 126440, lr = 0.0102494
I0605 17:29:59.991539   904 solver.cpp:229] Iteration 126480, loss = 2.36669
I0605 17:29:59.991767   904 solver.cpp:245]     Train net output #0: loss = 2.43516 (* 1 = 2.43516 loss)
I0605 17:29:59.991792   904 sgd_solver.cpp:106] Iteration 126480, lr = 0.01024
I0605 17:30:17.046581   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 17:30:20.665940   904 solver.cpp:229] Iteration 126520, loss = 2.38139
I0605 17:30:20.665994   904 solver.cpp:245]     Train net output #0: loss = 2.14315 (* 1 = 2.14315 loss)
I0605 17:30:20.666003   904 sgd_solver.cpp:106] Iteration 126520, lr = 0.0102306
I0605 17:30:41.348057   904 solver.cpp:229] Iteration 126560, loss = 2.3812
I0605 17:30:41.348304   904 solver.cpp:245]     Train net output #0: loss = 2.25289 (* 1 = 2.25289 loss)
I0605 17:30:41.348321   904 sgd_solver.cpp:106] Iteration 126560, lr = 0.0102212
I0605 17:31:02.021347   904 solver.cpp:229] Iteration 126600, loss = 2.37004
I0605 17:31:02.021405   904 solver.cpp:245]     Train net output #0: loss = 2.37252 (* 1 = 2.37252 loss)
I0605 17:31:02.021415   904 sgd_solver.cpp:106] Iteration 126600, lr = 0.0102118
I0605 17:31:22.676772   904 solver.cpp:229] Iteration 126640, loss = 2.34409
I0605 17:31:22.676975   904 solver.cpp:245]     Train net output #0: loss = 2.48274 (* 1 = 2.48274 loss)
I0605 17:31:22.676997   904 sgd_solver.cpp:106] Iteration 126640, lr = 0.0102024
I0605 17:31:43.350272   904 solver.cpp:229] Iteration 126680, loss = 2.35471
I0605 17:31:43.350328   904 solver.cpp:245]     Train net output #0: loss = 2.10638 (* 1 = 2.10638 loss)
I0605 17:31:43.350339   904 sgd_solver.cpp:106] Iteration 126680, lr = 0.0101929
I0605 17:32:04.004019   904 solver.cpp:229] Iteration 126720, loss = 2.36708
I0605 17:32:04.004268   904 solver.cpp:245]     Train net output #0: loss = 2.47661 (* 1 = 2.47661 loss)
I0605 17:32:04.004295   904 sgd_solver.cpp:106] Iteration 126720, lr = 0.0101835
I0605 17:32:24.658041   904 solver.cpp:229] Iteration 126760, loss = 2.34146
I0605 17:32:24.658089   904 solver.cpp:245]     Train net output #0: loss = 2.29463 (* 1 = 2.29463 loss)
I0605 17:32:24.658097   904 sgd_solver.cpp:106] Iteration 126760, lr = 0.0101741
I0605 17:32:45.182714   904 solver.cpp:229] Iteration 126800, loss = 2.37822
I0605 17:32:45.182948   904 solver.cpp:245]     Train net output #0: loss = 2.51471 (* 1 = 2.51471 loss)
I0605 17:32:45.182971   904 sgd_solver.cpp:106] Iteration 126800, lr = 0.0101647
I0605 17:33:05.720981   904 solver.cpp:229] Iteration 126840, loss = 2.30065
I0605 17:33:05.721026   904 solver.cpp:245]     Train net output #0: loss = 2.3747 (* 1 = 2.3747 loss)
I0605 17:33:05.721037   904 sgd_solver.cpp:106] Iteration 126840, lr = 0.0101553
I0605 17:33:26.354015   904 solver.cpp:229] Iteration 126880, loss = 2.33987
I0605 17:33:26.354218   904 solver.cpp:245]     Train net output #0: loss = 2.37433 (* 1 = 2.37433 loss)
I0605 17:33:26.354230   904 sgd_solver.cpp:106] Iteration 126880, lr = 0.0101459
I0605 17:33:47.003296   904 solver.cpp:229] Iteration 126920, loss = 2.30427
I0605 17:33:47.003342   904 solver.cpp:245]     Train net output #0: loss = 2.40216 (* 1 = 2.40216 loss)
I0605 17:33:47.003355   904 sgd_solver.cpp:106] Iteration 126920, lr = 0.0101365
I0605 17:34:07.619428   904 solver.cpp:229] Iteration 126960, loss = 2.3417
I0605 17:34:07.619717   904 solver.cpp:245]     Train net output #0: loss = 2.3963 (* 1 = 2.3963 loss)
I0605 17:34:07.619741   904 sgd_solver.cpp:106] Iteration 126960, lr = 0.0101271
I0605 17:34:27.607278   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_127000.caffemodel
I0605 17:34:27.875180   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_127000.solverstate
I0605 17:34:27.950276   904 solver.cpp:338] Iteration 127000, Testing net (#0)
I0605 17:34:27.950366   904 net.cpp:748] Ignoring source layer loss
I0605 17:34:32.367890   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 17:35:06.253479   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 17:35:36.588590   904 solver.cpp:406]     Test net output #0: accuracy = 0.473901
I0605 17:35:36.588794   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.72024
I0605 17:35:36.905046   904 solver.cpp:229] Iteration 127000, loss = 2.33971
I0605 17:35:36.905094   904 solver.cpp:245]     Train net output #0: loss = 2.43277 (* 1 = 2.43277 loss)
I0605 17:35:36.905107   904 sgd_solver.cpp:106] Iteration 127000, lr = 0.0101176
I0605 17:35:56.172360   904 solver.cpp:229] Iteration 127040, loss = 2.31755
I0605 17:35:56.172420   904 solver.cpp:245]     Train net output #0: loss = 2.16413 (* 1 = 2.16413 loss)
I0605 17:35:56.172430   904 sgd_solver.cpp:106] Iteration 127040, lr = 0.0101082
I0605 17:36:12.333478   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 17:36:17.717545   904 solver.cpp:229] Iteration 127080, loss = 2.35479
I0605 17:36:17.717597   904 solver.cpp:245]     Train net output #0: loss = 2.4673 (* 1 = 2.4673 loss)
I0605 17:36:17.717607   904 sgd_solver.cpp:106] Iteration 127080, lr = 0.0100988
I0605 17:36:39.260138   904 solver.cpp:229] Iteration 127120, loss = 2.31952
I0605 17:36:39.260191   904 solver.cpp:245]     Train net output #0: loss = 2.15433 (* 1 = 2.15433 loss)
I0605 17:36:39.260205   904 sgd_solver.cpp:106] Iteration 127120, lr = 0.0100894
I0605 17:37:00.710533   904 solver.cpp:229] Iteration 127160, loss = 2.3186
I0605 17:37:00.710757   904 solver.cpp:245]     Train net output #0: loss = 2.15956 (* 1 = 2.15956 loss)
I0605 17:37:00.710769   904 sgd_solver.cpp:106] Iteration 127160, lr = 0.01008
I0605 17:37:21.853373   904 solver.cpp:229] Iteration 127200, loss = 2.32446
I0605 17:37:21.853421   904 solver.cpp:245]     Train net output #0: loss = 2.39953 (* 1 = 2.39953 loss)
I0605 17:37:21.853431   904 sgd_solver.cpp:106] Iteration 127200, lr = 0.0100706
I0605 17:37:42.861063   904 solver.cpp:229] Iteration 127240, loss = 2.32239
I0605 17:37:42.861312   904 solver.cpp:245]     Train net output #0: loss = 2.11802 (* 1 = 2.11802 loss)
I0605 17:37:42.861337   904 sgd_solver.cpp:106] Iteration 127240, lr = 0.0100612
I0605 17:38:03.843245   904 solver.cpp:229] Iteration 127280, loss = 2.3343
I0605 17:38:03.843296   904 solver.cpp:245]     Train net output #0: loss = 2.33148 (* 1 = 2.33148 loss)
I0605 17:38:03.843303   904 sgd_solver.cpp:106] Iteration 127280, lr = 0.0100518
I0605 17:38:24.824486   904 solver.cpp:229] Iteration 127320, loss = 2.30807
I0605 17:38:24.824689   904 solver.cpp:245]     Train net output #0: loss = 2.44163 (* 1 = 2.44163 loss)
I0605 17:38:24.824715   904 sgd_solver.cpp:106] Iteration 127320, lr = 0.0100424
I0605 17:38:45.809753   904 solver.cpp:229] Iteration 127360, loss = 2.35076
I0605 17:38:45.809806   904 solver.cpp:245]     Train net output #0: loss = 2.45258 (* 1 = 2.45258 loss)
I0605 17:38:45.809819   904 sgd_solver.cpp:106] Iteration 127360, lr = 0.0100329
I0605 17:39:06.707917   904 solver.cpp:229] Iteration 127400, loss = 2.3425
I0605 17:39:06.708062   904 solver.cpp:245]     Train net output #0: loss = 2.51409 (* 1 = 2.51409 loss)
I0605 17:39:06.708073   904 sgd_solver.cpp:106] Iteration 127400, lr = 0.0100235
I0605 17:39:27.482713   904 solver.cpp:229] Iteration 127440, loss = 2.32103
I0605 17:39:27.482769   904 solver.cpp:245]     Train net output #0: loss = 2.22306 (* 1 = 2.22306 loss)
I0605 17:39:27.482779   904 sgd_solver.cpp:106] Iteration 127440, lr = 0.0100141
I0605 17:39:48.156729   904 solver.cpp:229] Iteration 127480, loss = 2.31191
I0605 17:39:48.157003   904 solver.cpp:245]     Train net output #0: loss = 2.40256 (* 1 = 2.40256 loss)
I0605 17:39:48.157032   904 sgd_solver.cpp:106] Iteration 127480, lr = 0.0100047
I0605 17:40:08.829222   904 solver.cpp:229] Iteration 127520, loss = 2.3618
I0605 17:40:08.829280   904 solver.cpp:245]     Train net output #0: loss = 2.31061 (* 1 = 2.31061 loss)
I0605 17:40:08.829291   904 sgd_solver.cpp:106] Iteration 127520, lr = 0.00999529
I0605 17:40:29.496808   904 solver.cpp:229] Iteration 127560, loss = 2.34209
I0605 17:40:29.497104   904 solver.cpp:245]     Train net output #0: loss = 2.6521 (* 1 = 2.6521 loss)
I0605 17:40:29.497130   904 sgd_solver.cpp:106] Iteration 127560, lr = 0.00998588
I0605 17:40:41.902447   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 17:40:50.165417   904 solver.cpp:229] Iteration 127600, loss = 2.34584
I0605 17:40:50.165463   904 solver.cpp:245]     Train net output #0: loss = 2.36909 (* 1 = 2.36909 loss)
I0605 17:40:50.165475   904 sgd_solver.cpp:106] Iteration 127600, lr = 0.00997647
I0605 17:41:10.800863   904 solver.cpp:229] Iteration 127640, loss = 2.35805
I0605 17:41:10.801085   904 solver.cpp:245]     Train net output #0: loss = 2.21932 (* 1 = 2.21932 loss)
I0605 17:41:10.801112   904 sgd_solver.cpp:106] Iteration 127640, lr = 0.00996706
I0605 17:41:31.266693   904 solver.cpp:229] Iteration 127680, loss = 2.35207
I0605 17:41:31.266752   904 solver.cpp:245]     Train net output #0: loss = 2.37577 (* 1 = 2.37577 loss)
I0605 17:41:31.266763   904 sgd_solver.cpp:106] Iteration 127680, lr = 0.00995765
I0605 17:41:51.753190   904 solver.cpp:229] Iteration 127720, loss = 2.35463
I0605 17:41:51.753398   904 solver.cpp:245]     Train net output #0: loss = 2.56421 (* 1 = 2.56421 loss)
I0605 17:41:51.753420   904 sgd_solver.cpp:106] Iteration 127720, lr = 0.00994823
I0605 17:42:12.345473   904 solver.cpp:229] Iteration 127760, loss = 2.31971
I0605 17:42:12.345521   904 solver.cpp:245]     Train net output #0: loss = 2.32003 (* 1 = 2.32003 loss)
I0605 17:42:12.345541   904 sgd_solver.cpp:106] Iteration 127760, lr = 0.00993882
I0605 17:42:32.928573   904 solver.cpp:229] Iteration 127800, loss = 2.35201
I0605 17:42:32.928750   904 solver.cpp:245]     Train net output #0: loss = 2.20688 (* 1 = 2.20688 loss)
I0605 17:42:32.928761   904 sgd_solver.cpp:106] Iteration 127800, lr = 0.00992941
I0605 17:42:53.430665   904 solver.cpp:229] Iteration 127840, loss = 2.32839
I0605 17:42:53.430717   904 solver.cpp:245]     Train net output #0: loss = 2.48021 (* 1 = 2.48021 loss)
I0605 17:42:53.430729   904 sgd_solver.cpp:106] Iteration 127840, lr = 0.00992
I0605 17:43:13.927713   904 solver.cpp:229] Iteration 127880, loss = 2.34174
I0605 17:43:13.927916   904 solver.cpp:245]     Train net output #0: loss = 2.59195 (* 1 = 2.59195 loss)
I0605 17:43:13.927943   904 sgd_solver.cpp:106] Iteration 127880, lr = 0.00991059
I0605 17:43:34.452597   904 solver.cpp:229] Iteration 127920, loss = 2.35786
I0605 17:43:34.452652   904 solver.cpp:245]     Train net output #0: loss = 2.18433 (* 1 = 2.18433 loss)
I0605 17:43:34.452662   904 sgd_solver.cpp:106] Iteration 127920, lr = 0.00990118
I0605 17:43:54.951639   904 solver.cpp:229] Iteration 127960, loss = 2.33667
I0605 17:43:54.951828   904 solver.cpp:245]     Train net output #0: loss = 2.47695 (* 1 = 2.47695 loss)
I0605 17:43:54.951839   904 sgd_solver.cpp:106] Iteration 127960, lr = 0.00989177
I0605 17:44:14.954224   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_128000.caffemodel
I0605 17:44:15.220036   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_128000.solverstate
I0605 17:44:15.294052   904 solver.cpp:338] Iteration 128000, Testing net (#0)
I0605 17:44:15.294127   904 net.cpp:748] Ignoring source layer loss
I0605 17:44:22.182394   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 17:44:57.029326   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 17:45:25.930024   904 solver.cpp:406]     Test net output #0: accuracy = 0.467721
I0605 17:45:25.930063   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.71758
I0605 17:45:26.244451   904 solver.cpp:229] Iteration 128000, loss = 2.34073
I0605 17:45:26.244498   904 solver.cpp:245]     Train net output #0: loss = 2.39159 (* 1 = 2.39159 loss)
I0605 17:45:26.244508   904 sgd_solver.cpp:106] Iteration 128000, lr = 0.00988235
I0605 17:45:45.423125   904 solver.cpp:229] Iteration 128040, loss = 2.31932
I0605 17:45:45.423382   904 solver.cpp:245]     Train net output #0: loss = 2.34813 (* 1 = 2.34813 loss)
I0605 17:45:45.423409   904 sgd_solver.cpp:106] Iteration 128040, lr = 0.00987294
I0605 17:46:06.852862   904 solver.cpp:229] Iteration 128080, loss = 2.363
I0605 17:46:06.852910   904 solver.cpp:245]     Train net output #0: loss = 2.56614 (* 1 = 2.56614 loss)
I0605 17:46:06.852921   904 sgd_solver.cpp:106] Iteration 128080, lr = 0.00986353
I0605 17:46:19.197865   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 17:46:28.218030   904 solver.cpp:229] Iteration 128120, loss = 2.33758
I0605 17:46:28.218081   904 solver.cpp:245]     Train net output #0: loss = 2.38918 (* 1 = 2.38918 loss)
I0605 17:46:28.218101   904 sgd_solver.cpp:106] Iteration 128120, lr = 0.00985412
I0605 17:46:49.130173   904 solver.cpp:229] Iteration 128160, loss = 2.33408
I0605 17:46:49.130218   904 solver.cpp:245]     Train net output #0: loss = 2.4416 (* 1 = 2.4416 loss)
I0605 17:46:49.130228   904 sgd_solver.cpp:106] Iteration 128160, lr = 0.00984471
I0605 17:47:10.044291   904 solver.cpp:229] Iteration 128200, loss = 2.33029
I0605 17:47:10.044575   904 solver.cpp:245]     Train net output #0: loss = 2.2211 (* 1 = 2.2211 loss)
I0605 17:47:10.044605   904 sgd_solver.cpp:106] Iteration 128200, lr = 0.00983529
I0605 17:47:30.965806   904 solver.cpp:229] Iteration 128240, loss = 2.32916
I0605 17:47:30.965847   904 solver.cpp:245]     Train net output #0: loss = 2.18088 (* 1 = 2.18088 loss)
I0605 17:47:30.965858   904 sgd_solver.cpp:106] Iteration 128240, lr = 0.00982588
I0605 17:47:51.871973   904 solver.cpp:229] Iteration 128280, loss = 2.35132
I0605 17:47:51.872118   904 solver.cpp:245]     Train net output #0: loss = 2.15193 (* 1 = 2.15193 loss)
I0605 17:47:51.872128   904 sgd_solver.cpp:106] Iteration 128280, lr = 0.00981647
I0605 17:48:12.494374   904 solver.cpp:229] Iteration 128320, loss = 2.30724
I0605 17:48:12.494437   904 solver.cpp:245]     Train net output #0: loss = 2.25481 (* 1 = 2.25481 loss)
I0605 17:48:12.494453   904 sgd_solver.cpp:106] Iteration 128320, lr = 0.00980706
I0605 17:48:33.089478   904 solver.cpp:229] Iteration 128360, loss = 2.37281
I0605 17:48:33.089645   904 solver.cpp:245]     Train net output #0: loss = 2.35609 (* 1 = 2.35609 loss)
I0605 17:48:33.089658   904 sgd_solver.cpp:106] Iteration 128360, lr = 0.00979765
I0605 17:48:53.707414   904 solver.cpp:229] Iteration 128400, loss = 2.32619
I0605 17:48:53.707463   904 solver.cpp:245]     Train net output #0: loss = 2.26793 (* 1 = 2.26793 loss)
I0605 17:48:53.707473   904 sgd_solver.cpp:106] Iteration 128400, lr = 0.00978823
I0605 17:49:14.298085   904 solver.cpp:229] Iteration 128440, loss = 2.30767
I0605 17:49:14.298373   904 solver.cpp:245]     Train net output #0: loss = 2.25854 (* 1 = 2.25854 loss)
I0605 17:49:14.298399   904 sgd_solver.cpp:106] Iteration 128440, lr = 0.00977882
I0605 17:49:34.836532   904 solver.cpp:229] Iteration 128480, loss = 2.30536
I0605 17:49:34.836612   904 solver.cpp:245]     Train net output #0: loss = 2.10824 (* 1 = 2.10824 loss)
I0605 17:49:34.836624   904 sgd_solver.cpp:106] Iteration 128480, lr = 0.00976941
I0605 17:49:55.582427   904 solver.cpp:229] Iteration 128520, loss = 2.30603
I0605 17:49:55.582659   904 solver.cpp:245]     Train net output #0: loss = 2.65842 (* 1 = 2.65842 loss)
I0605 17:49:55.582685   904 sgd_solver.cpp:106] Iteration 128520, lr = 0.00976
I0605 17:50:16.103268   904 solver.cpp:229] Iteration 128560, loss = 2.31018
I0605 17:50:16.103308   904 solver.cpp:245]     Train net output #0: loss = 2.2481 (* 1 = 2.2481 loss)
I0605 17:50:16.103317   904 sgd_solver.cpp:106] Iteration 128560, lr = 0.00975059
I0605 17:50:36.737865   904 solver.cpp:229] Iteration 128600, loss = 2.31344
I0605 17:50:36.738142   904 solver.cpp:245]     Train net output #0: loss = 2.25517 (* 1 = 2.25517 loss)
I0605 17:50:36.738158   904 sgd_solver.cpp:106] Iteration 128600, lr = 0.00974118
I0605 17:50:54.108212   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 17:50:57.167964   904 solver.cpp:229] Iteration 128640, loss = 2.26945
I0605 17:50:57.168020   904 solver.cpp:245]     Train net output #0: loss = 2.3928 (* 1 = 2.3928 loss)
I0605 17:50:57.168030   904 sgd_solver.cpp:106] Iteration 128640, lr = 0.00973176
I0605 17:51:17.909426   904 solver.cpp:229] Iteration 128680, loss = 2.31908
I0605 17:51:17.909644   904 solver.cpp:245]     Train net output #0: loss = 2.08032 (* 1 = 2.08032 loss)
I0605 17:51:17.909670   904 sgd_solver.cpp:106] Iteration 128680, lr = 0.00972235
I0605 17:51:38.197023   904 solver.cpp:229] Iteration 128720, loss = 2.32228
I0605 17:51:38.197068   904 solver.cpp:245]     Train net output #0: loss = 2.14393 (* 1 = 2.14393 loss)
I0605 17:51:38.197079   904 sgd_solver.cpp:106] Iteration 128720, lr = 0.00971294
I0605 17:51:58.640735   904 solver.cpp:229] Iteration 128760, loss = 2.326
I0605 17:51:58.640971   904 solver.cpp:245]     Train net output #0: loss = 2.37473 (* 1 = 2.37473 loss)
I0605 17:51:58.640992   904 sgd_solver.cpp:106] Iteration 128760, lr = 0.00970353
I0605 17:52:19.066239   904 solver.cpp:229] Iteration 128800, loss = 2.3219
I0605 17:52:19.066301   904 solver.cpp:245]     Train net output #0: loss = 2.41473 (* 1 = 2.41473 loss)
I0605 17:52:19.066313   904 sgd_solver.cpp:106] Iteration 128800, lr = 0.00969412
I0605 17:52:39.285560   904 solver.cpp:229] Iteration 128840, loss = 2.29969
I0605 17:52:39.285758   904 solver.cpp:245]     Train net output #0: loss = 2.563 (* 1 = 2.563 loss)
I0605 17:52:39.285773   904 sgd_solver.cpp:106] Iteration 128840, lr = 0.00968471
I0605 17:52:59.523669   904 solver.cpp:229] Iteration 128880, loss = 2.32836
I0605 17:52:59.523718   904 solver.cpp:245]     Train net output #0: loss = 2.4367 (* 1 = 2.4367 loss)
I0605 17:52:59.523728   904 sgd_solver.cpp:106] Iteration 128880, lr = 0.00967529
I0605 17:53:19.768044   904 solver.cpp:229] Iteration 128920, loss = 2.30941
I0605 17:53:19.768251   904 solver.cpp:245]     Train net output #0: loss = 2.41022 (* 1 = 2.41022 loss)
I0605 17:53:19.768276   904 sgd_solver.cpp:106] Iteration 128920, lr = 0.00966588
I0605 17:53:40.118515   904 solver.cpp:229] Iteration 128960, loss = 2.3484
I0605 17:53:40.118571   904 solver.cpp:245]     Train net output #0: loss = 2.16983 (* 1 = 2.16983 loss)
I0605 17:53:40.118582   904 sgd_solver.cpp:106] Iteration 128960, lr = 0.00965647
I0605 17:53:59.829113   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_129000.caffemodel
I0605 17:54:00.090579   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_129000.solverstate
I0605 17:54:00.169219   904 solver.cpp:338] Iteration 129000, Testing net (#0)
I0605 17:54:00.169293   904 net.cpp:748] Ignoring source layer loss
I0605 17:54:10.605304   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 17:54:45.788767   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 17:55:10.478579   904 solver.cpp:406]     Test net output #0: accuracy = 0.47206
I0605 17:55:10.478632   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.721919
I0605 17:55:10.795186   904 solver.cpp:229] Iteration 129000, loss = 2.33119
I0605 17:55:10.795229   904 solver.cpp:245]     Train net output #0: loss = 2.50888 (* 1 = 2.50888 loss)
I0605 17:55:10.795239   904 sgd_solver.cpp:106] Iteration 129000, lr = 0.00964706
I0605 17:55:29.983785   904 solver.cpp:229] Iteration 129040, loss = 2.36446
I0605 17:55:29.984174   904 solver.cpp:245]     Train net output #0: loss = 2.19173 (* 1 = 2.19173 loss)
I0605 17:55:29.984192   904 sgd_solver.cpp:106] Iteration 129040, lr = 0.00963765
I0605 17:55:51.400641   904 solver.cpp:229] Iteration 129080, loss = 2.33506
I0605 17:55:51.400699   904 solver.cpp:245]     Train net output #0: loss = 2.66111 (* 1 = 2.66111 loss)
I0605 17:55:51.400709   904 sgd_solver.cpp:106] Iteration 129080, lr = 0.00962824
I0605 17:56:12.895912   904 solver.cpp:229] Iteration 129120, loss = 2.30806
I0605 17:56:12.896139   904 solver.cpp:245]     Train net output #0: loss = 2.09709 (* 1 = 2.09709 loss)
I0605 17:56:12.896152   904 sgd_solver.cpp:106] Iteration 129120, lr = 0.00961882
I0605 17:56:28.720149   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 17:56:33.962437   904 solver.cpp:229] Iteration 129160, loss = 2.34459
I0605 17:56:33.962489   904 solver.cpp:245]     Train net output #0: loss = 2.35733 (* 1 = 2.35733 loss)
I0605 17:56:33.962498   904 sgd_solver.cpp:106] Iteration 129160, lr = 0.00960941
I0605 17:56:54.960149   904 solver.cpp:229] Iteration 129200, loss = 2.34964
I0605 17:56:54.960321   904 solver.cpp:245]     Train net output #0: loss = 2.07978 (* 1 = 2.07978 loss)
I0605 17:56:54.960332   904 sgd_solver.cpp:106] Iteration 129200, lr = 0.0096
I0605 17:57:15.950788   904 solver.cpp:229] Iteration 129240, loss = 2.33578
I0605 17:57:15.950839   904 solver.cpp:245]     Train net output #0: loss = 2.18674 (* 1 = 2.18674 loss)
I0605 17:57:15.950848   904 sgd_solver.cpp:106] Iteration 129240, lr = 0.00959059
I0605 17:57:36.930124   904 solver.cpp:229] Iteration 129280, loss = 2.33359
I0605 17:57:36.930327   904 solver.cpp:245]     Train net output #0: loss = 2.35104 (* 1 = 2.35104 loss)
I0605 17:57:36.930353   904 sgd_solver.cpp:106] Iteration 129280, lr = 0.00958118
I0605 17:57:57.918118   904 solver.cpp:229] Iteration 129320, loss = 2.32273
I0605 17:57:57.918197   904 solver.cpp:245]     Train net output #0: loss = 2.09101 (* 1 = 2.09101 loss)
I0605 17:57:57.918208   904 sgd_solver.cpp:106] Iteration 129320, lr = 0.00957176
I0605 17:58:18.788478   904 solver.cpp:229] Iteration 129360, loss = 2.28724
I0605 17:58:18.788715   904 solver.cpp:245]     Train net output #0: loss = 2.31485 (* 1 = 2.31485 loss)
I0605 17:58:18.788741   904 sgd_solver.cpp:106] Iteration 129360, lr = 0.00956235
I0605 17:58:39.487921   904 solver.cpp:229] Iteration 129400, loss = 2.31943
I0605 17:58:39.487970   904 solver.cpp:245]     Train net output #0: loss = 2.33363 (* 1 = 2.33363 loss)
I0605 17:58:39.487982   904 sgd_solver.cpp:106] Iteration 129400, lr = 0.00955294
I0605 17:59:00.185276   904 solver.cpp:229] Iteration 129440, loss = 2.27072
I0605 17:59:00.185487   904 solver.cpp:245]     Train net output #0: loss = 2.22149 (* 1 = 2.22149 loss)
I0605 17:59:00.185503   904 sgd_solver.cpp:106] Iteration 129440, lr = 0.00954353
I0605 17:59:20.865625   904 solver.cpp:229] Iteration 129480, loss = 2.3481
I0605 17:59:20.865681   904 solver.cpp:245]     Train net output #0: loss = 2.41524 (* 1 = 2.41524 loss)
I0605 17:59:20.865692   904 sgd_solver.cpp:106] Iteration 129480, lr = 0.00953412
I0605 17:59:41.549726   904 solver.cpp:229] Iteration 129520, loss = 2.30247
I0605 17:59:41.549971   904 solver.cpp:245]     Train net output #0: loss = 2.50676 (* 1 = 2.50676 loss)
I0605 17:59:41.549998   904 sgd_solver.cpp:106] Iteration 129520, lr = 0.0095247
I0605 18:00:02.219548   904 solver.cpp:229] Iteration 129560, loss = 2.28214
I0605 18:00:02.219597   904 solver.cpp:245]     Train net output #0: loss = 2.42587 (* 1 = 2.42587 loss)
I0605 18:00:02.219610   904 sgd_solver.cpp:106] Iteration 129560, lr = 0.00951529
I0605 18:00:22.901831   904 solver.cpp:229] Iteration 129600, loss = 2.31066
I0605 18:00:22.902058   904 solver.cpp:245]     Train net output #0: loss = 2.2254 (* 1 = 2.2254 loss)
I0605 18:00:22.902086   904 sgd_solver.cpp:106] Iteration 129600, lr = 0.00950588
I0605 18:00:43.559031   904 solver.cpp:229] Iteration 129640, loss = 2.28966
I0605 18:00:43.559074   904 solver.cpp:245]     Train net output #0: loss = 2.23279 (* 1 = 2.23279 loss)
I0605 18:00:43.559084   904 sgd_solver.cpp:106] Iteration 129640, lr = 0.00949647
I0605 18:00:53.122087   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 18:01:04.234144   904 solver.cpp:229] Iteration 129680, loss = 2.29979
I0605 18:01:04.234207   904 solver.cpp:245]     Train net output #0: loss = 2.39444 (* 1 = 2.39444 loss)
I0605 18:01:04.234220   904 sgd_solver.cpp:106] Iteration 129680, lr = 0.00948706
I0605 18:01:24.815732   904 solver.cpp:229] Iteration 129720, loss = 2.333
I0605 18:01:24.815999   904 solver.cpp:245]     Train net output #0: loss = 2.28769 (* 1 = 2.28769 loss)
I0605 18:01:24.816026   904 sgd_solver.cpp:106] Iteration 129720, lr = 0.00947765
I0605 18:01:45.266031   904 solver.cpp:229] Iteration 129760, loss = 2.29451
I0605 18:01:45.266104   904 solver.cpp:245]     Train net output #0: loss = 2.5152 (* 1 = 2.5152 loss)
I0605 18:01:45.266116   904 sgd_solver.cpp:106] Iteration 129760, lr = 0.00946824
I0605 18:02:05.743182   904 solver.cpp:229] Iteration 129800, loss = 2.33507
I0605 18:02:05.743458   904 solver.cpp:245]     Train net output #0: loss = 2.17277 (* 1 = 2.17277 loss)
I0605 18:02:05.743486   904 sgd_solver.cpp:106] Iteration 129800, lr = 0.00945882
I0605 18:02:26.068178   904 solver.cpp:229] Iteration 129840, loss = 2.31383
I0605 18:02:26.068238   904 solver.cpp:245]     Train net output #0: loss = 2.28929 (* 1 = 2.28929 loss)
I0605 18:02:26.068249   904 sgd_solver.cpp:106] Iteration 129840, lr = 0.00944941
I0605 18:02:46.198418   904 solver.cpp:229] Iteration 129880, loss = 2.34755
I0605 18:02:46.198676   904 solver.cpp:245]     Train net output #0: loss = 2.68118 (* 1 = 2.68118 loss)
I0605 18:02:46.198701   904 sgd_solver.cpp:106] Iteration 129880, lr = 0.00944
I0605 18:03:06.329249   904 solver.cpp:229] Iteration 129920, loss = 2.32142
I0605 18:03:06.329318   904 solver.cpp:245]     Train net output #0: loss = 2.23097 (* 1 = 2.23097 loss)
I0605 18:03:06.329326   904 sgd_solver.cpp:106] Iteration 129920, lr = 0.00943059
I0605 18:03:26.462052   904 solver.cpp:229] Iteration 129960, loss = 2.26911
I0605 18:03:26.462296   904 solver.cpp:245]     Train net output #0: loss = 2.38252 (* 1 = 2.38252 loss)
I0605 18:03:26.462327   904 sgd_solver.cpp:106] Iteration 129960, lr = 0.00942118
I0605 18:03:46.111315   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_130000.caffemodel
I0605 18:03:46.368927   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_130000.solverstate
I0605 18:03:46.444200   904 solver.cpp:338] Iteration 130000, Testing net (#0)
I0605 18:03:46.444272   904 net.cpp:748] Ignoring source layer loss
I0605 18:03:59.354794   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 18:04:34.230402   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 18:04:57.653852   904 solver.cpp:406]     Test net output #0: accuracy = 0.4852
I0605 18:04:57.653897   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.73148
I0605 18:04:57.967980   904 solver.cpp:229] Iteration 130000, loss = 2.30184
I0605 18:04:57.968025   904 solver.cpp:245]     Train net output #0: loss = 2.21458 (* 1 = 2.21458 loss)
I0605 18:04:57.968036   904 sgd_solver.cpp:106] Iteration 130000, lr = 0.00941176
I0605 18:05:17.155119   904 solver.cpp:229] Iteration 130040, loss = 2.31806
I0605 18:05:17.155323   904 solver.cpp:245]     Train net output #0: loss = 2.5174 (* 1 = 2.5174 loss)
I0605 18:05:17.155345   904 sgd_solver.cpp:106] Iteration 130040, lr = 0.00940235
I0605 18:05:38.460392   904 solver.cpp:229] Iteration 130080, loss = 2.32232
I0605 18:05:38.460450   904 solver.cpp:245]     Train net output #0: loss = 2.188 (* 1 = 2.188 loss)
I0605 18:05:38.460461   904 sgd_solver.cpp:106] Iteration 130080, lr = 0.00939294
I0605 18:05:59.843971   904 solver.cpp:229] Iteration 130120, loss = 2.34114
I0605 18:05:59.844255   904 solver.cpp:245]     Train net output #0: loss = 2.32341 (* 1 = 2.32341 loss)
I0605 18:05:59.844282   904 sgd_solver.cpp:106] Iteration 130120, lr = 0.00938353
I0605 18:06:20.825160   904 solver.cpp:229] Iteration 130160, loss = 2.33108
I0605 18:06:20.825207   904 solver.cpp:245]     Train net output #0: loss = 2.25612 (* 1 = 2.25612 loss)
I0605 18:06:20.825217   904 sgd_solver.cpp:106] Iteration 130160, lr = 0.00937412
I0605 18:06:41.803580   904 solver.cpp:229] Iteration 130200, loss = 2.30202
I0605 18:06:41.803843   904 solver.cpp:245]     Train net output #0: loss = 2.47115 (* 1 = 2.47115 loss)
I0605 18:06:41.803854   904 sgd_solver.cpp:106] Iteration 130200, lr = 0.0093647
I0605 18:06:42.331230   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 18:07:02.792811   904 solver.cpp:229] Iteration 130240, loss = 2.29443
I0605 18:07:02.792870   904 solver.cpp:245]     Train net output #0: loss = 2.3774 (* 1 = 2.3774 loss)
I0605 18:07:02.792891   904 sgd_solver.cpp:106] Iteration 130240, lr = 0.00935529
I0605 18:07:23.856075   904 solver.cpp:229] Iteration 130280, loss = 2.29778
I0605 18:07:23.856287   904 solver.cpp:245]     Train net output #0: loss = 2.33596 (* 1 = 2.33596 loss)
I0605 18:07:23.856313   904 sgd_solver.cpp:106] Iteration 130280, lr = 0.00934588
I0605 18:07:44.807492   904 solver.cpp:229] Iteration 130320, loss = 2.32425
I0605 18:07:44.807534   904 solver.cpp:245]     Train net output #0: loss = 2.24739 (* 1 = 2.24739 loss)
I0605 18:07:44.807544   904 sgd_solver.cpp:106] Iteration 130320, lr = 0.00933647
I0605 18:08:05.607215   904 solver.cpp:229] Iteration 130360, loss = 2.30519
I0605 18:08:05.607445   904 solver.cpp:245]     Train net output #0: loss = 1.89005 (* 1 = 1.89005 loss)
I0605 18:08:05.607465   904 sgd_solver.cpp:106] Iteration 130360, lr = 0.00932706
I0605 18:08:26.360117   904 solver.cpp:229] Iteration 130400, loss = 2.3426
I0605 18:08:26.360164   904 solver.cpp:245]     Train net output #0: loss = 2.50194 (* 1 = 2.50194 loss)
I0605 18:08:26.360180   904 sgd_solver.cpp:106] Iteration 130400, lr = 0.00931765
I0605 18:08:47.115089   904 solver.cpp:229] Iteration 130440, loss = 2.32582
I0605 18:08:47.115310   904 solver.cpp:245]     Train net output #0: loss = 2.19911 (* 1 = 2.19911 loss)
I0605 18:08:47.115332   904 sgd_solver.cpp:106] Iteration 130440, lr = 0.00930824
I0605 18:09:07.923765   904 solver.cpp:229] Iteration 130480, loss = 2.31397
I0605 18:09:07.923820   904 solver.cpp:245]     Train net output #0: loss = 2.32957 (* 1 = 2.32957 loss)
I0605 18:09:07.923830   904 sgd_solver.cpp:106] Iteration 130480, lr = 0.00929882
I0605 18:09:28.598531   904 solver.cpp:229] Iteration 130520, loss = 2.29766
I0605 18:09:28.598755   904 solver.cpp:245]     Train net output #0: loss = 2.37972 (* 1 = 2.37972 loss)
I0605 18:09:28.598793   904 sgd_solver.cpp:106] Iteration 130520, lr = 0.00928941
I0605 18:09:49.276659   904 solver.cpp:229] Iteration 130560, loss = 2.31871
I0605 18:09:49.276727   904 solver.cpp:245]     Train net output #0: loss = 2.17581 (* 1 = 2.17581 loss)
I0605 18:09:49.276736   904 sgd_solver.cpp:106] Iteration 130560, lr = 0.00928
I0605 18:10:09.908732   904 solver.cpp:229] Iteration 130600, loss = 2.35536
I0605 18:10:09.909015   904 solver.cpp:245]     Train net output #0: loss = 2.25306 (* 1 = 2.25306 loss)
I0605 18:10:09.909039   904 sgd_solver.cpp:106] Iteration 130600, lr = 0.00927059
I0605 18:10:30.357496   904 solver.cpp:229] Iteration 130640, loss = 2.30667
I0605 18:10:30.357550   904 solver.cpp:245]     Train net output #0: loss = 2.30095 (* 1 = 2.30095 loss)
I0605 18:10:30.357559   904 sgd_solver.cpp:106] Iteration 130640, lr = 0.00926118
I0605 18:10:51.023607   904 solver.cpp:229] Iteration 130680, loss = 2.29694
I0605 18:10:51.023947   904 solver.cpp:245]     Train net output #0: loss = 2.29426 (* 1 = 2.29426 loss)
I0605 18:10:51.023983   904 sgd_solver.cpp:106] Iteration 130680, lr = 0.00925176
I0605 18:11:11.585283   904 solver.cpp:229] Iteration 130720, loss = 2.30752
I0605 18:11:11.585331   904 solver.cpp:245]     Train net output #0: loss = 2.37618 (* 1 = 2.37618 loss)
I0605 18:11:11.585342   904 sgd_solver.cpp:106] Iteration 130720, lr = 0.00924235
I0605 18:11:12.100608   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 18:11:32.127439   904 solver.cpp:229] Iteration 130760, loss = 2.33653
I0605 18:11:32.127691   904 solver.cpp:245]     Train net output #0: loss = 2.4447 (* 1 = 2.4447 loss)
I0605 18:11:32.127701   904 sgd_solver.cpp:106] Iteration 130760, lr = 0.00923294
I0605 18:11:52.664279   904 solver.cpp:229] Iteration 130800, loss = 2.32089
I0605 18:11:52.664333   904 solver.cpp:245]     Train net output #0: loss = 2.1768 (* 1 = 2.1768 loss)
I0605 18:11:52.664345   904 sgd_solver.cpp:106] Iteration 130800, lr = 0.00922353
I0605 18:12:13.192193   904 solver.cpp:229] Iteration 130840, loss = 2.29869
I0605 18:12:13.192420   904 solver.cpp:245]     Train net output #0: loss = 2.24912 (* 1 = 2.24912 loss)
I0605 18:12:13.192445   904 sgd_solver.cpp:106] Iteration 130840, lr = 0.00921412
I0605 18:12:33.717440   904 solver.cpp:229] Iteration 130880, loss = 2.3564
I0605 18:12:33.717492   904 solver.cpp:245]     Train net output #0: loss = 2.28979 (* 1 = 2.28979 loss)
I0605 18:12:33.717504   904 sgd_solver.cpp:106] Iteration 130880, lr = 0.0092047
I0605 18:12:54.244704   904 solver.cpp:229] Iteration 130920, loss = 2.29678
I0605 18:12:54.244910   904 solver.cpp:245]     Train net output #0: loss = 2.09431 (* 1 = 2.09431 loss)
I0605 18:12:54.244945   904 sgd_solver.cpp:106] Iteration 130920, lr = 0.00919529
I0605 18:13:14.804014   904 solver.cpp:229] Iteration 130960, loss = 2.30758
I0605 18:13:14.804055   904 solver.cpp:245]     Train net output #0: loss = 2.03816 (* 1 = 2.03816 loss)
I0605 18:13:14.804064   904 sgd_solver.cpp:106] Iteration 130960, lr = 0.00918588
I0605 18:13:34.807622   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_131000.caffemodel
I0605 18:13:35.071014   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_131000.solverstate
I0605 18:13:35.154482   904 solver.cpp:338] Iteration 131000, Testing net (#0)
I0605 18:13:35.154556   904 net.cpp:748] Ignoring source layer loss
I0605 18:13:51.614095   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 18:14:24.952412   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 18:14:41.899106   904 solver.cpp:406]     Test net output #0: accuracy = 0.47696
I0605 18:14:41.899147   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.725119
I0605 18:14:42.216207   904 solver.cpp:229] Iteration 131000, loss = 2.281
I0605 18:14:42.216248   904 solver.cpp:245]     Train net output #0: loss = 2.53532 (* 1 = 2.53532 loss)
I0605 18:14:42.216258   904 sgd_solver.cpp:106] Iteration 131000, lr = 0.00917647
I0605 18:15:01.464601   904 solver.cpp:229] Iteration 131040, loss = 2.28283
I0605 18:15:01.464869   904 solver.cpp:245]     Train net output #0: loss = 2.47868 (* 1 = 2.47868 loss)
I0605 18:15:01.464898   904 sgd_solver.cpp:106] Iteration 131040, lr = 0.00916706
I0605 18:15:22.918220   904 solver.cpp:229] Iteration 131080, loss = 2.27857
I0605 18:15:22.918261   904 solver.cpp:245]     Train net output #0: loss = 2.38651 (* 1 = 2.38651 loss)
I0605 18:15:22.918282   904 sgd_solver.cpp:106] Iteration 131080, lr = 0.00915765
I0605 18:15:44.367290   904 solver.cpp:229] Iteration 131120, loss = 2.27098
I0605 18:15:44.367480   904 solver.cpp:245]     Train net output #0: loss = 1.97524 (* 1 = 1.97524 loss)
I0605 18:15:44.367494   904 sgd_solver.cpp:106] Iteration 131120, lr = 0.00914824
I0605 18:16:05.406340   904 solver.cpp:229] Iteration 131160, loss = 2.30685
I0605 18:16:05.406385   904 solver.cpp:245]     Train net output #0: loss = 2.23572 (* 1 = 2.23572 loss)
I0605 18:16:05.406394   904 sgd_solver.cpp:106] Iteration 131160, lr = 0.00913882
I0605 18:16:26.387943   904 solver.cpp:229] Iteration 131200, loss = 2.29293
I0605 18:16:26.388139   904 solver.cpp:245]     Train net output #0: loss = 2.25598 (* 1 = 2.25598 loss)
I0605 18:16:26.388161   904 sgd_solver.cpp:106] Iteration 131200, lr = 0.00912941
I0605 18:16:47.390609   904 solver.cpp:229] Iteration 131240, loss = 2.2869
I0605 18:16:47.390660   904 solver.cpp:245]     Train net output #0: loss = 2.31449 (* 1 = 2.31449 loss)
I0605 18:16:47.390671   904 sgd_solver.cpp:106] Iteration 131240, lr = 0.00912
I0605 18:16:55.774083   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 18:17:08.370800   904 solver.cpp:229] Iteration 131280, loss = 2.29869
I0605 18:17:08.371098   904 solver.cpp:245]     Train net output #0: loss = 1.94005 (* 1 = 1.94005 loss)
I0605 18:17:08.371119   904 sgd_solver.cpp:106] Iteration 131280, lr = 0.00911059
I0605 18:17:29.145539   904 solver.cpp:229] Iteration 131320, loss = 2.31902
I0605 18:17:29.145586   904 solver.cpp:245]     Train net output #0: loss = 2.13847 (* 1 = 2.13847 loss)
I0605 18:17:29.145596   904 sgd_solver.cpp:106] Iteration 131320, lr = 0.00910118
I0605 18:17:49.931049   904 solver.cpp:229] Iteration 131360, loss = 2.29231
I0605 18:17:49.931285   904 solver.cpp:245]     Train net output #0: loss = 2.26818 (* 1 = 2.26818 loss)
I0605 18:17:49.931309   904 sgd_solver.cpp:106] Iteration 131360, lr = 0.00909177
I0605 18:18:10.618331   904 solver.cpp:229] Iteration 131400, loss = 2.29043
I0605 18:18:10.618388   904 solver.cpp:245]     Train net output #0: loss = 2.41602 (* 1 = 2.41602 loss)
I0605 18:18:10.618398   904 sgd_solver.cpp:106] Iteration 131400, lr = 0.00908235
I0605 18:18:31.332594   904 solver.cpp:229] Iteration 131440, loss = 2.2929
I0605 18:18:31.332813   904 solver.cpp:245]     Train net output #0: loss = 2.3264 (* 1 = 2.3264 loss)
I0605 18:18:31.332835   904 sgd_solver.cpp:106] Iteration 131440, lr = 0.00907294
I0605 18:18:51.916637   904 solver.cpp:229] Iteration 131480, loss = 2.3241
I0605 18:18:51.916702   904 solver.cpp:245]     Train net output #0: loss = 2.2172 (* 1 = 2.2172 loss)
I0605 18:18:51.916712   904 sgd_solver.cpp:106] Iteration 131480, lr = 0.00906353
I0605 18:19:12.418681   904 solver.cpp:229] Iteration 131520, loss = 2.32518
I0605 18:19:12.418864   904 solver.cpp:245]     Train net output #0: loss = 2.16215 (* 1 = 2.16215 loss)
I0605 18:19:12.418874   904 sgd_solver.cpp:106] Iteration 131520, lr = 0.00905412
I0605 18:19:33.028231   904 solver.cpp:229] Iteration 131560, loss = 2.32838
I0605 18:19:33.028278   904 solver.cpp:245]     Train net output #0: loss = 2.42255 (* 1 = 2.42255 loss)
I0605 18:19:33.028287   904 sgd_solver.cpp:106] Iteration 131560, lr = 0.00904471
I0605 18:19:53.607920   904 solver.cpp:229] Iteration 131600, loss = 2.29981
I0605 18:19:53.608150   904 solver.cpp:245]     Train net output #0: loss = 2.28632 (* 1 = 2.28632 loss)
I0605 18:19:53.608175   904 sgd_solver.cpp:106] Iteration 131600, lr = 0.00903529
I0605 18:20:14.174553   904 solver.cpp:229] Iteration 131640, loss = 2.29502
I0605 18:20:14.174605   904 solver.cpp:245]     Train net output #0: loss = 2.48265 (* 1 = 2.48265 loss)
I0605 18:20:14.174618   904 sgd_solver.cpp:106] Iteration 131640, lr = 0.00902588
I0605 18:20:34.396440   904 solver.cpp:229] Iteration 131680, loss = 2.33761
I0605 18:20:34.396656   904 solver.cpp:245]     Train net output #0: loss = 2.05789 (* 1 = 2.05789 loss)
I0605 18:20:34.396682   904 sgd_solver.cpp:106] Iteration 131680, lr = 0.00901647
I0605 18:20:54.841090   904 solver.cpp:229] Iteration 131720, loss = 2.30527
I0605 18:20:54.841142   904 solver.cpp:245]     Train net output #0: loss = 2.4097 (* 1 = 2.4097 loss)
I0605 18:20:54.841155   904 sgd_solver.cpp:106] Iteration 131720, lr = 0.00900706
I0605 18:21:15.314291   904 solver.cpp:229] Iteration 131760, loss = 2.32008
I0605 18:21:15.314543   904 solver.cpp:245]     Train net output #0: loss = 2.3256 (* 1 = 2.3256 loss)
I0605 18:21:15.314564   904 sgd_solver.cpp:106] Iteration 131760, lr = 0.00899765
I0605 18:21:21.983502   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 18:21:35.830238   904 solver.cpp:229] Iteration 131800, loss = 2.32699
I0605 18:21:35.830281   904 solver.cpp:245]     Train net output #0: loss = 2.40129 (* 1 = 2.40129 loss)
I0605 18:21:35.830291   904 sgd_solver.cpp:106] Iteration 131800, lr = 0.00898824
I0605 18:21:56.221029   904 solver.cpp:229] Iteration 131840, loss = 2.30502
I0605 18:21:56.221220   904 solver.cpp:245]     Train net output #0: loss = 2.06493 (* 1 = 2.06493 loss)
I0605 18:21:56.221232   904 sgd_solver.cpp:106] Iteration 131840, lr = 0.00897882
I0605 18:22:16.662569   904 solver.cpp:229] Iteration 131880, loss = 2.30408
I0605 18:22:16.662616   904 solver.cpp:245]     Train net output #0: loss = 2.21344 (* 1 = 2.21344 loss)
I0605 18:22:16.662626   904 sgd_solver.cpp:106] Iteration 131880, lr = 0.00896941
I0605 18:22:37.030903   904 solver.cpp:229] Iteration 131920, loss = 2.32684
I0605 18:22:37.031131   904 solver.cpp:245]     Train net output #0: loss = 2.05919 (* 1 = 2.05919 loss)
I0605 18:22:37.031142   904 sgd_solver.cpp:106] Iteration 131920, lr = 0.00896
I0605 18:22:57.538291   904 solver.cpp:229] Iteration 131960, loss = 2.29634
I0605 18:22:57.538343   904 solver.cpp:245]     Train net output #0: loss = 2.42979 (* 1 = 2.42979 loss)
I0605 18:22:57.538352   904 sgd_solver.cpp:106] Iteration 131960, lr = 0.00895059
I0605 18:23:17.542083   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_132000.caffemodel
I0605 18:23:17.799973   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_132000.solverstate
I0605 18:23:17.885308   904 solver.cpp:338] Iteration 132000, Testing net (#0)
I0605 18:23:17.885376   904 net.cpp:748] Ignoring source layer loss
I0605 18:23:36.721940   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 18:24:11.999168   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 18:24:28.521451   904 solver.cpp:406]     Test net output #0: accuracy = 0.47944
I0605 18:24:28.521502   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.72648
I0605 18:24:28.835183   904 solver.cpp:229] Iteration 132000, loss = 2.30585
I0605 18:24:28.835227   904 solver.cpp:245]     Train net output #0: loss = 2.33442 (* 1 = 2.33442 loss)
I0605 18:24:28.835238   904 sgd_solver.cpp:106] Iteration 132000, lr = 0.00894118
I0605 18:24:48.110874   904 solver.cpp:229] Iteration 132040, loss = 2.28017
I0605 18:24:48.111090   904 solver.cpp:245]     Train net output #0: loss = 2.36706 (* 1 = 2.36706 loss)
I0605 18:24:48.111116   904 sgd_solver.cpp:106] Iteration 132040, lr = 0.00893177
I0605 18:25:09.491430   904 solver.cpp:229] Iteration 132080, loss = 2.28752
I0605 18:25:09.491482   904 solver.cpp:245]     Train net output #0: loss = 2.35964 (* 1 = 2.35964 loss)
I0605 18:25:09.491494   904 sgd_solver.cpp:106] Iteration 132080, lr = 0.00892235
I0605 18:25:31.065132   904 solver.cpp:229] Iteration 132120, loss = 2.27921
I0605 18:25:31.065309   904 solver.cpp:245]     Train net output #0: loss = 2.36405 (* 1 = 2.36405 loss)
I0605 18:25:31.065318   904 sgd_solver.cpp:106] Iteration 132120, lr = 0.00891294
I0605 18:25:52.130761   904 solver.cpp:229] Iteration 132160, loss = 2.28288
I0605 18:25:52.130803   904 solver.cpp:245]     Train net output #0: loss = 2.24911 (* 1 = 2.24911 loss)
I0605 18:25:52.130812   904 sgd_solver.cpp:106] Iteration 132160, lr = 0.00890353
I0605 18:26:13.159498   904 solver.cpp:229] Iteration 132200, loss = 2.29821
I0605 18:26:13.159709   904 solver.cpp:245]     Train net output #0: loss = 2.39144 (* 1 = 2.39144 loss)
I0605 18:26:13.159729   904 sgd_solver.cpp:106] Iteration 132200, lr = 0.00889412
I0605 18:26:34.253744   904 solver.cpp:229] Iteration 132240, loss = 2.31248
I0605 18:26:34.253800   904 solver.cpp:245]     Train net output #0: loss = 2.37021 (* 1 = 2.37021 loss)
I0605 18:26:34.253811   904 sgd_solver.cpp:106] Iteration 132240, lr = 0.00888471
I0605 18:26:55.290318   904 solver.cpp:229] Iteration 132280, loss = 2.30627
I0605 18:26:55.290479   904 solver.cpp:245]     Train net output #0: loss = 2.39187 (* 1 = 2.39187 loss)
I0605 18:26:55.290490   904 sgd_solver.cpp:106] Iteration 132280, lr = 0.00887529
I0605 18:27:10.008236   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 18:27:16.319327   904 solver.cpp:229] Iteration 132320, loss = 2.25974
I0605 18:27:16.319385   904 solver.cpp:245]     Train net output #0: loss = 2.2631 (* 1 = 2.2631 loss)
I0605 18:27:16.319394   904 sgd_solver.cpp:106] Iteration 132320, lr = 0.00886588
I0605 18:27:37.291986   904 solver.cpp:229] Iteration 132360, loss = 2.30402
I0605 18:27:37.292212   904 solver.cpp:245]     Train net output #0: loss = 2.38733 (* 1 = 2.38733 loss)
I0605 18:27:37.292224   904 sgd_solver.cpp:106] Iteration 132360, lr = 0.00885647
I0605 18:27:58.160465   904 solver.cpp:229] Iteration 132400, loss = 2.32675
I0605 18:27:58.160518   904 solver.cpp:245]     Train net output #0: loss = 2.30973 (* 1 = 2.30973 loss)
I0605 18:27:58.160528   904 sgd_solver.cpp:106] Iteration 132400, lr = 0.00884706
I0605 18:28:18.988348   904 solver.cpp:229] Iteration 132440, loss = 2.27802
I0605 18:28:18.988597   904 solver.cpp:245]     Train net output #0: loss = 2.30611 (* 1 = 2.30611 loss)
I0605 18:28:18.988622   904 sgd_solver.cpp:106] Iteration 132440, lr = 0.00883765
I0605 18:28:39.847487   904 solver.cpp:229] Iteration 132480, loss = 2.24003
I0605 18:28:39.847532   904 solver.cpp:245]     Train net output #0: loss = 2.15263 (* 1 = 2.15263 loss)
I0605 18:28:39.847539   904 sgd_solver.cpp:106] Iteration 132480, lr = 0.00882823
I0605 18:29:00.649426   904 solver.cpp:229] Iteration 132520, loss = 2.29156
I0605 18:29:00.649652   904 solver.cpp:245]     Train net output #0: loss = 2.25264 (* 1 = 2.25264 loss)
I0605 18:29:00.649662   904 sgd_solver.cpp:106] Iteration 132520, lr = 0.00881882
I0605 18:29:21.405181   904 solver.cpp:229] Iteration 132560, loss = 2.31188
I0605 18:29:21.405227   904 solver.cpp:245]     Train net output #0: loss = 2.6092 (* 1 = 2.6092 loss)
I0605 18:29:21.405237   904 sgd_solver.cpp:106] Iteration 132560, lr = 0.00880941
I0605 18:29:42.147454   904 solver.cpp:229] Iteration 132600, loss = 2.32214
I0605 18:29:42.147613   904 solver.cpp:245]     Train net output #0: loss = 2.05397 (* 1 = 2.05397 loss)
I0605 18:29:42.147622   904 sgd_solver.cpp:106] Iteration 132600, lr = 0.0088
I0605 18:30:02.893162   904 solver.cpp:229] Iteration 132640, loss = 2.34443
I0605 18:30:02.893211   904 solver.cpp:245]     Train net output #0: loss = 2.22252 (* 1 = 2.22252 loss)
I0605 18:30:02.893219   904 sgd_solver.cpp:106] Iteration 132640, lr = 0.00879059
I0605 18:30:23.636173   904 solver.cpp:229] Iteration 132680, loss = 2.32226
I0605 18:30:23.648460   904 solver.cpp:245]     Train net output #0: loss = 2.18371 (* 1 = 2.18371 loss)
I0605 18:30:23.648481   904 sgd_solver.cpp:106] Iteration 132680, lr = 0.00878118
I0605 18:30:44.428011   904 solver.cpp:229] Iteration 132720, loss = 2.29933
I0605 18:30:44.428061   904 solver.cpp:245]     Train net output #0: loss = 2.21835 (* 1 = 2.21835 loss)
I0605 18:30:44.428069   904 sgd_solver.cpp:106] Iteration 132720, lr = 0.00877177
I0605 18:31:05.087575   904 solver.cpp:229] Iteration 132760, loss = 2.28431
I0605 18:31:05.087836   904 solver.cpp:245]     Train net output #0: loss = 2.14398 (* 1 = 2.14398 loss)
I0605 18:31:05.087862   904 sgd_solver.cpp:106] Iteration 132760, lr = 0.00876235
I0605 18:31:25.651568   904 solver.cpp:229] Iteration 132800, loss = 2.30637
I0605 18:31:25.651610   904 solver.cpp:245]     Train net output #0: loss = 2.22614 (* 1 = 2.22614 loss)
I0605 18:31:25.651619   904 sgd_solver.cpp:106] Iteration 132800, lr = 0.00875294
I0605 18:31:43.733013   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 18:31:46.321156   904 solver.cpp:229] Iteration 132840, loss = 2.27726
I0605 18:31:46.321205   904 solver.cpp:245]     Train net output #0: loss = 2.19369 (* 1 = 2.19369 loss)
I0605 18:31:46.321216   904 sgd_solver.cpp:106] Iteration 132840, lr = 0.00874353
I0605 18:32:06.995829   904 solver.cpp:229] Iteration 132880, loss = 2.30688
I0605 18:32:06.995887   904 solver.cpp:245]     Train net output #0: loss = 2.08249 (* 1 = 2.08249 loss)
I0605 18:32:06.995896   904 sgd_solver.cpp:106] Iteration 132880, lr = 0.00873412
I0605 18:32:27.675655   904 solver.cpp:229] Iteration 132920, loss = 2.3127
I0605 18:32:27.675910   904 solver.cpp:245]     Train net output #0: loss = 2.32805 (* 1 = 2.32805 loss)
I0605 18:32:27.675938   904 sgd_solver.cpp:106] Iteration 132920, lr = 0.00872471
I0605 18:32:48.278103   904 solver.cpp:229] Iteration 132960, loss = 2.30979
I0605 18:32:48.278156   904 solver.cpp:245]     Train net output #0: loss = 2.25529 (* 1 = 2.25529 loss)
I0605 18:32:48.278167   904 sgd_solver.cpp:106] Iteration 132960, lr = 0.00871529
I0605 18:33:08.311950   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_133000.caffemodel
I0605 18:33:08.578586   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_133000.solverstate
I0605 18:33:08.653789   904 solver.cpp:338] Iteration 133000, Testing net (#0)
I0605 18:33:08.653868   904 net.cpp:748] Ignoring source layer loss
I0605 18:33:33.452011   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 18:34:08.126111   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 18:34:19.328284   904 solver.cpp:406]     Test net output #0: accuracy = 0.482361
I0605 18:34:19.328325   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.73228
I0605 18:34:19.643913   904 solver.cpp:229] Iteration 133000, loss = 2.29084
I0605 18:34:19.643965   904 solver.cpp:245]     Train net output #0: loss = 2.35003 (* 1 = 2.35003 loss)
I0605 18:34:19.643975   904 sgd_solver.cpp:106] Iteration 133000, lr = 0.00870588
I0605 18:34:38.962448   904 solver.cpp:229] Iteration 133040, loss = 2.26227
I0605 18:34:38.962697   904 solver.cpp:245]     Train net output #0: loss = 2.309 (* 1 = 2.309 loss)
I0605 18:34:38.962726   904 sgd_solver.cpp:106] Iteration 133040, lr = 0.00869647
I0605 18:35:00.511014   904 solver.cpp:229] Iteration 133080, loss = 2.32601
I0605 18:35:00.511064   904 solver.cpp:245]     Train net output #0: loss = 2.3745 (* 1 = 2.3745 loss)
I0605 18:35:00.511075   904 sgd_solver.cpp:106] Iteration 133080, lr = 0.00868706
I0605 18:35:22.093636   904 solver.cpp:229] Iteration 133120, loss = 2.32974
I0605 18:35:22.093842   904 solver.cpp:245]     Train net output #0: loss = 2.29235 (* 1 = 2.29235 loss)
I0605 18:35:22.093869   904 sgd_solver.cpp:106] Iteration 133120, lr = 0.00867765
I0605 18:35:43.417210   904 solver.cpp:229] Iteration 133160, loss = 2.26373
I0605 18:35:43.417255   904 solver.cpp:245]     Train net output #0: loss = 2.41483 (* 1 = 2.41483 loss)
I0605 18:35:43.417265   904 sgd_solver.cpp:106] Iteration 133160, lr = 0.00866823
I0605 18:36:04.388325   904 solver.cpp:229] Iteration 133200, loss = 2.29128
I0605 18:36:04.388558   904 solver.cpp:245]     Train net output #0: loss = 2.52924 (* 1 = 2.52924 loss)
I0605 18:36:04.388595   904 sgd_solver.cpp:106] Iteration 133200, lr = 0.00865882
I0605 18:36:25.408430   904 solver.cpp:229] Iteration 133240, loss = 2.31115
I0605 18:36:25.408480   904 solver.cpp:245]     Train net output #0: loss = 2.14381 (* 1 = 2.14381 loss)
I0605 18:36:25.408493   904 sgd_solver.cpp:106] Iteration 133240, lr = 0.00864941
I0605 18:36:46.419776   904 solver.cpp:229] Iteration 133280, loss = 2.29995
I0605 18:36:46.419975   904 solver.cpp:245]     Train net output #0: loss = 2.37917 (* 1 = 2.37917 loss)
I0605 18:36:46.419998   904 sgd_solver.cpp:106] Iteration 133280, lr = 0.00864
I0605 18:37:07.419160   904 solver.cpp:229] Iteration 133320, loss = 2.2836
I0605 18:37:07.419212   904 solver.cpp:245]     Train net output #0: loss = 2.22796 (* 1 = 2.22796 loss)
I0605 18:37:07.419225   904 sgd_solver.cpp:106] Iteration 133320, lr = 0.00863059
I0605 18:37:28.368847   904 solver.cpp:229] Iteration 133360, loss = 2.31501
I0605 18:37:28.369071   904 solver.cpp:245]     Train net output #0: loss = 2.33709 (* 1 = 2.33709 loss)
I0605 18:37:28.369107   904 sgd_solver.cpp:106] Iteration 133360, lr = 0.00862117
I0605 18:37:32.524986   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 18:37:49.116935   904 solver.cpp:229] Iteration 133400, loss = 2.31435
I0605 18:37:49.116978   904 solver.cpp:245]     Train net output #0: loss = 2.00751 (* 1 = 2.00751 loss)
I0605 18:37:49.116987   904 sgd_solver.cpp:106] Iteration 133400, lr = 0.00861176
I0605 18:38:09.840194   904 solver.cpp:229] Iteration 133440, loss = 2.25992
I0605 18:38:09.840358   904 solver.cpp:245]     Train net output #0: loss = 2.27037 (* 1 = 2.27037 loss)
I0605 18:38:09.840369   904 sgd_solver.cpp:106] Iteration 133440, lr = 0.00860235
I0605 18:38:30.663499   904 solver.cpp:229] Iteration 133480, loss = 2.25748
I0605 18:38:30.663555   904 solver.cpp:245]     Train net output #0: loss = 2.21863 (* 1 = 2.21863 loss)
I0605 18:38:30.663563   904 sgd_solver.cpp:106] Iteration 133480, lr = 0.00859294
I0605 18:38:51.303345   904 solver.cpp:229] Iteration 133520, loss = 2.27367
I0605 18:38:51.303623   904 solver.cpp:245]     Train net output #0: loss = 2.1741 (* 1 = 2.1741 loss)
I0605 18:38:51.303634   904 sgd_solver.cpp:106] Iteration 133520, lr = 0.00858353
I0605 18:39:11.976176   904 solver.cpp:229] Iteration 133560, loss = 2.26233
I0605 18:39:11.976235   904 solver.cpp:245]     Train net output #0: loss = 2.32212 (* 1 = 2.32212 loss)
I0605 18:39:11.976246   904 sgd_solver.cpp:106] Iteration 133560, lr = 0.00857412
I0605 18:39:32.645051   904 solver.cpp:229] Iteration 133600, loss = 2.29144
I0605 18:39:32.645263   904 solver.cpp:245]     Train net output #0: loss = 2.21362 (* 1 = 2.21362 loss)
I0605 18:39:32.645289   904 sgd_solver.cpp:106] Iteration 133600, lr = 0.00856471
I0605 18:39:53.251960   904 solver.cpp:229] Iteration 133640, loss = 2.25679
I0605 18:39:53.252007   904 solver.cpp:245]     Train net output #0: loss = 2.35119 (* 1 = 2.35119 loss)
I0605 18:39:53.252020   904 sgd_solver.cpp:106] Iteration 133640, lr = 0.00855529
I0605 18:40:13.778163   904 solver.cpp:229] Iteration 133680, loss = 2.28909
I0605 18:40:13.778412   904 solver.cpp:245]     Train net output #0: loss = 2.07286 (* 1 = 2.07286 loss)
I0605 18:40:13.778437   904 sgd_solver.cpp:106] Iteration 133680, lr = 0.00854588
I0605 18:40:34.325918   904 solver.cpp:229] Iteration 133720, loss = 2.25639
I0605 18:40:34.325978   904 solver.cpp:245]     Train net output #0: loss = 2.08891 (* 1 = 2.08891 loss)
I0605 18:40:34.325990   904 sgd_solver.cpp:106] Iteration 133720, lr = 0.00853647
I0605 18:40:54.842499   904 solver.cpp:229] Iteration 133760, loss = 2.29893
I0605 18:40:54.842730   904 solver.cpp:245]     Train net output #0: loss = 2.18652 (* 1 = 2.18652 loss)
I0605 18:40:54.842754   904 sgd_solver.cpp:106] Iteration 133760, lr = 0.00852706
I0605 18:41:15.397605   904 solver.cpp:229] Iteration 133800, loss = 2.28327
I0605 18:41:15.397665   904 solver.cpp:245]     Train net output #0: loss = 2.31151 (* 1 = 2.31151 loss)
I0605 18:41:15.397676   904 sgd_solver.cpp:106] Iteration 133800, lr = 0.00851765
I0605 18:41:35.798588   904 solver.cpp:229] Iteration 133840, loss = 2.2956
I0605 18:41:35.798805   904 solver.cpp:245]     Train net output #0: loss = 2.36331 (* 1 = 2.36331 loss)
I0605 18:41:35.798828   904 sgd_solver.cpp:106] Iteration 133840, lr = 0.00850824
I0605 18:41:56.090688   904 solver.cpp:229] Iteration 133880, loss = 2.28201
I0605 18:41:56.090739   904 solver.cpp:245]     Train net output #0: loss = 2.20667 (* 1 = 2.20667 loss)
I0605 18:41:56.090751   904 sgd_solver.cpp:106] Iteration 133880, lr = 0.00849882
I0605 18:42:02.687044   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 18:42:16.417309   904 solver.cpp:229] Iteration 133920, loss = 2.27282
I0605 18:42:16.417517   904 solver.cpp:245]     Train net output #0: loss = 2.40688 (* 1 = 2.40688 loss)
I0605 18:42:16.417543   904 sgd_solver.cpp:106] Iteration 133920, lr = 0.00848941
I0605 18:42:36.944042   904 solver.cpp:229] Iteration 133960, loss = 2.29108
I0605 18:42:36.944085   904 solver.cpp:245]     Train net output #0: loss = 2.35651 (* 1 = 2.35651 loss)
I0605 18:42:36.944095   904 sgd_solver.cpp:106] Iteration 133960, lr = 0.00848
I0605 18:42:56.745229   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_134000.caffemodel
I0605 18:42:57.009606   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_134000.solverstate
I0605 18:42:57.081724   904 solver.cpp:338] Iteration 134000, Testing net (#0)
I0605 18:42:57.081807   904 net.cpp:748] Ignoring source layer loss
I0605 18:43:25.644194   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 18:44:02.420527   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 18:44:09.677886   904 solver.cpp:406]     Test net output #0: accuracy = 0.4855
I0605 18:44:09.677927   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.7321
I0605 18:44:09.990494   904 solver.cpp:229] Iteration 134000, loss = 2.28312
I0605 18:44:09.990536   904 solver.cpp:245]     Train net output #0: loss = 2.14023 (* 1 = 2.14023 loss)
I0605 18:44:09.990545   904 sgd_solver.cpp:106] Iteration 134000, lr = 0.00847059
I0605 18:44:29.166555   904 solver.cpp:229] Iteration 134040, loss = 2.31917
I0605 18:44:29.166607   904 solver.cpp:245]     Train net output #0: loss = 2.61355 (* 1 = 2.61355 loss)
I0605 18:44:29.166620   904 sgd_solver.cpp:106] Iteration 134040, lr = 0.00846118
I0605 18:44:50.488562   904 solver.cpp:229] Iteration 134080, loss = 2.28553
I0605 18:44:50.488745   904 solver.cpp:245]     Train net output #0: loss = 2.29886 (* 1 = 2.29886 loss)
I0605 18:44:50.488757   904 sgd_solver.cpp:106] Iteration 134080, lr = 0.00845176
I0605 18:45:12.010478   904 solver.cpp:229] Iteration 134120, loss = 2.2473
I0605 18:45:12.010526   904 solver.cpp:245]     Train net output #0: loss = 2.20822 (* 1 = 2.20822 loss)
I0605 18:45:12.010535   904 sgd_solver.cpp:106] Iteration 134120, lr = 0.00844235
I0605 18:45:33.020798   904 solver.cpp:229] Iteration 134160, loss = 2.29555
I0605 18:45:33.020941   904 solver.cpp:245]     Train net output #0: loss = 2.38149 (* 1 = 2.38149 loss)
I0605 18:45:33.020951   904 sgd_solver.cpp:106] Iteration 134160, lr = 0.00843294
I0605 18:45:54.014040   904 solver.cpp:229] Iteration 134200, loss = 2.31068
I0605 18:45:54.014093   904 solver.cpp:245]     Train net output #0: loss = 2.2963 (* 1 = 2.2963 loss)
I0605 18:45:54.014102   904 sgd_solver.cpp:106] Iteration 134200, lr = 0.00842353
I0605 18:46:15.013028   904 solver.cpp:229] Iteration 134240, loss = 2.3005
I0605 18:46:15.013192   904 solver.cpp:245]     Train net output #0: loss = 2.56764 (* 1 = 2.56764 loss)
I0605 18:46:15.013203   904 sgd_solver.cpp:106] Iteration 134240, lr = 0.00841412
I0605 18:46:35.891202   904 solver.cpp:229] Iteration 134280, loss = 2.30015
I0605 18:46:35.891268   904 solver.cpp:245]     Train net output #0: loss = 2.32969 (* 1 = 2.32969 loss)
I0605 18:46:35.891283   904 sgd_solver.cpp:106] Iteration 134280, lr = 0.00840471
I0605 18:46:56.731724   904 solver.cpp:229] Iteration 134320, loss = 2.29758
I0605 18:46:56.731950   904 solver.cpp:245]     Train net output #0: loss = 2.36456 (* 1 = 2.36456 loss)
I0605 18:46:56.731976   904 sgd_solver.cpp:106] Iteration 134320, lr = 0.00839529
I0605 18:47:17.533360   904 solver.cpp:229] Iteration 134360, loss = 2.24513
I0605 18:47:17.533407   904 solver.cpp:245]     Train net output #0: loss = 2.21956 (* 1 = 2.21956 loss)
I0605 18:47:17.533418   904 sgd_solver.cpp:106] Iteration 134360, lr = 0.00838588
I0605 18:47:38.218562   904 solver.cpp:229] Iteration 134400, loss = 2.28624
I0605 18:47:38.218708   904 solver.cpp:245]     Train net output #0: loss = 2.16902 (* 1 = 2.16902 loss)
I0605 18:47:38.218719   904 sgd_solver.cpp:106] Iteration 134400, lr = 0.00837647
I0605 18:47:42.348852   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 18:47:58.895489   904 solver.cpp:229] Iteration 134440, loss = 2.27113
I0605 18:47:58.895540   904 solver.cpp:245]     Train net output #0: loss = 2.34918 (* 1 = 2.34918 loss)
I0605 18:47:58.895550   904 sgd_solver.cpp:106] Iteration 134440, lr = 0.00836706
I0605 18:48:19.492882   904 solver.cpp:229] Iteration 134480, loss = 2.27433
I0605 18:48:19.493062   904 solver.cpp:245]     Train net output #0: loss = 2.08986 (* 1 = 2.08986 loss)
I0605 18:48:19.493073   904 sgd_solver.cpp:106] Iteration 134480, lr = 0.00835765
I0605 18:48:39.993324   904 solver.cpp:229] Iteration 134520, loss = 2.26826
I0605 18:48:39.993381   904 solver.cpp:245]     Train net output #0: loss = 2.16169 (* 1 = 2.16169 loss)
I0605 18:48:39.993391   904 sgd_solver.cpp:106] Iteration 134520, lr = 0.00834824
I0605 18:49:00.587381   904 solver.cpp:229] Iteration 134560, loss = 2.25466
I0605 18:49:00.587659   904 solver.cpp:245]     Train net output #0: loss = 2.34813 (* 1 = 2.34813 loss)
I0605 18:49:00.587682   904 sgd_solver.cpp:106] Iteration 134560, lr = 0.00833882
I0605 18:49:21.142511   904 solver.cpp:229] Iteration 134600, loss = 2.27722
I0605 18:49:21.142556   904 solver.cpp:245]     Train net output #0: loss = 2.13264 (* 1 = 2.13264 loss)
I0605 18:49:21.142565   904 sgd_solver.cpp:106] Iteration 134600, lr = 0.00832941
I0605 18:49:41.450798   904 solver.cpp:229] Iteration 134640, loss = 2.26969
I0605 18:49:41.451020   904 solver.cpp:245]     Train net output #0: loss = 2.19987 (* 1 = 2.19987 loss)
I0605 18:49:41.451047   904 sgd_solver.cpp:106] Iteration 134640, lr = 0.00832
I0605 18:50:01.905508   904 solver.cpp:229] Iteration 134680, loss = 2.24445
I0605 18:50:01.905556   904 solver.cpp:245]     Train net output #0: loss = 2.542 (* 1 = 2.542 loss)
I0605 18:50:01.905568   904 sgd_solver.cpp:106] Iteration 134680, lr = 0.00831059
I0605 18:50:22.424942   904 solver.cpp:229] Iteration 134720, loss = 2.26357
I0605 18:50:22.425107   904 solver.cpp:245]     Train net output #0: loss = 2.20735 (* 1 = 2.20735 loss)
I0605 18:50:22.425117   904 sgd_solver.cpp:106] Iteration 134720, lr = 0.00830118
I0605 18:50:42.912968   904 solver.cpp:229] Iteration 134760, loss = 2.27923
I0605 18:50:42.913038   904 solver.cpp:245]     Train net output #0: loss = 2.15472 (* 1 = 2.15472 loss)
I0605 18:50:42.913051   904 sgd_solver.cpp:106] Iteration 134760, lr = 0.00829176
I0605 18:51:03.174851   904 solver.cpp:229] Iteration 134800, loss = 2.30058
I0605 18:51:03.175006   904 solver.cpp:245]     Train net output #0: loss = 2.31394 (* 1 = 2.31394 loss)
I0605 18:51:03.175017   904 sgd_solver.cpp:106] Iteration 134800, lr = 0.00828235
I0605 18:51:23.596731   904 solver.cpp:229] Iteration 134840, loss = 2.24114
I0605 18:51:23.596773   904 solver.cpp:245]     Train net output #0: loss = 2.22226 (* 1 = 2.22226 loss)
I0605 18:51:23.596782   904 sgd_solver.cpp:106] Iteration 134840, lr = 0.00827294
I0605 18:51:44.105818   904 solver.cpp:229] Iteration 134880, loss = 2.27071
I0605 18:51:44.105988   904 solver.cpp:245]     Train net output #0: loss = 2.33126 (* 1 = 2.33126 loss)
I0605 18:51:44.105998   904 sgd_solver.cpp:106] Iteration 134880, lr = 0.00826353
I0605 18:52:04.602952   904 solver.cpp:229] Iteration 134920, loss = 2.28466
I0605 18:52:04.603008   904 solver.cpp:245]     Train net output #0: loss = 2.18531 (* 1 = 2.18531 loss)
I0605 18:52:04.603018   904 sgd_solver.cpp:106] Iteration 134920, lr = 0.00825412
I0605 18:52:05.633149   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 18:52:25.002914   904 solver.cpp:229] Iteration 134960, loss = 2.22277
I0605 18:52:25.003134   904 solver.cpp:245]     Train net output #0: loss = 2.10914 (* 1 = 2.10914 loss)
I0605 18:52:25.003162   904 sgd_solver.cpp:106] Iteration 134960, lr = 0.00824471
I0605 18:52:44.732537   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_135000.caffemodel
I0605 18:52:44.995128   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_135000.solverstate
I0605 18:52:45.071481   904 solver.cpp:338] Iteration 135000, Testing net (#0)
I0605 18:52:45.071542   904 net.cpp:748] Ignoring source layer loss
I0605 18:53:17.023738   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 18:53:52.568486   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 18:53:57.109467   904 solver.cpp:406]     Test net output #0: accuracy = 0.48334
I0605 18:53:57.109510   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.729539
I0605 18:53:57.423393   904 solver.cpp:229] Iteration 135000, loss = 2.28389
I0605 18:53:57.423444   904 solver.cpp:245]     Train net output #0: loss = 2.32511 (* 1 = 2.32511 loss)
I0605 18:53:57.423458   904 sgd_solver.cpp:106] Iteration 135000, lr = 0.00823529
I0605 18:54:16.596240   904 solver.cpp:229] Iteration 135040, loss = 2.26573
I0605 18:54:16.596293   904 solver.cpp:245]     Train net output #0: loss = 2.23542 (* 1 = 2.23542 loss)
I0605 18:54:16.596304   904 sgd_solver.cpp:106] Iteration 135040, lr = 0.00822588
I0605 18:54:38.035539   904 solver.cpp:229] Iteration 135080, loss = 2.27635
I0605 18:54:38.035825   904 solver.cpp:245]     Train net output #0: loss = 2.18136 (* 1 = 2.18136 loss)
I0605 18:54:38.035856   904 sgd_solver.cpp:106] Iteration 135080, lr = 0.00821647
I0605 18:54:59.526393   904 solver.cpp:229] Iteration 135120, loss = 2.29648
I0605 18:54:59.526440   904 solver.cpp:245]     Train net output #0: loss = 2.26875 (* 1 = 2.26875 loss)
I0605 18:54:59.526450   904 sgd_solver.cpp:106] Iteration 135120, lr = 0.00820706
I0605 18:55:20.658936   904 solver.cpp:229] Iteration 135160, loss = 2.30568
I0605 18:55:20.659142   904 solver.cpp:245]     Train net output #0: loss = 2.46564 (* 1 = 2.46564 loss)
I0605 18:55:20.659162   904 sgd_solver.cpp:106] Iteration 135160, lr = 0.00819765
I0605 18:55:41.558193   904 solver.cpp:229] Iteration 135200, loss = 2.27221
I0605 18:55:41.558238   904 solver.cpp:245]     Train net output #0: loss = 2.59891 (* 1 = 2.59891 loss)
I0605 18:55:41.558248   904 sgd_solver.cpp:106] Iteration 135200, lr = 0.00818824
I0605 18:56:02.513579   904 solver.cpp:229] Iteration 135240, loss = 2.2636
I0605 18:56:02.513859   904 solver.cpp:245]     Train net output #0: loss = 2.3179 (* 1 = 2.3179 loss)
I0605 18:56:02.513886   904 sgd_solver.cpp:106] Iteration 135240, lr = 0.00817882
I0605 18:56:23.745276   904 solver.cpp:229] Iteration 135280, loss = 2.26788
I0605 18:56:23.745326   904 solver.cpp:245]     Train net output #0: loss = 2.29795 (* 1 = 2.29795 loss)
I0605 18:56:23.745337   904 sgd_solver.cpp:106] Iteration 135280, lr = 0.00816941
I0605 18:56:44.435657   904 solver.cpp:229] Iteration 135320, loss = 2.2831
I0605 18:56:44.435892   904 solver.cpp:245]     Train net output #0: loss = 1.91178 (* 1 = 1.91178 loss)
I0605 18:56:44.435917   904 sgd_solver.cpp:106] Iteration 135320, lr = 0.00816
I0605 18:57:05.196807   904 solver.cpp:229] Iteration 135360, loss = 2.26637
I0605 18:57:05.196852   904 solver.cpp:245]     Train net output #0: loss = 2.24389 (* 1 = 2.24389 loss)
I0605 18:57:05.196866   904 sgd_solver.cpp:106] Iteration 135360, lr = 0.00815059
I0605 18:57:25.968391   904 solver.cpp:229] Iteration 135400, loss = 2.2906
I0605 18:57:25.968770   904 solver.cpp:245]     Train net output #0: loss = 2.1529 (* 1 = 2.1529 loss)
I0605 18:57:25.968794   904 sgd_solver.cpp:106] Iteration 135400, lr = 0.00814118
I0605 18:57:46.734935   904 solver.cpp:229] Iteration 135440, loss = 2.26816
I0605 18:57:46.735018   904 solver.cpp:245]     Train net output #0: loss = 2.14553 (* 1 = 2.14553 loss)
I0605 18:57:46.735033   904 sgd_solver.cpp:106] Iteration 135440, lr = 0.00813176
I0605 18:57:52.701545   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 18:58:07.500942   904 solver.cpp:229] Iteration 135480, loss = 2.27552
I0605 18:58:07.501094   904 solver.cpp:245]     Train net output #0: loss = 2.31521 (* 1 = 2.31521 loss)
I0605 18:58:07.501111   904 sgd_solver.cpp:106] Iteration 135480, lr = 0.00812235
I0605 18:58:28.176542   904 solver.cpp:229] Iteration 135520, loss = 2.25647
I0605 18:58:28.176587   904 solver.cpp:245]     Train net output #0: loss = 2.17986 (* 1 = 2.17986 loss)
I0605 18:58:28.176599   904 sgd_solver.cpp:106] Iteration 135520, lr = 0.00811294
I0605 18:58:48.806210   904 solver.cpp:229] Iteration 135560, loss = 2.26917
I0605 18:58:48.806391   904 solver.cpp:245]     Train net output #0: loss = 2.38621 (* 1 = 2.38621 loss)
I0605 18:58:48.806404   904 sgd_solver.cpp:106] Iteration 135560, lr = 0.00810353
I0605 18:59:09.538833   904 solver.cpp:229] Iteration 135600, loss = 2.28875
I0605 18:59:09.538889   904 solver.cpp:245]     Train net output #0: loss = 2.30125 (* 1 = 2.30125 loss)
I0605 18:59:09.538900   904 sgd_solver.cpp:106] Iteration 135600, lr = 0.00809412
I0605 18:59:30.059747   904 solver.cpp:229] Iteration 135640, loss = 2.26256
I0605 18:59:30.059912   904 solver.cpp:245]     Train net output #0: loss = 2.22131 (* 1 = 2.22131 loss)
I0605 18:59:30.059924   904 sgd_solver.cpp:106] Iteration 135640, lr = 0.00808471
I0605 18:59:50.647351   904 solver.cpp:229] Iteration 135680, loss = 2.2583
I0605 18:59:50.647405   904 solver.cpp:245]     Train net output #0: loss = 2.29783 (* 1 = 2.29783 loss)
I0605 18:59:50.647415   904 sgd_solver.cpp:106] Iteration 135680, lr = 0.00807529
I0605 19:00:11.214110   904 solver.cpp:229] Iteration 135720, loss = 2.28713
I0605 19:00:11.214432   904 solver.cpp:245]     Train net output #0: loss = 2.31412 (* 1 = 2.31412 loss)
I0605 19:00:11.214457   904 sgd_solver.cpp:106] Iteration 135720, lr = 0.00806588
I0605 19:00:31.765800   904 solver.cpp:229] Iteration 135760, loss = 2.26765
I0605 19:00:31.765856   904 solver.cpp:245]     Train net output #0: loss = 2.04603 (* 1 = 2.04603 loss)
I0605 19:00:31.765866   904 sgd_solver.cpp:106] Iteration 135760, lr = 0.00805647
I0605 19:00:52.206393   904 solver.cpp:229] Iteration 135800, loss = 2.28195
I0605 19:00:52.206634   904 solver.cpp:245]     Train net output #0: loss = 2.38516 (* 1 = 2.38516 loss)
I0605 19:00:52.206662   904 sgd_solver.cpp:106] Iteration 135800, lr = 0.00804706
I0605 19:01:12.653816   904 solver.cpp:229] Iteration 135840, loss = 2.27058
I0605 19:01:12.653861   904 solver.cpp:245]     Train net output #0: loss = 2.26167 (* 1 = 2.26167 loss)
I0605 19:01:12.653870   904 sgd_solver.cpp:106] Iteration 135840, lr = 0.00803765
I0605 19:01:33.159432   904 solver.cpp:229] Iteration 135880, loss = 2.31231
I0605 19:01:33.159610   904 solver.cpp:245]     Train net output #0: loss = 2.08477 (* 1 = 2.08477 loss)
I0605 19:01:33.159621   904 sgd_solver.cpp:106] Iteration 135880, lr = 0.00802824
I0605 19:01:53.721673   904 solver.cpp:229] Iteration 135920, loss = 2.27509
I0605 19:01:53.721722   904 solver.cpp:245]     Train net output #0: loss = 2.23702 (* 1 = 2.23702 loss)
I0605 19:01:53.721730   904 sgd_solver.cpp:106] Iteration 135920, lr = 0.00801882
I0605 19:02:14.164151   904 solver.cpp:229] Iteration 135960, loss = 2.2379
I0605 19:02:14.164366   904 solver.cpp:245]     Train net output #0: loss = 2.5286 (* 1 = 2.5286 loss)
I0605 19:02:14.164400   904 sgd_solver.cpp:106] Iteration 135960, lr = 0.00800941
I0605 19:02:16.209303   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 19:02:34.106916   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_136000.caffemodel
I0605 19:02:34.371325   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_136000.solverstate
I0605 19:02:34.444563   904 solver.cpp:338] Iteration 136000, Testing net (#0)
I0605 19:02:34.444639   904 net.cpp:748] Ignoring source layer loss
I0605 19:03:07.991055   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 19:03:43.674914   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 19:03:45.906052   904 solver.cpp:406]     Test net output #0: accuracy = 0.49244
I0605 19:03:45.906107   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.734079
I0605 19:03:46.220475   904 solver.cpp:229] Iteration 136000, loss = 2.24026
I0605 19:03:46.220521   904 solver.cpp:245]     Train net output #0: loss = 2.47892 (* 1 = 2.47892 loss)
I0605 19:03:46.220531   904 sgd_solver.cpp:106] Iteration 136000, lr = 0.008
I0605 19:04:05.487546   904 solver.cpp:229] Iteration 136040, loss = 2.26005
I0605 19:04:05.487607   904 solver.cpp:245]     Train net output #0: loss = 2.33163 (* 1 = 2.33163 loss)
I0605 19:04:05.487620   904 sgd_solver.cpp:106] Iteration 136040, lr = 0.00799059
I0605 19:04:27.016757   904 solver.cpp:229] Iteration 136080, loss = 2.23157
I0605 19:04:27.016959   904 solver.cpp:245]     Train net output #0: loss = 2.15509 (* 1 = 2.15509 loss)
I0605 19:04:27.016984   904 sgd_solver.cpp:106] Iteration 136080, lr = 0.00798118
I0605 19:04:48.585714   904 solver.cpp:229] Iteration 136120, loss = 2.26661
I0605 19:04:48.585765   904 solver.cpp:245]     Train net output #0: loss = 2.18104 (* 1 = 2.18104 loss)
I0605 19:04:48.585777   904 sgd_solver.cpp:106] Iteration 136120, lr = 0.00797176
I0605 19:05:09.640156   904 solver.cpp:229] Iteration 136160, loss = 2.25451
I0605 19:05:09.640434   904 solver.cpp:245]     Train net output #0: loss = 2.36152 (* 1 = 2.36152 loss)
I0605 19:05:09.640445   904 sgd_solver.cpp:106] Iteration 136160, lr = 0.00796235
I0605 19:05:30.676944   904 solver.cpp:229] Iteration 136200, loss = 2.2495
I0605 19:05:30.677000   904 solver.cpp:245]     Train net output #0: loss = 2.36182 (* 1 = 2.36182 loss)
I0605 19:05:30.677012   904 sgd_solver.cpp:106] Iteration 136200, lr = 0.00795294
I0605 19:05:51.691398   904 solver.cpp:229] Iteration 136240, loss = 2.24861
I0605 19:05:51.691597   904 solver.cpp:245]     Train net output #0: loss = 2.27559 (* 1 = 2.27559 loss)
I0605 19:05:51.691607   904 sgd_solver.cpp:106] Iteration 136240, lr = 0.00794353
I0605 19:06:12.711143   904 solver.cpp:229] Iteration 136280, loss = 2.26439
I0605 19:06:12.711184   904 solver.cpp:245]     Train net output #0: loss = 2.18122 (* 1 = 2.18122 loss)
I0605 19:06:12.711194   904 sgd_solver.cpp:106] Iteration 136280, lr = 0.00793412
I0605 19:06:33.619491   904 solver.cpp:229] Iteration 136320, loss = 2.26956
I0605 19:06:33.619740   904 solver.cpp:245]     Train net output #0: loss = 2.01858 (* 1 = 2.01858 loss)
I0605 19:06:33.619766   904 sgd_solver.cpp:106] Iteration 136320, lr = 0.00792471
I0605 19:06:54.282938   904 solver.cpp:229] Iteration 136360, loss = 2.26006
I0605 19:06:54.282991   904 solver.cpp:245]     Train net output #0: loss = 2.52018 (* 1 = 2.52018 loss)
I0605 19:06:54.283002   904 sgd_solver.cpp:106] Iteration 136360, lr = 0.00791529
I0605 19:07:14.787654   904 solver.cpp:229] Iteration 136400, loss = 2.24362
I0605 19:07:14.787859   904 solver.cpp:245]     Train net output #0: loss = 2.22271 (* 1 = 2.22271 loss)
I0605 19:07:14.787871   904 sgd_solver.cpp:106] Iteration 136400, lr = 0.00790588
I0605 19:07:35.288641   904 solver.cpp:229] Iteration 136440, loss = 2.23991
I0605 19:07:35.288687   904 solver.cpp:245]     Train net output #0: loss = 2.34774 (* 1 = 2.34774 loss)
I0605 19:07:35.288697   904 sgd_solver.cpp:106] Iteration 136440, lr = 0.00789647
I0605 19:07:55.538801   904 solver.cpp:229] Iteration 136480, loss = 2.28891
I0605 19:07:55.539059   904 solver.cpp:245]     Train net output #0: loss = 2.38112 (* 1 = 2.38112 loss)
I0605 19:07:55.539083   904 sgd_solver.cpp:106] Iteration 136480, lr = 0.00788706
I0605 19:08:06.610724   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 19:08:15.673687   904 solver.cpp:229] Iteration 136520, loss = 2.24066
I0605 19:08:15.673756   904 solver.cpp:245]     Train net output #0: loss = 2.0697 (* 1 = 2.0697 loss)
I0605 19:08:15.673769   904 sgd_solver.cpp:106] Iteration 136520, lr = 0.00787765
I0605 19:08:35.818156   904 solver.cpp:229] Iteration 136560, loss = 2.26556
I0605 19:08:35.818341   904 solver.cpp:245]     Train net output #0: loss = 2.26168 (* 1 = 2.26168 loss)
I0605 19:08:35.818353   904 sgd_solver.cpp:106] Iteration 136560, lr = 0.00786823
I0605 19:08:55.842689   904 solver.cpp:229] Iteration 136600, loss = 2.29164
I0605 19:08:55.842732   904 solver.cpp:245]     Train net output #0: loss = 2.3228 (* 1 = 2.3228 loss)
I0605 19:08:55.842743   904 sgd_solver.cpp:106] Iteration 136600, lr = 0.00785882
I0605 19:09:15.858592   904 solver.cpp:229] Iteration 136640, loss = 2.26372
I0605 19:09:15.858794   904 solver.cpp:245]     Train net output #0: loss = 2.03669 (* 1 = 2.03669 loss)
I0605 19:09:15.858821   904 sgd_solver.cpp:106] Iteration 136640, lr = 0.00784941
I0605 19:09:35.871999   904 solver.cpp:229] Iteration 136680, loss = 2.30324
I0605 19:09:35.872057   904 solver.cpp:245]     Train net output #0: loss = 2.75004 (* 1 = 2.75004 loss)
I0605 19:09:35.872067   904 sgd_solver.cpp:106] Iteration 136680, lr = 0.00784
I0605 19:09:56.077512   904 solver.cpp:229] Iteration 136720, loss = 2.26349
I0605 19:09:56.077750   904 solver.cpp:245]     Train net output #0: loss = 2.56592 (* 1 = 2.56592 loss)
I0605 19:09:56.077776   904 sgd_solver.cpp:106] Iteration 136720, lr = 0.00783059
I0605 19:10:16.428783   904 solver.cpp:229] Iteration 136760, loss = 2.29584
I0605 19:10:16.428838   904 solver.cpp:245]     Train net output #0: loss = 2.26499 (* 1 = 2.26499 loss)
I0605 19:10:16.428853   904 sgd_solver.cpp:106] Iteration 136760, lr = 0.00782118
I0605 19:10:36.651365   904 solver.cpp:229] Iteration 136800, loss = 2.26134
I0605 19:10:36.651644   904 solver.cpp:245]     Train net output #0: loss = 2.37725 (* 1 = 2.37725 loss)
I0605 19:10:36.651669   904 sgd_solver.cpp:106] Iteration 136800, lr = 0.00781177
I0605 19:10:56.903833   904 solver.cpp:229] Iteration 136840, loss = 2.25885
I0605 19:10:56.903889   904 solver.cpp:245]     Train net output #0: loss = 2.32281 (* 1 = 2.32281 loss)
I0605 19:10:56.903898   904 sgd_solver.cpp:106] Iteration 136840, lr = 0.00780235
I0605 19:11:17.208711   904 solver.cpp:229] Iteration 136880, loss = 2.2689
I0605 19:11:17.208945   904 solver.cpp:245]     Train net output #0: loss = 2.48937 (* 1 = 2.48937 loss)
I0605 19:11:17.208972   904 sgd_solver.cpp:106] Iteration 136880, lr = 0.00779294
I0605 19:11:37.481696   904 solver.cpp:229] Iteration 136920, loss = 2.24976
I0605 19:11:37.481748   904 solver.cpp:245]     Train net output #0: loss = 2.0569 (* 1 = 2.0569 loss)
I0605 19:11:37.481757   904 sgd_solver.cpp:106] Iteration 136920, lr = 0.00778353
I0605 19:11:57.762470   904 solver.cpp:229] Iteration 136960, loss = 2.24832
I0605 19:11:57.762671   904 solver.cpp:245]     Train net output #0: loss = 2.39206 (* 1 = 2.39206 loss)
I0605 19:11:57.762694   904 sgd_solver.cpp:106] Iteration 136960, lr = 0.00777412
I0605 19:12:17.509796   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_137000.caffemodel
I0605 19:12:17.762127   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_137000.solverstate
I0605 19:12:17.841342   904 solver.cpp:338] Iteration 137000, Testing net (#0)
I0605 19:12:17.841418   904 net.cpp:748] Ignoring source layer loss
I0605 19:12:19.737149   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 19:12:52.512467   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 19:13:25.064574   904 solver.cpp:406]     Test net output #0: accuracy = 0.48842
I0605 19:13:25.064704   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.73274
I0605 19:13:25.381783   904 solver.cpp:229] Iteration 137000, loss = 2.26777
I0605 19:13:25.381834   904 solver.cpp:245]     Train net output #0: loss = 2.29443 (* 1 = 2.29443 loss)
I0605 19:13:25.381844   904 sgd_solver.cpp:106] Iteration 137000, lr = 0.00776471
I0605 19:13:40.011235   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 19:13:44.581532   904 solver.cpp:229] Iteration 137040, loss = 2.23602
I0605 19:13:44.581576   904 solver.cpp:245]     Train net output #0: loss = 2.21001 (* 1 = 2.21001 loss)
I0605 19:13:44.581586   904 sgd_solver.cpp:106] Iteration 137040, lr = 0.00775529
I0605 19:14:05.807430   904 solver.cpp:229] Iteration 137080, loss = 2.26245
I0605 19:14:05.807662   904 solver.cpp:245]     Train net output #0: loss = 2.18219 (* 1 = 2.18219 loss)
I0605 19:14:05.807687   904 sgd_solver.cpp:106] Iteration 137080, lr = 0.00774588
I0605 19:14:27.239369   904 solver.cpp:229] Iteration 137120, loss = 2.24748
I0605 19:14:27.239436   904 solver.cpp:245]     Train net output #0: loss = 2.2313 (* 1 = 2.2313 loss)
I0605 19:14:27.239447   904 sgd_solver.cpp:106] Iteration 137120, lr = 0.00773647
I0605 19:14:48.217586   904 solver.cpp:229] Iteration 137160, loss = 2.24997
I0605 19:14:48.217723   904 solver.cpp:245]     Train net output #0: loss = 2.50638 (* 1 = 2.50638 loss)
I0605 19:14:48.217731   904 sgd_solver.cpp:106] Iteration 137160, lr = 0.00772706
I0605 19:15:09.186436   904 solver.cpp:229] Iteration 137200, loss = 2.23642
I0605 19:15:09.186472   904 solver.cpp:245]     Train net output #0: loss = 2.24499 (* 1 = 2.24499 loss)
I0605 19:15:09.186480   904 sgd_solver.cpp:106] Iteration 137200, lr = 0.00771765
I0605 19:15:30.138861   904 solver.cpp:229] Iteration 137240, loss = 2.25299
I0605 19:15:30.139025   904 solver.cpp:245]     Train net output #0: loss = 2.36358 (* 1 = 2.36358 loss)
I0605 19:15:30.139051   904 sgd_solver.cpp:106] Iteration 137240, lr = 0.00770823
I0605 19:15:50.883358   904 solver.cpp:229] Iteration 137280, loss = 2.24983
I0605 19:15:50.883404   904 solver.cpp:245]     Train net output #0: loss = 2.40409 (* 1 = 2.40409 loss)
I0605 19:15:50.883416   904 sgd_solver.cpp:106] Iteration 137280, lr = 0.00769882
I0605 19:16:11.542448   904 solver.cpp:229] Iteration 137320, loss = 2.2543
I0605 19:16:11.542724   904 solver.cpp:245]     Train net output #0: loss = 2.09818 (* 1 = 2.09818 loss)
I0605 19:16:11.542744   904 sgd_solver.cpp:106] Iteration 137320, lr = 0.00768941
I0605 19:16:32.198964   904 solver.cpp:229] Iteration 137360, loss = 2.24844
I0605 19:16:32.199012   904 solver.cpp:245]     Train net output #0: loss = 2.43849 (* 1 = 2.43849 loss)
I0605 19:16:32.199021   904 sgd_solver.cpp:106] Iteration 137360, lr = 0.00768
I0605 19:16:52.887795   904 solver.cpp:229] Iteration 137400, loss = 2.26682
I0605 19:16:52.888010   904 solver.cpp:245]     Train net output #0: loss = 2.48252 (* 1 = 2.48252 loss)
I0605 19:16:52.888039   904 sgd_solver.cpp:106] Iteration 137400, lr = 0.00767059
I0605 19:17:13.564538   904 solver.cpp:229] Iteration 137440, loss = 2.23776
I0605 19:17:13.564584   904 solver.cpp:245]     Train net output #0: loss = 2.26357 (* 1 = 2.26357 loss)
I0605 19:17:13.564592   904 sgd_solver.cpp:106] Iteration 137440, lr = 0.00766118
I0605 19:17:34.115339   904 solver.cpp:229] Iteration 137480, loss = 2.21094
I0605 19:17:34.115527   904 solver.cpp:245]     Train net output #0: loss = 2.46106 (* 1 = 2.46106 loss)
I0605 19:17:34.115557   904 sgd_solver.cpp:106] Iteration 137480, lr = 0.00765177
I0605 19:17:54.636072   904 solver.cpp:229] Iteration 137520, loss = 2.2701
I0605 19:17:54.636149   904 solver.cpp:245]     Train net output #0: loss = 2.28718 (* 1 = 2.28718 loss)
I0605 19:17:54.636163   904 sgd_solver.cpp:106] Iteration 137520, lr = 0.00764235
I0605 19:18:15.114178   904 solver.cpp:229] Iteration 137560, loss = 2.25801
I0605 19:18:15.114322   904 solver.cpp:245]     Train net output #0: loss = 2.17467 (* 1 = 2.17467 loss)
I0605 19:18:15.114331   904 sgd_solver.cpp:106] Iteration 137560, lr = 0.00763294
I0605 19:18:24.092741   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 19:18:35.624270   904 solver.cpp:229] Iteration 137600, loss = 2.23235
I0605 19:18:35.624325   904 solver.cpp:245]     Train net output #0: loss = 2.22271 (* 1 = 2.22271 loss)
I0605 19:18:35.624335   904 sgd_solver.cpp:106] Iteration 137600, lr = 0.00762353
I0605 19:18:56.128707   904 solver.cpp:229] Iteration 137640, loss = 2.27737
I0605 19:18:56.128916   904 solver.cpp:245]     Train net output #0: loss = 2.44413 (* 1 = 2.44413 loss)
I0605 19:18:56.128945   904 sgd_solver.cpp:106] Iteration 137640, lr = 0.00761412
I0605 19:19:16.644448   904 solver.cpp:229] Iteration 137680, loss = 2.28727
I0605 19:19:16.644515   904 solver.cpp:245]     Train net output #0: loss = 2.2762 (* 1 = 2.2762 loss)
I0605 19:19:16.644525   904 sgd_solver.cpp:106] Iteration 137680, lr = 0.00760471
I0605 19:19:37.123957   904 solver.cpp:229] Iteration 137720, loss = 2.24622
I0605 19:19:37.124162   904 solver.cpp:245]     Train net output #0: loss = 2.37847 (* 1 = 2.37847 loss)
I0605 19:19:37.124199   904 sgd_solver.cpp:106] Iteration 137720, lr = 0.00759529
I0605 19:19:57.608968   904 solver.cpp:229] Iteration 137760, loss = 2.23941
I0605 19:19:57.609011   904 solver.cpp:245]     Train net output #0: loss = 2.34744 (* 1 = 2.34744 loss)
I0605 19:19:57.609021   904 sgd_solver.cpp:106] Iteration 137760, lr = 0.00758588
I0605 19:20:18.116109   904 solver.cpp:229] Iteration 137800, loss = 2.26457
I0605 19:20:18.116284   904 solver.cpp:245]     Train net output #0: loss = 2.31423 (* 1 = 2.31423 loss)
I0605 19:20:18.116314   904 sgd_solver.cpp:106] Iteration 137800, lr = 0.00757647
I0605 19:20:38.633535   904 solver.cpp:229] Iteration 137840, loss = 2.26661
I0605 19:20:38.633577   904 solver.cpp:245]     Train net output #0: loss = 2.37396 (* 1 = 2.37396 loss)
I0605 19:20:38.633586   904 sgd_solver.cpp:106] Iteration 137840, lr = 0.00756706
I0605 19:20:58.943400   904 solver.cpp:229] Iteration 137880, loss = 2.25638
I0605 19:20:58.943609   904 solver.cpp:245]     Train net output #0: loss = 2.22917 (* 1 = 2.22917 loss)
I0605 19:20:58.943645   904 sgd_solver.cpp:106] Iteration 137880, lr = 0.00755765
I0605 19:21:19.261795   904 solver.cpp:229] Iteration 137920, loss = 2.25096
I0605 19:21:19.261836   904 solver.cpp:245]     Train net output #0: loss = 1.91815 (* 1 = 1.91815 loss)
I0605 19:21:19.261844   904 sgd_solver.cpp:106] Iteration 137920, lr = 0.00754823
I0605 19:21:39.749058   904 solver.cpp:229] Iteration 137960, loss = 2.25473
I0605 19:21:39.749219   904 solver.cpp:245]     Train net output #0: loss = 2.13078 (* 1 = 2.13078 loss)
I0605 19:21:39.749241   904 sgd_solver.cpp:106] Iteration 137960, lr = 0.00753882
I0605 19:21:59.750661   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_138000.caffemodel
I0605 19:22:00.015466   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_138000.solverstate
I0605 19:22:00.092936   904 solver.cpp:338] Iteration 138000, Testing net (#0)
I0605 19:22:00.093013   904 net.cpp:748] Ignoring source layer loss
I0605 19:22:10.369786   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 19:22:43.672358   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 19:23:08.244817   904 solver.cpp:406]     Test net output #0: accuracy = 0.48976
I0605 19:23:08.244863   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.732139
I0605 19:23:08.561487   904 solver.cpp:229] Iteration 138000, loss = 2.23195
I0605 19:23:08.561534   904 solver.cpp:245]     Train net output #0: loss = 2.53519 (* 1 = 2.53519 loss)
I0605 19:23:08.561542   904 sgd_solver.cpp:106] Iteration 138000, lr = 0.00752941
I0605 19:23:27.771390   904 solver.cpp:229] Iteration 138040, loss = 2.24938
I0605 19:23:27.771550   904 solver.cpp:245]     Train net output #0: loss = 2.25199 (* 1 = 2.25199 loss)
I0605 19:23:27.771564   904 sgd_solver.cpp:106] Iteration 138040, lr = 0.00752
I0605 19:23:49.235298   904 solver.cpp:229] Iteration 138080, loss = 2.25141
I0605 19:23:49.235345   904 solver.cpp:245]     Train net output #0: loss = 2.44064 (* 1 = 2.44064 loss)
I0605 19:23:49.235353   904 sgd_solver.cpp:106] Iteration 138080, lr = 0.00751059
I0605 19:24:10.758994   904 solver.cpp:229] Iteration 138120, loss = 2.29738
I0605 19:24:10.759137   904 solver.cpp:245]     Train net output #0: loss = 2.16739 (* 1 = 2.16739 loss)
I0605 19:24:10.759148   904 sgd_solver.cpp:106] Iteration 138120, lr = 0.00750118
I0605 19:24:28.117523   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 19:24:31.777389   904 solver.cpp:229] Iteration 138160, loss = 2.24001
I0605 19:24:31.777437   904 solver.cpp:245]     Train net output #0: loss = 2.32886 (* 1 = 2.32886 loss)
I0605 19:24:31.777446   904 sgd_solver.cpp:106] Iteration 138160, lr = 0.00749177
I0605 19:24:52.737602   904 solver.cpp:229] Iteration 138200, loss = 2.25817
I0605 19:24:52.737818   904 solver.cpp:245]     Train net output #0: loss = 2.22665 (* 1 = 2.22665 loss)
I0605 19:24:52.737850   904 sgd_solver.cpp:106] Iteration 138200, lr = 0.00748235
I0605 19:25:13.773447   904 solver.cpp:229] Iteration 138240, loss = 2.24853
I0605 19:25:13.773500   904 solver.cpp:245]     Train net output #0: loss = 2.29389 (* 1 = 2.29389 loss)
I0605 19:25:13.773509   904 sgd_solver.cpp:106] Iteration 138240, lr = 0.00747294
I0605 19:25:34.847044   904 solver.cpp:229] Iteration 138280, loss = 2.29207
I0605 19:25:34.847259   904 solver.cpp:245]     Train net output #0: loss = 2.21693 (* 1 = 2.21693 loss)
I0605 19:25:34.847287   904 sgd_solver.cpp:106] Iteration 138280, lr = 0.00746353
I0605 19:25:55.640983   904 solver.cpp:229] Iteration 138320, loss = 2.21954
I0605 19:25:55.641036   904 solver.cpp:245]     Train net output #0: loss = 2.21172 (* 1 = 2.21172 loss)
I0605 19:25:55.641044   904 sgd_solver.cpp:106] Iteration 138320, lr = 0.00745412
I0605 19:26:16.454337   904 solver.cpp:229] Iteration 138360, loss = 2.25509
I0605 19:26:16.454577   904 solver.cpp:245]     Train net output #0: loss = 2.34359 (* 1 = 2.34359 loss)
I0605 19:26:16.454607   904 sgd_solver.cpp:106] Iteration 138360, lr = 0.00744471
I0605 19:26:37.409710   904 solver.cpp:229] Iteration 138400, loss = 2.27528
I0605 19:26:37.409747   904 solver.cpp:245]     Train net output #0: loss = 2.18372 (* 1 = 2.18372 loss)
I0605 19:26:37.409754   904 sgd_solver.cpp:106] Iteration 138400, lr = 0.00743529
I0605 19:26:58.045418   904 solver.cpp:229] Iteration 138440, loss = 2.23475
I0605 19:26:58.045608   904 solver.cpp:245]     Train net output #0: loss = 2.24297 (* 1 = 2.24297 loss)
I0605 19:26:58.045629   904 sgd_solver.cpp:106] Iteration 138440, lr = 0.00742588
I0605 19:27:18.812721   904 solver.cpp:229] Iteration 138480, loss = 2.1992
I0605 19:27:18.812775   904 solver.cpp:245]     Train net output #0: loss = 2.16714 (* 1 = 2.16714 loss)
I0605 19:27:18.812788   904 sgd_solver.cpp:106] Iteration 138480, lr = 0.00741647
I0605 19:27:39.606721   904 solver.cpp:229] Iteration 138520, loss = 2.24836
I0605 19:27:39.606930   904 solver.cpp:245]     Train net output #0: loss = 2.3015 (* 1 = 2.3015 loss)
I0605 19:27:39.606959   904 sgd_solver.cpp:106] Iteration 138520, lr = 0.00740706
I0605 19:28:00.390463   904 solver.cpp:229] Iteration 138560, loss = 2.2204
I0605 19:28:00.390513   904 solver.cpp:245]     Train net output #0: loss = 2.33891 (* 1 = 2.33891 loss)
I0605 19:28:00.390525   904 sgd_solver.cpp:106] Iteration 138560, lr = 0.00739765
I0605 19:28:21.043445   904 solver.cpp:229] Iteration 138600, loss = 2.24765
I0605 19:28:21.043588   904 solver.cpp:245]     Train net output #0: loss = 2.31125 (* 1 = 2.31125 loss)
I0605 19:28:21.043598   904 sgd_solver.cpp:106] Iteration 138600, lr = 0.00738823
I0605 19:28:41.677095   904 solver.cpp:229] Iteration 138640, loss = 2.2037
I0605 19:28:41.677153   904 solver.cpp:245]     Train net output #0: loss = 2.28385 (* 1 = 2.28385 loss)
I0605 19:28:41.677161   904 sgd_solver.cpp:106] Iteration 138640, lr = 0.00737882
I0605 19:29:02.328238   904 solver.cpp:229] Iteration 138680, loss = 2.26745
I0605 19:29:02.328457   904 solver.cpp:245]     Train net output #0: loss = 2.21284 (* 1 = 2.21284 loss)
I0605 19:29:02.328485   904 sgd_solver.cpp:106] Iteration 138680, lr = 0.00736941
I0605 19:29:22.822383   904 solver.cpp:229] Iteration 138720, loss = 2.21938
I0605 19:29:22.822441   904 solver.cpp:245]     Train net output #0: loss = 2.15195 (* 1 = 2.15195 loss)
I0605 19:29:22.822450   904 sgd_solver.cpp:106] Iteration 138720, lr = 0.00736
I0605 19:29:43.316095   904 solver.cpp:229] Iteration 138760, loss = 2.25163
I0605 19:29:43.316282   904 solver.cpp:245]     Train net output #0: loss = 1.99809 (* 1 = 1.99809 loss)
I0605 19:29:43.316310   904 sgd_solver.cpp:106] Iteration 138760, lr = 0.00735059
I0605 19:29:47.934723   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 19:30:03.811554   904 solver.cpp:229] Iteration 138800, loss = 2.24203
I0605 19:30:03.811605   904 solver.cpp:245]     Train net output #0: loss = 2.28899 (* 1 = 2.28899 loss)
I0605 19:30:03.811614   904 sgd_solver.cpp:106] Iteration 138800, lr = 0.00734118
I0605 19:30:24.307685   904 solver.cpp:229] Iteration 138840, loss = 2.23271
I0605 19:30:24.307894   904 solver.cpp:245]     Train net output #0: loss = 2.18212 (* 1 = 2.18212 loss)
I0605 19:30:24.307919   904 sgd_solver.cpp:106] Iteration 138840, lr = 0.00733176
I0605 19:30:44.781947   904 solver.cpp:229] Iteration 138880, loss = 2.23828
I0605 19:30:44.781999   904 solver.cpp:245]     Train net output #0: loss = 1.90347 (* 1 = 1.90347 loss)
I0605 19:30:44.782008   904 sgd_solver.cpp:106] Iteration 138880, lr = 0.00732235
I0605 19:31:05.281492   904 solver.cpp:229] Iteration 138920, loss = 2.22648
I0605 19:31:05.281635   904 solver.cpp:245]     Train net output #0: loss = 2.40962 (* 1 = 2.40962 loss)
I0605 19:31:05.281643   904 sgd_solver.cpp:106] Iteration 138920, lr = 0.00731294
I0605 19:31:25.758884   904 solver.cpp:229] Iteration 138960, loss = 2.2391
I0605 19:31:25.758935   904 solver.cpp:245]     Train net output #0: loss = 2.50257 (* 1 = 2.50257 loss)
I0605 19:31:25.758944   904 sgd_solver.cpp:106] Iteration 138960, lr = 0.00730353
I0605 19:31:45.660341   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_139000.caffemodel
I0605 19:31:45.927739   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_139000.solverstate
I0605 19:31:46.008591   904 solver.cpp:338] Iteration 139000, Testing net (#0)
I0605 19:31:46.008671   904 net.cpp:748] Ignoring source layer loss
I0605 19:32:05.788570   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 19:32:38.780289   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 19:32:51.219177   904 solver.cpp:406]     Test net output #0: accuracy = 0.488701
I0605 19:32:51.219208   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.733041
I0605 19:32:51.534530   904 solver.cpp:229] Iteration 139000, loss = 2.21975
I0605 19:32:51.534570   904 solver.cpp:245]     Train net output #0: loss = 2.27049 (* 1 = 2.27049 loss)
I0605 19:32:51.534579   904 sgd_solver.cpp:106] Iteration 139000, lr = 0.00729412
I0605 19:33:10.734647   904 solver.cpp:229] Iteration 139040, loss = 2.24498
I0605 19:33:10.734848   904 solver.cpp:245]     Train net output #0: loss = 2.26357 (* 1 = 2.26357 loss)
I0605 19:33:10.734875   904 sgd_solver.cpp:106] Iteration 139040, lr = 0.00728471
I0605 19:33:32.127140   904 solver.cpp:229] Iteration 139080, loss = 2.26342
I0605 19:33:32.127182   904 solver.cpp:245]     Train net output #0: loss = 2.29562 (* 1 = 2.29562 loss)
I0605 19:33:32.127193   904 sgd_solver.cpp:106] Iteration 139080, lr = 0.00727529
I0605 19:33:53.670958   904 solver.cpp:229] Iteration 139120, loss = 2.25665
I0605 19:33:53.671139   904 solver.cpp:245]     Train net output #0: loss = 2.42604 (* 1 = 2.42604 loss)
I0605 19:33:53.671160   904 sgd_solver.cpp:106] Iteration 139120, lr = 0.00726588
I0605 19:34:14.873353   904 solver.cpp:229] Iteration 139160, loss = 2.23255
I0605 19:34:14.873399   904 solver.cpp:245]     Train net output #0: loss = 2.00142 (* 1 = 2.00142 loss)
I0605 19:34:14.873404   904 sgd_solver.cpp:106] Iteration 139160, lr = 0.00725647
I0605 19:34:35.856554   904 solver.cpp:229] Iteration 139200, loss = 2.27915
I0605 19:34:35.856740   904 solver.cpp:245]     Train net output #0: loss = 2.22208 (* 1 = 2.22208 loss)
I0605 19:34:35.856770   904 sgd_solver.cpp:106] Iteration 139200, lr = 0.00724706
I0605 19:34:56.834422   904 solver.cpp:229] Iteration 139240, loss = 2.26442
I0605 19:34:56.834477   904 solver.cpp:245]     Train net output #0: loss = 2.37365 (* 1 = 2.37365 loss)
I0605 19:34:56.834491   904 sgd_solver.cpp:106] Iteration 139240, lr = 0.00723765
I0605 19:35:17.810225   904 solver.cpp:229] Iteration 139280, loss = 2.26135
I0605 19:35:17.810369   904 solver.cpp:245]     Train net output #0: loss = 2.05336 (* 1 = 2.05336 loss)
I0605 19:35:17.810380   904 sgd_solver.cpp:106] Iteration 139280, lr = 0.00722824
I0605 19:35:38.701371   904 solver.cpp:229] Iteration 139320, loss = 2.26644
I0605 19:35:38.701422   904 solver.cpp:245]     Train net output #0: loss = 2.42853 (* 1 = 2.42853 loss)
I0605 19:35:38.701431   904 sgd_solver.cpp:106] Iteration 139320, lr = 0.00721882
I0605 19:35:39.742725   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 19:35:59.501591   904 solver.cpp:229] Iteration 139360, loss = 2.20876
I0605 19:35:59.501767   904 solver.cpp:245]     Train net output #0: loss = 2.22096 (* 1 = 2.22096 loss)
I0605 19:35:59.501792   904 sgd_solver.cpp:106] Iteration 139360, lr = 0.00720941
I0605 19:36:20.314651   904 solver.cpp:229] Iteration 139400, loss = 2.22932
I0605 19:36:20.314697   904 solver.cpp:245]     Train net output #0: loss = 2.05097 (* 1 = 2.05097 loss)
I0605 19:36:20.314707   904 sgd_solver.cpp:106] Iteration 139400, lr = 0.0072
I0605 19:36:41.167569   904 solver.cpp:229] Iteration 139440, loss = 2.22459
I0605 19:36:41.167718   904 solver.cpp:245]     Train net output #0: loss = 2.23994 (* 1 = 2.23994 loss)
I0605 19:36:41.167731   904 sgd_solver.cpp:106] Iteration 139440, lr = 0.00719059
I0605 19:37:01.663300   904 solver.cpp:229] Iteration 139480, loss = 2.23638
I0605 19:37:01.663357   904 solver.cpp:245]     Train net output #0: loss = 2.2347 (* 1 = 2.2347 loss)
I0605 19:37:01.663372   904 sgd_solver.cpp:106] Iteration 139480, lr = 0.00718118
I0605 19:37:22.264504   904 solver.cpp:229] Iteration 139520, loss = 2.24862
I0605 19:37:22.264756   904 solver.cpp:245]     Train net output #0: loss = 2.11856 (* 1 = 2.11856 loss)
I0605 19:37:22.264785   904 sgd_solver.cpp:106] Iteration 139520, lr = 0.00717176
I0605 19:37:42.903813   904 solver.cpp:229] Iteration 139560, loss = 2.20766
I0605 19:37:42.903867   904 solver.cpp:245]     Train net output #0: loss = 2.58364 (* 1 = 2.58364 loss)
I0605 19:37:42.903877   904 sgd_solver.cpp:106] Iteration 139560, lr = 0.00716235
I0605 19:38:03.437253   904 solver.cpp:229] Iteration 139600, loss = 2.22012
I0605 19:38:03.437469   904 solver.cpp:245]     Train net output #0: loss = 2.25514 (* 1 = 2.25514 loss)
I0605 19:38:03.437497   904 sgd_solver.cpp:106] Iteration 139600, lr = 0.00715294
I0605 19:38:23.930733   904 solver.cpp:229] Iteration 139640, loss = 2.20406
I0605 19:38:23.930785   904 solver.cpp:245]     Train net output #0: loss = 2.30944 (* 1 = 2.30944 loss)
I0605 19:38:23.930794   904 sgd_solver.cpp:106] Iteration 139640, lr = 0.00714353
I0605 19:38:44.442389   904 solver.cpp:229] Iteration 139680, loss = 2.20483
I0605 19:38:44.442571   904 solver.cpp:245]     Train net output #0: loss = 2.13943 (* 1 = 2.13943 loss)
I0605 19:38:44.442596   904 sgd_solver.cpp:106] Iteration 139680, lr = 0.00713412
I0605 19:39:04.950951   904 solver.cpp:229] Iteration 139720, loss = 2.24294
I0605 19:39:04.951012   904 solver.cpp:245]     Train net output #0: loss = 2.22475 (* 1 = 2.22475 loss)
I0605 19:39:04.951023   904 sgd_solver.cpp:106] Iteration 139720, lr = 0.00712471
I0605 19:39:25.458147   904 solver.cpp:229] Iteration 139760, loss = 2.22656
I0605 19:39:25.458303   904 solver.cpp:245]     Train net output #0: loss = 2.0862 (* 1 = 2.0862 loss)
I0605 19:39:25.458330   904 sgd_solver.cpp:106] Iteration 139760, lr = 0.00711529
I0605 19:39:45.964354   904 solver.cpp:229] Iteration 139800, loss = 2.26386
I0605 19:39:45.964411   904 solver.cpp:245]     Train net output #0: loss = 2.31539 (* 1 = 2.31539 loss)
I0605 19:39:45.964426   904 sgd_solver.cpp:106] Iteration 139800, lr = 0.00710588
I0605 19:39:58.636715   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 19:40:06.233968   904 solver.cpp:229] Iteration 139840, loss = 2.18458
I0605 19:40:06.234014   904 solver.cpp:245]     Train net output #0: loss = 2.04095 (* 1 = 2.04095 loss)
I0605 19:40:06.234022   904 sgd_solver.cpp:106] Iteration 139840, lr = 0.00709647
I0605 19:40:26.505713   904 solver.cpp:229] Iteration 139880, loss = 2.23895
I0605 19:40:26.505755   904 solver.cpp:245]     Train net output #0: loss = 2.42055 (* 1 = 2.42055 loss)
I0605 19:40:26.505764   904 sgd_solver.cpp:106] Iteration 139880, lr = 0.00708706
I0605 19:40:46.784421   904 solver.cpp:229] Iteration 139920, loss = 2.26187
I0605 19:40:46.784590   904 solver.cpp:245]     Train net output #0: loss = 2.53544 (* 1 = 2.53544 loss)
I0605 19:40:46.784616   904 sgd_solver.cpp:106] Iteration 139920, lr = 0.00707765
I0605 19:41:07.051060   904 solver.cpp:229] Iteration 139960, loss = 2.20921
I0605 19:41:07.051103   904 solver.cpp:245]     Train net output #0: loss = 2.19418 (* 1 = 2.19418 loss)
I0605 19:41:07.051112   904 sgd_solver.cpp:106] Iteration 139960, lr = 0.00706824
I0605 19:41:26.821120   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_140000.caffemodel
I0605 19:41:27.079005   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_140000.solverstate
I0605 19:41:27.159590   904 solver.cpp:338] Iteration 140000, Testing net (#0)
I0605 19:41:27.159668   904 net.cpp:748] Ignoring source layer loss
I0605 19:41:50.734577   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 19:42:24.481987   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 19:42:35.436512   904 solver.cpp:406]     Test net output #0: accuracy = 0.48364
I0605 19:42:35.436565   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.72942
I0605 19:42:35.750820   904 solver.cpp:229] Iteration 140000, loss = 2.21218
I0605 19:42:35.750877   904 solver.cpp:245]     Train net output #0: loss = 2.36043 (* 1 = 2.36043 loss)
I0605 19:42:35.750887   904 sgd_solver.cpp:106] Iteration 140000, lr = 0.00705882
I0605 19:42:54.916821   904 solver.cpp:229] Iteration 140040, loss = 2.25353
I0605 19:42:54.916935   904 solver.cpp:245]     Train net output #0: loss = 2.16583 (* 1 = 2.16583 loss)
I0605 19:42:54.916947   904 sgd_solver.cpp:106] Iteration 140040, lr = 0.00704941
I0605 19:43:16.235149   904 solver.cpp:229] Iteration 140080, loss = 2.23413
I0605 19:43:16.235206   904 solver.cpp:245]     Train net output #0: loss = 2.11021 (* 1 = 2.11021 loss)
I0605 19:43:16.235216   904 sgd_solver.cpp:106] Iteration 140080, lr = 0.00704
I0605 19:43:37.678802   904 solver.cpp:229] Iteration 140120, loss = 2.21685
I0605 19:43:37.678987   904 solver.cpp:245]     Train net output #0: loss = 1.99192 (* 1 = 1.99192 loss)
I0605 19:43:37.679013   904 sgd_solver.cpp:106] Iteration 140120, lr = 0.00703059
I0605 19:43:58.716897   904 solver.cpp:229] Iteration 140160, loss = 2.241
I0605 19:43:58.716939   904 solver.cpp:245]     Train net output #0: loss = 2.40696 (* 1 = 2.40696 loss)
I0605 19:43:58.716948   904 sgd_solver.cpp:106] Iteration 140160, lr = 0.00702118
I0605 19:44:19.629492   904 solver.cpp:229] Iteration 140200, loss = 2.21852
I0605 19:44:19.629684   904 solver.cpp:245]     Train net output #0: loss = 2.23904 (* 1 = 2.23904 loss)
I0605 19:44:19.629709   904 sgd_solver.cpp:106] Iteration 140200, lr = 0.00701176
I0605 19:44:40.545783   904 solver.cpp:229] Iteration 140240, loss = 2.22734
I0605 19:44:40.545833   904 solver.cpp:245]     Train net output #0: loss = 2.09659 (* 1 = 2.09659 loss)
I0605 19:44:40.545842   904 sgd_solver.cpp:106] Iteration 140240, lr = 0.00700235
I0605 19:45:01.442220   904 solver.cpp:229] Iteration 140280, loss = 2.19365
I0605 19:45:01.442450   904 solver.cpp:245]     Train net output #0: loss = 2.31293 (* 1 = 2.31293 loss)
I0605 19:45:01.442478   904 sgd_solver.cpp:106] Iteration 140280, lr = 0.00699294
I0605 19:45:22.344363   904 solver.cpp:229] Iteration 140320, loss = 2.25121
I0605 19:45:22.344419   904 solver.cpp:245]     Train net output #0: loss = 2.57132 (* 1 = 2.57132 loss)
I0605 19:45:22.344431   904 sgd_solver.cpp:106] Iteration 140320, lr = 0.00698353
I0605 19:45:34.889358   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 19:45:43.150694   904 solver.cpp:229] Iteration 140360, loss = 2.24859
I0605 19:45:43.150733   904 solver.cpp:245]     Train net output #0: loss = 2.21512 (* 1 = 2.21512 loss)
I0605 19:45:43.150743   904 sgd_solver.cpp:106] Iteration 140360, lr = 0.00697412
I0605 19:46:03.588624   904 solver.cpp:229] Iteration 140400, loss = 2.25819
I0605 19:46:03.588672   904 solver.cpp:245]     Train net output #0: loss = 2.21341 (* 1 = 2.21341 loss)
I0605 19:46:03.588682   904 sgd_solver.cpp:106] Iteration 140400, lr = 0.0069647
I0605 19:46:24.209564   904 solver.cpp:229] Iteration 140440, loss = 2.23682
I0605 19:46:24.209827   904 solver.cpp:245]     Train net output #0: loss = 2.18589 (* 1 = 2.18589 loss)
I0605 19:46:24.209856   904 sgd_solver.cpp:106] Iteration 140440, lr = 0.00695529
I0605 19:46:44.946176   904 solver.cpp:229] Iteration 140480, loss = 2.21527
I0605 19:46:44.946228   904 solver.cpp:245]     Train net output #0: loss = 1.9564 (* 1 = 1.9564 loss)
I0605 19:46:44.946239   904 sgd_solver.cpp:106] Iteration 140480, lr = 0.00694588
I0605 19:47:05.459667   904 solver.cpp:229] Iteration 140520, loss = 2.21185
I0605 19:47:05.459872   904 solver.cpp:245]     Train net output #0: loss = 2.34193 (* 1 = 2.34193 loss)
I0605 19:47:05.459908   904 sgd_solver.cpp:106] Iteration 140520, lr = 0.00693647
I0605 19:47:25.913702   904 solver.cpp:229] Iteration 140560, loss = 2.20961
I0605 19:47:25.913739   904 solver.cpp:245]     Train net output #0: loss = 2.15533 (* 1 = 2.15533 loss)
I0605 19:47:25.913745   904 sgd_solver.cpp:106] Iteration 140560, lr = 0.00692706
I0605 19:47:46.514621   904 solver.cpp:229] Iteration 140600, loss = 2.23871
I0605 19:47:46.514842   904 solver.cpp:245]     Train net output #0: loss = 2.4874 (* 1 = 2.4874 loss)
I0605 19:47:46.514853   904 sgd_solver.cpp:106] Iteration 140600, lr = 0.00691765
I0605 19:48:07.065424   904 solver.cpp:229] Iteration 140640, loss = 2.22367
I0605 19:48:07.065477   904 solver.cpp:245]     Train net output #0: loss = 2.17787 (* 1 = 2.17787 loss)
I0605 19:48:07.065487   904 sgd_solver.cpp:106] Iteration 140640, lr = 0.00690824
I0605 19:48:27.503984   904 solver.cpp:229] Iteration 140680, loss = 2.22002
I0605 19:48:27.504210   904 solver.cpp:245]     Train net output #0: loss = 2.34162 (* 1 = 2.34162 loss)
I0605 19:48:27.504236   904 sgd_solver.cpp:106] Iteration 140680, lr = 0.00689882
I0605 19:48:47.922508   904 solver.cpp:229] Iteration 140720, loss = 2.25174
I0605 19:48:47.922560   904 solver.cpp:245]     Train net output #0: loss = 2.30058 (* 1 = 2.30058 loss)
I0605 19:48:47.922569   904 sgd_solver.cpp:106] Iteration 140720, lr = 0.00688941
I0605 19:49:08.343653   904 solver.cpp:229] Iteration 140760, loss = 2.21975
I0605 19:49:08.343858   904 solver.cpp:245]     Train net output #0: loss = 2.08363 (* 1 = 2.08363 loss)
I0605 19:49:08.343884   904 sgd_solver.cpp:106] Iteration 140760, lr = 0.00688
I0605 19:49:28.780328   904 solver.cpp:229] Iteration 140800, loss = 2.25321
I0605 19:49:28.780369   904 solver.cpp:245]     Train net output #0: loss = 2.16429 (* 1 = 2.16429 loss)
I0605 19:49:28.780382   904 sgd_solver.cpp:106] Iteration 140800, lr = 0.00687059
I0605 19:49:49.208189   904 solver.cpp:229] Iteration 140840, loss = 2.20333
I0605 19:49:49.208417   904 solver.cpp:245]     Train net output #0: loss = 2.04097 (* 1 = 2.04097 loss)
I0605 19:49:49.208444   904 sgd_solver.cpp:106] Iteration 140840, lr = 0.00686118
I0605 19:49:52.279142   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 19:50:09.653419   904 solver.cpp:229] Iteration 140880, loss = 2.27276
I0605 19:50:09.653463   904 solver.cpp:245]     Train net output #0: loss = 2.18323 (* 1 = 2.18323 loss)
I0605 19:50:09.653472   904 sgd_solver.cpp:106] Iteration 140880, lr = 0.00685176
I0605 19:50:30.053745   904 solver.cpp:229] Iteration 140920, loss = 2.21869
I0605 19:50:30.053941   904 solver.cpp:245]     Train net output #0: loss = 2.23867 (* 1 = 2.23867 loss)
I0605 19:50:30.053966   904 sgd_solver.cpp:106] Iteration 140920, lr = 0.00684235
I0605 19:50:50.480284   904 solver.cpp:229] Iteration 140960, loss = 2.19965
I0605 19:50:50.480329   904 solver.cpp:245]     Train net output #0: loss = 2.24602 (* 1 = 2.24602 loss)
I0605 19:50:50.480337   904 sgd_solver.cpp:106] Iteration 140960, lr = 0.00683294
I0605 19:51:10.408629   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_141000.caffemodel
I0605 19:51:10.674288   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_141000.solverstate
I0605 19:51:10.750668   904 solver.cpp:338] Iteration 141000, Testing net (#0)
I0605 19:51:10.750730   904 net.cpp:748] Ignoring source layer loss
I0605 19:51:35.068692   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 19:52:08.460439   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 19:52:18.926204   904 solver.cpp:406]     Test net output #0: accuracy = 0.4919
I0605 19:52:18.926242   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.738519
I0605 19:52:19.240986   904 solver.cpp:229] Iteration 141000, loss = 2.21649
I0605 19:52:19.241042   904 solver.cpp:245]     Train net output #0: loss = 1.9863 (* 1 = 1.9863 loss)
I0605 19:52:19.241052   904 sgd_solver.cpp:106] Iteration 141000, lr = 0.00682353
I0605 19:52:38.495496   904 solver.cpp:229] Iteration 141040, loss = 2.21745
I0605 19:52:38.495682   904 solver.cpp:245]     Train net output #0: loss = 2.18144 (* 1 = 2.18144 loss)
I0605 19:52:38.495715   904 sgd_solver.cpp:106] Iteration 141040, lr = 0.00681412
I0605 19:53:00.001750   904 solver.cpp:229] Iteration 141080, loss = 2.19191
I0605 19:53:00.001801   904 solver.cpp:245]     Train net output #0: loss = 2.03212 (* 1 = 2.03212 loss)
I0605 19:53:00.001812   904 sgd_solver.cpp:106] Iteration 141080, lr = 0.00680471
I0605 19:53:21.517899   904 solver.cpp:229] Iteration 141120, loss = 2.2282
I0605 19:53:21.518081   904 solver.cpp:245]     Train net output #0: loss = 2.18786 (* 1 = 2.18786 loss)
I0605 19:53:21.518091   904 sgd_solver.cpp:106] Iteration 141120, lr = 0.00679529
I0605 19:53:42.992198   904 solver.cpp:229] Iteration 141160, loss = 2.209
I0605 19:53:42.992241   904 solver.cpp:245]     Train net output #0: loss = 2.49932 (* 1 = 2.49932 loss)
I0605 19:53:42.992251   904 sgd_solver.cpp:106] Iteration 141160, lr = 0.00678588
I0605 19:54:03.981081   904 solver.cpp:229] Iteration 141200, loss = 2.20841
I0605 19:54:03.981293   904 solver.cpp:245]     Train net output #0: loss = 2.42802 (* 1 = 2.42802 loss)
I0605 19:54:03.981318   904 sgd_solver.cpp:106] Iteration 141200, lr = 0.00677647
I0605 19:54:25.059031   904 solver.cpp:229] Iteration 141240, loss = 2.22588
I0605 19:54:25.059080   904 solver.cpp:245]     Train net output #0: loss = 2.06386 (* 1 = 2.06386 loss)
I0605 19:54:25.059092   904 sgd_solver.cpp:106] Iteration 141240, lr = 0.00676706
I0605 19:54:46.474438   904 solver.cpp:229] Iteration 141280, loss = 2.22734
I0605 19:54:46.474661   904 solver.cpp:245]     Train net output #0: loss = 2.23062 (* 1 = 2.23062 loss)
I0605 19:54:46.474687   904 sgd_solver.cpp:106] Iteration 141280, lr = 0.00675765
I0605 19:55:08.158633   904 solver.cpp:229] Iteration 141320, loss = 2.20488
I0605 19:55:08.158684   904 solver.cpp:245]     Train net output #0: loss = 2.13493 (* 1 = 2.13493 loss)
I0605 19:55:08.158694   904 sgd_solver.cpp:106] Iteration 141320, lr = 0.00674823
I0605 19:55:27.110651   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 19:55:28.930897   904 solver.cpp:229] Iteration 141360, loss = 2.21666
I0605 19:55:28.930937   904 solver.cpp:245]     Train net output #0: loss = 2.12127 (* 1 = 2.12127 loss)
I0605 19:55:28.930945   904 sgd_solver.cpp:106] Iteration 141360, lr = 0.00673882
I0605 19:55:49.748122   904 solver.cpp:229] Iteration 141400, loss = 2.19792
I0605 19:55:49.748162   904 solver.cpp:245]     Train net output #0: loss = 2.16565 (* 1 = 2.16565 loss)
I0605 19:55:49.748169   904 sgd_solver.cpp:106] Iteration 141400, lr = 0.00672941
I0605 19:56:10.559365   904 solver.cpp:229] Iteration 141440, loss = 2.20864
I0605 19:56:10.559561   904 solver.cpp:245]     Train net output #0: loss = 2.14324 (* 1 = 2.14324 loss)
I0605 19:56:10.559584   904 sgd_solver.cpp:106] Iteration 141440, lr = 0.00672
I0605 19:56:31.380194   904 solver.cpp:229] Iteration 141480, loss = 2.23612
I0605 19:56:31.380264   904 solver.cpp:245]     Train net output #0: loss = 1.96725 (* 1 = 1.96725 loss)
I0605 19:56:31.380272   904 sgd_solver.cpp:106] Iteration 141480, lr = 0.00671059
I0605 19:56:52.035416   904 solver.cpp:229] Iteration 141520, loss = 2.22851
I0605 19:56:52.035588   904 solver.cpp:245]     Train net output #0: loss = 2.40077 (* 1 = 2.40077 loss)
I0605 19:56:52.035599   904 sgd_solver.cpp:106] Iteration 141520, lr = 0.00670118
I0605 19:57:12.562688   904 solver.cpp:229] Iteration 141560, loss = 2.24201
I0605 19:57:12.562741   904 solver.cpp:245]     Train net output #0: loss = 2.04748 (* 1 = 2.04748 loss)
I0605 19:57:12.562752   904 sgd_solver.cpp:106] Iteration 141560, lr = 0.00669177
I0605 19:57:32.881947   904 solver.cpp:229] Iteration 141600, loss = 2.23709
I0605 19:57:32.882102   904 solver.cpp:245]     Train net output #0: loss = 2.24576 (* 1 = 2.24576 loss)
I0605 19:57:32.882114   904 sgd_solver.cpp:106] Iteration 141600, lr = 0.00668235
I0605 19:57:53.117986   904 solver.cpp:229] Iteration 141640, loss = 2.21666
I0605 19:57:53.118036   904 solver.cpp:245]     Train net output #0: loss = 2.11471 (* 1 = 2.11471 loss)
I0605 19:57:53.118046   904 sgd_solver.cpp:106] Iteration 141640, lr = 0.00667294
I0605 19:58:13.264163   904 solver.cpp:229] Iteration 141680, loss = 2.25282
I0605 19:58:13.264392   904 solver.cpp:245]     Train net output #0: loss = 2.35589 (* 1 = 2.35589 loss)
I0605 19:58:13.264405   904 sgd_solver.cpp:106] Iteration 141680, lr = 0.00666353
I0605 19:58:33.423054   904 solver.cpp:229] Iteration 141720, loss = 2.21532
I0605 19:58:33.423105   904 solver.cpp:245]     Train net output #0: loss = 2.25206 (* 1 = 2.25206 loss)
I0605 19:58:33.423115   904 sgd_solver.cpp:106] Iteration 141720, lr = 0.00665412
I0605 19:58:53.489405   904 solver.cpp:229] Iteration 141760, loss = 2.22281
I0605 19:58:53.489645   904 solver.cpp:245]     Train net output #0: loss = 2.49935 (* 1 = 2.49935 loss)
I0605 19:58:53.489672   904 sgd_solver.cpp:106] Iteration 141760, lr = 0.00664471
I0605 19:59:14.065392   904 solver.cpp:229] Iteration 141800, loss = 2.21003
I0605 19:59:14.065449   904 solver.cpp:245]     Train net output #0: loss = 2.1829 (* 1 = 2.1829 loss)
I0605 19:59:14.065459   904 sgd_solver.cpp:106] Iteration 141800, lr = 0.00663529
I0605 19:59:34.188180   904 solver.cpp:229] Iteration 141840, loss = 2.21657
I0605 19:59:34.188360   904 solver.cpp:245]     Train net output #0: loss = 1.87075 (* 1 = 1.87075 loss)
I0605 19:59:34.188390   904 sgd_solver.cpp:106] Iteration 141840, lr = 0.00662588
I0605 19:59:54.372946   904 solver.cpp:229] Iteration 141880, loss = 2.19361
I0605 19:59:54.372988   904 solver.cpp:245]     Train net output #0: loss = 2.33374 (* 1 = 2.33374 loss)
I0605 19:59:54.372997   904 sgd_solver.cpp:106] Iteration 141880, lr = 0.00661647
I0605 20:00:14.574374   904 solver.cpp:229] Iteration 141920, loss = 2.22474
I0605 20:00:14.574540   904 solver.cpp:245]     Train net output #0: loss = 2.40772 (* 1 = 2.40772 loss)
I0605 20:00:14.574571   904 sgd_solver.cpp:106] Iteration 141920, lr = 0.00660706
I0605 20:00:15.833858   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 20:00:34.739145   904 solver.cpp:229] Iteration 141960, loss = 2.20352
I0605 20:00:34.739199   904 solver.cpp:245]     Train net output #0: loss = 2.1641 (* 1 = 2.1641 loss)
I0605 20:00:34.739208   904 sgd_solver.cpp:106] Iteration 141960, lr = 0.00659765
I0605 20:00:55.211580   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_142000.caffemodel
I0605 20:00:55.494595   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_142000.solverstate
I0605 20:00:55.571815   904 solver.cpp:338] Iteration 142000, Testing net (#0)
I0605 20:00:55.571910   904 net.cpp:748] Ignoring source layer loss
I0605 20:01:23.866838   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 20:01:56.895527   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 20:02:01.094223   904 solver.cpp:406]     Test net output #0: accuracy = 0.49304
I0605 20:02:01.094276   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.73832
I0605 20:02:01.411936   904 solver.cpp:229] Iteration 142000, loss = 2.23311
I0605 20:02:01.411978   904 solver.cpp:245]     Train net output #0: loss = 2.58153 (* 1 = 2.58153 loss)
I0605 20:02:01.411988   904 sgd_solver.cpp:106] Iteration 142000, lr = 0.00658823
I0605 20:02:20.617761   904 solver.cpp:229] Iteration 142040, loss = 2.19135
I0605 20:02:20.617810   904 solver.cpp:245]     Train net output #0: loss = 1.99413 (* 1 = 1.99413 loss)
I0605 20:02:20.617818   904 sgd_solver.cpp:106] Iteration 142040, lr = 0.00657882
I0605 20:02:41.887573   904 solver.cpp:229] Iteration 142080, loss = 2.19944
I0605 20:02:41.887759   904 solver.cpp:245]     Train net output #0: loss = 2.23384 (* 1 = 2.23384 loss)
I0605 20:02:41.887787   904 sgd_solver.cpp:106] Iteration 142080, lr = 0.00656941
I0605 20:03:03.332588   904 solver.cpp:229] Iteration 142120, loss = 2.19794
I0605 20:03:03.332635   904 solver.cpp:245]     Train net output #0: loss = 2.07271 (* 1 = 2.07271 loss)
I0605 20:03:03.332644   904 sgd_solver.cpp:106] Iteration 142120, lr = 0.00656
I0605 20:03:24.320538   904 solver.cpp:229] Iteration 142160, loss = 2.18195
I0605 20:03:24.320839   904 solver.cpp:245]     Train net output #0: loss = 2.16087 (* 1 = 2.16087 loss)
I0605 20:03:24.320868   904 sgd_solver.cpp:106] Iteration 142160, lr = 0.00655059
I0605 20:03:45.298221   904 solver.cpp:229] Iteration 142200, loss = 2.18376
I0605 20:03:45.298266   904 solver.cpp:245]     Train net output #0: loss = 2.17849 (* 1 = 2.17849 loss)
I0605 20:03:45.298276   904 sgd_solver.cpp:106] Iteration 142200, lr = 0.00654118
I0605 20:04:06.301080   904 solver.cpp:229] Iteration 142240, loss = 2.23728
I0605 20:04:06.301270   904 solver.cpp:245]     Train net output #0: loss = 2.26451 (* 1 = 2.26451 loss)
I0605 20:04:06.301295   904 sgd_solver.cpp:106] Iteration 142240, lr = 0.00653177
I0605 20:04:27.276151   904 solver.cpp:229] Iteration 142280, loss = 2.20602
I0605 20:04:27.276203   904 solver.cpp:245]     Train net output #0: loss = 2.16416 (* 1 = 2.16416 loss)
I0605 20:04:27.276211   904 sgd_solver.cpp:106] Iteration 142280, lr = 0.00652235
I0605 20:04:48.170171   904 solver.cpp:229] Iteration 142320, loss = 2.21173
I0605 20:04:48.170337   904 solver.cpp:245]     Train net output #0: loss = 2.2244 (* 1 = 2.2244 loss)
I0605 20:04:48.170347   904 sgd_solver.cpp:106] Iteration 142320, lr = 0.00651294
I0605 20:05:08.938838   904 solver.cpp:229] Iteration 142360, loss = 2.17339
I0605 20:05:08.938886   904 solver.cpp:245]     Train net output #0: loss = 2.28061 (* 1 = 2.28061 loss)
I0605 20:05:08.938895   904 sgd_solver.cpp:106] Iteration 142360, lr = 0.00650353
I0605 20:05:29.611948   904 solver.cpp:229] Iteration 142400, loss = 2.21783
I0605 20:05:29.612144   904 solver.cpp:245]     Train net output #0: loss = 2.07782 (* 1 = 2.07782 loss)
I0605 20:05:29.612179   904 sgd_solver.cpp:106] Iteration 142400, lr = 0.00649412
I0605 20:05:50.314280   904 solver.cpp:229] Iteration 142440, loss = 2.19552
I0605 20:05:50.314314   904 solver.cpp:245]     Train net output #0: loss = 2.36197 (* 1 = 2.36197 loss)
I0605 20:05:50.314322   904 sgd_solver.cpp:106] Iteration 142440, lr = 0.00648471
I0605 20:06:10.224539   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 20:06:11.001029   904 solver.cpp:229] Iteration 142480, loss = 2.17222
I0605 20:06:11.001091   904 solver.cpp:245]     Train net output #0: loss = 2.26853 (* 1 = 2.26853 loss)
I0605 20:06:11.001106   904 sgd_solver.cpp:106] Iteration 142480, lr = 0.00647529
I0605 20:06:31.691519   904 solver.cpp:229] Iteration 142520, loss = 2.21414
I0605 20:06:31.691557   904 solver.cpp:245]     Train net output #0: loss = 2.26023 (* 1 = 2.26023 loss)
I0605 20:06:31.691566   904 sgd_solver.cpp:106] Iteration 142520, lr = 0.00646588
I0605 20:06:52.205178   904 solver.cpp:229] Iteration 142560, loss = 2.20421
I0605 20:06:52.205363   904 solver.cpp:245]     Train net output #0: loss = 2.24461 (* 1 = 2.24461 loss)
I0605 20:06:52.205384   904 sgd_solver.cpp:106] Iteration 142560, lr = 0.00645647
I0605 20:07:12.717319   904 solver.cpp:229] Iteration 142600, loss = 2.21373
I0605 20:07:12.717370   904 solver.cpp:245]     Train net output #0: loss = 1.89583 (* 1 = 1.89583 loss)
I0605 20:07:12.717377   904 sgd_solver.cpp:106] Iteration 142600, lr = 0.00644706
I0605 20:07:33.387320   904 solver.cpp:229] Iteration 142640, loss = 2.24486
I0605 20:07:33.387516   904 solver.cpp:245]     Train net output #0: loss = 2.39295 (* 1 = 2.39295 loss)
I0605 20:07:33.387544   904 sgd_solver.cpp:106] Iteration 142640, lr = 0.00643765
I0605 20:07:53.940237   904 solver.cpp:229] Iteration 142680, loss = 2.22627
I0605 20:07:53.940286   904 solver.cpp:245]     Train net output #0: loss = 2.63168 (* 1 = 2.63168 loss)
I0605 20:07:53.940299   904 sgd_solver.cpp:106] Iteration 142680, lr = 0.00642823
I0605 20:08:14.482609   904 solver.cpp:229] Iteration 142720, loss = 2.19627
I0605 20:08:14.482748   904 solver.cpp:245]     Train net output #0: loss = 2.09256 (* 1 = 2.09256 loss)
I0605 20:08:14.482769   904 sgd_solver.cpp:106] Iteration 142720, lr = 0.00641882
I0605 20:08:35.009237   904 solver.cpp:229] Iteration 142760, loss = 2.18456
I0605 20:08:35.009281   904 solver.cpp:245]     Train net output #0: loss = 2.26351 (* 1 = 2.26351 loss)
I0605 20:08:35.009290   904 sgd_solver.cpp:106] Iteration 142760, lr = 0.00640941
I0605 20:08:55.524984   904 solver.cpp:229] Iteration 142800, loss = 2.22568
I0605 20:08:55.525243   904 solver.cpp:245]     Train net output #0: loss = 2.39219 (* 1 = 2.39219 loss)
I0605 20:08:55.525266   904 sgd_solver.cpp:106] Iteration 142800, lr = 0.0064
I0605 20:09:16.006459   904 solver.cpp:229] Iteration 142840, loss = 2.19914
I0605 20:09:16.006501   904 solver.cpp:245]     Train net output #0: loss = 1.99578 (* 1 = 1.99578 loss)
I0605 20:09:16.006510   904 sgd_solver.cpp:106] Iteration 142840, lr = 0.00639059
I0605 20:09:36.463202   904 solver.cpp:229] Iteration 142880, loss = 2.20496
I0605 20:09:36.463429   904 solver.cpp:245]     Train net output #0: loss = 2.15597 (* 1 = 2.15597 loss)
I0605 20:09:36.463455   904 sgd_solver.cpp:106] Iteration 142880, lr = 0.00638118
I0605 20:09:56.753749   904 solver.cpp:229] Iteration 142920, loss = 2.21882
I0605 20:09:56.753800   904 solver.cpp:245]     Train net output #0: loss = 2.2681 (* 1 = 2.2681 loss)
I0605 20:09:56.753809   904 sgd_solver.cpp:106] Iteration 142920, lr = 0.00637176
I0605 20:10:17.053902   904 solver.cpp:229] Iteration 142960, loss = 2.19442
I0605 20:10:17.054124   904 solver.cpp:245]     Train net output #0: loss = 2.15922 (* 1 = 2.15922 loss)
I0605 20:10:17.054146   904 sgd_solver.cpp:106] Iteration 142960, lr = 0.00636235
I0605 20:10:36.836947   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_143000.caffemodel
I0605 20:10:37.105113   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_143000.solverstate
I0605 20:10:37.184620   904 solver.cpp:338] Iteration 143000, Testing net (#0)
I0605 20:10:37.184697   904 net.cpp:748] Ignoring source layer loss
I0605 20:10:39.992269   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 20:11:12.195260   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 20:11:42.099411   904 solver.cpp:406]     Test net output #0: accuracy = 0.49746
I0605 20:11:42.099449   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.74256
I0605 20:11:42.415911   904 solver.cpp:229] Iteration 143000, loss = 2.17305
I0605 20:11:42.416095   904 solver.cpp:245]     Train net output #0: loss = 2.2235 (* 1 = 2.2235 loss)
I0605 20:11:42.416116   904 sgd_solver.cpp:106] Iteration 143000, lr = 0.00635294
I0605 20:12:01.807965   904 solver.cpp:229] Iteration 143040, loss = 2.1916
I0605 20:12:01.808014   904 solver.cpp:245]     Train net output #0: loss = 2.39697 (* 1 = 2.39697 loss)
I0605 20:12:01.808022   904 sgd_solver.cpp:106] Iteration 143040, lr = 0.00634353
I0605 20:12:03.269856   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 20:12:23.129478   904 solver.cpp:229] Iteration 143080, loss = 2.2281
I0605 20:12:23.129590   904 solver.cpp:245]     Train net output #0: loss = 2.14026 (* 1 = 2.14026 loss)
I0605 20:12:23.129597   904 sgd_solver.cpp:106] Iteration 143080, lr = 0.00633412
I0605 20:12:44.662725   904 solver.cpp:229] Iteration 143120, loss = 2.22215
I0605 20:12:44.662765   904 solver.cpp:245]     Train net output #0: loss = 2.04573 (* 1 = 2.04573 loss)
I0605 20:12:44.662775   904 sgd_solver.cpp:106] Iteration 143120, lr = 0.00632471
I0605 20:13:05.810472   904 solver.cpp:229] Iteration 143160, loss = 2.18324
I0605 20:13:05.810667   904 solver.cpp:245]     Train net output #0: loss = 2.1491 (* 1 = 2.1491 loss)
I0605 20:13:05.810695   904 sgd_solver.cpp:106] Iteration 143160, lr = 0.00631529
I0605 20:13:26.953968   904 solver.cpp:229] Iteration 143200, loss = 2.20118
I0605 20:13:26.954027   904 solver.cpp:245]     Train net output #0: loss = 1.94444 (* 1 = 1.94444 loss)
I0605 20:13:26.954036   904 sgd_solver.cpp:106] Iteration 143200, lr = 0.00630588
I0605 20:13:47.958142   904 solver.cpp:229] Iteration 143240, loss = 2.22363
I0605 20:13:47.958333   904 solver.cpp:245]     Train net output #0: loss = 2.37618 (* 1 = 2.37618 loss)
I0605 20:13:47.958358   904 sgd_solver.cpp:106] Iteration 143240, lr = 0.00629647
I0605 20:14:08.910181   904 solver.cpp:229] Iteration 143280, loss = 2.23597
I0605 20:14:08.910233   904 solver.cpp:245]     Train net output #0: loss = 2.20561 (* 1 = 2.20561 loss)
I0605 20:14:08.910241   904 sgd_solver.cpp:106] Iteration 143280, lr = 0.00628706
I0605 20:14:29.923573   904 solver.cpp:229] Iteration 143320, loss = 2.20496
I0605 20:14:29.923845   904 solver.cpp:245]     Train net output #0: loss = 2.15347 (* 1 = 2.15347 loss)
I0605 20:14:29.923868   904 sgd_solver.cpp:106] Iteration 143320, lr = 0.00627765
I0605 20:14:50.901051   904 solver.cpp:229] Iteration 143360, loss = 2.21388
I0605 20:14:50.901092   904 solver.cpp:245]     Train net output #0: loss = 2.08333 (* 1 = 2.08333 loss)
I0605 20:14:50.901099   904 sgd_solver.cpp:106] Iteration 143360, lr = 0.00626823
I0605 20:15:11.718413   904 solver.cpp:229] Iteration 143400, loss = 2.22916
I0605 20:15:11.718555   904 solver.cpp:245]     Train net output #0: loss = 2.29401 (* 1 = 2.29401 loss)
I0605 20:15:11.718566   904 sgd_solver.cpp:106] Iteration 143400, lr = 0.00625882
I0605 20:15:32.705646   904 solver.cpp:229] Iteration 143440, loss = 2.16333
I0605 20:15:32.705689   904 solver.cpp:245]     Train net output #0: loss = 2.13105 (* 1 = 2.13105 loss)
I0605 20:15:32.705700   904 sgd_solver.cpp:106] Iteration 143440, lr = 0.00624941
I0605 20:15:53.697753   904 solver.cpp:229] Iteration 143480, loss = 2.1632
I0605 20:15:53.697911   904 solver.cpp:245]     Train net output #0: loss = 2.51359 (* 1 = 2.51359 loss)
I0605 20:15:53.697922   904 sgd_solver.cpp:106] Iteration 143480, lr = 0.00624
I0605 20:16:14.496953   904 solver.cpp:229] Iteration 143520, loss = 2.1985
I0605 20:16:14.497004   904 solver.cpp:245]     Train net output #0: loss = 2.36327 (* 1 = 2.36327 loss)
I0605 20:16:14.497010   904 sgd_solver.cpp:106] Iteration 143520, lr = 0.00623059
I0605 20:16:35.139252   904 solver.cpp:229] Iteration 143560, loss = 2.20331
I0605 20:16:35.139483   904 solver.cpp:245]     Train net output #0: loss = 2.20953 (* 1 = 2.20953 loss)
I0605 20:16:35.139518   904 sgd_solver.cpp:106] Iteration 143560, lr = 0.00622118
I0605 20:16:55.786458   904 solver.cpp:229] Iteration 143600, loss = 2.19747
I0605 20:16:55.786510   904 solver.cpp:245]     Train net output #0: loss = 1.94672 (* 1 = 1.94672 loss)
I0605 20:16:55.786521   904 sgd_solver.cpp:106] Iteration 143600, lr = 0.00621176
I0605 20:17:00.440080   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 20:17:16.469959   904 solver.cpp:229] Iteration 143640, loss = 2.14835
I0605 20:17:16.470182   904 solver.cpp:245]     Train net output #0: loss = 1.82863 (* 1 = 1.82863 loss)
I0605 20:17:16.470209   904 sgd_solver.cpp:106] Iteration 143640, lr = 0.00620235
I0605 20:17:37.115624   904 solver.cpp:229] Iteration 143680, loss = 2.19991
I0605 20:17:37.115666   904 solver.cpp:245]     Train net output #0: loss = 2.29901 (* 1 = 2.29901 loss)
I0605 20:17:37.115672   904 sgd_solver.cpp:106] Iteration 143680, lr = 0.00619294
I0605 20:17:57.700382   904 solver.cpp:229] Iteration 143720, loss = 2.18226
I0605 20:17:57.700597   904 solver.cpp:245]     Train net output #0: loss = 2.18275 (* 1 = 2.18275 loss)
I0605 20:17:57.700620   904 sgd_solver.cpp:106] Iteration 143720, lr = 0.00618353
I0605 20:18:18.219914   904 solver.cpp:229] Iteration 143760, loss = 2.19487
I0605 20:18:18.219969   904 solver.cpp:245]     Train net output #0: loss = 2.25543 (* 1 = 2.25543 loss)
I0605 20:18:18.219974   904 sgd_solver.cpp:106] Iteration 143760, lr = 0.00617412
I0605 20:18:38.822854   904 solver.cpp:229] Iteration 143800, loss = 2.18794
I0605 20:18:38.823078   904 solver.cpp:245]     Train net output #0: loss = 2.32855 (* 1 = 2.32855 loss)
I0605 20:18:38.823106   904 sgd_solver.cpp:106] Iteration 143800, lr = 0.00616471
I0605 20:18:59.478126   904 solver.cpp:229] Iteration 143840, loss = 2.18372
I0605 20:18:59.478178   904 solver.cpp:245]     Train net output #0: loss = 2.27771 (* 1 = 2.27771 loss)
I0605 20:18:59.478188   904 sgd_solver.cpp:106] Iteration 143840, lr = 0.00615529
I0605 20:19:19.991690   904 solver.cpp:229] Iteration 143880, loss = 2.20008
I0605 20:19:19.991935   904 solver.cpp:245]     Train net output #0: loss = 2.19678 (* 1 = 2.19678 loss)
I0605 20:19:19.991960   904 sgd_solver.cpp:106] Iteration 143880, lr = 0.00614588
I0605 20:19:40.514178   904 solver.cpp:229] Iteration 143920, loss = 2.18139
I0605 20:19:40.514209   904 solver.cpp:245]     Train net output #0: loss = 2.31597 (* 1 = 2.31597 loss)
I0605 20:19:40.514228   904 sgd_solver.cpp:106] Iteration 143920, lr = 0.00613647
I0605 20:20:01.277712   904 solver.cpp:229] Iteration 143960, loss = 2.18577
I0605 20:20:01.277875   904 solver.cpp:245]     Train net output #0: loss = 2.25076 (* 1 = 2.25076 loss)
I0605 20:20:01.277886   904 sgd_solver.cpp:106] Iteration 143960, lr = 0.00612706
I0605 20:20:21.273871   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_144000.caffemodel
I0605 20:20:21.562598   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_144000.solverstate
I0605 20:20:21.648160   904 solver.cpp:338] Iteration 144000, Testing net (#0)
I0605 20:20:21.648237   904 net.cpp:748] Ignoring source layer loss
I0605 20:20:34.274111   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 20:21:08.909494   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 20:21:30.201285   904 solver.cpp:406]     Test net output #0: accuracy = 0.49546
I0605 20:21:30.201320   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.742821
I0605 20:21:30.512603   904 solver.cpp:229] Iteration 144000, loss = 2.22169
I0605 20:21:30.512650   904 solver.cpp:245]     Train net output #0: loss = 2.12162 (* 1 = 2.12162 loss)
I0605 20:21:30.512658   904 sgd_solver.cpp:106] Iteration 144000, lr = 0.00611765
I0605 20:21:49.789912   904 solver.cpp:229] Iteration 144040, loss = 2.19861
I0605 20:21:49.790025   904 solver.cpp:245]     Train net output #0: loss = 2.20076 (* 1 = 2.20076 loss)
I0605 20:21:49.790035   904 sgd_solver.cpp:106] Iteration 144040, lr = 0.00610824
I0605 20:22:11.296703   904 solver.cpp:229] Iteration 144080, loss = 2.20808
I0605 20:22:11.296756   904 solver.cpp:245]     Train net output #0: loss = 2.08667 (* 1 = 2.08667 loss)
I0605 20:22:11.296766   904 sgd_solver.cpp:106] Iteration 144080, lr = 0.00609882
I0605 20:22:32.869580   904 solver.cpp:229] Iteration 144120, loss = 2.20747
I0605 20:22:32.869727   904 solver.cpp:245]     Train net output #0: loss = 2.05796 (* 1 = 2.05796 loss)
I0605 20:22:32.869750   904 sgd_solver.cpp:106] Iteration 144120, lr = 0.00608941
I0605 20:22:54.300787   904 solver.cpp:229] Iteration 144160, loss = 2.20291
I0605 20:22:54.300824   904 solver.cpp:245]     Train net output #0: loss = 2.28677 (* 1 = 2.28677 loss)
I0605 20:22:54.300833   904 sgd_solver.cpp:106] Iteration 144160, lr = 0.00608
I0605 20:23:15.302333   904 solver.cpp:229] Iteration 144200, loss = 2.24151
I0605 20:23:15.302467   904 solver.cpp:245]     Train net output #0: loss = 1.92683 (* 1 = 1.92683 loss)
I0605 20:23:15.302477   904 sgd_solver.cpp:106] Iteration 144200, lr = 0.00607059
I0605 20:23:28.966226   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 20:23:36.331480   904 solver.cpp:229] Iteration 144240, loss = 2.20247
I0605 20:23:36.331527   904 solver.cpp:245]     Train net output #0: loss = 2.33867 (* 1 = 2.33867 loss)
I0605 20:23:36.331535   904 sgd_solver.cpp:106] Iteration 144240, lr = 0.00606118
I0605 20:23:57.361853   904 solver.cpp:229] Iteration 144280, loss = 2.20883
I0605 20:23:57.361995   904 solver.cpp:245]     Train net output #0: loss = 2.41056 (* 1 = 2.41056 loss)
I0605 20:23:57.362005   904 sgd_solver.cpp:106] Iteration 144280, lr = 0.00605176
I0605 20:24:18.382997   904 solver.cpp:229] Iteration 144320, loss = 2.18095
I0605 20:24:18.383049   904 solver.cpp:245]     Train net output #0: loss = 2.25309 (* 1 = 2.25309 loss)
I0605 20:24:18.383059   904 sgd_solver.cpp:106] Iteration 144320, lr = 0.00604235
I0605 20:24:39.298080   904 solver.cpp:229] Iteration 144360, loss = 2.15738
I0605 20:24:39.298336   904 solver.cpp:245]     Train net output #0: loss = 2.24704 (* 1 = 2.24704 loss)
I0605 20:24:39.298362   904 sgd_solver.cpp:106] Iteration 144360, lr = 0.00603294
I0605 20:25:00.137837   904 solver.cpp:229] Iteration 144400, loss = 2.17133
I0605 20:25:00.137881   904 solver.cpp:245]     Train net output #0: loss = 1.92902 (* 1 = 1.92902 loss)
I0605 20:25:00.137889   904 sgd_solver.cpp:106] Iteration 144400, lr = 0.00602353
I0605 20:25:20.953155   904 solver.cpp:229] Iteration 144440, loss = 2.19326
I0605 20:25:20.953294   904 solver.cpp:245]     Train net output #0: loss = 2.47104 (* 1 = 2.47104 loss)
I0605 20:25:20.953305   904 sgd_solver.cpp:106] Iteration 144440, lr = 0.00601412
I0605 20:25:41.674893   904 solver.cpp:229] Iteration 144480, loss = 2.18945
I0605 20:25:41.674932   904 solver.cpp:245]     Train net output #0: loss = 2.39296 (* 1 = 2.39296 loss)
I0605 20:25:41.674940   904 sgd_solver.cpp:106] Iteration 144480, lr = 0.00600471
I0605 20:26:02.420337   904 solver.cpp:229] Iteration 144520, loss = 2.19517
I0605 20:26:02.420471   904 solver.cpp:245]     Train net output #0: loss = 2.29617 (* 1 = 2.29617 loss)
I0605 20:26:02.420482   904 sgd_solver.cpp:106] Iteration 144520, lr = 0.0059953
I0605 20:26:23.182799   904 solver.cpp:229] Iteration 144560, loss = 2.16012
I0605 20:26:23.182850   904 solver.cpp:245]     Train net output #0: loss = 2.37062 (* 1 = 2.37062 loss)
I0605 20:26:23.182860   904 sgd_solver.cpp:106] Iteration 144560, lr = 0.00598588
I0605 20:26:43.748874   904 solver.cpp:229] Iteration 144600, loss = 2.2046
I0605 20:26:43.749085   904 solver.cpp:245]     Train net output #0: loss = 2.30097 (* 1 = 2.30097 loss)
I0605 20:26:43.749114   904 sgd_solver.cpp:106] Iteration 144600, lr = 0.00597647
I0605 20:27:04.325634   904 solver.cpp:229] Iteration 144640, loss = 2.15845
I0605 20:27:04.325681   904 solver.cpp:245]     Train net output #0: loss = 2.19646 (* 1 = 2.19646 loss)
I0605 20:27:04.325690   904 sgd_solver.cpp:106] Iteration 144640, lr = 0.00596706
I0605 20:27:24.913249   904 solver.cpp:229] Iteration 144680, loss = 2.1657
I0605 20:27:24.913390   904 solver.cpp:245]     Train net output #0: loss = 2.23029 (* 1 = 2.23029 loss)
I0605 20:27:24.913403   904 sgd_solver.cpp:106] Iteration 144680, lr = 0.00595765
I0605 20:27:45.460291   904 solver.cpp:229] Iteration 144720, loss = 2.1922
I0605 20:27:45.460350   904 solver.cpp:245]     Train net output #0: loss = 2.18197 (* 1 = 2.18197 loss)
I0605 20:27:45.460361   904 sgd_solver.cpp:106] Iteration 144720, lr = 0.00594824
I0605 20:27:55.235584   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 20:28:06.028017   904 solver.cpp:229] Iteration 144760, loss = 2.19135
I0605 20:28:06.028056   904 solver.cpp:245]     Train net output #0: loss = 2.12354 (* 1 = 2.12354 loss)
I0605 20:28:06.028064   904 sgd_solver.cpp:106] Iteration 144760, lr = 0.00593882
I0605 20:28:26.587685   904 solver.cpp:229] Iteration 144800, loss = 2.2195
I0605 20:28:26.587895   904 solver.cpp:245]     Train net output #0: loss = 2.35062 (* 1 = 2.35062 loss)
I0605 20:28:26.587925   904 sgd_solver.cpp:106] Iteration 144800, lr = 0.00592941
I0605 20:28:47.129310   904 solver.cpp:229] Iteration 144840, loss = 2.12995
I0605 20:28:47.129356   904 solver.cpp:245]     Train net output #0: loss = 2.26191 (* 1 = 2.26191 loss)
I0605 20:28:47.129369   904 sgd_solver.cpp:106] Iteration 144840, lr = 0.00592
I0605 20:29:07.597128   904 solver.cpp:229] Iteration 144880, loss = 2.19494
I0605 20:29:07.597323   904 solver.cpp:245]     Train net output #0: loss = 2.436 (* 1 = 2.436 loss)
I0605 20:29:07.597347   904 sgd_solver.cpp:106] Iteration 144880, lr = 0.00591059
I0605 20:29:27.937866   904 solver.cpp:229] Iteration 144920, loss = 2.2055
I0605 20:29:27.937916   904 solver.cpp:245]     Train net output #0: loss = 2.21697 (* 1 = 2.21697 loss)
I0605 20:29:27.937923   904 sgd_solver.cpp:106] Iteration 144920, lr = 0.00590118
I0605 20:29:48.275691   904 solver.cpp:229] Iteration 144960, loss = 2.15686
I0605 20:29:48.275950   904 solver.cpp:245]     Train net output #0: loss = 2.1674 (* 1 = 2.1674 loss)
I0605 20:29:48.275976   904 sgd_solver.cpp:106] Iteration 144960, lr = 0.00589176
I0605 20:30:08.096317   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_145000.caffemodel
I0605 20:30:08.350780   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_145000.solverstate
I0605 20:30:08.428359   904 solver.cpp:338] Iteration 145000, Testing net (#0)
I0605 20:30:08.428448   904 net.cpp:748] Ignoring source layer loss
I0605 20:30:25.271723   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 20:30:59.960626   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 20:31:17.607743   904 solver.cpp:406]     Test net output #0: accuracy = 0.49906
I0605 20:31:17.607779   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.740259
I0605 20:31:17.922477   904 solver.cpp:229] Iteration 145000, loss = 2.17962
I0605 20:31:17.922519   904 solver.cpp:245]     Train net output #0: loss = 2.41072 (* 1 = 2.41072 loss)
I0605 20:31:17.922528   904 sgd_solver.cpp:106] Iteration 145000, lr = 0.00588235
I0605 20:31:37.137481   904 solver.cpp:229] Iteration 145040, loss = 2.19564
I0605 20:31:37.137687   904 solver.cpp:245]     Train net output #0: loss = 2.15514 (* 1 = 2.15514 loss)
I0605 20:31:37.137715   904 sgd_solver.cpp:106] Iteration 145040, lr = 0.00587294
I0605 20:31:58.478462   904 solver.cpp:229] Iteration 145080, loss = 2.1912
I0605 20:31:58.478513   904 solver.cpp:245]     Train net output #0: loss = 2.35808 (* 1 = 2.35808 loss)
I0605 20:31:58.478523   904 sgd_solver.cpp:106] Iteration 145080, lr = 0.00586353
I0605 20:32:19.924029   904 solver.cpp:229] Iteration 145120, loss = 2.17397
I0605 20:32:19.924235   904 solver.cpp:245]     Train net output #0: loss = 2.35047 (* 1 = 2.35047 loss)
I0605 20:32:19.924262   904 sgd_solver.cpp:106] Iteration 145120, lr = 0.00585412
I0605 20:32:40.908152   904 solver.cpp:229] Iteration 145160, loss = 2.21099
I0605 20:32:40.908207   904 solver.cpp:245]     Train net output #0: loss = 2.24237 (* 1 = 2.24237 loss)
I0605 20:32:40.908217   904 sgd_solver.cpp:106] Iteration 145160, lr = 0.0058447
I0605 20:33:01.908592   904 solver.cpp:229] Iteration 145200, loss = 2.17908
I0605 20:33:01.908783   904 solver.cpp:245]     Train net output #0: loss = 2.03804 (* 1 = 2.03804 loss)
I0605 20:33:01.908810   904 sgd_solver.cpp:106] Iteration 145200, lr = 0.00583529
I0605 20:33:22.755646   904 solver.cpp:229] Iteration 145240, loss = 2.20087
I0605 20:33:22.755707   904 solver.cpp:245]     Train net output #0: loss = 2.0122 (* 1 = 2.0122 loss)
I0605 20:33:22.755719   904 sgd_solver.cpp:106] Iteration 145240, lr = 0.00582588
I0605 20:33:28.228857   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 20:33:43.589336   904 solver.cpp:229] Iteration 145280, loss = 2.18717
I0605 20:33:43.589545   904 solver.cpp:245]     Train net output #0: loss = 2.31494 (* 1 = 2.31494 loss)
I0605 20:33:43.589572   904 sgd_solver.cpp:106] Iteration 145280, lr = 0.00581647
I0605 20:34:04.395129   904 solver.cpp:229] Iteration 145320, loss = 2.22014
I0605 20:34:04.395180   904 solver.cpp:245]     Train net output #0: loss = 2.17882 (* 1 = 2.17882 loss)
I0605 20:34:04.395189   904 sgd_solver.cpp:106] Iteration 145320, lr = 0.00580706
I0605 20:34:25.210407   904 solver.cpp:229] Iteration 145360, loss = 2.18687
I0605 20:34:25.210589   904 solver.cpp:245]     Train net output #0: loss = 1.99016 (* 1 = 1.99016 loss)
I0605 20:34:25.210615   904 sgd_solver.cpp:106] Iteration 145360, lr = 0.00579765
I0605 20:34:45.765964   904 solver.cpp:229] Iteration 145400, loss = 2.20529
I0605 20:34:45.766010   904 solver.cpp:245]     Train net output #0: loss = 2.03981 (* 1 = 2.03981 loss)
I0605 20:34:45.766022   904 sgd_solver.cpp:106] Iteration 145400, lr = 0.00578824
I0605 20:35:06.388783   904 solver.cpp:229] Iteration 145440, loss = 2.17842
I0605 20:35:06.389031   904 solver.cpp:245]     Train net output #0: loss = 2.29819 (* 1 = 2.29819 loss)
I0605 20:35:06.389056   904 sgd_solver.cpp:106] Iteration 145440, lr = 0.00577882
I0605 20:35:27.031281   904 solver.cpp:229] Iteration 145480, loss = 2.16319
I0605 20:35:27.031327   904 solver.cpp:245]     Train net output #0: loss = 2.04214 (* 1 = 2.04214 loss)
I0605 20:35:27.031338   904 sgd_solver.cpp:106] Iteration 145480, lr = 0.00576941
I0605 20:35:47.625376   904 solver.cpp:229] Iteration 145520, loss = 2.1424
I0605 20:35:47.625538   904 solver.cpp:245]     Train net output #0: loss = 1.97209 (* 1 = 1.97209 loss)
I0605 20:35:47.625550   904 sgd_solver.cpp:106] Iteration 145520, lr = 0.00576
I0605 20:36:08.154330   904 solver.cpp:229] Iteration 145560, loss = 2.17066
I0605 20:36:08.154386   904 solver.cpp:245]     Train net output #0: loss = 2.38262 (* 1 = 2.38262 loss)
I0605 20:36:08.154395   904 sgd_solver.cpp:106] Iteration 145560, lr = 0.00575059
I0605 20:36:28.682682   904 solver.cpp:229] Iteration 145600, loss = 2.18763
I0605 20:36:28.682857   904 solver.cpp:245]     Train net output #0: loss = 2.32656 (* 1 = 2.32656 loss)
I0605 20:36:28.682880   904 sgd_solver.cpp:106] Iteration 145600, lr = 0.00574118
I0605 20:36:49.205260   904 solver.cpp:229] Iteration 145640, loss = 2.19555
I0605 20:36:49.205298   904 solver.cpp:245]     Train net output #0: loss = 2.18615 (* 1 = 2.18615 loss)
I0605 20:36:49.205307   904 sgd_solver.cpp:106] Iteration 145640, lr = 0.00573176
I0605 20:37:09.740080   904 solver.cpp:229] Iteration 145680, loss = 2.14947
I0605 20:37:09.740299   904 solver.cpp:245]     Train net output #0: loss = 2.04919 (* 1 = 2.04919 loss)
I0605 20:37:09.740329   904 sgd_solver.cpp:106] Iteration 145680, lr = 0.00572235
I0605 20:37:30.280268   904 solver.cpp:229] Iteration 145720, loss = 2.18283
I0605 20:37:30.280324   904 solver.cpp:245]     Train net output #0: loss = 1.9596 (* 1 = 1.9596 loss)
I0605 20:37:30.280335   904 sgd_solver.cpp:106] Iteration 145720, lr = 0.00571294
I0605 20:37:47.139679   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 20:37:50.694636   904 solver.cpp:229] Iteration 145760, loss = 2.18801
I0605 20:37:50.694681   904 solver.cpp:245]     Train net output #0: loss = 2.15913 (* 1 = 2.15913 loss)
I0605 20:37:50.694690   904 sgd_solver.cpp:106] Iteration 145760, lr = 0.00570353
I0605 20:38:10.976305   904 solver.cpp:229] Iteration 145800, loss = 2.20892
I0605 20:38:10.976347   904 solver.cpp:245]     Train net output #0: loss = 2.21418 (* 1 = 2.21418 loss)
I0605 20:38:10.976356   904 sgd_solver.cpp:106] Iteration 145800, lr = 0.00569412
I0605 20:38:31.260524   904 solver.cpp:229] Iteration 145840, loss = 2.16896
I0605 20:38:31.260748   904 solver.cpp:245]     Train net output #0: loss = 2.23114 (* 1 = 2.23114 loss)
I0605 20:38:31.260774   904 sgd_solver.cpp:106] Iteration 145840, lr = 0.0056847
I0605 20:38:51.684098   904 solver.cpp:229] Iteration 145880, loss = 2.21405
I0605 20:38:51.684161   904 solver.cpp:245]     Train net output #0: loss = 1.9722 (* 1 = 1.9722 loss)
I0605 20:38:51.684172   904 sgd_solver.cpp:106] Iteration 145880, lr = 0.00567529
I0605 20:39:12.187024   904 solver.cpp:229] Iteration 145920, loss = 2.18909
I0605 20:39:12.187162   904 solver.cpp:245]     Train net output #0: loss = 2.32083 (* 1 = 2.32083 loss)
I0605 20:39:12.187176   904 sgd_solver.cpp:106] Iteration 145920, lr = 0.00566588
I0605 20:39:32.553197   904 solver.cpp:229] Iteration 145960, loss = 2.1325
I0605 20:39:32.553253   904 solver.cpp:245]     Train net output #0: loss = 2.04454 (* 1 = 2.04454 loss)
I0605 20:39:32.553264   904 sgd_solver.cpp:106] Iteration 145960, lr = 0.00565647
I0605 20:39:52.344873   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_146000.caffemodel
I0605 20:39:52.606933   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_146000.solverstate
I0605 20:39:52.691107   904 solver.cpp:338] Iteration 146000, Testing net (#0)
I0605 20:39:52.691189   904 net.cpp:748] Ignoring source layer loss
I0605 20:40:09.990700   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 20:40:42.472690   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 20:40:58.578471   904 solver.cpp:406]     Test net output #0: accuracy = 0.50408
I0605 20:40:58.578516   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.7454
I0605 20:40:58.891978   904 solver.cpp:229] Iteration 146000, loss = 2.16067
I0605 20:40:58.892024   904 solver.cpp:245]     Train net output #0: loss = 2.18157 (* 1 = 2.18157 loss)
I0605 20:40:58.892035   904 sgd_solver.cpp:106] Iteration 146000, lr = 0.00564706
I0605 20:41:18.126132   904 solver.cpp:229] Iteration 146040, loss = 2.16854
I0605 20:41:18.126332   904 solver.cpp:245]     Train net output #0: loss = 2.41246 (* 1 = 2.41246 loss)
I0605 20:41:18.126368   904 sgd_solver.cpp:106] Iteration 146040, lr = 0.00563765
I0605 20:41:39.556706   904 solver.cpp:229] Iteration 146080, loss = 2.16036
I0605 20:41:39.556777   904 solver.cpp:245]     Train net output #0: loss = 2.13655 (* 1 = 2.13655 loss)
I0605 20:41:39.556787   904 sgd_solver.cpp:106] Iteration 146080, lr = 0.00562824
I0605 20:42:01.123265   904 solver.cpp:229] Iteration 146120, loss = 2.15391
I0605 20:42:01.123411   904 solver.cpp:245]     Train net output #0: loss = 2.07909 (* 1 = 2.07909 loss)
I0605 20:42:01.123423   904 sgd_solver.cpp:106] Iteration 146120, lr = 0.00561882
I0605 20:42:22.357273   904 solver.cpp:229] Iteration 146160, loss = 2.13838
I0605 20:42:22.357316   904 solver.cpp:245]     Train net output #0: loss = 2.34406 (* 1 = 2.34406 loss)
I0605 20:42:22.357326   904 sgd_solver.cpp:106] Iteration 146160, lr = 0.00560941
I0605 20:42:43.541115   904 solver.cpp:229] Iteration 146200, loss = 2.15878
I0605 20:42:43.541339   904 solver.cpp:245]     Train net output #0: loss = 2.28332 (* 1 = 2.28332 loss)
I0605 20:42:43.541363   904 sgd_solver.cpp:106] Iteration 146200, lr = 0.0056
I0605 20:43:04.572551   904 solver.cpp:229] Iteration 146240, loss = 2.15901
I0605 20:43:04.572603   904 solver.cpp:245]     Train net output #0: loss = 2.06349 (* 1 = 2.06349 loss)
I0605 20:43:04.572616   904 sgd_solver.cpp:106] Iteration 146240, lr = 0.00559059
I0605 20:43:15.870622   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 20:43:25.577554   904 solver.cpp:229] Iteration 146280, loss = 2.1896
I0605 20:43:25.577600   904 solver.cpp:245]     Train net output #0: loss = 2.13877 (* 1 = 2.13877 loss)
I0605 20:43:25.577610   904 sgd_solver.cpp:106] Iteration 146280, lr = 0.00558118
I0605 20:43:46.591591   904 solver.cpp:229] Iteration 146320, loss = 2.1445
I0605 20:43:46.591820   904 solver.cpp:245]     Train net output #0: loss = 1.90894 (* 1 = 1.90894 loss)
I0605 20:43:46.591846   904 sgd_solver.cpp:106] Iteration 146320, lr = 0.00557176
I0605 20:44:07.590952   904 solver.cpp:229] Iteration 146360, loss = 2.16714
I0605 20:44:07.591004   904 solver.cpp:245]     Train net output #0: loss = 2.29039 (* 1 = 2.29039 loss)
I0605 20:44:07.591018   904 sgd_solver.cpp:106] Iteration 146360, lr = 0.00556235
I0605 20:44:28.553836   904 solver.cpp:229] Iteration 146400, loss = 2.14426
I0605 20:44:28.553966   904 solver.cpp:245]     Train net output #0: loss = 2.14549 (* 1 = 2.14549 loss)
I0605 20:44:28.553977   904 sgd_solver.cpp:106] Iteration 146400, lr = 0.00555294
I0605 20:44:49.390043   904 solver.cpp:229] Iteration 146440, loss = 2.14337
I0605 20:44:49.390090   904 solver.cpp:245]     Train net output #0: loss = 2.28712 (* 1 = 2.28712 loss)
I0605 20:44:49.390103   904 sgd_solver.cpp:106] Iteration 146440, lr = 0.00554353
I0605 20:45:10.209144   904 solver.cpp:229] Iteration 146480, loss = 2.18188
I0605 20:45:10.209380   904 solver.cpp:245]     Train net output #0: loss = 1.95044 (* 1 = 1.95044 loss)
I0605 20:45:10.209406   904 sgd_solver.cpp:106] Iteration 146480, lr = 0.00553412
I0605 20:45:31.035812   904 solver.cpp:229] Iteration 146520, loss = 2.16637
I0605 20:45:31.035871   904 solver.cpp:245]     Train net output #0: loss = 2.20716 (* 1 = 2.20716 loss)
I0605 20:45:31.035882   904 sgd_solver.cpp:106] Iteration 146520, lr = 0.00552471
I0605 20:45:51.842592   904 solver.cpp:229] Iteration 146560, loss = 2.18097
I0605 20:45:51.842818   904 solver.cpp:245]     Train net output #0: loss = 2.22077 (* 1 = 2.22077 loss)
I0605 20:45:51.842844   904 sgd_solver.cpp:106] Iteration 146560, lr = 0.00551529
I0605 20:46:12.667767   904 solver.cpp:229] Iteration 146600, loss = 2.18611
I0605 20:46:12.667817   904 solver.cpp:245]     Train net output #0: loss = 2.22628 (* 1 = 2.22628 loss)
I0605 20:46:12.667825   904 sgd_solver.cpp:106] Iteration 146600, lr = 0.00550588
I0605 20:46:33.387374   904 solver.cpp:229] Iteration 146640, loss = 2.15948
I0605 20:46:33.387583   904 solver.cpp:245]     Train net output #0: loss = 2.11753 (* 1 = 2.11753 loss)
I0605 20:46:33.387605   904 sgd_solver.cpp:106] Iteration 146640, lr = 0.00549647
I0605 20:46:54.057071   904 solver.cpp:229] Iteration 146680, loss = 2.20911
I0605 20:46:54.057117   904 solver.cpp:245]     Train net output #0: loss = 2.30554 (* 1 = 2.30554 loss)
I0605 20:46:54.057128   904 sgd_solver.cpp:106] Iteration 146680, lr = 0.00548706
I0605 20:47:14.615808   904 solver.cpp:229] Iteration 146720, loss = 2.16821
I0605 20:47:14.616016   904 solver.cpp:245]     Train net output #0: loss = 2.10508 (* 1 = 2.10508 loss)
I0605 20:47:14.616045   904 sgd_solver.cpp:106] Iteration 146720, lr = 0.00547765
I0605 20:47:34.973803   904 solver.cpp:229] Iteration 146760, loss = 2.17829
I0605 20:47:34.973852   904 solver.cpp:245]     Train net output #0: loss = 1.97962 (* 1 = 1.97962 loss)
I0605 20:47:34.973866   904 sgd_solver.cpp:106] Iteration 146760, lr = 0.00546823
I0605 20:47:40.303869   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 20:47:55.246170   904 solver.cpp:229] Iteration 146800, loss = 2.19218
I0605 20:47:55.246311   904 solver.cpp:245]     Train net output #0: loss = 1.91053 (* 1 = 1.91053 loss)
I0605 20:47:55.246323   904 sgd_solver.cpp:106] Iteration 146800, lr = 0.00545882
I0605 20:48:15.429903   904 solver.cpp:229] Iteration 146840, loss = 2.19034
I0605 20:48:15.429958   904 solver.cpp:245]     Train net output #0: loss = 2.19585 (* 1 = 2.19585 loss)
I0605 20:48:15.429970   904 sgd_solver.cpp:106] Iteration 146840, lr = 0.00544941
I0605 20:48:35.558636   904 solver.cpp:229] Iteration 146880, loss = 2.15424
I0605 20:48:35.558895   904 solver.cpp:245]     Train net output #0: loss = 2.15035 (* 1 = 2.15035 loss)
I0605 20:48:35.558923   904 sgd_solver.cpp:106] Iteration 146880, lr = 0.00544
I0605 20:48:55.697616   904 solver.cpp:229] Iteration 146920, loss = 2.16707
I0605 20:48:55.697659   904 solver.cpp:245]     Train net output #0: loss = 2.02797 (* 1 = 2.02797 loss)
I0605 20:48:55.697667   904 sgd_solver.cpp:106] Iteration 146920, lr = 0.00543059
I0605 20:49:15.848304   904 solver.cpp:229] Iteration 146960, loss = 2.13676
I0605 20:49:15.848501   904 solver.cpp:245]     Train net output #0: loss = 2.16841 (* 1 = 2.16841 loss)
I0605 20:49:15.848525   904 sgd_solver.cpp:106] Iteration 146960, lr = 0.00542118
I0605 20:49:35.602018   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_147000.caffemodel
I0605 20:49:35.864922   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_147000.solverstate
I0605 20:49:35.943521   904 solver.cpp:338] Iteration 147000, Testing net (#0)
I0605 20:49:35.943600   904 net.cpp:748] Ignoring source layer loss
I0605 20:49:54.622598   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 20:50:27.526877   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 20:50:42.035747   904 solver.cpp:406]     Test net output #0: accuracy = 0.4969
I0605 20:50:42.035792   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.73924
I0605 20:50:42.349701   904 solver.cpp:229] Iteration 147000, loss = 2.17909
I0605 20:50:42.349745   904 solver.cpp:245]     Train net output #0: loss = 2.1585 (* 1 = 2.1585 loss)
I0605 20:50:42.349753   904 sgd_solver.cpp:106] Iteration 147000, lr = 0.00541177
I0605 20:51:01.826169   904 solver.cpp:229] Iteration 147040, loss = 2.13894
I0605 20:51:01.826284   904 solver.cpp:245]     Train net output #0: loss = 2.04442 (* 1 = 2.04442 loss)
I0605 20:51:01.826292   904 sgd_solver.cpp:106] Iteration 147040, lr = 0.00540235
I0605 20:51:23.114223   904 solver.cpp:229] Iteration 147080, loss = 2.14748
I0605 20:51:23.114275   904 solver.cpp:245]     Train net output #0: loss = 2.28359 (* 1 = 2.28359 loss)
I0605 20:51:23.114286   904 sgd_solver.cpp:106] Iteration 147080, lr = 0.00539294
I0605 20:51:44.524310   904 solver.cpp:229] Iteration 147120, loss = 2.15973
I0605 20:51:44.524579   904 solver.cpp:245]     Train net output #0: loss = 2.13825 (* 1 = 2.13825 loss)
I0605 20:51:44.524600   904 sgd_solver.cpp:106] Iteration 147120, lr = 0.00538353
I0605 20:52:05.398944   904 solver.cpp:229] Iteration 147160, loss = 2.14907
I0605 20:52:05.398991   904 solver.cpp:245]     Train net output #0: loss = 1.91105 (* 1 = 1.91105 loss)
I0605 20:52:05.399001   904 sgd_solver.cpp:106] Iteration 147160, lr = 0.00537412
I0605 20:52:26.292080   904 solver.cpp:229] Iteration 147200, loss = 2.13041
I0605 20:52:26.292287   904 solver.cpp:245]     Train net output #0: loss = 2.12742 (* 1 = 2.12742 loss)
I0605 20:52:26.292311   904 sgd_solver.cpp:106] Iteration 147200, lr = 0.00536471
I0605 20:52:47.215502   904 solver.cpp:229] Iteration 147240, loss = 2.17087
I0605 20:52:47.215549   904 solver.cpp:245]     Train net output #0: loss = 2.33495 (* 1 = 2.33495 loss)
I0605 20:52:47.215569   904 sgd_solver.cpp:106] Iteration 147240, lr = 0.00535529
I0605 20:53:08.123327   904 solver.cpp:229] Iteration 147280, loss = 2.14682
I0605 20:53:08.123520   904 solver.cpp:245]     Train net output #0: loss = 2.28204 (* 1 = 2.28204 loss)
I0605 20:53:08.123548   904 sgd_solver.cpp:106] Iteration 147280, lr = 0.00534588
I0605 20:53:19.618798   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 20:53:29.035317   904 solver.cpp:229] Iteration 147320, loss = 2.18068
I0605 20:53:29.035374   904 solver.cpp:245]     Train net output #0: loss = 2.03954 (* 1 = 2.03954 loss)
I0605 20:53:29.035384   904 sgd_solver.cpp:106] Iteration 147320, lr = 0.00533647
I0605 20:53:49.711638   904 solver.cpp:229] Iteration 147360, loss = 2.12586
I0605 20:53:49.711799   904 solver.cpp:245]     Train net output #0: loss = 2.36992 (* 1 = 2.36992 loss)
I0605 20:53:49.711823   904 sgd_solver.cpp:106] Iteration 147360, lr = 0.00532706
I0605 20:54:10.353343   904 solver.cpp:229] Iteration 147400, loss = 2.17603
I0605 20:54:10.353380   904 solver.cpp:245]     Train net output #0: loss = 2.06657 (* 1 = 2.06657 loss)
I0605 20:54:10.353387   904 sgd_solver.cpp:106] Iteration 147400, lr = 0.00531765
I0605 20:54:30.989333   904 solver.cpp:229] Iteration 147440, loss = 2.16738
I0605 20:54:30.989537   904 solver.cpp:245]     Train net output #0: loss = 2.19028 (* 1 = 2.19028 loss)
I0605 20:54:30.989562   904 sgd_solver.cpp:106] Iteration 147440, lr = 0.00530823
I0605 20:54:51.606345   904 solver.cpp:229] Iteration 147480, loss = 2.10515
I0605 20:54:51.606400   904 solver.cpp:245]     Train net output #0: loss = 2.25089 (* 1 = 2.25089 loss)
I0605 20:54:51.606410   904 sgd_solver.cpp:106] Iteration 147480, lr = 0.00529882
I0605 20:55:12.240504   904 solver.cpp:229] Iteration 147520, loss = 2.16394
I0605 20:55:12.240670   904 solver.cpp:245]     Train net output #0: loss = 2.39022 (* 1 = 2.39022 loss)
I0605 20:55:12.240681   904 sgd_solver.cpp:106] Iteration 147520, lr = 0.00528941
I0605 20:55:32.753337   904 solver.cpp:229] Iteration 147560, loss = 2.15052
I0605 20:55:32.753391   904 solver.cpp:245]     Train net output #0: loss = 2.259 (* 1 = 2.259 loss)
I0605 20:55:32.753401   904 sgd_solver.cpp:106] Iteration 147560, lr = 0.00528
I0605 20:55:53.195976   904 solver.cpp:229] Iteration 147600, loss = 2.17978
I0605 20:55:53.196131   904 solver.cpp:245]     Train net output #0: loss = 2.12714 (* 1 = 2.12714 loss)
I0605 20:55:53.196143   904 sgd_solver.cpp:106] Iteration 147600, lr = 0.00527059
I0605 20:56:13.759866   904 solver.cpp:229] Iteration 147640, loss = 2.19287
I0605 20:56:13.759917   904 solver.cpp:245]     Train net output #0: loss = 2.33919 (* 1 = 2.33919 loss)
I0605 20:56:13.759925   904 sgd_solver.cpp:106] Iteration 147640, lr = 0.00526118
I0605 20:56:34.335249   904 solver.cpp:229] Iteration 147680, loss = 2.17943
I0605 20:56:34.335453   904 solver.cpp:245]     Train net output #0: loss = 2.4674 (* 1 = 2.4674 loss)
I0605 20:56:34.335465   904 sgd_solver.cpp:106] Iteration 147680, lr = 0.00525177
I0605 20:56:54.734524   904 solver.cpp:229] Iteration 147720, loss = 2.15222
I0605 20:56:54.734578   904 solver.cpp:245]     Train net output #0: loss = 2.18588 (* 1 = 2.18588 loss)
I0605 20:56:54.734588   904 sgd_solver.cpp:106] Iteration 147720, lr = 0.00524235
I0605 20:57:15.014955   904 solver.cpp:229] Iteration 147760, loss = 2.14646
I0605 20:57:15.015099   904 solver.cpp:245]     Train net output #0: loss = 2.04144 (* 1 = 2.04144 loss)
I0605 20:57:15.015122   904 sgd_solver.cpp:106] Iteration 147760, lr = 0.00523294
I0605 20:57:35.473397   904 solver.cpp:229] Iteration 147800, loss = 2.17581
I0605 20:57:35.473461   904 solver.cpp:245]     Train net output #0: loss = 2.22333 (* 1 = 2.22333 loss)
I0605 20:57:35.473474   904 sgd_solver.cpp:106] Iteration 147800, lr = 0.00522353
I0605 20:57:43.978632   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 20:57:56.012047   904 solver.cpp:229] Iteration 147840, loss = 2.18014
I0605 20:57:56.012193   904 solver.cpp:245]     Train net output #0: loss = 2.23019 (* 1 = 2.23019 loss)
I0605 20:57:56.012207   904 sgd_solver.cpp:106] Iteration 147840, lr = 0.00521412
I0605 20:58:16.457701   904 solver.cpp:229] Iteration 147880, loss = 2.16048
I0605 20:58:16.457751   904 solver.cpp:245]     Train net output #0: loss = 2.45996 (* 1 = 2.45996 loss)
I0605 20:58:16.457762   904 sgd_solver.cpp:106] Iteration 147880, lr = 0.00520471
I0605 20:58:36.944923   904 solver.cpp:229] Iteration 147920, loss = 2.17041
I0605 20:58:36.945122   904 solver.cpp:245]     Train net output #0: loss = 1.99514 (* 1 = 1.99514 loss)
I0605 20:58:36.945147   904 sgd_solver.cpp:106] Iteration 147920, lr = 0.00519529
I0605 20:58:57.138834   904 solver.cpp:229] Iteration 147960, loss = 2.15392
I0605 20:58:57.138896   904 solver.cpp:245]     Train net output #0: loss = 2.00715 (* 1 = 2.00715 loss)
I0605 20:58:57.138911   904 sgd_solver.cpp:106] Iteration 147960, lr = 0.00518588
I0605 20:59:16.958158   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_148000.caffemodel
I0605 20:59:17.216120   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_148000.solverstate
I0605 20:59:17.298779   904 solver.cpp:338] Iteration 148000, Testing net (#0)
I0605 20:59:17.298872   904 net.cpp:748] Ignoring source layer loss
I0605 20:59:40.414258   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 21:00:15.384773   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 21:00:25.759413   904 solver.cpp:406]     Test net output #0: accuracy = 0.50186
I0605 21:00:25.759459   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.743621
I0605 21:00:26.073746   904 solver.cpp:229] Iteration 148000, loss = 2.13
I0605 21:00:26.073792   904 solver.cpp:245]     Train net output #0: loss = 2.12135 (* 1 = 2.12135 loss)
I0605 21:00:26.073812   904 sgd_solver.cpp:106] Iteration 148000, lr = 0.00517647
I0605 21:00:45.306339   904 solver.cpp:229] Iteration 148040, loss = 2.13046
I0605 21:00:45.306391   904 solver.cpp:245]     Train net output #0: loss = 2.20938 (* 1 = 2.20938 loss)
I0605 21:00:45.306401   904 sgd_solver.cpp:106] Iteration 148040, lr = 0.00516706
I0605 21:01:06.730105   904 solver.cpp:229] Iteration 148080, loss = 2.16928
I0605 21:01:06.730320   904 solver.cpp:245]     Train net output #0: loss = 2.47782 (* 1 = 2.47782 loss)
I0605 21:01:06.730350   904 sgd_solver.cpp:106] Iteration 148080, lr = 0.00515765
I0605 21:01:28.311771   904 solver.cpp:229] Iteration 148120, loss = 2.19484
I0605 21:01:28.311822   904 solver.cpp:245]     Train net output #0: loss = 2.01029 (* 1 = 2.01029 loss)
I0605 21:01:28.311830   904 sgd_solver.cpp:106] Iteration 148120, lr = 0.00514823
I0605 21:01:49.380398   904 solver.cpp:229] Iteration 148160, loss = 2.15503
I0605 21:01:49.380612   904 solver.cpp:245]     Train net output #0: loss = 2.15189 (* 1 = 2.15189 loss)
I0605 21:01:49.380622   904 sgd_solver.cpp:106] Iteration 148160, lr = 0.00513882
I0605 21:02:10.397178   904 solver.cpp:229] Iteration 148200, loss = 2.16119
I0605 21:02:10.397217   904 solver.cpp:245]     Train net output #0: loss = 2.02992 (* 1 = 2.02992 loss)
I0605 21:02:10.397227   904 sgd_solver.cpp:106] Iteration 148200, lr = 0.00512941
I0605 21:02:31.401777   904 solver.cpp:229] Iteration 148240, loss = 2.16807
I0605 21:02:31.402024   904 solver.cpp:245]     Train net output #0: loss = 2.28554 (* 1 = 2.28554 loss)
I0605 21:02:31.402052   904 sgd_solver.cpp:106] Iteration 148240, lr = 0.00512
I0605 21:02:52.405637   904 solver.cpp:229] Iteration 148280, loss = 2.15883
I0605 21:02:52.405684   904 solver.cpp:245]     Train net output #0: loss = 1.95935 (* 1 = 1.95935 loss)
I0605 21:02:52.405696   904 sgd_solver.cpp:106] Iteration 148280, lr = 0.00511059
I0605 21:03:13.279537   904 solver.cpp:229] Iteration 148320, loss = 2.1393
I0605 21:03:13.279726   904 solver.cpp:245]     Train net output #0: loss = 2.01107 (* 1 = 2.01107 loss)
I0605 21:03:13.279748   904 sgd_solver.cpp:106] Iteration 148320, lr = 0.00510118
I0605 21:03:34.001281   904 solver.cpp:229] Iteration 148360, loss = 2.16604
I0605 21:03:34.001329   904 solver.cpp:245]     Train net output #0: loss = 2.11409 (* 1 = 2.11409 loss)
I0605 21:03:34.001341   904 sgd_solver.cpp:106] Iteration 148360, lr = 0.00509176
I0605 21:03:54.782908   904 solver.cpp:229] Iteration 148400, loss = 2.18251
I0605 21:03:54.783152   904 solver.cpp:245]     Train net output #0: loss = 2.63342 (* 1 = 2.63342 loss)
I0605 21:03:54.783203   904 sgd_solver.cpp:106] Iteration 148400, lr = 0.00508235
I0605 21:04:06.601057   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 21:04:15.309676   904 solver.cpp:229] Iteration 148440, loss = 2.15449
I0605 21:04:15.309713   904 solver.cpp:245]     Train net output #0: loss = 2.20825 (* 1 = 2.20825 loss)
I0605 21:04:15.309722   904 sgd_solver.cpp:106] Iteration 148440, lr = 0.00507294
I0605 21:04:35.964603   904 solver.cpp:229] Iteration 148480, loss = 2.13303
I0605 21:04:35.964826   904 solver.cpp:245]     Train net output #0: loss = 2.16191 (* 1 = 2.16191 loss)
I0605 21:04:35.964848   904 sgd_solver.cpp:106] Iteration 148480, lr = 0.00506353
I0605 21:04:56.631664   904 solver.cpp:229] Iteration 148520, loss = 2.15371
I0605 21:04:56.631726   904 solver.cpp:245]     Train net output #0: loss = 2.07352 (* 1 = 2.07352 loss)
I0605 21:04:56.631734   904 sgd_solver.cpp:106] Iteration 148520, lr = 0.00505412
I0605 21:05:17.161687   904 solver.cpp:229] Iteration 148560, loss = 2.14438
I0605 21:05:17.161813   904 solver.cpp:245]     Train net output #0: loss = 2.12072 (* 1 = 2.12072 loss)
I0605 21:05:17.161823   904 sgd_solver.cpp:106] Iteration 148560, lr = 0.00504471
I0605 21:05:37.686321   904 solver.cpp:229] Iteration 148600, loss = 2.13142
I0605 21:05:37.686381   904 solver.cpp:245]     Train net output #0: loss = 2.23394 (* 1 = 2.23394 loss)
I0605 21:05:37.686390   904 sgd_solver.cpp:106] Iteration 148600, lr = 0.00503529
I0605 21:05:58.217612   904 solver.cpp:229] Iteration 148640, loss = 2.12341
I0605 21:05:58.217768   904 solver.cpp:245]     Train net output #0: loss = 2.00422 (* 1 = 2.00422 loss)
I0605 21:05:58.217789   904 sgd_solver.cpp:106] Iteration 148640, lr = 0.00502588
I0605 21:06:18.771807   904 solver.cpp:229] Iteration 148680, loss = 2.15366
I0605 21:06:18.771852   904 solver.cpp:245]     Train net output #0: loss = 2.11941 (* 1 = 2.11941 loss)
I0605 21:06:18.771859   904 sgd_solver.cpp:106] Iteration 148680, lr = 0.00501647
I0605 21:06:39.279316   904 solver.cpp:229] Iteration 148720, loss = 2.12069
I0605 21:06:39.279494   904 solver.cpp:245]     Train net output #0: loss = 2.12734 (* 1 = 2.12734 loss)
I0605 21:06:39.279511   904 sgd_solver.cpp:106] Iteration 148720, lr = 0.00500706
I0605 21:06:59.822887   904 solver.cpp:229] Iteration 148760, loss = 2.14796
I0605 21:06:59.822919   904 solver.cpp:245]     Train net output #0: loss = 2.07174 (* 1 = 2.07174 loss)
I0605 21:06:59.822924   904 sgd_solver.cpp:106] Iteration 148760, lr = 0.00499765
I0605 21:07:20.347916   904 solver.cpp:229] Iteration 148800, loss = 2.12041
I0605 21:07:20.348161   904 solver.cpp:245]     Train net output #0: loss = 2.2465 (* 1 = 2.2465 loss)
I0605 21:07:20.348184   904 sgd_solver.cpp:106] Iteration 148800, lr = 0.00498824
I0605 21:07:40.894175   904 solver.cpp:229] Iteration 148840, loss = 2.12372
I0605 21:07:40.894218   904 solver.cpp:245]     Train net output #0: loss = 2.21113 (* 1 = 2.21113 loss)
I0605 21:07:40.894229   904 sgd_solver.cpp:106] Iteration 148840, lr = 0.00497882
I0605 21:08:01.426409   904 solver.cpp:229] Iteration 148880, loss = 2.15019
I0605 21:08:01.426622   904 solver.cpp:245]     Train net output #0: loss = 2.23419 (* 1 = 2.23419 loss)
I0605 21:08:01.426643   904 sgd_solver.cpp:106] Iteration 148880, lr = 0.00496941
I0605 21:08:21.939174   904 solver.cpp:229] Iteration 148920, loss = 2.12346
I0605 21:08:21.939226   904 solver.cpp:245]     Train net output #0: loss = 2.30108 (* 1 = 2.30108 loss)
I0605 21:08:21.939246   904 sgd_solver.cpp:106] Iteration 148920, lr = 0.00496
I0605 21:08:42.450047   904 solver.cpp:229] Iteration 148960, loss = 2.12636
I0605 21:08:42.450214   904 solver.cpp:245]     Train net output #0: loss = 2.39276 (* 1 = 2.39276 loss)
I0605 21:08:42.450237   904 sgd_solver.cpp:106] Iteration 148960, lr = 0.00495059
I0605 21:09:02.457265   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_149000.caffemodel
I0605 21:09:02.731683   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_149000.solverstate
I0605 21:09:02.808619   904 solver.cpp:338] Iteration 149000, Testing net (#0)
I0605 21:09:02.808704   904 net.cpp:748] Ignoring source layer loss
I0605 21:09:03.668807   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 21:09:36.080972   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 21:10:08.122390   904 solver.cpp:406]     Test net output #0: accuracy = 0.50204
I0605 21:10:08.122580   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.74544
I0605 21:10:08.440994   904 solver.cpp:229] Iteration 149000, loss = 2.1743
I0605 21:10:08.441058   904 solver.cpp:245]     Train net output #0: loss = 2.10645 (* 1 = 2.10645 loss)
I0605 21:10:08.441071   904 sgd_solver.cpp:106] Iteration 149000, lr = 0.00494118
I0605 21:10:18.776409   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 21:10:27.710927   904 solver.cpp:229] Iteration 149040, loss = 2.15368
I0605 21:10:27.710963   904 solver.cpp:245]     Train net output #0: loss = 2.03825 (* 1 = 2.03825 loss)
I0605 21:10:27.710970   904 sgd_solver.cpp:106] Iteration 149040, lr = 0.00493176
I0605 21:10:49.211637   904 solver.cpp:229] Iteration 149080, loss = 2.15717
I0605 21:10:49.211762   904 solver.cpp:245]     Train net output #0: loss = 2.48264 (* 1 = 2.48264 loss)
I0605 21:10:49.211772   904 sgd_solver.cpp:106] Iteration 149080, lr = 0.00492235
I0605 21:11:10.740077   904 solver.cpp:229] Iteration 149120, loss = 2.14638
I0605 21:11:10.740116   904 solver.cpp:245]     Train net output #0: loss = 2.08198 (* 1 = 2.08198 loss)
I0605 21:11:10.740124   904 sgd_solver.cpp:106] Iteration 149120, lr = 0.00491294
I0605 21:11:32.230901   904 solver.cpp:229] Iteration 149160, loss = 2.17277
I0605 21:11:32.231072   904 solver.cpp:245]     Train net output #0: loss = 2.30431 (* 1 = 2.30431 loss)
I0605 21:11:32.231097   904 sgd_solver.cpp:106] Iteration 149160, lr = 0.00490353
I0605 21:11:53.369220   904 solver.cpp:229] Iteration 149200, loss = 2.19893
I0605 21:11:53.369271   904 solver.cpp:245]     Train net output #0: loss = 2.12009 (* 1 = 2.12009 loss)
I0605 21:11:53.369280   904 sgd_solver.cpp:106] Iteration 149200, lr = 0.00489412
I0605 21:12:14.329432   904 solver.cpp:229] Iteration 149240, loss = 2.15037
I0605 21:12:14.329639   904 solver.cpp:245]     Train net output #0: loss = 2.12295 (* 1 = 2.12295 loss)
I0605 21:12:14.329660   904 sgd_solver.cpp:106] Iteration 149240, lr = 0.00488471
I0605 21:12:35.440368   904 solver.cpp:229] Iteration 149280, loss = 2.16589
I0605 21:12:35.440425   904 solver.cpp:245]     Train net output #0: loss = 2.12269 (* 1 = 2.12269 loss)
I0605 21:12:35.440436   904 sgd_solver.cpp:106] Iteration 149280, lr = 0.00487529
I0605 21:12:56.549583   904 solver.cpp:229] Iteration 149320, loss = 2.13328
I0605 21:12:56.549870   904 solver.cpp:245]     Train net output #0: loss = 1.9828 (* 1 = 1.9828 loss)
I0605 21:12:56.549896   904 sgd_solver.cpp:106] Iteration 149320, lr = 0.00486588
I0605 21:13:17.549926   904 solver.cpp:229] Iteration 149360, loss = 2.108
I0605 21:13:17.549978   904 solver.cpp:245]     Train net output #0: loss = 2.0278 (* 1 = 2.0278 loss)
I0605 21:13:17.549988   904 sgd_solver.cpp:106] Iteration 149360, lr = 0.00485647
I0605 21:13:38.536905   904 solver.cpp:229] Iteration 149400, loss = 2.14923
I0605 21:13:38.537111   904 solver.cpp:245]     Train net output #0: loss = 2.32531 (* 1 = 2.32531 loss)
I0605 21:13:38.537133   904 sgd_solver.cpp:106] Iteration 149400, lr = 0.00484706
I0605 21:13:59.501765   904 solver.cpp:229] Iteration 149440, loss = 2.13225
I0605 21:13:59.501811   904 solver.cpp:245]     Train net output #0: loss = 2.40457 (* 1 = 2.40457 loss)
I0605 21:13:59.501821   904 sgd_solver.cpp:106] Iteration 149440, lr = 0.00483765
I0605 21:14:20.223980   904 solver.cpp:229] Iteration 149480, loss = 2.12567
I0605 21:14:20.224135   904 solver.cpp:245]     Train net output #0: loss = 2.17612 (* 1 = 2.17612 loss)
I0605 21:14:20.224166   904 sgd_solver.cpp:106] Iteration 149480, lr = 0.00482824
I0605 21:14:40.923053   904 solver.cpp:229] Iteration 149520, loss = 2.1376
I0605 21:14:40.923116   904 solver.cpp:245]     Train net output #0: loss = 2.30681 (* 1 = 2.30681 loss)
I0605 21:14:40.923125   904 sgd_solver.cpp:106] Iteration 149520, lr = 0.00481882
I0605 21:15:01.719485   904 solver.cpp:229] Iteration 149560, loss = 2.09823
I0605 21:15:01.719594   904 solver.cpp:245]     Train net output #0: loss = 1.87304 (* 1 = 1.87304 loss)
I0605 21:15:01.719601   904 sgd_solver.cpp:106] Iteration 149560, lr = 0.00480941
I0605 21:15:03.284167   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 21:15:22.498880   904 solver.cpp:229] Iteration 149600, loss = 2.15505
I0605 21:15:22.498934   904 solver.cpp:245]     Train net output #0: loss = 1.97012 (* 1 = 1.97012 loss)
I0605 21:15:22.498940   904 sgd_solver.cpp:106] Iteration 149600, lr = 0.0048
I0605 21:15:43.154045   904 solver.cpp:229] Iteration 149640, loss = 2.12381
I0605 21:15:43.154189   904 solver.cpp:245]     Train net output #0: loss = 2.00386 (* 1 = 2.00386 loss)
I0605 21:15:43.154199   904 sgd_solver.cpp:106] Iteration 149640, lr = 0.00479059
I0605 21:16:03.809640   904 solver.cpp:229] Iteration 149680, loss = 2.127
I0605 21:16:03.809682   904 solver.cpp:245]     Train net output #0: loss = 2.15222 (* 1 = 2.15222 loss)
I0605 21:16:03.809689   904 sgd_solver.cpp:106] Iteration 149680, lr = 0.00478118
I0605 21:16:24.455837   904 solver.cpp:229] Iteration 149720, loss = 2.14269
I0605 21:16:24.455974   904 solver.cpp:245]     Train net output #0: loss = 2.26415 (* 1 = 2.26415 loss)
I0605 21:16:24.455984   904 sgd_solver.cpp:106] Iteration 149720, lr = 0.00477176
I0605 21:16:45.118731   904 solver.cpp:229] Iteration 149760, loss = 2.15562
I0605 21:16:45.118780   904 solver.cpp:245]     Train net output #0: loss = 2.05087 (* 1 = 2.05087 loss)
I0605 21:16:45.118791   904 sgd_solver.cpp:106] Iteration 149760, lr = 0.00476235
I0605 21:17:05.682474   904 solver.cpp:229] Iteration 149800, loss = 2.13329
I0605 21:17:05.682677   904 solver.cpp:245]     Train net output #0: loss = 2.21554 (* 1 = 2.21554 loss)
I0605 21:17:05.682703   904 sgd_solver.cpp:106] Iteration 149800, lr = 0.00475294
I0605 21:17:26.139842   904 solver.cpp:229] Iteration 149840, loss = 2.10672
I0605 21:17:26.139897   904 solver.cpp:245]     Train net output #0: loss = 1.90455 (* 1 = 1.90455 loss)
I0605 21:17:26.139909   904 sgd_solver.cpp:106] Iteration 149840, lr = 0.00474353
I0605 21:17:46.715481   904 solver.cpp:229] Iteration 149880, loss = 2.13273
I0605 21:17:46.715737   904 solver.cpp:245]     Train net output #0: loss = 2.15544 (* 1 = 2.15544 loss)
I0605 21:17:46.715764   904 sgd_solver.cpp:106] Iteration 149880, lr = 0.00473412
I0605 21:18:07.312285   904 solver.cpp:229] Iteration 149920, loss = 2.15207
I0605 21:18:07.312331   904 solver.cpp:245]     Train net output #0: loss = 1.90952 (* 1 = 1.90952 loss)
I0605 21:18:07.312342   904 sgd_solver.cpp:106] Iteration 149920, lr = 0.00472471
I0605 21:18:27.815690   904 solver.cpp:229] Iteration 149960, loss = 2.10786
I0605 21:18:27.815815   904 solver.cpp:245]     Train net output #0: loss = 2.20455 (* 1 = 2.20455 loss)
I0605 21:18:27.815826   904 sgd_solver.cpp:106] Iteration 149960, lr = 0.00471529
I0605 21:18:47.803979   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_150000.caffemodel
I0605 21:18:48.065197   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_150000.solverstate
I0605 21:18:48.141778   904 solver.cpp:338] Iteration 150000, Testing net (#0)
I0605 21:18:48.141871   904 net.cpp:748] Ignoring source layer loss
I0605 21:18:52.989778   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 21:19:27.503880   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 21:19:56.004993   904 solver.cpp:406]     Test net output #0: accuracy = 0.50672
I0605 21:19:56.005053   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.747041
I0605 21:19:56.323796   904 solver.cpp:229] Iteration 150000, loss = 2.10835
I0605 21:19:56.323842   904 solver.cpp:245]     Train net output #0: loss = 2.32995 (* 1 = 2.32995 loss)
I0605 21:19:56.323853   904 sgd_solver.cpp:106] Iteration 150000, lr = 0.00470588
I0605 21:20:15.539997   904 solver.cpp:229] Iteration 150040, loss = 2.1486
I0605 21:20:15.540144   904 solver.cpp:245]     Train net output #0: loss = 2.17706 (* 1 = 2.17706 loss)
I0605 21:20:15.540153   904 sgd_solver.cpp:106] Iteration 150040, lr = 0.00469647
I0605 21:20:32.432950   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 21:20:37.008231   904 solver.cpp:229] Iteration 150080, loss = 2.11862
I0605 21:20:37.008292   904 solver.cpp:245]     Train net output #0: loss = 2.22173 (* 1 = 2.22173 loss)
I0605 21:20:37.008302   904 sgd_solver.cpp:106] Iteration 150080, lr = 0.00468706
I0605 21:20:58.543931   904 solver.cpp:229] Iteration 150120, loss = 2.13463
I0605 21:20:58.544070   904 solver.cpp:245]     Train net output #0: loss = 2.23292 (* 1 = 2.23292 loss)
I0605 21:20:58.544080   904 sgd_solver.cpp:106] Iteration 150120, lr = 0.00467765
I0605 21:21:19.847972   904 solver.cpp:229] Iteration 150160, loss = 2.17013
I0605 21:21:19.848016   904 solver.cpp:245]     Train net output #0: loss = 2.36874 (* 1 = 2.36874 loss)
I0605 21:21:19.848021   904 sgd_solver.cpp:106] Iteration 150160, lr = 0.00466824
I0605 21:21:40.858943   904 solver.cpp:229] Iteration 150200, loss = 2.16327
I0605 21:21:40.859146   904 solver.cpp:245]     Train net output #0: loss = 1.93411 (* 1 = 1.93411 loss)
I0605 21:21:40.859172   904 sgd_solver.cpp:106] Iteration 150200, lr = 0.00465882
I0605 21:22:01.798719   904 solver.cpp:229] Iteration 150240, loss = 2.14817
I0605 21:22:01.798768   904 solver.cpp:245]     Train net output #0: loss = 2.17752 (* 1 = 2.17752 loss)
I0605 21:22:01.798775   904 sgd_solver.cpp:106] Iteration 150240, lr = 0.00464941
I0605 21:22:22.759871   904 solver.cpp:229] Iteration 150280, loss = 2.13503
I0605 21:22:22.760072   904 solver.cpp:245]     Train net output #0: loss = 2.04141 (* 1 = 2.04141 loss)
I0605 21:22:22.760098   904 sgd_solver.cpp:106] Iteration 150280, lr = 0.00464
I0605 21:22:43.698333   904 solver.cpp:229] Iteration 150320, loss = 2.15831
I0605 21:22:43.698395   904 solver.cpp:245]     Train net output #0: loss = 2.20402 (* 1 = 2.20402 loss)
I0605 21:22:43.698408   904 sgd_solver.cpp:106] Iteration 150320, lr = 0.00463059
I0605 21:23:04.623971   904 solver.cpp:229] Iteration 150360, loss = 2.15417
I0605 21:23:04.624279   904 solver.cpp:245]     Train net output #0: loss = 2.17961 (* 1 = 2.17961 loss)
I0605 21:23:04.624306   904 sgd_solver.cpp:106] Iteration 150360, lr = 0.00462118
I0605 21:23:25.325692   904 solver.cpp:229] Iteration 150400, loss = 2.12285
I0605 21:23:25.325736   904 solver.cpp:245]     Train net output #0: loss = 1.94501 (* 1 = 1.94501 loss)
I0605 21:23:25.325745   904 sgd_solver.cpp:106] Iteration 150400, lr = 0.00461176
I0605 21:23:45.928894   904 solver.cpp:229] Iteration 150440, loss = 2.14799
I0605 21:23:45.929083   904 solver.cpp:245]     Train net output #0: loss = 2.08191 (* 1 = 2.08191 loss)
I0605 21:23:45.929111   904 sgd_solver.cpp:106] Iteration 150440, lr = 0.00460235
I0605 21:24:06.578317   904 solver.cpp:229] Iteration 150480, loss = 2.12863
I0605 21:24:06.578359   904 solver.cpp:245]     Train net output #0: loss = 2.19083 (* 1 = 2.19083 loss)
I0605 21:24:06.578367   904 sgd_solver.cpp:106] Iteration 150480, lr = 0.00459294
I0605 21:24:27.233309   904 solver.cpp:229] Iteration 150520, loss = 2.09397
I0605 21:24:27.233508   904 solver.cpp:245]     Train net output #0: loss = 1.93675 (* 1 = 1.93675 loss)
I0605 21:24:27.233532   904 sgd_solver.cpp:106] Iteration 150520, lr = 0.00458353
I0605 21:24:47.827837   904 solver.cpp:229] Iteration 150560, loss = 2.1261
I0605 21:24:47.827886   904 solver.cpp:245]     Train net output #0: loss = 1.99305 (* 1 = 1.99305 loss)
I0605 21:24:47.827896   904 sgd_solver.cpp:106] Iteration 150560, lr = 0.00457412
I0605 21:24:57.039260   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 21:25:08.289202   904 solver.cpp:229] Iteration 150600, loss = 2.15829
I0605 21:25:08.289400   904 solver.cpp:245]     Train net output #0: loss = 2.04176 (* 1 = 2.04176 loss)
I0605 21:25:08.289438   904 sgd_solver.cpp:106] Iteration 150600, lr = 0.0045647
I0605 21:25:28.779158   904 solver.cpp:229] Iteration 150640, loss = 2.14961
I0605 21:25:28.779214   904 solver.cpp:245]     Train net output #0: loss = 2.19224 (* 1 = 2.19224 loss)
I0605 21:25:28.779223   904 sgd_solver.cpp:106] Iteration 150640, lr = 0.00455529
I0605 21:25:49.392999   904 solver.cpp:229] Iteration 150680, loss = 2.10397
I0605 21:25:49.393218   904 solver.cpp:245]     Train net output #0: loss = 2.05872 (* 1 = 2.05872 loss)
I0605 21:25:49.393244   904 sgd_solver.cpp:106] Iteration 150680, lr = 0.00454588
I0605 21:26:09.858383   904 solver.cpp:229] Iteration 150720, loss = 2.1193
I0605 21:26:09.858438   904 solver.cpp:245]     Train net output #0: loss = 2.2485 (* 1 = 2.2485 loss)
I0605 21:26:09.858448   904 sgd_solver.cpp:106] Iteration 150720, lr = 0.00453647
I0605 21:26:30.324041   904 solver.cpp:229] Iteration 150760, loss = 2.13569
I0605 21:26:30.324142   904 solver.cpp:245]     Train net output #0: loss = 2.15027 (* 1 = 2.15027 loss)
I0605 21:26:30.324152   904 sgd_solver.cpp:106] Iteration 150760, lr = 0.00452706
I0605 21:26:50.792147   904 solver.cpp:229] Iteration 150800, loss = 2.15043
I0605 21:26:50.792192   904 solver.cpp:245]     Train net output #0: loss = 2.20023 (* 1 = 2.20023 loss)
I0605 21:26:50.792198   904 sgd_solver.cpp:106] Iteration 150800, lr = 0.00451765
I0605 21:27:11.259981   904 solver.cpp:229] Iteration 150840, loss = 2.10227
I0605 21:27:11.260112   904 solver.cpp:245]     Train net output #0: loss = 2.25904 (* 1 = 2.25904 loss)
I0605 21:27:11.260121   904 sgd_solver.cpp:106] Iteration 150840, lr = 0.00450824
I0605 21:27:31.722014   904 solver.cpp:229] Iteration 150880, loss = 2.15302
I0605 21:27:31.722050   904 solver.cpp:245]     Train net output #0: loss = 2.4865 (* 1 = 2.4865 loss)
I0605 21:27:31.722057   904 sgd_solver.cpp:106] Iteration 150880, lr = 0.00449882
I0605 21:27:52.210952   904 solver.cpp:229] Iteration 150920, loss = 2.14025
I0605 21:27:52.211169   904 solver.cpp:245]     Train net output #0: loss = 2.19671 (* 1 = 2.19671 loss)
I0605 21:27:52.211211   904 sgd_solver.cpp:106] Iteration 150920, lr = 0.00448941
I0605 21:28:12.533568   904 solver.cpp:229] Iteration 150960, loss = 2.11136
I0605 21:28:12.533619   904 solver.cpp:245]     Train net output #0: loss = 2.09626 (* 1 = 2.09626 loss)
I0605 21:28:12.533629   904 sgd_solver.cpp:106] Iteration 150960, lr = 0.00448
I0605 21:28:32.284505   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_151000.caffemodel
I0605 21:28:32.551787   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_151000.solverstate
I0605 21:28:32.630771   904 solver.cpp:338] Iteration 151000, Testing net (#0)
I0605 21:28:32.630854   904 net.cpp:748] Ignoring source layer loss
I0605 21:28:38.252331   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 21:29:11.410904   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 21:29:39.996876   904 solver.cpp:406]     Test net output #0: accuracy = 0.50358
I0605 21:29:39.996912   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.7439
I0605 21:29:40.313613   904 solver.cpp:229] Iteration 151000, loss = 2.12094
I0605 21:29:40.313663   904 solver.cpp:245]     Train net output #0: loss = 2.29859 (* 1 = 2.29859 loss)
I0605 21:29:40.313671   904 sgd_solver.cpp:106] Iteration 151000, lr = 0.00447059
I0605 21:29:59.490224   904 solver.cpp:229] Iteration 151040, loss = 2.10417
I0605 21:29:59.490423   904 solver.cpp:245]     Train net output #0: loss = 1.9773 (* 1 = 1.9773 loss)
I0605 21:29:59.490452   904 sgd_solver.cpp:106] Iteration 151040, lr = 0.00446118
I0605 21:30:20.776587   904 solver.cpp:229] Iteration 151080, loss = 2.11208
I0605 21:30:20.776643   904 solver.cpp:245]     Train net output #0: loss = 1.93193 (* 1 = 1.93193 loss)
I0605 21:30:20.776656   904 sgd_solver.cpp:106] Iteration 151080, lr = 0.00445176
I0605 21:30:25.898246   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 21:30:42.114619   904 solver.cpp:229] Iteration 151120, loss = 2.12781
I0605 21:30:42.114828   904 solver.cpp:245]     Train net output #0: loss = 2.23113 (* 1 = 2.23113 loss)
I0605 21:30:42.114843   904 sgd_solver.cpp:106] Iteration 151120, lr = 0.00444235
I0605 21:31:03.131093   904 solver.cpp:229] Iteration 151160, loss = 2.07905
I0605 21:31:03.131139   904 solver.cpp:245]     Train net output #0: loss = 2.08104 (* 1 = 2.08104 loss)
I0605 21:31:03.131166   904 sgd_solver.cpp:106] Iteration 151160, lr = 0.00443294
I0605 21:31:24.122881   904 solver.cpp:229] Iteration 151200, loss = 2.10731
I0605 21:31:24.123086   904 solver.cpp:245]     Train net output #0: loss = 2.21538 (* 1 = 2.21538 loss)
I0605 21:31:24.123138   904 sgd_solver.cpp:106] Iteration 151200, lr = 0.00442353
I0605 21:31:45.016525   904 solver.cpp:229] Iteration 151240, loss = 2.11038
I0605 21:31:45.016572   904 solver.cpp:245]     Train net output #0: loss = 2.03536 (* 1 = 2.03536 loss)
I0605 21:31:45.016582   904 sgd_solver.cpp:106] Iteration 151240, lr = 0.00441412
I0605 21:32:05.826614   904 solver.cpp:229] Iteration 151280, loss = 2.13804
I0605 21:32:05.826838   904 solver.cpp:245]     Train net output #0: loss = 1.9525 (* 1 = 1.9525 loss)
I0605 21:32:05.826864   904 sgd_solver.cpp:106] Iteration 151280, lr = 0.00440471
I0605 21:32:26.625600   904 solver.cpp:229] Iteration 151320, loss = 2.11559
I0605 21:32:26.625649   904 solver.cpp:245]     Train net output #0: loss = 2.05323 (* 1 = 2.05323 loss)
I0605 21:32:26.625660   904 sgd_solver.cpp:106] Iteration 151320, lr = 0.00439529
I0605 21:32:47.431511   904 solver.cpp:229] Iteration 151360, loss = 2.10819
I0605 21:32:47.431620   904 solver.cpp:245]     Train net output #0: loss = 1.96845 (* 1 = 1.96845 loss)
I0605 21:32:47.431630   904 sgd_solver.cpp:106] Iteration 151360, lr = 0.00438588
I0605 21:33:08.152142   904 solver.cpp:229] Iteration 151400, loss = 2.12609
I0605 21:33:08.152189   904 solver.cpp:245]     Train net output #0: loss = 2.06889 (* 1 = 2.06889 loss)
I0605 21:33:08.152206   904 sgd_solver.cpp:106] Iteration 151400, lr = 0.00437647
I0605 21:33:28.811753   904 solver.cpp:229] Iteration 151440, loss = 2.0948
I0605 21:33:28.811942   904 solver.cpp:245]     Train net output #0: loss = 1.84345 (* 1 = 1.84345 loss)
I0605 21:33:28.811969   904 sgd_solver.cpp:106] Iteration 151440, lr = 0.00436706
I0605 21:33:49.502185   904 solver.cpp:229] Iteration 151480, loss = 2.14613
I0605 21:33:49.502229   904 solver.cpp:245]     Train net output #0: loss = 2.2472 (* 1 = 2.2472 loss)
I0605 21:33:49.502239   904 sgd_solver.cpp:106] Iteration 151480, lr = 0.00435765
I0605 21:34:10.178341   904 solver.cpp:229] Iteration 151520, loss = 2.10652
I0605 21:34:10.178532   904 solver.cpp:245]     Train net output #0: loss = 2.22894 (* 1 = 2.22894 loss)
I0605 21:34:10.178544   904 sgd_solver.cpp:106] Iteration 151520, lr = 0.00434824
I0605 21:34:30.830019   904 solver.cpp:229] Iteration 151560, loss = 2.14913
I0605 21:34:30.830081   904 solver.cpp:245]     Train net output #0: loss = 1.99558 (* 1 = 1.99558 loss)
I0605 21:34:30.830093   904 sgd_solver.cpp:106] Iteration 151560, lr = 0.00433882
I0605 21:34:47.616386   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 21:34:51.492815   904 solver.cpp:229] Iteration 151600, loss = 2.13697
I0605 21:34:51.492863   904 solver.cpp:245]     Train net output #0: loss = 2.18357 (* 1 = 2.18357 loss)
I0605 21:34:51.492876   904 sgd_solver.cpp:106] Iteration 151600, lr = 0.00432941
I0605 21:35:11.982642   904 solver.cpp:229] Iteration 151640, loss = 2.11555
I0605 21:35:11.982689   904 solver.cpp:245]     Train net output #0: loss = 1.96604 (* 1 = 1.96604 loss)
I0605 21:35:11.982702   904 sgd_solver.cpp:106] Iteration 151640, lr = 0.00432
I0605 21:35:32.526206   904 solver.cpp:229] Iteration 151680, loss = 2.14729
I0605 21:35:32.526382   904 solver.cpp:245]     Train net output #0: loss = 2.29969 (* 1 = 2.29969 loss)
I0605 21:35:32.526392   904 sgd_solver.cpp:106] Iteration 151680, lr = 0.00431059
I0605 21:35:53.176668   904 solver.cpp:229] Iteration 151720, loss = 2.14565
I0605 21:35:53.176705   904 solver.cpp:245]     Train net output #0: loss = 2.07755 (* 1 = 2.07755 loss)
I0605 21:35:53.176713   904 sgd_solver.cpp:106] Iteration 151720, lr = 0.00430118
I0605 21:36:13.828768   904 solver.cpp:229] Iteration 151760, loss = 2.12838
I0605 21:36:13.828964   904 solver.cpp:245]     Train net output #0: loss = 2.106 (* 1 = 2.106 loss)
I0605 21:36:13.828976   904 sgd_solver.cpp:106] Iteration 151760, lr = 0.00429177
I0605 21:36:34.325572   904 solver.cpp:229] Iteration 151800, loss = 2.12491
I0605 21:36:34.325637   904 solver.cpp:245]     Train net output #0: loss = 2.18128 (* 1 = 2.18128 loss)
I0605 21:36:34.325649   904 sgd_solver.cpp:106] Iteration 151800, lr = 0.00428235
I0605 21:36:54.774691   904 solver.cpp:229] Iteration 151840, loss = 2.10701
I0605 21:36:54.774881   904 solver.cpp:245]     Train net output #0: loss = 2.2622 (* 1 = 2.2622 loss)
I0605 21:36:54.774893   904 sgd_solver.cpp:106] Iteration 151840, lr = 0.00427294
I0605 21:37:14.976649   904 solver.cpp:229] Iteration 151880, loss = 2.07584
I0605 21:37:14.976709   904 solver.cpp:245]     Train net output #0: loss = 2.05369 (* 1 = 2.05369 loss)
I0605 21:37:14.976719   904 sgd_solver.cpp:106] Iteration 151880, lr = 0.00426353
I0605 21:37:35.121034   904 solver.cpp:229] Iteration 151920, loss = 2.11172
I0605 21:37:35.121176   904 solver.cpp:245]     Train net output #0: loss = 2.07668 (* 1 = 2.07668 loss)
I0605 21:37:35.121187   904 sgd_solver.cpp:106] Iteration 151920, lr = 0.00425412
I0605 21:37:55.266011   904 solver.cpp:229] Iteration 151960, loss = 2.09394
I0605 21:37:55.266055   904 solver.cpp:245]     Train net output #0: loss = 1.98674 (* 1 = 1.98674 loss)
I0605 21:37:55.266064   904 sgd_solver.cpp:106] Iteration 151960, lr = 0.00424471
I0605 21:38:14.818724   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_152000.caffemodel
I0605 21:38:15.072932   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_152000.solverstate
I0605 21:38:15.154584   904 solver.cpp:338] Iteration 152000, Testing net (#0)
I0605 21:38:15.154671   904 net.cpp:748] Ignoring source layer loss
I0605 21:38:22.561491   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 21:38:55.851883   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 21:39:22.140957   904 solver.cpp:406]     Test net output #0: accuracy = 0.51084
I0605 21:39:22.141006   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.75162
I0605 21:39:22.455034   904 solver.cpp:229] Iteration 152000, loss = 2.12272
I0605 21:39:22.455091   904 solver.cpp:245]     Train net output #0: loss = 2.13226 (* 1 = 2.13226 loss)
I0605 21:39:22.455102   904 sgd_solver.cpp:106] Iteration 152000, lr = 0.00423529
I0605 21:39:41.644026   904 solver.cpp:229] Iteration 152040, loss = 2.10598
I0605 21:39:41.644250   904 solver.cpp:245]     Train net output #0: loss = 1.9811 (* 1 = 1.9811 loss)
I0605 21:39:41.644276   904 sgd_solver.cpp:106] Iteration 152040, lr = 0.00422588
I0605 21:40:02.836021   904 solver.cpp:229] Iteration 152080, loss = 2.1115
I0605 21:40:02.836068   904 solver.cpp:245]     Train net output #0: loss = 2.20901 (* 1 = 2.20901 loss)
I0605 21:40:02.836081   904 sgd_solver.cpp:106] Iteration 152080, lr = 0.00421647
I0605 21:40:24.122752   904 solver.cpp:229] Iteration 152120, loss = 2.12378
I0605 21:40:24.123013   904 solver.cpp:245]     Train net output #0: loss = 2.24268 (* 1 = 2.24268 loss)
I0605 21:40:24.123035   904 sgd_solver.cpp:106] Iteration 152120, lr = 0.00420706
I0605 21:40:25.167198   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 21:40:45.056521   904 solver.cpp:229] Iteration 152160, loss = 2.08047
I0605 21:40:45.056579   904 solver.cpp:245]     Train net output #0: loss = 1.80668 (* 1 = 1.80668 loss)
I0605 21:40:45.056601   904 sgd_solver.cpp:106] Iteration 152160, lr = 0.00419765
I0605 21:41:06.011143   904 solver.cpp:229] Iteration 152200, loss = 2.07598
I0605 21:41:06.011327   904 solver.cpp:245]     Train net output #0: loss = 1.80266 (* 1 = 1.80266 loss)
I0605 21:41:06.011338   904 sgd_solver.cpp:106] Iteration 152200, lr = 0.00418823
I0605 21:41:26.963122   904 solver.cpp:229] Iteration 152240, loss = 2.12831
I0605 21:41:26.963187   904 solver.cpp:245]     Train net output #0: loss = 2.33472 (* 1 = 2.33472 loss)
I0605 21:41:26.963201   904 sgd_solver.cpp:106] Iteration 152240, lr = 0.00417882
I0605 21:41:47.872141   904 solver.cpp:229] Iteration 152280, loss = 2.095
I0605 21:41:47.872354   904 solver.cpp:245]     Train net output #0: loss = 2.27204 (* 1 = 2.27204 loss)
I0605 21:41:47.872386   904 sgd_solver.cpp:106] Iteration 152280, lr = 0.00416941
I0605 21:42:08.706107   904 solver.cpp:229] Iteration 152320, loss = 2.13273
I0605 21:42:08.706156   904 solver.cpp:245]     Train net output #0: loss = 2.05369 (* 1 = 2.05369 loss)
I0605 21:42:08.706164   904 sgd_solver.cpp:106] Iteration 152320, lr = 0.00416
I0605 21:42:29.512437   904 solver.cpp:229] Iteration 152360, loss = 2.05969
I0605 21:42:29.512629   904 solver.cpp:245]     Train net output #0: loss = 1.97435 (* 1 = 1.97435 loss)
I0605 21:42:29.512648   904 sgd_solver.cpp:106] Iteration 152360, lr = 0.00415059
I0605 21:42:50.274484   904 solver.cpp:229] Iteration 152400, loss = 2.12131
I0605 21:42:50.274525   904 solver.cpp:245]     Train net output #0: loss = 2.0955 (* 1 = 2.0955 loss)
I0605 21:42:50.274533   904 sgd_solver.cpp:106] Iteration 152400, lr = 0.00414118
I0605 21:43:11.056332   904 solver.cpp:229] Iteration 152440, loss = 2.12514
I0605 21:43:11.056581   904 solver.cpp:245]     Train net output #0: loss = 1.8566 (* 1 = 1.8566 loss)
I0605 21:43:11.056607   904 sgd_solver.cpp:106] Iteration 152440, lr = 0.00413177
I0605 21:43:31.808362   904 solver.cpp:229] Iteration 152480, loss = 2.06555
I0605 21:43:31.808419   904 solver.cpp:245]     Train net output #0: loss = 1.98459 (* 1 = 1.98459 loss)
I0605 21:43:31.808429   904 sgd_solver.cpp:106] Iteration 152480, lr = 0.00412235
I0605 21:43:52.478668   904 solver.cpp:229] Iteration 152520, loss = 2.11991
I0605 21:43:52.478891   904 solver.cpp:245]     Train net output #0: loss = 2.29176 (* 1 = 2.29176 loss)
I0605 21:43:52.478916   904 sgd_solver.cpp:106] Iteration 152520, lr = 0.00411294
I0605 21:44:13.093662   904 solver.cpp:229] Iteration 152560, loss = 2.09538
I0605 21:44:13.093722   904 solver.cpp:245]     Train net output #0: loss = 2.06269 (* 1 = 2.06269 loss)
I0605 21:44:13.093734   904 sgd_solver.cpp:106] Iteration 152560, lr = 0.00410353
I0605 21:44:33.740180   904 solver.cpp:229] Iteration 152600, loss = 2.12018
I0605 21:44:33.740471   904 solver.cpp:245]     Train net output #0: loss = 2.04503 (* 1 = 2.04503 loss)
I0605 21:44:33.740491   904 sgd_solver.cpp:106] Iteration 152600, lr = 0.00409412
I0605 21:44:54.366338   904 solver.cpp:229] Iteration 152640, loss = 2.11249
I0605 21:44:54.366392   904 solver.cpp:245]     Train net output #0: loss = 2.17086 (* 1 = 2.17086 loss)
I0605 21:44:54.366401   904 sgd_solver.cpp:106] Iteration 152640, lr = 0.00408471
I0605 21:44:55.911872   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 21:45:14.994385   904 solver.cpp:229] Iteration 152680, loss = 2.13847
I0605 21:45:14.994621   904 solver.cpp:245]     Train net output #0: loss = 1.80436 (* 1 = 1.80436 loss)
I0605 21:45:14.994647   904 sgd_solver.cpp:106] Iteration 152680, lr = 0.00407529
I0605 21:45:35.592156   904 solver.cpp:229] Iteration 152720, loss = 2.08442
I0605 21:45:35.592202   904 solver.cpp:245]     Train net output #0: loss = 1.98316 (* 1 = 1.98316 loss)
I0605 21:45:35.592213   904 sgd_solver.cpp:106] Iteration 152720, lr = 0.00406588
I0605 21:45:56.036370   904 solver.cpp:229] Iteration 152760, loss = 2.09395
I0605 21:45:56.036573   904 solver.cpp:245]     Train net output #0: loss = 2.29362 (* 1 = 2.29362 loss)
I0605 21:45:56.036612   904 sgd_solver.cpp:106] Iteration 152760, lr = 0.00405647
I0605 21:46:16.543263   904 solver.cpp:229] Iteration 152800, loss = 2.11662
I0605 21:46:16.543318   904 solver.cpp:245]     Train net output #0: loss = 2.2514 (* 1 = 2.2514 loss)
I0605 21:46:16.543325   904 sgd_solver.cpp:106] Iteration 152800, lr = 0.00404706
I0605 21:46:37.126229   904 solver.cpp:229] Iteration 152840, loss = 2.10909
I0605 21:46:37.126415   904 solver.cpp:245]     Train net output #0: loss = 2.27799 (* 1 = 2.27799 loss)
I0605 21:46:37.126426   904 sgd_solver.cpp:106] Iteration 152840, lr = 0.00403765
I0605 21:46:57.623987   904 solver.cpp:229] Iteration 152880, loss = 2.1235
I0605 21:46:57.624032   904 solver.cpp:245]     Train net output #0: loss = 1.86965 (* 1 = 1.86965 loss)
I0605 21:46:57.624040   904 sgd_solver.cpp:106] Iteration 152880, lr = 0.00402823
I0605 21:47:18.063323   904 solver.cpp:229] Iteration 152920, loss = 2.10525
I0605 21:47:18.063469   904 solver.cpp:245]     Train net output #0: loss = 1.91798 (* 1 = 1.91798 loss)
I0605 21:47:18.063483   904 sgd_solver.cpp:106] Iteration 152920, lr = 0.00401882
I0605 21:47:38.520360   904 solver.cpp:229] Iteration 152960, loss = 2.09985
I0605 21:47:38.520431   904 solver.cpp:245]     Train net output #0: loss = 1.95996 (* 1 = 1.95996 loss)
I0605 21:47:38.520448   904 sgd_solver.cpp:106] Iteration 152960, lr = 0.00400941
I0605 21:47:58.471073   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_153000.caffemodel
I0605 21:47:58.737020   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_153000.solverstate
I0605 21:47:58.821635   904 solver.cpp:338] Iteration 153000, Testing net (#0)
I0605 21:47:58.821720   904 net.cpp:748] Ignoring source layer loss
I0605 21:48:09.251583   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 21:48:43.171080   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 21:49:07.023253   904 solver.cpp:406]     Test net output #0: accuracy = 0.51102
I0605 21:49:07.023291   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.753201
I0605 21:49:07.340992   904 solver.cpp:229] Iteration 153000, loss = 2.08549
I0605 21:49:07.341032   904 solver.cpp:245]     Train net output #0: loss = 2.12955 (* 1 = 2.12955 loss)
I0605 21:49:07.341042   904 sgd_solver.cpp:106] Iteration 153000, lr = 0.004
I0605 21:49:26.614495   904 solver.cpp:229] Iteration 153040, loss = 2.07644
I0605 21:49:26.614739   904 solver.cpp:245]     Train net output #0: loss = 1.99457 (* 1 = 1.99457 loss)
I0605 21:49:26.614778   904 sgd_solver.cpp:106] Iteration 153040, lr = 0.00399059
I0605 21:49:48.031805   904 solver.cpp:229] Iteration 153080, loss = 2.09906
I0605 21:49:48.031855   904 solver.cpp:245]     Train net output #0: loss = 1.99242 (* 1 = 1.99242 loss)
I0605 21:49:48.031867   904 sgd_solver.cpp:106] Iteration 153080, lr = 0.00398118
I0605 21:50:09.582541   904 solver.cpp:229] Iteration 153120, loss = 2.1203
I0605 21:50:09.582821   904 solver.cpp:245]     Train net output #0: loss = 2.07901 (* 1 = 2.07901 loss)
I0605 21:50:09.582839   904 sgd_solver.cpp:106] Iteration 153120, lr = 0.00397176
I0605 21:50:30.813644   904 solver.cpp:229] Iteration 153160, loss = 2.08713
I0605 21:50:30.813694   904 solver.cpp:245]     Train net output #0: loss = 1.95057 (* 1 = 1.95057 loss)
I0605 21:50:30.813704   904 sgd_solver.cpp:106] Iteration 153160, lr = 0.00396235
I0605 21:50:35.015725   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 21:50:51.842277   904 solver.cpp:229] Iteration 153200, loss = 2.09128
I0605 21:50:51.842555   904 solver.cpp:245]     Train net output #0: loss = 2.1103 (* 1 = 2.1103 loss)
I0605 21:50:51.842588   904 sgd_solver.cpp:106] Iteration 153200, lr = 0.00395294
I0605 21:51:12.857879   904 solver.cpp:229] Iteration 153240, loss = 2.10575
I0605 21:51:12.857939   904 solver.cpp:245]     Train net output #0: loss = 2.22046 (* 1 = 2.22046 loss)
I0605 21:51:12.857961   904 sgd_solver.cpp:106] Iteration 153240, lr = 0.00394353
I0605 21:51:33.867633   904 solver.cpp:229] Iteration 153280, loss = 2.11762
I0605 21:51:33.867866   904 solver.cpp:245]     Train net output #0: loss = 2.16875 (* 1 = 2.16875 loss)
I0605 21:51:33.867894   904 sgd_solver.cpp:106] Iteration 153280, lr = 0.00393412
I0605 21:51:54.873103   904 solver.cpp:229] Iteration 153320, loss = 2.10503
I0605 21:51:54.873160   904 solver.cpp:245]     Train net output #0: loss = 2.23518 (* 1 = 2.23518 loss)
I0605 21:51:54.873170   904 sgd_solver.cpp:106] Iteration 153320, lr = 0.00392471
I0605 21:52:15.626899   904 solver.cpp:229] Iteration 153360, loss = 2.11711
I0605 21:52:15.627025   904 solver.cpp:245]     Train net output #0: loss = 2.19887 (* 1 = 2.19887 loss)
I0605 21:52:15.627035   904 sgd_solver.cpp:106] Iteration 153360, lr = 0.00391529
I0605 21:52:36.218376   904 solver.cpp:229] Iteration 153400, loss = 2.12014
I0605 21:52:36.218425   904 solver.cpp:245]     Train net output #0: loss = 2.1374 (* 1 = 2.1374 loss)
I0605 21:52:36.218436   904 sgd_solver.cpp:106] Iteration 153400, lr = 0.00390588
I0605 21:52:57.066458   904 solver.cpp:229] Iteration 153440, loss = 2.08242
I0605 21:52:57.066668   904 solver.cpp:245]     Train net output #0: loss = 1.91944 (* 1 = 1.91944 loss)
I0605 21:52:57.066692   904 sgd_solver.cpp:106] Iteration 153440, lr = 0.00389647
I0605 21:53:17.764552   904 solver.cpp:229] Iteration 153480, loss = 2.09046
I0605 21:53:17.764600   904 solver.cpp:245]     Train net output #0: loss = 2.10101 (* 1 = 2.10101 loss)
I0605 21:53:17.764612   904 sgd_solver.cpp:106] Iteration 153480, lr = 0.00388706
I0605 21:53:38.306694   904 solver.cpp:229] Iteration 153520, loss = 2.07791
I0605 21:53:38.306913   904 solver.cpp:245]     Train net output #0: loss = 2.23746 (* 1 = 2.23746 loss)
I0605 21:53:38.306957   904 sgd_solver.cpp:106] Iteration 153520, lr = 0.00387765
I0605 21:53:58.961005   904 solver.cpp:229] Iteration 153560, loss = 2.09312
I0605 21:53:58.961057   904 solver.cpp:245]     Train net output #0: loss = 2.20167 (* 1 = 2.20167 loss)
I0605 21:53:58.961071   904 sgd_solver.cpp:106] Iteration 153560, lr = 0.00386823
I0605 21:54:19.518784   904 solver.cpp:229] Iteration 153600, loss = 2.07271
I0605 21:54:19.518973   904 solver.cpp:245]     Train net output #0: loss = 2.15458 (* 1 = 2.15458 loss)
I0605 21:54:19.518996   904 sgd_solver.cpp:106] Iteration 153600, lr = 0.00385882
I0605 21:54:40.034806   904 solver.cpp:229] Iteration 153640, loss = 2.09324
I0605 21:54:40.034844   904 solver.cpp:245]     Train net output #0: loss = 1.8571 (* 1 = 1.8571 loss)
I0605 21:54:40.034853   904 sgd_solver.cpp:106] Iteration 153640, lr = 0.00384941
I0605 21:55:00.556587   904 solver.cpp:229] Iteration 153680, loss = 2.08386
I0605 21:55:00.556802   904 solver.cpp:245]     Train net output #0: loss = 2.26742 (* 1 = 2.26742 loss)
I0605 21:55:00.556815   904 sgd_solver.cpp:106] Iteration 153680, lr = 0.00384
I0605 21:55:07.479238   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 21:55:21.057709   904 solver.cpp:229] Iteration 153720, loss = 2.07251
I0605 21:55:21.057767   904 solver.cpp:245]     Train net output #0: loss = 1.88776 (* 1 = 1.88776 loss)
I0605 21:55:21.057778   904 sgd_solver.cpp:106] Iteration 153720, lr = 0.00383059
I0605 21:55:41.499573   904 solver.cpp:229] Iteration 153760, loss = 2.08231
I0605 21:55:41.499728   904 solver.cpp:245]     Train net output #0: loss = 2.11377 (* 1 = 2.11377 loss)
I0605 21:55:41.499738   904 sgd_solver.cpp:106] Iteration 153760, lr = 0.00382118
I0605 21:56:01.804610   904 solver.cpp:229] Iteration 153800, loss = 2.10486
I0605 21:56:01.804657   904 solver.cpp:245]     Train net output #0: loss = 1.98931 (* 1 = 1.98931 loss)
I0605 21:56:01.804666   904 sgd_solver.cpp:106] Iteration 153800, lr = 0.00381176
I0605 21:56:22.134207   904 solver.cpp:229] Iteration 153840, loss = 2.10302
I0605 21:56:22.134405   904 solver.cpp:245]     Train net output #0: loss = 1.97258 (* 1 = 1.97258 loss)
I0605 21:56:22.134431   904 sgd_solver.cpp:106] Iteration 153840, lr = 0.00380235
I0605 21:56:42.468716   904 solver.cpp:229] Iteration 153880, loss = 2.10736
I0605 21:56:42.468767   904 solver.cpp:245]     Train net output #0: loss = 1.87181 (* 1 = 1.87181 loss)
I0605 21:56:42.468776   904 sgd_solver.cpp:106] Iteration 153880, lr = 0.00379294
I0605 21:57:02.781813   904 solver.cpp:229] Iteration 153920, loss = 2.08221
I0605 21:57:02.781973   904 solver.cpp:245]     Train net output #0: loss = 2.02651 (* 1 = 2.02651 loss)
I0605 21:57:02.781998   904 sgd_solver.cpp:106] Iteration 153920, lr = 0.00378353
I0605 21:57:23.119446   904 solver.cpp:229] Iteration 153960, loss = 2.05245
I0605 21:57:23.119484   904 solver.cpp:245]     Train net output #0: loss = 1.87266 (* 1 = 1.87266 loss)
I0605 21:57:23.119493   904 sgd_solver.cpp:106] Iteration 153960, lr = 0.00377412
I0605 21:57:42.925701   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_154000.caffemodel
I0605 21:57:43.187304   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_154000.solverstate
I0605 21:57:43.264391   904 solver.cpp:338] Iteration 154000, Testing net (#0)
I0605 21:57:43.264443   904 net.cpp:748] Ignoring source layer loss
I0605 21:57:57.915865   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 21:58:31.516552   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 21:58:49.812032   904 solver.cpp:406]     Test net output #0: accuracy = 0.51072
I0605 21:58:49.812105   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.75272
I0605 21:58:50.131486   904 solver.cpp:229] Iteration 154000, loss = 2.13517
I0605 21:58:50.131532   904 solver.cpp:245]     Train net output #0: loss = 2.22051 (* 1 = 2.22051 loss)
I0605 21:58:50.131543   904 sgd_solver.cpp:106] Iteration 154000, lr = 0.00376471
I0605 21:59:09.371886   904 solver.cpp:229] Iteration 154040, loss = 2.08954
I0605 21:59:09.372043   904 solver.cpp:245]     Train net output #0: loss = 1.95082 (* 1 = 1.95082 loss)
I0605 21:59:09.372057   904 sgd_solver.cpp:106] Iteration 154040, lr = 0.0037553
I0605 21:59:30.716058   904 solver.cpp:229] Iteration 154080, loss = 2.10864
I0605 21:59:30.716130   904 solver.cpp:245]     Train net output #0: loss = 2.20598 (* 1 = 2.20598 loss)
I0605 21:59:30.716138   904 sgd_solver.cpp:106] Iteration 154080, lr = 0.00374588
I0605 21:59:51.882205   904 solver.cpp:229] Iteration 154120, loss = 2.10317
I0605 21:59:51.882370   904 solver.cpp:245]     Train net output #0: loss = 1.95444 (* 1 = 1.95444 loss)
I0605 21:59:51.882382   904 sgd_solver.cpp:106] Iteration 154120, lr = 0.00373647
I0605 22:00:12.694519   904 solver.cpp:229] Iteration 154160, loss = 2.09781
I0605 22:00:12.694582   904 solver.cpp:245]     Train net output #0: loss = 2.05325 (* 1 = 2.05325 loss)
I0605 22:00:12.694592   904 sgd_solver.cpp:106] Iteration 154160, lr = 0.00372706
I0605 22:00:33.503720   904 solver.cpp:229] Iteration 154200, loss = 2.14308
I0605 22:00:33.504004   904 solver.cpp:245]     Train net output #0: loss = 2.1089 (* 1 = 2.1089 loss)
I0605 22:00:33.504029   904 sgd_solver.cpp:106] Iteration 154200, lr = 0.00371765
I0605 22:00:45.738016   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 22:00:54.310565   904 solver.cpp:229] Iteration 154240, loss = 2.08154
I0605 22:00:54.310624   904 solver.cpp:245]     Train net output #0: loss = 2.03075 (* 1 = 2.03075 loss)
I0605 22:00:54.310636   904 sgd_solver.cpp:106] Iteration 154240, lr = 0.00370824
I0605 22:01:15.119132   904 solver.cpp:229] Iteration 154280, loss = 2.08178
I0605 22:01:15.119339   904 solver.cpp:245]     Train net output #0: loss = 2.29496 (* 1 = 2.29496 loss)
I0605 22:01:15.119362   904 sgd_solver.cpp:106] Iteration 154280, lr = 0.00369882
I0605 22:01:35.901232   904 solver.cpp:229] Iteration 154320, loss = 2.11146
I0605 22:01:35.901284   904 solver.cpp:245]     Train net output #0: loss = 2.16601 (* 1 = 2.16601 loss)
I0605 22:01:35.901293   904 sgd_solver.cpp:106] Iteration 154320, lr = 0.00368941
I0605 22:01:56.600169   904 solver.cpp:229] Iteration 154360, loss = 2.05894
I0605 22:01:56.600406   904 solver.cpp:245]     Train net output #0: loss = 2.12305 (* 1 = 2.12305 loss)
I0605 22:01:56.600432   904 sgd_solver.cpp:106] Iteration 154360, lr = 0.00368
I0605 22:02:17.271960   904 solver.cpp:229] Iteration 154400, loss = 2.08347
I0605 22:02:17.272017   904 solver.cpp:245]     Train net output #0: loss = 2.0613 (* 1 = 2.0613 loss)
I0605 22:02:17.272027   904 sgd_solver.cpp:106] Iteration 154400, lr = 0.00367059
I0605 22:02:37.964476   904 solver.cpp:229] Iteration 154440, loss = 2.0788
I0605 22:02:37.964627   904 solver.cpp:245]     Train net output #0: loss = 2.18383 (* 1 = 2.18383 loss)
I0605 22:02:37.964639   904 sgd_solver.cpp:106] Iteration 154440, lr = 0.00366118
I0605 22:02:58.581758   904 solver.cpp:229] Iteration 154480, loss = 2.0947
I0605 22:02:58.581806   904 solver.cpp:245]     Train net output #0: loss = 2.17193 (* 1 = 2.17193 loss)
I0605 22:02:58.581815   904 sgd_solver.cpp:106] Iteration 154480, lr = 0.00365176
I0605 22:03:19.076742   904 solver.cpp:229] Iteration 154520, loss = 2.09793
I0605 22:03:19.076936   904 solver.cpp:245]     Train net output #0: loss = 2.02979 (* 1 = 2.02979 loss)
I0605 22:03:19.076962   904 sgd_solver.cpp:106] Iteration 154520, lr = 0.00364235
I0605 22:03:39.742090   904 solver.cpp:229] Iteration 154560, loss = 2.07832
I0605 22:03:39.742136   904 solver.cpp:245]     Train net output #0: loss = 1.81726 (* 1 = 1.81726 loss)
I0605 22:03:39.742146   904 sgd_solver.cpp:106] Iteration 154560, lr = 0.00363294
I0605 22:04:00.380920   904 solver.cpp:229] Iteration 154600, loss = 2.09695
I0605 22:04:00.381122   904 solver.cpp:245]     Train net output #0: loss = 2.0945 (* 1 = 2.0945 loss)
I0605 22:04:00.381145   904 sgd_solver.cpp:106] Iteration 154600, lr = 0.00362353
I0605 22:04:20.969161   904 solver.cpp:229] Iteration 154640, loss = 2.0711
I0605 22:04:20.969213   904 solver.cpp:245]     Train net output #0: loss = 1.92689 (* 1 = 1.92689 loss)
I0605 22:04:20.969221   904 sgd_solver.cpp:106] Iteration 154640, lr = 0.00361412
I0605 22:04:41.495960   904 solver.cpp:229] Iteration 154680, loss = 2.05724
I0605 22:04:41.496093   904 solver.cpp:245]     Train net output #0: loss = 2.14123 (* 1 = 2.14123 loss)
I0605 22:04:41.496103   904 sgd_solver.cpp:106] Iteration 154680, lr = 0.00360471
I0605 22:05:02.032063   904 solver.cpp:229] Iteration 154720, loss = 2.05982
I0605 22:05:02.032106   904 solver.cpp:245]     Train net output #0: loss = 2.12443 (* 1 = 2.12443 loss)
I0605 22:05:02.032116   904 sgd_solver.cpp:106] Iteration 154720, lr = 0.00359529
I0605 22:05:17.937961   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 22:05:22.562885   904 solver.cpp:229] Iteration 154760, loss = 2.09946
I0605 22:05:22.562939   904 solver.cpp:245]     Train net output #0: loss = 2.10952 (* 1 = 2.10952 loss)
I0605 22:05:22.562952   904 sgd_solver.cpp:106] Iteration 154760, lr = 0.00358588
I0605 22:05:43.076433   904 solver.cpp:229] Iteration 154800, loss = 2.0686
I0605 22:05:43.076485   904 solver.cpp:245]     Train net output #0: loss = 1.92271 (* 1 = 1.92271 loss)
I0605 22:05:43.076496   904 sgd_solver.cpp:106] Iteration 154800, lr = 0.00357647
I0605 22:06:03.577291   904 solver.cpp:229] Iteration 154840, loss = 2.03756
I0605 22:06:03.577559   904 solver.cpp:245]     Train net output #0: loss = 1.93978 (* 1 = 1.93978 loss)
I0605 22:06:03.577587   904 sgd_solver.cpp:106] Iteration 154840, lr = 0.00356706
I0605 22:06:24.010972   904 solver.cpp:229] Iteration 154880, loss = 2.07463
I0605 22:06:24.011016   904 solver.cpp:245]     Train net output #0: loss = 2.04931 (* 1 = 2.04931 loss)
I0605 22:06:24.011026   904 sgd_solver.cpp:106] Iteration 154880, lr = 0.00355765
I0605 22:06:44.450222   904 solver.cpp:229] Iteration 154920, loss = 2.09222
I0605 22:06:44.450440   904 solver.cpp:245]     Train net output #0: loss = 2.33258 (* 1 = 2.33258 loss)
I0605 22:06:44.450465   904 sgd_solver.cpp:106] Iteration 154920, lr = 0.00354824
I0605 22:07:04.953264   904 solver.cpp:229] Iteration 154960, loss = 2.067
I0605 22:07:04.953307   904 solver.cpp:245]     Train net output #0: loss = 1.99913 (* 1 = 1.99913 loss)
I0605 22:07:04.953317   904 sgd_solver.cpp:106] Iteration 154960, lr = 0.00353882
I0605 22:07:24.949136   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_155000.caffemodel
I0605 22:07:25.205898   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_155000.solverstate
I0605 22:07:25.282937   904 solver.cpp:338] Iteration 155000, Testing net (#0)
I0605 22:07:25.283059   904 net.cpp:748] Ignoring source layer loss
I0605 22:07:43.625551   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 22:08:18.821521   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 22:08:35.673770   904 solver.cpp:406]     Test net output #0: accuracy = 0.51344
I0605 22:08:35.673831   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.753021
I0605 22:08:35.990087   904 solver.cpp:229] Iteration 155000, loss = 2.05321
I0605 22:08:35.990135   904 solver.cpp:245]     Train net output #0: loss = 2.05205 (* 1 = 2.05205 loss)
I0605 22:08:35.990146   904 sgd_solver.cpp:106] Iteration 155000, lr = 0.00352941
I0605 22:08:55.211392   904 solver.cpp:229] Iteration 155040, loss = 2.094
I0605 22:08:55.211611   904 solver.cpp:245]     Train net output #0: loss = 1.97325 (* 1 = 1.97325 loss)
I0605 22:08:55.211645   904 sgd_solver.cpp:106] Iteration 155040, lr = 0.00352
I0605 22:09:16.677714   904 solver.cpp:229] Iteration 155080, loss = 2.08434
I0605 22:09:16.677753   904 solver.cpp:245]     Train net output #0: loss = 2.18704 (* 1 = 2.18704 loss)
I0605 22:09:16.677762   904 sgd_solver.cpp:106] Iteration 155080, lr = 0.00351059
I0605 22:09:38.247509   904 solver.cpp:229] Iteration 155120, loss = 2.07991
I0605 22:09:38.247689   904 solver.cpp:245]     Train net output #0: loss = 2.07922 (* 1 = 2.07922 loss)
I0605 22:09:38.247714   904 sgd_solver.cpp:106] Iteration 155120, lr = 0.00350118
I0605 22:09:59.548487   904 solver.cpp:229] Iteration 155160, loss = 2.11989
I0605 22:09:59.548552   904 solver.cpp:245]     Train net output #0: loss = 2.31729 (* 1 = 2.31729 loss)
I0605 22:09:59.548563   904 sgd_solver.cpp:106] Iteration 155160, lr = 0.00349176
I0605 22:10:20.554334   904 solver.cpp:229] Iteration 155200, loss = 2.11153
I0605 22:10:20.554456   904 solver.cpp:245]     Train net output #0: loss = 2.06429 (* 1 = 2.06429 loss)
I0605 22:10:20.554467   904 sgd_solver.cpp:106] Iteration 155200, lr = 0.00348235
I0605 22:10:41.527726   904 solver.cpp:229] Iteration 155240, loss = 2.08161
I0605 22:10:41.527782   904 solver.cpp:245]     Train net output #0: loss = 2.02075 (* 1 = 2.02075 loss)
I0605 22:10:41.527796   904 sgd_solver.cpp:106] Iteration 155240, lr = 0.00347294
I0605 22:10:59.953583   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 22:11:02.570915   904 solver.cpp:229] Iteration 155280, loss = 2.08126
I0605 22:11:02.570963   904 solver.cpp:245]     Train net output #0: loss = 2.15269 (* 1 = 2.15269 loss)
I0605 22:11:02.570974   904 sgd_solver.cpp:106] Iteration 155280, lr = 0.00346353
I0605 22:11:23.539865   904 solver.cpp:229] Iteration 155320, loss = 2.09782
I0605 22:11:23.539937   904 solver.cpp:245]     Train net output #0: loss = 2.14004 (* 1 = 2.14004 loss)
I0605 22:11:23.539947   904 sgd_solver.cpp:106] Iteration 155320, lr = 0.00345412
I0605 22:11:44.452422   904 solver.cpp:229] Iteration 155360, loss = 2.07842
I0605 22:11:44.452524   904 solver.cpp:245]     Train net output #0: loss = 2.21956 (* 1 = 2.21956 loss)
I0605 22:11:44.452534   904 sgd_solver.cpp:106] Iteration 155360, lr = 0.0034447
I0605 22:12:05.266070   904 solver.cpp:229] Iteration 155400, loss = 2.0674
I0605 22:12:05.266110   904 solver.cpp:245]     Train net output #0: loss = 2.08053 (* 1 = 2.08053 loss)
I0605 22:12:05.266119   904 sgd_solver.cpp:106] Iteration 155400, lr = 0.00343529
I0605 22:12:26.056639   904 solver.cpp:229] Iteration 155440, loss = 2.10541
I0605 22:12:26.056779   904 solver.cpp:245]     Train net output #0: loss = 2.25627 (* 1 = 2.25627 loss)
I0605 22:12:26.056799   904 sgd_solver.cpp:106] Iteration 155440, lr = 0.00342588
I0605 22:12:46.771571   904 solver.cpp:229] Iteration 155480, loss = 2.06984
I0605 22:12:46.771615   904 solver.cpp:245]     Train net output #0: loss = 1.84977 (* 1 = 1.84977 loss)
I0605 22:12:46.771625   904 sgd_solver.cpp:106] Iteration 155480, lr = 0.00341647
I0605 22:13:07.435715   904 solver.cpp:229] Iteration 155520, loss = 2.06955
I0605 22:13:07.435894   904 solver.cpp:245]     Train net output #0: loss = 2.00275 (* 1 = 2.00275 loss)
I0605 22:13:07.435909   904 sgd_solver.cpp:106] Iteration 155520, lr = 0.00340706
I0605 22:13:28.119480   904 solver.cpp:229] Iteration 155560, loss = 2.04667
I0605 22:13:28.119527   904 solver.cpp:245]     Train net output #0: loss = 1.84825 (* 1 = 1.84825 loss)
I0605 22:13:28.119537   904 sgd_solver.cpp:106] Iteration 155560, lr = 0.00339765
I0605 22:13:48.790933   904 solver.cpp:229] Iteration 155600, loss = 2.09013
I0605 22:13:48.791189   904 solver.cpp:245]     Train net output #0: loss = 1.90423 (* 1 = 1.90423 loss)
I0605 22:13:48.791216   904 sgd_solver.cpp:106] Iteration 155600, lr = 0.00338824
I0605 22:14:09.353781   904 solver.cpp:229] Iteration 155640, loss = 2.09189
I0605 22:14:09.353828   904 solver.cpp:245]     Train net output #0: loss = 2.23876 (* 1 = 2.23876 loss)
I0605 22:14:09.353839   904 sgd_solver.cpp:106] Iteration 155640, lr = 0.00337882
I0605 22:14:29.956887   904 solver.cpp:229] Iteration 155680, loss = 2.05527
I0605 22:14:29.957087   904 solver.cpp:245]     Train net output #0: loss = 2.27118 (* 1 = 2.27118 loss)
I0605 22:14:29.957113   904 sgd_solver.cpp:106] Iteration 155680, lr = 0.00336941
I0605 22:14:50.595233   904 solver.cpp:229] Iteration 155720, loss = 2.07945
I0605 22:14:50.595300   904 solver.cpp:245]     Train net output #0: loss = 2.10994 (* 1 = 2.10994 loss)
I0605 22:14:50.595310   904 sgd_solver.cpp:106] Iteration 155720, lr = 0.00336
I0605 22:15:11.122575   904 solver.cpp:229] Iteration 155760, loss = 2.08908
I0605 22:15:11.122804   904 solver.cpp:245]     Train net output #0: loss = 2.23441 (* 1 = 2.23441 loss)
I0605 22:15:11.122831   904 sgd_solver.cpp:106] Iteration 155760, lr = 0.00335059
I0605 22:15:24.960875   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 22:15:31.621037   904 solver.cpp:229] Iteration 155800, loss = 2.1125
I0605 22:15:31.621083   904 solver.cpp:245]     Train net output #0: loss = 2.08497 (* 1 = 2.08497 loss)
I0605 22:15:31.621094   904 sgd_solver.cpp:106] Iteration 155800, lr = 0.00334118
I0605 22:15:52.128944   904 solver.cpp:229] Iteration 155840, loss = 2.05574
I0605 22:15:52.129170   904 solver.cpp:245]     Train net output #0: loss = 2.19031 (* 1 = 2.19031 loss)
I0605 22:15:52.129209   904 sgd_solver.cpp:106] Iteration 155840, lr = 0.00333176
I0605 22:16:12.633077   904 solver.cpp:229] Iteration 155880, loss = 2.07802
I0605 22:16:12.633132   904 solver.cpp:245]     Train net output #0: loss = 1.8975 (* 1 = 1.8975 loss)
I0605 22:16:12.633141   904 sgd_solver.cpp:106] Iteration 155880, lr = 0.00332235
I0605 22:16:33.141985   904 solver.cpp:229] Iteration 155920, loss = 2.09937
I0605 22:16:33.142231   904 solver.cpp:245]     Train net output #0: loss = 2.11846 (* 1 = 2.11846 loss)
I0605 22:16:33.142254   904 sgd_solver.cpp:106] Iteration 155920, lr = 0.00331294
I0605 22:16:53.652951   904 solver.cpp:229] Iteration 155960, loss = 2.05349
I0605 22:16:53.652994   904 solver.cpp:245]     Train net output #0: loss = 2.07318 (* 1 = 2.07318 loss)
I0605 22:16:53.653005   904 sgd_solver.cpp:106] Iteration 155960, lr = 0.00330353
I0605 22:17:13.453683   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_156000.caffemodel
I0605 22:17:13.727566   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_156000.solverstate
I0605 22:17:13.806815   904 solver.cpp:338] Iteration 156000, Testing net (#0)
I0605 22:17:13.806910   904 net.cpp:748] Ignoring source layer loss
I0605 22:17:35.165691   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 22:18:11.113554   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 22:18:26.236927   904 solver.cpp:406]     Test net output #0: accuracy = 0.51894
I0605 22:18:26.236979   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.75772
I0605 22:18:26.552650   904 solver.cpp:229] Iteration 156000, loss = 2.05267
I0605 22:18:26.552706   904 solver.cpp:245]     Train net output #0: loss = 2.12827 (* 1 = 2.12827 loss)
I0605 22:18:26.552718   904 sgd_solver.cpp:106] Iteration 156000, lr = 0.00329412
I0605 22:18:46.210414   904 solver.cpp:229] Iteration 156040, loss = 2.06701
I0605 22:18:46.210611   904 solver.cpp:245]     Train net output #0: loss = 1.93472 (* 1 = 1.93472 loss)
I0605 22:18:46.210644   904 sgd_solver.cpp:106] Iteration 156040, lr = 0.00328471
I0605 22:19:07.538627   904 solver.cpp:229] Iteration 156080, loss = 2.04831
I0605 22:19:07.538673   904 solver.cpp:245]     Train net output #0: loss = 2.03958 (* 1 = 2.03958 loss)
I0605 22:19:07.538683   904 sgd_solver.cpp:106] Iteration 156080, lr = 0.00327529
I0605 22:19:28.952318   904 solver.cpp:229] Iteration 156120, loss = 2.07959
I0605 22:19:28.952453   904 solver.cpp:245]     Train net output #0: loss = 2.08734 (* 1 = 2.08734 loss)
I0605 22:19:28.952466   904 sgd_solver.cpp:106] Iteration 156120, lr = 0.00326588
I0605 22:19:49.804069   904 solver.cpp:229] Iteration 156160, loss = 2.01525
I0605 22:19:49.804141   904 solver.cpp:245]     Train net output #0: loss = 2.10517 (* 1 = 2.10517 loss)
I0605 22:19:49.804159   904 sgd_solver.cpp:106] Iteration 156160, lr = 0.00325647
I0605 22:20:10.651829   904 solver.cpp:229] Iteration 156200, loss = 2.08094
I0605 22:20:10.652019   904 solver.cpp:245]     Train net output #0: loss = 2.05204 (* 1 = 2.05204 loss)
I0605 22:20:10.652045   904 sgd_solver.cpp:106] Iteration 156200, lr = 0.00324706
I0605 22:20:31.538763   904 solver.cpp:229] Iteration 156240, loss = 2.0568
I0605 22:20:31.538813   904 solver.cpp:245]     Train net output #0: loss = 2.12547 (* 1 = 2.12547 loss)
I0605 22:20:31.538823   904 sgd_solver.cpp:106] Iteration 156240, lr = 0.00323765
I0605 22:20:52.382272   904 solver.cpp:229] Iteration 156280, loss = 2.08039
I0605 22:20:52.382453   904 solver.cpp:245]     Train net output #0: loss = 2.31083 (* 1 = 2.31083 loss)
I0605 22:20:52.382483   904 sgd_solver.cpp:106] Iteration 156280, lr = 0.00322824
I0605 22:21:09.565937   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 22:21:13.216789   904 solver.cpp:229] Iteration 156320, loss = 2.04528
I0605 22:21:13.216841   904 solver.cpp:245]     Train net output #0: loss = 1.8481 (* 1 = 1.8481 loss)
I0605 22:21:13.216850   904 sgd_solver.cpp:106] Iteration 156320, lr = 0.00321882
I0605 22:21:33.883215   904 solver.cpp:229] Iteration 156360, loss = 2.04517
I0605 22:21:33.883442   904 solver.cpp:245]     Train net output #0: loss = 2.01109 (* 1 = 2.01109 loss)
I0605 22:21:33.883456   904 sgd_solver.cpp:106] Iteration 156360, lr = 0.00320941
I0605 22:21:54.442104   904 solver.cpp:229] Iteration 156400, loss = 2.05803
I0605 22:21:54.442157   904 solver.cpp:245]     Train net output #0: loss = 2.30215 (* 1 = 2.30215 loss)
I0605 22:21:54.442167   904 sgd_solver.cpp:106] Iteration 156400, lr = 0.0032
I0605 22:22:15.120256   904 solver.cpp:229] Iteration 156440, loss = 2.06185
I0605 22:22:15.120482   904 solver.cpp:245]     Train net output #0: loss = 2.20741 (* 1 = 2.20741 loss)
I0605 22:22:15.120512   904 sgd_solver.cpp:106] Iteration 156440, lr = 0.00319059
I0605 22:22:35.706794   904 solver.cpp:229] Iteration 156480, loss = 2.06228
I0605 22:22:35.706856   904 solver.cpp:245]     Train net output #0: loss = 2.10577 (* 1 = 2.10577 loss)
I0605 22:22:35.706866   904 sgd_solver.cpp:106] Iteration 156480, lr = 0.00318118
I0605 22:22:56.256022   904 solver.cpp:229] Iteration 156520, loss = 2.05316
I0605 22:22:56.256610   904 solver.cpp:245]     Train net output #0: loss = 1.94116 (* 1 = 1.94116 loss)
I0605 22:22:56.256633   904 sgd_solver.cpp:106] Iteration 156520, lr = 0.00317177
I0605 22:23:16.821655   904 solver.cpp:229] Iteration 156560, loss = 2.10102
I0605 22:23:16.821712   904 solver.cpp:245]     Train net output #0: loss = 2.16067 (* 1 = 2.16067 loss)
I0605 22:23:16.821722   904 sgd_solver.cpp:106] Iteration 156560, lr = 0.00316235
I0605 22:23:37.363185   904 solver.cpp:229] Iteration 156600, loss = 2.07255
I0605 22:23:37.363337   904 solver.cpp:245]     Train net output #0: loss = 1.94251 (* 1 = 1.94251 loss)
I0605 22:23:37.363348   904 sgd_solver.cpp:106] Iteration 156600, lr = 0.00315294
I0605 22:23:57.931712   904 solver.cpp:229] Iteration 156640, loss = 2.06102
I0605 22:23:57.931768   904 solver.cpp:245]     Train net output #0: loss = 1.92831 (* 1 = 1.92831 loss)
I0605 22:23:57.931779   904 sgd_solver.cpp:106] Iteration 156640, lr = 0.00314353
I0605 22:24:18.497604   904 solver.cpp:229] Iteration 156680, loss = 2.08024
I0605 22:24:18.497855   904 solver.cpp:245]     Train net output #0: loss = 2.02332 (* 1 = 2.02332 loss)
I0605 22:24:18.497881   904 sgd_solver.cpp:106] Iteration 156680, lr = 0.00313412
I0605 22:24:38.965610   904 solver.cpp:229] Iteration 156720, loss = 2.08335
I0605 22:24:38.965664   904 solver.cpp:245]     Train net output #0: loss = 1.76886 (* 1 = 1.76886 loss)
I0605 22:24:38.965675   904 sgd_solver.cpp:106] Iteration 156720, lr = 0.00312471
I0605 22:24:59.212168   904 solver.cpp:229] Iteration 156760, loss = 2.05833
I0605 22:24:59.212384   904 solver.cpp:245]     Train net output #0: loss = 1.9349 (* 1 = 1.9349 loss)
I0605 22:24:59.212416   904 sgd_solver.cpp:106] Iteration 156760, lr = 0.00311529
I0605 22:25:19.687736   904 solver.cpp:229] Iteration 156800, loss = 2.06786
I0605 22:25:19.687786   904 solver.cpp:245]     Train net output #0: loss = 1.9573 (* 1 = 1.9573 loss)
I0605 22:25:19.687795   904 sgd_solver.cpp:106] Iteration 156800, lr = 0.00310588
I0605 22:25:31.506767   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 22:25:40.228420   904 solver.cpp:229] Iteration 156840, loss = 2.07959
I0605 22:25:40.228474   904 solver.cpp:245]     Train net output #0: loss = 1.94673 (* 1 = 1.94673 loss)
I0605 22:25:40.228485   904 sgd_solver.cpp:106] Iteration 156840, lr = 0.00309647
I0605 22:26:00.613081   904 solver.cpp:229] Iteration 156880, loss = 2.01799
I0605 22:26:00.613122   904 solver.cpp:245]     Train net output #0: loss = 2.33752 (* 1 = 2.33752 loss)
I0605 22:26:00.613131   904 sgd_solver.cpp:106] Iteration 156880, lr = 0.00308706
I0605 22:26:20.827278   904 solver.cpp:229] Iteration 156920, loss = 2.05063
I0605 22:26:20.827481   904 solver.cpp:245]     Train net output #0: loss = 2.00095 (* 1 = 2.00095 loss)
I0605 22:26:20.827503   904 sgd_solver.cpp:106] Iteration 156920, lr = 0.00307765
I0605 22:26:41.147177   904 solver.cpp:229] Iteration 156960, loss = 2.04157
I0605 22:26:41.147228   904 solver.cpp:245]     Train net output #0: loss = 2.03698 (* 1 = 2.03698 loss)
I0605 22:26:41.147235   904 sgd_solver.cpp:106] Iteration 156960, lr = 0.00306823
I0605 22:27:01.380153   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_157000.caffemodel
I0605 22:27:01.662168   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_157000.solverstate
I0605 22:27:01.747190   904 solver.cpp:338] Iteration 157000, Testing net (#0)
I0605 22:27:01.747259   904 net.cpp:748] Ignoring source layer loss
I0605 22:27:28.553305   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 22:28:03.550966   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 22:28:15.750326   904 solver.cpp:406]     Test net output #0: accuracy = 0.516079
I0605 22:28:15.750404   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.754301
I0605 22:28:16.067602   904 solver.cpp:229] Iteration 157000, loss = 2.06382
I0605 22:28:16.067663   904 solver.cpp:245]     Train net output #0: loss = 1.97302 (* 1 = 1.97302 loss)
I0605 22:28:16.067675   904 sgd_solver.cpp:106] Iteration 157000, lr = 0.00305882
I0605 22:28:35.256608   904 solver.cpp:229] Iteration 157040, loss = 2.04343
I0605 22:28:35.256805   904 solver.cpp:245]     Train net output #0: loss = 2.02457 (* 1 = 2.02457 loss)
I0605 22:28:35.256819   904 sgd_solver.cpp:106] Iteration 157040, lr = 0.00304941
I0605 22:28:56.589826   904 solver.cpp:229] Iteration 157080, loss = 2.04586
I0605 22:28:56.589874   904 solver.cpp:245]     Train net output #0: loss = 1.77814 (* 1 = 1.77814 loss)
I0605 22:28:56.589884   904 sgd_solver.cpp:106] Iteration 157080, lr = 0.00304
I0605 22:29:17.396188   904 solver.cpp:229] Iteration 157120, loss = 2.06438
I0605 22:29:17.396353   904 solver.cpp:245]     Train net output #0: loss = 1.93575 (* 1 = 1.93575 loss)
I0605 22:29:17.396366   904 sgd_solver.cpp:106] Iteration 157120, lr = 0.00303059
I0605 22:29:37.921084   904 solver.cpp:229] Iteration 157160, loss = 2.03245
I0605 22:29:37.921131   904 solver.cpp:245]     Train net output #0: loss = 1.98587 (* 1 = 1.98587 loss)
I0605 22:29:37.921140   904 sgd_solver.cpp:106] Iteration 157160, lr = 0.00302118
I0605 22:29:58.429458   904 solver.cpp:229] Iteration 157200, loss = 2.02562
I0605 22:29:58.429680   904 solver.cpp:245]     Train net output #0: loss = 2.22655 (* 1 = 2.22655 loss)
I0605 22:29:58.429709   904 sgd_solver.cpp:106] Iteration 157200, lr = 0.00301177
I0605 22:30:18.861838   904 solver.cpp:229] Iteration 157240, loss = 2.06885
I0605 22:30:18.861896   904 solver.cpp:245]     Train net output #0: loss = 2.11538 (* 1 = 2.11538 loss)
I0605 22:30:18.861907   904 sgd_solver.cpp:106] Iteration 157240, lr = 0.00300235
I0605 22:30:39.166620   904 solver.cpp:229] Iteration 157280, loss = 2.03631
I0605 22:30:39.166849   904 solver.cpp:245]     Train net output #0: loss = 1.99984 (* 1 = 1.99984 loss)
I0605 22:30:39.166875   904 sgd_solver.cpp:106] Iteration 157280, lr = 0.00299294
I0605 22:30:59.483623   904 solver.cpp:229] Iteration 157320, loss = 2.07189
I0605 22:30:59.483669   904 solver.cpp:245]     Train net output #0: loss = 1.84612 (* 1 = 1.84612 loss)
I0605 22:30:59.483680   904 sgd_solver.cpp:106] Iteration 157320, lr = 0.00298353
I0605 22:31:19.849944   904 solver.cpp:229] Iteration 157360, loss = 2.01885
I0605 22:31:19.850096   904 solver.cpp:245]     Train net output #0: loss = 2.06936 (* 1 = 2.06936 loss)
I0605 22:31:19.850109   904 sgd_solver.cpp:106] Iteration 157360, lr = 0.00297412
I0605 22:31:22.645514   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 22:31:40.253813   904 solver.cpp:229] Iteration 157400, loss = 2.06757
I0605 22:31:40.253867   904 solver.cpp:245]     Train net output #0: loss = 2.13081 (* 1 = 2.13081 loss)
I0605 22:31:40.253876   904 sgd_solver.cpp:106] Iteration 157400, lr = 0.00296471
I0605 22:32:00.928933   904 solver.cpp:229] Iteration 157440, loss = 2.07227
I0605 22:32:00.929113   904 solver.cpp:245]     Train net output #0: loss = 1.8632 (* 1 = 1.8632 loss)
I0605 22:32:00.929147   904 sgd_solver.cpp:106] Iteration 157440, lr = 0.00295529
I0605 22:32:21.468060   904 solver.cpp:229] Iteration 157480, loss = 2.00634
I0605 22:32:21.468111   904 solver.cpp:245]     Train net output #0: loss = 2.0045 (* 1 = 2.0045 loss)
I0605 22:32:21.468123   904 sgd_solver.cpp:106] Iteration 157480, lr = 0.00294588
I0605 22:32:41.983420   904 solver.cpp:229] Iteration 157520, loss = 2.05693
I0605 22:32:41.983729   904 solver.cpp:245]     Train net output #0: loss = 2.11409 (* 1 = 2.11409 loss)
I0605 22:32:41.983754   904 sgd_solver.cpp:106] Iteration 157520, lr = 0.00293647
I0605 22:33:02.533927   904 solver.cpp:229] Iteration 157560, loss = 2.04884
I0605 22:33:02.533994   904 solver.cpp:245]     Train net output #0: loss = 2.14468 (* 1 = 2.14468 loss)
I0605 22:33:02.534008   904 sgd_solver.cpp:106] Iteration 157560, lr = 0.00292706
I0605 22:33:23.084985   904 solver.cpp:229] Iteration 157600, loss = 2.07266
I0605 22:33:23.085207   904 solver.cpp:245]     Train net output #0: loss = 1.94496 (* 1 = 1.94496 loss)
I0605 22:33:23.085237   904 sgd_solver.cpp:106] Iteration 157600, lr = 0.00291765
I0605 22:33:43.609333   904 solver.cpp:229] Iteration 157640, loss = 2.0502
I0605 22:33:43.609391   904 solver.cpp:245]     Train net output #0: loss = 1.96027 (* 1 = 1.96027 loss)
I0605 22:33:43.609401   904 sgd_solver.cpp:106] Iteration 157640, lr = 0.00290823
I0605 22:34:04.143568   904 solver.cpp:229] Iteration 157680, loss = 2.08114
I0605 22:34:04.143762   904 solver.cpp:245]     Train net output #0: loss = 2.36205 (* 1 = 2.36205 loss)
I0605 22:34:04.143787   904 sgd_solver.cpp:106] Iteration 157680, lr = 0.00289882
I0605 22:34:24.663564   904 solver.cpp:229] Iteration 157720, loss = 2.05116
I0605 22:34:24.663609   904 solver.cpp:245]     Train net output #0: loss = 2.05256 (* 1 = 2.05256 loss)
I0605 22:34:24.663619   904 sgd_solver.cpp:106] Iteration 157720, lr = 0.00288941
I0605 22:34:45.208441   904 solver.cpp:229] Iteration 157760, loss = 2.0339
I0605 22:34:45.208637   904 solver.cpp:245]     Train net output #0: loss = 2.00557 (* 1 = 2.00557 loss)
I0605 22:34:45.208662   904 sgd_solver.cpp:106] Iteration 157760, lr = 0.00288
I0605 22:35:05.755731   904 solver.cpp:229] Iteration 157800, loss = 2.07508
I0605 22:35:05.755785   904 solver.cpp:245]     Train net output #0: loss = 2.1116 (* 1 = 2.1116 loss)
I0605 22:35:05.755796   904 sgd_solver.cpp:106] Iteration 157800, lr = 0.00287059
I0605 22:35:26.312542   904 solver.cpp:229] Iteration 157840, loss = 2.05284
I0605 22:35:26.312731   904 solver.cpp:245]     Train net output #0: loss = 2.11399 (* 1 = 2.11399 loss)
I0605 22:35:26.312744   904 sgd_solver.cpp:106] Iteration 157840, lr = 0.00286118
I0605 22:35:44.277261   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 22:35:46.834328   904 solver.cpp:229] Iteration 157880, loss = 2.03866
I0605 22:35:46.834365   904 solver.cpp:245]     Train net output #0: loss = 2.02851 (* 1 = 2.02851 loss)
I0605 22:35:46.834374   904 sgd_solver.cpp:106] Iteration 157880, lr = 0.00285177
I0605 22:36:07.376402   904 solver.cpp:229] Iteration 157920, loss = 2.06335
I0605 22:36:07.376627   904 solver.cpp:245]     Train net output #0: loss = 2.39792 (* 1 = 2.39792 loss)
I0605 22:36:07.376654   904 sgd_solver.cpp:106] Iteration 157920, lr = 0.00284235
I0605 22:36:27.904744   904 solver.cpp:229] Iteration 157960, loss = 2.05469
I0605 22:36:27.904811   904 solver.cpp:245]     Train net output #0: loss = 2.05705 (* 1 = 2.05705 loss)
I0605 22:36:27.904821   904 sgd_solver.cpp:106] Iteration 157960, lr = 0.00283294
I0605 22:36:47.940649   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_158000.caffemodel
I0605 22:36:48.222489   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_158000.solverstate
I0605 22:36:48.307746   904 solver.cpp:338] Iteration 158000, Testing net (#0)
I0605 22:36:48.307821   904 net.cpp:748] Ignoring source layer loss
I0605 22:37:14.163820   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 22:37:46.888547   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 22:37:54.590425   904 solver.cpp:406]     Test net output #0: accuracy = 0.52456
I0605 22:37:54.590472   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.76196
I0605 22:37:54.906888   904 solver.cpp:229] Iteration 158000, loss = 2.0228
I0605 22:37:54.906944   904 solver.cpp:245]     Train net output #0: loss = 1.84683 (* 1 = 1.84683 loss)
I0605 22:37:54.906960   904 sgd_solver.cpp:106] Iteration 158000, lr = 0.00282353
I0605 22:38:14.189970   904 solver.cpp:229] Iteration 158040, loss = 2.02506
I0605 22:38:14.190019   904 solver.cpp:245]     Train net output #0: loss = 2.13993 (* 1 = 2.13993 loss)
I0605 22:38:14.190027   904 sgd_solver.cpp:106] Iteration 158040, lr = 0.00281412
I0605 22:38:35.725013   904 solver.cpp:229] Iteration 158080, loss = 2.03603
I0605 22:38:35.725234   904 solver.cpp:245]     Train net output #0: loss = 2.03581 (* 1 = 2.03581 loss)
I0605 22:38:35.725260   904 sgd_solver.cpp:106] Iteration 158080, lr = 0.00280471
I0605 22:38:57.279201   904 solver.cpp:229] Iteration 158120, loss = 2.064
I0605 22:38:57.279242   904 solver.cpp:245]     Train net output #0: loss = 2.27316 (* 1 = 2.27316 loss)
I0605 22:38:57.279253   904 sgd_solver.cpp:106] Iteration 158120, lr = 0.00279529
I0605 22:39:18.622218   904 solver.cpp:229] Iteration 158160, loss = 2.03924
I0605 22:39:18.622375   904 solver.cpp:245]     Train net output #0: loss = 2.3737 (* 1 = 2.3737 loss)
I0605 22:39:18.622385   904 sgd_solver.cpp:106] Iteration 158160, lr = 0.00278588
I0605 22:39:39.705190   904 solver.cpp:229] Iteration 158200, loss = 2.02915
I0605 22:39:39.705231   904 solver.cpp:245]     Train net output #0: loss = 2.10449 (* 1 = 2.10449 loss)
I0605 22:39:39.705240   904 sgd_solver.cpp:106] Iteration 158200, lr = 0.00277647
I0605 22:40:00.726557   904 solver.cpp:229] Iteration 158240, loss = 2.06158
I0605 22:40:00.726781   904 solver.cpp:245]     Train net output #0: loss = 2.13437 (* 1 = 2.13437 loss)
I0605 22:40:00.726819   904 sgd_solver.cpp:106] Iteration 158240, lr = 0.00276706
I0605 22:40:21.707980   904 solver.cpp:229] Iteration 158280, loss = 2.05412
I0605 22:40:21.708048   904 solver.cpp:245]     Train net output #0: loss = 2.07092 (* 1 = 2.07092 loss)
I0605 22:40:21.708058   904 sgd_solver.cpp:106] Iteration 158280, lr = 0.00275765
I0605 22:40:42.723454   904 solver.cpp:229] Iteration 158320, loss = 2.05105
I0605 22:40:42.723676   904 solver.cpp:245]     Train net output #0: loss = 2.00254 (* 1 = 2.00254 loss)
I0605 22:40:42.723701   904 sgd_solver.cpp:106] Iteration 158320, lr = 0.00274823
I0605 22:41:03.708137   904 solver.cpp:229] Iteration 158360, loss = 2.04742
I0605 22:41:03.708178   904 solver.cpp:245]     Train net output #0: loss = 2.54004 (* 1 = 2.54004 loss)
I0605 22:41:03.708187   904 sgd_solver.cpp:106] Iteration 158360, lr = 0.00273882
I0605 22:41:24.660363   904 solver.cpp:229] Iteration 158400, loss = 2.06664
I0605 22:41:24.660519   904 solver.cpp:245]     Train net output #0: loss = 2.16087 (* 1 = 2.16087 loss)
I0605 22:41:24.660533   904 sgd_solver.cpp:106] Iteration 158400, lr = 0.00272941
I0605 22:41:28.017261   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 22:41:45.340564   904 solver.cpp:229] Iteration 158440, loss = 2.03264
I0605 22:41:45.340631   904 solver.cpp:245]     Train net output #0: loss = 1.82818 (* 1 = 1.82818 loss)
I0605 22:41:45.340641   904 sgd_solver.cpp:106] Iteration 158440, lr = 0.00272
I0605 22:42:06.018817   904 solver.cpp:229] Iteration 158480, loss = 2.00765
I0605 22:42:06.018980   904 solver.cpp:245]     Train net output #0: loss = 1.86727 (* 1 = 1.86727 loss)
I0605 22:42:06.018990   904 sgd_solver.cpp:106] Iteration 158480, lr = 0.00271059
I0605 22:42:26.719686   904 solver.cpp:229] Iteration 158520, loss = 2.01672
I0605 22:42:26.719738   904 solver.cpp:245]     Train net output #0: loss = 2.16354 (* 1 = 2.16354 loss)
I0605 22:42:26.719748   904 sgd_solver.cpp:106] Iteration 158520, lr = 0.00270118
I0605 22:42:47.424031   904 solver.cpp:229] Iteration 158560, loss = 2.01472
I0605 22:42:47.424283   904 solver.cpp:245]     Train net output #0: loss = 1.85955 (* 1 = 1.85955 loss)
I0605 22:42:47.424311   904 sgd_solver.cpp:106] Iteration 158560, lr = 0.00269176
I0605 22:43:08.080927   904 solver.cpp:229] Iteration 158600, loss = 1.99917
I0605 22:43:08.080992   904 solver.cpp:245]     Train net output #0: loss = 1.87747 (* 1 = 1.87747 loss)
I0605 22:43:08.081003   904 sgd_solver.cpp:106] Iteration 158600, lr = 0.00268235
I0605 22:43:28.751616   904 solver.cpp:229] Iteration 158640, loss = 2.03634
I0605 22:43:28.751826   904 solver.cpp:245]     Train net output #0: loss = 1.7956 (* 1 = 1.7956 loss)
I0605 22:43:28.751852   904 sgd_solver.cpp:106] Iteration 158640, lr = 0.00267294
I0605 22:43:49.259578   904 solver.cpp:229] Iteration 158680, loss = 2.01731
I0605 22:43:49.259623   904 solver.cpp:245]     Train net output #0: loss = 1.99879 (* 1 = 1.99879 loss)
I0605 22:43:49.259630   904 sgd_solver.cpp:106] Iteration 158680, lr = 0.00266353
I0605 22:44:09.881039   904 solver.cpp:229] Iteration 158720, loss = 2.00314
I0605 22:44:09.881265   904 solver.cpp:245]     Train net output #0: loss = 1.89088 (* 1 = 1.89088 loss)
I0605 22:44:09.881288   904 sgd_solver.cpp:106] Iteration 158720, lr = 0.00265412
I0605 22:44:30.478780   904 solver.cpp:229] Iteration 158760, loss = 2.03033
I0605 22:44:30.478833   904 solver.cpp:245]     Train net output #0: loss = 1.85646 (* 1 = 1.85646 loss)
I0605 22:44:30.478845   904 sgd_solver.cpp:106] Iteration 158760, lr = 0.00264471
I0605 22:44:50.977737   904 solver.cpp:229] Iteration 158800, loss = 2.03194
I0605 22:44:50.977952   904 solver.cpp:245]     Train net output #0: loss = 2.02068 (* 1 = 2.02068 loss)
I0605 22:44:50.977973   904 sgd_solver.cpp:106] Iteration 158800, lr = 0.00263529
I0605 22:45:11.454929   904 solver.cpp:229] Iteration 158840, loss = 2.03662
I0605 22:45:11.454975   904 solver.cpp:245]     Train net output #0: loss = 1.81087 (* 1 = 1.81087 loss)
I0605 22:45:11.454984   904 sgd_solver.cpp:106] Iteration 158840, lr = 0.00262588
I0605 22:45:31.978127   904 solver.cpp:229] Iteration 158880, loss = 2.02643
I0605 22:45:31.978356   904 solver.cpp:245]     Train net output #0: loss = 1.94703 (* 1 = 1.94703 loss)
I0605 22:45:31.978384   904 sgd_solver.cpp:106] Iteration 158880, lr = 0.00261647
I0605 22:45:52.479873   904 solver.cpp:229] Iteration 158920, loss = 2.0236
I0605 22:45:52.479924   904 solver.cpp:245]     Train net output #0: loss = 2.18587 (* 1 = 2.18587 loss)
I0605 22:45:52.479938   904 sgd_solver.cpp:106] Iteration 158920, lr = 0.00260706
I0605 22:45:59.099078   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 22:46:12.833784   904 solver.cpp:229] Iteration 158960, loss = 2.01079
I0605 22:46:12.834002   904 solver.cpp:245]     Train net output #0: loss = 2.06512 (* 1 = 2.06512 loss)
I0605 22:46:12.834027   904 sgd_solver.cpp:106] Iteration 158960, lr = 0.00259765
I0605 22:46:32.670555   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_159000.caffemodel
I0605 22:46:32.926677   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_159000.solverstate
I0605 22:46:33.003077   904 solver.cpp:338] Iteration 159000, Testing net (#0)
I0605 22:46:33.003151   904 net.cpp:748] Ignoring source layer loss
I0605 22:47:03.131042   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 22:47:35.991837   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 22:47:39.785933   904 solver.cpp:406]     Test net output #0: accuracy = 0.521479
I0605 22:47:39.785990   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.76052
I0605 22:47:40.099319   904 solver.cpp:229] Iteration 159000, loss = 2.03845
I0605 22:47:40.099364   904 solver.cpp:245]     Train net output #0: loss = 2.1742 (* 1 = 2.1742 loss)
I0605 22:47:40.099375   904 sgd_solver.cpp:106] Iteration 159000, lr = 0.00258824
I0605 22:47:59.310920   904 solver.cpp:229] Iteration 159040, loss = 2.03467
I0605 22:47:59.311031   904 solver.cpp:245]     Train net output #0: loss = 2.23878 (* 1 = 2.23878 loss)
I0605 22:47:59.311064   904 sgd_solver.cpp:106] Iteration 159040, lr = 0.00257882
I0605 22:48:20.727562   904 solver.cpp:229] Iteration 159080, loss = 2.04043
I0605 22:48:20.727852   904 solver.cpp:245]     Train net output #0: loss = 2.00552 (* 1 = 2.00552 loss)
I0605 22:48:20.727880   904 sgd_solver.cpp:106] Iteration 159080, lr = 0.00256941
I0605 22:48:42.230732   904 solver.cpp:229] Iteration 159120, loss = 2.05417
I0605 22:48:42.230769   904 solver.cpp:245]     Train net output #0: loss = 2.01985 (* 1 = 2.01985 loss)
I0605 22:48:42.230778   904 sgd_solver.cpp:106] Iteration 159120, lr = 0.00256
I0605 22:49:03.606441   904 solver.cpp:229] Iteration 159160, loss = 2.02684
I0605 22:49:03.606616   904 solver.cpp:245]     Train net output #0: loss = 2.17794 (* 1 = 2.17794 loss)
I0605 22:49:03.606631   904 sgd_solver.cpp:106] Iteration 159160, lr = 0.00255059
I0605 22:49:24.534418   904 solver.cpp:229] Iteration 159200, loss = 2.06363
I0605 22:49:24.534466   904 solver.cpp:245]     Train net output #0: loss = 2.15046 (* 1 = 2.15046 loss)
I0605 22:49:24.534476   904 sgd_solver.cpp:106] Iteration 159200, lr = 0.00254118
I0605 22:49:45.466502   904 solver.cpp:229] Iteration 159240, loss = 2.01699
I0605 22:49:45.466701   904 solver.cpp:245]     Train net output #0: loss = 1.69056 (* 1 = 1.69056 loss)
I0605 22:49:45.466717   904 sgd_solver.cpp:106] Iteration 159240, lr = 0.00253176
I0605 22:50:06.681301   904 solver.cpp:229] Iteration 159280, loss = 2.03163
I0605 22:50:06.681349   904 solver.cpp:245]     Train net output #0: loss = 1.99969 (* 1 = 1.99969 loss)
I0605 22:50:06.681356   904 sgd_solver.cpp:106] Iteration 159280, lr = 0.00252235
I0605 22:50:27.541460   904 solver.cpp:229] Iteration 159320, loss = 2.04635
I0605 22:50:27.541673   904 solver.cpp:245]     Train net output #0: loss = 2.15509 (* 1 = 2.15509 loss)
I0605 22:50:27.541688   904 sgd_solver.cpp:106] Iteration 159320, lr = 0.00251294
I0605 22:50:48.199201   904 solver.cpp:229] Iteration 159360, loss = 2.00267
I0605 22:50:48.199262   904 solver.cpp:245]     Train net output #0: loss = 1.75102 (* 1 = 1.75102 loss)
I0605 22:50:48.199275   904 sgd_solver.cpp:106] Iteration 159360, lr = 0.00250353
I0605 22:51:08.813046   904 solver.cpp:229] Iteration 159400, loss = 2.02804
I0605 22:51:08.813153   904 solver.cpp:245]     Train net output #0: loss = 2.09397 (* 1 = 2.09397 loss)
I0605 22:51:08.813163   904 sgd_solver.cpp:106] Iteration 159400, lr = 0.00249412
I0605 22:51:29.495090   904 solver.cpp:229] Iteration 159440, loss = 2.01636
I0605 22:51:29.495148   904 solver.cpp:245]     Train net output #0: loss = 2.00926 (* 1 = 2.00926 loss)
I0605 22:51:29.495159   904 sgd_solver.cpp:106] Iteration 159440, lr = 0.00248471
I0605 22:51:50.146090   904 solver.cpp:229] Iteration 159480, loss = 2.00965
I0605 22:51:50.146275   904 solver.cpp:245]     Train net output #0: loss = 1.86078 (* 1 = 1.86078 loss)
I0605 22:51:50.146293   904 sgd_solver.cpp:106] Iteration 159480, lr = 0.00247529
I0605 22:51:50.405189   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 22:52:10.775516   904 solver.cpp:229] Iteration 159520, loss = 2.03437
I0605 22:52:10.775585   904 solver.cpp:245]     Train net output #0: loss = 2.03638 (* 1 = 2.03638 loss)
I0605 22:52:10.775596   904 sgd_solver.cpp:106] Iteration 159520, lr = 0.00246588
I0605 22:52:31.290638   904 solver.cpp:229] Iteration 159560, loss = 2.02572
I0605 22:52:31.290815   904 solver.cpp:245]     Train net output #0: loss = 2.13715 (* 1 = 2.13715 loss)
I0605 22:52:31.290832   904 sgd_solver.cpp:106] Iteration 159560, lr = 0.00245647
I0605 22:52:51.737592   904 solver.cpp:229] Iteration 159600, loss = 2.01906
I0605 22:52:51.737640   904 solver.cpp:245]     Train net output #0: loss = 1.92681 (* 1 = 1.92681 loss)
I0605 22:52:51.737649   904 sgd_solver.cpp:106] Iteration 159600, lr = 0.00244706
I0605 22:53:12.184541   904 solver.cpp:229] Iteration 159640, loss = 1.99748
I0605 22:53:12.184746   904 solver.cpp:245]     Train net output #0: loss = 2.01265 (* 1 = 2.01265 loss)
I0605 22:53:12.184772   904 sgd_solver.cpp:106] Iteration 159640, lr = 0.00243765
I0605 22:53:32.628062   904 solver.cpp:229] Iteration 159680, loss = 1.99208
I0605 22:53:32.628113   904 solver.cpp:245]     Train net output #0: loss = 2.0168 (* 1 = 2.0168 loss)
I0605 22:53:32.628120   904 sgd_solver.cpp:106] Iteration 159680, lr = 0.00242824
I0605 22:53:53.062336   904 solver.cpp:229] Iteration 159720, loss = 2.00373
I0605 22:53:53.062571   904 solver.cpp:245]     Train net output #0: loss = 2.16032 (* 1 = 2.16032 loss)
I0605 22:53:53.062592   904 sgd_solver.cpp:106] Iteration 159720, lr = 0.00241882
I0605 22:54:13.499040   904 solver.cpp:229] Iteration 159760, loss = 2.0329
I0605 22:54:13.499089   904 solver.cpp:245]     Train net output #0: loss = 2.13242 (* 1 = 2.13242 loss)
I0605 22:54:13.499099   904 sgd_solver.cpp:106] Iteration 159760, lr = 0.00240941
I0605 22:54:33.929752   904 solver.cpp:229] Iteration 159800, loss = 2.02192
I0605 22:54:33.929908   904 solver.cpp:245]     Train net output #0: loss = 2.10878 (* 1 = 2.10878 loss)
I0605 22:54:33.929920   904 sgd_solver.cpp:106] Iteration 159800, lr = 0.0024
I0605 22:54:54.180172   904 solver.cpp:229] Iteration 159840, loss = 1.99782
I0605 22:54:54.180219   904 solver.cpp:245]     Train net output #0: loss = 1.84572 (* 1 = 1.84572 loss)
I0605 22:54:54.180230   904 sgd_solver.cpp:106] Iteration 159840, lr = 0.00239059
I0605 22:55:14.443459   904 solver.cpp:229] Iteration 159880, loss = 2.00249
I0605 22:55:14.443675   904 solver.cpp:245]     Train net output #0: loss = 1.63291 (* 1 = 1.63291 loss)
I0605 22:55:14.443698   904 sgd_solver.cpp:106] Iteration 159880, lr = 0.00238118
I0605 22:55:34.702695   904 solver.cpp:229] Iteration 159920, loss = 2.02179
I0605 22:55:34.702739   904 solver.cpp:245]     Train net output #0: loss = 1.82845 (* 1 = 1.82845 loss)
I0605 22:55:34.702749   904 sgd_solver.cpp:106] Iteration 159920, lr = 0.00237176
I0605 22:55:54.931049   904 solver.cpp:229] Iteration 159960, loss = 2.01752
I0605 22:55:54.931212   904 solver.cpp:245]     Train net output #0: loss = 2.18248 (* 1 = 2.18248 loss)
I0605 22:55:54.931224   904 sgd_solver.cpp:106] Iteration 159960, lr = 0.00236235
I0605 22:56:14.696233   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_160000.caffemodel
I0605 22:56:14.969995   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_160000.solverstate
I0605 22:56:15.059856   904 solver.cpp:338] Iteration 160000, Testing net (#0)
I0605 22:56:15.059937   904 net.cpp:748] Ignoring source layer loss
I0605 22:56:15.414512   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 22:56:51.655396   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 22:57:26.521302   904 solver.cpp:406]     Test net output #0: accuracy = 0.527979
I0605 22:57:26.521492   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.763621
I0605 22:57:26.836628   904 solver.cpp:229] Iteration 160000, loss = 1.96745
I0605 22:57:26.836675   904 solver.cpp:245]     Train net output #0: loss = 1.89175 (* 1 = 1.89175 loss)
I0605 22:57:26.836686   904 sgd_solver.cpp:106] Iteration 160000, lr = 0.00235294
I0605 22:57:30.450835   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 22:57:46.105057   904 solver.cpp:229] Iteration 160040, loss = 2.03486
I0605 22:57:46.105104   904 solver.cpp:245]     Train net output #0: loss = 1.92687 (* 1 = 1.92687 loss)
I0605 22:57:46.105115   904 sgd_solver.cpp:106] Iteration 160040, lr = 0.00234353
I0605 22:58:07.546718   904 solver.cpp:229] Iteration 160080, loss = 2.01267
I0605 22:58:07.546959   904 solver.cpp:245]     Train net output #0: loss = 2.09794 (* 1 = 2.09794 loss)
I0605 22:58:07.546985   904 sgd_solver.cpp:106] Iteration 160080, lr = 0.00233412
I0605 22:58:29.098897   904 solver.cpp:229] Iteration 160120, loss = 2.03089
I0605 22:58:29.098953   904 solver.cpp:245]     Train net output #0: loss = 2.00432 (* 1 = 2.00432 loss)
I0605 22:58:29.098963   904 sgd_solver.cpp:106] Iteration 160120, lr = 0.00232471
I0605 22:58:50.142676   904 solver.cpp:229] Iteration 160160, loss = 2.04271
I0605 22:58:50.142904   904 solver.cpp:245]     Train net output #0: loss = 2.02956 (* 1 = 2.02956 loss)
I0605 22:58:50.142927   904 sgd_solver.cpp:106] Iteration 160160, lr = 0.00231529
I0605 22:59:11.181380   904 solver.cpp:229] Iteration 160200, loss = 2.05087
I0605 22:59:11.181440   904 solver.cpp:245]     Train net output #0: loss = 2.07811 (* 1 = 2.07811 loss)
I0605 22:59:11.181452   904 sgd_solver.cpp:106] Iteration 160200, lr = 0.00230588
I0605 22:59:32.209027   904 solver.cpp:229] Iteration 160240, loss = 2.02081
I0605 22:59:32.209131   904 solver.cpp:245]     Train net output #0: loss = 2.16201 (* 1 = 2.16201 loss)
I0605 22:59:32.209141   904 sgd_solver.cpp:106] Iteration 160240, lr = 0.00229647
I0605 22:59:53.212188   904 solver.cpp:229] Iteration 160280, loss = 2.01413
I0605 22:59:53.212240   904 solver.cpp:245]     Train net output #0: loss = 2.06891 (* 1 = 2.06891 loss)
I0605 22:59:53.212249   904 sgd_solver.cpp:106] Iteration 160280, lr = 0.00228706
I0605 23:00:14.150540   904 solver.cpp:229] Iteration 160320, loss = 2.03699
I0605 23:00:14.150681   904 solver.cpp:245]     Train net output #0: loss = 1.98494 (* 1 = 1.98494 loss)
I0605 23:00:14.150707   904 sgd_solver.cpp:106] Iteration 160320, lr = 0.00227765
I0605 23:00:34.922155   904 solver.cpp:229] Iteration 160360, loss = 2.00725
I0605 23:00:34.922209   904 solver.cpp:245]     Train net output #0: loss = 1.9848 (* 1 = 1.9848 loss)
I0605 23:00:34.922222   904 sgd_solver.cpp:106] Iteration 160360, lr = 0.00226824
I0605 23:00:55.645509   904 solver.cpp:229] Iteration 160400, loss = 2.00647
I0605 23:00:55.645706   904 solver.cpp:245]     Train net output #0: loss = 2.09385 (* 1 = 2.09385 loss)
I0605 23:00:55.645731   904 sgd_solver.cpp:106] Iteration 160400, lr = 0.00225882
I0605 23:01:16.359956   904 solver.cpp:229] Iteration 160440, loss = 2.02489
I0605 23:01:16.360013   904 solver.cpp:245]     Train net output #0: loss = 1.8126 (* 1 = 1.8126 loss)
I0605 23:01:16.360023   904 sgd_solver.cpp:106] Iteration 160440, lr = 0.00224941
I0605 23:01:37.053632   904 solver.cpp:229] Iteration 160480, loss = 2.03913
I0605 23:01:37.053851   904 solver.cpp:245]     Train net output #0: loss = 1.88511 (* 1 = 1.88511 loss)
I0605 23:01:37.053879   904 sgd_solver.cpp:106] Iteration 160480, lr = 0.00224
I0605 23:01:57.763479   904 solver.cpp:229] Iteration 160520, loss = 1.97662
I0605 23:01:57.763525   904 solver.cpp:245]     Train net output #0: loss = 1.94087 (* 1 = 1.94087 loss)
I0605 23:01:57.763533   904 sgd_solver.cpp:106] Iteration 160520, lr = 0.00223059
I0605 23:02:11.715375   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 23:02:18.374608   904 solver.cpp:229] Iteration 160560, loss = 1.99658
I0605 23:02:18.374666   904 solver.cpp:245]     Train net output #0: loss = 2.11754 (* 1 = 2.11754 loss)
I0605 23:02:18.374678   904 sgd_solver.cpp:106] Iteration 160560, lr = 0.00222118
I0605 23:02:38.939913   904 solver.cpp:229] Iteration 160600, loss = 2.01302
I0605 23:02:38.939965   904 solver.cpp:245]     Train net output #0: loss = 1.91084 (* 1 = 1.91084 loss)
I0605 23:02:38.939980   904 sgd_solver.cpp:106] Iteration 160600, lr = 0.00221176
I0605 23:02:59.661509   904 solver.cpp:229] Iteration 160640, loss = 2.02804
I0605 23:02:59.661730   904 solver.cpp:245]     Train net output #0: loss = 2.18148 (* 1 = 2.18148 loss)
I0605 23:02:59.661747   904 sgd_solver.cpp:106] Iteration 160640, lr = 0.00220235
I0605 23:03:20.310849   904 solver.cpp:229] Iteration 160680, loss = 1.98017
I0605 23:03:20.310907   904 solver.cpp:245]     Train net output #0: loss = 2.04718 (* 1 = 2.04718 loss)
I0605 23:03:20.310917   904 sgd_solver.cpp:106] Iteration 160680, lr = 0.00219294
I0605 23:03:40.861892   904 solver.cpp:229] Iteration 160720, loss = 2.01467
I0605 23:03:40.862058   904 solver.cpp:245]     Train net output #0: loss = 2.07695 (* 1 = 2.07695 loss)
I0605 23:03:40.862083   904 sgd_solver.cpp:106] Iteration 160720, lr = 0.00218353
I0605 23:04:01.428753   904 solver.cpp:229] Iteration 160760, loss = 2.01484
I0605 23:04:01.428802   904 solver.cpp:245]     Train net output #0: loss = 2.02266 (* 1 = 2.02266 loss)
I0605 23:04:01.428813   904 sgd_solver.cpp:106] Iteration 160760, lr = 0.00217412
I0605 23:04:22.013586   904 solver.cpp:229] Iteration 160800, loss = 2.03485
I0605 23:04:22.013806   904 solver.cpp:245]     Train net output #0: loss = 2.07559 (* 1 = 2.07559 loss)
I0605 23:04:22.013833   904 sgd_solver.cpp:106] Iteration 160800, lr = 0.0021647
I0605 23:04:42.564651   904 solver.cpp:229] Iteration 160840, loss = 2.01268
I0605 23:04:42.564697   904 solver.cpp:245]     Train net output #0: loss = 2.04951 (* 1 = 2.04951 loss)
I0605 23:04:42.564709   904 sgd_solver.cpp:106] Iteration 160840, lr = 0.00215529
I0605 23:05:03.110911   904 solver.cpp:229] Iteration 160880, loss = 2.0142
I0605 23:05:03.111135   904 solver.cpp:245]     Train net output #0: loss = 2.03868 (* 1 = 2.03868 loss)
I0605 23:05:03.111168   904 sgd_solver.cpp:106] Iteration 160880, lr = 0.00214588
I0605 23:05:23.675040   904 solver.cpp:229] Iteration 160920, loss = 2.03457
I0605 23:05:23.675096   904 solver.cpp:245]     Train net output #0: loss = 2.21115 (* 1 = 2.21115 loss)
I0605 23:05:23.675109   904 sgd_solver.cpp:106] Iteration 160920, lr = 0.00213647
I0605 23:05:44.226770   904 solver.cpp:229] Iteration 160960, loss = 1.98409
I0605 23:05:44.226898   904 solver.cpp:245]     Train net output #0: loss = 1.91205 (* 1 = 1.91205 loss)
I0605 23:05:44.226908   904 sgd_solver.cpp:106] Iteration 160960, lr = 0.00212706
I0605 23:06:04.295683   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_161000.caffemodel
I0605 23:06:04.554180   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_161000.solverstate
I0605 23:06:04.631429   904 solver.cpp:338] Iteration 161000, Testing net (#0)
I0605 23:06:04.631510   904 net.cpp:748] Ignoring source layer loss
I0605 23:06:10.068547   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 23:06:46.283648   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 23:07:16.250144   904 solver.cpp:406]     Test net output #0: accuracy = 0.529639
I0605 23:07:16.250197   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.76426
I0605 23:07:16.565667   904 solver.cpp:229] Iteration 161000, loss = 1.9856
I0605 23:07:16.565876   904 solver.cpp:245]     Train net output #0: loss = 1.92111 (* 1 = 1.92111 loss)
I0605 23:07:16.565901   904 sgd_solver.cpp:106] Iteration 161000, lr = 0.00211765
I0605 23:07:35.787292   904 solver.cpp:229] Iteration 161040, loss = 2.0012
I0605 23:07:35.787344   904 solver.cpp:245]     Train net output #0: loss = 2.29581 (* 1 = 2.29581 loss)
I0605 23:07:35.787353   904 sgd_solver.cpp:106] Iteration 161040, lr = 0.00210824
I0605 23:07:57.249053   904 solver.cpp:229] Iteration 161080, loss = 1.99194
I0605 23:07:57.249167   904 solver.cpp:245]     Train net output #0: loss = 2.04501 (* 1 = 2.04501 loss)
I0605 23:07:57.249182   904 sgd_solver.cpp:106] Iteration 161080, lr = 0.00209882
I0605 23:08:02.097054   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 23:08:18.786455   904 solver.cpp:229] Iteration 161120, loss = 2.00104
I0605 23:08:18.786504   904 solver.cpp:245]     Train net output #0: loss = 2.17059 (* 1 = 2.17059 loss)
I0605 23:08:18.786512   904 sgd_solver.cpp:106] Iteration 161120, lr = 0.00208941
I0605 23:08:39.986520   904 solver.cpp:229] Iteration 161160, loss = 1.95245
I0605 23:08:39.986721   904 solver.cpp:245]     Train net output #0: loss = 1.84437 (* 1 = 1.84437 loss)
I0605 23:08:39.986744   904 sgd_solver.cpp:106] Iteration 161160, lr = 0.00208
I0605 23:09:00.959573   904 solver.cpp:229] Iteration 161200, loss = 2.02871
I0605 23:09:00.959630   904 solver.cpp:245]     Train net output #0: loss = 2.04305 (* 1 = 2.04305 loss)
I0605 23:09:00.959638   904 sgd_solver.cpp:106] Iteration 161200, lr = 0.00207059
I0605 23:09:21.928194   904 solver.cpp:229] Iteration 161240, loss = 1.97546
I0605 23:09:21.928426   904 solver.cpp:245]     Train net output #0: loss = 1.78014 (* 1 = 1.78014 loss)
I0605 23:09:21.928454   904 sgd_solver.cpp:106] Iteration 161240, lr = 0.00206118
I0605 23:09:42.900907   904 solver.cpp:229] Iteration 161280, loss = 2.00908
I0605 23:09:42.900959   904 solver.cpp:245]     Train net output #0: loss = 2.1809 (* 1 = 2.1809 loss)
I0605 23:09:42.900970   904 sgd_solver.cpp:106] Iteration 161280, lr = 0.00205176
I0605 23:10:03.883688   904 solver.cpp:229] Iteration 161320, loss = 1.97851
I0605 23:10:03.883929   904 solver.cpp:245]     Train net output #0: loss = 2.1847 (* 1 = 2.1847 loss)
I0605 23:10:03.883951   904 sgd_solver.cpp:106] Iteration 161320, lr = 0.00204235
I0605 23:10:24.847373   904 solver.cpp:229] Iteration 161360, loss = 2.01229
I0605 23:10:24.847432   904 solver.cpp:245]     Train net output #0: loss = 2.11093 (* 1 = 2.11093 loss)
I0605 23:10:24.847443   904 sgd_solver.cpp:106] Iteration 161360, lr = 0.00203294
I0605 23:10:45.443589   904 solver.cpp:229] Iteration 161400, loss = 1.98696
I0605 23:10:45.443815   904 solver.cpp:245]     Train net output #0: loss = 2.06006 (* 1 = 2.06006 loss)
I0605 23:10:45.443837   904 sgd_solver.cpp:106] Iteration 161400, lr = 0.00202353
I0605 23:11:06.291091   904 solver.cpp:229] Iteration 161440, loss = 1.98971
I0605 23:11:06.291138   904 solver.cpp:245]     Train net output #0: loss = 2.07261 (* 1 = 2.07261 loss)
I0605 23:11:06.291148   904 sgd_solver.cpp:106] Iteration 161440, lr = 0.00201412
I0605 23:11:26.957475   904 solver.cpp:229] Iteration 161480, loss = 2.00757
I0605 23:11:26.957666   904 solver.cpp:245]     Train net output #0: loss = 2.04887 (* 1 = 2.04887 loss)
I0605 23:11:26.957692   904 sgd_solver.cpp:106] Iteration 161480, lr = 0.00200471
I0605 23:11:47.599594   904 solver.cpp:229] Iteration 161520, loss = 2.00628
I0605 23:11:47.599643   904 solver.cpp:245]     Train net output #0: loss = 1.98967 (* 1 = 1.98967 loss)
I0605 23:11:47.599653   904 sgd_solver.cpp:106] Iteration 161520, lr = 0.00199529
I0605 23:12:08.257315   904 solver.cpp:229] Iteration 161560, loss = 2.02783
I0605 23:12:08.257514   904 solver.cpp:245]     Train net output #0: loss = 1.94357 (* 1 = 1.94357 loss)
I0605 23:12:08.257542   904 sgd_solver.cpp:106] Iteration 161560, lr = 0.00198588
I0605 23:12:28.806280   904 solver.cpp:229] Iteration 161600, loss = 2.01695
I0605 23:12:28.806334   904 solver.cpp:245]     Train net output #0: loss = 1.95691 (* 1 = 1.95691 loss)
I0605 23:12:28.806347   904 sgd_solver.cpp:106] Iteration 161600, lr = 0.00197647
I0605 23:12:35.726740   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 23:12:49.426090   904 solver.cpp:229] Iteration 161640, loss = 2.00497
I0605 23:12:49.426278   904 solver.cpp:245]     Train net output #0: loss = 2.1693 (* 1 = 2.1693 loss)
I0605 23:12:49.426308   904 sgd_solver.cpp:106] Iteration 161640, lr = 0.00196706
I0605 23:13:09.830977   904 solver.cpp:229] Iteration 161680, loss = 2.01019
I0605 23:13:09.831024   904 solver.cpp:245]     Train net output #0: loss = 1.89497 (* 1 = 1.89497 loss)
I0605 23:13:09.831035   904 sgd_solver.cpp:106] Iteration 161680, lr = 0.00195765
I0605 23:13:30.380230   904 solver.cpp:229] Iteration 161720, loss = 2.0219
I0605 23:13:30.380343   904 solver.cpp:245]     Train net output #0: loss = 2.14922 (* 1 = 2.14922 loss)
I0605 23:13:30.380354   904 sgd_solver.cpp:106] Iteration 161720, lr = 0.00194823
I0605 23:13:50.862747   904 solver.cpp:229] Iteration 161760, loss = 1.9951
I0605 23:13:50.862789   904 solver.cpp:245]     Train net output #0: loss = 1.92702 (* 1 = 1.92702 loss)
I0605 23:13:50.862799   904 sgd_solver.cpp:106] Iteration 161760, lr = 0.00193882
I0605 23:14:11.348920   904 solver.cpp:229] Iteration 161800, loss = 2.01534
I0605 23:14:11.349206   904 solver.cpp:245]     Train net output #0: loss = 2.16683 (* 1 = 2.16683 loss)
I0605 23:14:11.349256   904 sgd_solver.cpp:106] Iteration 161800, lr = 0.00192941
I0605 23:14:31.987323   904 solver.cpp:229] Iteration 161840, loss = 2.00556
I0605 23:14:31.987376   904 solver.cpp:245]     Train net output #0: loss = 2.12218 (* 1 = 2.12218 loss)
I0605 23:14:31.987386   904 sgd_solver.cpp:106] Iteration 161840, lr = 0.00192
I0605 23:14:52.368175   904 solver.cpp:229] Iteration 161880, loss = 1.95323
I0605 23:14:52.368419   904 solver.cpp:245]     Train net output #0: loss = 1.90633 (* 1 = 1.90633 loss)
I0605 23:14:52.368441   904 sgd_solver.cpp:106] Iteration 161880, lr = 0.00191059
I0605 23:15:12.622670   904 solver.cpp:229] Iteration 161920, loss = 1.99739
I0605 23:15:12.622720   904 solver.cpp:245]     Train net output #0: loss = 2.32824 (* 1 = 2.32824 loss)
I0605 23:15:12.622730   904 sgd_solver.cpp:106] Iteration 161920, lr = 0.00190118
I0605 23:15:33.007495   904 solver.cpp:229] Iteration 161960, loss = 1.98076
I0605 23:15:33.007644   904 solver.cpp:245]     Train net output #0: loss = 2.11648 (* 1 = 2.11648 loss)
I0605 23:15:33.007657   904 sgd_solver.cpp:106] Iteration 161960, lr = 0.00189177
I0605 23:15:52.904474   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_162000.caffemodel
I0605 23:15:53.171947   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_162000.solverstate
I0605 23:15:53.250552   904 solver.cpp:338] Iteration 162000, Testing net (#0)
I0605 23:15:53.250643   904 net.cpp:748] Ignoring source layer loss
I0605 23:16:02.113639   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 23:16:37.982532   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 23:17:04.599228   904 solver.cpp:406]     Test net output #0: accuracy = 0.5282
I0605 23:17:04.599277   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.766321
I0605 23:17:04.912698   904 solver.cpp:229] Iteration 162000, loss = 1.99665
I0605 23:17:04.912744   904 solver.cpp:245]     Train net output #0: loss = 1.91549 (* 1 = 1.91549 loss)
I0605 23:17:04.912755   904 sgd_solver.cpp:106] Iteration 162000, lr = 0.00188235
I0605 23:17:24.671183   904 solver.cpp:229] Iteration 162040, loss = 1.98496
I0605 23:17:24.671381   904 solver.cpp:245]     Train net output #0: loss = 2.03408 (* 1 = 2.03408 loss)
I0605 23:17:24.671406   904 sgd_solver.cpp:106] Iteration 162040, lr = 0.00187294
I0605 23:17:45.988299   904 solver.cpp:229] Iteration 162080, loss = 1.96323
I0605 23:17:45.988363   904 solver.cpp:245]     Train net output #0: loss = 2.06399 (* 1 = 2.06399 loss)
I0605 23:17:45.988389   904 sgd_solver.cpp:106] Iteration 162080, lr = 0.00186353
I0605 23:18:07.525724   904 solver.cpp:229] Iteration 162120, loss = 1.9868
I0605 23:18:07.525939   904 solver.cpp:245]     Train net output #0: loss = 1.921 (* 1 = 1.921 loss)
I0605 23:18:07.525966   904 sgd_solver.cpp:106] Iteration 162120, lr = 0.00185412
I0605 23:18:15.884277   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 23:18:29.065405   904 solver.cpp:229] Iteration 162160, loss = 1.96994
I0605 23:18:29.065471   904 solver.cpp:245]     Train net output #0: loss = 2.10236 (* 1 = 2.10236 loss)
I0605 23:18:29.065488   904 sgd_solver.cpp:106] Iteration 162160, lr = 0.00184471
I0605 23:18:50.028587   904 solver.cpp:229] Iteration 162200, loss = 1.97525
I0605 23:18:50.028759   904 solver.cpp:245]     Train net output #0: loss = 1.96938 (* 1 = 1.96938 loss)
I0605 23:18:50.028784   904 sgd_solver.cpp:106] Iteration 162200, lr = 0.00183529
I0605 23:19:10.973860   904 solver.cpp:229] Iteration 162240, loss = 1.99019
I0605 23:19:10.973906   904 solver.cpp:245]     Train net output #0: loss = 2.16619 (* 1 = 2.16619 loss)
I0605 23:19:10.973917   904 sgd_solver.cpp:106] Iteration 162240, lr = 0.00182588
I0605 23:19:32.096978   904 solver.cpp:229] Iteration 162280, loss = 1.98698
I0605 23:19:32.097177   904 solver.cpp:245]     Train net output #0: loss = 2.17931 (* 1 = 2.17931 loss)
I0605 23:19:32.097203   904 sgd_solver.cpp:106] Iteration 162280, lr = 0.00181647
I0605 23:19:53.014608   904 solver.cpp:229] Iteration 162320, loss = 2.01385
I0605 23:19:53.014654   904 solver.cpp:245]     Train net output #0: loss = 1.85666 (* 1 = 1.85666 loss)
I0605 23:19:53.014664   904 sgd_solver.cpp:106] Iteration 162320, lr = 0.00180706
I0605 23:20:13.811048   904 solver.cpp:229] Iteration 162360, loss = 1.9591
I0605 23:20:13.811257   904 solver.cpp:245]     Train net output #0: loss = 1.90184 (* 1 = 1.90184 loss)
I0605 23:20:13.811270   904 sgd_solver.cpp:106] Iteration 162360, lr = 0.00179765
I0605 23:20:34.621378   904 solver.cpp:229] Iteration 162400, loss = 1.9801
I0605 23:20:34.621438   904 solver.cpp:245]     Train net output #0: loss = 1.82469 (* 1 = 1.82469 loss)
I0605 23:20:34.621450   904 sgd_solver.cpp:106] Iteration 162400, lr = 0.00178823
I0605 23:20:55.411113   904 solver.cpp:229] Iteration 162440, loss = 2.00657
I0605 23:20:55.411351   904 solver.cpp:245]     Train net output #0: loss = 1.97511 (* 1 = 1.97511 loss)
I0605 23:20:55.411376   904 sgd_solver.cpp:106] Iteration 162440, lr = 0.00177882
I0605 23:21:15.979457   904 solver.cpp:229] Iteration 162480, loss = 1.94699
I0605 23:21:15.979511   904 solver.cpp:245]     Train net output #0: loss = 1.85623 (* 1 = 1.85623 loss)
I0605 23:21:15.979523   904 sgd_solver.cpp:106] Iteration 162480, lr = 0.00176941
I0605 23:21:36.559700   904 solver.cpp:229] Iteration 162520, loss = 1.96055
I0605 23:21:36.559893   904 solver.cpp:245]     Train net output #0: loss = 1.83205 (* 1 = 1.83205 loss)
I0605 23:21:36.559918   904 sgd_solver.cpp:106] Iteration 162520, lr = 0.00176
I0605 23:21:57.283701   904 solver.cpp:229] Iteration 162560, loss = 2.00592
I0605 23:21:57.283761   904 solver.cpp:245]     Train net output #0: loss = 1.91442 (* 1 = 1.91442 loss)
I0605 23:21:57.283773   904 sgd_solver.cpp:106] Iteration 162560, lr = 0.00175059
I0605 23:22:17.897658   904 solver.cpp:229] Iteration 162600, loss = 2.01499
I0605 23:22:17.897789   904 solver.cpp:245]     Train net output #0: loss = 2.05875 (* 1 = 2.05875 loss)
I0605 23:22:17.897800   904 sgd_solver.cpp:106] Iteration 162600, lr = 0.00174118
I0605 23:22:38.363054   904 solver.cpp:229] Iteration 162640, loss = 1.97188
I0605 23:22:38.363109   904 solver.cpp:245]     Train net output #0: loss = 1.74155 (* 1 = 1.74155 loss)
I0605 23:22:38.363119   904 sgd_solver.cpp:106] Iteration 162640, lr = 0.00173177
I0605 23:22:48.866247   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 23:22:58.843919   904 solver.cpp:229] Iteration 162680, loss = 2.01253
I0605 23:22:58.843966   904 solver.cpp:245]     Train net output #0: loss = 2.06403 (* 1 = 2.06403 loss)
I0605 23:22:58.843978   904 sgd_solver.cpp:106] Iteration 162680, lr = 0.00172235
I0605 23:23:19.316819   904 solver.cpp:229] Iteration 162720, loss = 1.98894
I0605 23:23:19.316997   904 solver.cpp:245]     Train net output #0: loss = 1.95987 (* 1 = 1.95987 loss)
I0605 23:23:19.317023   904 sgd_solver.cpp:106] Iteration 162720, lr = 0.00171294
I0605 23:23:39.799971   904 solver.cpp:229] Iteration 162760, loss = 1.98238
I0605 23:23:39.800031   904 solver.cpp:245]     Train net output #0: loss = 2.02133 (* 1 = 2.02133 loss)
I0605 23:23:39.800045   904 sgd_solver.cpp:106] Iteration 162760, lr = 0.00170353
I0605 23:24:00.278810   904 solver.cpp:229] Iteration 162800, loss = 1.98016
I0605 23:24:00.278954   904 solver.cpp:245]     Train net output #0: loss = 1.88448 (* 1 = 1.88448 loss)
I0605 23:24:00.278969   904 sgd_solver.cpp:106] Iteration 162800, lr = 0.00169412
I0605 23:24:20.670660   904 solver.cpp:229] Iteration 162840, loss = 2.00176
I0605 23:24:20.670708   904 solver.cpp:245]     Train net output #0: loss = 2.01964 (* 1 = 2.01964 loss)
I0605 23:24:20.670722   904 sgd_solver.cpp:106] Iteration 162840, lr = 0.00168471
I0605 23:24:41.013499   904 solver.cpp:229] Iteration 162880, loss = 1.99086
I0605 23:24:41.013710   904 solver.cpp:245]     Train net output #0: loss = 1.98108 (* 1 = 1.98108 loss)
I0605 23:24:41.013734   904 sgd_solver.cpp:106] Iteration 162880, lr = 0.00167529
I0605 23:25:01.341848   904 solver.cpp:229] Iteration 162920, loss = 1.99222
I0605 23:25:01.341903   904 solver.cpp:245]     Train net output #0: loss = 1.82501 (* 1 = 1.82501 loss)
I0605 23:25:01.341917   904 sgd_solver.cpp:106] Iteration 162920, lr = 0.00166588
I0605 23:25:21.618237   904 solver.cpp:229] Iteration 162960, loss = 1.9853
I0605 23:25:21.618432   904 solver.cpp:245]     Train net output #0: loss = 2.02021 (* 1 = 2.02021 loss)
I0605 23:25:21.618456   904 sgd_solver.cpp:106] Iteration 162960, lr = 0.00165647
I0605 23:25:41.377403   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_163000.caffemodel
I0605 23:25:41.646201   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_163000.solverstate
I0605 23:25:41.724341   904 solver.cpp:338] Iteration 163000, Testing net (#0)
I0605 23:25:41.724449   904 net.cpp:748] Ignoring source layer loss
I0605 23:25:54.212532   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 23:26:29.853966   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 23:26:53.357620   904 solver.cpp:406]     Test net output #0: accuracy = 0.534139
I0605 23:26:53.357657   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.767621
I0605 23:26:53.670861   904 solver.cpp:229] Iteration 163000, loss = 1.9669
I0605 23:26:53.670898   904 solver.cpp:245]     Train net output #0: loss = 2.0033 (* 1 = 2.0033 loss)
I0605 23:26:53.670907   904 sgd_solver.cpp:106] Iteration 163000, lr = 0.00164706
I0605 23:27:13.389780   904 solver.cpp:229] Iteration 163040, loss = 1.95977
I0605 23:27:13.389916   904 solver.cpp:245]     Train net output #0: loss = 2.12996 (* 1 = 2.12996 loss)
I0605 23:27:13.389932   904 sgd_solver.cpp:106] Iteration 163040, lr = 0.00163765
I0605 23:27:34.747845   904 solver.cpp:229] Iteration 163080, loss = 1.96637
I0605 23:27:34.747894   904 solver.cpp:245]     Train net output #0: loss = 2.2387 (* 1 = 2.2387 loss)
I0605 23:27:34.747913   904 sgd_solver.cpp:106] Iteration 163080, lr = 0.00162823
I0605 23:27:56.293570   904 solver.cpp:229] Iteration 163120, loss = 2.00106
I0605 23:27:56.293700   904 solver.cpp:245]     Train net output #0: loss = 1.96623 (* 1 = 1.96623 loss)
I0605 23:27:56.293711   904 sgd_solver.cpp:106] Iteration 163120, lr = 0.00161882
I0605 23:28:17.651404   904 solver.cpp:229] Iteration 163160, loss = 1.99
I0605 23:28:17.651454   904 solver.cpp:245]     Train net output #0: loss = 1.83304 (* 1 = 1.83304 loss)
I0605 23:28:17.651463   904 sgd_solver.cpp:106] Iteration 163160, lr = 0.00160941
I0605 23:28:25.592957   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 23:28:38.795516   904 solver.cpp:229] Iteration 163200, loss = 1.95325
I0605 23:28:38.795713   904 solver.cpp:245]     Train net output #0: loss = 1.89387 (* 1 = 1.89387 loss)
I0605 23:28:38.795734   904 sgd_solver.cpp:106] Iteration 163200, lr = 0.0016
I0605 23:28:59.757446   904 solver.cpp:229] Iteration 163240, loss = 1.98975
I0605 23:28:59.757506   904 solver.cpp:245]     Train net output #0: loss = 1.67864 (* 1 = 1.67864 loss)
I0605 23:28:59.757517   904 sgd_solver.cpp:106] Iteration 163240, lr = 0.00159059
I0605 23:29:20.749487   904 solver.cpp:229] Iteration 163280, loss = 1.99103
I0605 23:29:20.749644   904 solver.cpp:245]     Train net output #0: loss = 1.91724 (* 1 = 1.91724 loss)
I0605 23:29:20.749656   904 sgd_solver.cpp:106] Iteration 163280, lr = 0.00158118
I0605 23:29:41.749287   904 solver.cpp:229] Iteration 163320, loss = 1.98713
I0605 23:29:41.749332   904 solver.cpp:245]     Train net output #0: loss = 1.86788 (* 1 = 1.86788 loss)
I0605 23:29:41.749342   904 sgd_solver.cpp:106] Iteration 163320, lr = 0.00157176
I0605 23:30:02.754441   904 solver.cpp:229] Iteration 163360, loss = 1.96343
I0605 23:30:02.754643   904 solver.cpp:245]     Train net output #0: loss = 1.94417 (* 1 = 1.94417 loss)
I0605 23:30:02.754662   904 sgd_solver.cpp:106] Iteration 163360, lr = 0.00156235
I0605 23:30:23.755019   904 solver.cpp:229] Iteration 163400, loss = 2.01872
I0605 23:30:23.755064   904 solver.cpp:245]     Train net output #0: loss = 2.02719 (* 1 = 2.02719 loss)
I0605 23:30:23.755074   904 sgd_solver.cpp:106] Iteration 163400, lr = 0.00155294
I0605 23:30:44.566684   904 solver.cpp:229] Iteration 163440, loss = 1.98529
I0605 23:30:44.566920   904 solver.cpp:245]     Train net output #0: loss = 1.94033 (* 1 = 1.94033 loss)
I0605 23:30:44.566946   904 sgd_solver.cpp:106] Iteration 163440, lr = 0.00154353
I0605 23:31:05.401203   904 solver.cpp:229] Iteration 163480, loss = 1.94657
I0605 23:31:05.401250   904 solver.cpp:245]     Train net output #0: loss = 1.95545 (* 1 = 1.95545 loss)
I0605 23:31:05.401259   904 sgd_solver.cpp:106] Iteration 163480, lr = 0.00153412
I0605 23:31:26.199740   904 solver.cpp:229] Iteration 163520, loss = 1.97361
I0605 23:31:26.199981   904 solver.cpp:245]     Train net output #0: loss = 2.21323 (* 1 = 2.21323 loss)
I0605 23:31:26.200009   904 sgd_solver.cpp:106] Iteration 163520, lr = 0.00152471
I0605 23:31:46.870209   904 solver.cpp:229] Iteration 163560, loss = 1.96602
I0605 23:31:46.870265   904 solver.cpp:245]     Train net output #0: loss = 2.14274 (* 1 = 2.14274 loss)
I0605 23:31:46.870275   904 sgd_solver.cpp:106] Iteration 163560, lr = 0.00151529
I0605 23:32:07.554350   904 solver.cpp:229] Iteration 163600, loss = 1.94047
I0605 23:32:07.554602   904 solver.cpp:245]     Train net output #0: loss = 2.13472 (* 1 = 2.13472 loss)
I0605 23:32:07.554639   904 sgd_solver.cpp:106] Iteration 163600, lr = 0.00150588
I0605 23:32:28.282021   904 solver.cpp:229] Iteration 163640, loss = 1.9577
I0605 23:32:28.282075   904 solver.cpp:245]     Train net output #0: loss = 2.12062 (* 1 = 2.12062 loss)
I0605 23:32:28.282085   904 sgd_solver.cpp:106] Iteration 163640, lr = 0.00149647
I0605 23:32:48.963974   904 solver.cpp:229] Iteration 163680, loss = 1.94387
I0605 23:32:48.964186   904 solver.cpp:245]     Train net output #0: loss = 1.89215 (* 1 = 1.89215 loss)
I0605 23:32:48.964224   904 sgd_solver.cpp:106] Iteration 163680, lr = 0.00148706
I0605 23:32:52.319787   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 23:33:09.625418   904 solver.cpp:229] Iteration 163720, loss = 1.95546
I0605 23:33:09.625463   904 solver.cpp:245]     Train net output #0: loss = 2.01532 (* 1 = 2.01532 loss)
I0605 23:33:09.625473   904 sgd_solver.cpp:106] Iteration 163720, lr = 0.00147765
I0605 23:33:30.143240   904 solver.cpp:229] Iteration 163760, loss = 1.9745
I0605 23:33:30.143456   904 solver.cpp:245]     Train net output #0: loss = 2.0105 (* 1 = 2.0105 loss)
I0605 23:33:30.143484   904 sgd_solver.cpp:106] Iteration 163760, lr = 0.00146824
I0605 23:33:50.417912   904 solver.cpp:229] Iteration 163800, loss = 1.97436
I0605 23:33:50.417969   904 solver.cpp:245]     Train net output #0: loss = 2.29274 (* 1 = 2.29274 loss)
I0605 23:33:50.417979   904 sgd_solver.cpp:106] Iteration 163800, lr = 0.00145882
I0605 23:34:10.694120   904 solver.cpp:229] Iteration 163840, loss = 1.96525
I0605 23:34:10.694298   904 solver.cpp:245]     Train net output #0: loss = 2.13626 (* 1 = 2.13626 loss)
I0605 23:34:10.694310   904 sgd_solver.cpp:106] Iteration 163840, lr = 0.00144941
I0605 23:34:30.975329   904 solver.cpp:229] Iteration 163880, loss = 1.94727
I0605 23:34:30.975390   904 solver.cpp:245]     Train net output #0: loss = 2.25728 (* 1 = 2.25728 loss)
I0605 23:34:30.975401   904 sgd_solver.cpp:106] Iteration 163880, lr = 0.00144
I0605 23:34:51.121510   904 solver.cpp:229] Iteration 163920, loss = 1.95416
I0605 23:34:51.121742   904 solver.cpp:245]     Train net output #0: loss = 2.25929 (* 1 = 2.25929 loss)
I0605 23:34:51.121769   904 sgd_solver.cpp:106] Iteration 163920, lr = 0.00143059
I0605 23:35:11.089589   904 solver.cpp:229] Iteration 163960, loss = 1.95543
I0605 23:35:11.089650   904 solver.cpp:245]     Train net output #0: loss = 2.00032 (* 1 = 2.00032 loss)
I0605 23:35:11.089660   904 sgd_solver.cpp:106] Iteration 163960, lr = 0.00142118
I0605 23:35:30.567100   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_164000.caffemodel
I0605 23:35:30.823321   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_164000.solverstate
I0605 23:35:30.901949   904 solver.cpp:338] Iteration 164000, Testing net (#0)
I0605 23:35:30.902045   904 net.cpp:748] Ignoring source layer loss
I0605 23:35:46.157338   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 23:36:20.879889   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 23:36:41.195523   904 solver.cpp:406]     Test net output #0: accuracy = 0.535139
I0605 23:36:41.195577   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.76884
I0605 23:36:41.510146   904 solver.cpp:229] Iteration 164000, loss = 1.9903
I0605 23:36:41.510192   904 solver.cpp:245]     Train net output #0: loss = 1.95039 (* 1 = 1.95039 loss)
I0605 23:36:41.510201   904 sgd_solver.cpp:106] Iteration 164000, lr = 0.00141176
I0605 23:37:00.654822   904 solver.cpp:229] Iteration 164040, loss = 1.97456
I0605 23:37:00.655021   904 solver.cpp:245]     Train net output #0: loss = 2.17859 (* 1 = 2.17859 loss)
I0605 23:37:00.655048   904 sgd_solver.cpp:106] Iteration 164040, lr = 0.00140235
I0605 23:37:21.973850   904 solver.cpp:229] Iteration 164080, loss = 1.99534
I0605 23:37:21.973908   904 solver.cpp:245]     Train net output #0: loss = 2.07735 (* 1 = 2.07735 loss)
I0605 23:37:21.973918   904 sgd_solver.cpp:106] Iteration 164080, lr = 0.00139294
I0605 23:37:43.267472   904 solver.cpp:229] Iteration 164120, loss = 1.9724
I0605 23:37:43.267602   904 solver.cpp:245]     Train net output #0: loss = 2.02033 (* 1 = 2.02033 loss)
I0605 23:37:43.267614   904 sgd_solver.cpp:106] Iteration 164120, lr = 0.00138353
I0605 23:38:04.086812   904 solver.cpp:229] Iteration 164160, loss = 1.9586
I0605 23:38:04.086856   904 solver.cpp:245]     Train net output #0: loss = 1.87472 (* 1 = 1.87472 loss)
I0605 23:38:04.086864   904 sgd_solver.cpp:106] Iteration 164160, lr = 0.00137412
I0605 23:38:24.876307   904 solver.cpp:229] Iteration 164200, loss = 1.97601
I0605 23:38:24.876528   904 solver.cpp:245]     Train net output #0: loss = 2.19774 (* 1 = 2.19774 loss)
I0605 23:38:24.876550   904 sgd_solver.cpp:106] Iteration 164200, lr = 0.00136471
I0605 23:38:34.021719   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 23:38:45.781417   904 solver.cpp:229] Iteration 164240, loss = 1.96203
I0605 23:38:45.781473   904 solver.cpp:245]     Train net output #0: loss = 2.07911 (* 1 = 2.07911 loss)
I0605 23:38:45.781486   904 sgd_solver.cpp:106] Iteration 164240, lr = 0.0013553
I0605 23:39:06.648988   904 solver.cpp:229] Iteration 164280, loss = 1.96514
I0605 23:39:06.649230   904 solver.cpp:245]     Train net output #0: loss = 1.9436 (* 1 = 1.9436 loss)
I0605 23:39:06.649255   904 sgd_solver.cpp:106] Iteration 164280, lr = 0.00134588
I0605 23:39:27.275754   904 solver.cpp:229] Iteration 164320, loss = 1.96741
I0605 23:39:27.275820   904 solver.cpp:245]     Train net output #0: loss = 1.94377 (* 1 = 1.94377 loss)
I0605 23:39:27.275836   904 sgd_solver.cpp:106] Iteration 164320, lr = 0.00133647
I0605 23:39:47.917615   904 solver.cpp:229] Iteration 164360, loss = 1.94845
I0605 23:39:47.917843   904 solver.cpp:245]     Train net output #0: loss = 2.09844 (* 1 = 2.09844 loss)
I0605 23:39:47.917872   904 sgd_solver.cpp:106] Iteration 164360, lr = 0.00132706
I0605 23:40:08.530556   904 solver.cpp:229] Iteration 164400, loss = 1.94484
I0605 23:40:08.530603   904 solver.cpp:245]     Train net output #0: loss = 2.00254 (* 1 = 2.00254 loss)
I0605 23:40:08.530612   904 sgd_solver.cpp:106] Iteration 164400, lr = 0.00131765
I0605 23:40:29.137449   904 solver.cpp:229] Iteration 164440, loss = 1.96257
I0605 23:40:29.137652   904 solver.cpp:245]     Train net output #0: loss = 1.76523 (* 1 = 1.76523 loss)
I0605 23:40:29.137677   904 sgd_solver.cpp:106] Iteration 164440, lr = 0.00130824
I0605 23:40:49.746929   904 solver.cpp:229] Iteration 164480, loss = 1.94308
I0605 23:40:49.746984   904 solver.cpp:245]     Train net output #0: loss = 1.82745 (* 1 = 1.82745 loss)
I0605 23:40:49.746994   904 sgd_solver.cpp:106] Iteration 164480, lr = 0.00129882
I0605 23:41:10.256976   904 solver.cpp:229] Iteration 164520, loss = 1.96866
I0605 23:41:10.258926   904 solver.cpp:245]     Train net output #0: loss = 2.13072 (* 1 = 2.13072 loss)
I0605 23:41:10.258952   904 sgd_solver.cpp:106] Iteration 164520, lr = 0.00128941
I0605 23:41:30.682597   904 solver.cpp:229] Iteration 164560, loss = 1.95145
I0605 23:41:30.682637   904 solver.cpp:245]     Train net output #0: loss = 1.9401 (* 1 = 1.9401 loss)
I0605 23:41:30.682646   904 sgd_solver.cpp:106] Iteration 164560, lr = 0.00128
I0605 23:41:51.126425   904 solver.cpp:229] Iteration 164600, loss = 1.95323
I0605 23:41:51.126765   904 solver.cpp:245]     Train net output #0: loss = 2.05542 (* 1 = 2.05542 loss)
I0605 23:41:51.126793   904 sgd_solver.cpp:106] Iteration 164600, lr = 0.00127059
I0605 23:42:11.602550   904 solver.cpp:229] Iteration 164640, loss = 1.93796
I0605 23:42:11.602597   904 solver.cpp:245]     Train net output #0: loss = 1.97133 (* 1 = 1.97133 loss)
I0605 23:42:11.602608   904 sgd_solver.cpp:106] Iteration 164640, lr = 0.00126118
I0605 23:42:32.071535   904 solver.cpp:229] Iteration 164680, loss = 1.93815
I0605 23:42:32.071689   904 solver.cpp:245]     Train net output #0: loss = 1.67582 (* 1 = 1.67582 loss)
I0605 23:42:32.071699   904 sgd_solver.cpp:106] Iteration 164680, lr = 0.00125176
I0605 23:42:52.516800   904 solver.cpp:229] Iteration 164720, loss = 1.9376
I0605 23:42:52.516844   904 solver.cpp:245]     Train net output #0: loss = 2.07976 (* 1 = 2.07976 loss)
I0605 23:42:52.516855   904 sgd_solver.cpp:106] Iteration 164720, lr = 0.00124235
I0605 23:43:00.433344   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 23:43:12.878243   904 solver.cpp:229] Iteration 164760, loss = 1.98192
I0605 23:43:12.878455   904 solver.cpp:245]     Train net output #0: loss = 2.35235 (* 1 = 2.35235 loss)
I0605 23:43:12.878474   904 sgd_solver.cpp:106] Iteration 164760, lr = 0.00123294
I0605 23:43:33.172371   904 solver.cpp:229] Iteration 164800, loss = 1.95004
I0605 23:43:33.172426   904 solver.cpp:245]     Train net output #0: loss = 2.02148 (* 1 = 2.02148 loss)
I0605 23:43:33.172435   904 sgd_solver.cpp:106] Iteration 164800, lr = 0.00122353
I0605 23:43:53.400234   904 solver.cpp:229] Iteration 164840, loss = 1.95055
I0605 23:43:53.400465   904 solver.cpp:245]     Train net output #0: loss = 1.79352 (* 1 = 1.79352 loss)
I0605 23:43:53.400490   904 sgd_solver.cpp:106] Iteration 164840, lr = 0.00121412
I0605 23:44:13.669018   904 solver.cpp:229] Iteration 164880, loss = 1.93732
I0605 23:44:13.669062   904 solver.cpp:245]     Train net output #0: loss = 2.03233 (* 1 = 2.03233 loss)
I0605 23:44:13.669071   904 sgd_solver.cpp:106] Iteration 164880, lr = 0.00120471
I0605 23:44:33.971375   904 solver.cpp:229] Iteration 164920, loss = 1.95673
I0605 23:44:33.971596   904 solver.cpp:245]     Train net output #0: loss = 1.88439 (* 1 = 1.88439 loss)
I0605 23:44:33.971622   904 sgd_solver.cpp:106] Iteration 164920, lr = 0.00119529
I0605 23:44:54.400079   904 solver.cpp:229] Iteration 164960, loss = 1.94151
I0605 23:44:54.400130   904 solver.cpp:245]     Train net output #0: loss = 2.08291 (* 1 = 2.08291 loss)
I0605 23:44:54.400137   904 sgd_solver.cpp:106] Iteration 164960, lr = 0.00118588
I0605 23:45:14.136091   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_165000.caffemodel
I0605 23:45:14.395823   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_165000.solverstate
I0605 23:45:14.473654   904 solver.cpp:338] Iteration 165000, Testing net (#0)
I0605 23:45:14.473737   904 net.cpp:748] Ignoring source layer loss
I0605 23:45:32.104815   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 23:46:08.675838   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 23:46:26.046267   904 solver.cpp:406]     Test net output #0: accuracy = 0.536559
I0605 23:46:26.046324   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.76978
I0605 23:46:26.362243   904 solver.cpp:229] Iteration 165000, loss = 1.92131
I0605 23:46:26.362287   904 solver.cpp:245]     Train net output #0: loss = 1.98904 (* 1 = 1.98904 loss)
I0605 23:46:26.362298   904 sgd_solver.cpp:106] Iteration 165000, lr = 0.00117647
I0605 23:46:45.586163   904 solver.cpp:229] Iteration 165040, loss = 1.94332
I0605 23:46:45.589627   904 solver.cpp:245]     Train net output #0: loss = 1.99822 (* 1 = 1.99822 loss)
I0605 23:46:45.589643   904 sgd_solver.cpp:106] Iteration 165040, lr = 0.00116706
I0605 23:47:07.002023   904 solver.cpp:229] Iteration 165080, loss = 1.94799
I0605 23:47:07.002070   904 solver.cpp:245]     Train net output #0: loss = 1.96052 (* 1 = 1.96052 loss)
I0605 23:47:07.002079   904 sgd_solver.cpp:106] Iteration 165080, lr = 0.00115765
I0605 23:47:28.425879   904 solver.cpp:229] Iteration 165120, loss = 1.95864
I0605 23:47:28.426143   904 solver.cpp:245]     Train net output #0: loss = 2.18276 (* 1 = 2.18276 loss)
I0605 23:47:28.426180   904 sgd_solver.cpp:106] Iteration 165120, lr = 0.00114824
I0605 23:47:49.417234   904 solver.cpp:229] Iteration 165160, loss = 1.9602
I0605 23:47:49.417284   904 solver.cpp:245]     Train net output #0: loss = 2.10469 (* 1 = 2.10469 loss)
I0605 23:47:49.417294   904 sgd_solver.cpp:106] Iteration 165160, lr = 0.00113882
I0605 23:48:10.395184   904 solver.cpp:229] Iteration 165200, loss = 1.96667
I0605 23:48:10.395330   904 solver.cpp:245]     Train net output #0: loss = 1.90414 (* 1 = 1.90414 loss)
I0605 23:48:10.395340   904 sgd_solver.cpp:106] Iteration 165200, lr = 0.00112941
I0605 23:48:31.400182   904 solver.cpp:229] Iteration 165240, loss = 1.95172
I0605 23:48:31.400240   904 solver.cpp:245]     Train net output #0: loss = 1.91445 (* 1 = 1.91445 loss)
I0605 23:48:31.400251   904 sgd_solver.cpp:106] Iteration 165240, lr = 0.00112
I0605 23:48:41.835263   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 23:48:52.238320   904 solver.cpp:229] Iteration 165280, loss = 1.93286
I0605 23:48:52.238369   904 solver.cpp:245]     Train net output #0: loss = 1.84374 (* 1 = 1.84374 loss)
I0605 23:48:52.238379   904 sgd_solver.cpp:106] Iteration 165280, lr = 0.00111059
I0605 23:49:13.081876   904 solver.cpp:229] Iteration 165320, loss = 1.96707
I0605 23:49:13.082089   904 solver.cpp:245]     Train net output #0: loss = 2.23412 (* 1 = 2.23412 loss)
I0605 23:49:13.082126   904 sgd_solver.cpp:106] Iteration 165320, lr = 0.00110118
I0605 23:49:33.886083   904 solver.cpp:229] Iteration 165360, loss = 1.96082
I0605 23:49:33.886137   904 solver.cpp:245]     Train net output #0: loss = 2.17862 (* 1 = 2.17862 loss)
I0605 23:49:33.886145   904 sgd_solver.cpp:106] Iteration 165360, lr = 0.00109176
I0605 23:49:54.429599   904 solver.cpp:229] Iteration 165400, loss = 1.94817
I0605 23:49:54.429793   904 solver.cpp:245]     Train net output #0: loss = 2.05165 (* 1 = 2.05165 loss)
I0605 23:49:54.429817   904 sgd_solver.cpp:106] Iteration 165400, lr = 0.00108235
I0605 23:50:15.004011   904 solver.cpp:229] Iteration 165440, loss = 1.96939
I0605 23:50:15.004062   904 solver.cpp:245]     Train net output #0: loss = 2.00059 (* 1 = 2.00059 loss)
I0605 23:50:15.004070   904 sgd_solver.cpp:106] Iteration 165440, lr = 0.00107294
I0605 23:50:35.686053   904 solver.cpp:229] Iteration 165480, loss = 1.95916
I0605 23:50:35.686245   904 solver.cpp:245]     Train net output #0: loss = 1.936 (* 1 = 1.936 loss)
I0605 23:50:35.686270   904 sgd_solver.cpp:106] Iteration 165480, lr = 0.00106353
I0605 23:50:56.234716   904 solver.cpp:229] Iteration 165520, loss = 1.9121
I0605 23:50:56.234772   904 solver.cpp:245]     Train net output #0: loss = 1.80838 (* 1 = 1.80838 loss)
I0605 23:50:56.234782   904 sgd_solver.cpp:106] Iteration 165520, lr = 0.00105412
I0605 23:51:16.532196   904 solver.cpp:229] Iteration 165560, loss = 1.91666
I0605 23:51:16.532361   904 solver.cpp:245]     Train net output #0: loss = 1.85553 (* 1 = 1.85553 loss)
I0605 23:51:16.532371   904 sgd_solver.cpp:106] Iteration 165560, lr = 0.0010447
I0605 23:51:36.943873   904 solver.cpp:229] Iteration 165600, loss = 1.96172
I0605 23:51:36.943930   904 solver.cpp:245]     Train net output #0: loss = 1.98065 (* 1 = 1.98065 loss)
I0605 23:51:36.943943   904 sgd_solver.cpp:106] Iteration 165600, lr = 0.00103529
I0605 23:51:57.426128   904 solver.cpp:229] Iteration 165640, loss = 1.96023
I0605 23:51:57.426268   904 solver.cpp:245]     Train net output #0: loss = 2.14966 (* 1 = 2.14966 loss)
I0605 23:51:57.426280   904 sgd_solver.cpp:106] Iteration 165640, lr = 0.00102588
I0605 23:52:17.964427   904 solver.cpp:229] Iteration 165680, loss = 1.92394
I0605 23:52:17.964479   904 solver.cpp:245]     Train net output #0: loss = 2.07408 (* 1 = 2.07408 loss)
I0605 23:52:17.964490   904 sgd_solver.cpp:106] Iteration 165680, lr = 0.00101647
I0605 23:52:38.450932   904 solver.cpp:229] Iteration 165720, loss = 1.93332
I0605 23:52:38.451185   904 solver.cpp:245]     Train net output #0: loss = 1.92467 (* 1 = 1.92467 loss)
I0605 23:52:38.451196   904 sgd_solver.cpp:106] Iteration 165720, lr = 0.00100706
I0605 23:52:58.788380   904 solver.cpp:229] Iteration 165760, loss = 1.95752
I0605 23:52:58.788432   904 solver.cpp:245]     Train net output #0: loss = 1.93095 (* 1 = 1.93095 loss)
I0605 23:52:58.788441   904 sgd_solver.cpp:106] Iteration 165760, lr = 0.000997648
I0605 23:53:09.454198   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 23:53:19.093832   904 solver.cpp:229] Iteration 165800, loss = 1.96379
I0605 23:53:19.093884   904 solver.cpp:245]     Train net output #0: loss = 1.95858 (* 1 = 1.95858 loss)
I0605 23:53:19.093894   904 sgd_solver.cpp:106] Iteration 165800, lr = 0.000988235
I0605 23:53:39.403569   904 solver.cpp:229] Iteration 165840, loss = 1.94061
I0605 23:53:39.403614   904 solver.cpp:245]     Train net output #0: loss = 1.82451 (* 1 = 1.82451 loss)
I0605 23:53:39.403625   904 sgd_solver.cpp:106] Iteration 165840, lr = 0.000978823
I0605 23:53:59.716959   904 solver.cpp:229] Iteration 165880, loss = 1.94838
I0605 23:53:59.717134   904 solver.cpp:245]     Train net output #0: loss = 1.81012 (* 1 = 1.81012 loss)
I0605 23:53:59.717162   904 sgd_solver.cpp:106] Iteration 165880, lr = 0.000969412
I0605 23:54:20.019181   904 solver.cpp:229] Iteration 165920, loss = 1.96096
I0605 23:54:20.019238   904 solver.cpp:245]     Train net output #0: loss = 1.93645 (* 1 = 1.93645 loss)
I0605 23:54:20.019251   904 sgd_solver.cpp:106] Iteration 165920, lr = 0.00096
I0605 23:54:40.340245   904 solver.cpp:229] Iteration 165960, loss = 1.9199
I0605 23:54:40.340456   904 solver.cpp:245]     Train net output #0: loss = 1.72928 (* 1 = 1.72928 loss)
I0605 23:54:40.340482   904 sgd_solver.cpp:106] Iteration 165960, lr = 0.000950589
I0605 23:55:00.153298   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_166000.caffemodel
I0605 23:55:00.417932   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_166000.solverstate
I0605 23:55:00.503479   904 solver.cpp:338] Iteration 166000, Testing net (#0)
I0605 23:55:00.503558   904 net.cpp:748] Ignoring source layer loss
I0605 23:55:20.385524   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 23:55:55.789376   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 23:56:09.968982   904 solver.cpp:406]     Test net output #0: accuracy = 0.538539
I0605 23:56:09.969017   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.770941
I0605 23:56:10.282269   904 solver.cpp:229] Iteration 166000, loss = 1.92323
I0605 23:56:10.282318   904 solver.cpp:245]     Train net output #0: loss = 1.87309 (* 1 = 1.87309 loss)
I0605 23:56:10.282332   904 sgd_solver.cpp:106] Iteration 166000, lr = 0.000941176
I0605 23:56:29.508757   904 solver.cpp:229] Iteration 166040, loss = 1.94588
I0605 23:56:29.508903   904 solver.cpp:245]     Train net output #0: loss = 1.78488 (* 1 = 1.78488 loss)
I0605 23:56:29.508913   904 sgd_solver.cpp:106] Iteration 166040, lr = 0.000931764
I0605 23:56:50.937608   904 solver.cpp:229] Iteration 166080, loss = 1.93058
I0605 23:56:50.937652   904 solver.cpp:245]     Train net output #0: loss = 1.84301 (* 1 = 1.84301 loss)
I0605 23:56:50.937662   904 sgd_solver.cpp:106] Iteration 166080, lr = 0.000922353
I0605 23:57:12.510581   904 solver.cpp:229] Iteration 166120, loss = 1.92809
I0605 23:57:12.510731   904 solver.cpp:245]     Train net output #0: loss = 2.03009 (* 1 = 2.03009 loss)
I0605 23:57:12.510742   904 sgd_solver.cpp:106] Iteration 166120, lr = 0.00091294
I0605 23:57:33.799674   904 solver.cpp:229] Iteration 166160, loss = 1.90016
I0605 23:57:33.799720   904 solver.cpp:245]     Train net output #0: loss = 1.77911 (* 1 = 1.77911 loss)
I0605 23:57:33.799728   904 sgd_solver.cpp:106] Iteration 166160, lr = 0.00090353
I0605 23:57:54.813316   904 solver.cpp:229] Iteration 166200, loss = 1.93218
I0605 23:57:54.813551   904 solver.cpp:245]     Train net output #0: loss = 1.68392 (* 1 = 1.68392 loss)
I0605 23:57:54.813567   904 sgd_solver.cpp:106] Iteration 166200, lr = 0.000894117
I0605 23:58:15.825639   904 solver.cpp:229] Iteration 166240, loss = 1.91212
I0605 23:58:15.825680   904 solver.cpp:245]     Train net output #0: loss = 1.98276 (* 1 = 1.98276 loss)
I0605 23:58:15.825687   904 sgd_solver.cpp:106] Iteration 166240, lr = 0.000884707
I0605 23:58:36.824715   904 solver.cpp:229] Iteration 166280, loss = 1.95168
I0605 23:58:36.824867   904 solver.cpp:245]     Train net output #0: loss = 1.82671 (* 1 = 1.82671 loss)
I0605 23:58:36.824877   904 sgd_solver.cpp:106] Iteration 166280, lr = 0.000875294
I0605 23:58:52.845711   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0605 23:58:57.830692   904 solver.cpp:229] Iteration 166320, loss = 1.91459
I0605 23:58:57.830741   904 solver.cpp:245]     Train net output #0: loss = 1.9615 (* 1 = 1.9615 loss)
I0605 23:58:57.830749   904 sgd_solver.cpp:106] Iteration 166320, lr = 0.000865881
I0605 23:59:18.818164   904 solver.cpp:229] Iteration 166360, loss = 1.91824
I0605 23:59:18.818361   904 solver.cpp:245]     Train net output #0: loss = 1.52767 (* 1 = 1.52767 loss)
I0605 23:59:18.818387   904 sgd_solver.cpp:106] Iteration 166360, lr = 0.000856471
I0605 23:59:39.657163   904 solver.cpp:229] Iteration 166400, loss = 1.93404
I0605 23:59:39.657219   904 solver.cpp:245]     Train net output #0: loss = 2.06367 (* 1 = 2.06367 loss)
I0605 23:59:39.657228   904 sgd_solver.cpp:106] Iteration 166400, lr = 0.000847058
I0606 00:00:00.543156   904 solver.cpp:229] Iteration 166440, loss = 1.9242
I0606 00:00:00.543320   904 solver.cpp:245]     Train net output #0: loss = 1.82199 (* 1 = 1.82199 loss)
I0606 00:00:00.543331   904 sgd_solver.cpp:106] Iteration 166440, lr = 0.000837648
I0606 00:00:21.270808   904 solver.cpp:229] Iteration 166480, loss = 1.93345
I0606 00:00:21.270861   904 solver.cpp:245]     Train net output #0: loss = 2.12612 (* 1 = 2.12612 loss)
I0606 00:00:21.270874   904 sgd_solver.cpp:106] Iteration 166480, lr = 0.000828235
I0606 00:00:41.974408   904 solver.cpp:229] Iteration 166520, loss = 1.95466
I0606 00:00:41.974587   904 solver.cpp:245]     Train net output #0: loss = 2.0401 (* 1 = 2.0401 loss)
I0606 00:00:41.974612   904 sgd_solver.cpp:106] Iteration 166520, lr = 0.000818822
I0606 00:01:02.696203   904 solver.cpp:229] Iteration 166560, loss = 1.94607
I0606 00:01:02.696246   904 solver.cpp:245]     Train net output #0: loss = 1.90977 (* 1 = 1.90977 loss)
I0606 00:01:02.696254   904 sgd_solver.cpp:106] Iteration 166560, lr = 0.000809412
I0606 00:01:23.384951   904 solver.cpp:229] Iteration 166600, loss = 1.95359
I0606 00:01:23.385092   904 solver.cpp:245]     Train net output #0: loss = 2.07212 (* 1 = 2.07212 loss)
I0606 00:01:23.385103   904 sgd_solver.cpp:106] Iteration 166600, lr = 0.000799999
I0606 00:01:44.096140   904 solver.cpp:229] Iteration 166640, loss = 1.94656
I0606 00:01:44.096192   904 solver.cpp:245]     Train net output #0: loss = 1.97492 (* 1 = 1.97492 loss)
I0606 00:01:44.096201   904 sgd_solver.cpp:106] Iteration 166640, lr = 0.000790589
I0606 00:02:04.889163   904 solver.cpp:229] Iteration 166680, loss = 1.94025
I0606 00:02:04.889322   904 solver.cpp:245]     Train net output #0: loss = 2.08956 (* 1 = 2.08956 loss)
I0606 00:02:04.889335   904 sgd_solver.cpp:106] Iteration 166680, lr = 0.000781176
I0606 00:02:25.468766   904 solver.cpp:229] Iteration 166720, loss = 1.95492
I0606 00:02:25.468816   904 solver.cpp:245]     Train net output #0: loss = 2.06961 (* 1 = 2.06961 loss)
I0606 00:02:25.468825   904 sgd_solver.cpp:106] Iteration 166720, lr = 0.000771766
I0606 00:02:45.999127   904 solver.cpp:229] Iteration 166760, loss = 1.92223
I0606 00:02:45.999275   904 solver.cpp:245]     Train net output #0: loss = 1.96608 (* 1 = 1.96608 loss)
I0606 00:02:45.999287   904 sgd_solver.cpp:106] Iteration 166760, lr = 0.000762353
I0606 00:03:06.666004   904 solver.cpp:229] Iteration 166800, loss = 1.92571
I0606 00:03:06.666056   904 solver.cpp:245]     Train net output #0: loss = 2.04547 (* 1 = 2.04547 loss)
I0606 00:03:06.666067   904 sgd_solver.cpp:106] Iteration 166800, lr = 0.00075294
I0606 00:03:27.231446   904 solver.cpp:229] Iteration 166840, loss = 1.93602
I0606 00:03:27.231705   904 solver.cpp:245]     Train net output #0: loss = 2.01796 (* 1 = 2.01796 loss)
I0606 00:03:27.231730   904 sgd_solver.cpp:106] Iteration 166840, lr = 0.00074353
I0606 00:03:31.849241   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0606 00:03:47.766520   904 solver.cpp:229] Iteration 166880, loss = 1.9011
I0606 00:03:47.766569   904 solver.cpp:245]     Train net output #0: loss = 2.09166 (* 1 = 2.09166 loss)
I0606 00:03:47.766580   904 sgd_solver.cpp:106] Iteration 166880, lr = 0.000734117
I0606 00:04:08.312080   904 solver.cpp:229] Iteration 166920, loss = 1.92304
I0606 00:04:08.312299   904 solver.cpp:245]     Train net output #0: loss = 2.15885 (* 1 = 2.15885 loss)
I0606 00:04:08.312325   904 sgd_solver.cpp:106] Iteration 166920, lr = 0.000724707
I0606 00:04:28.843894   904 solver.cpp:229] Iteration 166960, loss = 1.90837
I0606 00:04:28.843938   904 solver.cpp:245]     Train net output #0: loss = 1.75522 (* 1 = 1.75522 loss)
I0606 00:04:28.843948   904 sgd_solver.cpp:106] Iteration 166960, lr = 0.000715294
I0606 00:04:48.835165   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_167000.caffemodel
I0606 00:04:49.096773   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_167000.solverstate
I0606 00:04:49.173976   904 solver.cpp:338] Iteration 167000, Testing net (#0)
I0606 00:04:49.174060   904 net.cpp:748] Ignoring source layer loss
I0606 00:05:15.000094   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0606 00:05:53.670001   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0606 00:06:03.386487   904 solver.cpp:406]     Test net output #0: accuracy = 0.540359
I0606 00:06:03.386539   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.771921
I0606 00:06:03.702333   904 solver.cpp:229] Iteration 167000, loss = 1.9335
I0606 00:06:03.702370   904 solver.cpp:245]     Train net output #0: loss = 2.30927 (* 1 = 2.30927 loss)
I0606 00:06:03.702379   904 sgd_solver.cpp:106] Iteration 167000, lr = 0.000705883
I0606 00:06:22.921841   904 solver.cpp:229] Iteration 167040, loss = 1.91807
I0606 00:06:22.921895   904 solver.cpp:245]     Train net output #0: loss = 2.17234 (* 1 = 2.17234 loss)
I0606 00:06:22.921905   904 sgd_solver.cpp:106] Iteration 167040, lr = 0.000696471
I0606 00:06:44.446764   904 solver.cpp:229] Iteration 167080, loss = 1.90304
I0606 00:06:44.446986   904 solver.cpp:245]     Train net output #0: loss = 1.80364 (* 1 = 1.80364 loss)
I0606 00:06:44.447011   904 sgd_solver.cpp:106] Iteration 167080, lr = 0.000687058
I0606 00:07:05.986268   904 solver.cpp:229] Iteration 167120, loss = 1.92145
I0606 00:07:05.986325   904 solver.cpp:245]     Train net output #0: loss = 1.76802 (* 1 = 1.76802 loss)
I0606 00:07:05.986333   904 sgd_solver.cpp:106] Iteration 167120, lr = 0.000677648
I0606 00:07:27.247714   904 solver.cpp:229] Iteration 167160, loss = 1.90875
I0606 00:07:27.247875   904 solver.cpp:245]     Train net output #0: loss = 1.71666 (* 1 = 1.71666 loss)
I0606 00:07:27.247886   904 sgd_solver.cpp:106] Iteration 167160, lr = 0.000668235
I0606 00:07:48.232378   904 solver.cpp:229] Iteration 167200, loss = 1.91369
I0606 00:07:48.232442   904 solver.cpp:245]     Train net output #0: loss = 1.91462 (* 1 = 1.91462 loss)
I0606 00:07:48.232452   904 sgd_solver.cpp:106] Iteration 167200, lr = 0.000658824
I0606 00:08:09.194183   904 solver.cpp:229] Iteration 167240, loss = 1.92245
I0606 00:08:09.194430   904 solver.cpp:245]     Train net output #0: loss = 1.93679 (* 1 = 1.93679 loss)
I0606 00:08:09.194456   904 sgd_solver.cpp:106] Iteration 167240, lr = 0.000649412
I0606 00:08:30.233986   904 solver.cpp:229] Iteration 167280, loss = 1.91133
I0606 00:08:30.234041   904 solver.cpp:245]     Train net output #0: loss = 1.6607 (* 1 = 1.6607 loss)
I0606 00:08:30.234052   904 sgd_solver.cpp:106] Iteration 167280, lr = 0.000639999
I0606 00:08:51.230892   904 solver.cpp:229] Iteration 167320, loss = 1.9455
I0606 00:08:51.231123   904 solver.cpp:245]     Train net output #0: loss = 2.00376 (* 1 = 2.00376 loss)
I0606 00:08:51.231153   904 sgd_solver.cpp:106] Iteration 167320, lr = 0.000630589
I0606 00:09:12.036603   904 solver.cpp:229] Iteration 167360, loss = 1.87872
I0606 00:09:12.036661   904 solver.cpp:245]     Train net output #0: loss = 2.21318 (* 1 = 2.21318 loss)
I0606 00:09:12.036671   904 sgd_solver.cpp:106] Iteration 167360, lr = 0.000621176
I0606 00:09:19.026445   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0606 00:09:32.742179   904 solver.cpp:229] Iteration 167400, loss = 1.93149
I0606 00:09:32.742367   904 solver.cpp:245]     Train net output #0: loss = 1.71286 (* 1 = 1.71286 loss)
I0606 00:09:32.742384   904 sgd_solver.cpp:106] Iteration 167400, lr = 0.000611765
I0606 00:09:53.435262   904 solver.cpp:229] Iteration 167440, loss = 1.93749
I0606 00:09:53.435312   904 solver.cpp:245]     Train net output #0: loss = 2.2987 (* 1 = 2.2987 loss)
I0606 00:09:53.435324   904 sgd_solver.cpp:106] Iteration 167440, lr = 0.000602353
I0606 00:10:14.141794   904 solver.cpp:229] Iteration 167480, loss = 1.88453
I0606 00:10:14.141964   904 solver.cpp:245]     Train net output #0: loss = 1.84869 (* 1 = 1.84869 loss)
I0606 00:10:14.141984   904 sgd_solver.cpp:106] Iteration 167480, lr = 0.000592942
I0606 00:10:34.812599   904 solver.cpp:229] Iteration 167520, loss = 1.88963
I0606 00:10:34.812635   904 solver.cpp:245]     Train net output #0: loss = 1.65609 (* 1 = 1.65609 loss)
I0606 00:10:34.812644   904 sgd_solver.cpp:106] Iteration 167520, lr = 0.000583529
I0606 00:10:55.296517   904 solver.cpp:229] Iteration 167560, loss = 1.93395
I0606 00:10:55.296694   904 solver.cpp:245]     Train net output #0: loss = 2.0755 (* 1 = 2.0755 loss)
I0606 00:10:55.296720   904 sgd_solver.cpp:106] Iteration 167560, lr = 0.000574117
I0606 00:11:15.792748   904 solver.cpp:229] Iteration 167600, loss = 1.92999
I0606 00:11:15.792803   904 solver.cpp:245]     Train net output #0: loss = 1.85709 (* 1 = 1.85709 loss)
I0606 00:11:15.792812   904 sgd_solver.cpp:106] Iteration 167600, lr = 0.000564706
I0606 00:11:36.311885   904 solver.cpp:229] Iteration 167640, loss = 1.90807
I0606 00:11:36.312042   904 solver.cpp:245]     Train net output #0: loss = 1.90422 (* 1 = 1.90422 loss)
I0606 00:11:36.312052   904 sgd_solver.cpp:106] Iteration 167640, lr = 0.000555294
I0606 00:11:56.815605   904 solver.cpp:229] Iteration 167680, loss = 1.93879
I0606 00:11:56.815670   904 solver.cpp:245]     Train net output #0: loss = 2.00707 (* 1 = 2.00707 loss)
I0606 00:11:56.815686   904 sgd_solver.cpp:106] Iteration 167680, lr = 0.000545883
I0606 00:12:17.320031   904 solver.cpp:229] Iteration 167720, loss = 1.93203
I0606 00:12:17.320262   904 solver.cpp:245]     Train net output #0: loss = 2.09003 (* 1 = 2.09003 loss)
I0606 00:12:17.320287   904 sgd_solver.cpp:106] Iteration 167720, lr = 0.00053647
I0606 00:12:37.740684   904 solver.cpp:229] Iteration 167760, loss = 1.93372
I0606 00:12:37.740725   904 solver.cpp:245]     Train net output #0: loss = 1.94526 (* 1 = 1.94526 loss)
I0606 00:12:37.740733   904 sgd_solver.cpp:106] Iteration 167760, lr = 0.000527058
I0606 00:12:58.166798   904 solver.cpp:229] Iteration 167800, loss = 1.88865
I0606 00:12:58.167035   904 solver.cpp:245]     Train net output #0: loss = 1.92136 (* 1 = 1.92136 loss)
I0606 00:12:58.167063   904 sgd_solver.cpp:106] Iteration 167800, lr = 0.000517647
I0606 00:13:18.420143   904 solver.cpp:229] Iteration 167840, loss = 1.93055
I0606 00:13:18.420198   904 solver.cpp:245]     Train net output #0: loss = 1.89519 (* 1 = 1.89519 loss)
I0606 00:13:18.420208   904 sgd_solver.cpp:106] Iteration 167840, lr = 0.000508234
I0606 00:13:38.692118   904 solver.cpp:229] Iteration 167880, loss = 1.92955
I0606 00:13:38.692350   904 solver.cpp:245]     Train net output #0: loss = 1.88524 (* 1 = 1.88524 loss)
I0606 00:13:38.692361   904 sgd_solver.cpp:106] Iteration 167880, lr = 0.000498824
I0606 00:13:42.235333   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0606 00:13:58.951336   904 solver.cpp:229] Iteration 167920, loss = 1.92264
I0606 00:13:58.951380   904 solver.cpp:245]     Train net output #0: loss = 2.18062 (* 1 = 2.18062 loss)
I0606 00:13:58.951390   904 sgd_solver.cpp:106] Iteration 167920, lr = 0.000489411
I0606 00:14:19.233297   904 solver.cpp:229] Iteration 167960, loss = 1.92085
I0606 00:14:19.233444   904 solver.cpp:245]     Train net output #0: loss = 1.91332 (* 1 = 1.91332 loss)
I0606 00:14:19.233460   904 sgd_solver.cpp:106] Iteration 167960, lr = 0.000480001
I0606 00:14:39.008301   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_168000.caffemodel
I0606 00:14:39.276808   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_168000.solverstate
I0606 00:14:39.357921   904 solver.cpp:338] Iteration 168000, Testing net (#0)
I0606 00:14:39.358006   904 net.cpp:748] Ignoring source layer loss
I0606 00:15:06.489230   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0606 00:15:42.898387   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0606 00:15:50.010418   904 solver.cpp:406]     Test net output #0: accuracy = 0.54178
I0606 00:15:50.010457   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.7735
I0606 00:15:50.325793   904 solver.cpp:229] Iteration 168000, loss = 1.9037
I0606 00:15:50.325845   904 solver.cpp:245]     Train net output #0: loss = 1.89493 (* 1 = 1.89493 loss)
I0606 00:15:50.325856   904 sgd_solver.cpp:106] Iteration 168000, lr = 0.000470588
I0606 00:16:09.581933   904 solver.cpp:229] Iteration 168040, loss = 1.87575
I0606 00:16:09.581986   904 solver.cpp:245]     Train net output #0: loss = 1.73456 (* 1 = 1.73456 loss)
I0606 00:16:09.581995   904 sgd_solver.cpp:106] Iteration 168040, lr = 0.000461175
I0606 00:16:30.957912   904 solver.cpp:229] Iteration 168080, loss = 1.89357
I0606 00:16:30.958144   904 solver.cpp:245]     Train net output #0: loss = 1.60234 (* 1 = 1.60234 loss)
I0606 00:16:30.958173   904 sgd_solver.cpp:106] Iteration 168080, lr = 0.000451765
I0606 00:16:52.315750   904 solver.cpp:229] Iteration 168120, loss = 1.93106
I0606 00:16:52.315799   904 solver.cpp:245]     Train net output #0: loss = 1.7987 (* 1 = 1.7987 loss)
I0606 00:16:52.315810   904 sgd_solver.cpp:106] Iteration 168120, lr = 0.000442352
I0606 00:17:13.293020   904 solver.cpp:229] Iteration 168160, loss = 1.92035
I0606 00:17:13.293218   904 solver.cpp:245]     Train net output #0: loss = 1.99133 (* 1 = 1.99133 loss)
I0606 00:17:13.293243   904 sgd_solver.cpp:106] Iteration 168160, lr = 0.000432942
I0606 00:17:34.198187   904 solver.cpp:229] Iteration 168200, loss = 1.87696
I0606 00:17:34.198228   904 solver.cpp:245]     Train net output #0: loss = 1.63018 (* 1 = 1.63018 loss)
I0606 00:17:34.198238   904 sgd_solver.cpp:106] Iteration 168200, lr = 0.000423529
I0606 00:17:55.056355   904 solver.cpp:229] Iteration 168240, loss = 1.92027
I0606 00:17:55.056584   904 solver.cpp:245]     Train net output #0: loss = 1.83326 (* 1 = 1.83326 loss)
I0606 00:17:55.056608   904 sgd_solver.cpp:106] Iteration 168240, lr = 0.000414119
I0606 00:18:15.916229   904 solver.cpp:229] Iteration 168280, loss = 1.91207
I0606 00:18:15.916272   904 solver.cpp:245]     Train net output #0: loss = 1.8813 (* 1 = 1.8813 loss)
I0606 00:18:15.916285   904 sgd_solver.cpp:106] Iteration 168280, lr = 0.000404706
I0606 00:18:36.748142   904 solver.cpp:229] Iteration 168320, loss = 1.91948
I0606 00:18:36.748286   904 solver.cpp:245]     Train net output #0: loss = 1.75029 (* 1 = 1.75029 loss)
I0606 00:18:36.748297   904 sgd_solver.cpp:106] Iteration 168320, lr = 0.000395293
I0606 00:18:57.456529   904 solver.cpp:229] Iteration 168360, loss = 1.89869
I0606 00:18:57.456601   904 solver.cpp:245]     Train net output #0: loss = 1.74259 (* 1 = 1.74259 loss)
I0606 00:18:57.456611   904 sgd_solver.cpp:106] Iteration 168360, lr = 0.000385883
I0606 00:19:18.012205   904 solver.cpp:229] Iteration 168400, loss = 1.9254
I0606 00:19:18.012516   904 solver.cpp:245]     Train net output #0: loss = 1.88376 (* 1 = 1.88376 loss)
I0606 00:19:18.012545   904 sgd_solver.cpp:106] Iteration 168400, lr = 0.00037647
I0606 00:19:21.608968   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0606 00:19:38.908279   904 solver.cpp:229] Iteration 168440, loss = 1.9064
I0606 00:19:38.908324   904 solver.cpp:245]     Train net output #0: loss = 2.01568 (* 1 = 2.01568 loss)
I0606 00:19:38.908334   904 sgd_solver.cpp:106] Iteration 168440, lr = 0.00036706
I0606 00:19:59.466934   904 solver.cpp:229] Iteration 168480, loss = 1.87662
I0606 00:19:59.467072   904 solver.cpp:245]     Train net output #0: loss = 1.65765 (* 1 = 1.65765 loss)
I0606 00:19:59.467084   904 sgd_solver.cpp:106] Iteration 168480, lr = 0.000357647
I0606 00:20:20.026593   904 solver.cpp:229] Iteration 168520, loss = 1.90147
I0606 00:20:20.026633   904 solver.cpp:245]     Train net output #0: loss = 1.94003 (* 1 = 1.94003 loss)
I0606 00:20:20.026643   904 sgd_solver.cpp:106] Iteration 168520, lr = 0.000348234
I0606 00:20:40.628123   904 solver.cpp:229] Iteration 168560, loss = 1.89411
I0606 00:20:40.628346   904 solver.cpp:245]     Train net output #0: loss = 1.66916 (* 1 = 1.66916 loss)
I0606 00:20:40.628371   904 sgd_solver.cpp:106] Iteration 168560, lr = 0.000338824
I0606 00:21:01.184610   904 solver.cpp:229] Iteration 168600, loss = 1.88018
I0606 00:21:01.184664   904 solver.cpp:245]     Train net output #0: loss = 1.86191 (* 1 = 1.86191 loss)
I0606 00:21:01.184676   904 sgd_solver.cpp:106] Iteration 168600, lr = 0.000329411
I0606 00:21:21.557366   904 solver.cpp:229] Iteration 168640, loss = 1.89424
I0606 00:21:21.557570   904 solver.cpp:245]     Train net output #0: loss = 1.83558 (* 1 = 1.83558 loss)
I0606 00:21:21.557593   904 sgd_solver.cpp:106] Iteration 168640, lr = 0.000320001
I0606 00:21:42.110414   904 solver.cpp:229] Iteration 168680, loss = 1.86689
I0606 00:21:42.110457   904 solver.cpp:245]     Train net output #0: loss = 2.13304 (* 1 = 2.13304 loss)
I0606 00:21:42.110468   904 sgd_solver.cpp:106] Iteration 168680, lr = 0.000310588
I0606 00:22:02.576138   904 solver.cpp:229] Iteration 168720, loss = 1.91466
I0606 00:22:02.576323   904 solver.cpp:245]     Train net output #0: loss = 1.75528 (* 1 = 1.75528 loss)
I0606 00:22:02.576350   904 sgd_solver.cpp:106] Iteration 168720, lr = 0.000301177
I0606 00:22:22.889855   904 solver.cpp:229] Iteration 168760, loss = 1.89145
I0606 00:22:22.889904   904 solver.cpp:245]     Train net output #0: loss = 1.91821 (* 1 = 1.91821 loss)
I0606 00:22:22.889916   904 sgd_solver.cpp:106] Iteration 168760, lr = 0.000291765
I0606 00:22:43.188294   904 solver.cpp:229] Iteration 168800, loss = 1.90062
I0606 00:22:43.188457   904 solver.cpp:245]     Train net output #0: loss = 2.01789 (* 1 = 2.01789 loss)
I0606 00:22:43.188467   904 sgd_solver.cpp:106] Iteration 168800, lr = 0.000282352
I0606 00:23:03.512465   904 solver.cpp:229] Iteration 168840, loss = 1.89004
I0606 00:23:03.512509   904 solver.cpp:245]     Train net output #0: loss = 1.69358 (* 1 = 1.69358 loss)
I0606 00:23:03.512521   904 sgd_solver.cpp:106] Iteration 168840, lr = 0.000272942
I0606 00:23:23.834273   904 solver.cpp:229] Iteration 168880, loss = 1.88651
I0606 00:23:23.834429   904 solver.cpp:245]     Train net output #0: loss = 1.82445 (* 1 = 1.82445 loss)
I0606 00:23:23.834441   904 sgd_solver.cpp:106] Iteration 168880, lr = 0.000263529
I0606 00:23:44.176266   904 solver.cpp:229] Iteration 168920, loss = 1.90347
I0606 00:23:44.176385   904 solver.cpp:245]     Train net output #0: loss = 1.7919 (* 1 = 1.7919 loss)
I0606 00:23:44.176414   904 sgd_solver.cpp:106] Iteration 168920, lr = 0.000254118
I0606 00:23:46.457909   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0606 00:24:04.502876   904 solver.cpp:229] Iteration 168960, loss = 1.8883
I0606 00:24:04.503116   904 solver.cpp:245]     Train net output #0: loss = 1.81744 (* 1 = 1.81744 loss)
I0606 00:24:04.503135   904 sgd_solver.cpp:106] Iteration 168960, lr = 0.000244706
I0606 00:24:24.328490   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_169000.caffemodel
I0606 00:24:24.612285   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_169000.solverstate
I0606 00:24:24.689312   904 solver.cpp:338] Iteration 169000, Testing net (#0)
I0606 00:24:24.689415   904 net.cpp:748] Ignoring source layer loss
I0606 00:24:55.498093   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0606 00:25:31.256199   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0606 00:25:36.386217   904 solver.cpp:406]     Test net output #0: accuracy = 0.545259
I0606 00:25:36.386260   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.776222
I0606 00:25:36.701377   904 solver.cpp:229] Iteration 169000, loss = 1.9253
I0606 00:25:36.701424   904 solver.cpp:245]     Train net output #0: loss = 1.83165 (* 1 = 1.83165 loss)
I0606 00:25:36.701433   904 sgd_solver.cpp:106] Iteration 169000, lr = 0.000235295
I0606 00:25:55.923475   904 solver.cpp:229] Iteration 169040, loss = 1.89459
I0606 00:25:55.923543   904 solver.cpp:245]     Train net output #0: loss = 1.98007 (* 1 = 1.98007 loss)
I0606 00:25:55.923554   904 sgd_solver.cpp:106] Iteration 169040, lr = 0.000225883
I0606 00:26:16.985493   904 solver.cpp:229] Iteration 169080, loss = 1.91173
I0606 00:26:16.985720   904 solver.cpp:245]     Train net output #0: loss = 1.8582 (* 1 = 1.8582 loss)
I0606 00:26:16.985752   904 sgd_solver.cpp:106] Iteration 169080, lr = 0.00021647
I0606 00:26:37.853242   904 solver.cpp:229] Iteration 169120, loss = 1.90448
I0606 00:26:37.853293   904 solver.cpp:245]     Train net output #0: loss = 1.86141 (* 1 = 1.86141 loss)
I0606 00:26:37.853305   904 sgd_solver.cpp:106] Iteration 169120, lr = 0.000207059
I0606 00:26:58.385989   904 solver.cpp:229] Iteration 169160, loss = 1.89893
I0606 00:26:58.386215   904 solver.cpp:245]     Train net output #0: loss = 1.91253 (* 1 = 1.91253 loss)
I0606 00:26:58.386245   904 sgd_solver.cpp:106] Iteration 169160, lr = 0.000197647
I0606 00:27:18.911902   904 solver.cpp:229] Iteration 169200, loss = 1.91157
I0606 00:27:18.911944   904 solver.cpp:245]     Train net output #0: loss = 1.94503 (* 1 = 1.94503 loss)
I0606 00:27:18.911953   904 sgd_solver.cpp:106] Iteration 169200, lr = 0.000188236
I0606 00:27:39.534163   904 solver.cpp:229] Iteration 169240, loss = 1.89706
I0606 00:27:39.534405   904 solver.cpp:245]     Train net output #0: loss = 1.94098 (* 1 = 1.94098 loss)
I0606 00:27:39.534440   904 sgd_solver.cpp:106] Iteration 169240, lr = 0.000178823
I0606 00:28:00.220190   904 solver.cpp:229] Iteration 169280, loss = 1.89964
I0606 00:28:00.220239   904 solver.cpp:245]     Train net output #0: loss = 1.78004 (* 1 = 1.78004 loss)
I0606 00:28:00.220248   904 sgd_solver.cpp:106] Iteration 169280, lr = 0.000169411
I0606 00:28:20.908012   904 solver.cpp:229] Iteration 169320, loss = 1.9054
I0606 00:28:20.908197   904 solver.cpp:245]     Train net output #0: loss = 1.78722 (* 1 = 1.78722 loss)
I0606 00:28:20.908222   904 sgd_solver.cpp:106] Iteration 169320, lr = 0.00016
I0606 00:28:41.592195   904 solver.cpp:229] Iteration 169360, loss = 1.89238
I0606 00:28:41.592244   904 solver.cpp:245]     Train net output #0: loss = 1.83014 (* 1 = 1.83014 loss)
I0606 00:28:41.592254   904 sgd_solver.cpp:106] Iteration 169360, lr = 0.000150588
I0606 00:29:02.247400   904 solver.cpp:229] Iteration 169400, loss = 1.88376
I0606 00:29:02.247586   904 solver.cpp:245]     Train net output #0: loss = 1.88989 (* 1 = 1.88989 loss)
I0606 00:29:02.247611   904 sgd_solver.cpp:106] Iteration 169400, lr = 0.000141177
I0606 00:29:22.917103   904 solver.cpp:229] Iteration 169440, loss = 1.89797
I0606 00:29:22.917150   904 solver.cpp:245]     Train net output #0: loss = 2.00225 (* 1 = 2.00225 loss)
I0606 00:29:22.917162   904 sgd_solver.cpp:106] Iteration 169440, lr = 0.000131764
I0606 00:29:30.711964   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0606 00:29:43.624634   904 solver.cpp:229] Iteration 169480, loss = 1.87653
I0606 00:29:43.624897   904 solver.cpp:245]     Train net output #0: loss = 1.76696 (* 1 = 1.76696 loss)
I0606 00:29:43.624909   904 sgd_solver.cpp:106] Iteration 169480, lr = 0.000122354
I0606 00:30:04.292281   904 solver.cpp:229] Iteration 169520, loss = 1.91106
I0606 00:30:04.292331   904 solver.cpp:245]     Train net output #0: loss = 1.95767 (* 1 = 1.95767 loss)
I0606 00:30:04.292340   904 sgd_solver.cpp:106] Iteration 169520, lr = 0.000112941
I0606 00:30:24.965565   904 solver.cpp:229] Iteration 169560, loss = 1.88032
I0606 00:30:24.965735   904 solver.cpp:245]     Train net output #0: loss = 1.66506 (* 1 = 1.66506 loss)
I0606 00:30:24.965761   904 sgd_solver.cpp:106] Iteration 169560, lr = 0.000103528
I0606 00:30:45.661480   904 solver.cpp:229] Iteration 169600, loss = 1.87289
I0606 00:30:45.661521   904 solver.cpp:245]     Train net output #0: loss = 2.10545 (* 1 = 2.10545 loss)
I0606 00:30:45.661530   904 sgd_solver.cpp:106] Iteration 169600, lr = 9.41181e-05
I0606 00:31:06.311105   904 solver.cpp:229] Iteration 169640, loss = 1.87429
I0606 00:31:06.311259   904 solver.cpp:245]     Train net output #0: loss = 1.72976 (* 1 = 1.72976 loss)
I0606 00:31:06.311272   904 sgd_solver.cpp:106] Iteration 169640, lr = 8.47054e-05
I0606 00:31:26.937855   904 solver.cpp:229] Iteration 169680, loss = 1.87611
I0606 00:31:26.937906   904 solver.cpp:245]     Train net output #0: loss = 1.89513 (* 1 = 1.89513 loss)
I0606 00:31:26.937913   904 sgd_solver.cpp:106] Iteration 169680, lr = 7.5295e-05
I0606 00:31:47.471084   904 solver.cpp:229] Iteration 169720, loss = 1.86151
I0606 00:31:47.471312   904 solver.cpp:245]     Train net output #0: loss = 2.03459 (* 1 = 2.03459 loss)
I0606 00:31:47.471338   904 sgd_solver.cpp:106] Iteration 169720, lr = 6.58822e-05
I0606 00:32:08.257184   904 solver.cpp:229] Iteration 169760, loss = 1.89951
I0606 00:32:08.257242   904 solver.cpp:245]     Train net output #0: loss = 1.7446 (* 1 = 1.7446 loss)
I0606 00:32:08.257256   904 sgd_solver.cpp:106] Iteration 169760, lr = 5.64694e-05
I0606 00:32:28.832183   904 solver.cpp:229] Iteration 169800, loss = 1.88825
I0606 00:32:28.832336   904 solver.cpp:245]     Train net output #0: loss = 1.89004 (* 1 = 1.89004 loss)
I0606 00:32:28.832348   904 sgd_solver.cpp:106] Iteration 169800, lr = 4.70591e-05
I0606 00:32:49.511847   904 solver.cpp:229] Iteration 169840, loss = 1.90782
I0606 00:32:49.511903   904 solver.cpp:245]     Train net output #0: loss = 1.88221 (* 1 = 1.88221 loss)
I0606 00:32:49.511912   904 sgd_solver.cpp:106] Iteration 169840, lr = 3.76463e-05
I0606 00:33:10.044080   904 solver.cpp:229] Iteration 169880, loss = 1.85782
I0606 00:33:10.044298   904 solver.cpp:245]     Train net output #0: loss = 1.85288 (* 1 = 1.85288 loss)
I0606 00:33:10.044324   904 sgd_solver.cpp:106] Iteration 169880, lr = 2.82359e-05
I0606 00:33:30.562376   904 solver.cpp:229] Iteration 169920, loss = 1.8913
I0606 00:33:30.562420   904 solver.cpp:245]     Train net output #0: loss = 1.64018 (* 1 = 1.64018 loss)
I0606 00:33:30.562440   904 sgd_solver.cpp:106] Iteration 169920, lr = 1.88231e-05
I0606 00:33:51.090131   904 solver.cpp:229] Iteration 169960, loss = 1.88646
I0606 00:33:51.090314   904 solver.cpp:245]     Train net output #0: loss = 1.72765 (* 1 = 1.72765 loss)
I0606 00:33:51.090327   904 sgd_solver.cpp:106] Iteration 169960, lr = 9.41277e-06
I0606 00:34:00.840976   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0606 00:34:11.104009   904 solver.cpp:456] Snapshotting to binary proto file snapshots/squeezenet128__iter_170000.caffemodel
I0606 00:34:11.354769   904 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/squeezenet128__iter_170000.solverstate
I0606 00:34:11.515251   904 solver.cpp:318] Iteration 170000, loss = 1.83804
I0606 00:34:11.515296   904 solver.cpp:338] Iteration 170000, Testing net (#0)
I0606 00:34:11.515355   904 net.cpp:748] Ignoring source layer loss
I0606 00:34:44.516003   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0606 00:35:19.635150   904 blocking_queue.cpp:50] Data layer prefetch queue empty
I0606 00:35:21.090291   904 solver.cpp:406]     Test net output #0: accuracy = 0.546579
I0606 00:35:21.090344   904 solver.cpp:406]     Test net output #1: accuracy_top5 = 0.777561
I0606 00:35:21.090350   904 solver.cpp:323] Optimization Done.
I0606 00:35:21.090354   904 caffe.cpp:216] Optimization Done.
