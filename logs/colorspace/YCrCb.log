I0123 17:12:52.280418 29630 upgrade_proto.cpp:990] Attempting to upgrade input file specified using deprecated 'solver_type' field (enum)': ./caffenet128_lsuv_ycrcb.prototxt
I0123 17:12:52.280567 29630 upgrade_proto.cpp:997] Successfully upgraded file specified using deprecated 'solver_type' field (enum) to 'type' field (string).
W0123 17:12:52.280570 29630 upgrade_proto.cpp:999] Note that future Caffe releases will only support 'type' field (string) for a solver's type.
I0123 17:12:52.280624 29630 caffe.cpp:184] Using GPUs 0
I0123 17:12:52.405680 29630 solver.cpp:48] Initializing solver from parameters: 
test_iter: 1000
test_interval: 1000
base_lr: 0.01
display: 20
max_iter: 320000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 100000
snapshot: 10000
snapshot_prefix: "snapshots/caffenet128_lsuv_ycrcb"
solver_mode: GPU
device_id: 0
net_param {
  name: "CaffeNet"
  layer {
    name: "data"
    type: "Data"
    top: "data"
    top: "label"
    include {
      phase: TRAIN
    }
    transform_param {
      mirror: true
      crop_size: 128
      force_color: true
      resize_param {
        prob: 1
        resize_mode: FIT_SMALL_SIZE
        height: 144
        width: 144
        pad_mode: MIRRORED
        interp_mode: LINEAR
        center_object: false
        max_angle: 0
      }
      noise_param {
        prob: 1
        convert_to_ycrcb: true
      }
    }
    data_param {
      source: "/home/share/storage/datasets/imagenet/lmdb/ilsvrc12_train_lmdb"
      batch_size: 256
      backend: LMDB
    }
  }
  layer {
    name: "data"
    type: "Data"
    top: "data"
    top: "label"
    include {
      phase: TEST
    }
    transform_param {
      mirror: false
      crop_size: 128
      force_color: true
      resize_param {
        prob: 1
        resize_mode: FIT_SMALL_SIZE
        height: 144
        width: 144
        pad_mode: MIRRORED
        interp_mode: LINEAR
        center_object: false
        max_angle: 0
      }
      noise_param {
        prob: 1
        convert_to_ycrcb: true
      }
    }
    data_param {
      source: "/home/share/storage/datasets/imagenet/lmdb/ilsvrc12_val_lmdb"
      batch_size: 50
      backend: LMDB
    }
  }
  layer {
    name: "data_lab_BN"
    type: "BatchNorm"
    bottom: "data"
    top: "data_lab_BN"
    param {
      lr_mult: 0
      decay_mult: 0
    }
    param {
      lr_mult: 0
      decay_mult: 0
    }
    param {
      lr_mult: 0
      decay_mult: 0
    }
    include {
      phase: TRAIN
    }
    batch_norm_param {
      use_global_stats: false
      moving_average_fraction: 0.95
    }
  }
  layer {
    name: "data_lab_BN"
    type: "BatchNorm"
    bottom: "data"
    top: "data_lab_BN"
    param {
      lr_mult: 0
      decay_mult: 0
    }
    param {
      lr_mult: 0
      decay_mult: 0
    }
    param {
      lr_mult: 0
      decay_mult: 0
    }
    include {
      phase: TEST
    }
    batch_norm_param {
      use_global_stats: true
      moving_average_fraction: 0.95
    }
  }
  layer {
    name: "conv1"
    type: "Convolution"
    bottom: "data_lab_BN"
    top: "conv1"
    param {
      lr_mult: 1
      decay_mult: 1
    }
    param {
      lr_mult: 2
      decay_mult: 0
    }
    convolution_param {
      num_output: 96
      kernel_size: 11
      stride: 4
      weight_filler {
        type: "gaussian"
        std: 0.01
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layer {
    name: "relu1"
    type: "ReLU"
    bottom: "conv1"
    top: "relu1"
  }
  layer {
    name: "pool1"
    type: "Pooling"
    bottom: "relu1"
    top: "pool1"
    pooling_param {
      pool: MAX
      kernel_size: 3
      stride: 2
    }
  }
  layer {
    name: "conv2"
    type: "Convolution"
    bottom: "pool1"
    top: "conv2"
    param {
      lr_mult: 1
      decay_mult: 1
    }
    param {
      lr_mult: 2
      decay_mult: 0
    }
    convolution_param {
      num_output: 256
      pad: 2
      kernel_size: 5
      group: 2
      weight_filler {
        type: "gaussian"
        std: 0.01
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layer {
    name: "relu2"
    type: "ReLU"
    bottom: "conv2"
    top: "relu2"
  }
  layer {
    name: "pool2"
    type: "Pooling"
    bottom: "relu2"
    top: "pool2"
    pooling_param {
      pool: MAX
      kernel_size: 3
      stride: 2
    }
  }
  layer {
    name: "conv3"
    type: "Convolution"
    bottom: "pool2"
    top: "conv3"
    param {
      lr_mult: 1
      decay_mult: 1
    }
    param {
      lr_mult: 2
      decay_mult: 0
    }
    convolution_param {
      num_output: 384
      pad: 1
      kernel_size: 3
      weight_filler {
        type: "gaussian"
        std: 0.01
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layer {
    name: "relu3"
    type: "ReLU"
    bottom: "conv3"
    top: "relu3"
  }
  layer {
    name: "conv4"
    type: "Convolution"
    bottom: "relu3"
    top: "conv4"
    param {
      lr_mult: 1
      decay_mult: 1
    }
    param {
      lr_mult: 2
      decay_mult: 0
    }
    convolution_param {
      num_output: 384
      pad: 1
      kernel_size: 3
      group: 2
      weight_filler {
        type: "gaussian"
        std: 0.01
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layer {
    name: "relu4"
    type: "ReLU"
    bottom: "conv4"
    top: "relu4"
  }
  layer {
    name: "conv5"
    type: "Convolution"
    bottom: "relu4"
    top: "conv5"
    param {
      lr_mult: 1
      decay_mult: 1
    }
    param {
      lr_mult: 2
      decay_mult: 0
    }
    convolution_param {
      num_output: 256
      pad: 1
      kernel_size: 3
      group: 2
      weight_filler {
        type: "gaussian"
        std: 0.01
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layer {
    name: "relu5"
    type: "ReLU"
    bottom: "conv5"
    top: "relu5"
  }
  layer {
    name: "pool5"
    type: "Pooling"
    bottom: "relu5"
    top: "pool5"
    pooling_param {
      pool: MAX
      kernel_size: 3
      stride: 2
    }
  }
  layer {
    name: "fc6"
    type: "InnerProduct"
    bottom: "pool5"
    top: "fc6"
    param {
      lr_mult: 1
      decay_mult: 1
    }
    param {
      lr_mult: 2
      decay_mult: 0
    }
    inner_product_param {
      num_output: 2048
      weight_filler {
        type: "gaussian"
        std: 0.005
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layer {
    name: "relu6"
    type: "ReLU"
    bottom: "fc6"
    top: "relu6"
  }
  layer {
    name: "drop6"
    type: "Dropout"
    bottom: "relu6"
    top: "drop6"
    dropout_param {
      dropout_ratio: 0.5
    }
  }
  layer {
    name: "fc7"
    type: "InnerProduct"
    bottom: "drop6"
    top: "fc7"
    param {
      lr_mult: 1
      decay_mult: 1
    }
    param {
      lr_mult: 2
      decay_mult: 0
    }
    inner_product_param {
      num_output: 2048
      weight_filler {
        type: "gaussian"
        std: 0.005
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layer {
    name: "relu7"
    type: "ReLU"
    bottom: "fc7"
    top: "relu7"
  }
  layer {
    name: "drop7"
    type: "Dropout"
    bottom: "relu7"
    top: "drop7"
    dropout_param {
      dropout_ratio: 0.5
    }
  }
  layer {
    name: "fc8"
    type: "InnerProduct"
    bottom: "drop7"
    top: "fc8"
    param {
      lr_mult: 1
      decay_mult: 1
    }
    param {
      lr_mult: 2
      decay_mult: 0
    }
    inner_product_param {
      num_output: 1000
      weight_filler {
        type: "gaussian"
        std: 0.01
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layer {
    name: "accuracy"
    type: "Accuracy"
    bottom: "fc8"
    bottom: "label"
    top: "accuracy"
    include {
      phase: TEST
    }
  }
  layer {
    name: "loss"
    type: "SoftmaxWithLoss"
    bottom: "fc8"
    bottom: "label"
    top: "loss"
  }
}
test_initialization: false
iter_size: 1
type: "SGD"
I0123 17:12:52.405876 29630 solver.cpp:86] Creating training net specified in net_param.
I0123 17:12:52.405943 29630 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0123 17:12:52.405949 29630 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data_lab_BN
I0123 17:12:52.405959 29630 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0123 17:12:52.406070 29630 net.cpp:49] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 128
    force_color: true
    resize_param {
      prob: 1
      resize_mode: FIT_SMALL_SIZE
      height: 144
      width: 144
      pad_mode: MIRRORED
      interp_mode: LINEAR
      center_object: false
      max_angle: 0
    }
    noise_param {
      prob: 1
      convert_to_ycrcb: true
    }
  }
  data_param {
    source: "/home/share/storage/datasets/imagenet/lmdb/ilsvrc12_train_lmdb"
    batch_size: 256
    backend: LMDB
  }
}
layer {
  name: "data_lab_BN"
  type: "BatchNorm"
  bottom: "data"
  top: "data_lab_BN"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data_lab_BN"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "relu1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "relu1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "relu2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "relu2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "relu3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "relu3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "relu4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "relu4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "relu5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "relu5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "relu6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "relu6"
  top: "drop6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "drop6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "relu7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "relu7"
  top: "drop7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "drop7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0123 17:12:52.406147 29630 layer_factory.hpp:76] Creating layer data
I0123 17:12:52.406643 29630 net.cpp:106] Creating Layer data
I0123 17:12:52.406653 29630 net.cpp:411] data -> data
I0123 17:12:52.406678 29630 net.cpp:411] data -> label
I0123 17:12:52.407923 29634 db_lmdb.cpp:38] Opened lmdb /home/share/storage/datasets/imagenet/lmdb/ilsvrc12_train_lmdb
I0123 17:12:52.417537 29630 data_layer.cpp:41] output data size: 256,3,128,128
I0123 17:12:52.493885 29630 net.cpp:150] Setting up data
I0123 17:12:52.493922 29630 net.cpp:157] Top shape: 256 3 128 128 (12582912)
I0123 17:12:52.493927 29630 net.cpp:157] Top shape: 256 (256)
I0123 17:12:52.493930 29630 net.cpp:165] Memory required for data: 50332672
I0123 17:12:52.493947 29630 layer_factory.hpp:76] Creating layer data_lab_BN
I0123 17:12:52.493963 29630 net.cpp:106] Creating Layer data_lab_BN
I0123 17:12:52.493968 29630 net.cpp:454] data_lab_BN <- data
I0123 17:12:52.493983 29630 net.cpp:411] data_lab_BN -> data_lab_BN
I0123 17:12:52.494555 29630 net.cpp:150] Setting up data_lab_BN
I0123 17:12:52.494565 29630 net.cpp:157] Top shape: 256 3 128 128 (12582912)
I0123 17:12:52.494575 29630 net.cpp:165] Memory required for data: 100664320
I0123 17:12:52.494606 29630 layer_factory.hpp:76] Creating layer conv1
I0123 17:12:52.494616 29630 net.cpp:106] Creating Layer conv1
I0123 17:12:52.494619 29630 net.cpp:454] conv1 <- data_lab_BN
I0123 17:12:52.494624 29630 net.cpp:411] conv1 -> conv1
I0123 17:12:52.626510 29630 net.cpp:150] Setting up conv1
I0123 17:12:52.626539 29630 net.cpp:157] Top shape: 256 96 30 30 (22118400)
I0123 17:12:52.626543 29630 net.cpp:165] Memory required for data: 189137920
I0123 17:12:52.626554 29630 layer_factory.hpp:76] Creating layer relu1
I0123 17:12:52.626574 29630 net.cpp:106] Creating Layer relu1
I0123 17:12:52.626576 29630 net.cpp:454] relu1 <- conv1
I0123 17:12:52.626581 29630 net.cpp:411] relu1 -> relu1
I0123 17:12:52.626749 29630 net.cpp:150] Setting up relu1
I0123 17:12:52.626756 29630 net.cpp:157] Top shape: 256 96 30 30 (22118400)
I0123 17:12:52.626768 29630 net.cpp:165] Memory required for data: 277611520
I0123 17:12:52.626771 29630 layer_factory.hpp:76] Creating layer pool1
I0123 17:12:52.626777 29630 net.cpp:106] Creating Layer pool1
I0123 17:12:52.626788 29630 net.cpp:454] pool1 <- relu1
I0123 17:12:52.626791 29630 net.cpp:411] pool1 -> pool1
I0123 17:12:52.627106 29630 net.cpp:150] Setting up pool1
I0123 17:12:52.627115 29630 net.cpp:157] Top shape: 256 96 15 15 (5529600)
I0123 17:12:52.627126 29630 net.cpp:165] Memory required for data: 299729920
I0123 17:12:52.627128 29630 layer_factory.hpp:76] Creating layer conv2
I0123 17:12:52.627136 29630 net.cpp:106] Creating Layer conv2
I0123 17:12:52.627140 29630 net.cpp:454] conv2 <- pool1
I0123 17:12:52.627152 29630 net.cpp:411] conv2 -> conv2
I0123 17:12:52.635601 29630 net.cpp:150] Setting up conv2
I0123 17:12:52.635639 29630 net.cpp:157] Top shape: 256 256 15 15 (14745600)
I0123 17:12:52.635643 29630 net.cpp:165] Memory required for data: 358712320
I0123 17:12:52.635658 29630 layer_factory.hpp:76] Creating layer relu2
I0123 17:12:52.635664 29630 net.cpp:106] Creating Layer relu2
I0123 17:12:52.635668 29630 net.cpp:454] relu2 <- conv2
I0123 17:12:52.635671 29630 net.cpp:411] relu2 -> relu2
I0123 17:12:52.635957 29630 net.cpp:150] Setting up relu2
I0123 17:12:52.635974 29630 net.cpp:157] Top shape: 256 256 15 15 (14745600)
I0123 17:12:52.635977 29630 net.cpp:165] Memory required for data: 417694720
I0123 17:12:52.635979 29630 layer_factory.hpp:76] Creating layer pool2
I0123 17:12:52.635998 29630 net.cpp:106] Creating Layer pool2
I0123 17:12:52.636000 29630 net.cpp:454] pool2 <- relu2
I0123 17:12:52.636004 29630 net.cpp:411] pool2 -> pool2
I0123 17:12:52.636286 29630 net.cpp:150] Setting up pool2
I0123 17:12:52.636293 29630 net.cpp:157] Top shape: 256 256 7 7 (3211264)
I0123 17:12:52.636296 29630 net.cpp:165] Memory required for data: 430539776
I0123 17:12:52.636298 29630 layer_factory.hpp:76] Creating layer conv3
I0123 17:12:52.636306 29630 net.cpp:106] Creating Layer conv3
I0123 17:12:52.636307 29630 net.cpp:454] conv3 <- pool2
I0123 17:12:52.636312 29630 net.cpp:411] conv3 -> conv3
I0123 17:12:52.657963 29630 net.cpp:150] Setting up conv3
I0123 17:12:52.657989 29630 net.cpp:157] Top shape: 256 384 7 7 (4816896)
I0123 17:12:52.657992 29630 net.cpp:165] Memory required for data: 449807360
I0123 17:12:52.658002 29630 layer_factory.hpp:76] Creating layer relu3
I0123 17:12:52.658020 29630 net.cpp:106] Creating Layer relu3
I0123 17:12:52.658022 29630 net.cpp:454] relu3 <- conv3
I0123 17:12:52.658028 29630 net.cpp:411] relu3 -> relu3
I0123 17:12:52.658320 29630 net.cpp:150] Setting up relu3
I0123 17:12:52.658339 29630 net.cpp:157] Top shape: 256 384 7 7 (4816896)
I0123 17:12:52.658340 29630 net.cpp:165] Memory required for data: 469074944
I0123 17:12:52.658342 29630 layer_factory.hpp:76] Creating layer conv4
I0123 17:12:52.658351 29630 net.cpp:106] Creating Layer conv4
I0123 17:12:52.658362 29630 net.cpp:454] conv4 <- relu3
I0123 17:12:52.658367 29630 net.cpp:411] conv4 -> conv4
I0123 17:12:52.675168 29630 net.cpp:150] Setting up conv4
I0123 17:12:52.675192 29630 net.cpp:157] Top shape: 256 384 7 7 (4816896)
I0123 17:12:52.675195 29630 net.cpp:165] Memory required for data: 488342528
I0123 17:12:52.675201 29630 layer_factory.hpp:76] Creating layer relu4
I0123 17:12:52.675209 29630 net.cpp:106] Creating Layer relu4
I0123 17:12:52.675222 29630 net.cpp:454] relu4 <- conv4
I0123 17:12:52.675226 29630 net.cpp:411] relu4 -> relu4
I0123 17:12:52.675490 29630 net.cpp:150] Setting up relu4
I0123 17:12:52.675498 29630 net.cpp:157] Top shape: 256 384 7 7 (4816896)
I0123 17:12:52.675509 29630 net.cpp:165] Memory required for data: 507610112
I0123 17:12:52.675511 29630 layer_factory.hpp:76] Creating layer conv5
I0123 17:12:52.675519 29630 net.cpp:106] Creating Layer conv5
I0123 17:12:52.675521 29630 net.cpp:454] conv5 <- relu4
I0123 17:12:52.675536 29630 net.cpp:411] conv5 -> conv5
I0123 17:12:52.687357 29630 net.cpp:150] Setting up conv5
I0123 17:12:52.687381 29630 net.cpp:157] Top shape: 256 256 7 7 (3211264)
I0123 17:12:52.687383 29630 net.cpp:165] Memory required for data: 520455168
I0123 17:12:52.687391 29630 layer_factory.hpp:76] Creating layer relu5
I0123 17:12:52.687397 29630 net.cpp:106] Creating Layer relu5
I0123 17:12:52.687410 29630 net.cpp:454] relu5 <- conv5
I0123 17:12:52.687414 29630 net.cpp:411] relu5 -> relu5
I0123 17:12:52.687588 29630 net.cpp:150] Setting up relu5
I0123 17:12:52.687594 29630 net.cpp:157] Top shape: 256 256 7 7 (3211264)
I0123 17:12:52.687607 29630 net.cpp:165] Memory required for data: 533300224
I0123 17:12:52.687608 29630 layer_factory.hpp:76] Creating layer pool5
I0123 17:12:52.687614 29630 net.cpp:106] Creating Layer pool5
I0123 17:12:52.687616 29630 net.cpp:454] pool5 <- relu5
I0123 17:12:52.687620 29630 net.cpp:411] pool5 -> pool5
I0123 17:12:52.687927 29630 net.cpp:150] Setting up pool5
I0123 17:12:52.687935 29630 net.cpp:157] Top shape: 256 256 3 3 (589824)
I0123 17:12:52.687973 29630 net.cpp:165] Memory required for data: 535659520
I0123 17:12:52.687975 29630 layer_factory.hpp:76] Creating layer fc6
I0123 17:12:52.687986 29630 net.cpp:106] Creating Layer fc6
I0123 17:12:52.687989 29630 net.cpp:454] fc6 <- pool5
I0123 17:12:52.687994 29630 net.cpp:411] fc6 -> fc6
I0123 17:12:52.798390 29630 net.cpp:150] Setting up fc6
I0123 17:12:52.798418 29630 net.cpp:157] Top shape: 256 2048 (524288)
I0123 17:12:52.798421 29630 net.cpp:165] Memory required for data: 537756672
I0123 17:12:52.798429 29630 layer_factory.hpp:76] Creating layer relu6
I0123 17:12:52.798447 29630 net.cpp:106] Creating Layer relu6
I0123 17:12:52.798451 29630 net.cpp:454] relu6 <- fc6
I0123 17:12:52.798457 29630 net.cpp:411] relu6 -> relu6
I0123 17:12:52.798698 29630 net.cpp:150] Setting up relu6
I0123 17:12:52.798705 29630 net.cpp:157] Top shape: 256 2048 (524288)
I0123 17:12:52.798717 29630 net.cpp:165] Memory required for data: 539853824
I0123 17:12:52.798719 29630 layer_factory.hpp:76] Creating layer drop6
I0123 17:12:52.798728 29630 net.cpp:106] Creating Layer drop6
I0123 17:12:52.798732 29630 net.cpp:454] drop6 <- relu6
I0123 17:12:52.798748 29630 net.cpp:411] drop6 -> drop6
I0123 17:12:52.798784 29630 net.cpp:150] Setting up drop6
I0123 17:12:52.798796 29630 net.cpp:157] Top shape: 256 2048 (524288)
I0123 17:12:52.798799 29630 net.cpp:165] Memory required for data: 541950976
I0123 17:12:52.798800 29630 layer_factory.hpp:76] Creating layer fc7
I0123 17:12:52.798816 29630 net.cpp:106] Creating Layer fc7
I0123 17:12:52.798818 29630 net.cpp:454] fc7 <- drop6
I0123 17:12:52.798822 29630 net.cpp:411] fc7 -> fc7
I0123 17:12:52.896687 29630 net.cpp:150] Setting up fc7
I0123 17:12:52.896715 29630 net.cpp:157] Top shape: 256 2048 (524288)
I0123 17:12:52.896718 29630 net.cpp:165] Memory required for data: 544048128
I0123 17:12:52.896728 29630 layer_factory.hpp:76] Creating layer relu7
I0123 17:12:52.896746 29630 net.cpp:106] Creating Layer relu7
I0123 17:12:52.896749 29630 net.cpp:454] relu7 <- fc7
I0123 17:12:52.896756 29630 net.cpp:411] relu7 -> relu7
I0123 17:12:52.897217 29630 net.cpp:150] Setting up relu7
I0123 17:12:52.897225 29630 net.cpp:157] Top shape: 256 2048 (524288)
I0123 17:12:52.897238 29630 net.cpp:165] Memory required for data: 546145280
I0123 17:12:52.897239 29630 layer_factory.hpp:76] Creating layer drop7
I0123 17:12:52.897246 29630 net.cpp:106] Creating Layer drop7
I0123 17:12:52.897249 29630 net.cpp:454] drop7 <- relu7
I0123 17:12:52.897264 29630 net.cpp:411] drop7 -> drop7
I0123 17:12:52.897295 29630 net.cpp:150] Setting up drop7
I0123 17:12:52.897308 29630 net.cpp:157] Top shape: 256 2048 (524288)
I0123 17:12:52.897310 29630 net.cpp:165] Memory required for data: 548242432
I0123 17:12:52.897311 29630 layer_factory.hpp:76] Creating layer fc8
I0123 17:12:52.897327 29630 net.cpp:106] Creating Layer fc8
I0123 17:12:52.897330 29630 net.cpp:454] fc8 <- drop7
I0123 17:12:52.897333 29630 net.cpp:411] fc8 -> fc8
I0123 17:12:52.945158 29630 net.cpp:150] Setting up fc8
I0123 17:12:52.945185 29630 net.cpp:157] Top shape: 256 1000 (256000)
I0123 17:12:52.945188 29630 net.cpp:165] Memory required for data: 549266432
I0123 17:12:52.945197 29630 layer_factory.hpp:76] Creating layer loss
I0123 17:12:52.945219 29630 net.cpp:106] Creating Layer loss
I0123 17:12:52.945224 29630 net.cpp:454] loss <- fc8
I0123 17:12:52.945230 29630 net.cpp:454] loss <- label
I0123 17:12:52.945235 29630 net.cpp:411] loss -> loss
I0123 17:12:52.945250 29630 layer_factory.hpp:76] Creating layer loss
I0123 17:12:52.946204 29630 net.cpp:150] Setting up loss
I0123 17:12:52.946213 29630 net.cpp:157] Top shape: (1)
I0123 17:12:52.946225 29630 net.cpp:160]     with loss weight 1
I0123 17:12:52.946254 29630 net.cpp:165] Memory required for data: 549266436
I0123 17:12:52.946257 29630 net.cpp:226] loss needs backward computation.
I0123 17:12:52.946260 29630 net.cpp:226] fc8 needs backward computation.
I0123 17:12:52.946264 29630 net.cpp:226] drop7 needs backward computation.
I0123 17:12:52.946265 29630 net.cpp:226] relu7 needs backward computation.
I0123 17:12:52.946290 29630 net.cpp:226] fc7 needs backward computation.
I0123 17:12:52.946292 29630 net.cpp:226] drop6 needs backward computation.
I0123 17:12:52.946295 29630 net.cpp:226] relu6 needs backward computation.
I0123 17:12:52.946296 29630 net.cpp:226] fc6 needs backward computation.
I0123 17:12:52.946298 29630 net.cpp:226] pool5 needs backward computation.
I0123 17:12:52.946301 29630 net.cpp:226] relu5 needs backward computation.
I0123 17:12:52.946303 29630 net.cpp:226] conv5 needs backward computation.
I0123 17:12:52.946305 29630 net.cpp:226] relu4 needs backward computation.
I0123 17:12:52.946307 29630 net.cpp:226] conv4 needs backward computation.
I0123 17:12:52.946310 29630 net.cpp:226] relu3 needs backward computation.
I0123 17:12:52.946311 29630 net.cpp:226] conv3 needs backward computation.
I0123 17:12:52.946313 29630 net.cpp:226] pool2 needs backward computation.
I0123 17:12:52.946316 29630 net.cpp:226] relu2 needs backward computation.
I0123 17:12:52.946318 29630 net.cpp:226] conv2 needs backward computation.
I0123 17:12:52.946321 29630 net.cpp:226] pool1 needs backward computation.
I0123 17:12:52.946322 29630 net.cpp:226] relu1 needs backward computation.
I0123 17:12:52.946324 29630 net.cpp:226] conv1 needs backward computation.
I0123 17:12:52.946326 29630 net.cpp:228] data_lab_BN does not need backward computation.
I0123 17:12:52.946329 29630 net.cpp:228] data does not need backward computation.
I0123 17:12:52.946331 29630 net.cpp:270] This network produces output loss
I0123 17:12:52.946346 29630 net.cpp:283] Network initialization done.
I0123 17:12:52.946446 29630 solver.cpp:181] Creating test net (#0) specified by net_param
I0123 17:12:52.946494 29630 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0123 17:12:52.946498 29630 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data_lab_BN
I0123 17:12:52.946707 29630 net.cpp:49] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 128
    force_color: true
    resize_param {
      prob: 1
      resize_mode: FIT_SMALL_SIZE
      height: 144
      width: 144
      pad_mode: MIRRORED
      interp_mode: LINEAR
      center_object: false
      max_angle: 0
    }
    noise_param {
      prob: 1
      convert_to_ycrcb: true
    }
  }
  data_param {
    source: "/home/share/storage/datasets/imagenet/lmdb/ilsvrc12_val_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "data_lab_BN"
  type: "BatchNorm"
  bottom: "data"
  top: "data_lab_BN"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data_lab_BN"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "relu1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "relu1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "relu2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "relu2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "relu3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "relu3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "relu4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "relu4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "relu5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "relu5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "relu6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "relu6"
  top: "drop6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "drop6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "relu7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "relu7"
  top: "drop7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "drop7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0123 17:12:52.946815 29630 layer_factory.hpp:76] Creating layer data
I0123 17:12:52.947057 29630 net.cpp:106] Creating Layer data
I0123 17:12:52.947062 29630 net.cpp:411] data -> data
I0123 17:12:52.947069 29630 net.cpp:411] data -> label
I0123 17:12:52.948196 29643 db_lmdb.cpp:38] Opened lmdb /home/share/storage/datasets/imagenet/lmdb/ilsvrc12_val_lmdb
I0123 17:12:52.949384 29630 data_layer.cpp:41] output data size: 50,3,128,128
I0123 17:12:52.972772 29630 net.cpp:150] Setting up data
I0123 17:12:52.972805 29630 net.cpp:157] Top shape: 50 3 128 128 (2457600)
I0123 17:12:52.972810 29630 net.cpp:157] Top shape: 50 (50)
I0123 17:12:52.972811 29630 net.cpp:165] Memory required for data: 9830600
I0123 17:12:52.972816 29630 layer_factory.hpp:76] Creating layer label_data_1_split
I0123 17:12:52.972831 29630 net.cpp:106] Creating Layer label_data_1_split
I0123 17:12:52.972857 29630 net.cpp:454] label_data_1_split <- label
I0123 17:12:52.972863 29630 net.cpp:411] label_data_1_split -> label_data_1_split_0
I0123 17:12:52.972872 29630 net.cpp:411] label_data_1_split -> label_data_1_split_1
I0123 17:12:52.973271 29630 net.cpp:150] Setting up label_data_1_split
I0123 17:12:52.973280 29630 net.cpp:157] Top shape: 50 (50)
I0123 17:12:52.973284 29630 net.cpp:157] Top shape: 50 (50)
I0123 17:12:52.973285 29630 net.cpp:165] Memory required for data: 9831000
I0123 17:12:52.973328 29630 layer_factory.hpp:76] Creating layer data_lab_BN
I0123 17:12:52.973352 29630 net.cpp:106] Creating Layer data_lab_BN
I0123 17:12:52.973356 29630 net.cpp:454] data_lab_BN <- data
I0123 17:12:52.973361 29630 net.cpp:411] data_lab_BN -> data_lab_BN
I0123 17:12:52.973633 29630 net.cpp:150] Setting up data_lab_BN
I0123 17:12:52.973639 29630 net.cpp:157] Top shape: 50 3 128 128 (2457600)
I0123 17:12:52.973661 29630 net.cpp:165] Memory required for data: 19661400
I0123 17:12:52.973701 29630 layer_factory.hpp:76] Creating layer conv1
I0123 17:12:52.973727 29630 net.cpp:106] Creating Layer conv1
I0123 17:12:52.973731 29630 net.cpp:454] conv1 <- data_lab_BN
I0123 17:12:52.973754 29630 net.cpp:411] conv1 -> conv1
I0123 17:12:52.976919 29630 net.cpp:150] Setting up conv1
I0123 17:12:52.976929 29630 net.cpp:157] Top shape: 50 96 30 30 (4320000)
I0123 17:12:52.976933 29630 net.cpp:165] Memory required for data: 36941400
I0123 17:12:52.976938 29630 layer_factory.hpp:76] Creating layer relu1
I0123 17:12:52.976944 29630 net.cpp:106] Creating Layer relu1
I0123 17:12:52.976946 29630 net.cpp:454] relu1 <- conv1
I0123 17:12:52.977020 29630 net.cpp:411] relu1 -> relu1
I0123 17:12:52.977341 29630 net.cpp:150] Setting up relu1
I0123 17:12:52.977349 29630 net.cpp:157] Top shape: 50 96 30 30 (4320000)
I0123 17:12:52.977360 29630 net.cpp:165] Memory required for data: 54221400
I0123 17:12:52.977363 29630 layer_factory.hpp:76] Creating layer pool1
I0123 17:12:52.977368 29630 net.cpp:106] Creating Layer pool1
I0123 17:12:52.977370 29630 net.cpp:454] pool1 <- relu1
I0123 17:12:52.977373 29630 net.cpp:411] pool1 -> pool1
I0123 17:12:52.977644 29630 net.cpp:150] Setting up pool1
I0123 17:12:52.977651 29630 net.cpp:157] Top shape: 50 96 15 15 (1080000)
I0123 17:12:52.977653 29630 net.cpp:165] Memory required for data: 58541400
I0123 17:12:52.977656 29630 layer_factory.hpp:76] Creating layer conv2
I0123 17:12:52.977663 29630 net.cpp:106] Creating Layer conv2
I0123 17:12:52.977664 29630 net.cpp:454] conv2 <- pool1
I0123 17:12:52.977669 29630 net.cpp:411] conv2 -> conv2
I0123 17:12:52.986816 29630 net.cpp:150] Setting up conv2
I0123 17:12:52.986841 29630 net.cpp:157] Top shape: 50 256 15 15 (2880000)
I0123 17:12:52.986843 29630 net.cpp:165] Memory required for data: 70061400
I0123 17:12:52.986850 29630 layer_factory.hpp:76] Creating layer relu2
I0123 17:12:52.986958 29630 net.cpp:106] Creating Layer relu2
I0123 17:12:52.986964 29630 net.cpp:454] relu2 <- conv2
I0123 17:12:52.986974 29630 net.cpp:411] relu2 -> relu2
I0123 17:12:52.987213 29630 net.cpp:150] Setting up relu2
I0123 17:12:52.987221 29630 net.cpp:157] Top shape: 50 256 15 15 (2880000)
I0123 17:12:52.987232 29630 net.cpp:165] Memory required for data: 81581400
I0123 17:12:52.987234 29630 layer_factory.hpp:76] Creating layer pool2
I0123 17:12:52.987279 29630 net.cpp:106] Creating Layer pool2
I0123 17:12:52.987284 29630 net.cpp:454] pool2 <- relu2
I0123 17:12:52.987289 29630 net.cpp:411] pool2 -> pool2
I0123 17:12:52.987627 29630 net.cpp:150] Setting up pool2
I0123 17:12:52.987634 29630 net.cpp:157] Top shape: 50 256 7 7 (627200)
I0123 17:12:52.987645 29630 net.cpp:165] Memory required for data: 84090200
I0123 17:12:52.987648 29630 layer_factory.hpp:76] Creating layer conv3
I0123 17:12:52.987715 29630 net.cpp:106] Creating Layer conv3
I0123 17:12:52.987720 29630 net.cpp:454] conv3 <- pool2
I0123 17:12:52.987751 29630 net.cpp:411] conv3 -> conv3
I0123 17:12:53.010341 29630 net.cpp:150] Setting up conv3
I0123 17:12:53.010368 29630 net.cpp:157] Top shape: 50 384 7 7 (940800)
I0123 17:12:53.010838 29630 net.cpp:165] Memory required for data: 87853400
I0123 17:12:53.010851 29630 layer_factory.hpp:76] Creating layer relu3
I0123 17:12:53.010864 29630 net.cpp:106] Creating Layer relu3
I0123 17:12:53.010867 29630 net.cpp:454] relu3 <- conv3
I0123 17:12:53.010872 29630 net.cpp:411] relu3 -> relu3
I0123 17:12:53.011138 29630 net.cpp:150] Setting up relu3
I0123 17:12:53.011157 29630 net.cpp:157] Top shape: 50 384 7 7 (940800)
I0123 17:12:53.011159 29630 net.cpp:165] Memory required for data: 91616600
I0123 17:12:53.011162 29630 layer_factory.hpp:76] Creating layer conv4
I0123 17:12:53.011170 29630 net.cpp:106] Creating Layer conv4
I0123 17:12:53.011243 29630 net.cpp:454] conv4 <- relu3
I0123 17:12:53.011251 29630 net.cpp:411] conv4 -> conv4
I0123 17:12:53.029263 29630 net.cpp:150] Setting up conv4
I0123 17:12:53.029289 29630 net.cpp:157] Top shape: 50 384 7 7 (940800)
I0123 17:12:53.029292 29630 net.cpp:165] Memory required for data: 95379800
I0123 17:12:53.029299 29630 layer_factory.hpp:76] Creating layer relu4
I0123 17:12:53.029412 29630 net.cpp:106] Creating Layer relu4
I0123 17:12:53.029418 29630 net.cpp:454] relu4 <- conv4
I0123 17:12:53.029424 29630 net.cpp:411] relu4 -> relu4
I0123 17:12:53.029674 29630 net.cpp:150] Setting up relu4
I0123 17:12:53.029692 29630 net.cpp:157] Top shape: 50 384 7 7 (940800)
I0123 17:12:53.029695 29630 net.cpp:165] Memory required for data: 99143000
I0123 17:12:53.029697 29630 layer_factory.hpp:76] Creating layer conv5
I0123 17:12:53.029769 29630 net.cpp:106] Creating Layer conv5
I0123 17:12:53.029774 29630 net.cpp:454] conv5 <- relu4
I0123 17:12:53.029808 29630 net.cpp:411] conv5 -> conv5
I0123 17:12:53.042237 29630 net.cpp:150] Setting up conv5
I0123 17:12:53.042263 29630 net.cpp:157] Top shape: 50 256 7 7 (627200)
I0123 17:12:53.042265 29630 net.cpp:165] Memory required for data: 101651800
I0123 17:12:53.042273 29630 layer_factory.hpp:76] Creating layer relu5
I0123 17:12:53.042387 29630 net.cpp:106] Creating Layer relu5
I0123 17:12:53.042394 29630 net.cpp:454] relu5 <- conv5
I0123 17:12:53.042400 29630 net.cpp:411] relu5 -> relu5
I0123 17:12:53.042645 29630 net.cpp:150] Setting up relu5
I0123 17:12:53.042664 29630 net.cpp:157] Top shape: 50 256 7 7 (627200)
I0123 17:12:53.042665 29630 net.cpp:165] Memory required for data: 104160600
I0123 17:12:53.042668 29630 layer_factory.hpp:76] Creating layer pool5
I0123 17:12:53.042729 29630 net.cpp:106] Creating Layer pool5
I0123 17:12:53.042732 29630 net.cpp:454] pool5 <- relu5
I0123 17:12:53.042735 29630 net.cpp:411] pool5 -> pool5
I0123 17:12:53.043037 29630 net.cpp:150] Setting up pool5
I0123 17:12:53.043046 29630 net.cpp:157] Top shape: 50 256 3 3 (115200)
I0123 17:12:53.043073 29630 net.cpp:165] Memory required for data: 104621400
I0123 17:12:53.043076 29630 layer_factory.hpp:76] Creating layer fc6
I0123 17:12:53.043117 29630 net.cpp:106] Creating Layer fc6
I0123 17:12:53.043120 29630 net.cpp:454] fc6 <- pool5
I0123 17:12:53.043150 29630 net.cpp:411] fc6 -> fc6
I0123 17:12:53.157471 29630 net.cpp:150] Setting up fc6
I0123 17:12:53.157491 29630 net.cpp:157] Top shape: 50 2048 (102400)
I0123 17:12:53.157495 29630 net.cpp:165] Memory required for data: 105031000
I0123 17:12:53.157502 29630 layer_factory.hpp:76] Creating layer relu6
I0123 17:12:53.157624 29630 net.cpp:106] Creating Layer relu6
I0123 17:12:53.157626 29630 net.cpp:454] relu6 <- fc6
I0123 17:12:53.157634 29630 net.cpp:411] relu6 -> relu6
I0123 17:12:53.158116 29630 net.cpp:150] Setting up relu6
I0123 17:12:53.158125 29630 net.cpp:157] Top shape: 50 2048 (102400)
I0123 17:12:53.158138 29630 net.cpp:165] Memory required for data: 105440600
I0123 17:12:53.158140 29630 layer_factory.hpp:76] Creating layer drop6
I0123 17:12:53.158145 29630 net.cpp:106] Creating Layer drop6
I0123 17:12:53.158149 29630 net.cpp:454] drop6 <- relu6
I0123 17:12:53.158231 29630 net.cpp:411] drop6 -> drop6
I0123 17:12:53.158319 29630 net.cpp:150] Setting up drop6
I0123 17:12:53.158325 29630 net.cpp:157] Top shape: 50 2048 (102400)
I0123 17:12:53.158337 29630 net.cpp:165] Memory required for data: 105850200
I0123 17:12:53.158390 29630 layer_factory.hpp:76] Creating layer fc7
I0123 17:12:53.158399 29630 net.cpp:106] Creating Layer fc7
I0123 17:12:53.158401 29630 net.cpp:454] fc7 <- drop6
I0123 17:12:53.158406 29630 net.cpp:411] fc7 -> fc7
I0123 17:12:53.258438 29630 net.cpp:150] Setting up fc7
I0123 17:12:53.258466 29630 net.cpp:157] Top shape: 50 2048 (102400)
I0123 17:12:53.258468 29630 net.cpp:165] Memory required for data: 106259800
I0123 17:12:53.258479 29630 layer_factory.hpp:76] Creating layer relu7
I0123 17:12:53.258497 29630 net.cpp:106] Creating Layer relu7
I0123 17:12:53.258501 29630 net.cpp:454] relu7 <- fc7
I0123 17:12:53.258507 29630 net.cpp:411] relu7 -> relu7
I0123 17:12:53.258761 29630 net.cpp:150] Setting up relu7
I0123 17:12:53.258769 29630 net.cpp:157] Top shape: 50 2048 (102400)
I0123 17:12:53.258780 29630 net.cpp:165] Memory required for data: 106669400
I0123 17:12:53.258782 29630 layer_factory.hpp:76] Creating layer drop7
I0123 17:12:53.258790 29630 net.cpp:106] Creating Layer drop7
I0123 17:12:53.258792 29630 net.cpp:454] drop7 <- relu7
I0123 17:12:53.258806 29630 net.cpp:411] drop7 -> drop7
I0123 17:12:53.258838 29630 net.cpp:150] Setting up drop7
I0123 17:12:53.258842 29630 net.cpp:157] Top shape: 50 2048 (102400)
I0123 17:12:53.258844 29630 net.cpp:165] Memory required for data: 107079000
I0123 17:12:53.258846 29630 layer_factory.hpp:76] Creating layer fc8
I0123 17:12:53.258853 29630 net.cpp:106] Creating Layer fc8
I0123 17:12:53.258855 29630 net.cpp:454] fc8 <- drop7
I0123 17:12:53.258858 29630 net.cpp:411] fc8 -> fc8
I0123 17:12:53.306778 29630 net.cpp:150] Setting up fc8
I0123 17:12:53.306820 29630 net.cpp:157] Top shape: 50 1000 (50000)
I0123 17:12:53.306823 29630 net.cpp:165] Memory required for data: 107279000
I0123 17:12:53.306831 29630 layer_factory.hpp:76] Creating layer fc8_fc8_0_split
I0123 17:12:53.306841 29630 net.cpp:106] Creating Layer fc8_fc8_0_split
I0123 17:12:53.306845 29630 net.cpp:454] fc8_fc8_0_split <- fc8
I0123 17:12:53.306850 29630 net.cpp:411] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0123 17:12:53.306859 29630 net.cpp:411] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0123 17:12:53.306913 29630 net.cpp:150] Setting up fc8_fc8_0_split
I0123 17:12:53.306917 29630 net.cpp:157] Top shape: 50 1000 (50000)
I0123 17:12:53.306920 29630 net.cpp:157] Top shape: 50 1000 (50000)
I0123 17:12:53.306921 29630 net.cpp:165] Memory required for data: 107679000
I0123 17:12:53.306932 29630 layer_factory.hpp:76] Creating layer accuracy
I0123 17:12:53.306941 29630 net.cpp:106] Creating Layer accuracy
I0123 17:12:53.306944 29630 net.cpp:454] accuracy <- fc8_fc8_0_split_0
I0123 17:12:53.306947 29630 net.cpp:454] accuracy <- label_data_1_split_0
I0123 17:12:53.306951 29630 net.cpp:411] accuracy -> accuracy
I0123 17:12:53.306958 29630 net.cpp:150] Setting up accuracy
I0123 17:12:53.306962 29630 net.cpp:157] Top shape: (1)
I0123 17:12:53.306963 29630 net.cpp:165] Memory required for data: 107679004
I0123 17:12:53.306965 29630 layer_factory.hpp:76] Creating layer loss
I0123 17:12:53.306970 29630 net.cpp:106] Creating Layer loss
I0123 17:12:53.306972 29630 net.cpp:454] loss <- fc8_fc8_0_split_1
I0123 17:12:53.306975 29630 net.cpp:454] loss <- label_data_1_split_1
I0123 17:12:53.306978 29630 net.cpp:411] loss -> loss
I0123 17:12:53.306984 29630 layer_factory.hpp:76] Creating layer loss
I0123 17:12:53.307519 29630 net.cpp:150] Setting up loss
I0123 17:12:53.307528 29630 net.cpp:157] Top shape: (1)
I0123 17:12:53.307539 29630 net.cpp:160]     with loss weight 1
I0123 17:12:53.307548 29630 net.cpp:165] Memory required for data: 107679008
I0123 17:12:53.307550 29630 net.cpp:226] loss needs backward computation.
I0123 17:12:53.307554 29630 net.cpp:228] accuracy does not need backward computation.
I0123 17:12:53.307556 29630 net.cpp:226] fc8_fc8_0_split needs backward computation.
I0123 17:12:53.307557 29630 net.cpp:226] fc8 needs backward computation.
I0123 17:12:53.307559 29630 net.cpp:226] drop7 needs backward computation.
I0123 17:12:53.307561 29630 net.cpp:226] relu7 needs backward computation.
I0123 17:12:53.307584 29630 net.cpp:226] fc7 needs backward computation.
I0123 17:12:53.307586 29630 net.cpp:226] drop6 needs backward computation.
I0123 17:12:53.307590 29630 net.cpp:226] relu6 needs backward computation.
I0123 17:12:53.307591 29630 net.cpp:226] fc6 needs backward computation.
I0123 17:12:53.307593 29630 net.cpp:226] pool5 needs backward computation.
I0123 17:12:53.307595 29630 net.cpp:226] relu5 needs backward computation.
I0123 17:12:53.307597 29630 net.cpp:226] conv5 needs backward computation.
I0123 17:12:53.307600 29630 net.cpp:226] relu4 needs backward computation.
I0123 17:12:53.307603 29630 net.cpp:226] conv4 needs backward computation.
I0123 17:12:53.307605 29630 net.cpp:226] relu3 needs backward computation.
I0123 17:12:53.307607 29630 net.cpp:226] conv3 needs backward computation.
I0123 17:12:53.307610 29630 net.cpp:226] pool2 needs backward computation.
I0123 17:12:53.307611 29630 net.cpp:226] relu2 needs backward computation.
I0123 17:12:53.307613 29630 net.cpp:226] conv2 needs backward computation.
I0123 17:12:53.307615 29630 net.cpp:226] pool1 needs backward computation.
I0123 17:12:53.307617 29630 net.cpp:226] relu1 needs backward computation.
I0123 17:12:53.307620 29630 net.cpp:226] conv1 needs backward computation.
I0123 17:12:53.307622 29630 net.cpp:228] data_lab_BN does not need backward computation.
I0123 17:12:53.307624 29630 net.cpp:228] label_data_1_split does not need backward computation.
I0123 17:12:53.307627 29630 net.cpp:228] data does not need backward computation.
I0123 17:12:53.307629 29630 net.cpp:270] This network produces output accuracy
I0123 17:12:53.307631 29630 net.cpp:270] This network produces output loss
I0123 17:12:53.307647 29630 net.cpp:283] Network initialization done.
I0123 17:12:53.307731 29630 solver.cpp:60] Solver scaffolding done.
I0123 17:12:53.308243 29630 caffe.cpp:128] Finetuning from ./caffenet128_lsuv_ycrcb.prototxt.caffemodel
I0123 17:12:53.449506 29630 caffe.cpp:212] Starting Optimization
I0123 17:12:53.449543 29630 solver.cpp:288] Solving CaffeNet
I0123 17:12:53.449556 29630 solver.cpp:289] Learning Rate Policy: step
I0123 17:12:53.510673 29630 solver.cpp:237] Iteration 0, loss = 7.55769
I0123 17:12:53.510709 29630 solver.cpp:253]     Train net output #0: loss = 7.55769 (* 1 = 7.55769 loss)
I0123 17:12:53.510722 29630 sgd_solver.cpp:106] Iteration 0, lr = 0.01
I0123 17:12:53.701459 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 17:13:00.208144 29630 solver.cpp:237] Iteration 20, loss = 6.92868
I0123 17:13:00.208181 29630 solver.cpp:253]     Train net output #0: loss = 6.92868 (* 1 = 6.92868 loss)
I0123 17:13:00.208187 29630 sgd_solver.cpp:106] Iteration 20, lr = 0.01
I0123 17:13:07.402434 29630 solver.cpp:237] Iteration 40, loss = 6.90797
I0123 17:13:07.402473 29630 solver.cpp:253]     Train net output #0: loss = 6.90797 (* 1 = 6.90797 loss)
I0123 17:13:07.402479 29630 sgd_solver.cpp:106] Iteration 40, lr = 0.01
I0123 17:13:14.625737 29630 solver.cpp:237] Iteration 60, loss = 6.91732
I0123 17:13:14.625776 29630 solver.cpp:253]     Train net output #0: loss = 6.91732 (* 1 = 6.91732 loss)
I0123 17:13:14.625782 29630 sgd_solver.cpp:106] Iteration 60, lr = 0.01
I0123 17:13:21.855878 29630 solver.cpp:237] Iteration 80, loss = 6.91284
I0123 17:13:21.855917 29630 solver.cpp:253]     Train net output #0: loss = 6.91284 (* 1 = 6.91284 loss)
I0123 17:13:21.855923 29630 sgd_solver.cpp:106] Iteration 80, lr = 0.01
I0123 17:13:29.049863 29630 solver.cpp:237] Iteration 100, loss = 6.90771
I0123 17:13:29.049991 29630 solver.cpp:253]     Train net output #0: loss = 6.90771 (* 1 = 6.90771 loss)
I0123 17:13:29.049999 29630 sgd_solver.cpp:106] Iteration 100, lr = 0.01
I0123 17:13:36.207447 29630 solver.cpp:237] Iteration 120, loss = 6.90741
I0123 17:13:36.207484 29630 solver.cpp:253]     Train net output #0: loss = 6.90741 (* 1 = 6.90741 loss)
I0123 17:13:36.207492 29630 sgd_solver.cpp:106] Iteration 120, lr = 0.01
I0123 17:13:43.322901 29630 solver.cpp:237] Iteration 140, loss = 6.91192
I0123 17:13:43.322939 29630 solver.cpp:253]     Train net output #0: loss = 6.91192 (* 1 = 6.91192 loss)
I0123 17:13:43.322945 29630 sgd_solver.cpp:106] Iteration 140, lr = 0.01
I0123 17:13:50.499238 29630 solver.cpp:237] Iteration 160, loss = 6.90855
I0123 17:13:50.499276 29630 solver.cpp:253]     Train net output #0: loss = 6.90855 (* 1 = 6.90855 loss)
I0123 17:13:50.499284 29630 sgd_solver.cpp:106] Iteration 160, lr = 0.01
I0123 17:13:57.631881 29630 solver.cpp:237] Iteration 180, loss = 6.9086
I0123 17:13:57.631921 29630 solver.cpp:253]     Train net output #0: loss = 6.9086 (* 1 = 6.9086 loss)
I0123 17:13:57.631927 29630 sgd_solver.cpp:106] Iteration 180, lr = 0.01
I0123 17:14:04.811880 29630 solver.cpp:237] Iteration 200, loss = 6.89288
I0123 17:14:04.812059 29630 solver.cpp:253]     Train net output #0: loss = 6.89288 (* 1 = 6.89288 loss)
I0123 17:14:04.812068 29630 sgd_solver.cpp:106] Iteration 200, lr = 0.01
I0123 17:14:12.002281 29630 solver.cpp:237] Iteration 220, loss = 6.90231
I0123 17:14:12.002321 29630 solver.cpp:253]     Train net output #0: loss = 6.90231 (* 1 = 6.90231 loss)
I0123 17:14:12.002326 29630 sgd_solver.cpp:106] Iteration 220, lr = 0.01
I0123 17:14:19.180842 29630 solver.cpp:237] Iteration 240, loss = 6.89448
I0123 17:14:19.180879 29630 solver.cpp:253]     Train net output #0: loss = 6.89448 (* 1 = 6.89448 loss)
I0123 17:14:19.180886 29630 sgd_solver.cpp:106] Iteration 240, lr = 0.01
I0123 17:14:26.368620 29630 solver.cpp:237] Iteration 260, loss = 6.89332
I0123 17:14:26.368659 29630 solver.cpp:253]     Train net output #0: loss = 6.89332 (* 1 = 6.89332 loss)
I0123 17:14:26.368665 29630 sgd_solver.cpp:106] Iteration 260, lr = 0.01
I0123 17:14:33.499155 29630 solver.cpp:237] Iteration 280, loss = 6.89378
I0123 17:14:33.499192 29630 solver.cpp:253]     Train net output #0: loss = 6.89378 (* 1 = 6.89378 loss)
I0123 17:14:33.499198 29630 sgd_solver.cpp:106] Iteration 280, lr = 0.01
I0123 17:14:40.678572 29630 solver.cpp:237] Iteration 300, loss = 6.92236
I0123 17:14:40.678694 29630 solver.cpp:253]     Train net output #0: loss = 6.92236 (* 1 = 6.92236 loss)
I0123 17:14:40.678702 29630 sgd_solver.cpp:106] Iteration 300, lr = 0.01
I0123 17:14:47.821722 29630 solver.cpp:237] Iteration 320, loss = 6.90299
I0123 17:14:47.821760 29630 solver.cpp:253]     Train net output #0: loss = 6.90299 (* 1 = 6.90299 loss)
I0123 17:14:47.821768 29630 sgd_solver.cpp:106] Iteration 320, lr = 0.01
I0123 17:14:54.996083 29630 solver.cpp:237] Iteration 340, loss = 6.8764
I0123 17:14:54.996122 29630 solver.cpp:253]     Train net output #0: loss = 6.8764 (* 1 = 6.8764 loss)
I0123 17:14:54.996129 29630 sgd_solver.cpp:106] Iteration 340, lr = 0.01
I0123 17:15:02.166210 29630 solver.cpp:237] Iteration 360, loss = 6.88452
I0123 17:15:02.166249 29630 solver.cpp:253]     Train net output #0: loss = 6.88452 (* 1 = 6.88452 loss)
I0123 17:15:02.166256 29630 sgd_solver.cpp:106] Iteration 360, lr = 0.01
I0123 17:15:09.343870 29630 solver.cpp:237] Iteration 380, loss = 6.87059
I0123 17:15:09.343909 29630 solver.cpp:253]     Train net output #0: loss = 6.87059 (* 1 = 6.87059 loss)
I0123 17:15:09.343915 29630 sgd_solver.cpp:106] Iteration 380, lr = 0.01
I0123 17:15:16.523882 29630 solver.cpp:237] Iteration 400, loss = 6.86085
I0123 17:15:16.524013 29630 solver.cpp:253]     Train net output #0: loss = 6.86085 (* 1 = 6.86085 loss)
I0123 17:15:16.524029 29630 sgd_solver.cpp:106] Iteration 400, lr = 0.01
I0123 17:15:23.622669 29630 solver.cpp:237] Iteration 420, loss = 6.807
I0123 17:15:23.622707 29630 solver.cpp:253]     Train net output #0: loss = 6.807 (* 1 = 6.807 loss)
I0123 17:15:23.622714 29630 sgd_solver.cpp:106] Iteration 420, lr = 0.01
I0123 17:15:30.798887 29630 solver.cpp:237] Iteration 440, loss = 6.79879
I0123 17:15:30.798925 29630 solver.cpp:253]     Train net output #0: loss = 6.79879 (* 1 = 6.79879 loss)
I0123 17:15:30.798931 29630 sgd_solver.cpp:106] Iteration 440, lr = 0.01
I0123 17:15:37.977361 29630 solver.cpp:237] Iteration 460, loss = 6.83746
I0123 17:15:37.977399 29630 solver.cpp:253]     Train net output #0: loss = 6.83746 (* 1 = 6.83746 loss)
I0123 17:15:37.977406 29630 sgd_solver.cpp:106] Iteration 460, lr = 0.01
I0123 17:15:45.160698 29630 solver.cpp:237] Iteration 480, loss = 6.80226
I0123 17:15:45.160735 29630 solver.cpp:253]     Train net output #0: loss = 6.80226 (* 1 = 6.80226 loss)
I0123 17:15:45.160742 29630 sgd_solver.cpp:106] Iteration 480, lr = 0.01
I0123 17:15:52.323029 29630 solver.cpp:237] Iteration 500, loss = 6.79452
I0123 17:15:52.323171 29630 solver.cpp:253]     Train net output #0: loss = 6.79452 (* 1 = 6.79452 loss)
I0123 17:15:52.323179 29630 sgd_solver.cpp:106] Iteration 500, lr = 0.01
I0123 17:15:59.487512 29630 solver.cpp:237] Iteration 520, loss = 6.79424
I0123 17:15:59.487551 29630 solver.cpp:253]     Train net output #0: loss = 6.79424 (* 1 = 6.79424 loss)
I0123 17:15:59.487558 29630 sgd_solver.cpp:106] Iteration 520, lr = 0.01
I0123 17:16:06.653694 29630 solver.cpp:237] Iteration 540, loss = 6.76227
I0123 17:16:06.653735 29630 solver.cpp:253]     Train net output #0: loss = 6.76227 (* 1 = 6.76227 loss)
I0123 17:16:06.653754 29630 sgd_solver.cpp:106] Iteration 540, lr = 0.01
I0123 17:16:13.834142 29630 solver.cpp:237] Iteration 560, loss = 6.81484
I0123 17:16:13.834180 29630 solver.cpp:253]     Train net output #0: loss = 6.81484 (* 1 = 6.81484 loss)
I0123 17:16:13.834188 29630 sgd_solver.cpp:106] Iteration 560, lr = 0.01
I0123 17:16:21.019672 29630 solver.cpp:237] Iteration 580, loss = 6.6917
I0123 17:16:21.019711 29630 solver.cpp:253]     Train net output #0: loss = 6.6917 (* 1 = 6.6917 loss)
I0123 17:16:21.019717 29630 sgd_solver.cpp:106] Iteration 580, lr = 0.01
I0123 17:16:28.168437 29630 solver.cpp:237] Iteration 600, loss = 6.74042
I0123 17:16:28.168557 29630 solver.cpp:253]     Train net output #0: loss = 6.74042 (* 1 = 6.74042 loss)
I0123 17:16:28.168565 29630 sgd_solver.cpp:106] Iteration 600, lr = 0.01
I0123 17:16:35.362931 29630 solver.cpp:237] Iteration 620, loss = 6.75494
I0123 17:16:35.362969 29630 solver.cpp:253]     Train net output #0: loss = 6.75494 (* 1 = 6.75494 loss)
I0123 17:16:35.362977 29630 sgd_solver.cpp:106] Iteration 620, lr = 0.01
I0123 17:16:42.762115 29630 solver.cpp:237] Iteration 640, loss = 6.82916
I0123 17:16:42.762153 29630 solver.cpp:253]     Train net output #0: loss = 6.82916 (* 1 = 6.82916 loss)
I0123 17:16:42.762161 29630 sgd_solver.cpp:106] Iteration 640, lr = 0.01
I0123 17:16:50.725762 29630 solver.cpp:237] Iteration 660, loss = 6.71816
I0123 17:16:50.725798 29630 solver.cpp:253]     Train net output #0: loss = 6.71816 (* 1 = 6.71816 loss)
I0123 17:16:50.725805 29630 sgd_solver.cpp:106] Iteration 660, lr = 0.01
I0123 17:16:58.080379 29630 solver.cpp:237] Iteration 680, loss = 6.72839
I0123 17:16:58.080415 29630 solver.cpp:253]     Train net output #0: loss = 6.72839 (* 1 = 6.72839 loss)
I0123 17:16:58.080421 29630 sgd_solver.cpp:106] Iteration 680, lr = 0.01
I0123 17:17:05.266965 29630 solver.cpp:237] Iteration 700, loss = 6.76983
I0123 17:17:05.267133 29630 solver.cpp:253]     Train net output #0: loss = 6.76983 (* 1 = 6.76983 loss)
I0123 17:17:05.267150 29630 sgd_solver.cpp:106] Iteration 700, lr = 0.01
I0123 17:17:12.719357 29630 solver.cpp:237] Iteration 720, loss = 6.6523
I0123 17:17:12.719393 29630 solver.cpp:253]     Train net output #0: loss = 6.6523 (* 1 = 6.6523 loss)
I0123 17:17:12.719399 29630 sgd_solver.cpp:106] Iteration 720, lr = 0.01
I0123 17:17:19.915469 29630 solver.cpp:237] Iteration 740, loss = 6.6387
I0123 17:17:19.915508 29630 solver.cpp:253]     Train net output #0: loss = 6.6387 (* 1 = 6.6387 loss)
I0123 17:17:19.915514 29630 sgd_solver.cpp:106] Iteration 740, lr = 0.01
I0123 17:17:27.147619 29630 solver.cpp:237] Iteration 760, loss = 6.79238
I0123 17:17:27.147657 29630 solver.cpp:253]     Train net output #0: loss = 6.79238 (* 1 = 6.79238 loss)
I0123 17:17:27.147663 29630 sgd_solver.cpp:106] Iteration 760, lr = 0.01
I0123 17:17:34.284368 29630 solver.cpp:237] Iteration 780, loss = 6.7426
I0123 17:17:34.284399 29630 solver.cpp:253]     Train net output #0: loss = 6.7426 (* 1 = 6.7426 loss)
I0123 17:17:34.284404 29630 sgd_solver.cpp:106] Iteration 780, lr = 0.01
I0123 17:17:41.431810 29630 solver.cpp:237] Iteration 800, loss = 6.73016
I0123 17:17:41.431977 29630 solver.cpp:253]     Train net output #0: loss = 6.73016 (* 1 = 6.73016 loss)
I0123 17:17:41.431985 29630 sgd_solver.cpp:106] Iteration 800, lr = 0.01
I0123 17:17:48.655174 29630 solver.cpp:237] Iteration 820, loss = 6.70732
I0123 17:17:48.655212 29630 solver.cpp:253]     Train net output #0: loss = 6.70732 (* 1 = 6.70732 loss)
I0123 17:17:48.655218 29630 sgd_solver.cpp:106] Iteration 820, lr = 0.01
I0123 17:17:55.857658 29630 solver.cpp:237] Iteration 840, loss = 6.7337
I0123 17:17:55.857697 29630 solver.cpp:253]     Train net output #0: loss = 6.7337 (* 1 = 6.7337 loss)
I0123 17:17:55.857703 29630 sgd_solver.cpp:106] Iteration 840, lr = 0.01
I0123 17:18:03.062633 29630 solver.cpp:237] Iteration 860, loss = 6.59595
I0123 17:18:03.062670 29630 solver.cpp:253]     Train net output #0: loss = 6.59595 (* 1 = 6.59595 loss)
I0123 17:18:03.062677 29630 sgd_solver.cpp:106] Iteration 860, lr = 0.01
I0123 17:18:10.248760 29630 solver.cpp:237] Iteration 880, loss = 6.64988
I0123 17:18:10.248798 29630 solver.cpp:253]     Train net output #0: loss = 6.64988 (* 1 = 6.64988 loss)
I0123 17:18:10.248805 29630 sgd_solver.cpp:106] Iteration 880, lr = 0.01
I0123 17:18:17.456946 29630 solver.cpp:237] Iteration 900, loss = 6.71518
I0123 17:18:17.457070 29630 solver.cpp:253]     Train net output #0: loss = 6.71518 (* 1 = 6.71518 loss)
I0123 17:18:17.457078 29630 sgd_solver.cpp:106] Iteration 900, lr = 0.01
I0123 17:18:24.605038 29630 solver.cpp:237] Iteration 920, loss = 6.68673
I0123 17:18:24.605077 29630 solver.cpp:253]     Train net output #0: loss = 6.68673 (* 1 = 6.68673 loss)
I0123 17:18:24.605082 29630 sgd_solver.cpp:106] Iteration 920, lr = 0.01
I0123 17:18:31.817244 29630 solver.cpp:237] Iteration 940, loss = 6.66192
I0123 17:18:31.817282 29630 solver.cpp:253]     Train net output #0: loss = 6.66192 (* 1 = 6.66192 loss)
I0123 17:18:31.817288 29630 sgd_solver.cpp:106] Iteration 940, lr = 0.01
I0123 17:18:39.041352 29630 solver.cpp:237] Iteration 960, loss = 6.66704
I0123 17:18:39.041388 29630 solver.cpp:253]     Train net output #0: loss = 6.66704 (* 1 = 6.66704 loss)
I0123 17:18:39.041394 29630 sgd_solver.cpp:106] Iteration 960, lr = 0.01
I0123 17:18:46.230723 29630 solver.cpp:237] Iteration 980, loss = 6.69154
I0123 17:18:46.230763 29630 solver.cpp:253]     Train net output #0: loss = 6.69154 (* 1 = 6.69154 loss)
I0123 17:18:46.230769 29630 sgd_solver.cpp:106] Iteration 980, lr = 0.01
I0123 17:18:53.165096 29630 solver.cpp:341] Iteration 1000, Testing net (#0)
I0123 17:18:53.335516 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 17:20:06.798619 29630 solver.cpp:409]     Test net output #0: accuracy = 0.00486
I0123 17:20:06.798768 29630 solver.cpp:409]     Test net output #1: loss = 6.6246 (* 1 = 6.6246 loss)
I0123 17:20:06.839314 29630 solver.cpp:237] Iteration 1000, loss = 6.7375
I0123 17:20:06.839359 29630 solver.cpp:253]     Train net output #0: loss = 6.7375 (* 1 = 6.7375 loss)
I0123 17:20:06.839365 29630 sgd_solver.cpp:106] Iteration 1000, lr = 0.01
I0123 17:20:08.714925 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 17:20:13.323200 29630 solver.cpp:237] Iteration 1020, loss = 6.67516
I0123 17:20:13.323238 29630 solver.cpp:253]     Train net output #0: loss = 6.67516 (* 1 = 6.67516 loss)
I0123 17:20:13.323246 29630 sgd_solver.cpp:106] Iteration 1020, lr = 0.01
I0123 17:20:20.505408 29630 solver.cpp:237] Iteration 1040, loss = 6.64616
I0123 17:20:20.505446 29630 solver.cpp:253]     Train net output #0: loss = 6.64616 (* 1 = 6.64616 loss)
I0123 17:20:20.505452 29630 sgd_solver.cpp:106] Iteration 1040, lr = 0.01
I0123 17:20:27.732486 29630 solver.cpp:237] Iteration 1060, loss = 6.62424
I0123 17:20:27.732544 29630 solver.cpp:253]     Train net output #0: loss = 6.62424 (* 1 = 6.62424 loss)
I0123 17:20:27.732556 29630 sgd_solver.cpp:106] Iteration 1060, lr = 0.01
I0123 17:20:34.964190 29630 solver.cpp:237] Iteration 1080, loss = 6.63999
I0123 17:20:34.964228 29630 solver.cpp:253]     Train net output #0: loss = 6.63999 (* 1 = 6.63999 loss)
I0123 17:20:34.964234 29630 sgd_solver.cpp:106] Iteration 1080, lr = 0.01
I0123 17:20:42.194561 29630 solver.cpp:237] Iteration 1100, loss = 6.67173
I0123 17:20:42.194726 29630 solver.cpp:253]     Train net output #0: loss = 6.67173 (* 1 = 6.67173 loss)
I0123 17:20:42.194735 29630 sgd_solver.cpp:106] Iteration 1100, lr = 0.01
I0123 17:20:49.711710 29630 solver.cpp:237] Iteration 1120, loss = 6.57047
I0123 17:20:49.711748 29630 solver.cpp:253]     Train net output #0: loss = 6.57047 (* 1 = 6.57047 loss)
I0123 17:20:49.711755 29630 sgd_solver.cpp:106] Iteration 1120, lr = 0.01
I0123 17:20:57.484977 29630 solver.cpp:237] Iteration 1140, loss = 6.72969
I0123 17:20:57.485014 29630 solver.cpp:253]     Train net output #0: loss = 6.72969 (* 1 = 6.72969 loss)
I0123 17:20:57.485020 29630 sgd_solver.cpp:106] Iteration 1140, lr = 0.01
I0123 17:21:04.859014 29630 solver.cpp:237] Iteration 1160, loss = 6.60147
I0123 17:21:04.859052 29630 solver.cpp:253]     Train net output #0: loss = 6.60147 (* 1 = 6.60147 loss)
I0123 17:21:04.859058 29630 sgd_solver.cpp:106] Iteration 1160, lr = 0.01
I0123 17:21:12.082746 29630 solver.cpp:237] Iteration 1180, loss = 6.61441
I0123 17:21:12.082782 29630 solver.cpp:253]     Train net output #0: loss = 6.61441 (* 1 = 6.61441 loss)
I0123 17:21:12.082788 29630 sgd_solver.cpp:106] Iteration 1180, lr = 0.01
I0123 17:21:19.287649 29630 solver.cpp:237] Iteration 1200, loss = 6.55681
I0123 17:21:19.300782 29630 solver.cpp:253]     Train net output #0: loss = 6.55681 (* 1 = 6.55681 loss)
I0123 17:21:19.300801 29630 sgd_solver.cpp:106] Iteration 1200, lr = 0.01
I0123 17:21:26.499188 29630 solver.cpp:237] Iteration 1220, loss = 6.56969
I0123 17:21:26.499228 29630 solver.cpp:253]     Train net output #0: loss = 6.56969 (* 1 = 6.56969 loss)
I0123 17:21:26.499233 29630 sgd_solver.cpp:106] Iteration 1220, lr = 0.01
I0123 17:21:33.725329 29630 solver.cpp:237] Iteration 1240, loss = 6.61
I0123 17:21:33.725368 29630 solver.cpp:253]     Train net output #0: loss = 6.61 (* 1 = 6.61 loss)
I0123 17:21:33.725373 29630 sgd_solver.cpp:106] Iteration 1240, lr = 0.01
I0123 17:21:40.969496 29630 solver.cpp:237] Iteration 1260, loss = 6.51687
I0123 17:21:40.969524 29630 solver.cpp:253]     Train net output #0: loss = 6.51687 (* 1 = 6.51687 loss)
I0123 17:21:40.969532 29630 sgd_solver.cpp:106] Iteration 1260, lr = 0.01
I0123 17:21:48.235251 29630 solver.cpp:237] Iteration 1280, loss = 6.59552
I0123 17:21:48.235291 29630 solver.cpp:253]     Train net output #0: loss = 6.59552 (* 1 = 6.59552 loss)
I0123 17:21:48.235296 29630 sgd_solver.cpp:106] Iteration 1280, lr = 0.01
I0123 17:21:55.457622 29630 solver.cpp:237] Iteration 1300, loss = 6.68009
I0123 17:21:55.457749 29630 solver.cpp:253]     Train net output #0: loss = 6.68009 (* 1 = 6.68009 loss)
I0123 17:21:55.457765 29630 sgd_solver.cpp:106] Iteration 1300, lr = 0.01
I0123 17:22:02.700355 29630 solver.cpp:237] Iteration 1320, loss = 6.59684
I0123 17:22:02.700392 29630 solver.cpp:253]     Train net output #0: loss = 6.59684 (* 1 = 6.59684 loss)
I0123 17:22:02.700399 29630 sgd_solver.cpp:106] Iteration 1320, lr = 0.01
I0123 17:22:09.952239 29630 solver.cpp:237] Iteration 1340, loss = 6.42566
I0123 17:22:09.952277 29630 solver.cpp:253]     Train net output #0: loss = 6.42566 (* 1 = 6.42566 loss)
I0123 17:22:09.952283 29630 sgd_solver.cpp:106] Iteration 1340, lr = 0.01
I0123 17:22:17.194555 29630 solver.cpp:237] Iteration 1360, loss = 6.58843
I0123 17:22:17.194593 29630 solver.cpp:253]     Train net output #0: loss = 6.58843 (* 1 = 6.58843 loss)
I0123 17:22:17.194599 29630 sgd_solver.cpp:106] Iteration 1360, lr = 0.01
I0123 17:22:24.427016 29630 solver.cpp:237] Iteration 1380, loss = 6.61694
I0123 17:22:24.427045 29630 solver.cpp:253]     Train net output #0: loss = 6.61694 (* 1 = 6.61694 loss)
I0123 17:22:24.427052 29630 sgd_solver.cpp:106] Iteration 1380, lr = 0.01
I0123 17:22:31.686069 29630 solver.cpp:237] Iteration 1400, loss = 6.5652
I0123 17:22:31.686208 29630 solver.cpp:253]     Train net output #0: loss = 6.5652 (* 1 = 6.5652 loss)
I0123 17:22:31.686214 29630 sgd_solver.cpp:106] Iteration 1400, lr = 0.01
I0123 17:22:38.915177 29630 solver.cpp:237] Iteration 1420, loss = 6.50013
I0123 17:22:38.915215 29630 solver.cpp:253]     Train net output #0: loss = 6.50013 (* 1 = 6.50013 loss)
I0123 17:22:38.915222 29630 sgd_solver.cpp:106] Iteration 1420, lr = 0.01
I0123 17:22:46.164805 29630 solver.cpp:237] Iteration 1440, loss = 6.58347
I0123 17:22:46.164844 29630 solver.cpp:253]     Train net output #0: loss = 6.58347 (* 1 = 6.58347 loss)
I0123 17:22:46.164850 29630 sgd_solver.cpp:106] Iteration 1440, lr = 0.01
I0123 17:22:53.386350 29630 solver.cpp:237] Iteration 1460, loss = 6.53291
I0123 17:22:53.386411 29630 solver.cpp:253]     Train net output #0: loss = 6.53291 (* 1 = 6.53291 loss)
I0123 17:22:53.386421 29630 sgd_solver.cpp:106] Iteration 1460, lr = 0.01
I0123 17:23:00.527426 29630 solver.cpp:237] Iteration 1480, loss = 6.54839
I0123 17:23:00.527464 29630 solver.cpp:253]     Train net output #0: loss = 6.54839 (* 1 = 6.54839 loss)
I0123 17:23:00.527469 29630 sgd_solver.cpp:106] Iteration 1480, lr = 0.01
I0123 17:23:07.778067 29630 solver.cpp:237] Iteration 1500, loss = 6.56324
I0123 17:23:07.778165 29630 solver.cpp:253]     Train net output #0: loss = 6.56324 (* 1 = 6.56324 loss)
I0123 17:23:07.778172 29630 sgd_solver.cpp:106] Iteration 1500, lr = 0.01
I0123 17:23:15.031633 29630 solver.cpp:237] Iteration 1520, loss = 6.48942
I0123 17:23:15.031672 29630 solver.cpp:253]     Train net output #0: loss = 6.48942 (* 1 = 6.48942 loss)
I0123 17:23:15.031677 29630 sgd_solver.cpp:106] Iteration 1520, lr = 0.01
I0123 17:23:22.281869 29630 solver.cpp:237] Iteration 1540, loss = 6.46961
I0123 17:23:22.281908 29630 solver.cpp:253]     Train net output #0: loss = 6.46961 (* 1 = 6.46961 loss)
I0123 17:23:22.281914 29630 sgd_solver.cpp:106] Iteration 1540, lr = 0.01
I0123 17:23:29.570058 29630 solver.cpp:237] Iteration 1560, loss = 6.46747
I0123 17:23:29.570096 29630 solver.cpp:253]     Train net output #0: loss = 6.46747 (* 1 = 6.46747 loss)
I0123 17:23:29.570102 29630 sgd_solver.cpp:106] Iteration 1560, lr = 0.01
I0123 17:23:36.845424 29630 solver.cpp:237] Iteration 1580, loss = 6.41701
I0123 17:23:36.845463 29630 solver.cpp:253]     Train net output #0: loss = 6.41701 (* 1 = 6.41701 loss)
I0123 17:23:36.845470 29630 sgd_solver.cpp:106] Iteration 1580, lr = 0.01
I0123 17:23:44.249512 29630 solver.cpp:237] Iteration 1600, loss = 6.4489
I0123 17:23:44.249969 29630 solver.cpp:253]     Train net output #0: loss = 6.4489 (* 1 = 6.4489 loss)
I0123 17:23:44.249976 29630 sgd_solver.cpp:106] Iteration 1600, lr = 0.01
I0123 17:23:51.532145 29630 solver.cpp:237] Iteration 1620, loss = 6.45637
I0123 17:23:51.532191 29630 solver.cpp:253]     Train net output #0: loss = 6.45637 (* 1 = 6.45637 loss)
I0123 17:23:51.532205 29630 sgd_solver.cpp:106] Iteration 1620, lr = 0.01
I0123 17:23:58.801946 29630 solver.cpp:237] Iteration 1640, loss = 6.44558
I0123 17:23:58.801985 29630 solver.cpp:253]     Train net output #0: loss = 6.44558 (* 1 = 6.44558 loss)
I0123 17:23:58.801990 29630 sgd_solver.cpp:106] Iteration 1640, lr = 0.01
I0123 17:24:06.094786 29630 solver.cpp:237] Iteration 1660, loss = 6.51003
I0123 17:24:06.094825 29630 solver.cpp:253]     Train net output #0: loss = 6.51003 (* 1 = 6.51003 loss)
I0123 17:24:06.094831 29630 sgd_solver.cpp:106] Iteration 1660, lr = 0.01
I0123 17:24:13.476580 29630 solver.cpp:237] Iteration 1680, loss = 6.54651
I0123 17:24:13.476619 29630 solver.cpp:253]     Train net output #0: loss = 6.54651 (* 1 = 6.54651 loss)
I0123 17:24:13.476625 29630 sgd_solver.cpp:106] Iteration 1680, lr = 0.01
I0123 17:24:20.864172 29630 solver.cpp:237] Iteration 1700, loss = 6.36884
I0123 17:24:20.864328 29630 solver.cpp:253]     Train net output #0: loss = 6.36884 (* 1 = 6.36884 loss)
I0123 17:24:20.864336 29630 sgd_solver.cpp:106] Iteration 1700, lr = 0.01
I0123 17:24:28.228062 29630 solver.cpp:237] Iteration 1720, loss = 6.47063
I0123 17:24:28.228101 29630 solver.cpp:253]     Train net output #0: loss = 6.47063 (* 1 = 6.47063 loss)
I0123 17:24:28.228106 29630 sgd_solver.cpp:106] Iteration 1720, lr = 0.01
I0123 17:24:35.570379 29630 solver.cpp:237] Iteration 1740, loss = 6.46679
I0123 17:24:35.570416 29630 solver.cpp:253]     Train net output #0: loss = 6.46679 (* 1 = 6.46679 loss)
I0123 17:24:35.570422 29630 sgd_solver.cpp:106] Iteration 1740, lr = 0.01
I0123 17:24:42.788159 29630 solver.cpp:237] Iteration 1760, loss = 6.33623
I0123 17:24:42.788197 29630 solver.cpp:253]     Train net output #0: loss = 6.33623 (* 1 = 6.33623 loss)
I0123 17:24:42.788203 29630 sgd_solver.cpp:106] Iteration 1760, lr = 0.01
I0123 17:24:50.070534 29630 solver.cpp:237] Iteration 1780, loss = 6.21922
I0123 17:24:50.070572 29630 solver.cpp:253]     Train net output #0: loss = 6.21922 (* 1 = 6.21922 loss)
I0123 17:24:50.070579 29630 sgd_solver.cpp:106] Iteration 1780, lr = 0.01
I0123 17:24:57.526980 29630 solver.cpp:237] Iteration 1800, loss = 6.30718
I0123 17:24:57.527083 29630 solver.cpp:253]     Train net output #0: loss = 6.30718 (* 1 = 6.30718 loss)
I0123 17:24:57.527101 29630 sgd_solver.cpp:106] Iteration 1800, lr = 0.01
I0123 17:25:05.095593 29630 solver.cpp:237] Iteration 1820, loss = 6.37391
I0123 17:25:05.095631 29630 solver.cpp:253]     Train net output #0: loss = 6.37391 (* 1 = 6.37391 loss)
I0123 17:25:05.095638 29630 sgd_solver.cpp:106] Iteration 1820, lr = 0.01
I0123 17:25:12.585397 29630 solver.cpp:237] Iteration 1840, loss = 6.34049
I0123 17:25:12.585435 29630 solver.cpp:253]     Train net output #0: loss = 6.34049 (* 1 = 6.34049 loss)
I0123 17:25:12.585443 29630 sgd_solver.cpp:106] Iteration 1840, lr = 0.01
I0123 17:25:19.862324 29630 solver.cpp:237] Iteration 1860, loss = 6.23636
I0123 17:25:19.862362 29630 solver.cpp:253]     Train net output #0: loss = 6.23636 (* 1 = 6.23636 loss)
I0123 17:25:19.862368 29630 sgd_solver.cpp:106] Iteration 1860, lr = 0.01
I0123 17:25:27.134323 29630 solver.cpp:237] Iteration 1880, loss = 6.37663
I0123 17:25:27.134361 29630 solver.cpp:253]     Train net output #0: loss = 6.37663 (* 1 = 6.37663 loss)
I0123 17:25:27.134368 29630 sgd_solver.cpp:106] Iteration 1880, lr = 0.01
I0123 17:25:34.386746 29630 solver.cpp:237] Iteration 1900, loss = 6.41572
I0123 17:25:34.386921 29630 solver.cpp:253]     Train net output #0: loss = 6.41572 (* 1 = 6.41572 loss)
I0123 17:25:34.386930 29630 sgd_solver.cpp:106] Iteration 1900, lr = 0.01
I0123 17:25:41.623347 29630 solver.cpp:237] Iteration 1920, loss = 6.39366
I0123 17:25:41.623383 29630 solver.cpp:253]     Train net output #0: loss = 6.39366 (* 1 = 6.39366 loss)
I0123 17:25:41.623389 29630 sgd_solver.cpp:106] Iteration 1920, lr = 0.01
I0123 17:25:48.888958 29630 solver.cpp:237] Iteration 1940, loss = 6.27713
I0123 17:25:48.888998 29630 solver.cpp:253]     Train net output #0: loss = 6.27713 (* 1 = 6.27713 loss)
I0123 17:25:48.889003 29630 sgd_solver.cpp:106] Iteration 1940, lr = 0.01
I0123 17:25:56.124236 29630 solver.cpp:237] Iteration 1960, loss = 6.29475
I0123 17:25:56.124275 29630 solver.cpp:253]     Train net output #0: loss = 6.29475 (* 1 = 6.29475 loss)
I0123 17:25:56.124281 29630 sgd_solver.cpp:106] Iteration 1960, lr = 0.01
I0123 17:26:03.417948 29630 solver.cpp:237] Iteration 1980, loss = 6.22119
I0123 17:26:03.417989 29630 solver.cpp:253]     Train net output #0: loss = 6.22119 (* 1 = 6.22119 loss)
I0123 17:26:03.417994 29630 sgd_solver.cpp:106] Iteration 1980, lr = 0.01
I0123 17:26:10.345568 29630 solver.cpp:341] Iteration 2000, Testing net (#0)
I0123 17:26:10.968041 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 17:27:23.763463 29630 solver.cpp:409]     Test net output #0: accuracy = 0.0195601
I0123 17:27:23.763614 29630 solver.cpp:409]     Test net output #1: loss = 6.16985 (* 1 = 6.16985 loss)
I0123 17:27:23.804335 29630 solver.cpp:237] Iteration 2000, loss = 6.27118
I0123 17:27:23.804371 29630 solver.cpp:253]     Train net output #0: loss = 6.27118 (* 1 = 6.27118 loss)
I0123 17:27:23.804378 29630 sgd_solver.cpp:106] Iteration 2000, lr = 0.01
I0123 17:27:27.858471 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 17:27:30.341450 29630 solver.cpp:237] Iteration 2020, loss = 6.3363
I0123 17:27:30.341490 29630 solver.cpp:253]     Train net output #0: loss = 6.3363 (* 1 = 6.3363 loss)
I0123 17:27:30.341495 29630 sgd_solver.cpp:106] Iteration 2020, lr = 0.01
I0123 17:27:37.563520 29630 solver.cpp:237] Iteration 2040, loss = 6.37289
I0123 17:27:37.563554 29630 solver.cpp:253]     Train net output #0: loss = 6.37289 (* 1 = 6.37289 loss)
I0123 17:27:37.563560 29630 sgd_solver.cpp:106] Iteration 2040, lr = 0.01
I0123 17:27:44.799402 29630 solver.cpp:237] Iteration 2060, loss = 6.37801
I0123 17:27:44.799440 29630 solver.cpp:253]     Train net output #0: loss = 6.37801 (* 1 = 6.37801 loss)
I0123 17:27:44.799446 29630 sgd_solver.cpp:106] Iteration 2060, lr = 0.01
I0123 17:27:51.964229 29630 solver.cpp:237] Iteration 2080, loss = 6.36437
I0123 17:27:51.964267 29630 solver.cpp:253]     Train net output #0: loss = 6.36437 (* 1 = 6.36437 loss)
I0123 17:27:51.964274 29630 sgd_solver.cpp:106] Iteration 2080, lr = 0.01
I0123 17:27:59.191766 29630 solver.cpp:237] Iteration 2100, loss = 6.35377
I0123 17:27:59.191959 29630 solver.cpp:253]     Train net output #0: loss = 6.35377 (* 1 = 6.35377 loss)
I0123 17:27:59.191967 29630 sgd_solver.cpp:106] Iteration 2100, lr = 0.01
I0123 17:28:06.421133 29630 solver.cpp:237] Iteration 2120, loss = 6.12735
I0123 17:28:06.421172 29630 solver.cpp:253]     Train net output #0: loss = 6.12735 (* 1 = 6.12735 loss)
I0123 17:28:06.421178 29630 sgd_solver.cpp:106] Iteration 2120, lr = 0.01
I0123 17:28:13.710728 29630 solver.cpp:237] Iteration 2140, loss = 6.06976
I0123 17:28:13.710767 29630 solver.cpp:253]     Train net output #0: loss = 6.06976 (* 1 = 6.06976 loss)
I0123 17:28:13.710772 29630 sgd_solver.cpp:106] Iteration 2140, lr = 0.01
I0123 17:28:20.961936 29630 solver.cpp:237] Iteration 2160, loss = 6.21652
I0123 17:28:20.961976 29630 solver.cpp:253]     Train net output #0: loss = 6.21652 (* 1 = 6.21652 loss)
I0123 17:28:20.961982 29630 sgd_solver.cpp:106] Iteration 2160, lr = 0.01
I0123 17:28:28.153965 29630 solver.cpp:237] Iteration 2180, loss = 6.19186
I0123 17:28:28.154003 29630 solver.cpp:253]     Train net output #0: loss = 6.19186 (* 1 = 6.19186 loss)
I0123 17:28:28.154011 29630 sgd_solver.cpp:106] Iteration 2180, lr = 0.01
I0123 17:28:35.414052 29630 solver.cpp:237] Iteration 2200, loss = 6.21078
I0123 17:28:35.414197 29630 solver.cpp:253]     Train net output #0: loss = 6.21078 (* 1 = 6.21078 loss)
I0123 17:28:35.414206 29630 sgd_solver.cpp:106] Iteration 2200, lr = 0.01
I0123 17:28:42.768843 29630 solver.cpp:237] Iteration 2220, loss = 6.13282
I0123 17:28:42.768882 29630 solver.cpp:253]     Train net output #0: loss = 6.13282 (* 1 = 6.13282 loss)
I0123 17:28:42.768888 29630 sgd_solver.cpp:106] Iteration 2220, lr = 0.01
I0123 17:28:50.279680 29630 solver.cpp:237] Iteration 2240, loss = 6.08093
I0123 17:28:50.279719 29630 solver.cpp:253]     Train net output #0: loss = 6.08093 (* 1 = 6.08093 loss)
I0123 17:28:50.279726 29630 sgd_solver.cpp:106] Iteration 2240, lr = 0.01
I0123 17:28:57.792073 29630 solver.cpp:237] Iteration 2260, loss = 6.27514
I0123 17:28:57.792110 29630 solver.cpp:253]     Train net output #0: loss = 6.27514 (* 1 = 6.27514 loss)
I0123 17:28:57.792116 29630 sgd_solver.cpp:106] Iteration 2260, lr = 0.01
I0123 17:29:05.096753 29630 solver.cpp:237] Iteration 2280, loss = 5.95072
I0123 17:29:05.096791 29630 solver.cpp:253]     Train net output #0: loss = 5.95072 (* 1 = 5.95072 loss)
I0123 17:29:05.096797 29630 sgd_solver.cpp:106] Iteration 2280, lr = 0.01
I0123 17:29:12.359786 29630 solver.cpp:237] Iteration 2300, loss = 6.04978
I0123 17:29:12.359920 29630 solver.cpp:253]     Train net output #0: loss = 6.04978 (* 1 = 6.04978 loss)
I0123 17:29:12.359927 29630 sgd_solver.cpp:106] Iteration 2300, lr = 0.01
I0123 17:29:19.603060 29630 solver.cpp:237] Iteration 2320, loss = 6.15364
I0123 17:29:19.603103 29630 solver.cpp:253]     Train net output #0: loss = 6.15364 (* 1 = 6.15364 loss)
I0123 17:29:19.603121 29630 sgd_solver.cpp:106] Iteration 2320, lr = 0.01
I0123 17:29:26.886309 29630 solver.cpp:237] Iteration 2340, loss = 5.95678
I0123 17:29:26.886346 29630 solver.cpp:253]     Train net output #0: loss = 5.95678 (* 1 = 5.95678 loss)
I0123 17:29:26.886353 29630 sgd_solver.cpp:106] Iteration 2340, lr = 0.01
I0123 17:29:34.107717 29630 solver.cpp:237] Iteration 2360, loss = 6.28414
I0123 17:29:34.107754 29630 solver.cpp:253]     Train net output #0: loss = 6.28414 (* 1 = 6.28414 loss)
I0123 17:29:34.107761 29630 sgd_solver.cpp:106] Iteration 2360, lr = 0.01
I0123 17:29:41.344921 29630 solver.cpp:237] Iteration 2380, loss = 6.21049
I0123 17:29:41.344960 29630 solver.cpp:253]     Train net output #0: loss = 6.21049 (* 1 = 6.21049 loss)
I0123 17:29:41.344965 29630 sgd_solver.cpp:106] Iteration 2380, lr = 0.01
I0123 17:29:48.580706 29630 solver.cpp:237] Iteration 2400, loss = 6.09359
I0123 17:29:48.580835 29630 solver.cpp:253]     Train net output #0: loss = 6.09359 (* 1 = 6.09359 loss)
I0123 17:29:48.580842 29630 sgd_solver.cpp:106] Iteration 2400, lr = 0.01
I0123 17:29:55.830130 29630 solver.cpp:237] Iteration 2420, loss = 6.09661
I0123 17:29:55.830169 29630 solver.cpp:253]     Train net output #0: loss = 6.09661 (* 1 = 6.09661 loss)
I0123 17:29:55.830176 29630 sgd_solver.cpp:106] Iteration 2420, lr = 0.01
I0123 17:30:03.095877 29630 solver.cpp:237] Iteration 2440, loss = 6.24291
I0123 17:30:03.095916 29630 solver.cpp:253]     Train net output #0: loss = 6.24291 (* 1 = 6.24291 loss)
I0123 17:30:03.095921 29630 sgd_solver.cpp:106] Iteration 2440, lr = 0.01
I0123 17:30:10.329723 29630 solver.cpp:237] Iteration 2460, loss = 6.19341
I0123 17:30:10.329761 29630 solver.cpp:253]     Train net output #0: loss = 6.19341 (* 1 = 6.19341 loss)
I0123 17:30:10.329768 29630 sgd_solver.cpp:106] Iteration 2460, lr = 0.01
I0123 17:30:17.556733 29630 solver.cpp:237] Iteration 2480, loss = 6.12124
I0123 17:30:17.556773 29630 solver.cpp:253]     Train net output #0: loss = 6.12124 (* 1 = 6.12124 loss)
I0123 17:30:17.556779 29630 sgd_solver.cpp:106] Iteration 2480, lr = 0.01
I0123 17:30:24.789731 29630 solver.cpp:237] Iteration 2500, loss = 6.06779
I0123 17:30:24.789865 29630 solver.cpp:253]     Train net output #0: loss = 6.06779 (* 1 = 6.06779 loss)
I0123 17:30:24.789880 29630 sgd_solver.cpp:106] Iteration 2500, lr = 0.01
I0123 17:30:32.038425 29630 solver.cpp:237] Iteration 2520, loss = 6.17766
I0123 17:30:32.038465 29630 solver.cpp:253]     Train net output #0: loss = 6.17766 (* 1 = 6.17766 loss)
I0123 17:30:32.038470 29630 sgd_solver.cpp:106] Iteration 2520, lr = 0.01
I0123 17:30:39.265157 29630 solver.cpp:237] Iteration 2540, loss = 6.08631
I0123 17:30:39.265197 29630 solver.cpp:253]     Train net output #0: loss = 6.08631 (* 1 = 6.08631 loss)
I0123 17:30:39.265204 29630 sgd_solver.cpp:106] Iteration 2540, lr = 0.01
I0123 17:30:46.490597 29630 solver.cpp:237] Iteration 2560, loss = 6.00315
I0123 17:30:46.490636 29630 solver.cpp:253]     Train net output #0: loss = 6.00315 (* 1 = 6.00315 loss)
I0123 17:30:46.490643 29630 sgd_solver.cpp:106] Iteration 2560, lr = 0.01
I0123 17:30:53.689131 29630 solver.cpp:237] Iteration 2580, loss = 6.01867
I0123 17:30:53.689170 29630 solver.cpp:253]     Train net output #0: loss = 6.01867 (* 1 = 6.01867 loss)
I0123 17:30:53.689177 29630 sgd_solver.cpp:106] Iteration 2580, lr = 0.01
I0123 17:31:00.894902 29630 solver.cpp:237] Iteration 2600, loss = 6.03361
I0123 17:31:00.895035 29630 solver.cpp:253]     Train net output #0: loss = 6.03361 (* 1 = 6.03361 loss)
I0123 17:31:00.895051 29630 sgd_solver.cpp:106] Iteration 2600, lr = 0.01
I0123 17:31:08.105689 29630 solver.cpp:237] Iteration 2620, loss = 6.01628
I0123 17:31:08.105726 29630 solver.cpp:253]     Train net output #0: loss = 6.01628 (* 1 = 6.01628 loss)
I0123 17:31:08.105732 29630 sgd_solver.cpp:106] Iteration 2620, lr = 0.01
I0123 17:31:15.359045 29630 solver.cpp:237] Iteration 2640, loss = 5.79333
I0123 17:31:15.359083 29630 solver.cpp:253]     Train net output #0: loss = 5.79333 (* 1 = 5.79333 loss)
I0123 17:31:15.359089 29630 sgd_solver.cpp:106] Iteration 2640, lr = 0.01
I0123 17:31:22.597615 29630 solver.cpp:237] Iteration 2660, loss = 6.02578
I0123 17:31:22.597652 29630 solver.cpp:253]     Train net output #0: loss = 6.02578 (* 1 = 6.02578 loss)
I0123 17:31:22.597659 29630 sgd_solver.cpp:106] Iteration 2660, lr = 0.01
I0123 17:31:29.812665 29630 solver.cpp:237] Iteration 2680, loss = 6.11367
I0123 17:31:29.812703 29630 solver.cpp:253]     Train net output #0: loss = 6.11367 (* 1 = 6.11367 loss)
I0123 17:31:29.812710 29630 sgd_solver.cpp:106] Iteration 2680, lr = 0.01
I0123 17:31:37.091421 29630 solver.cpp:237] Iteration 2700, loss = 6.00243
I0123 17:31:37.091585 29630 solver.cpp:253]     Train net output #0: loss = 6.00243 (* 1 = 6.00243 loss)
I0123 17:31:37.091593 29630 sgd_solver.cpp:106] Iteration 2700, lr = 0.01
I0123 17:31:44.316264 29630 solver.cpp:237] Iteration 2720, loss = 5.90407
I0123 17:31:44.316304 29630 solver.cpp:253]     Train net output #0: loss = 5.90407 (* 1 = 5.90407 loss)
I0123 17:31:44.316310 29630 sgd_solver.cpp:106] Iteration 2720, lr = 0.01
I0123 17:31:51.568248 29630 solver.cpp:237] Iteration 2740, loss = 6.08349
I0123 17:31:51.568284 29630 solver.cpp:253]     Train net output #0: loss = 6.08349 (* 1 = 6.08349 loss)
I0123 17:31:51.568290 29630 sgd_solver.cpp:106] Iteration 2740, lr = 0.01
I0123 17:31:58.798251 29630 solver.cpp:237] Iteration 2760, loss = 5.88736
I0123 17:31:58.798288 29630 solver.cpp:253]     Train net output #0: loss = 5.88736 (* 1 = 5.88736 loss)
I0123 17:31:58.798295 29630 sgd_solver.cpp:106] Iteration 2760, lr = 0.01
I0123 17:32:06.016343 29630 solver.cpp:237] Iteration 2780, loss = 6.04998
I0123 17:32:06.016381 29630 solver.cpp:253]     Train net output #0: loss = 6.04998 (* 1 = 6.04998 loss)
I0123 17:32:06.016386 29630 sgd_solver.cpp:106] Iteration 2780, lr = 0.01
I0123 17:32:13.300690 29630 solver.cpp:237] Iteration 2800, loss = 5.92604
I0123 17:32:13.300812 29630 solver.cpp:253]     Train net output #0: loss = 5.92604 (* 1 = 5.92604 loss)
I0123 17:32:13.300820 29630 sgd_solver.cpp:106] Iteration 2800, lr = 0.01
I0123 17:32:20.569123 29630 solver.cpp:237] Iteration 2820, loss = 5.97398
I0123 17:32:20.569159 29630 solver.cpp:253]     Train net output #0: loss = 5.97398 (* 1 = 5.97398 loss)
I0123 17:32:20.569165 29630 sgd_solver.cpp:106] Iteration 2820, lr = 0.01
I0123 17:32:27.837376 29630 solver.cpp:237] Iteration 2840, loss = 5.84538
I0123 17:32:27.837414 29630 solver.cpp:253]     Train net output #0: loss = 5.84538 (* 1 = 5.84538 loss)
I0123 17:32:27.837421 29630 sgd_solver.cpp:106] Iteration 2840, lr = 0.01
I0123 17:32:35.057801 29630 solver.cpp:237] Iteration 2860, loss = 5.71393
I0123 17:32:35.057838 29630 solver.cpp:253]     Train net output #0: loss = 5.71393 (* 1 = 5.71393 loss)
I0123 17:32:35.057845 29630 sgd_solver.cpp:106] Iteration 2860, lr = 0.01
I0123 17:32:42.418038 29630 solver.cpp:237] Iteration 2880, loss = 5.97611
I0123 17:32:42.418076 29630 solver.cpp:253]     Train net output #0: loss = 5.97611 (* 1 = 5.97611 loss)
I0123 17:32:42.418083 29630 sgd_solver.cpp:106] Iteration 2880, lr = 0.01
I0123 17:32:49.815114 29630 solver.cpp:237] Iteration 2900, loss = 6.07174
I0123 17:32:49.815238 29630 solver.cpp:253]     Train net output #0: loss = 6.07174 (* 1 = 6.07174 loss)
I0123 17:32:49.815245 29630 sgd_solver.cpp:106] Iteration 2900, lr = 0.01
I0123 17:32:57.205952 29630 solver.cpp:237] Iteration 2920, loss = 5.85608
I0123 17:32:57.205991 29630 solver.cpp:253]     Train net output #0: loss = 5.85608 (* 1 = 5.85608 loss)
I0123 17:32:57.205996 29630 sgd_solver.cpp:106] Iteration 2920, lr = 0.01
I0123 17:33:04.625092 29630 solver.cpp:237] Iteration 2940, loss = 5.95457
I0123 17:33:04.625133 29630 solver.cpp:253]     Train net output #0: loss = 5.95457 (* 1 = 5.95457 loss)
I0123 17:33:04.625138 29630 sgd_solver.cpp:106] Iteration 2940, lr = 0.01
I0123 17:33:11.927273 29630 solver.cpp:237] Iteration 2960, loss = 5.80244
I0123 17:33:11.927311 29630 solver.cpp:253]     Train net output #0: loss = 5.80244 (* 1 = 5.80244 loss)
I0123 17:33:11.927319 29630 sgd_solver.cpp:106] Iteration 2960, lr = 0.01
I0123 17:33:19.231822 29630 solver.cpp:237] Iteration 2980, loss = 5.95474
I0123 17:33:19.231860 29630 solver.cpp:253]     Train net output #0: loss = 5.95474 (* 1 = 5.95474 loss)
I0123 17:33:19.231868 29630 sgd_solver.cpp:106] Iteration 2980, lr = 0.01
I0123 17:33:26.178679 29630 solver.cpp:341] Iteration 3000, Testing net (#0)
I0123 17:33:27.273504 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 17:34:39.280881 29644 blocking_queue.cpp:50] Waiting for data
I0123 17:34:40.371357 29630 solver.cpp:409]     Test net output #0: accuracy = 0.0382403
I0123 17:34:40.371393 29630 solver.cpp:409]     Test net output #1: loss = 5.75538 (* 1 = 5.75538 loss)
I0123 17:34:40.411880 29630 solver.cpp:237] Iteration 3000, loss = 6.06267
I0123 17:34:40.411907 29630 solver.cpp:253]     Train net output #0: loss = 6.06267 (* 1 = 6.06267 loss)
I0123 17:34:40.411916 29630 sgd_solver.cpp:106] Iteration 3000, lr = 0.01
I0123 17:34:46.668956 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 17:34:46.967378 29630 solver.cpp:237] Iteration 3020, loss = 5.87232
I0123 17:34:46.967422 29630 solver.cpp:253]     Train net output #0: loss = 5.87232 (* 1 = 5.87232 loss)
I0123 17:34:46.967438 29630 sgd_solver.cpp:106] Iteration 3020, lr = 0.01
I0123 17:34:54.225092 29630 solver.cpp:237] Iteration 3040, loss = 5.83162
I0123 17:34:54.225131 29630 solver.cpp:253]     Train net output #0: loss = 5.83162 (* 1 = 5.83162 loss)
I0123 17:34:54.225136 29630 sgd_solver.cpp:106] Iteration 3040, lr = 0.01
I0123 17:35:01.471613 29630 solver.cpp:237] Iteration 3060, loss = 5.78729
I0123 17:35:01.471653 29630 solver.cpp:253]     Train net output #0: loss = 5.78729 (* 1 = 5.78729 loss)
I0123 17:35:01.471659 29630 sgd_solver.cpp:106] Iteration 3060, lr = 0.01
I0123 17:35:08.736147 29630 solver.cpp:237] Iteration 3080, loss = 6.03882
I0123 17:35:08.736186 29630 solver.cpp:253]     Train net output #0: loss = 6.03882 (* 1 = 6.03882 loss)
I0123 17:35:08.736191 29630 sgd_solver.cpp:106] Iteration 3080, lr = 0.01
I0123 17:35:16.064748 29630 solver.cpp:237] Iteration 3100, loss = 5.92313
I0123 17:35:16.064857 29630 solver.cpp:253]     Train net output #0: loss = 5.92313 (* 1 = 5.92313 loss)
I0123 17:35:16.064864 29630 sgd_solver.cpp:106] Iteration 3100, lr = 0.01
I0123 17:35:23.410894 29630 solver.cpp:237] Iteration 3120, loss = 5.74785
I0123 17:35:23.410933 29630 solver.cpp:253]     Train net output #0: loss = 5.74785 (* 1 = 5.74785 loss)
I0123 17:35:23.410938 29630 sgd_solver.cpp:106] Iteration 3120, lr = 0.01
I0123 17:35:30.650827 29630 solver.cpp:237] Iteration 3140, loss = 5.94789
I0123 17:35:30.650866 29630 solver.cpp:253]     Train net output #0: loss = 5.94789 (* 1 = 5.94789 loss)
I0123 17:35:30.650871 29630 sgd_solver.cpp:106] Iteration 3140, lr = 0.01
I0123 17:35:37.884510 29630 solver.cpp:237] Iteration 3160, loss = 5.68799
I0123 17:35:37.884552 29630 solver.cpp:253]     Train net output #0: loss = 5.68799 (* 1 = 5.68799 loss)
I0123 17:35:37.884557 29630 sgd_solver.cpp:106] Iteration 3160, lr = 0.01
I0123 17:35:45.189265 29630 solver.cpp:237] Iteration 3180, loss = 5.76201
I0123 17:35:45.189321 29630 solver.cpp:253]     Train net output #0: loss = 5.76201 (* 1 = 5.76201 loss)
I0123 17:35:45.189327 29630 sgd_solver.cpp:106] Iteration 3180, lr = 0.01
I0123 17:35:52.412081 29630 solver.cpp:237] Iteration 3200, loss = 5.71665
I0123 17:35:52.412256 29630 solver.cpp:253]     Train net output #0: loss = 5.71665 (* 1 = 5.71665 loss)
I0123 17:35:52.412264 29630 sgd_solver.cpp:106] Iteration 3200, lr = 0.01
I0123 17:35:59.671109 29630 solver.cpp:237] Iteration 3220, loss = 5.78292
I0123 17:35:59.671147 29630 solver.cpp:253]     Train net output #0: loss = 5.78292 (* 1 = 5.78292 loss)
I0123 17:35:59.671154 29630 sgd_solver.cpp:106] Iteration 3220, lr = 0.01
I0123 17:36:06.923413 29630 solver.cpp:237] Iteration 3240, loss = 5.75803
I0123 17:36:06.923450 29630 solver.cpp:253]     Train net output #0: loss = 5.75803 (* 1 = 5.75803 loss)
I0123 17:36:06.923456 29630 sgd_solver.cpp:106] Iteration 3240, lr = 0.01
I0123 17:36:14.193729 29630 solver.cpp:237] Iteration 3260, loss = 5.80424
I0123 17:36:14.193766 29630 solver.cpp:253]     Train net output #0: loss = 5.80424 (* 1 = 5.80424 loss)
I0123 17:36:14.193771 29630 sgd_solver.cpp:106] Iteration 3260, lr = 0.01
I0123 17:36:21.458482 29630 solver.cpp:237] Iteration 3280, loss = 5.83931
I0123 17:36:21.458520 29630 solver.cpp:253]     Train net output #0: loss = 5.83931 (* 1 = 5.83931 loss)
I0123 17:36:21.458526 29630 sgd_solver.cpp:106] Iteration 3280, lr = 0.01
I0123 17:36:28.700248 29630 solver.cpp:237] Iteration 3300, loss = 5.85494
I0123 17:36:28.700357 29630 solver.cpp:253]     Train net output #0: loss = 5.85494 (* 1 = 5.85494 loss)
I0123 17:36:28.700374 29630 sgd_solver.cpp:106] Iteration 3300, lr = 0.01
I0123 17:36:35.948132 29630 solver.cpp:237] Iteration 3320, loss = 5.7721
I0123 17:36:35.948168 29630 solver.cpp:253]     Train net output #0: loss = 5.7721 (* 1 = 5.7721 loss)
I0123 17:36:35.948174 29630 sgd_solver.cpp:106] Iteration 3320, lr = 0.01
I0123 17:36:43.213145 29630 solver.cpp:237] Iteration 3340, loss = 5.81307
I0123 17:36:43.213183 29630 solver.cpp:253]     Train net output #0: loss = 5.81307 (* 1 = 5.81307 loss)
I0123 17:36:43.213189 29630 sgd_solver.cpp:106] Iteration 3340, lr = 0.01
I0123 17:36:50.709321 29630 solver.cpp:237] Iteration 3360, loss = 5.8551
I0123 17:36:50.709360 29630 solver.cpp:253]     Train net output #0: loss = 5.8551 (* 1 = 5.8551 loss)
I0123 17:36:50.709367 29630 sgd_solver.cpp:106] Iteration 3360, lr = 0.01
I0123 17:36:58.147658 29630 solver.cpp:237] Iteration 3380, loss = 5.85205
I0123 17:36:58.147697 29630 solver.cpp:253]     Train net output #0: loss = 5.85205 (* 1 = 5.85205 loss)
I0123 17:36:58.147704 29630 sgd_solver.cpp:106] Iteration 3380, lr = 0.01
I0123 17:37:05.482393 29630 solver.cpp:237] Iteration 3400, loss = 5.62355
I0123 17:37:05.482547 29630 solver.cpp:253]     Train net output #0: loss = 5.62355 (* 1 = 5.62355 loss)
I0123 17:37:05.482556 29630 sgd_solver.cpp:106] Iteration 3400, lr = 0.01
I0123 17:37:12.915206 29630 solver.cpp:237] Iteration 3420, loss = 5.70586
I0123 17:37:12.915243 29630 solver.cpp:253]     Train net output #0: loss = 5.70586 (* 1 = 5.70586 loss)
I0123 17:37:12.915249 29630 sgd_solver.cpp:106] Iteration 3420, lr = 0.01
I0123 17:37:20.259475 29630 solver.cpp:237] Iteration 3440, loss = 5.7021
I0123 17:37:20.259513 29630 solver.cpp:253]     Train net output #0: loss = 5.7021 (* 1 = 5.7021 loss)
I0123 17:37:20.259519 29630 sgd_solver.cpp:106] Iteration 3440, lr = 0.01
I0123 17:37:27.555872 29630 solver.cpp:237] Iteration 3460, loss = 5.73258
I0123 17:37:27.555912 29630 solver.cpp:253]     Train net output #0: loss = 5.73258 (* 1 = 5.73258 loss)
I0123 17:37:27.555917 29630 sgd_solver.cpp:106] Iteration 3460, lr = 0.01
I0123 17:37:34.809303 29630 solver.cpp:237] Iteration 3480, loss = 5.78393
I0123 17:37:34.809344 29630 solver.cpp:253]     Train net output #0: loss = 5.78393 (* 1 = 5.78393 loss)
I0123 17:37:34.809350 29630 sgd_solver.cpp:106] Iteration 3480, lr = 0.01
I0123 17:37:42.082386 29630 solver.cpp:237] Iteration 3500, loss = 5.65093
I0123 17:37:42.082501 29630 solver.cpp:253]     Train net output #0: loss = 5.65093 (* 1 = 5.65093 loss)
I0123 17:37:42.082509 29630 sgd_solver.cpp:106] Iteration 3500, lr = 0.01
I0123 17:37:49.305894 29630 solver.cpp:237] Iteration 3520, loss = 5.79703
I0123 17:37:49.305932 29630 solver.cpp:253]     Train net output #0: loss = 5.79703 (* 1 = 5.79703 loss)
I0123 17:37:49.305938 29630 sgd_solver.cpp:106] Iteration 3520, lr = 0.01
I0123 17:37:56.573938 29630 solver.cpp:237] Iteration 3540, loss = 5.61927
I0123 17:37:56.573977 29630 solver.cpp:253]     Train net output #0: loss = 5.61927 (* 1 = 5.61927 loss)
I0123 17:37:56.573983 29630 sgd_solver.cpp:106] Iteration 3540, lr = 0.01
I0123 17:38:03.806248 29630 solver.cpp:237] Iteration 3560, loss = 5.7882
I0123 17:38:03.806287 29630 solver.cpp:253]     Train net output #0: loss = 5.7882 (* 1 = 5.7882 loss)
I0123 17:38:03.806293 29630 sgd_solver.cpp:106] Iteration 3560, lr = 0.01
I0123 17:38:11.027024 29630 solver.cpp:237] Iteration 3580, loss = 5.7098
I0123 17:38:11.027061 29630 solver.cpp:253]     Train net output #0: loss = 5.7098 (* 1 = 5.7098 loss)
I0123 17:38:11.027078 29630 sgd_solver.cpp:106] Iteration 3580, lr = 0.01
I0123 17:38:18.288064 29630 solver.cpp:237] Iteration 3600, loss = 5.57771
I0123 17:38:18.288225 29630 solver.cpp:253]     Train net output #0: loss = 5.57771 (* 1 = 5.57771 loss)
I0123 17:38:18.288234 29630 sgd_solver.cpp:106] Iteration 3600, lr = 0.01
I0123 17:38:25.534224 29630 solver.cpp:237] Iteration 3620, loss = 5.78227
I0123 17:38:25.534261 29630 solver.cpp:253]     Train net output #0: loss = 5.78227 (* 1 = 5.78227 loss)
I0123 17:38:25.534267 29630 sgd_solver.cpp:106] Iteration 3620, lr = 0.01
I0123 17:38:32.782232 29630 solver.cpp:237] Iteration 3640, loss = 5.65698
I0123 17:38:32.782269 29630 solver.cpp:253]     Train net output #0: loss = 5.65698 (* 1 = 5.65698 loss)
I0123 17:38:32.782276 29630 sgd_solver.cpp:106] Iteration 3640, lr = 0.01
I0123 17:38:40.000969 29630 solver.cpp:237] Iteration 3660, loss = 5.79158
I0123 17:38:40.001008 29630 solver.cpp:253]     Train net output #0: loss = 5.79158 (* 1 = 5.79158 loss)
I0123 17:38:40.001013 29630 sgd_solver.cpp:106] Iteration 3660, lr = 0.01
I0123 17:38:47.218667 29630 solver.cpp:237] Iteration 3680, loss = 5.55935
I0123 17:38:47.218706 29630 solver.cpp:253]     Train net output #0: loss = 5.55935 (* 1 = 5.55935 loss)
I0123 17:38:47.218713 29630 sgd_solver.cpp:106] Iteration 3680, lr = 0.01
I0123 17:38:54.461151 29630 solver.cpp:237] Iteration 3700, loss = 5.47546
I0123 17:38:54.461330 29630 solver.cpp:253]     Train net output #0: loss = 5.47546 (* 1 = 5.47546 loss)
I0123 17:38:54.461338 29630 sgd_solver.cpp:106] Iteration 3700, lr = 0.01
I0123 17:39:01.685178 29630 solver.cpp:237] Iteration 3720, loss = 5.51072
I0123 17:39:01.685216 29630 solver.cpp:253]     Train net output #0: loss = 5.51072 (* 1 = 5.51072 loss)
I0123 17:39:01.685222 29630 sgd_solver.cpp:106] Iteration 3720, lr = 0.01
I0123 17:39:08.949308 29630 solver.cpp:237] Iteration 3740, loss = 5.71994
I0123 17:39:08.949347 29630 solver.cpp:253]     Train net output #0: loss = 5.71994 (* 1 = 5.71994 loss)
I0123 17:39:08.949353 29630 sgd_solver.cpp:106] Iteration 3740, lr = 0.01
I0123 17:39:16.143601 29630 solver.cpp:237] Iteration 3760, loss = 5.51312
I0123 17:39:16.143640 29630 solver.cpp:253]     Train net output #0: loss = 5.51312 (* 1 = 5.51312 loss)
I0123 17:39:16.143646 29630 sgd_solver.cpp:106] Iteration 3760, lr = 0.01
I0123 17:39:23.360684 29630 solver.cpp:237] Iteration 3780, loss = 5.65257
I0123 17:39:23.360723 29630 solver.cpp:253]     Train net output #0: loss = 5.65257 (* 1 = 5.65257 loss)
I0123 17:39:23.360728 29630 sgd_solver.cpp:106] Iteration 3780, lr = 0.01
I0123 17:39:30.600033 29630 solver.cpp:237] Iteration 3800, loss = 5.51008
I0123 17:39:30.600178 29630 solver.cpp:253]     Train net output #0: loss = 5.51008 (* 1 = 5.51008 loss)
I0123 17:39:30.600186 29630 sgd_solver.cpp:106] Iteration 3800, lr = 0.01
I0123 17:39:37.853122 29630 solver.cpp:237] Iteration 3820, loss = 5.78597
I0123 17:39:37.853162 29630 solver.cpp:253]     Train net output #0: loss = 5.78597 (* 1 = 5.78597 loss)
I0123 17:39:37.853168 29630 sgd_solver.cpp:106] Iteration 3820, lr = 0.01
I0123 17:39:45.118523 29630 solver.cpp:237] Iteration 3840, loss = 5.87539
I0123 17:39:45.118561 29630 solver.cpp:253]     Train net output #0: loss = 5.87539 (* 1 = 5.87539 loss)
I0123 17:39:45.118567 29630 sgd_solver.cpp:106] Iteration 3840, lr = 0.01
I0123 17:39:52.376598 29630 solver.cpp:237] Iteration 3860, loss = 5.61209
I0123 17:39:52.376636 29630 solver.cpp:253]     Train net output #0: loss = 5.61209 (* 1 = 5.61209 loss)
I0123 17:39:52.376642 29630 sgd_solver.cpp:106] Iteration 3860, lr = 0.01
I0123 17:39:59.658042 29630 solver.cpp:237] Iteration 3880, loss = 5.59391
I0123 17:39:59.658080 29630 solver.cpp:253]     Train net output #0: loss = 5.59391 (* 1 = 5.59391 loss)
I0123 17:39:59.658087 29630 sgd_solver.cpp:106] Iteration 3880, lr = 0.01
I0123 17:40:06.921453 29630 solver.cpp:237] Iteration 3900, loss = 5.61272
I0123 17:40:06.921619 29630 solver.cpp:253]     Train net output #0: loss = 5.61272 (* 1 = 5.61272 loss)
I0123 17:40:06.921628 29630 sgd_solver.cpp:106] Iteration 3900, lr = 0.01
I0123 17:40:14.174412 29630 solver.cpp:237] Iteration 3920, loss = 5.53155
I0123 17:40:14.174449 29630 solver.cpp:253]     Train net output #0: loss = 5.53155 (* 1 = 5.53155 loss)
I0123 17:40:14.174456 29630 sgd_solver.cpp:106] Iteration 3920, lr = 0.01
I0123 17:40:21.408856 29630 solver.cpp:237] Iteration 3940, loss = 5.60446
I0123 17:40:21.408896 29630 solver.cpp:253]     Train net output #0: loss = 5.60446 (* 1 = 5.60446 loss)
I0123 17:40:21.408902 29630 sgd_solver.cpp:106] Iteration 3940, lr = 0.01
I0123 17:40:28.715495 29630 solver.cpp:237] Iteration 3960, loss = 5.69225
I0123 17:40:28.715534 29630 solver.cpp:253]     Train net output #0: loss = 5.69225 (* 1 = 5.69225 loss)
I0123 17:40:28.715539 29630 sgd_solver.cpp:106] Iteration 3960, lr = 0.01
I0123 17:40:35.989665 29630 solver.cpp:237] Iteration 3980, loss = 5.59374
I0123 17:40:35.989704 29630 solver.cpp:253]     Train net output #0: loss = 5.59374 (* 1 = 5.59374 loss)
I0123 17:40:35.989711 29630 sgd_solver.cpp:106] Iteration 3980, lr = 0.01
I0123 17:40:42.990712 29630 solver.cpp:341] Iteration 4000, Testing net (#0)
I0123 17:40:44.531407 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 17:41:57.436985 29630 solver.cpp:409]     Test net output #0: accuracy = 0.0582404
I0123 17:41:57.437111 29630 solver.cpp:409]     Test net output #1: loss = 5.4165 (* 1 = 5.4165 loss)
I0123 17:41:57.477866 29630 solver.cpp:237] Iteration 4000, loss = 5.5148
I0123 17:41:57.477903 29630 solver.cpp:253]     Train net output #0: loss = 5.5148 (* 1 = 5.5148 loss)
I0123 17:41:57.477910 29630 sgd_solver.cpp:106] Iteration 4000, lr = 0.01
I0123 17:42:03.995085 29630 solver.cpp:237] Iteration 4020, loss = 5.60666
I0123 17:42:03.995124 29630 solver.cpp:253]     Train net output #0: loss = 5.60666 (* 1 = 5.60666 loss)
I0123 17:42:03.995131 29630 sgd_solver.cpp:106] Iteration 4020, lr = 0.01
I0123 17:42:05.887394 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 17:42:11.243760 29630 solver.cpp:237] Iteration 4040, loss = 5.60337
I0123 17:42:11.243798 29630 solver.cpp:253]     Train net output #0: loss = 5.60337 (* 1 = 5.60337 loss)
I0123 17:42:11.243804 29630 sgd_solver.cpp:106] Iteration 4040, lr = 0.01
I0123 17:42:18.474140 29630 solver.cpp:237] Iteration 4060, loss = 5.44916
I0123 17:42:18.474179 29630 solver.cpp:253]     Train net output #0: loss = 5.44916 (* 1 = 5.44916 loss)
I0123 17:42:18.474184 29630 sgd_solver.cpp:106] Iteration 4060, lr = 0.01
I0123 17:42:25.687175 29630 solver.cpp:237] Iteration 4080, loss = 5.63357
I0123 17:42:25.687222 29630 solver.cpp:253]     Train net output #0: loss = 5.63357 (* 1 = 5.63357 loss)
I0123 17:42:25.687228 29630 sgd_solver.cpp:106] Iteration 4080, lr = 0.01
I0123 17:42:32.943301 29630 solver.cpp:237] Iteration 4100, loss = 5.51371
I0123 17:42:32.943476 29630 solver.cpp:253]     Train net output #0: loss = 5.51371 (* 1 = 5.51371 loss)
I0123 17:42:32.943485 29630 sgd_solver.cpp:106] Iteration 4100, lr = 0.01
I0123 17:42:40.166828 29630 solver.cpp:237] Iteration 4120, loss = 5.39797
I0123 17:42:40.166867 29630 solver.cpp:253]     Train net output #0: loss = 5.39797 (* 1 = 5.39797 loss)
I0123 17:42:40.166883 29630 sgd_solver.cpp:106] Iteration 4120, lr = 0.01
I0123 17:42:47.363989 29630 solver.cpp:237] Iteration 4140, loss = 5.58814
I0123 17:42:47.364027 29630 solver.cpp:253]     Train net output #0: loss = 5.58814 (* 1 = 5.58814 loss)
I0123 17:42:47.364032 29630 sgd_solver.cpp:106] Iteration 4140, lr = 0.01
I0123 17:42:54.580111 29630 solver.cpp:237] Iteration 4160, loss = 5.73129
I0123 17:42:54.580149 29630 solver.cpp:253]     Train net output #0: loss = 5.73129 (* 1 = 5.73129 loss)
I0123 17:42:54.580155 29630 sgd_solver.cpp:106] Iteration 4160, lr = 0.01
I0123 17:43:01.835080 29630 solver.cpp:237] Iteration 4180, loss = 5.52328
I0123 17:43:01.835119 29630 solver.cpp:253]     Train net output #0: loss = 5.52328 (* 1 = 5.52328 loss)
I0123 17:43:01.835124 29630 sgd_solver.cpp:106] Iteration 4180, lr = 0.01
I0123 17:43:09.080850 29630 solver.cpp:237] Iteration 4200, loss = 5.50148
I0123 17:43:09.080976 29630 solver.cpp:253]     Train net output #0: loss = 5.50148 (* 1 = 5.50148 loss)
I0123 17:43:09.081001 29630 sgd_solver.cpp:106] Iteration 4200, lr = 0.01
I0123 17:43:16.292080 29630 solver.cpp:237] Iteration 4220, loss = 5.41627
I0123 17:43:16.292120 29630 solver.cpp:253]     Train net output #0: loss = 5.41627 (* 1 = 5.41627 loss)
I0123 17:43:16.292126 29630 sgd_solver.cpp:106] Iteration 4220, lr = 0.01
I0123 17:43:23.551285 29630 solver.cpp:237] Iteration 4240, loss = 5.3774
I0123 17:43:23.551321 29630 solver.cpp:253]     Train net output #0: loss = 5.3774 (* 1 = 5.3774 loss)
I0123 17:43:23.551327 29630 sgd_solver.cpp:106] Iteration 4240, lr = 0.01
I0123 17:43:30.813243 29630 solver.cpp:237] Iteration 4260, loss = 5.55221
I0123 17:43:30.813282 29630 solver.cpp:253]     Train net output #0: loss = 5.55221 (* 1 = 5.55221 loss)
I0123 17:43:30.813289 29630 sgd_solver.cpp:106] Iteration 4260, lr = 0.01
I0123 17:43:38.048207 29630 solver.cpp:237] Iteration 4280, loss = 5.36557
I0123 17:43:38.048244 29630 solver.cpp:253]     Train net output #0: loss = 5.36557 (* 1 = 5.36557 loss)
I0123 17:43:38.048249 29630 sgd_solver.cpp:106] Iteration 4280, lr = 0.01
I0123 17:43:45.281102 29630 solver.cpp:237] Iteration 4300, loss = 5.43142
I0123 17:43:45.281287 29630 solver.cpp:253]     Train net output #0: loss = 5.43142 (* 1 = 5.43142 loss)
I0123 17:43:45.281296 29630 sgd_solver.cpp:106] Iteration 4300, lr = 0.01
I0123 17:43:52.530433 29630 solver.cpp:237] Iteration 4320, loss = 5.53052
I0123 17:43:52.530469 29630 solver.cpp:253]     Train net output #0: loss = 5.53052 (* 1 = 5.53052 loss)
I0123 17:43:52.530485 29630 sgd_solver.cpp:106] Iteration 4320, lr = 0.01
I0123 17:43:59.746335 29630 solver.cpp:237] Iteration 4340, loss = 5.46455
I0123 17:43:59.746372 29630 solver.cpp:253]     Train net output #0: loss = 5.46455 (* 1 = 5.46455 loss)
I0123 17:43:59.746378 29630 sgd_solver.cpp:106] Iteration 4340, lr = 0.01
I0123 17:44:07.006361 29630 solver.cpp:237] Iteration 4360, loss = 5.55438
I0123 17:44:07.006398 29630 solver.cpp:253]     Train net output #0: loss = 5.55438 (* 1 = 5.55438 loss)
I0123 17:44:07.006404 29630 sgd_solver.cpp:106] Iteration 4360, lr = 0.01
I0123 17:44:14.208963 29630 solver.cpp:237] Iteration 4380, loss = 5.40149
I0123 17:44:14.209008 29630 solver.cpp:253]     Train net output #0: loss = 5.40149 (* 1 = 5.40149 loss)
I0123 17:44:14.209023 29630 sgd_solver.cpp:106] Iteration 4380, lr = 0.01
I0123 17:44:21.507928 29630 solver.cpp:237] Iteration 4400, loss = 5.32177
I0123 17:44:21.508034 29630 solver.cpp:253]     Train net output #0: loss = 5.32177 (* 1 = 5.32177 loss)
I0123 17:44:21.508051 29630 sgd_solver.cpp:106] Iteration 4400, lr = 0.01
I0123 17:44:28.771132 29630 solver.cpp:237] Iteration 4420, loss = 5.44485
I0123 17:44:28.771172 29630 solver.cpp:253]     Train net output #0: loss = 5.44485 (* 1 = 5.44485 loss)
I0123 17:44:28.771178 29630 sgd_solver.cpp:106] Iteration 4420, lr = 0.01
I0123 17:44:36.024178 29630 solver.cpp:237] Iteration 4440, loss = 5.52213
I0123 17:44:36.024214 29630 solver.cpp:253]     Train net output #0: loss = 5.52213 (* 1 = 5.52213 loss)
I0123 17:44:36.024221 29630 sgd_solver.cpp:106] Iteration 4440, lr = 0.01
I0123 17:44:43.254128 29630 solver.cpp:237] Iteration 4460, loss = 5.65653
I0123 17:44:43.254168 29630 solver.cpp:253]     Train net output #0: loss = 5.65653 (* 1 = 5.65653 loss)
I0123 17:44:43.254173 29630 sgd_solver.cpp:106] Iteration 4460, lr = 0.01
I0123 17:44:50.564924 29630 solver.cpp:237] Iteration 4480, loss = 5.62899
I0123 17:44:50.564962 29630 solver.cpp:253]     Train net output #0: loss = 5.62899 (* 1 = 5.62899 loss)
I0123 17:44:50.564968 29630 sgd_solver.cpp:106] Iteration 4480, lr = 0.01
I0123 17:44:57.827942 29630 solver.cpp:237] Iteration 4500, loss = 5.52177
I0123 17:44:57.828086 29630 solver.cpp:253]     Train net output #0: loss = 5.52177 (* 1 = 5.52177 loss)
I0123 17:44:57.828094 29630 sgd_solver.cpp:106] Iteration 4500, lr = 0.01
I0123 17:45:05.214521 29630 solver.cpp:237] Iteration 4520, loss = 5.52482
I0123 17:45:05.214560 29630 solver.cpp:253]     Train net output #0: loss = 5.52482 (* 1 = 5.52482 loss)
I0123 17:45:05.214565 29630 sgd_solver.cpp:106] Iteration 4520, lr = 0.01
I0123 17:45:12.726191 29630 solver.cpp:237] Iteration 4540, loss = 5.76384
I0123 17:45:12.726229 29630 solver.cpp:253]     Train net output #0: loss = 5.76384 (* 1 = 5.76384 loss)
I0123 17:45:12.726234 29630 sgd_solver.cpp:106] Iteration 4540, lr = 0.01
I0123 17:45:20.012293 29630 solver.cpp:237] Iteration 4560, loss = 5.38667
I0123 17:45:20.012331 29630 solver.cpp:253]     Train net output #0: loss = 5.38667 (* 1 = 5.38667 loss)
I0123 17:45:20.012338 29630 sgd_solver.cpp:106] Iteration 4560, lr = 0.01
I0123 17:45:27.372550 29630 solver.cpp:237] Iteration 4580, loss = 5.34485
I0123 17:45:27.372588 29630 solver.cpp:253]     Train net output #0: loss = 5.34485 (* 1 = 5.34485 loss)
I0123 17:45:27.372594 29630 sgd_solver.cpp:106] Iteration 4580, lr = 0.01
I0123 17:45:34.645823 29630 solver.cpp:237] Iteration 4600, loss = 5.38198
I0123 17:45:34.645969 29630 solver.cpp:253]     Train net output #0: loss = 5.38198 (* 1 = 5.38198 loss)
I0123 17:45:34.645987 29630 sgd_solver.cpp:106] Iteration 4600, lr = 0.01
I0123 17:45:41.946574 29630 solver.cpp:237] Iteration 4620, loss = 5.45725
I0123 17:45:41.946611 29630 solver.cpp:253]     Train net output #0: loss = 5.45725 (* 1 = 5.45725 loss)
I0123 17:45:41.946617 29630 sgd_solver.cpp:106] Iteration 4620, lr = 0.01
I0123 17:45:49.188964 29630 solver.cpp:237] Iteration 4640, loss = 5.50058
I0123 17:45:49.189002 29630 solver.cpp:253]     Train net output #0: loss = 5.50058 (* 1 = 5.50058 loss)
I0123 17:45:49.189007 29630 sgd_solver.cpp:106] Iteration 4640, lr = 0.01
I0123 17:45:56.426856 29630 solver.cpp:237] Iteration 4660, loss = 5.43587
I0123 17:45:56.426894 29630 solver.cpp:253]     Train net output #0: loss = 5.43587 (* 1 = 5.43587 loss)
I0123 17:45:56.426900 29630 sgd_solver.cpp:106] Iteration 4660, lr = 0.01
I0123 17:46:03.663684 29630 solver.cpp:237] Iteration 4680, loss = 5.54572
I0123 17:46:03.663723 29630 solver.cpp:253]     Train net output #0: loss = 5.54572 (* 1 = 5.54572 loss)
I0123 17:46:03.663729 29630 sgd_solver.cpp:106] Iteration 4680, lr = 0.01
I0123 17:46:10.872027 29630 solver.cpp:237] Iteration 4700, loss = 5.4667
I0123 17:46:10.872134 29630 solver.cpp:253]     Train net output #0: loss = 5.4667 (* 1 = 5.4667 loss)
I0123 17:46:10.872143 29630 sgd_solver.cpp:106] Iteration 4700, lr = 0.01
I0123 17:46:18.119293 29630 solver.cpp:237] Iteration 4720, loss = 5.37177
I0123 17:46:18.119333 29630 solver.cpp:253]     Train net output #0: loss = 5.37177 (* 1 = 5.37177 loss)
I0123 17:46:18.119338 29630 sgd_solver.cpp:106] Iteration 4720, lr = 0.01
I0123 17:46:25.334620 29630 solver.cpp:237] Iteration 4740, loss = 5.3568
I0123 17:46:25.334658 29630 solver.cpp:253]     Train net output #0: loss = 5.3568 (* 1 = 5.3568 loss)
I0123 17:46:25.334664 29630 sgd_solver.cpp:106] Iteration 4740, lr = 0.01
I0123 17:46:32.579411 29630 solver.cpp:237] Iteration 4760, loss = 5.21606
I0123 17:46:32.579449 29630 solver.cpp:253]     Train net output #0: loss = 5.21606 (* 1 = 5.21606 loss)
I0123 17:46:32.579455 29630 sgd_solver.cpp:106] Iteration 4760, lr = 0.01
I0123 17:46:39.759927 29630 solver.cpp:237] Iteration 4780, loss = 5.11609
I0123 17:46:39.759968 29630 solver.cpp:253]     Train net output #0: loss = 5.11609 (* 1 = 5.11609 loss)
I0123 17:46:39.759974 29630 sgd_solver.cpp:106] Iteration 4780, lr = 0.01
I0123 17:46:46.993073 29630 solver.cpp:237] Iteration 4800, loss = 5.34259
I0123 17:46:46.993218 29630 solver.cpp:253]     Train net output #0: loss = 5.34259 (* 1 = 5.34259 loss)
I0123 17:46:46.993227 29630 sgd_solver.cpp:106] Iteration 4800, lr = 0.01
I0123 17:46:54.204169 29630 solver.cpp:237] Iteration 4820, loss = 5.2505
I0123 17:46:54.204207 29630 solver.cpp:253]     Train net output #0: loss = 5.2505 (* 1 = 5.2505 loss)
I0123 17:46:54.204213 29630 sgd_solver.cpp:106] Iteration 4820, lr = 0.01
I0123 17:47:01.407038 29630 solver.cpp:237] Iteration 4840, loss = 5.58022
I0123 17:47:01.407076 29630 solver.cpp:253]     Train net output #0: loss = 5.58022 (* 1 = 5.58022 loss)
I0123 17:47:01.407083 29630 sgd_solver.cpp:106] Iteration 4840, lr = 0.01
I0123 17:47:08.655597 29630 solver.cpp:237] Iteration 4860, loss = 5.20025
I0123 17:47:08.655635 29630 solver.cpp:253]     Train net output #0: loss = 5.20025 (* 1 = 5.20025 loss)
I0123 17:47:08.655642 29630 sgd_solver.cpp:106] Iteration 4860, lr = 0.01
I0123 17:47:15.896553 29630 solver.cpp:237] Iteration 4880, loss = 5.41886
I0123 17:47:15.896592 29630 solver.cpp:253]     Train net output #0: loss = 5.41886 (* 1 = 5.41886 loss)
I0123 17:47:15.896598 29630 sgd_solver.cpp:106] Iteration 4880, lr = 0.01
I0123 17:47:23.105594 29630 solver.cpp:237] Iteration 4900, loss = 5.49109
I0123 17:47:23.105734 29630 solver.cpp:253]     Train net output #0: loss = 5.49109 (* 1 = 5.49109 loss)
I0123 17:47:23.105741 29630 sgd_solver.cpp:106] Iteration 4900, lr = 0.01
I0123 17:47:30.359485 29630 solver.cpp:237] Iteration 4920, loss = 5.25052
I0123 17:47:30.359525 29630 solver.cpp:253]     Train net output #0: loss = 5.25052 (* 1 = 5.25052 loss)
I0123 17:47:30.359532 29630 sgd_solver.cpp:106] Iteration 4920, lr = 0.01
I0123 17:47:37.594574 29630 solver.cpp:237] Iteration 4940, loss = 5.27803
I0123 17:47:37.594660 29630 solver.cpp:253]     Train net output #0: loss = 5.27803 (* 1 = 5.27803 loss)
I0123 17:47:37.594676 29630 sgd_solver.cpp:106] Iteration 4940, lr = 0.01
I0123 17:47:44.825911 29630 solver.cpp:237] Iteration 4960, loss = 5.29336
I0123 17:47:44.825950 29630 solver.cpp:253]     Train net output #0: loss = 5.29336 (* 1 = 5.29336 loss)
I0123 17:47:44.825956 29630 sgd_solver.cpp:106] Iteration 4960, lr = 0.01
I0123 17:47:52.076892 29630 solver.cpp:237] Iteration 4980, loss = 5.71736
I0123 17:47:52.076931 29630 solver.cpp:253]     Train net output #0: loss = 5.71736 (* 1 = 5.71736 loss)
I0123 17:47:52.076937 29630 sgd_solver.cpp:106] Iteration 4980, lr = 0.01
I0123 17:47:59.055532 29630 solver.cpp:341] Iteration 5000, Testing net (#0)
I0123 17:48:01.033288 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 17:49:13.023753 29630 solver.cpp:409]     Test net output #0: accuracy = 0.0746202
I0123 17:49:13.023897 29630 solver.cpp:409]     Test net output #1: loss = 5.1955 (* 1 = 5.1955 loss)
I0123 17:49:13.064674 29630 solver.cpp:237] Iteration 5000, loss = 5.43958
I0123 17:49:13.064712 29630 solver.cpp:253]     Train net output #0: loss = 5.43958 (* 1 = 5.43958 loss)
I0123 17:49:13.064718 29630 sgd_solver.cpp:106] Iteration 5000, lr = 0.01
I0123 17:49:19.646090 29630 solver.cpp:237] Iteration 5020, loss = 5.42169
I0123 17:49:19.646128 29630 solver.cpp:253]     Train net output #0: loss = 5.42169 (* 1 = 5.42169 loss)
I0123 17:49:19.646134 29630 sgd_solver.cpp:106] Iteration 5020, lr = 0.01
I0123 17:49:23.738016 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 17:49:27.037636 29630 solver.cpp:237] Iteration 5040, loss = 5.30277
I0123 17:49:27.037674 29630 solver.cpp:253]     Train net output #0: loss = 5.30277 (* 1 = 5.30277 loss)
I0123 17:49:27.037679 29630 sgd_solver.cpp:106] Iteration 5040, lr = 0.01
I0123 17:49:34.420269 29630 solver.cpp:237] Iteration 5060, loss = 5.3724
I0123 17:49:34.420307 29630 solver.cpp:253]     Train net output #0: loss = 5.3724 (* 1 = 5.3724 loss)
I0123 17:49:34.420312 29630 sgd_solver.cpp:106] Iteration 5060, lr = 0.01
I0123 17:49:41.816069 29630 solver.cpp:237] Iteration 5080, loss = 5.54749
I0123 17:49:41.816108 29630 solver.cpp:253]     Train net output #0: loss = 5.54749 (* 1 = 5.54749 loss)
I0123 17:49:41.816114 29630 sgd_solver.cpp:106] Iteration 5080, lr = 0.01
I0123 17:49:49.149945 29630 solver.cpp:237] Iteration 5100, loss = 5.40715
I0123 17:49:49.150104 29630 solver.cpp:253]     Train net output #0: loss = 5.40715 (* 1 = 5.40715 loss)
I0123 17:49:49.150122 29630 sgd_solver.cpp:106] Iteration 5100, lr = 0.01
I0123 17:49:56.459213 29630 solver.cpp:237] Iteration 5120, loss = 5.32935
I0123 17:49:56.459252 29630 solver.cpp:253]     Train net output #0: loss = 5.32935 (* 1 = 5.32935 loss)
I0123 17:49:56.459259 29630 sgd_solver.cpp:106] Iteration 5120, lr = 0.01
I0123 17:50:03.775387 29630 solver.cpp:237] Iteration 5140, loss = 5.32689
I0123 17:50:03.775424 29630 solver.cpp:253]     Train net output #0: loss = 5.32689 (* 1 = 5.32689 loss)
I0123 17:50:03.775431 29630 sgd_solver.cpp:106] Iteration 5140, lr = 0.01
I0123 17:50:11.039198 29630 solver.cpp:237] Iteration 5160, loss = 5.23319
I0123 17:50:11.039237 29630 solver.cpp:253]     Train net output #0: loss = 5.23319 (* 1 = 5.23319 loss)
I0123 17:50:11.039243 29630 sgd_solver.cpp:106] Iteration 5160, lr = 0.01
I0123 17:50:18.256160 29630 solver.cpp:237] Iteration 5180, loss = 5.30902
I0123 17:50:18.256197 29630 solver.cpp:253]     Train net output #0: loss = 5.30902 (* 1 = 5.30902 loss)
I0123 17:50:18.256204 29630 sgd_solver.cpp:106] Iteration 5180, lr = 0.01
I0123 17:50:25.505419 29630 solver.cpp:237] Iteration 5200, loss = 5.37394
I0123 17:50:25.505550 29630 solver.cpp:253]     Train net output #0: loss = 5.37394 (* 1 = 5.37394 loss)
I0123 17:50:25.505558 29630 sgd_solver.cpp:106] Iteration 5200, lr = 0.01
I0123 17:50:32.777459 29630 solver.cpp:237] Iteration 5220, loss = 5.27827
I0123 17:50:32.777498 29630 solver.cpp:253]     Train net output #0: loss = 5.27827 (* 1 = 5.27827 loss)
I0123 17:50:32.777503 29630 sgd_solver.cpp:106] Iteration 5220, lr = 0.01
I0123 17:50:40.019814 29630 solver.cpp:237] Iteration 5240, loss = 5.2245
I0123 17:50:40.019853 29630 solver.cpp:253]     Train net output #0: loss = 5.2245 (* 1 = 5.2245 loss)
I0123 17:50:40.019860 29630 sgd_solver.cpp:106] Iteration 5240, lr = 0.01
I0123 17:50:47.264825 29630 solver.cpp:237] Iteration 5260, loss = 5.22712
I0123 17:50:47.264863 29630 solver.cpp:253]     Train net output #0: loss = 5.22712 (* 1 = 5.22712 loss)
I0123 17:50:47.264868 29630 sgd_solver.cpp:106] Iteration 5260, lr = 0.01
I0123 17:50:54.498459 29630 solver.cpp:237] Iteration 5280, loss = 5.40735
I0123 17:50:54.498497 29630 solver.cpp:253]     Train net output #0: loss = 5.40735 (* 1 = 5.40735 loss)
I0123 17:50:54.498503 29630 sgd_solver.cpp:106] Iteration 5280, lr = 0.01
I0123 17:51:01.754190 29630 solver.cpp:237] Iteration 5300, loss = 5.44755
I0123 17:51:01.754334 29630 solver.cpp:253]     Train net output #0: loss = 5.44755 (* 1 = 5.44755 loss)
I0123 17:51:01.754341 29630 sgd_solver.cpp:106] Iteration 5300, lr = 0.01
I0123 17:51:08.990476 29630 solver.cpp:237] Iteration 5320, loss = 5.20273
I0123 17:51:08.990515 29630 solver.cpp:253]     Train net output #0: loss = 5.20273 (* 1 = 5.20273 loss)
I0123 17:51:08.990521 29630 sgd_solver.cpp:106] Iteration 5320, lr = 0.01
I0123 17:51:16.278789 29630 solver.cpp:237] Iteration 5340, loss = 5.21765
I0123 17:51:16.278828 29630 solver.cpp:253]     Train net output #0: loss = 5.21765 (* 1 = 5.21765 loss)
I0123 17:51:16.278834 29630 sgd_solver.cpp:106] Iteration 5340, lr = 0.01
I0123 17:51:23.500288 29630 solver.cpp:237] Iteration 5360, loss = 5.43176
I0123 17:51:23.500326 29630 solver.cpp:253]     Train net output #0: loss = 5.43176 (* 1 = 5.43176 loss)
I0123 17:51:23.500332 29630 sgd_solver.cpp:106] Iteration 5360, lr = 0.01
I0123 17:51:30.758149 29630 solver.cpp:237] Iteration 5380, loss = 5.36445
I0123 17:51:30.758188 29630 solver.cpp:253]     Train net output #0: loss = 5.36445 (* 1 = 5.36445 loss)
I0123 17:51:30.758194 29630 sgd_solver.cpp:106] Iteration 5380, lr = 0.01
I0123 17:51:37.979743 29630 solver.cpp:237] Iteration 5400, loss = 5.26194
I0123 17:51:37.979890 29630 solver.cpp:253]     Train net output #0: loss = 5.26194 (* 1 = 5.26194 loss)
I0123 17:51:37.979898 29630 sgd_solver.cpp:106] Iteration 5400, lr = 0.01
I0123 17:51:45.200991 29630 solver.cpp:237] Iteration 5420, loss = 5.26007
I0123 17:51:45.201030 29630 solver.cpp:253]     Train net output #0: loss = 5.26007 (* 1 = 5.26007 loss)
I0123 17:51:45.201036 29630 sgd_solver.cpp:106] Iteration 5420, lr = 0.01
I0123 17:51:52.447170 29630 solver.cpp:237] Iteration 5440, loss = 5.26648
I0123 17:51:52.447208 29630 solver.cpp:253]     Train net output #0: loss = 5.26648 (* 1 = 5.26648 loss)
I0123 17:51:52.447214 29630 sgd_solver.cpp:106] Iteration 5440, lr = 0.01
I0123 17:51:59.705327 29630 solver.cpp:237] Iteration 5460, loss = 5.38753
I0123 17:51:59.705365 29630 solver.cpp:253]     Train net output #0: loss = 5.38753 (* 1 = 5.38753 loss)
I0123 17:51:59.705371 29630 sgd_solver.cpp:106] Iteration 5460, lr = 0.01
I0123 17:52:06.931161 29630 solver.cpp:237] Iteration 5480, loss = 5.10548
I0123 17:52:06.931200 29630 solver.cpp:253]     Train net output #0: loss = 5.10548 (* 1 = 5.10548 loss)
I0123 17:52:06.931205 29630 sgd_solver.cpp:106] Iteration 5480, lr = 0.01
I0123 17:52:14.178807 29630 solver.cpp:237] Iteration 5500, loss = 5.36647
I0123 17:52:14.178973 29630 solver.cpp:253]     Train net output #0: loss = 5.36647 (* 1 = 5.36647 loss)
I0123 17:52:14.178982 29630 sgd_solver.cpp:106] Iteration 5500, lr = 0.01
I0123 17:52:21.430994 29630 solver.cpp:237] Iteration 5520, loss = 5.1901
I0123 17:52:21.431033 29630 solver.cpp:253]     Train net output #0: loss = 5.1901 (* 1 = 5.1901 loss)
I0123 17:52:21.431040 29630 sgd_solver.cpp:106] Iteration 5520, lr = 0.01
I0123 17:52:28.651373 29630 solver.cpp:237] Iteration 5540, loss = 5.33518
I0123 17:52:28.651412 29630 solver.cpp:253]     Train net output #0: loss = 5.33518 (* 1 = 5.33518 loss)
I0123 17:52:28.651419 29630 sgd_solver.cpp:106] Iteration 5540, lr = 0.01
I0123 17:52:35.888273 29630 solver.cpp:237] Iteration 5560, loss = 5.1575
I0123 17:52:35.888311 29630 solver.cpp:253]     Train net output #0: loss = 5.1575 (* 1 = 5.1575 loss)
I0123 17:52:35.888317 29630 sgd_solver.cpp:106] Iteration 5560, lr = 0.01
I0123 17:52:43.125464 29630 solver.cpp:237] Iteration 5580, loss = 5.27009
I0123 17:52:43.125504 29630 solver.cpp:253]     Train net output #0: loss = 5.27009 (* 1 = 5.27009 loss)
I0123 17:52:43.125509 29630 sgd_solver.cpp:106] Iteration 5580, lr = 0.01
I0123 17:52:50.381691 29630 solver.cpp:237] Iteration 5600, loss = 5.31872
I0123 17:52:50.381858 29630 solver.cpp:253]     Train net output #0: loss = 5.31872 (* 1 = 5.31872 loss)
I0123 17:52:50.381866 29630 sgd_solver.cpp:106] Iteration 5600, lr = 0.01
I0123 17:52:57.656633 29630 solver.cpp:237] Iteration 5620, loss = 5.24035
I0123 17:52:57.656672 29630 solver.cpp:253]     Train net output #0: loss = 5.24035 (* 1 = 5.24035 loss)
I0123 17:52:57.656678 29630 sgd_solver.cpp:106] Iteration 5620, lr = 0.01
I0123 17:53:04.901078 29630 solver.cpp:237] Iteration 5640, loss = 5.28681
I0123 17:53:04.901118 29630 solver.cpp:253]     Train net output #0: loss = 5.28681 (* 1 = 5.28681 loss)
I0123 17:53:04.901124 29630 sgd_solver.cpp:106] Iteration 5640, lr = 0.01
I0123 17:53:12.119853 29630 solver.cpp:237] Iteration 5660, loss = 5.20363
I0123 17:53:12.119891 29630 solver.cpp:253]     Train net output #0: loss = 5.20363 (* 1 = 5.20363 loss)
I0123 17:53:12.119906 29630 sgd_solver.cpp:106] Iteration 5660, lr = 0.01
I0123 17:53:19.406472 29630 solver.cpp:237] Iteration 5680, loss = 5.25152
I0123 17:53:19.406502 29630 solver.cpp:253]     Train net output #0: loss = 5.25152 (* 1 = 5.25152 loss)
I0123 17:53:19.406508 29630 sgd_solver.cpp:106] Iteration 5680, lr = 0.01
I0123 17:53:26.749130 29630 solver.cpp:237] Iteration 5700, loss = 5.23009
I0123 17:53:26.749326 29630 solver.cpp:253]     Train net output #0: loss = 5.23009 (* 1 = 5.23009 loss)
I0123 17:53:26.749335 29630 sgd_solver.cpp:106] Iteration 5700, lr = 0.01
I0123 17:53:34.161099 29630 solver.cpp:237] Iteration 5720, loss = 5.25287
I0123 17:53:34.161139 29630 solver.cpp:253]     Train net output #0: loss = 5.25287 (* 1 = 5.25287 loss)
I0123 17:53:34.161144 29630 sgd_solver.cpp:106] Iteration 5720, lr = 0.01
I0123 17:53:41.586299 29630 solver.cpp:237] Iteration 5740, loss = 5.41756
I0123 17:53:41.586338 29630 solver.cpp:253]     Train net output #0: loss = 5.41756 (* 1 = 5.41756 loss)
I0123 17:53:41.586344 29630 sgd_solver.cpp:106] Iteration 5740, lr = 0.01
I0123 17:53:48.972909 29630 solver.cpp:237] Iteration 5760, loss = 5.39155
I0123 17:53:48.972944 29630 solver.cpp:253]     Train net output #0: loss = 5.39155 (* 1 = 5.39155 loss)
I0123 17:53:48.972950 29630 sgd_solver.cpp:106] Iteration 5760, lr = 0.01
I0123 17:53:56.287833 29630 solver.cpp:237] Iteration 5780, loss = 5.20304
I0123 17:53:56.287871 29630 solver.cpp:253]     Train net output #0: loss = 5.20304 (* 1 = 5.20304 loss)
I0123 17:53:56.287878 29630 sgd_solver.cpp:106] Iteration 5780, lr = 0.01
I0123 17:54:03.522714 29630 solver.cpp:237] Iteration 5800, loss = 5.23595
I0123 17:54:03.522845 29630 solver.cpp:253]     Train net output #0: loss = 5.23595 (* 1 = 5.23595 loss)
I0123 17:54:03.522852 29630 sgd_solver.cpp:106] Iteration 5800, lr = 0.01
I0123 17:54:10.857297 29630 solver.cpp:237] Iteration 5820, loss = 5.14937
I0123 17:54:10.857336 29630 solver.cpp:253]     Train net output #0: loss = 5.14937 (* 1 = 5.14937 loss)
I0123 17:54:10.857342 29630 sgd_solver.cpp:106] Iteration 5820, lr = 0.01
I0123 17:54:18.097925 29630 solver.cpp:237] Iteration 5840, loss = 5.1876
I0123 17:54:18.097965 29630 solver.cpp:253]     Train net output #0: loss = 5.1876 (* 1 = 5.1876 loss)
I0123 17:54:18.097970 29630 sgd_solver.cpp:106] Iteration 5840, lr = 0.01
I0123 17:54:25.361044 29630 solver.cpp:237] Iteration 5860, loss = 5.16411
I0123 17:54:25.361083 29630 solver.cpp:253]     Train net output #0: loss = 5.16411 (* 1 = 5.16411 loss)
I0123 17:54:25.361088 29630 sgd_solver.cpp:106] Iteration 5860, lr = 0.01
I0123 17:54:32.593216 29630 solver.cpp:237] Iteration 5880, loss = 5.10766
I0123 17:54:32.593255 29630 solver.cpp:253]     Train net output #0: loss = 5.10766 (* 1 = 5.10766 loss)
I0123 17:54:32.593261 29630 sgd_solver.cpp:106] Iteration 5880, lr = 0.01
I0123 17:54:39.809242 29630 solver.cpp:237] Iteration 5900, loss = 5.10692
I0123 17:54:39.809402 29630 solver.cpp:253]     Train net output #0: loss = 5.10692 (* 1 = 5.10692 loss)
I0123 17:54:39.809411 29630 sgd_solver.cpp:106] Iteration 5900, lr = 0.01
I0123 17:54:47.051797 29630 solver.cpp:237] Iteration 5920, loss = 5.34275
I0123 17:54:47.051836 29630 solver.cpp:253]     Train net output #0: loss = 5.34275 (* 1 = 5.34275 loss)
I0123 17:54:47.051842 29630 sgd_solver.cpp:106] Iteration 5920, lr = 0.01
I0123 17:54:54.295194 29630 solver.cpp:237] Iteration 5940, loss = 5.13306
I0123 17:54:54.295231 29630 solver.cpp:253]     Train net output #0: loss = 5.13306 (* 1 = 5.13306 loss)
I0123 17:54:54.295238 29630 sgd_solver.cpp:106] Iteration 5940, lr = 0.01
I0123 17:55:01.510038 29630 solver.cpp:237] Iteration 5960, loss = 5.0274
I0123 17:55:01.510076 29630 solver.cpp:253]     Train net output #0: loss = 5.0274 (* 1 = 5.0274 loss)
I0123 17:55:01.510082 29630 sgd_solver.cpp:106] Iteration 5960, lr = 0.01
I0123 17:55:08.704953 29630 solver.cpp:237] Iteration 5980, loss = 5.08831
I0123 17:55:08.704991 29630 solver.cpp:253]     Train net output #0: loss = 5.08831 (* 1 = 5.08831 loss)
I0123 17:55:08.704998 29630 sgd_solver.cpp:106] Iteration 5980, lr = 0.01
I0123 17:55:15.609630 29630 solver.cpp:341] Iteration 6000, Testing net (#0)
I0123 17:55:18.022927 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 17:56:29.190523 29630 solver.cpp:409]     Test net output #0: accuracy = 0.0952402
I0123 17:56:29.190691 29630 solver.cpp:409]     Test net output #1: loss = 4.97432 (* 1 = 4.97432 loss)
I0123 17:56:29.231447 29630 solver.cpp:237] Iteration 6000, loss = 5.11027
I0123 17:56:29.231475 29630 solver.cpp:253]     Train net output #0: loss = 5.11027 (* 1 = 5.11027 loss)
I0123 17:56:29.231482 29630 sgd_solver.cpp:106] Iteration 6000, lr = 0.01
I0123 17:56:35.734277 29630 solver.cpp:237] Iteration 6020, loss = 5.11172
I0123 17:56:35.734315 29630 solver.cpp:253]     Train net output #0: loss = 5.11172 (* 1 = 5.11172 loss)
I0123 17:56:35.734320 29630 sgd_solver.cpp:106] Iteration 6020, lr = 0.01
I0123 17:56:41.909080 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 17:56:42.903551 29630 solver.cpp:237] Iteration 6040, loss = 5.14539
I0123 17:56:42.903591 29630 solver.cpp:253]     Train net output #0: loss = 5.14539 (* 1 = 5.14539 loss)
I0123 17:56:42.903597 29630 sgd_solver.cpp:106] Iteration 6040, lr = 0.01
I0123 17:56:50.134703 29630 solver.cpp:237] Iteration 6060, loss = 5.19164
I0123 17:56:50.134742 29630 solver.cpp:253]     Train net output #0: loss = 5.19164 (* 1 = 5.19164 loss)
I0123 17:56:50.134748 29630 sgd_solver.cpp:106] Iteration 6060, lr = 0.01
I0123 17:56:57.369104 29630 solver.cpp:237] Iteration 6080, loss = 5.2902
I0123 17:56:57.369141 29630 solver.cpp:253]     Train net output #0: loss = 5.2902 (* 1 = 5.2902 loss)
I0123 17:56:57.369148 29630 sgd_solver.cpp:106] Iteration 6080, lr = 0.01
I0123 17:57:04.593701 29630 solver.cpp:237] Iteration 6100, loss = 5.22933
I0123 17:57:04.593828 29630 solver.cpp:253]     Train net output #0: loss = 5.22933 (* 1 = 5.22933 loss)
I0123 17:57:04.593835 29630 sgd_solver.cpp:106] Iteration 6100, lr = 0.01
I0123 17:57:11.840474 29630 solver.cpp:237] Iteration 6120, loss = 5.08747
I0123 17:57:11.840512 29630 solver.cpp:253]     Train net output #0: loss = 5.08747 (* 1 = 5.08747 loss)
I0123 17:57:11.840518 29630 sgd_solver.cpp:106] Iteration 6120, lr = 0.01
I0123 17:57:19.088232 29630 solver.cpp:237] Iteration 6140, loss = 5.12582
I0123 17:57:19.088269 29630 solver.cpp:253]     Train net output #0: loss = 5.12582 (* 1 = 5.12582 loss)
I0123 17:57:19.088276 29630 sgd_solver.cpp:106] Iteration 6140, lr = 0.01
I0123 17:57:26.367691 29630 solver.cpp:237] Iteration 6160, loss = 5.22889
I0123 17:57:26.367729 29630 solver.cpp:253]     Train net output #0: loss = 5.22889 (* 1 = 5.22889 loss)
I0123 17:57:26.367735 29630 sgd_solver.cpp:106] Iteration 6160, lr = 0.01
I0123 17:57:33.721226 29630 solver.cpp:237] Iteration 6180, loss = 5.0731
I0123 17:57:33.721264 29630 solver.cpp:253]     Train net output #0: loss = 5.0731 (* 1 = 5.0731 loss)
I0123 17:57:33.721271 29630 sgd_solver.cpp:106] Iteration 6180, lr = 0.01
I0123 17:57:41.097637 29630 solver.cpp:237] Iteration 6200, loss = 5.21181
I0123 17:57:41.097803 29630 solver.cpp:253]     Train net output #0: loss = 5.21181 (* 1 = 5.21181 loss)
I0123 17:57:41.097811 29630 sgd_solver.cpp:106] Iteration 6200, lr = 0.01
I0123 17:57:48.469358 29630 solver.cpp:237] Iteration 6220, loss = 4.98377
I0123 17:57:48.469396 29630 solver.cpp:253]     Train net output #0: loss = 4.98377 (* 1 = 4.98377 loss)
I0123 17:57:48.469403 29630 sgd_solver.cpp:106] Iteration 6220, lr = 0.01
I0123 17:57:55.800431 29630 solver.cpp:237] Iteration 6240, loss = 5.12525
I0123 17:57:55.800468 29630 solver.cpp:253]     Train net output #0: loss = 5.12525 (* 1 = 5.12525 loss)
I0123 17:57:55.800475 29630 sgd_solver.cpp:106] Iteration 6240, lr = 0.01
I0123 17:58:03.158295 29630 solver.cpp:237] Iteration 6260, loss = 5.06699
I0123 17:58:03.158334 29630 solver.cpp:253]     Train net output #0: loss = 5.06699 (* 1 = 5.06699 loss)
I0123 17:58:03.158341 29630 sgd_solver.cpp:106] Iteration 6260, lr = 0.01
I0123 17:58:10.444643 29630 solver.cpp:237] Iteration 6280, loss = 5.181
I0123 17:58:10.444682 29630 solver.cpp:253]     Train net output #0: loss = 5.181 (* 1 = 5.181 loss)
I0123 17:58:10.444689 29630 sgd_solver.cpp:106] Iteration 6280, lr = 0.01
I0123 17:58:17.721374 29630 solver.cpp:237] Iteration 6300, loss = 5.14277
I0123 17:58:17.721520 29630 solver.cpp:253]     Train net output #0: loss = 5.14277 (* 1 = 5.14277 loss)
I0123 17:58:17.721529 29630 sgd_solver.cpp:106] Iteration 6300, lr = 0.01
I0123 17:58:24.971290 29630 solver.cpp:237] Iteration 6320, loss = 5.23326
I0123 17:58:24.971328 29630 solver.cpp:253]     Train net output #0: loss = 5.23326 (* 1 = 5.23326 loss)
I0123 17:58:24.971334 29630 sgd_solver.cpp:106] Iteration 6320, lr = 0.01
I0123 17:58:32.238301 29630 solver.cpp:237] Iteration 6340, loss = 5.13281
I0123 17:58:32.238339 29630 solver.cpp:253]     Train net output #0: loss = 5.13281 (* 1 = 5.13281 loss)
I0123 17:58:32.238344 29630 sgd_solver.cpp:106] Iteration 6340, lr = 0.01
I0123 17:58:39.451261 29630 solver.cpp:237] Iteration 6360, loss = 5.15427
I0123 17:58:39.451298 29630 solver.cpp:253]     Train net output #0: loss = 5.15427 (* 1 = 5.15427 loss)
I0123 17:58:39.451304 29630 sgd_solver.cpp:106] Iteration 6360, lr = 0.01
I0123 17:58:46.690773 29630 solver.cpp:237] Iteration 6380, loss = 5.24497
I0123 17:58:46.690822 29630 solver.cpp:253]     Train net output #0: loss = 5.24497 (* 1 = 5.24497 loss)
I0123 17:58:46.690837 29630 sgd_solver.cpp:106] Iteration 6380, lr = 0.01
I0123 17:58:53.934361 29630 solver.cpp:237] Iteration 6400, loss = 5.11476
I0123 17:58:53.934525 29630 solver.cpp:253]     Train net output #0: loss = 5.11476 (* 1 = 5.11476 loss)
I0123 17:58:53.934533 29630 sgd_solver.cpp:106] Iteration 6400, lr = 0.01
I0123 17:59:01.156752 29630 solver.cpp:237] Iteration 6420, loss = 5.16133
I0123 17:59:01.156790 29630 solver.cpp:253]     Train net output #0: loss = 5.16133 (* 1 = 5.16133 loss)
I0123 17:59:01.156796 29630 sgd_solver.cpp:106] Iteration 6420, lr = 0.01
I0123 17:59:08.388233 29630 solver.cpp:237] Iteration 6440, loss = 5.17831
I0123 17:59:08.388273 29630 solver.cpp:253]     Train net output #0: loss = 5.17831 (* 1 = 5.17831 loss)
I0123 17:59:08.388278 29630 sgd_solver.cpp:106] Iteration 6440, lr = 0.01
I0123 17:59:15.632494 29630 solver.cpp:237] Iteration 6460, loss = 5.15329
I0123 17:59:15.632532 29630 solver.cpp:253]     Train net output #0: loss = 5.15329 (* 1 = 5.15329 loss)
I0123 17:59:15.632539 29630 sgd_solver.cpp:106] Iteration 6460, lr = 0.01
I0123 17:59:22.799083 29630 solver.cpp:237] Iteration 6480, loss = 5.05447
I0123 17:59:22.799124 29630 solver.cpp:253]     Train net output #0: loss = 5.05447 (* 1 = 5.05447 loss)
I0123 17:59:22.799129 29630 sgd_solver.cpp:106] Iteration 6480, lr = 0.01
I0123 17:59:30.068215 29630 solver.cpp:237] Iteration 6500, loss = 5.23478
I0123 17:59:30.068392 29630 solver.cpp:253]     Train net output #0: loss = 5.23478 (* 1 = 5.23478 loss)
I0123 17:59:30.068399 29630 sgd_solver.cpp:106] Iteration 6500, lr = 0.01
I0123 17:59:37.328408 29630 solver.cpp:237] Iteration 6520, loss = 5.10771
I0123 17:59:37.328447 29630 solver.cpp:253]     Train net output #0: loss = 5.10771 (* 1 = 5.10771 loss)
I0123 17:59:37.328454 29630 sgd_solver.cpp:106] Iteration 6520, lr = 0.01
I0123 17:59:44.542582 29630 solver.cpp:237] Iteration 6540, loss = 4.89838
I0123 17:59:44.542619 29630 solver.cpp:253]     Train net output #0: loss = 4.89838 (* 1 = 4.89838 loss)
I0123 17:59:44.542626 29630 sgd_solver.cpp:106] Iteration 6540, lr = 0.01
I0123 17:59:51.780589 29630 solver.cpp:237] Iteration 6560, loss = 4.94172
I0123 17:59:51.780627 29630 solver.cpp:253]     Train net output #0: loss = 4.94172 (* 1 = 4.94172 loss)
I0123 17:59:51.780633 29630 sgd_solver.cpp:106] Iteration 6560, lr = 0.01
I0123 17:59:59.007375 29630 solver.cpp:237] Iteration 6580, loss = 5.04179
I0123 17:59:59.007413 29630 solver.cpp:253]     Train net output #0: loss = 5.04179 (* 1 = 5.04179 loss)
I0123 17:59:59.007419 29630 sgd_solver.cpp:106] Iteration 6580, lr = 0.01
I0123 18:00:06.252607 29630 solver.cpp:237] Iteration 6600, loss = 4.96164
I0123 18:00:06.252703 29630 solver.cpp:253]     Train net output #0: loss = 4.96164 (* 1 = 4.96164 loss)
I0123 18:00:06.252712 29630 sgd_solver.cpp:106] Iteration 6600, lr = 0.01
I0123 18:00:13.513789 29630 solver.cpp:237] Iteration 6620, loss = 5.04376
I0123 18:00:13.513828 29630 solver.cpp:253]     Train net output #0: loss = 5.04376 (* 1 = 5.04376 loss)
I0123 18:00:13.513833 29630 sgd_solver.cpp:106] Iteration 6620, lr = 0.01
I0123 18:00:20.751313 29630 solver.cpp:237] Iteration 6640, loss = 5.16078
I0123 18:00:20.751353 29630 solver.cpp:253]     Train net output #0: loss = 5.16078 (* 1 = 5.16078 loss)
I0123 18:00:20.751361 29630 sgd_solver.cpp:106] Iteration 6640, lr = 0.01
I0123 18:00:27.999219 29630 solver.cpp:237] Iteration 6660, loss = 4.9239
I0123 18:00:27.999258 29630 solver.cpp:253]     Train net output #0: loss = 4.9239 (* 1 = 4.9239 loss)
I0123 18:00:27.999264 29630 sgd_solver.cpp:106] Iteration 6660, lr = 0.01
I0123 18:00:35.244150 29630 solver.cpp:237] Iteration 6680, loss = 4.9822
I0123 18:00:35.244189 29630 solver.cpp:253]     Train net output #0: loss = 4.9822 (* 1 = 4.9822 loss)
I0123 18:00:35.244194 29630 sgd_solver.cpp:106] Iteration 6680, lr = 0.01
I0123 18:00:42.509925 29630 solver.cpp:237] Iteration 6700, loss = 5.0426
I0123 18:00:42.510090 29630 solver.cpp:253]     Train net output #0: loss = 5.0426 (* 1 = 5.0426 loss)
I0123 18:00:42.510098 29630 sgd_solver.cpp:106] Iteration 6700, lr = 0.01
I0123 18:00:49.746925 29630 solver.cpp:237] Iteration 6720, loss = 5.22847
I0123 18:00:49.746964 29630 solver.cpp:253]     Train net output #0: loss = 5.22847 (* 1 = 5.22847 loss)
I0123 18:00:49.746970 29630 sgd_solver.cpp:106] Iteration 6720, lr = 0.01
I0123 18:00:57.015820 29630 solver.cpp:237] Iteration 6740, loss = 5.19303
I0123 18:00:57.015874 29630 solver.cpp:253]     Train net output #0: loss = 5.19303 (* 1 = 5.19303 loss)
I0123 18:00:57.015882 29630 sgd_solver.cpp:106] Iteration 6740, lr = 0.01
I0123 18:01:04.271278 29630 solver.cpp:237] Iteration 6760, loss = 4.97692
I0123 18:01:04.271317 29630 solver.cpp:253]     Train net output #0: loss = 4.97692 (* 1 = 4.97692 loss)
I0123 18:01:04.271323 29630 sgd_solver.cpp:106] Iteration 6760, lr = 0.01
I0123 18:01:11.527076 29630 solver.cpp:237] Iteration 6780, loss = 5.1174
I0123 18:01:11.527113 29630 solver.cpp:253]     Train net output #0: loss = 5.1174 (* 1 = 5.1174 loss)
I0123 18:01:11.527119 29630 sgd_solver.cpp:106] Iteration 6780, lr = 0.01
I0123 18:01:18.766100 29630 solver.cpp:237] Iteration 6800, loss = 5.22671
I0123 18:01:18.766243 29630 solver.cpp:253]     Train net output #0: loss = 5.22671 (* 1 = 5.22671 loss)
I0123 18:01:18.766252 29630 sgd_solver.cpp:106] Iteration 6800, lr = 0.01
I0123 18:01:26.030812 29630 solver.cpp:237] Iteration 6820, loss = 4.98078
I0123 18:01:26.030866 29630 solver.cpp:253]     Train net output #0: loss = 4.98078 (* 1 = 4.98078 loss)
I0123 18:01:26.030874 29630 sgd_solver.cpp:106] Iteration 6820, lr = 0.01
I0123 18:01:33.345613 29630 solver.cpp:237] Iteration 6840, loss = 4.92428
I0123 18:01:33.345651 29630 solver.cpp:253]     Train net output #0: loss = 4.92428 (* 1 = 4.92428 loss)
I0123 18:01:33.345657 29630 sgd_solver.cpp:106] Iteration 6840, lr = 0.01
I0123 18:01:40.627302 29630 solver.cpp:237] Iteration 6860, loss = 5.02852
I0123 18:01:40.627343 29630 solver.cpp:253]     Train net output #0: loss = 5.02852 (* 1 = 5.02852 loss)
I0123 18:01:40.627348 29630 sgd_solver.cpp:106] Iteration 6860, lr = 0.01
I0123 18:01:48.049046 29630 solver.cpp:237] Iteration 6880, loss = 5.23223
I0123 18:01:48.049087 29630 solver.cpp:253]     Train net output #0: loss = 5.23223 (* 1 = 5.23223 loss)
I0123 18:01:48.049093 29630 sgd_solver.cpp:106] Iteration 6880, lr = 0.01
I0123 18:01:55.461225 29630 solver.cpp:237] Iteration 6900, loss = 4.93094
I0123 18:01:55.461343 29630 solver.cpp:253]     Train net output #0: loss = 4.93094 (* 1 = 4.93094 loss)
I0123 18:01:55.461349 29630 sgd_solver.cpp:106] Iteration 6900, lr = 0.01
I0123 18:02:02.841778 29630 solver.cpp:237] Iteration 6920, loss = 4.7489
I0123 18:02:02.841816 29630 solver.cpp:253]     Train net output #0: loss = 4.7489 (* 1 = 4.7489 loss)
I0123 18:02:02.841822 29630 sgd_solver.cpp:106] Iteration 6920, lr = 0.01
I0123 18:02:10.174324 29630 solver.cpp:237] Iteration 6940, loss = 4.99941
I0123 18:02:10.174361 29630 solver.cpp:253]     Train net output #0: loss = 4.99941 (* 1 = 4.99941 loss)
I0123 18:02:10.174367 29630 sgd_solver.cpp:106] Iteration 6940, lr = 0.01
I0123 18:02:17.452090 29630 solver.cpp:237] Iteration 6960, loss = 4.9683
I0123 18:02:17.452128 29630 solver.cpp:253]     Train net output #0: loss = 4.9683 (* 1 = 4.9683 loss)
I0123 18:02:17.452134 29630 sgd_solver.cpp:106] Iteration 6960, lr = 0.01
I0123 18:02:24.768651 29630 solver.cpp:237] Iteration 6980, loss = 5.00644
I0123 18:02:24.768690 29630 solver.cpp:253]     Train net output #0: loss = 5.00644 (* 1 = 5.00644 loss)
I0123 18:02:24.768697 29630 sgd_solver.cpp:106] Iteration 6980, lr = 0.01
I0123 18:02:31.748741 29630 solver.cpp:341] Iteration 7000, Testing net (#0)
I0123 18:02:34.609269 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 18:03:45.489578 29630 solver.cpp:409]     Test net output #0: accuracy = 0.1054
I0123 18:03:45.489696 29630 solver.cpp:409]     Test net output #1: loss = 4.84247 (* 1 = 4.84247 loss)
I0123 18:03:45.530287 29630 solver.cpp:237] Iteration 7000, loss = 4.95206
I0123 18:03:45.530330 29630 solver.cpp:253]     Train net output #0: loss = 4.95206 (* 1 = 4.95206 loss)
I0123 18:03:45.530351 29630 sgd_solver.cpp:106] Iteration 7000, lr = 0.01
I0123 18:03:52.020231 29630 solver.cpp:237] Iteration 7020, loss = 5.00117
I0123 18:03:52.020270 29630 solver.cpp:253]     Train net output #0: loss = 5.00117 (* 1 = 5.00117 loss)
I0123 18:03:52.020277 29630 sgd_solver.cpp:106] Iteration 7020, lr = 0.01
I0123 18:03:59.254345 29630 solver.cpp:237] Iteration 7040, loss = 5.04848
I0123 18:03:59.254384 29630 solver.cpp:253]     Train net output #0: loss = 5.04848 (* 1 = 5.04848 loss)
I0123 18:03:59.254390 29630 sgd_solver.cpp:106] Iteration 7040, lr = 0.01
I0123 18:04:00.400168 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 18:04:06.510432 29630 solver.cpp:237] Iteration 7060, loss = 5.00975
I0123 18:04:06.510470 29630 solver.cpp:253]     Train net output #0: loss = 5.00975 (* 1 = 5.00975 loss)
I0123 18:04:06.510476 29630 sgd_solver.cpp:106] Iteration 7060, lr = 0.01
I0123 18:04:13.687266 29630 solver.cpp:237] Iteration 7080, loss = 4.90977
I0123 18:04:13.687304 29630 solver.cpp:253]     Train net output #0: loss = 4.90977 (* 1 = 4.90977 loss)
I0123 18:04:13.687310 29630 sgd_solver.cpp:106] Iteration 7080, lr = 0.01
I0123 18:04:20.890244 29630 solver.cpp:237] Iteration 7100, loss = 5.3148
I0123 18:04:20.890369 29630 solver.cpp:253]     Train net output #0: loss = 5.3148 (* 1 = 5.3148 loss)
I0123 18:04:20.890377 29630 sgd_solver.cpp:106] Iteration 7100, lr = 0.01
I0123 18:04:28.136664 29630 solver.cpp:237] Iteration 7120, loss = 4.88518
I0123 18:04:28.136705 29630 solver.cpp:253]     Train net output #0: loss = 4.88518 (* 1 = 4.88518 loss)
I0123 18:04:28.136713 29630 sgd_solver.cpp:106] Iteration 7120, lr = 0.01
I0123 18:04:35.488173 29630 solver.cpp:237] Iteration 7140, loss = 4.89964
I0123 18:04:35.488212 29630 solver.cpp:253]     Train net output #0: loss = 4.89964 (* 1 = 4.89964 loss)
I0123 18:04:35.488219 29630 sgd_solver.cpp:106] Iteration 7140, lr = 0.01
I0123 18:04:42.780711 29630 solver.cpp:237] Iteration 7160, loss = 5.03965
I0123 18:04:42.780748 29630 solver.cpp:253]     Train net output #0: loss = 5.03965 (* 1 = 5.03965 loss)
I0123 18:04:42.780755 29630 sgd_solver.cpp:106] Iteration 7160, lr = 0.01
I0123 18:04:50.030866 29630 solver.cpp:237] Iteration 7180, loss = 4.97251
I0123 18:04:50.030905 29630 solver.cpp:253]     Train net output #0: loss = 4.97251 (* 1 = 4.97251 loss)
I0123 18:04:50.030911 29630 sgd_solver.cpp:106] Iteration 7180, lr = 0.01
I0123 18:04:57.291147 29630 solver.cpp:237] Iteration 7200, loss = 5.01152
I0123 18:04:57.291324 29630 solver.cpp:253]     Train net output #0: loss = 5.01152 (* 1 = 5.01152 loss)
I0123 18:04:57.291333 29630 sgd_solver.cpp:106] Iteration 7200, lr = 0.01
I0123 18:05:04.536912 29630 solver.cpp:237] Iteration 7220, loss = 5.10747
I0123 18:05:04.536952 29630 solver.cpp:253]     Train net output #0: loss = 5.10747 (* 1 = 5.10747 loss)
I0123 18:05:04.536957 29630 sgd_solver.cpp:106] Iteration 7220, lr = 0.01
I0123 18:05:11.747562 29630 solver.cpp:237] Iteration 7240, loss = 4.83225
I0123 18:05:11.747601 29630 solver.cpp:253]     Train net output #0: loss = 4.83225 (* 1 = 4.83225 loss)
I0123 18:05:11.747606 29630 sgd_solver.cpp:106] Iteration 7240, lr = 0.01
I0123 18:05:19.077515 29630 solver.cpp:237] Iteration 7260, loss = 5.04217
I0123 18:05:19.077553 29630 solver.cpp:253]     Train net output #0: loss = 5.04217 (* 1 = 5.04217 loss)
I0123 18:05:19.077559 29630 sgd_solver.cpp:106] Iteration 7260, lr = 0.01
I0123 18:05:26.286932 29630 solver.cpp:237] Iteration 7280, loss = 5.17577
I0123 18:05:26.286968 29630 solver.cpp:253]     Train net output #0: loss = 5.17577 (* 1 = 5.17577 loss)
I0123 18:05:26.286975 29630 sgd_solver.cpp:106] Iteration 7280, lr = 0.01
I0123 18:05:33.573328 29630 solver.cpp:237] Iteration 7300, loss = 5.15337
I0123 18:05:33.573503 29630 solver.cpp:253]     Train net output #0: loss = 5.15337 (* 1 = 5.15337 loss)
I0123 18:05:33.573513 29630 sgd_solver.cpp:106] Iteration 7300, lr = 0.01
I0123 18:05:40.935916 29630 solver.cpp:237] Iteration 7320, loss = 4.69314
I0123 18:05:40.935953 29630 solver.cpp:253]     Train net output #0: loss = 4.69314 (* 1 = 4.69314 loss)
I0123 18:05:40.935961 29630 sgd_solver.cpp:106] Iteration 7320, lr = 0.01
I0123 18:05:48.298277 29630 solver.cpp:237] Iteration 7340, loss = 5.11234
I0123 18:05:48.298316 29630 solver.cpp:253]     Train net output #0: loss = 5.11234 (* 1 = 5.11234 loss)
I0123 18:05:48.298322 29630 sgd_solver.cpp:106] Iteration 7340, lr = 0.01
I0123 18:05:55.648476 29630 solver.cpp:237] Iteration 7360, loss = 5.02333
I0123 18:05:55.648514 29630 solver.cpp:253]     Train net output #0: loss = 5.02333 (* 1 = 5.02333 loss)
I0123 18:05:55.648521 29630 sgd_solver.cpp:106] Iteration 7360, lr = 0.01
I0123 18:06:03.012115 29630 solver.cpp:237] Iteration 7380, loss = 4.99704
I0123 18:06:03.012152 29630 solver.cpp:253]     Train net output #0: loss = 4.99704 (* 1 = 4.99704 loss)
I0123 18:06:03.012158 29630 sgd_solver.cpp:106] Iteration 7380, lr = 0.01
I0123 18:06:10.436362 29630 solver.cpp:237] Iteration 7400, loss = 4.85143
I0123 18:06:10.436535 29630 solver.cpp:253]     Train net output #0: loss = 4.85143 (* 1 = 4.85143 loss)
I0123 18:06:10.436543 29630 sgd_solver.cpp:106] Iteration 7400, lr = 0.01
I0123 18:06:17.743682 29630 solver.cpp:237] Iteration 7420, loss = 4.99952
I0123 18:06:17.743721 29630 solver.cpp:253]     Train net output #0: loss = 4.99952 (* 1 = 4.99952 loss)
I0123 18:06:17.743726 29630 sgd_solver.cpp:106] Iteration 7420, lr = 0.01
I0123 18:06:25.045320 29630 solver.cpp:237] Iteration 7440, loss = 5.15119
I0123 18:06:25.045367 29630 solver.cpp:253]     Train net output #0: loss = 5.15119 (* 1 = 5.15119 loss)
I0123 18:06:25.045374 29630 sgd_solver.cpp:106] Iteration 7440, lr = 0.01
I0123 18:06:32.318521 29630 solver.cpp:237] Iteration 7460, loss = 4.88835
I0123 18:06:32.318560 29630 solver.cpp:253]     Train net output #0: loss = 4.88835 (* 1 = 4.88835 loss)
I0123 18:06:32.318567 29630 sgd_solver.cpp:106] Iteration 7460, lr = 0.01
I0123 18:06:39.551456 29630 solver.cpp:237] Iteration 7480, loss = 4.79272
I0123 18:06:39.551507 29630 solver.cpp:253]     Train net output #0: loss = 4.79272 (* 1 = 4.79272 loss)
I0123 18:06:39.551514 29630 sgd_solver.cpp:106] Iteration 7480, lr = 0.01
I0123 18:06:46.790544 29630 solver.cpp:237] Iteration 7500, loss = 4.95679
I0123 18:06:46.790709 29630 solver.cpp:253]     Train net output #0: loss = 4.95679 (* 1 = 4.95679 loss)
I0123 18:06:46.790717 29630 sgd_solver.cpp:106] Iteration 7500, lr = 0.01
I0123 18:06:54.018535 29630 solver.cpp:237] Iteration 7520, loss = 4.9219
I0123 18:06:54.018574 29630 solver.cpp:253]     Train net output #0: loss = 4.9219 (* 1 = 4.9219 loss)
I0123 18:06:54.018580 29630 sgd_solver.cpp:106] Iteration 7520, lr = 0.01
I0123 18:07:01.244787 29630 solver.cpp:237] Iteration 7540, loss = 5.04997
I0123 18:07:01.244825 29630 solver.cpp:253]     Train net output #0: loss = 5.04997 (* 1 = 5.04997 loss)
I0123 18:07:01.244832 29630 sgd_solver.cpp:106] Iteration 7540, lr = 0.01
I0123 18:07:08.470197 29630 solver.cpp:237] Iteration 7560, loss = 4.85752
I0123 18:07:08.470237 29630 solver.cpp:253]     Train net output #0: loss = 4.85752 (* 1 = 4.85752 loss)
I0123 18:07:08.470242 29630 sgd_solver.cpp:106] Iteration 7560, lr = 0.01
I0123 18:07:15.662376 29630 solver.cpp:237] Iteration 7580, loss = 4.8503
I0123 18:07:15.662415 29630 solver.cpp:253]     Train net output #0: loss = 4.8503 (* 1 = 4.8503 loss)
I0123 18:07:15.662421 29630 sgd_solver.cpp:106] Iteration 7580, lr = 0.01
I0123 18:07:22.882032 29630 solver.cpp:237] Iteration 7600, loss = 5.14721
I0123 18:07:22.882205 29630 solver.cpp:253]     Train net output #0: loss = 5.14721 (* 1 = 5.14721 loss)
I0123 18:07:22.882212 29630 sgd_solver.cpp:106] Iteration 7600, lr = 0.01
I0123 18:07:30.093135 29630 solver.cpp:237] Iteration 7620, loss = 5.07002
I0123 18:07:30.093174 29630 solver.cpp:253]     Train net output #0: loss = 5.07002 (* 1 = 5.07002 loss)
I0123 18:07:30.093180 29630 sgd_solver.cpp:106] Iteration 7620, lr = 0.01
I0123 18:07:37.320168 29630 solver.cpp:237] Iteration 7640, loss = 4.92917
I0123 18:07:37.320207 29630 solver.cpp:253]     Train net output #0: loss = 4.92917 (* 1 = 4.92917 loss)
I0123 18:07:37.320214 29630 sgd_solver.cpp:106] Iteration 7640, lr = 0.01
I0123 18:07:44.528060 29630 solver.cpp:237] Iteration 7660, loss = 4.99319
I0123 18:07:44.528100 29630 solver.cpp:253]     Train net output #0: loss = 4.99319 (* 1 = 4.99319 loss)
I0123 18:07:44.528105 29630 sgd_solver.cpp:106] Iteration 7660, lr = 0.01
I0123 18:07:51.748036 29630 solver.cpp:237] Iteration 7680, loss = 4.95543
I0123 18:07:51.748075 29630 solver.cpp:253]     Train net output #0: loss = 4.95543 (* 1 = 4.95543 loss)
I0123 18:07:51.748081 29630 sgd_solver.cpp:106] Iteration 7680, lr = 0.01
I0123 18:07:58.975908 29630 solver.cpp:237] Iteration 7700, loss = 4.90264
I0123 18:07:58.976037 29630 solver.cpp:253]     Train net output #0: loss = 4.90264 (* 1 = 4.90264 loss)
I0123 18:07:58.976044 29630 sgd_solver.cpp:106] Iteration 7700, lr = 0.01
I0123 18:08:06.174800 29630 solver.cpp:237] Iteration 7720, loss = 4.92099
I0123 18:08:06.174839 29630 solver.cpp:253]     Train net output #0: loss = 4.92099 (* 1 = 4.92099 loss)
I0123 18:08:06.174845 29630 sgd_solver.cpp:106] Iteration 7720, lr = 0.01
I0123 18:08:13.406410 29630 solver.cpp:237] Iteration 7740, loss = 4.91279
I0123 18:08:13.406448 29630 solver.cpp:253]     Train net output #0: loss = 4.91279 (* 1 = 4.91279 loss)
I0123 18:08:13.406455 29630 sgd_solver.cpp:106] Iteration 7740, lr = 0.01
I0123 18:08:20.637300 29630 solver.cpp:237] Iteration 7760, loss = 4.87288
I0123 18:08:20.637338 29630 solver.cpp:253]     Train net output #0: loss = 4.87288 (* 1 = 4.87288 loss)
I0123 18:08:20.637346 29630 sgd_solver.cpp:106] Iteration 7760, lr = 0.01
I0123 18:08:27.882186 29630 solver.cpp:237] Iteration 7780, loss = 4.81216
I0123 18:08:27.882225 29630 solver.cpp:253]     Train net output #0: loss = 4.81216 (* 1 = 4.81216 loss)
I0123 18:08:27.882231 29630 sgd_solver.cpp:106] Iteration 7780, lr = 0.01
I0123 18:08:35.108516 29630 solver.cpp:237] Iteration 7800, loss = 4.83523
I0123 18:08:35.108669 29630 solver.cpp:253]     Train net output #0: loss = 4.83523 (* 1 = 4.83523 loss)
I0123 18:08:35.108677 29630 sgd_solver.cpp:106] Iteration 7800, lr = 0.01
I0123 18:08:42.341877 29630 solver.cpp:237] Iteration 7820, loss = 4.90622
I0123 18:08:42.341917 29630 solver.cpp:253]     Train net output #0: loss = 4.90622 (* 1 = 4.90622 loss)
I0123 18:08:42.341922 29630 sgd_solver.cpp:106] Iteration 7820, lr = 0.01
I0123 18:08:49.642114 29630 solver.cpp:237] Iteration 7840, loss = 4.84997
I0123 18:08:49.642153 29630 solver.cpp:253]     Train net output #0: loss = 4.84997 (* 1 = 4.84997 loss)
I0123 18:08:49.642158 29630 sgd_solver.cpp:106] Iteration 7840, lr = 0.01
I0123 18:08:56.890336 29630 solver.cpp:237] Iteration 7860, loss = 4.70355
I0123 18:08:56.890373 29630 solver.cpp:253]     Train net output #0: loss = 4.70355 (* 1 = 4.70355 loss)
I0123 18:08:56.890380 29630 sgd_solver.cpp:106] Iteration 7860, lr = 0.01
I0123 18:09:04.165304 29630 solver.cpp:237] Iteration 7880, loss = 5.06712
I0123 18:09:04.165343 29630 solver.cpp:253]     Train net output #0: loss = 5.06712 (* 1 = 5.06712 loss)
I0123 18:09:04.165349 29630 sgd_solver.cpp:106] Iteration 7880, lr = 0.01
I0123 18:09:11.384191 29630 solver.cpp:237] Iteration 7900, loss = 4.93924
I0123 18:09:11.384352 29630 solver.cpp:253]     Train net output #0: loss = 4.93924 (* 1 = 4.93924 loss)
I0123 18:09:11.384371 29630 sgd_solver.cpp:106] Iteration 7900, lr = 0.01
I0123 18:09:18.632313 29630 solver.cpp:237] Iteration 7920, loss = 4.83648
I0123 18:09:18.632350 29630 solver.cpp:253]     Train net output #0: loss = 4.83648 (* 1 = 4.83648 loss)
I0123 18:09:18.632356 29630 sgd_solver.cpp:106] Iteration 7920, lr = 0.01
I0123 18:09:25.911135 29630 solver.cpp:237] Iteration 7940, loss = 4.8804
I0123 18:09:25.911173 29630 solver.cpp:253]     Train net output #0: loss = 4.8804 (* 1 = 4.8804 loss)
I0123 18:09:25.911180 29630 sgd_solver.cpp:106] Iteration 7940, lr = 0.01
I0123 18:09:33.156334 29630 solver.cpp:237] Iteration 7960, loss = 4.80876
I0123 18:09:33.156373 29630 solver.cpp:253]     Train net output #0: loss = 4.80876 (* 1 = 4.80876 loss)
I0123 18:09:33.156380 29630 sgd_solver.cpp:106] Iteration 7960, lr = 0.01
I0123 18:09:40.438331 29630 solver.cpp:237] Iteration 7980, loss = 5.00353
I0123 18:09:40.438369 29630 solver.cpp:253]     Train net output #0: loss = 5.00353 (* 1 = 5.00353 loss)
I0123 18:09:40.438375 29630 sgd_solver.cpp:106] Iteration 7980, lr = 0.01
I0123 18:09:47.440042 29630 solver.cpp:341] Iteration 8000, Testing net (#0)
I0123 18:09:50.776821 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 18:11:01.724205 29630 solver.cpp:409]     Test net output #0: accuracy = 0.12084
I0123 18:11:01.724333 29630 solver.cpp:409]     Test net output #1: loss = 4.70388 (* 1 = 4.70388 loss)
I0123 18:11:01.764942 29630 solver.cpp:237] Iteration 8000, loss = 4.71346
I0123 18:11:01.764986 29630 solver.cpp:253]     Train net output #0: loss = 4.71346 (* 1 = 4.71346 loss)
I0123 18:11:01.764993 29630 sgd_solver.cpp:106] Iteration 8000, lr = 0.01
I0123 18:11:08.302233 29630 solver.cpp:237] Iteration 8020, loss = 4.93258
I0123 18:11:08.302294 29630 solver.cpp:253]     Train net output #0: loss = 4.93258 (* 1 = 4.93258 loss)
I0123 18:11:08.302306 29630 sgd_solver.cpp:106] Iteration 8020, lr = 0.01
I0123 18:11:15.584542 29630 solver.cpp:237] Iteration 8040, loss = 4.74687
I0123 18:11:15.584580 29630 solver.cpp:253]     Train net output #0: loss = 4.74687 (* 1 = 4.74687 loss)
I0123 18:11:15.584586 29630 sgd_solver.cpp:106] Iteration 8040, lr = 0.01
I0123 18:11:18.900333 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 18:11:22.800904 29630 solver.cpp:237] Iteration 8060, loss = 4.78194
I0123 18:11:22.800941 29630 solver.cpp:253]     Train net output #0: loss = 4.78194 (* 1 = 4.78194 loss)
I0123 18:11:22.800948 29630 sgd_solver.cpp:106] Iteration 8060, lr = 0.01
I0123 18:11:30.023326 29630 solver.cpp:237] Iteration 8080, loss = 4.89183
I0123 18:11:30.023365 29630 solver.cpp:253]     Train net output #0: loss = 4.89183 (* 1 = 4.89183 loss)
I0123 18:11:30.023370 29630 sgd_solver.cpp:106] Iteration 8080, lr = 0.01
I0123 18:11:37.274305 29630 solver.cpp:237] Iteration 8100, loss = 5.10332
I0123 18:11:37.274427 29630 solver.cpp:253]     Train net output #0: loss = 5.10332 (* 1 = 5.10332 loss)
I0123 18:11:37.274435 29630 sgd_solver.cpp:106] Iteration 8100, lr = 0.01
I0123 18:11:44.573768 29630 solver.cpp:237] Iteration 8120, loss = 4.84407
I0123 18:11:44.573807 29630 solver.cpp:253]     Train net output #0: loss = 4.84407 (* 1 = 4.84407 loss)
I0123 18:11:44.573812 29630 sgd_solver.cpp:106] Iteration 8120, lr = 0.01
I0123 18:11:51.808390 29630 solver.cpp:237] Iteration 8140, loss = 4.91328
I0123 18:11:51.808429 29630 solver.cpp:253]     Train net output #0: loss = 4.91328 (* 1 = 4.91328 loss)
I0123 18:11:51.808435 29630 sgd_solver.cpp:106] Iteration 8140, lr = 0.01
I0123 18:11:59.025321 29630 solver.cpp:237] Iteration 8160, loss = 4.68834
I0123 18:11:59.025359 29630 solver.cpp:253]     Train net output #0: loss = 4.68834 (* 1 = 4.68834 loss)
I0123 18:11:59.025365 29630 sgd_solver.cpp:106] Iteration 8160, lr = 0.01
I0123 18:12:06.262684 29630 solver.cpp:237] Iteration 8180, loss = 4.86174
I0123 18:12:06.262722 29630 solver.cpp:253]     Train net output #0: loss = 4.86174 (* 1 = 4.86174 loss)
I0123 18:12:06.262728 29630 sgd_solver.cpp:106] Iteration 8180, lr = 0.01
I0123 18:12:13.504081 29630 solver.cpp:237] Iteration 8200, loss = 4.91508
I0123 18:12:13.504176 29630 solver.cpp:253]     Train net output #0: loss = 4.91508 (* 1 = 4.91508 loss)
I0123 18:12:13.504184 29630 sgd_solver.cpp:106] Iteration 8200, lr = 0.01
I0123 18:12:20.721652 29630 solver.cpp:237] Iteration 8220, loss = 4.80421
I0123 18:12:20.721688 29630 solver.cpp:253]     Train net output #0: loss = 4.80421 (* 1 = 4.80421 loss)
I0123 18:12:20.721694 29630 sgd_solver.cpp:106] Iteration 8220, lr = 0.01
I0123 18:12:27.926188 29630 solver.cpp:237] Iteration 8240, loss = 4.70356
I0123 18:12:27.926228 29630 solver.cpp:253]     Train net output #0: loss = 4.70356 (* 1 = 4.70356 loss)
I0123 18:12:27.926234 29630 sgd_solver.cpp:106] Iteration 8240, lr = 0.01
I0123 18:12:35.177845 29630 solver.cpp:237] Iteration 8260, loss = 4.8518
I0123 18:12:35.177884 29630 solver.cpp:253]     Train net output #0: loss = 4.8518 (* 1 = 4.8518 loss)
I0123 18:12:35.177891 29630 sgd_solver.cpp:106] Iteration 8260, lr = 0.01
I0123 18:12:42.409915 29630 solver.cpp:237] Iteration 8280, loss = 4.91891
I0123 18:12:42.409953 29630 solver.cpp:253]     Train net output #0: loss = 4.91891 (* 1 = 4.91891 loss)
I0123 18:12:42.409960 29630 sgd_solver.cpp:106] Iteration 8280, lr = 0.01
I0123 18:12:49.632923 29630 solver.cpp:237] Iteration 8300, loss = 4.88232
I0123 18:12:49.633050 29630 solver.cpp:253]     Train net output #0: loss = 4.88232 (* 1 = 4.88232 loss)
I0123 18:12:49.633059 29630 sgd_solver.cpp:106] Iteration 8300, lr = 0.01
I0123 18:12:56.853157 29630 solver.cpp:237] Iteration 8320, loss = 4.88334
I0123 18:12:56.853195 29630 solver.cpp:253]     Train net output #0: loss = 4.88334 (* 1 = 4.88334 loss)
I0123 18:12:56.853201 29630 sgd_solver.cpp:106] Iteration 8320, lr = 0.01
I0123 18:13:04.127030 29630 solver.cpp:237] Iteration 8340, loss = 4.86116
I0123 18:13:04.127069 29630 solver.cpp:253]     Train net output #0: loss = 4.86116 (* 1 = 4.86116 loss)
I0123 18:13:04.127075 29630 sgd_solver.cpp:106] Iteration 8340, lr = 0.01
I0123 18:13:11.377549 29630 solver.cpp:237] Iteration 8360, loss = 4.84747
I0123 18:13:11.377599 29630 solver.cpp:253]     Train net output #0: loss = 4.84747 (* 1 = 4.84747 loss)
I0123 18:13:11.377605 29630 sgd_solver.cpp:106] Iteration 8360, lr = 0.01
I0123 18:13:18.620822 29630 solver.cpp:237] Iteration 8380, loss = 4.75089
I0123 18:13:18.620859 29630 solver.cpp:253]     Train net output #0: loss = 4.75089 (* 1 = 4.75089 loss)
I0123 18:13:18.620867 29630 sgd_solver.cpp:106] Iteration 8380, lr = 0.01
I0123 18:13:25.871042 29630 solver.cpp:237] Iteration 8400, loss = 4.97166
I0123 18:13:25.871219 29630 solver.cpp:253]     Train net output #0: loss = 4.97166 (* 1 = 4.97166 loss)
I0123 18:13:25.871227 29630 sgd_solver.cpp:106] Iteration 8400, lr = 0.01
I0123 18:13:33.147814 29630 solver.cpp:237] Iteration 8420, loss = 4.50039
I0123 18:13:33.147851 29630 solver.cpp:253]     Train net output #0: loss = 4.50039 (* 1 = 4.50039 loss)
I0123 18:13:33.147858 29630 sgd_solver.cpp:106] Iteration 8420, lr = 0.01
I0123 18:13:40.366194 29630 solver.cpp:237] Iteration 8440, loss = 4.79232
I0123 18:13:40.366235 29630 solver.cpp:253]     Train net output #0: loss = 4.79232 (* 1 = 4.79232 loss)
I0123 18:13:40.366241 29630 sgd_solver.cpp:106] Iteration 8440, lr = 0.01
I0123 18:13:47.690196 29630 solver.cpp:237] Iteration 8460, loss = 5.02627
I0123 18:13:47.690237 29630 solver.cpp:253]     Train net output #0: loss = 5.02627 (* 1 = 5.02627 loss)
I0123 18:13:47.690243 29630 sgd_solver.cpp:106] Iteration 8460, lr = 0.01
I0123 18:13:54.948289 29630 solver.cpp:237] Iteration 8480, loss = 4.6999
I0123 18:13:54.948328 29630 solver.cpp:253]     Train net output #0: loss = 4.6999 (* 1 = 4.6999 loss)
I0123 18:13:54.948334 29630 sgd_solver.cpp:106] Iteration 8480, lr = 0.01
I0123 18:14:02.289577 29630 solver.cpp:237] Iteration 8500, loss = 4.92409
I0123 18:14:02.289764 29630 solver.cpp:253]     Train net output #0: loss = 4.92409 (* 1 = 4.92409 loss)
I0123 18:14:02.289772 29630 sgd_solver.cpp:106] Iteration 8500, lr = 0.01
I0123 18:14:09.545975 29630 solver.cpp:237] Iteration 8520, loss = 4.97241
I0123 18:14:09.546013 29630 solver.cpp:253]     Train net output #0: loss = 4.97241 (* 1 = 4.97241 loss)
I0123 18:14:09.546020 29630 sgd_solver.cpp:106] Iteration 8520, lr = 0.01
I0123 18:14:16.957659 29630 solver.cpp:237] Iteration 8540, loss = 4.74616
I0123 18:14:16.957695 29630 solver.cpp:253]     Train net output #0: loss = 4.74616 (* 1 = 4.74616 loss)
I0123 18:14:16.957701 29630 sgd_solver.cpp:106] Iteration 8540, lr = 0.01
I0123 18:14:24.255975 29630 solver.cpp:237] Iteration 8560, loss = 4.93073
I0123 18:14:24.256013 29630 solver.cpp:253]     Train net output #0: loss = 4.93073 (* 1 = 4.93073 loss)
I0123 18:14:24.256019 29630 sgd_solver.cpp:106] Iteration 8560, lr = 0.01
I0123 18:14:31.688185 29630 solver.cpp:237] Iteration 8580, loss = 5.07387
I0123 18:14:31.688222 29630 solver.cpp:253]     Train net output #0: loss = 5.07387 (* 1 = 5.07387 loss)
I0123 18:14:31.688230 29630 sgd_solver.cpp:106] Iteration 8580, lr = 0.01
I0123 18:14:38.969739 29630 solver.cpp:237] Iteration 8600, loss = 4.94902
I0123 18:14:38.969903 29630 solver.cpp:253]     Train net output #0: loss = 4.94902 (* 1 = 4.94902 loss)
I0123 18:14:38.969913 29630 sgd_solver.cpp:106] Iteration 8600, lr = 0.01
I0123 18:14:46.293627 29630 solver.cpp:237] Iteration 8620, loss = 4.78569
I0123 18:14:46.293663 29630 solver.cpp:253]     Train net output #0: loss = 4.78569 (* 1 = 4.78569 loss)
I0123 18:14:46.293670 29630 sgd_solver.cpp:106] Iteration 8620, lr = 0.01
I0123 18:14:53.580476 29630 solver.cpp:237] Iteration 8640, loss = 4.91919
I0123 18:14:53.580518 29630 solver.cpp:253]     Train net output #0: loss = 4.91919 (* 1 = 4.91919 loss)
I0123 18:14:53.580523 29630 sgd_solver.cpp:106] Iteration 8640, lr = 0.01
I0123 18:15:00.797034 29630 solver.cpp:237] Iteration 8660, loss = 4.72641
I0123 18:15:00.797072 29630 solver.cpp:253]     Train net output #0: loss = 4.72641 (* 1 = 4.72641 loss)
I0123 18:15:00.797078 29630 sgd_solver.cpp:106] Iteration 8660, lr = 0.01
I0123 18:15:07.970631 29630 solver.cpp:237] Iteration 8680, loss = 4.70289
I0123 18:15:07.970670 29630 solver.cpp:253]     Train net output #0: loss = 4.70289 (* 1 = 4.70289 loss)
I0123 18:15:07.970676 29630 sgd_solver.cpp:106] Iteration 8680, lr = 0.01
I0123 18:15:15.204735 29630 solver.cpp:237] Iteration 8700, loss = 4.96054
I0123 18:15:15.204911 29630 solver.cpp:253]     Train net output #0: loss = 4.96054 (* 1 = 4.96054 loss)
I0123 18:15:15.204919 29630 sgd_solver.cpp:106] Iteration 8700, lr = 0.01
I0123 18:15:22.457869 29630 solver.cpp:237] Iteration 8720, loss = 4.78536
I0123 18:15:22.457906 29630 solver.cpp:253]     Train net output #0: loss = 4.78536 (* 1 = 4.78536 loss)
I0123 18:15:22.457913 29630 sgd_solver.cpp:106] Iteration 8720, lr = 0.01
I0123 18:15:29.700213 29630 solver.cpp:237] Iteration 8740, loss = 4.60546
I0123 18:15:29.700251 29630 solver.cpp:253]     Train net output #0: loss = 4.60546 (* 1 = 4.60546 loss)
I0123 18:15:29.700258 29630 sgd_solver.cpp:106] Iteration 8740, lr = 0.01
I0123 18:15:36.898609 29630 solver.cpp:237] Iteration 8760, loss = 4.6419
I0123 18:15:36.898648 29630 solver.cpp:253]     Train net output #0: loss = 4.6419 (* 1 = 4.6419 loss)
I0123 18:15:36.898654 29630 sgd_solver.cpp:106] Iteration 8760, lr = 0.01
I0123 18:15:44.137928 29630 solver.cpp:237] Iteration 8780, loss = 4.65249
I0123 18:15:44.137966 29630 solver.cpp:253]     Train net output #0: loss = 4.65249 (* 1 = 4.65249 loss)
I0123 18:15:44.137972 29630 sgd_solver.cpp:106] Iteration 8780, lr = 0.01
I0123 18:15:51.341934 29630 solver.cpp:237] Iteration 8800, loss = 4.74531
I0123 18:15:51.342111 29630 solver.cpp:253]     Train net output #0: loss = 4.74531 (* 1 = 4.74531 loss)
I0123 18:15:51.342120 29630 sgd_solver.cpp:106] Iteration 8800, lr = 0.01
I0123 18:15:58.584043 29630 solver.cpp:237] Iteration 8820, loss = 4.81865
I0123 18:15:58.584081 29630 solver.cpp:253]     Train net output #0: loss = 4.81865 (* 1 = 4.81865 loss)
I0123 18:15:58.584087 29630 sgd_solver.cpp:106] Iteration 8820, lr = 0.01
I0123 18:16:05.801036 29630 solver.cpp:237] Iteration 8840, loss = 4.92733
I0123 18:16:05.801074 29630 solver.cpp:253]     Train net output #0: loss = 4.92733 (* 1 = 4.92733 loss)
I0123 18:16:05.801080 29630 sgd_solver.cpp:106] Iteration 8840, lr = 0.01
I0123 18:16:13.045889 29630 solver.cpp:237] Iteration 8860, loss = 4.83143
I0123 18:16:13.045931 29630 solver.cpp:253]     Train net output #0: loss = 4.83143 (* 1 = 4.83143 loss)
I0123 18:16:13.045938 29630 sgd_solver.cpp:106] Iteration 8860, lr = 0.01
I0123 18:16:20.287104 29630 solver.cpp:237] Iteration 8880, loss = 4.87923
I0123 18:16:20.287142 29630 solver.cpp:253]     Train net output #0: loss = 4.87923 (* 1 = 4.87923 loss)
I0123 18:16:20.287147 29630 sgd_solver.cpp:106] Iteration 8880, lr = 0.01
I0123 18:16:27.506184 29630 solver.cpp:237] Iteration 8900, loss = 4.72154
I0123 18:16:27.506304 29630 solver.cpp:253]     Train net output #0: loss = 4.72154 (* 1 = 4.72154 loss)
I0123 18:16:27.506321 29630 sgd_solver.cpp:106] Iteration 8900, lr = 0.01
I0123 18:16:34.723021 29630 solver.cpp:237] Iteration 8920, loss = 4.88057
I0123 18:16:34.723058 29630 solver.cpp:253]     Train net output #0: loss = 4.88057 (* 1 = 4.88057 loss)
I0123 18:16:34.723065 29630 sgd_solver.cpp:106] Iteration 8920, lr = 0.01
I0123 18:16:41.911801 29630 solver.cpp:237] Iteration 8940, loss = 4.6326
I0123 18:16:41.911841 29630 solver.cpp:253]     Train net output #0: loss = 4.6326 (* 1 = 4.6326 loss)
I0123 18:16:41.911849 29630 sgd_solver.cpp:106] Iteration 8940, lr = 0.01
I0123 18:16:49.176301 29630 solver.cpp:237] Iteration 8960, loss = 4.94111
I0123 18:16:49.176339 29630 solver.cpp:253]     Train net output #0: loss = 4.94111 (* 1 = 4.94111 loss)
I0123 18:16:49.176345 29630 sgd_solver.cpp:106] Iteration 8960, lr = 0.01
I0123 18:16:56.417623 29630 solver.cpp:237] Iteration 8980, loss = 4.75682
I0123 18:16:56.417659 29630 solver.cpp:253]     Train net output #0: loss = 4.75682 (* 1 = 4.75682 loss)
I0123 18:16:56.417665 29630 sgd_solver.cpp:106] Iteration 8980, lr = 0.01
I0123 18:17:03.356075 29630 solver.cpp:341] Iteration 9000, Testing net (#0)
I0123 18:17:07.094184 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 18:18:17.178774 29630 solver.cpp:409]     Test net output #0: accuracy = 0.127
I0123 18:18:17.178884 29630 solver.cpp:409]     Test net output #1: loss = 4.645 (* 1 = 4.645 loss)
I0123 18:18:17.219599 29630 solver.cpp:237] Iteration 9000, loss = 4.78022
I0123 18:18:17.219625 29630 solver.cpp:253]     Train net output #0: loss = 4.78022 (* 1 = 4.78022 loss)
I0123 18:18:17.219632 29630 sgd_solver.cpp:106] Iteration 9000, lr = 0.01
I0123 18:18:23.840258 29630 solver.cpp:237] Iteration 9020, loss = 4.61509
I0123 18:18:23.840298 29630 solver.cpp:253]     Train net output #0: loss = 4.61509 (* 1 = 4.61509 loss)
I0123 18:18:23.840304 29630 sgd_solver.cpp:106] Iteration 9020, lr = 0.01
I0123 18:18:31.174986 29630 solver.cpp:237] Iteration 9040, loss = 4.70976
I0123 18:18:31.175025 29630 solver.cpp:253]     Train net output #0: loss = 4.70976 (* 1 = 4.70976 loss)
I0123 18:18:31.175031 29630 sgd_solver.cpp:106] Iteration 9040, lr = 0.01
I0123 18:18:36.852979 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 18:18:38.590139 29630 solver.cpp:237] Iteration 9060, loss = 4.74023
I0123 18:18:38.590178 29630 solver.cpp:253]     Train net output #0: loss = 4.74023 (* 1 = 4.74023 loss)
I0123 18:18:38.590184 29630 sgd_solver.cpp:106] Iteration 9060, lr = 0.01
I0123 18:18:45.844552 29630 solver.cpp:237] Iteration 9080, loss = 4.85859
I0123 18:18:45.844590 29630 solver.cpp:253]     Train net output #0: loss = 4.85859 (* 1 = 4.85859 loss)
I0123 18:18:45.844596 29630 sgd_solver.cpp:106] Iteration 9080, lr = 0.01
I0123 18:18:53.137629 29630 solver.cpp:237] Iteration 9100, loss = 4.9281
I0123 18:18:53.137804 29630 solver.cpp:253]     Train net output #0: loss = 4.9281 (* 1 = 4.9281 loss)
I0123 18:18:53.137811 29630 sgd_solver.cpp:106] Iteration 9100, lr = 0.01
I0123 18:19:00.386484 29630 solver.cpp:237] Iteration 9120, loss = 4.66281
I0123 18:19:00.386523 29630 solver.cpp:253]     Train net output #0: loss = 4.66281 (* 1 = 4.66281 loss)
I0123 18:19:00.386529 29630 sgd_solver.cpp:106] Iteration 9120, lr = 0.01
I0123 18:19:07.631136 29630 solver.cpp:237] Iteration 9140, loss = 4.55926
I0123 18:19:07.631175 29630 solver.cpp:253]     Train net output #0: loss = 4.55926 (* 1 = 4.55926 loss)
I0123 18:19:07.631180 29630 sgd_solver.cpp:106] Iteration 9140, lr = 0.01
I0123 18:19:14.824623 29630 solver.cpp:237] Iteration 9160, loss = 5.06585
I0123 18:19:14.824661 29630 solver.cpp:253]     Train net output #0: loss = 5.06585 (* 1 = 5.06585 loss)
I0123 18:19:14.824668 29630 sgd_solver.cpp:106] Iteration 9160, lr = 0.01
I0123 18:19:22.084312 29630 solver.cpp:237] Iteration 9180, loss = 4.78604
I0123 18:19:22.084352 29630 solver.cpp:253]     Train net output #0: loss = 4.78604 (* 1 = 4.78604 loss)
I0123 18:19:22.084357 29630 sgd_solver.cpp:106] Iteration 9180, lr = 0.01
I0123 18:19:29.352630 29630 solver.cpp:237] Iteration 9200, loss = 4.60395
I0123 18:19:29.352800 29630 solver.cpp:253]     Train net output #0: loss = 4.60395 (* 1 = 4.60395 loss)
I0123 18:19:29.352808 29630 sgd_solver.cpp:106] Iteration 9200, lr = 0.01
I0123 18:19:36.554970 29630 solver.cpp:237] Iteration 9220, loss = 4.74018
I0123 18:19:36.555017 29630 solver.cpp:253]     Train net output #0: loss = 4.74018 (* 1 = 4.74018 loss)
I0123 18:19:36.555024 29630 sgd_solver.cpp:106] Iteration 9220, lr = 0.01
I0123 18:19:43.794507 29630 solver.cpp:237] Iteration 9240, loss = 5.07072
I0123 18:19:43.794545 29630 solver.cpp:253]     Train net output #0: loss = 5.07072 (* 1 = 5.07072 loss)
I0123 18:19:43.794551 29630 sgd_solver.cpp:106] Iteration 9240, lr = 0.01
I0123 18:19:51.070307 29630 solver.cpp:237] Iteration 9260, loss = 4.62228
I0123 18:19:51.070344 29630 solver.cpp:253]     Train net output #0: loss = 4.62228 (* 1 = 4.62228 loss)
I0123 18:19:51.070350 29630 sgd_solver.cpp:106] Iteration 9260, lr = 0.01
I0123 18:19:58.327167 29630 solver.cpp:237] Iteration 9280, loss = 4.80766
I0123 18:19:58.327205 29630 solver.cpp:253]     Train net output #0: loss = 4.80766 (* 1 = 4.80766 loss)
I0123 18:19:58.327213 29630 sgd_solver.cpp:106] Iteration 9280, lr = 0.01
I0123 18:20:05.570278 29630 solver.cpp:237] Iteration 9300, loss = 4.6773
I0123 18:20:05.570379 29630 solver.cpp:253]     Train net output #0: loss = 4.6773 (* 1 = 4.6773 loss)
I0123 18:20:05.570395 29630 sgd_solver.cpp:106] Iteration 9300, lr = 0.01
I0123 18:20:12.800918 29630 solver.cpp:237] Iteration 9320, loss = 4.67747
I0123 18:20:12.800971 29630 solver.cpp:253]     Train net output #0: loss = 4.67747 (* 1 = 4.67747 loss)
I0123 18:20:12.800978 29630 sgd_solver.cpp:106] Iteration 9320, lr = 0.01
I0123 18:20:20.016429 29630 solver.cpp:237] Iteration 9340, loss = 4.87449
I0123 18:20:20.016466 29630 solver.cpp:253]     Train net output #0: loss = 4.87449 (* 1 = 4.87449 loss)
I0123 18:20:20.016472 29630 sgd_solver.cpp:106] Iteration 9340, lr = 0.01
I0123 18:20:27.245584 29630 solver.cpp:237] Iteration 9360, loss = 4.84269
I0123 18:20:27.245622 29630 solver.cpp:253]     Train net output #0: loss = 4.84269 (* 1 = 4.84269 loss)
I0123 18:20:27.245630 29630 sgd_solver.cpp:106] Iteration 9360, lr = 0.01
I0123 18:20:34.468323 29630 solver.cpp:237] Iteration 9380, loss = 4.83278
I0123 18:20:34.468369 29630 solver.cpp:253]     Train net output #0: loss = 4.83278 (* 1 = 4.83278 loss)
I0123 18:20:34.468375 29630 sgd_solver.cpp:106] Iteration 9380, lr = 0.01
I0123 18:20:41.715085 29630 solver.cpp:237] Iteration 9400, loss = 4.95634
I0123 18:20:41.715222 29630 solver.cpp:253]     Train net output #0: loss = 4.95634 (* 1 = 4.95634 loss)
I0123 18:20:41.715240 29630 sgd_solver.cpp:106] Iteration 9400, lr = 0.01
I0123 18:20:48.938822 29630 solver.cpp:237] Iteration 9420, loss = 4.80059
I0123 18:20:48.938860 29630 solver.cpp:253]     Train net output #0: loss = 4.80059 (* 1 = 4.80059 loss)
I0123 18:20:48.938866 29630 sgd_solver.cpp:106] Iteration 9420, lr = 0.01
I0123 18:20:56.159428 29630 solver.cpp:237] Iteration 9440, loss = 4.74529
I0123 18:20:56.159468 29630 solver.cpp:253]     Train net output #0: loss = 4.74529 (* 1 = 4.74529 loss)
I0123 18:20:56.159484 29630 sgd_solver.cpp:106] Iteration 9440, lr = 0.01
I0123 18:21:03.363459 29630 solver.cpp:237] Iteration 9460, loss = 4.62721
I0123 18:21:03.363497 29630 solver.cpp:253]     Train net output #0: loss = 4.62721 (* 1 = 4.62721 loss)
I0123 18:21:03.363503 29630 sgd_solver.cpp:106] Iteration 9460, lr = 0.01
I0123 18:21:10.618598 29630 solver.cpp:237] Iteration 9480, loss = 4.72798
I0123 18:21:10.618638 29630 solver.cpp:253]     Train net output #0: loss = 4.72798 (* 1 = 4.72798 loss)
I0123 18:21:10.618643 29630 sgd_solver.cpp:106] Iteration 9480, lr = 0.01
I0123 18:21:17.842000 29630 solver.cpp:237] Iteration 9500, loss = 4.68973
I0123 18:21:17.842180 29630 solver.cpp:253]     Train net output #0: loss = 4.68973 (* 1 = 4.68973 loss)
I0123 18:21:17.842190 29630 sgd_solver.cpp:106] Iteration 9500, lr = 0.01
I0123 18:21:25.080579 29630 solver.cpp:237] Iteration 9520, loss = 4.74413
I0123 18:21:25.080627 29630 solver.cpp:253]     Train net output #0: loss = 4.74413 (* 1 = 4.74413 loss)
I0123 18:21:25.080636 29630 sgd_solver.cpp:106] Iteration 9520, lr = 0.01
I0123 18:21:32.296457 29630 solver.cpp:237] Iteration 9540, loss = 4.57951
I0123 18:21:32.296494 29630 solver.cpp:253]     Train net output #0: loss = 4.57951 (* 1 = 4.57951 loss)
I0123 18:21:32.296500 29630 sgd_solver.cpp:106] Iteration 9540, lr = 0.01
I0123 18:21:39.516755 29630 solver.cpp:237] Iteration 9560, loss = 4.63641
I0123 18:21:39.516794 29630 solver.cpp:253]     Train net output #0: loss = 4.63641 (* 1 = 4.63641 loss)
I0123 18:21:39.516800 29630 sgd_solver.cpp:106] Iteration 9560, lr = 0.01
I0123 18:21:46.734745 29630 solver.cpp:237] Iteration 9580, loss = 4.79244
I0123 18:21:46.734783 29630 solver.cpp:253]     Train net output #0: loss = 4.79244 (* 1 = 4.79244 loss)
I0123 18:21:46.734789 29630 sgd_solver.cpp:106] Iteration 9580, lr = 0.01
I0123 18:21:53.956811 29630 solver.cpp:237] Iteration 9600, loss = 4.7989
I0123 18:21:53.957007 29630 solver.cpp:253]     Train net output #0: loss = 4.7989 (* 1 = 4.7989 loss)
I0123 18:21:53.957015 29630 sgd_solver.cpp:106] Iteration 9600, lr = 0.01
I0123 18:22:01.236520 29630 solver.cpp:237] Iteration 9620, loss = 4.64035
I0123 18:22:01.236558 29630 solver.cpp:253]     Train net output #0: loss = 4.64035 (* 1 = 4.64035 loss)
I0123 18:22:01.236564 29630 sgd_solver.cpp:106] Iteration 9620, lr = 0.01
I0123 18:22:08.504310 29630 solver.cpp:237] Iteration 9640, loss = 4.85163
I0123 18:22:08.504348 29630 solver.cpp:253]     Train net output #0: loss = 4.85163 (* 1 = 4.85163 loss)
I0123 18:22:08.504354 29630 sgd_solver.cpp:106] Iteration 9640, lr = 0.01
I0123 18:22:15.783962 29630 solver.cpp:237] Iteration 9660, loss = 4.84324
I0123 18:22:15.784009 29630 solver.cpp:253]     Train net output #0: loss = 4.84324 (* 1 = 4.84324 loss)
I0123 18:22:15.784014 29630 sgd_solver.cpp:106] Iteration 9660, lr = 0.01
I0123 18:22:23.095587 29630 solver.cpp:237] Iteration 9680, loss = 4.66204
I0123 18:22:23.095625 29630 solver.cpp:253]     Train net output #0: loss = 4.66204 (* 1 = 4.66204 loss)
I0123 18:22:23.095631 29630 sgd_solver.cpp:106] Iteration 9680, lr = 0.01
I0123 18:22:30.465199 29630 solver.cpp:237] Iteration 9700, loss = 4.64706
I0123 18:22:30.465345 29630 solver.cpp:253]     Train net output #0: loss = 4.64706 (* 1 = 4.64706 loss)
I0123 18:22:30.465353 29630 sgd_solver.cpp:106] Iteration 9700, lr = 0.01
I0123 18:22:37.767698 29630 solver.cpp:237] Iteration 9720, loss = 4.63993
I0123 18:22:37.767736 29630 solver.cpp:253]     Train net output #0: loss = 4.63993 (* 1 = 4.63993 loss)
I0123 18:22:37.767742 29630 sgd_solver.cpp:106] Iteration 9720, lr = 0.01
I0123 18:22:45.177242 29630 solver.cpp:237] Iteration 9740, loss = 4.72477
I0123 18:22:45.177281 29630 solver.cpp:253]     Train net output #0: loss = 4.72477 (* 1 = 4.72477 loss)
I0123 18:22:45.177287 29630 sgd_solver.cpp:106] Iteration 9740, lr = 0.01
I0123 18:22:52.528650 29630 solver.cpp:237] Iteration 9760, loss = 4.6788
I0123 18:22:52.528687 29630 solver.cpp:253]     Train net output #0: loss = 4.6788 (* 1 = 4.6788 loss)
I0123 18:22:52.528693 29630 sgd_solver.cpp:106] Iteration 9760, lr = 0.01
I0123 18:22:59.750006 29630 solver.cpp:237] Iteration 9780, loss = 4.64211
I0123 18:22:59.750043 29630 solver.cpp:253]     Train net output #0: loss = 4.64211 (* 1 = 4.64211 loss)
I0123 18:22:59.750051 29630 sgd_solver.cpp:106] Iteration 9780, lr = 0.01
I0123 18:23:07.049988 29630 solver.cpp:237] Iteration 9800, loss = 4.74982
I0123 18:23:07.050158 29630 solver.cpp:253]     Train net output #0: loss = 4.74982 (* 1 = 4.74982 loss)
I0123 18:23:07.050166 29630 sgd_solver.cpp:106] Iteration 9800, lr = 0.01
I0123 18:23:14.281862 29630 solver.cpp:237] Iteration 9820, loss = 4.68905
I0123 18:23:14.281903 29630 solver.cpp:253]     Train net output #0: loss = 4.68905 (* 1 = 4.68905 loss)
I0123 18:23:14.281922 29630 sgd_solver.cpp:106] Iteration 9820, lr = 0.01
I0123 18:23:21.473371 29630 solver.cpp:237] Iteration 9840, loss = 4.7134
I0123 18:23:21.473409 29630 solver.cpp:253]     Train net output #0: loss = 4.7134 (* 1 = 4.7134 loss)
I0123 18:23:21.473415 29630 sgd_solver.cpp:106] Iteration 9840, lr = 0.01
I0123 18:23:28.773501 29630 solver.cpp:237] Iteration 9860, loss = 4.46946
I0123 18:23:28.773540 29630 solver.cpp:253]     Train net output #0: loss = 4.46946 (* 1 = 4.46946 loss)
I0123 18:23:28.773546 29630 sgd_solver.cpp:106] Iteration 9860, lr = 0.01
I0123 18:23:36.065829 29630 solver.cpp:237] Iteration 9880, loss = 4.98187
I0123 18:23:36.065868 29630 solver.cpp:253]     Train net output #0: loss = 4.98187 (* 1 = 4.98187 loss)
I0123 18:23:36.065873 29630 sgd_solver.cpp:106] Iteration 9880, lr = 0.01
I0123 18:23:43.313674 29630 solver.cpp:237] Iteration 9900, loss = 4.65381
I0123 18:23:43.313803 29630 solver.cpp:253]     Train net output #0: loss = 4.65381 (* 1 = 4.65381 loss)
I0123 18:23:43.313810 29630 sgd_solver.cpp:106] Iteration 9900, lr = 0.01
I0123 18:23:50.570941 29630 solver.cpp:237] Iteration 9920, loss = 4.56989
I0123 18:23:50.570981 29630 solver.cpp:253]     Train net output #0: loss = 4.56989 (* 1 = 4.56989 loss)
I0123 18:23:50.570986 29630 sgd_solver.cpp:106] Iteration 9920, lr = 0.01
I0123 18:23:57.841941 29630 solver.cpp:237] Iteration 9940, loss = 4.56695
I0123 18:23:57.841979 29630 solver.cpp:253]     Train net output #0: loss = 4.56695 (* 1 = 4.56695 loss)
I0123 18:23:57.841985 29630 sgd_solver.cpp:106] Iteration 9940, lr = 0.01
I0123 18:24:05.076716 29630 solver.cpp:237] Iteration 9960, loss = 4.67719
I0123 18:24:05.076755 29630 solver.cpp:253]     Train net output #0: loss = 4.67719 (* 1 = 4.67719 loss)
I0123 18:24:05.076761 29630 sgd_solver.cpp:106] Iteration 9960, lr = 0.01
I0123 18:24:12.346103 29630 solver.cpp:237] Iteration 9980, loss = 4.4197
I0123 18:24:12.346150 29630 solver.cpp:253]     Train net output #0: loss = 4.4197 (* 1 = 4.4197 loss)
I0123 18:24:12.346158 29630 sgd_solver.cpp:106] Iteration 9980, lr = 0.01
I0123 18:24:19.285135 29630 solver.cpp:459] Snapshotting to binary proto file snapshots/caffenet128_lsuv_ycrcb_iter_10000.caffemodel
I0123 18:24:19.518162 29630 sgd_solver.cpp:269] Snapshotting solver state to binary proto file snapshots/caffenet128_lsuv_ycrcb_iter_10000.solverstate
I0123 18:24:19.576741 29630 solver.cpp:341] Iteration 10000, Testing net (#0)
I0123 18:24:24.046103 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 18:25:33.941431 29630 solver.cpp:409]     Test net output #0: accuracy = 0.14792
I0123 18:25:33.941602 29630 solver.cpp:409]     Test net output #1: loss = 4.46059 (* 1 = 4.46059 loss)
I0123 18:25:33.981973 29630 solver.cpp:237] Iteration 10000, loss = 4.65394
I0123 18:25:33.982012 29630 solver.cpp:253]     Train net output #0: loss = 4.65394 (* 1 = 4.65394 loss)
I0123 18:25:33.982019 29630 sgd_solver.cpp:106] Iteration 10000, lr = 0.01
I0123 18:25:40.508589 29630 solver.cpp:237] Iteration 10020, loss = 4.88657
I0123 18:25:40.508623 29630 solver.cpp:253]     Train net output #0: loss = 4.88657 (* 1 = 4.88657 loss)
I0123 18:25:40.508630 29630 sgd_solver.cpp:106] Iteration 10020, lr = 0.01
I0123 18:25:47.733556 29630 solver.cpp:237] Iteration 10040, loss = 4.5339
I0123 18:25:47.733602 29630 solver.cpp:253]     Train net output #0: loss = 4.5339 (* 1 = 4.5339 loss)
I0123 18:25:47.733608 29630 sgd_solver.cpp:106] Iteration 10040, lr = 0.01
I0123 18:25:55.017942 29630 solver.cpp:237] Iteration 10060, loss = 4.63278
I0123 18:25:55.017982 29630 solver.cpp:253]     Train net output #0: loss = 4.63278 (* 1 = 4.63278 loss)
I0123 18:25:55.017987 29630 sgd_solver.cpp:106] Iteration 10060, lr = 0.01
I0123 18:25:55.444447 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 18:26:02.312800 29630 solver.cpp:237] Iteration 10080, loss = 4.68952
I0123 18:26:02.312839 29630 solver.cpp:253]     Train net output #0: loss = 4.68952 (* 1 = 4.68952 loss)
I0123 18:26:02.312846 29630 sgd_solver.cpp:106] Iteration 10080, lr = 0.01
I0123 18:26:09.670943 29630 solver.cpp:237] Iteration 10100, loss = 4.59958
I0123 18:26:09.671108 29630 solver.cpp:253]     Train net output #0: loss = 4.59958 (* 1 = 4.59958 loss)
I0123 18:26:09.671115 29630 sgd_solver.cpp:106] Iteration 10100, lr = 0.01
I0123 18:26:16.977267 29630 solver.cpp:237] Iteration 10120, loss = 4.63762
I0123 18:26:16.977306 29630 solver.cpp:253]     Train net output #0: loss = 4.63762 (* 1 = 4.63762 loss)
I0123 18:26:16.977313 29630 sgd_solver.cpp:106] Iteration 10120, lr = 0.01
I0123 18:26:24.276993 29630 solver.cpp:237] Iteration 10140, loss = 4.66481
I0123 18:26:24.277034 29630 solver.cpp:253]     Train net output #0: loss = 4.66481 (* 1 = 4.66481 loss)
I0123 18:26:24.277040 29630 sgd_solver.cpp:106] Iteration 10140, lr = 0.01
I0123 18:26:31.619734 29630 solver.cpp:237] Iteration 10160, loss = 4.41224
I0123 18:26:31.619771 29630 solver.cpp:253]     Train net output #0: loss = 4.41224 (* 1 = 4.41224 loss)
I0123 18:26:31.619776 29630 sgd_solver.cpp:106] Iteration 10160, lr = 0.01
I0123 18:26:38.976138 29630 solver.cpp:237] Iteration 10180, loss = 5.00002
I0123 18:26:38.976178 29630 solver.cpp:253]     Train net output #0: loss = 5.00002 (* 1 = 5.00002 loss)
I0123 18:26:38.976184 29630 sgd_solver.cpp:106] Iteration 10180, lr = 0.01
I0123 18:26:46.281973 29630 solver.cpp:237] Iteration 10200, loss = 4.46092
I0123 18:26:46.282104 29630 solver.cpp:253]     Train net output #0: loss = 4.46092 (* 1 = 4.46092 loss)
I0123 18:26:46.282121 29630 sgd_solver.cpp:106] Iteration 10200, lr = 0.01
I0123 18:26:53.664196 29630 solver.cpp:237] Iteration 10220, loss = 4.6764
I0123 18:26:53.664235 29630 solver.cpp:253]     Train net output #0: loss = 4.6764 (* 1 = 4.6764 loss)
I0123 18:26:53.664242 29630 sgd_solver.cpp:106] Iteration 10220, lr = 0.01
I0123 18:27:01.100520 29630 solver.cpp:237] Iteration 10240, loss = 4.76328
I0123 18:27:01.100560 29630 solver.cpp:253]     Train net output #0: loss = 4.76328 (* 1 = 4.76328 loss)
I0123 18:27:01.100566 29630 sgd_solver.cpp:106] Iteration 10240, lr = 0.01
I0123 18:27:08.436416 29630 solver.cpp:237] Iteration 10260, loss = 4.75905
I0123 18:27:08.436456 29630 solver.cpp:253]     Train net output #0: loss = 4.75905 (* 1 = 4.75905 loss)
I0123 18:27:08.436463 29630 sgd_solver.cpp:106] Iteration 10260, lr = 0.01
I0123 18:27:15.730001 29630 solver.cpp:237] Iteration 10280, loss = 4.85899
I0123 18:27:15.730039 29630 solver.cpp:253]     Train net output #0: loss = 4.85899 (* 1 = 4.85899 loss)
I0123 18:27:15.730046 29630 sgd_solver.cpp:106] Iteration 10280, lr = 0.01
I0123 18:27:22.985548 29630 solver.cpp:237] Iteration 10300, loss = 4.84164
I0123 18:27:22.985724 29630 solver.cpp:253]     Train net output #0: loss = 4.84164 (* 1 = 4.84164 loss)
I0123 18:27:22.985733 29630 sgd_solver.cpp:106] Iteration 10300, lr = 0.01
I0123 18:27:30.211338 29630 solver.cpp:237] Iteration 10320, loss = 4.41347
I0123 18:27:30.211400 29630 solver.cpp:253]     Train net output #0: loss = 4.41347 (* 1 = 4.41347 loss)
I0123 18:27:30.211413 29630 sgd_solver.cpp:106] Iteration 10320, lr = 0.01
I0123 18:27:37.472903 29630 solver.cpp:237] Iteration 10340, loss = 4.6093
I0123 18:27:37.472954 29630 solver.cpp:253]     Train net output #0: loss = 4.6093 (* 1 = 4.6093 loss)
I0123 18:27:37.472968 29630 sgd_solver.cpp:106] Iteration 10340, lr = 0.01
I0123 18:27:44.762224 29630 solver.cpp:237] Iteration 10360, loss = 4.41662
I0123 18:27:44.762265 29630 solver.cpp:253]     Train net output #0: loss = 4.41662 (* 1 = 4.41662 loss)
I0123 18:27:44.762271 29630 sgd_solver.cpp:106] Iteration 10360, lr = 0.01
I0123 18:27:52.061081 29630 solver.cpp:237] Iteration 10380, loss = 4.66655
I0123 18:27:52.061130 29630 solver.cpp:253]     Train net output #0: loss = 4.66655 (* 1 = 4.66655 loss)
I0123 18:27:52.061136 29630 sgd_solver.cpp:106] Iteration 10380, lr = 0.01
I0123 18:27:59.292862 29630 solver.cpp:237] Iteration 10400, loss = 4.70112
I0123 18:27:59.293010 29630 solver.cpp:253]     Train net output #0: loss = 4.70112 (* 1 = 4.70112 loss)
I0123 18:27:59.293018 29630 sgd_solver.cpp:106] Iteration 10400, lr = 0.01
I0123 18:28:06.544476 29630 solver.cpp:237] Iteration 10420, loss = 4.60971
I0123 18:28:06.544513 29630 solver.cpp:253]     Train net output #0: loss = 4.60971 (* 1 = 4.60971 loss)
I0123 18:28:06.544520 29630 sgd_solver.cpp:106] Iteration 10420, lr = 0.01
I0123 18:28:13.815654 29630 solver.cpp:237] Iteration 10440, loss = 4.62306
I0123 18:28:13.815691 29630 solver.cpp:253]     Train net output #0: loss = 4.62306 (* 1 = 4.62306 loss)
I0123 18:28:13.815697 29630 sgd_solver.cpp:106] Iteration 10440, lr = 0.01
I0123 18:28:21.032908 29630 solver.cpp:237] Iteration 10460, loss = 4.73908
I0123 18:28:21.032948 29630 solver.cpp:253]     Train net output #0: loss = 4.73908 (* 1 = 4.73908 loss)
I0123 18:28:21.032954 29630 sgd_solver.cpp:106] Iteration 10460, lr = 0.01
I0123 18:28:28.261881 29630 solver.cpp:237] Iteration 10480, loss = 4.27661
I0123 18:28:28.261919 29630 solver.cpp:253]     Train net output #0: loss = 4.27661 (* 1 = 4.27661 loss)
I0123 18:28:28.261924 29630 sgd_solver.cpp:106] Iteration 10480, lr = 0.01
I0123 18:28:35.546087 29630 solver.cpp:237] Iteration 10500, loss = 4.60444
I0123 18:28:35.546214 29630 solver.cpp:253]     Train net output #0: loss = 4.60444 (* 1 = 4.60444 loss)
I0123 18:28:35.546222 29630 sgd_solver.cpp:106] Iteration 10500, lr = 0.01
I0123 18:28:42.765671 29630 solver.cpp:237] Iteration 10520, loss = 4.56595
I0123 18:28:42.765708 29630 solver.cpp:253]     Train net output #0: loss = 4.56595 (* 1 = 4.56595 loss)
I0123 18:28:42.765715 29630 sgd_solver.cpp:106] Iteration 10520, lr = 0.01
I0123 18:28:49.972591 29630 solver.cpp:237] Iteration 10540, loss = 4.66438
I0123 18:28:49.972630 29630 solver.cpp:253]     Train net output #0: loss = 4.66438 (* 1 = 4.66438 loss)
I0123 18:28:49.972637 29630 sgd_solver.cpp:106] Iteration 10540, lr = 0.01
I0123 18:28:57.182560 29630 solver.cpp:237] Iteration 10560, loss = 4.38793
I0123 18:28:57.182598 29630 solver.cpp:253]     Train net output #0: loss = 4.38793 (* 1 = 4.38793 loss)
I0123 18:28:57.182605 29630 sgd_solver.cpp:106] Iteration 10560, lr = 0.01
I0123 18:29:04.422356 29630 solver.cpp:237] Iteration 10580, loss = 4.51197
I0123 18:29:04.422410 29630 solver.cpp:253]     Train net output #0: loss = 4.51197 (* 1 = 4.51197 loss)
I0123 18:29:04.422417 29630 sgd_solver.cpp:106] Iteration 10580, lr = 0.01
I0123 18:29:11.656746 29630 solver.cpp:237] Iteration 10600, loss = 4.63386
I0123 18:29:11.656868 29630 solver.cpp:253]     Train net output #0: loss = 4.63386 (* 1 = 4.63386 loss)
I0123 18:29:11.656875 29630 sgd_solver.cpp:106] Iteration 10600, lr = 0.01
I0123 18:29:18.919260 29630 solver.cpp:237] Iteration 10620, loss = 4.58369
I0123 18:29:18.919301 29630 solver.cpp:253]     Train net output #0: loss = 4.58369 (* 1 = 4.58369 loss)
I0123 18:29:18.919307 29630 sgd_solver.cpp:106] Iteration 10620, lr = 0.01
I0123 18:29:26.170189 29630 solver.cpp:237] Iteration 10640, loss = 4.52462
I0123 18:29:26.170238 29630 solver.cpp:253]     Train net output #0: loss = 4.52462 (* 1 = 4.52462 loss)
I0123 18:29:26.170253 29630 sgd_solver.cpp:106] Iteration 10640, lr = 0.01
I0123 18:29:33.362345 29630 solver.cpp:237] Iteration 10660, loss = 4.79707
I0123 18:29:33.362385 29630 solver.cpp:253]     Train net output #0: loss = 4.79707 (* 1 = 4.79707 loss)
I0123 18:29:33.362390 29630 sgd_solver.cpp:106] Iteration 10660, lr = 0.01
I0123 18:29:40.635519 29630 solver.cpp:237] Iteration 10680, loss = 4.57842
I0123 18:29:40.635558 29630 solver.cpp:253]     Train net output #0: loss = 4.57842 (* 1 = 4.57842 loss)
I0123 18:29:40.635565 29630 sgd_solver.cpp:106] Iteration 10680, lr = 0.01
I0123 18:29:47.897131 29630 solver.cpp:237] Iteration 10700, loss = 4.80306
I0123 18:29:47.897307 29630 solver.cpp:253]     Train net output #0: loss = 4.80306 (* 1 = 4.80306 loss)
I0123 18:29:47.897315 29630 sgd_solver.cpp:106] Iteration 10700, lr = 0.01
I0123 18:29:55.158013 29630 solver.cpp:237] Iteration 10720, loss = 4.63952
I0123 18:29:55.158052 29630 solver.cpp:253]     Train net output #0: loss = 4.63952 (* 1 = 4.63952 loss)
I0123 18:29:55.158058 29630 sgd_solver.cpp:106] Iteration 10720, lr = 0.01
I0123 18:30:02.411804 29630 solver.cpp:237] Iteration 10740, loss = 4.67339
I0123 18:30:02.411844 29630 solver.cpp:253]     Train net output #0: loss = 4.67339 (* 1 = 4.67339 loss)
I0123 18:30:02.411850 29630 sgd_solver.cpp:106] Iteration 10740, lr = 0.01
I0123 18:30:09.671701 29630 solver.cpp:237] Iteration 10760, loss = 4.53713
I0123 18:30:09.671741 29630 solver.cpp:253]     Train net output #0: loss = 4.53713 (* 1 = 4.53713 loss)
I0123 18:30:09.671746 29630 sgd_solver.cpp:106] Iteration 10760, lr = 0.01
I0123 18:30:16.951025 29630 solver.cpp:237] Iteration 10780, loss = 4.76671
I0123 18:30:16.951064 29630 solver.cpp:253]     Train net output #0: loss = 4.76671 (* 1 = 4.76671 loss)
I0123 18:30:16.951071 29630 sgd_solver.cpp:106] Iteration 10780, lr = 0.01
I0123 18:30:24.167708 29630 solver.cpp:237] Iteration 10800, loss = 4.56022
I0123 18:30:24.167881 29630 solver.cpp:253]     Train net output #0: loss = 4.56022 (* 1 = 4.56022 loss)
I0123 18:30:24.167888 29630 sgd_solver.cpp:106] Iteration 10800, lr = 0.01
I0123 18:30:31.477221 29630 solver.cpp:237] Iteration 10820, loss = 4.45269
I0123 18:30:31.477253 29630 solver.cpp:253]     Train net output #0: loss = 4.45269 (* 1 = 4.45269 loss)
I0123 18:30:31.477259 29630 sgd_solver.cpp:106] Iteration 10820, lr = 0.01
I0123 18:30:38.844372 29630 solver.cpp:237] Iteration 10840, loss = 4.60716
I0123 18:30:38.844411 29630 solver.cpp:253]     Train net output #0: loss = 4.60716 (* 1 = 4.60716 loss)
I0123 18:30:38.844418 29630 sgd_solver.cpp:106] Iteration 10840, lr = 0.01
I0123 18:30:46.150499 29630 solver.cpp:237] Iteration 10860, loss = 4.66692
I0123 18:30:46.150537 29630 solver.cpp:253]     Train net output #0: loss = 4.66692 (* 1 = 4.66692 loss)
I0123 18:30:46.150544 29630 sgd_solver.cpp:106] Iteration 10860, lr = 0.01
I0123 18:30:53.408874 29630 solver.cpp:237] Iteration 10880, loss = 4.37567
I0123 18:30:53.408923 29630 solver.cpp:253]     Train net output #0: loss = 4.37567 (* 1 = 4.37567 loss)
I0123 18:30:53.408938 29630 sgd_solver.cpp:106] Iteration 10880, lr = 0.01
I0123 18:31:00.708356 29630 solver.cpp:237] Iteration 10900, loss = 4.43779
I0123 18:31:00.708477 29630 solver.cpp:253]     Train net output #0: loss = 4.43779 (* 1 = 4.43779 loss)
I0123 18:31:00.708483 29630 sgd_solver.cpp:106] Iteration 10900, lr = 0.01
I0123 18:31:08.088565 29630 solver.cpp:237] Iteration 10920, loss = 4.48509
I0123 18:31:08.088603 29630 solver.cpp:253]     Train net output #0: loss = 4.48509 (* 1 = 4.48509 loss)
I0123 18:31:08.088609 29630 sgd_solver.cpp:106] Iteration 10920, lr = 0.01
I0123 18:31:15.430433 29630 solver.cpp:237] Iteration 10940, loss = 4.56861
I0123 18:31:15.430471 29630 solver.cpp:253]     Train net output #0: loss = 4.56861 (* 1 = 4.56861 loss)
I0123 18:31:15.430476 29630 sgd_solver.cpp:106] Iteration 10940, lr = 0.01
I0123 18:31:22.761339 29630 solver.cpp:237] Iteration 10960, loss = 4.35558
I0123 18:31:22.761379 29630 solver.cpp:253]     Train net output #0: loss = 4.35558 (* 1 = 4.35558 loss)
I0123 18:31:22.761384 29630 sgd_solver.cpp:106] Iteration 10960, lr = 0.01
I0123 18:31:30.029258 29630 solver.cpp:237] Iteration 10980, loss = 4.53923
I0123 18:31:30.029295 29630 solver.cpp:253]     Train net output #0: loss = 4.53923 (* 1 = 4.53923 loss)
I0123 18:31:30.029301 29630 sgd_solver.cpp:106] Iteration 10980, lr = 0.01
I0123 18:31:36.968845 29630 solver.cpp:341] Iteration 11000, Testing net (#0)
I0123 18:31:41.612491 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 18:32:50.886549 29630 solver.cpp:409]     Test net output #0: accuracy = 0.15478
I0123 18:32:50.886721 29630 solver.cpp:409]     Test net output #1: loss = 4.38655 (* 1 = 4.38655 loss)
I0123 18:32:50.927458 29630 solver.cpp:237] Iteration 11000, loss = 4.58342
I0123 18:32:50.927494 29630 solver.cpp:253]     Train net output #0: loss = 4.58342 (* 1 = 4.58342 loss)
I0123 18:32:50.927500 29630 sgd_solver.cpp:106] Iteration 11000, lr = 0.01
I0123 18:32:57.445113 29630 solver.cpp:237] Iteration 11020, loss = 4.36017
I0123 18:32:57.445152 29630 solver.cpp:253]     Train net output #0: loss = 4.36017 (* 1 = 4.36017 loss)
I0123 18:32:57.445158 29630 sgd_solver.cpp:106] Iteration 11020, lr = 0.01
I0123 18:33:04.616703 29630 solver.cpp:237] Iteration 11040, loss = 4.94995
I0123 18:33:04.616750 29630 solver.cpp:253]     Train net output #0: loss = 4.94995 (* 1 = 4.94995 loss)
I0123 18:33:04.616756 29630 sgd_solver.cpp:106] Iteration 11040, lr = 0.01
I0123 18:33:11.832417 29630 solver.cpp:237] Iteration 11060, loss = 4.49121
I0123 18:33:11.832455 29630 solver.cpp:253]     Train net output #0: loss = 4.49121 (* 1 = 4.49121 loss)
I0123 18:33:11.832461 29630 sgd_solver.cpp:106] Iteration 11060, lr = 0.01
I0123 18:33:14.422056 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 18:33:19.050460 29630 solver.cpp:237] Iteration 11080, loss = 4.57592
I0123 18:33:19.050499 29630 solver.cpp:253]     Train net output #0: loss = 4.57592 (* 1 = 4.57592 loss)
I0123 18:33:19.050505 29630 sgd_solver.cpp:106] Iteration 11080, lr = 0.01
I0123 18:33:26.280884 29630 solver.cpp:237] Iteration 11100, loss = 4.48884
I0123 18:33:26.281062 29630 solver.cpp:253]     Train net output #0: loss = 4.48884 (* 1 = 4.48884 loss)
I0123 18:33:26.281070 29630 sgd_solver.cpp:106] Iteration 11100, lr = 0.01
I0123 18:33:33.519605 29630 solver.cpp:237] Iteration 11120, loss = 4.57285
I0123 18:33:33.519645 29630 solver.cpp:253]     Train net output #0: loss = 4.57285 (* 1 = 4.57285 loss)
I0123 18:33:33.519651 29630 sgd_solver.cpp:106] Iteration 11120, lr = 0.01
I0123 18:33:40.777137 29630 solver.cpp:237] Iteration 11140, loss = 4.59853
I0123 18:33:40.777175 29630 solver.cpp:253]     Train net output #0: loss = 4.59853 (* 1 = 4.59853 loss)
I0123 18:33:40.777182 29630 sgd_solver.cpp:106] Iteration 11140, lr = 0.01
I0123 18:33:47.996944 29630 solver.cpp:237] Iteration 11160, loss = 4.67014
I0123 18:33:47.996984 29630 solver.cpp:253]     Train net output #0: loss = 4.67014 (* 1 = 4.67014 loss)
I0123 18:33:47.996990 29630 sgd_solver.cpp:106] Iteration 11160, lr = 0.01
I0123 18:33:55.244467 29630 solver.cpp:237] Iteration 11180, loss = 4.38957
I0123 18:33:55.244504 29630 solver.cpp:253]     Train net output #0: loss = 4.38957 (* 1 = 4.38957 loss)
I0123 18:33:55.244511 29630 sgd_solver.cpp:106] Iteration 11180, lr = 0.01
I0123 18:34:02.475770 29630 solver.cpp:237] Iteration 11200, loss = 4.65637
I0123 18:34:02.475949 29630 solver.cpp:253]     Train net output #0: loss = 4.65637 (* 1 = 4.65637 loss)
I0123 18:34:02.475957 29630 sgd_solver.cpp:106] Iteration 11200, lr = 0.01
I0123 18:34:09.691578 29630 solver.cpp:237] Iteration 11220, loss = 4.46292
I0123 18:34:09.691617 29630 solver.cpp:253]     Train net output #0: loss = 4.46292 (* 1 = 4.46292 loss)
I0123 18:34:09.691623 29630 sgd_solver.cpp:106] Iteration 11220, lr = 0.01
I0123 18:34:16.914513 29630 solver.cpp:237] Iteration 11240, loss = 4.29921
I0123 18:34:16.914552 29630 solver.cpp:253]     Train net output #0: loss = 4.29921 (* 1 = 4.29921 loss)
I0123 18:34:16.914559 29630 sgd_solver.cpp:106] Iteration 11240, lr = 0.01
I0123 18:34:24.222210 29630 solver.cpp:237] Iteration 11260, loss = 4.35804
I0123 18:34:24.222256 29630 solver.cpp:253]     Train net output #0: loss = 4.35804 (* 1 = 4.35804 loss)
I0123 18:34:24.222262 29630 sgd_solver.cpp:106] Iteration 11260, lr = 0.01
I0123 18:34:31.564671 29630 solver.cpp:237] Iteration 11280, loss = 4.78252
I0123 18:34:31.564709 29630 solver.cpp:253]     Train net output #0: loss = 4.78252 (* 1 = 4.78252 loss)
I0123 18:34:31.564715 29630 sgd_solver.cpp:106] Iteration 11280, lr = 0.01
I0123 18:34:38.871289 29630 solver.cpp:237] Iteration 11300, loss = 4.49467
I0123 18:34:38.871434 29630 solver.cpp:253]     Train net output #0: loss = 4.49467 (* 1 = 4.49467 loss)
I0123 18:34:38.871443 29630 sgd_solver.cpp:106] Iteration 11300, lr = 0.01
I0123 18:34:46.174636 29630 solver.cpp:237] Iteration 11320, loss = 4.49256
I0123 18:34:46.174675 29630 solver.cpp:253]     Train net output #0: loss = 4.49256 (* 1 = 4.49256 loss)
I0123 18:34:46.174681 29630 sgd_solver.cpp:106] Iteration 11320, lr = 0.01
I0123 18:34:53.469745 29630 solver.cpp:237] Iteration 11340, loss = 4.39985
I0123 18:34:53.469784 29630 solver.cpp:253]     Train net output #0: loss = 4.39985 (* 1 = 4.39985 loss)
I0123 18:34:53.469789 29630 sgd_solver.cpp:106] Iteration 11340, lr = 0.01
I0123 18:35:00.723675 29630 solver.cpp:237] Iteration 11360, loss = 4.29373
I0123 18:35:00.723737 29630 solver.cpp:253]     Train net output #0: loss = 4.29373 (* 1 = 4.29373 loss)
I0123 18:35:00.723750 29630 sgd_solver.cpp:106] Iteration 11360, lr = 0.01
I0123 18:35:08.063714 29630 solver.cpp:237] Iteration 11380, loss = 4.46667
I0123 18:35:08.063745 29630 solver.cpp:253]     Train net output #0: loss = 4.46667 (* 1 = 4.46667 loss)
I0123 18:35:08.063751 29630 sgd_solver.cpp:106] Iteration 11380, lr = 0.01
I0123 18:35:15.460047 29630 solver.cpp:237] Iteration 11400, loss = 4.51143
I0123 18:35:15.460176 29630 solver.cpp:253]     Train net output #0: loss = 4.51143 (* 1 = 4.51143 loss)
I0123 18:35:15.460183 29630 sgd_solver.cpp:106] Iteration 11400, lr = 0.01
I0123 18:35:22.770941 29630 solver.cpp:237] Iteration 11420, loss = 4.35663
I0123 18:35:22.770980 29630 solver.cpp:253]     Train net output #0: loss = 4.35663 (* 1 = 4.35663 loss)
I0123 18:35:22.770987 29630 sgd_solver.cpp:106] Iteration 11420, lr = 0.01
I0123 18:35:30.085382 29630 solver.cpp:237] Iteration 11440, loss = 4.54123
I0123 18:35:30.085422 29630 solver.cpp:253]     Train net output #0: loss = 4.54123 (* 1 = 4.54123 loss)
I0123 18:35:30.085427 29630 sgd_solver.cpp:106] Iteration 11440, lr = 0.01
I0123 18:35:37.361722 29630 solver.cpp:237] Iteration 11460, loss = 4.59577
I0123 18:35:37.361762 29630 solver.cpp:253]     Train net output #0: loss = 4.59577 (* 1 = 4.59577 loss)
I0123 18:35:37.361768 29630 sgd_solver.cpp:106] Iteration 11460, lr = 0.01
I0123 18:35:44.485508 29630 solver.cpp:237] Iteration 11480, loss = 4.28145
I0123 18:35:44.485546 29630 solver.cpp:253]     Train net output #0: loss = 4.28145 (* 1 = 4.28145 loss)
I0123 18:35:44.485553 29630 sgd_solver.cpp:106] Iteration 11480, lr = 0.01
I0123 18:35:51.691309 29630 solver.cpp:237] Iteration 11500, loss = 4.44074
I0123 18:35:51.691491 29630 solver.cpp:253]     Train net output #0: loss = 4.44074 (* 1 = 4.44074 loss)
I0123 18:35:51.691499 29630 sgd_solver.cpp:106] Iteration 11500, lr = 0.01
I0123 18:35:58.969303 29630 solver.cpp:237] Iteration 11520, loss = 4.54809
I0123 18:35:58.969341 29630 solver.cpp:253]     Train net output #0: loss = 4.54809 (* 1 = 4.54809 loss)
I0123 18:35:58.969347 29630 sgd_solver.cpp:106] Iteration 11520, lr = 0.01
I0123 18:36:06.182178 29630 solver.cpp:237] Iteration 11540, loss = 4.617
I0123 18:36:06.182216 29630 solver.cpp:253]     Train net output #0: loss = 4.617 (* 1 = 4.617 loss)
I0123 18:36:06.182224 29630 sgd_solver.cpp:106] Iteration 11540, lr = 0.01
I0123 18:36:13.430604 29630 solver.cpp:237] Iteration 11560, loss = 4.61538
I0123 18:36:13.430642 29630 solver.cpp:253]     Train net output #0: loss = 4.61538 (* 1 = 4.61538 loss)
I0123 18:36:13.430649 29630 sgd_solver.cpp:106] Iteration 11560, lr = 0.01
I0123 18:36:20.669214 29630 solver.cpp:237] Iteration 11580, loss = 4.41142
I0123 18:36:20.669253 29630 solver.cpp:253]     Train net output #0: loss = 4.41142 (* 1 = 4.41142 loss)
I0123 18:36:20.669260 29630 sgd_solver.cpp:106] Iteration 11580, lr = 0.01
I0123 18:36:27.902737 29630 solver.cpp:237] Iteration 11600, loss = 4.60711
I0123 18:36:27.902835 29630 solver.cpp:253]     Train net output #0: loss = 4.60711 (* 1 = 4.60711 loss)
I0123 18:36:27.902850 29630 sgd_solver.cpp:106] Iteration 11600, lr = 0.01
I0123 18:36:35.152923 29630 solver.cpp:237] Iteration 11620, loss = 4.59264
I0123 18:36:35.152962 29630 solver.cpp:253]     Train net output #0: loss = 4.59264 (* 1 = 4.59264 loss)
I0123 18:36:35.152968 29630 sgd_solver.cpp:106] Iteration 11620, lr = 0.01
I0123 18:36:42.418442 29630 solver.cpp:237] Iteration 11640, loss = 4.64635
I0123 18:36:42.418480 29630 solver.cpp:253]     Train net output #0: loss = 4.64635 (* 1 = 4.64635 loss)
I0123 18:36:42.418496 29630 sgd_solver.cpp:106] Iteration 11640, lr = 0.01
I0123 18:36:49.668045 29630 solver.cpp:237] Iteration 11660, loss = 4.67129
I0123 18:36:49.668083 29630 solver.cpp:253]     Train net output #0: loss = 4.67129 (* 1 = 4.67129 loss)
I0123 18:36:49.668089 29630 sgd_solver.cpp:106] Iteration 11660, lr = 0.01
I0123 18:36:56.919131 29630 solver.cpp:237] Iteration 11680, loss = 4.37969
I0123 18:36:56.919170 29630 solver.cpp:253]     Train net output #0: loss = 4.37969 (* 1 = 4.37969 loss)
I0123 18:36:56.919176 29630 sgd_solver.cpp:106] Iteration 11680, lr = 0.01
I0123 18:37:04.169704 29630 solver.cpp:237] Iteration 11700, loss = 4.46178
I0123 18:37:04.169831 29630 solver.cpp:253]     Train net output #0: loss = 4.46178 (* 1 = 4.46178 loss)
I0123 18:37:04.169838 29630 sgd_solver.cpp:106] Iteration 11700, lr = 0.01
I0123 18:37:11.419472 29630 solver.cpp:237] Iteration 11720, loss = 4.41766
I0123 18:37:11.419512 29630 solver.cpp:253]     Train net output #0: loss = 4.41766 (* 1 = 4.41766 loss)
I0123 18:37:11.419517 29630 sgd_solver.cpp:106] Iteration 11720, lr = 0.01
I0123 18:37:18.676102 29630 solver.cpp:237] Iteration 11740, loss = 4.60907
I0123 18:37:18.676141 29630 solver.cpp:253]     Train net output #0: loss = 4.60907 (* 1 = 4.60907 loss)
I0123 18:37:18.676147 29630 sgd_solver.cpp:106] Iteration 11740, lr = 0.01
I0123 18:37:25.931242 29630 solver.cpp:237] Iteration 11760, loss = 4.5494
I0123 18:37:25.931290 29630 solver.cpp:253]     Train net output #0: loss = 4.5494 (* 1 = 4.5494 loss)
I0123 18:37:25.931296 29630 sgd_solver.cpp:106] Iteration 11760, lr = 0.01
I0123 18:37:33.187165 29630 solver.cpp:237] Iteration 11780, loss = 4.33454
I0123 18:37:33.187203 29630 solver.cpp:253]     Train net output #0: loss = 4.33454 (* 1 = 4.33454 loss)
I0123 18:37:33.187209 29630 sgd_solver.cpp:106] Iteration 11780, lr = 0.01
I0123 18:37:40.446244 29630 solver.cpp:237] Iteration 11800, loss = 4.27871
I0123 18:37:40.446408 29630 solver.cpp:253]     Train net output #0: loss = 4.27871 (* 1 = 4.27871 loss)
I0123 18:37:40.446416 29630 sgd_solver.cpp:106] Iteration 11800, lr = 0.01
I0123 18:37:47.690268 29630 solver.cpp:237] Iteration 11820, loss = 4.43177
I0123 18:37:47.690310 29630 solver.cpp:253]     Train net output #0: loss = 4.43177 (* 1 = 4.43177 loss)
I0123 18:37:47.690325 29630 sgd_solver.cpp:106] Iteration 11820, lr = 0.01
I0123 18:37:54.993051 29630 solver.cpp:237] Iteration 11840, loss = 4.62079
I0123 18:37:54.993089 29630 solver.cpp:253]     Train net output #0: loss = 4.62079 (* 1 = 4.62079 loss)
I0123 18:37:54.993095 29630 sgd_solver.cpp:106] Iteration 11840, lr = 0.01
I0123 18:38:02.202992 29630 solver.cpp:237] Iteration 11860, loss = 4.46326
I0123 18:38:02.203032 29630 solver.cpp:253]     Train net output #0: loss = 4.46326 (* 1 = 4.46326 loss)
I0123 18:38:02.203038 29630 sgd_solver.cpp:106] Iteration 11860, lr = 0.01
I0123 18:38:09.486433 29630 solver.cpp:237] Iteration 11880, loss = 4.55705
I0123 18:38:09.486472 29630 solver.cpp:253]     Train net output #0: loss = 4.55705 (* 1 = 4.55705 loss)
I0123 18:38:09.486479 29630 sgd_solver.cpp:106] Iteration 11880, lr = 0.01
I0123 18:38:16.708230 29630 solver.cpp:237] Iteration 11900, loss = 4.68938
I0123 18:38:16.708376 29630 solver.cpp:253]     Train net output #0: loss = 4.68938 (* 1 = 4.68938 loss)
I0123 18:38:16.708384 29630 sgd_solver.cpp:106] Iteration 11900, lr = 0.01
I0123 18:38:23.984371 29630 solver.cpp:237] Iteration 11920, loss = 4.44576
I0123 18:38:23.984411 29630 solver.cpp:253]     Train net output #0: loss = 4.44576 (* 1 = 4.44576 loss)
I0123 18:38:23.984417 29630 sgd_solver.cpp:106] Iteration 11920, lr = 0.01
I0123 18:38:31.278043 29630 solver.cpp:237] Iteration 11940, loss = 4.48848
I0123 18:38:31.278081 29630 solver.cpp:253]     Train net output #0: loss = 4.48848 (* 1 = 4.48848 loss)
I0123 18:38:31.278087 29630 sgd_solver.cpp:106] Iteration 11940, lr = 0.01
I0123 18:38:38.569681 29630 solver.cpp:237] Iteration 11960, loss = 4.33629
I0123 18:38:38.569720 29630 solver.cpp:253]     Train net output #0: loss = 4.33629 (* 1 = 4.33629 loss)
I0123 18:38:38.569726 29630 sgd_solver.cpp:106] Iteration 11960, lr = 0.01
I0123 18:38:45.892480 29630 solver.cpp:237] Iteration 11980, loss = 4.4597
I0123 18:38:45.892519 29630 solver.cpp:253]     Train net output #0: loss = 4.4597 (* 1 = 4.4597 loss)
I0123 18:38:45.892525 29630 sgd_solver.cpp:106] Iteration 11980, lr = 0.01
I0123 18:38:52.882115 29630 solver.cpp:341] Iteration 12000, Testing net (#0)
I0123 18:38:58.067895 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 18:40:07.408440 29630 solver.cpp:409]     Test net output #0: accuracy = 0.16646
I0123 18:40:07.408578 29630 solver.cpp:409]     Test net output #1: loss = 4.30828 (* 1 = 4.30828 loss)
I0123 18:40:07.449092 29630 solver.cpp:237] Iteration 12000, loss = 4.66217
I0123 18:40:07.449131 29630 solver.cpp:253]     Train net output #0: loss = 4.66217 (* 1 = 4.66217 loss)
I0123 18:40:07.449137 29630 sgd_solver.cpp:106] Iteration 12000, lr = 0.01
I0123 18:40:13.986896 29630 solver.cpp:237] Iteration 12020, loss = 4.42679
I0123 18:40:13.986932 29630 solver.cpp:253]     Train net output #0: loss = 4.42679 (* 1 = 4.42679 loss)
I0123 18:40:13.986938 29630 sgd_solver.cpp:106] Iteration 12020, lr = 0.01
I0123 18:40:21.259400 29630 solver.cpp:237] Iteration 12040, loss = 4.28041
I0123 18:40:21.259439 29630 solver.cpp:253]     Train net output #0: loss = 4.28041 (* 1 = 4.28041 loss)
I0123 18:40:21.259445 29630 sgd_solver.cpp:106] Iteration 12040, lr = 0.01
I0123 18:40:28.524857 29630 solver.cpp:237] Iteration 12060, loss = 4.31598
I0123 18:40:28.524895 29630 solver.cpp:253]     Train net output #0: loss = 4.31598 (* 1 = 4.31598 loss)
I0123 18:40:28.524901 29630 sgd_solver.cpp:106] Iteration 12060, lr = 0.01
I0123 18:40:33.246975 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 18:40:35.691814 29630 solver.cpp:237] Iteration 12080, loss = 4.20517
I0123 18:40:35.691853 29630 solver.cpp:253]     Train net output #0: loss = 4.20517 (* 1 = 4.20517 loss)
I0123 18:40:35.691859 29630 sgd_solver.cpp:106] Iteration 12080, lr = 0.01
I0123 18:40:42.885287 29630 solver.cpp:237] Iteration 12100, loss = 4.47715
I0123 18:40:42.885396 29630 solver.cpp:253]     Train net output #0: loss = 4.47715 (* 1 = 4.47715 loss)
I0123 18:40:42.885413 29630 sgd_solver.cpp:106] Iteration 12100, lr = 0.01
I0123 18:40:50.108860 29630 solver.cpp:237] Iteration 12120, loss = 4.34967
I0123 18:40:50.108898 29630 solver.cpp:253]     Train net output #0: loss = 4.34967 (* 1 = 4.34967 loss)
I0123 18:40:50.108913 29630 sgd_solver.cpp:106] Iteration 12120, lr = 0.01
I0123 18:40:57.425042 29630 solver.cpp:237] Iteration 12140, loss = 4.50691
I0123 18:40:57.425082 29630 solver.cpp:253]     Train net output #0: loss = 4.50691 (* 1 = 4.50691 loss)
I0123 18:40:57.425088 29630 sgd_solver.cpp:106] Iteration 12140, lr = 0.01
I0123 18:41:04.719933 29630 solver.cpp:237] Iteration 12160, loss = 4.38484
I0123 18:41:04.719972 29630 solver.cpp:253]     Train net output #0: loss = 4.38484 (* 1 = 4.38484 loss)
I0123 18:41:04.719979 29630 sgd_solver.cpp:106] Iteration 12160, lr = 0.01
I0123 18:41:11.928738 29630 solver.cpp:237] Iteration 12180, loss = 4.44923
I0123 18:41:11.928776 29630 solver.cpp:253]     Train net output #0: loss = 4.44923 (* 1 = 4.44923 loss)
I0123 18:41:11.928782 29630 sgd_solver.cpp:106] Iteration 12180, lr = 0.01
I0123 18:41:19.151031 29630 solver.cpp:237] Iteration 12200, loss = 4.33215
I0123 18:41:19.151197 29630 solver.cpp:253]     Train net output #0: loss = 4.33215 (* 1 = 4.33215 loss)
I0123 18:41:19.151206 29630 sgd_solver.cpp:106] Iteration 12200, lr = 0.01
I0123 18:41:26.376052 29630 solver.cpp:237] Iteration 12220, loss = 4.23667
I0123 18:41:26.376091 29630 solver.cpp:253]     Train net output #0: loss = 4.23667 (* 1 = 4.23667 loss)
I0123 18:41:26.376098 29630 sgd_solver.cpp:106] Iteration 12220, lr = 0.01
I0123 18:41:33.587968 29630 solver.cpp:237] Iteration 12240, loss = 4.65563
I0123 18:41:33.588008 29630 solver.cpp:253]     Train net output #0: loss = 4.65563 (* 1 = 4.65563 loss)
I0123 18:41:33.588014 29630 sgd_solver.cpp:106] Iteration 12240, lr = 0.01
I0123 18:41:40.866678 29630 solver.cpp:237] Iteration 12260, loss = 4.41682
I0123 18:41:40.866719 29630 solver.cpp:253]     Train net output #0: loss = 4.41682 (* 1 = 4.41682 loss)
I0123 18:41:40.866725 29630 sgd_solver.cpp:106] Iteration 12260, lr = 0.01
I0123 18:41:48.129467 29630 solver.cpp:237] Iteration 12280, loss = 4.42197
I0123 18:41:48.129506 29630 solver.cpp:253]     Train net output #0: loss = 4.42197 (* 1 = 4.42197 loss)
I0123 18:41:48.129513 29630 sgd_solver.cpp:106] Iteration 12280, lr = 0.01
I0123 18:41:55.359763 29630 solver.cpp:237] Iteration 12300, loss = 4.39006
I0123 18:41:55.359907 29630 solver.cpp:253]     Train net output #0: loss = 4.39006 (* 1 = 4.39006 loss)
I0123 18:41:55.359925 29630 sgd_solver.cpp:106] Iteration 12300, lr = 0.01
I0123 18:42:02.623479 29630 solver.cpp:237] Iteration 12320, loss = 4.3248
I0123 18:42:02.623518 29630 solver.cpp:253]     Train net output #0: loss = 4.3248 (* 1 = 4.3248 loss)
I0123 18:42:02.623524 29630 sgd_solver.cpp:106] Iteration 12320, lr = 0.01
I0123 18:42:09.910368 29630 solver.cpp:237] Iteration 12340, loss = 4.39416
I0123 18:42:09.910408 29630 solver.cpp:253]     Train net output #0: loss = 4.39416 (* 1 = 4.39416 loss)
I0123 18:42:09.910414 29630 sgd_solver.cpp:106] Iteration 12340, lr = 0.01
I0123 18:42:17.128041 29630 solver.cpp:237] Iteration 12360, loss = 4.21196
I0123 18:42:17.128080 29630 solver.cpp:253]     Train net output #0: loss = 4.21196 (* 1 = 4.21196 loss)
I0123 18:42:17.128087 29630 sgd_solver.cpp:106] Iteration 12360, lr = 0.01
I0123 18:42:24.386178 29630 solver.cpp:237] Iteration 12380, loss = 4.56819
I0123 18:42:24.386234 29630 solver.cpp:253]     Train net output #0: loss = 4.56819 (* 1 = 4.56819 loss)
I0123 18:42:24.386242 29630 sgd_solver.cpp:106] Iteration 12380, lr = 0.01
I0123 18:42:31.675871 29630 solver.cpp:237] Iteration 12400, loss = 4.34216
I0123 18:42:31.676008 29630 solver.cpp:253]     Train net output #0: loss = 4.34216 (* 1 = 4.34216 loss)
I0123 18:42:31.676017 29630 sgd_solver.cpp:106] Iteration 12400, lr = 0.01
I0123 18:42:38.943902 29630 solver.cpp:237] Iteration 12420, loss = 4.44795
I0123 18:42:38.943943 29630 solver.cpp:253]     Train net output #0: loss = 4.44795 (* 1 = 4.44795 loss)
I0123 18:42:38.943948 29630 sgd_solver.cpp:106] Iteration 12420, lr = 0.01
I0123 18:42:46.250629 29630 solver.cpp:237] Iteration 12440, loss = 4.21622
I0123 18:42:46.250668 29630 solver.cpp:253]     Train net output #0: loss = 4.21622 (* 1 = 4.21622 loss)
I0123 18:42:46.250675 29630 sgd_solver.cpp:106] Iteration 12440, lr = 0.01
I0123 18:42:53.531371 29630 solver.cpp:237] Iteration 12460, loss = 4.57947
I0123 18:42:53.531410 29630 solver.cpp:253]     Train net output #0: loss = 4.57947 (* 1 = 4.57947 loss)
I0123 18:42:53.531416 29630 sgd_solver.cpp:106] Iteration 12460, lr = 0.01
I0123 18:43:00.848098 29630 solver.cpp:237] Iteration 12480, loss = 4.25555
I0123 18:43:00.848139 29630 solver.cpp:253]     Train net output #0: loss = 4.25555 (* 1 = 4.25555 loss)
I0123 18:43:00.848145 29630 sgd_solver.cpp:106] Iteration 12480, lr = 0.01
I0123 18:43:08.132040 29630 solver.cpp:237] Iteration 12500, loss = 4.48954
I0123 18:43:08.132192 29630 solver.cpp:253]     Train net output #0: loss = 4.48954 (* 1 = 4.48954 loss)
I0123 18:43:08.132200 29630 sgd_solver.cpp:106] Iteration 12500, lr = 0.01
I0123 18:43:15.423323 29630 solver.cpp:237] Iteration 12520, loss = 4.46428
I0123 18:43:15.423362 29630 solver.cpp:253]     Train net output #0: loss = 4.46428 (* 1 = 4.46428 loss)
I0123 18:43:15.423367 29630 sgd_solver.cpp:106] Iteration 12520, lr = 0.01
I0123 18:43:22.816330 29630 solver.cpp:237] Iteration 12540, loss = 4.40377
I0123 18:43:22.816370 29630 solver.cpp:253]     Train net output #0: loss = 4.40377 (* 1 = 4.40377 loss)
I0123 18:43:22.816376 29630 sgd_solver.cpp:106] Iteration 12540, lr = 0.01
I0123 18:43:30.117846 29630 solver.cpp:237] Iteration 12560, loss = 4.59015
I0123 18:43:30.117885 29630 solver.cpp:253]     Train net output #0: loss = 4.59015 (* 1 = 4.59015 loss)
I0123 18:43:30.117892 29630 sgd_solver.cpp:106] Iteration 12560, lr = 0.01
I0123 18:43:37.425652 29630 solver.cpp:237] Iteration 12580, loss = 4.2472
I0123 18:43:37.425698 29630 solver.cpp:253]     Train net output #0: loss = 4.2472 (* 1 = 4.2472 loss)
I0123 18:43:37.425704 29630 sgd_solver.cpp:106] Iteration 12580, lr = 0.01
I0123 18:43:44.673851 29630 solver.cpp:237] Iteration 12600, loss = 4.51345
I0123 18:43:44.673979 29630 solver.cpp:253]     Train net output #0: loss = 4.51345 (* 1 = 4.51345 loss)
I0123 18:43:44.673986 29630 sgd_solver.cpp:106] Iteration 12600, lr = 0.01
I0123 18:43:51.918225 29630 solver.cpp:237] Iteration 12620, loss = 4.38517
I0123 18:43:51.918267 29630 solver.cpp:253]     Train net output #0: loss = 4.38517 (* 1 = 4.38517 loss)
I0123 18:43:51.918272 29630 sgd_solver.cpp:106] Iteration 12620, lr = 0.01
I0123 18:43:59.150624 29630 solver.cpp:237] Iteration 12640, loss = 4.51512
I0123 18:43:59.150663 29630 solver.cpp:253]     Train net output #0: loss = 4.51512 (* 1 = 4.51512 loss)
I0123 18:43:59.150670 29630 sgd_solver.cpp:106] Iteration 12640, lr = 0.01
I0123 18:44:06.445135 29630 solver.cpp:237] Iteration 12660, loss = 4.50574
I0123 18:44:06.445173 29630 solver.cpp:253]     Train net output #0: loss = 4.50574 (* 1 = 4.50574 loss)
I0123 18:44:06.445179 29630 sgd_solver.cpp:106] Iteration 12660, lr = 0.01
I0123 18:44:13.668176 29630 solver.cpp:237] Iteration 12680, loss = 4.27102
I0123 18:44:13.668213 29630 solver.cpp:253]     Train net output #0: loss = 4.27102 (* 1 = 4.27102 loss)
I0123 18:44:13.668220 29630 sgd_solver.cpp:106] Iteration 12680, lr = 0.01
I0123 18:44:20.912679 29630 solver.cpp:237] Iteration 12700, loss = 4.7542
I0123 18:44:20.912775 29630 solver.cpp:253]     Train net output #0: loss = 4.7542 (* 1 = 4.7542 loss)
I0123 18:44:20.912782 29630 sgd_solver.cpp:106] Iteration 12700, lr = 0.01
I0123 18:44:28.131397 29630 solver.cpp:237] Iteration 12720, loss = 4.35494
I0123 18:44:28.131434 29630 solver.cpp:253]     Train net output #0: loss = 4.35494 (* 1 = 4.35494 loss)
I0123 18:44:28.131440 29630 sgd_solver.cpp:106] Iteration 12720, lr = 0.01
I0123 18:44:35.373188 29630 solver.cpp:237] Iteration 12740, loss = 4.5078
I0123 18:44:35.373227 29630 solver.cpp:253]     Train net output #0: loss = 4.5078 (* 1 = 4.5078 loss)
I0123 18:44:35.373234 29630 sgd_solver.cpp:106] Iteration 12740, lr = 0.01
I0123 18:44:42.612686 29630 solver.cpp:237] Iteration 12760, loss = 4.39354
I0123 18:44:42.612725 29630 solver.cpp:253]     Train net output #0: loss = 4.39354 (* 1 = 4.39354 loss)
I0123 18:44:42.612731 29630 sgd_solver.cpp:106] Iteration 12760, lr = 0.01
I0123 18:44:49.854419 29630 solver.cpp:237] Iteration 12780, loss = 4.15676
I0123 18:44:49.854460 29630 solver.cpp:253]     Train net output #0: loss = 4.15676 (* 1 = 4.15676 loss)
I0123 18:44:49.854465 29630 sgd_solver.cpp:106] Iteration 12780, lr = 0.01
I0123 18:44:57.079388 29630 solver.cpp:237] Iteration 12800, loss = 4.53357
I0123 18:44:57.079566 29630 solver.cpp:253]     Train net output #0: loss = 4.53357 (* 1 = 4.53357 loss)
I0123 18:44:57.079574 29630 sgd_solver.cpp:106] Iteration 12800, lr = 0.01
I0123 18:45:04.335863 29630 solver.cpp:237] Iteration 12820, loss = 4.33751
I0123 18:45:04.335902 29630 solver.cpp:253]     Train net output #0: loss = 4.33751 (* 1 = 4.33751 loss)
I0123 18:45:04.335908 29630 sgd_solver.cpp:106] Iteration 12820, lr = 0.01
I0123 18:45:11.581190 29630 solver.cpp:237] Iteration 12840, loss = 4.38079
I0123 18:45:11.581229 29630 solver.cpp:253]     Train net output #0: loss = 4.38079 (* 1 = 4.38079 loss)
I0123 18:45:11.581235 29630 sgd_solver.cpp:106] Iteration 12840, lr = 0.01
I0123 18:45:18.802453 29630 solver.cpp:237] Iteration 12860, loss = 4.37409
I0123 18:45:18.802491 29630 solver.cpp:253]     Train net output #0: loss = 4.37409 (* 1 = 4.37409 loss)
I0123 18:45:18.802497 29630 sgd_solver.cpp:106] Iteration 12860, lr = 0.01
I0123 18:45:26.023998 29630 solver.cpp:237] Iteration 12880, loss = 4.41683
I0123 18:45:26.024034 29630 solver.cpp:253]     Train net output #0: loss = 4.41683 (* 1 = 4.41683 loss)
I0123 18:45:26.024041 29630 sgd_solver.cpp:106] Iteration 12880, lr = 0.01
I0123 18:45:33.231943 29630 solver.cpp:237] Iteration 12900, loss = 4.45015
I0123 18:45:33.232112 29630 solver.cpp:253]     Train net output #0: loss = 4.45015 (* 1 = 4.45015 loss)
I0123 18:45:33.232131 29630 sgd_solver.cpp:106] Iteration 12900, lr = 0.01
I0123 18:45:40.496341 29630 solver.cpp:237] Iteration 12920, loss = 4.49005
I0123 18:45:40.496381 29630 solver.cpp:253]     Train net output #0: loss = 4.49005 (* 1 = 4.49005 loss)
I0123 18:45:40.496387 29630 sgd_solver.cpp:106] Iteration 12920, lr = 0.01
I0123 18:45:47.727648 29630 solver.cpp:237] Iteration 12940, loss = 4.46161
I0123 18:45:47.727685 29630 solver.cpp:253]     Train net output #0: loss = 4.46161 (* 1 = 4.46161 loss)
I0123 18:45:47.727691 29630 sgd_solver.cpp:106] Iteration 12940, lr = 0.01
I0123 18:45:54.990147 29630 solver.cpp:237] Iteration 12960, loss = 4.59483
I0123 18:45:54.990185 29630 solver.cpp:253]     Train net output #0: loss = 4.59483 (* 1 = 4.59483 loss)
I0123 18:45:54.990191 29630 sgd_solver.cpp:106] Iteration 12960, lr = 0.01
I0123 18:46:02.254752 29630 solver.cpp:237] Iteration 12980, loss = 4.33408
I0123 18:46:02.254791 29630 solver.cpp:253]     Train net output #0: loss = 4.33408 (* 1 = 4.33408 loss)
I0123 18:46:02.254797 29630 sgd_solver.cpp:106] Iteration 12980, lr = 0.01
I0123 18:46:09.191278 29630 solver.cpp:341] Iteration 13000, Testing net (#0)
I0123 18:46:14.733989 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 18:47:23.306632 29630 solver.cpp:409]     Test net output #0: accuracy = 0.17248
I0123 18:47:23.306804 29630 solver.cpp:409]     Test net output #1: loss = 4.25596 (* 1 = 4.25596 loss)
I0123 18:47:23.347292 29630 solver.cpp:237] Iteration 13000, loss = 4.26637
I0123 18:47:23.347329 29630 solver.cpp:253]     Train net output #0: loss = 4.26637 (* 1 = 4.26637 loss)
I0123 18:47:23.347335 29630 sgd_solver.cpp:106] Iteration 13000, lr = 0.01
I0123 18:47:30.017968 29630 solver.cpp:237] Iteration 13020, loss = 4.60656
I0123 18:47:30.018008 29630 solver.cpp:253]     Train net output #0: loss = 4.60656 (* 1 = 4.60656 loss)
I0123 18:47:30.018014 29630 sgd_solver.cpp:106] Iteration 13020, lr = 0.01
I0123 18:47:37.346827 29630 solver.cpp:237] Iteration 13040, loss = 4.26534
I0123 18:47:37.346882 29630 solver.cpp:253]     Train net output #0: loss = 4.26534 (* 1 = 4.26534 loss)
I0123 18:47:37.346894 29630 sgd_solver.cpp:106] Iteration 13040, lr = 0.01
I0123 18:47:44.619055 29630 solver.cpp:237] Iteration 13060, loss = 4.40113
I0123 18:47:44.619092 29630 solver.cpp:253]     Train net output #0: loss = 4.40113 (* 1 = 4.40113 loss)
I0123 18:47:44.619099 29630 sgd_solver.cpp:106] Iteration 13060, lr = 0.01
I0123 18:47:51.559142 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 18:47:51.854774 29630 solver.cpp:237] Iteration 13080, loss = 4.497
I0123 18:47:51.854814 29630 solver.cpp:253]     Train net output #0: loss = 4.497 (* 1 = 4.497 loss)
I0123 18:47:51.854820 29630 sgd_solver.cpp:106] Iteration 13080, lr = 0.01
I0123 18:47:59.151476 29630 solver.cpp:237] Iteration 13100, loss = 4.48116
I0123 18:47:59.151656 29630 solver.cpp:253]     Train net output #0: loss = 4.48116 (* 1 = 4.48116 loss)
I0123 18:47:59.151664 29630 sgd_solver.cpp:106] Iteration 13100, lr = 0.01
I0123 18:48:06.429278 29630 solver.cpp:237] Iteration 13120, loss = 4.62434
I0123 18:48:06.429318 29630 solver.cpp:253]     Train net output #0: loss = 4.62434 (* 1 = 4.62434 loss)
I0123 18:48:06.429325 29630 sgd_solver.cpp:106] Iteration 13120, lr = 0.01
I0123 18:48:13.739665 29630 solver.cpp:237] Iteration 13140, loss = 4.41739
I0123 18:48:13.739703 29630 solver.cpp:253]     Train net output #0: loss = 4.41739 (* 1 = 4.41739 loss)
I0123 18:48:13.739709 29630 sgd_solver.cpp:106] Iteration 13140, lr = 0.01
I0123 18:48:20.979570 29630 solver.cpp:237] Iteration 13160, loss = 4.46729
I0123 18:48:20.979619 29630 solver.cpp:253]     Train net output #0: loss = 4.46729 (* 1 = 4.46729 loss)
I0123 18:48:20.979625 29630 sgd_solver.cpp:106] Iteration 13160, lr = 0.01
I0123 18:48:28.245555 29630 solver.cpp:237] Iteration 13180, loss = 4.34482
I0123 18:48:28.245601 29630 solver.cpp:253]     Train net output #0: loss = 4.34482 (* 1 = 4.34482 loss)
I0123 18:48:28.245607 29630 sgd_solver.cpp:106] Iteration 13180, lr = 0.01
I0123 18:48:35.501890 29630 solver.cpp:237] Iteration 13200, loss = 4.22317
I0123 18:48:35.502019 29630 solver.cpp:253]     Train net output #0: loss = 4.22317 (* 1 = 4.22317 loss)
I0123 18:48:35.502027 29630 sgd_solver.cpp:106] Iteration 13200, lr = 0.01
I0123 18:48:42.733897 29630 solver.cpp:237] Iteration 13220, loss = 4.3618
I0123 18:48:42.733935 29630 solver.cpp:253]     Train net output #0: loss = 4.3618 (* 1 = 4.3618 loss)
I0123 18:48:42.733942 29630 sgd_solver.cpp:106] Iteration 13220, lr = 0.01
I0123 18:48:49.958611 29630 solver.cpp:237] Iteration 13240, loss = 4.47821
I0123 18:48:49.958650 29630 solver.cpp:253]     Train net output #0: loss = 4.47821 (* 1 = 4.47821 loss)
I0123 18:48:49.958657 29630 sgd_solver.cpp:106] Iteration 13240, lr = 0.01
I0123 18:48:57.244446 29630 solver.cpp:237] Iteration 13260, loss = 4.63768
I0123 18:48:57.244483 29630 solver.cpp:253]     Train net output #0: loss = 4.63768 (* 1 = 4.63768 loss)
I0123 18:48:57.244489 29630 sgd_solver.cpp:106] Iteration 13260, lr = 0.01
I0123 18:49:04.513123 29630 solver.cpp:237] Iteration 13280, loss = 4.16385
I0123 18:49:04.513161 29630 solver.cpp:253]     Train net output #0: loss = 4.16385 (* 1 = 4.16385 loss)
I0123 18:49:04.513167 29630 sgd_solver.cpp:106] Iteration 13280, lr = 0.01
I0123 18:49:11.724756 29630 solver.cpp:237] Iteration 13300, loss = 4.58114
I0123 18:49:11.724920 29630 solver.cpp:253]     Train net output #0: loss = 4.58114 (* 1 = 4.58114 loss)
I0123 18:49:11.724927 29630 sgd_solver.cpp:106] Iteration 13300, lr = 0.01
I0123 18:49:18.957072 29630 solver.cpp:237] Iteration 13320, loss = 4.40883
I0123 18:49:18.957109 29630 solver.cpp:253]     Train net output #0: loss = 4.40883 (* 1 = 4.40883 loss)
I0123 18:49:18.957116 29630 sgd_solver.cpp:106] Iteration 13320, lr = 0.01
I0123 18:49:26.181712 29630 solver.cpp:237] Iteration 13340, loss = 4.50248
I0123 18:49:26.181751 29630 solver.cpp:253]     Train net output #0: loss = 4.50248 (* 1 = 4.50248 loss)
I0123 18:49:26.181757 29630 sgd_solver.cpp:106] Iteration 13340, lr = 0.01
I0123 18:49:33.434926 29630 solver.cpp:237] Iteration 13360, loss = 4.66181
I0123 18:49:33.434965 29630 solver.cpp:253]     Train net output #0: loss = 4.66181 (* 1 = 4.66181 loss)
I0123 18:49:33.434972 29630 sgd_solver.cpp:106] Iteration 13360, lr = 0.01
I0123 18:49:40.657430 29630 solver.cpp:237] Iteration 13380, loss = 4.3859
I0123 18:49:40.657469 29630 solver.cpp:253]     Train net output #0: loss = 4.3859 (* 1 = 4.3859 loss)
I0123 18:49:40.657475 29630 sgd_solver.cpp:106] Iteration 13380, lr = 0.01
I0123 18:49:47.895325 29630 solver.cpp:237] Iteration 13400, loss = 4.53491
I0123 18:49:47.895519 29630 solver.cpp:253]     Train net output #0: loss = 4.53491 (* 1 = 4.53491 loss)
I0123 18:49:47.895526 29630 sgd_solver.cpp:106] Iteration 13400, lr = 0.01
I0123 18:49:55.123843 29630 solver.cpp:237] Iteration 13420, loss = 4.23674
I0123 18:49:55.123883 29630 solver.cpp:253]     Train net output #0: loss = 4.23674 (* 1 = 4.23674 loss)
I0123 18:49:55.123889 29630 sgd_solver.cpp:106] Iteration 13420, lr = 0.01
I0123 18:50:02.338557 29630 solver.cpp:237] Iteration 13440, loss = 4.56718
I0123 18:50:02.338596 29630 solver.cpp:253]     Train net output #0: loss = 4.56718 (* 1 = 4.56718 loss)
I0123 18:50:02.338603 29630 sgd_solver.cpp:106] Iteration 13440, lr = 0.01
I0123 18:50:09.602555 29630 solver.cpp:237] Iteration 13460, loss = 4.49756
I0123 18:50:09.602612 29630 solver.cpp:253]     Train net output #0: loss = 4.49756 (* 1 = 4.49756 loss)
I0123 18:50:09.602624 29630 sgd_solver.cpp:106] Iteration 13460, lr = 0.01
I0123 18:50:16.864132 29630 solver.cpp:237] Iteration 13480, loss = 4.28466
I0123 18:50:16.864173 29630 solver.cpp:253]     Train net output #0: loss = 4.28466 (* 1 = 4.28466 loss)
I0123 18:50:16.864181 29630 sgd_solver.cpp:106] Iteration 13480, lr = 0.01
I0123 18:50:24.124140 29630 solver.cpp:237] Iteration 13500, loss = 4.2127
I0123 18:50:24.124305 29630 solver.cpp:253]     Train net output #0: loss = 4.2127 (* 1 = 4.2127 loss)
I0123 18:50:24.124312 29630 sgd_solver.cpp:106] Iteration 13500, lr = 0.01
I0123 18:50:31.361318 29630 solver.cpp:237] Iteration 13520, loss = 4.45055
I0123 18:50:31.361357 29630 solver.cpp:253]     Train net output #0: loss = 4.45055 (* 1 = 4.45055 loss)
I0123 18:50:31.361363 29630 sgd_solver.cpp:106] Iteration 13520, lr = 0.01
I0123 18:50:38.660460 29630 solver.cpp:237] Iteration 13540, loss = 4.44653
I0123 18:50:38.660487 29630 solver.cpp:253]     Train net output #0: loss = 4.44653 (* 1 = 4.44653 loss)
I0123 18:50:38.660493 29630 sgd_solver.cpp:106] Iteration 13540, lr = 0.01
I0123 18:50:45.952647 29630 solver.cpp:237] Iteration 13560, loss = 3.99558
I0123 18:50:45.952687 29630 solver.cpp:253]     Train net output #0: loss = 3.99558 (* 1 = 3.99558 loss)
I0123 18:50:45.952693 29630 sgd_solver.cpp:106] Iteration 13560, lr = 0.01
I0123 18:50:53.197841 29630 solver.cpp:237] Iteration 13580, loss = 4.45751
I0123 18:50:53.197890 29630 solver.cpp:253]     Train net output #0: loss = 4.45751 (* 1 = 4.45751 loss)
I0123 18:50:53.197896 29630 sgd_solver.cpp:106] Iteration 13580, lr = 0.01
I0123 18:51:00.464617 29630 solver.cpp:237] Iteration 13600, loss = 4.31099
I0123 18:51:00.464756 29630 solver.cpp:253]     Train net output #0: loss = 4.31099 (* 1 = 4.31099 loss)
I0123 18:51:00.464763 29630 sgd_solver.cpp:106] Iteration 13600, lr = 0.01
I0123 18:51:07.778795 29630 solver.cpp:237] Iteration 13620, loss = 4.44167
I0123 18:51:07.778834 29630 solver.cpp:253]     Train net output #0: loss = 4.44167 (* 1 = 4.44167 loss)
I0123 18:51:07.778841 29630 sgd_solver.cpp:106] Iteration 13620, lr = 0.01
I0123 18:51:15.115407 29630 solver.cpp:237] Iteration 13640, loss = 4.45179
I0123 18:51:15.115447 29630 solver.cpp:253]     Train net output #0: loss = 4.45179 (* 1 = 4.45179 loss)
I0123 18:51:15.115453 29630 sgd_solver.cpp:106] Iteration 13640, lr = 0.01
I0123 18:51:22.342012 29630 solver.cpp:237] Iteration 13660, loss = 4.40095
I0123 18:51:22.342051 29630 solver.cpp:253]     Train net output #0: loss = 4.40095 (* 1 = 4.40095 loss)
I0123 18:51:22.342057 29630 sgd_solver.cpp:106] Iteration 13660, lr = 0.01
I0123 18:51:29.596120 29630 solver.cpp:237] Iteration 13680, loss = 4.29465
I0123 18:51:29.596159 29630 solver.cpp:253]     Train net output #0: loss = 4.29465 (* 1 = 4.29465 loss)
I0123 18:51:29.596165 29630 sgd_solver.cpp:106] Iteration 13680, lr = 0.01
I0123 18:51:36.943938 29630 solver.cpp:237] Iteration 13700, loss = 4.33751
I0123 18:51:36.944123 29630 solver.cpp:253]     Train net output #0: loss = 4.33751 (* 1 = 4.33751 loss)
I0123 18:51:36.944139 29630 sgd_solver.cpp:106] Iteration 13700, lr = 0.01
I0123 18:51:44.262789 29630 solver.cpp:237] Iteration 13720, loss = 4.60924
I0123 18:51:44.262827 29630 solver.cpp:253]     Train net output #0: loss = 4.60924 (* 1 = 4.60924 loss)
I0123 18:51:44.262833 29630 sgd_solver.cpp:106] Iteration 13720, lr = 0.01
I0123 18:51:51.579741 29630 solver.cpp:237] Iteration 13740, loss = 4.38571
I0123 18:51:51.579780 29630 solver.cpp:253]     Train net output #0: loss = 4.38571 (* 1 = 4.38571 loss)
I0123 18:51:51.579787 29630 sgd_solver.cpp:106] Iteration 13740, lr = 0.01
I0123 18:51:58.862987 29630 solver.cpp:237] Iteration 13760, loss = 4.30152
I0123 18:51:58.863025 29630 solver.cpp:253]     Train net output #0: loss = 4.30152 (* 1 = 4.30152 loss)
I0123 18:51:58.863032 29630 sgd_solver.cpp:106] Iteration 13760, lr = 0.01
I0123 18:52:06.120209 29630 solver.cpp:237] Iteration 13780, loss = 4.25695
I0123 18:52:06.120247 29630 solver.cpp:253]     Train net output #0: loss = 4.25695 (* 1 = 4.25695 loss)
I0123 18:52:06.120254 29630 sgd_solver.cpp:106] Iteration 13780, lr = 0.01
I0123 18:52:13.340020 29630 solver.cpp:237] Iteration 13800, loss = 4.12401
I0123 18:52:13.340198 29630 solver.cpp:253]     Train net output #0: loss = 4.12401 (* 1 = 4.12401 loss)
I0123 18:52:13.340207 29630 sgd_solver.cpp:106] Iteration 13800, lr = 0.01
I0123 18:52:20.597395 29630 solver.cpp:237] Iteration 13820, loss = 4.47669
I0123 18:52:20.597435 29630 solver.cpp:253]     Train net output #0: loss = 4.47669 (* 1 = 4.47669 loss)
I0123 18:52:20.597441 29630 sgd_solver.cpp:106] Iteration 13820, lr = 0.01
I0123 18:52:27.802808 29630 solver.cpp:237] Iteration 13840, loss = 4.469
I0123 18:52:27.802847 29630 solver.cpp:253]     Train net output #0: loss = 4.469 (* 1 = 4.469 loss)
I0123 18:52:27.802853 29630 sgd_solver.cpp:106] Iteration 13840, lr = 0.01
I0123 18:52:35.095700 29630 solver.cpp:237] Iteration 13860, loss = 4.43317
I0123 18:52:35.095739 29630 solver.cpp:253]     Train net output #0: loss = 4.43317 (* 1 = 4.43317 loss)
I0123 18:52:35.095746 29630 sgd_solver.cpp:106] Iteration 13860, lr = 0.01
I0123 18:52:42.342170 29630 solver.cpp:237] Iteration 13880, loss = 4.40541
I0123 18:52:42.342207 29630 solver.cpp:253]     Train net output #0: loss = 4.40541 (* 1 = 4.40541 loss)
I0123 18:52:42.342213 29630 sgd_solver.cpp:106] Iteration 13880, lr = 0.01
I0123 18:52:49.597467 29630 solver.cpp:237] Iteration 13900, loss = 4.21782
I0123 18:52:49.597642 29630 solver.cpp:253]     Train net output #0: loss = 4.21782 (* 1 = 4.21782 loss)
I0123 18:52:49.597651 29630 sgd_solver.cpp:106] Iteration 13900, lr = 0.01
I0123 18:52:56.821694 29630 solver.cpp:237] Iteration 13920, loss = 4.55734
I0123 18:52:56.821743 29630 solver.cpp:253]     Train net output #0: loss = 4.55734 (* 1 = 4.55734 loss)
I0123 18:52:56.821754 29630 sgd_solver.cpp:106] Iteration 13920, lr = 0.01
I0123 18:53:04.063839 29630 solver.cpp:237] Iteration 13940, loss = 4.47328
I0123 18:53:04.063879 29630 solver.cpp:253]     Train net output #0: loss = 4.47328 (* 1 = 4.47328 loss)
I0123 18:53:04.063885 29630 sgd_solver.cpp:106] Iteration 13940, lr = 0.01
I0123 18:53:11.350422 29630 solver.cpp:237] Iteration 13960, loss = 4.43605
I0123 18:53:11.350461 29630 solver.cpp:253]     Train net output #0: loss = 4.43605 (* 1 = 4.43605 loss)
I0123 18:53:11.350466 29630 sgd_solver.cpp:106] Iteration 13960, lr = 0.01
I0123 18:53:18.632359 29630 solver.cpp:237] Iteration 13980, loss = 4.42801
I0123 18:53:18.632397 29630 solver.cpp:253]     Train net output #0: loss = 4.42801 (* 1 = 4.42801 loss)
I0123 18:53:18.632405 29630 sgd_solver.cpp:106] Iteration 13980, lr = 0.01
I0123 18:53:25.567323 29630 solver.cpp:341] Iteration 14000, Testing net (#0)
I0123 18:53:31.563344 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 18:54:40.103004 29630 solver.cpp:409]     Test net output #0: accuracy = 0.18338
I0123 18:54:40.103147 29630 solver.cpp:409]     Test net output #1: loss = 4.15968 (* 1 = 4.15968 loss)
I0123 18:54:40.143808 29630 solver.cpp:237] Iteration 14000, loss = 4.15166
I0123 18:54:40.143836 29630 solver.cpp:253]     Train net output #0: loss = 4.15166 (* 1 = 4.15166 loss)
I0123 18:54:40.143844 29630 sgd_solver.cpp:106] Iteration 14000, lr = 0.01
I0123 18:54:46.770916 29630 solver.cpp:237] Iteration 14020, loss = 4.48031
I0123 18:54:46.770956 29630 solver.cpp:253]     Train net output #0: loss = 4.48031 (* 1 = 4.48031 loss)
I0123 18:54:46.770962 29630 sgd_solver.cpp:106] Iteration 14020, lr = 0.01
I0123 18:54:54.062060 29630 solver.cpp:237] Iteration 14040, loss = 4.3693
I0123 18:54:54.062098 29630 solver.cpp:253]     Train net output #0: loss = 4.3693 (* 1 = 4.3693 loss)
I0123 18:54:54.062104 29630 sgd_solver.cpp:106] Iteration 14040, lr = 0.01
I0123 18:55:01.357951 29630 solver.cpp:237] Iteration 14060, loss = 4.38698
I0123 18:55:01.357980 29630 solver.cpp:253]     Train net output #0: loss = 4.38698 (* 1 = 4.38698 loss)
I0123 18:55:01.357985 29630 sgd_solver.cpp:106] Iteration 14060, lr = 0.01
I0123 18:55:08.614086 29630 solver.cpp:237] Iteration 14080, loss = 4.2689
I0123 18:55:08.614125 29630 solver.cpp:253]     Train net output #0: loss = 4.2689 (* 1 = 4.2689 loss)
I0123 18:55:08.614131 29630 sgd_solver.cpp:106] Iteration 14080, lr = 0.01
I0123 18:55:10.515470 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 18:55:15.904305 29630 solver.cpp:237] Iteration 14100, loss = 4.31083
I0123 18:55:15.904345 29630 solver.cpp:253]     Train net output #0: loss = 4.31083 (* 1 = 4.31083 loss)
I0123 18:55:15.904350 29630 sgd_solver.cpp:106] Iteration 14100, lr = 0.01
I0123 18:55:23.186559 29630 solver.cpp:237] Iteration 14120, loss = 4.48556
I0123 18:55:23.186599 29630 solver.cpp:253]     Train net output #0: loss = 4.48556 (* 1 = 4.48556 loss)
I0123 18:55:23.186604 29630 sgd_solver.cpp:106] Iteration 14120, lr = 0.01
I0123 18:55:30.467195 29630 solver.cpp:237] Iteration 14140, loss = 4.30327
I0123 18:55:30.467234 29630 solver.cpp:253]     Train net output #0: loss = 4.30327 (* 1 = 4.30327 loss)
I0123 18:55:30.467241 29630 sgd_solver.cpp:106] Iteration 14140, lr = 0.01
I0123 18:55:37.742010 29630 solver.cpp:237] Iteration 14160, loss = 4.184
I0123 18:55:37.742049 29630 solver.cpp:253]     Train net output #0: loss = 4.184 (* 1 = 4.184 loss)
I0123 18:55:37.742055 29630 sgd_solver.cpp:106] Iteration 14160, lr = 0.01
I0123 18:55:45.111430 29630 solver.cpp:237] Iteration 14180, loss = 4.32765
I0123 18:55:45.111598 29630 solver.cpp:253]     Train net output #0: loss = 4.32765 (* 1 = 4.32765 loss)
I0123 18:55:45.111604 29630 sgd_solver.cpp:106] Iteration 14180, lr = 0.01
I0123 18:55:52.435209 29630 solver.cpp:237] Iteration 14200, loss = 4.47153
I0123 18:55:52.435246 29630 solver.cpp:253]     Train net output #0: loss = 4.47153 (* 1 = 4.47153 loss)
I0123 18:55:52.435253 29630 sgd_solver.cpp:106] Iteration 14200, lr = 0.01
I0123 18:55:59.689437 29630 solver.cpp:237] Iteration 14220, loss = 4.18942
I0123 18:55:59.689476 29630 solver.cpp:253]     Train net output #0: loss = 4.18942 (* 1 = 4.18942 loss)
I0123 18:55:59.689481 29630 sgd_solver.cpp:106] Iteration 14220, lr = 0.01
I0123 18:56:06.920300 29630 solver.cpp:237] Iteration 14240, loss = 4.4277
I0123 18:56:06.920338 29630 solver.cpp:253]     Train net output #0: loss = 4.4277 (* 1 = 4.4277 loss)
I0123 18:56:06.920344 29630 sgd_solver.cpp:106] Iteration 14240, lr = 0.01
I0123 18:56:14.190898 29630 solver.cpp:237] Iteration 14260, loss = 4.29466
I0123 18:56:14.190937 29630 solver.cpp:253]     Train net output #0: loss = 4.29466 (* 1 = 4.29466 loss)
I0123 18:56:14.190943 29630 sgd_solver.cpp:106] Iteration 14260, lr = 0.01
I0123 18:56:21.450346 29630 solver.cpp:237] Iteration 14280, loss = 4.15207
I0123 18:56:21.450469 29630 solver.cpp:253]     Train net output #0: loss = 4.15207 (* 1 = 4.15207 loss)
I0123 18:56:21.450475 29630 sgd_solver.cpp:106] Iteration 14280, lr = 0.01
I0123 18:56:28.700294 29630 solver.cpp:237] Iteration 14300, loss = 4.36258
I0123 18:56:28.700331 29630 solver.cpp:253]     Train net output #0: loss = 4.36258 (* 1 = 4.36258 loss)
I0123 18:56:28.700337 29630 sgd_solver.cpp:106] Iteration 14300, lr = 0.01
I0123 18:56:35.982647 29630 solver.cpp:237] Iteration 14320, loss = 4.61456
I0123 18:56:35.982686 29630 solver.cpp:253]     Train net output #0: loss = 4.61456 (* 1 = 4.61456 loss)
I0123 18:56:35.982692 29630 sgd_solver.cpp:106] Iteration 14320, lr = 0.01
I0123 18:56:43.244675 29630 solver.cpp:237] Iteration 14340, loss = 4.19341
I0123 18:56:43.244714 29630 solver.cpp:253]     Train net output #0: loss = 4.19341 (* 1 = 4.19341 loss)
I0123 18:56:43.244719 29630 sgd_solver.cpp:106] Iteration 14340, lr = 0.01
I0123 18:56:50.461205 29630 solver.cpp:237] Iteration 14360, loss = 4.32518
I0123 18:56:50.461243 29630 solver.cpp:253]     Train net output #0: loss = 4.32518 (* 1 = 4.32518 loss)
I0123 18:56:50.461249 29630 sgd_solver.cpp:106] Iteration 14360, lr = 0.01
I0123 18:56:57.703297 29630 solver.cpp:237] Iteration 14380, loss = 4.24348
I0123 18:56:57.703409 29630 solver.cpp:253]     Train net output #0: loss = 4.24348 (* 1 = 4.24348 loss)
I0123 18:56:57.703426 29630 sgd_solver.cpp:106] Iteration 14380, lr = 0.01
I0123 18:57:04.938575 29630 solver.cpp:237] Iteration 14400, loss = 4.25866
I0123 18:57:04.938613 29630 solver.cpp:253]     Train net output #0: loss = 4.25866 (* 1 = 4.25866 loss)
I0123 18:57:04.938621 29630 sgd_solver.cpp:106] Iteration 14400, lr = 0.01
I0123 18:57:12.190115 29630 solver.cpp:237] Iteration 14420, loss = 4.56449
I0123 18:57:12.190155 29630 solver.cpp:253]     Train net output #0: loss = 4.56449 (* 1 = 4.56449 loss)
I0123 18:57:12.190161 29630 sgd_solver.cpp:106] Iteration 14420, lr = 0.01
I0123 18:57:19.446560 29630 solver.cpp:237] Iteration 14440, loss = 4.39683
I0123 18:57:19.446703 29630 solver.cpp:253]     Train net output #0: loss = 4.39683 (* 1 = 4.39683 loss)
I0123 18:57:19.446766 29630 sgd_solver.cpp:106] Iteration 14440, lr = 0.01
I0123 18:57:26.635658 29630 solver.cpp:237] Iteration 14460, loss = 4.35312
I0123 18:57:26.635696 29630 solver.cpp:253]     Train net output #0: loss = 4.35312 (* 1 = 4.35312 loss)
I0123 18:57:26.635702 29630 sgd_solver.cpp:106] Iteration 14460, lr = 0.01
I0123 18:57:33.887349 29630 solver.cpp:237] Iteration 14480, loss = 4.46773
I0123 18:57:33.887480 29630 solver.cpp:253]     Train net output #0: loss = 4.46773 (* 1 = 4.46773 loss)
I0123 18:57:33.887487 29630 sgd_solver.cpp:106] Iteration 14480, lr = 0.01
I0123 18:57:41.137488 29630 solver.cpp:237] Iteration 14500, loss = 4.60853
I0123 18:57:41.137527 29630 solver.cpp:253]     Train net output #0: loss = 4.60853 (* 1 = 4.60853 loss)
I0123 18:57:41.137533 29630 sgd_solver.cpp:106] Iteration 14500, lr = 0.01
I0123 18:57:48.387701 29630 solver.cpp:237] Iteration 14520, loss = 4.47619
I0123 18:57:48.387740 29630 solver.cpp:253]     Train net output #0: loss = 4.47619 (* 1 = 4.47619 loss)
I0123 18:57:48.387747 29630 sgd_solver.cpp:106] Iteration 14520, lr = 0.01
I0123 18:57:55.646420 29630 solver.cpp:237] Iteration 14540, loss = 4.32608
I0123 18:57:55.646461 29630 solver.cpp:253]     Train net output #0: loss = 4.32608 (* 1 = 4.32608 loss)
I0123 18:57:55.646466 29630 sgd_solver.cpp:106] Iteration 14540, lr = 0.01
I0123 18:58:02.872668 29630 solver.cpp:237] Iteration 14560, loss = 4.326
I0123 18:58:02.872706 29630 solver.cpp:253]     Train net output #0: loss = 4.326 (* 1 = 4.326 loss)
I0123 18:58:02.872712 29630 sgd_solver.cpp:106] Iteration 14560, lr = 0.01
I0123 18:58:10.125413 29630 solver.cpp:237] Iteration 14580, loss = 4.41759
I0123 18:58:10.125593 29630 solver.cpp:253]     Train net output #0: loss = 4.41759 (* 1 = 4.41759 loss)
I0123 18:58:10.125602 29630 sgd_solver.cpp:106] Iteration 14580, lr = 0.01
I0123 18:58:17.316570 29630 solver.cpp:237] Iteration 14600, loss = 4.25759
I0123 18:58:17.316611 29630 solver.cpp:253]     Train net output #0: loss = 4.25759 (* 1 = 4.25759 loss)
I0123 18:58:17.316617 29630 sgd_solver.cpp:106] Iteration 14600, lr = 0.01
I0123 18:58:24.582036 29630 solver.cpp:237] Iteration 14620, loss = 4.25734
I0123 18:58:24.582077 29630 solver.cpp:253]     Train net output #0: loss = 4.25734 (* 1 = 4.25734 loss)
I0123 18:58:24.582082 29630 sgd_solver.cpp:106] Iteration 14620, lr = 0.01
I0123 18:58:31.842897 29630 solver.cpp:237] Iteration 14640, loss = 4.44785
I0123 18:58:31.842936 29630 solver.cpp:253]     Train net output #0: loss = 4.44785 (* 1 = 4.44785 loss)
I0123 18:58:31.842942 29630 sgd_solver.cpp:106] Iteration 14640, lr = 0.01
I0123 18:58:39.103760 29630 solver.cpp:237] Iteration 14660, loss = 4.34026
I0123 18:58:39.103797 29630 solver.cpp:253]     Train net output #0: loss = 4.34026 (* 1 = 4.34026 loss)
I0123 18:58:39.103803 29630 sgd_solver.cpp:106] Iteration 14660, lr = 0.01
I0123 18:58:46.409312 29630 solver.cpp:237] Iteration 14680, loss = 4.08018
I0123 18:58:46.409488 29630 solver.cpp:253]     Train net output #0: loss = 4.08018 (* 1 = 4.08018 loss)
I0123 18:58:46.409497 29630 sgd_solver.cpp:106] Iteration 14680, lr = 0.01
I0123 18:58:53.687124 29630 solver.cpp:237] Iteration 14700, loss = 4.24542
I0123 18:58:53.687158 29630 solver.cpp:253]     Train net output #0: loss = 4.24542 (* 1 = 4.24542 loss)
I0123 18:58:53.687165 29630 sgd_solver.cpp:106] Iteration 14700, lr = 0.01
I0123 18:59:00.991600 29630 solver.cpp:237] Iteration 14720, loss = 4.31552
I0123 18:59:00.991638 29630 solver.cpp:253]     Train net output #0: loss = 4.31552 (* 1 = 4.31552 loss)
I0123 18:59:00.991646 29630 sgd_solver.cpp:106] Iteration 14720, lr = 0.01
I0123 18:59:08.322739 29630 solver.cpp:237] Iteration 14740, loss = 4.33028
I0123 18:59:08.322778 29630 solver.cpp:253]     Train net output #0: loss = 4.33028 (* 1 = 4.33028 loss)
I0123 18:59:08.322784 29630 sgd_solver.cpp:106] Iteration 14740, lr = 0.01
I0123 18:59:15.587502 29630 solver.cpp:237] Iteration 14760, loss = 4.25984
I0123 18:59:15.587561 29630 solver.cpp:253]     Train net output #0: loss = 4.25984 (* 1 = 4.25984 loss)
I0123 18:59:15.587573 29630 sgd_solver.cpp:106] Iteration 14760, lr = 0.01
I0123 18:59:22.899695 29630 solver.cpp:237] Iteration 14780, loss = 4.37232
I0123 18:59:22.899858 29630 solver.cpp:253]     Train net output #0: loss = 4.37232 (* 1 = 4.37232 loss)
I0123 18:59:22.899868 29630 sgd_solver.cpp:106] Iteration 14780, lr = 0.01
I0123 18:59:30.223357 29630 solver.cpp:237] Iteration 14800, loss = 4.4165
I0123 18:59:30.223397 29630 solver.cpp:253]     Train net output #0: loss = 4.4165 (* 1 = 4.4165 loss)
I0123 18:59:30.223402 29630 sgd_solver.cpp:106] Iteration 14800, lr = 0.01
I0123 18:59:37.506948 29630 solver.cpp:237] Iteration 14820, loss = 4.21025
I0123 18:59:37.506985 29630 solver.cpp:253]     Train net output #0: loss = 4.21025 (* 1 = 4.21025 loss)
I0123 18:59:37.506992 29630 sgd_solver.cpp:106] Iteration 14820, lr = 0.01
I0123 18:59:44.775058 29630 solver.cpp:237] Iteration 14840, loss = 4.42631
I0123 18:59:44.775097 29630 solver.cpp:253]     Train net output #0: loss = 4.42631 (* 1 = 4.42631 loss)
I0123 18:59:44.775104 29630 sgd_solver.cpp:106] Iteration 14840, lr = 0.01
I0123 18:59:52.182695 29630 solver.cpp:237] Iteration 14860, loss = 4.18877
I0123 18:59:52.182740 29630 solver.cpp:253]     Train net output #0: loss = 4.18877 (* 1 = 4.18877 loss)
I0123 18:59:52.182747 29630 sgd_solver.cpp:106] Iteration 14860, lr = 0.01
I0123 18:59:59.501039 29630 solver.cpp:237] Iteration 14880, loss = 4.20012
I0123 18:59:59.501198 29630 solver.cpp:253]     Train net output #0: loss = 4.20012 (* 1 = 4.20012 loss)
I0123 18:59:59.501214 29630 sgd_solver.cpp:106] Iteration 14880, lr = 0.01
I0123 19:00:06.804929 29630 solver.cpp:237] Iteration 14900, loss = 4.1344
I0123 19:00:06.804967 29630 solver.cpp:253]     Train net output #0: loss = 4.1344 (* 1 = 4.1344 loss)
I0123 19:00:06.804973 29630 sgd_solver.cpp:106] Iteration 14900, lr = 0.01
I0123 19:00:14.078246 29630 solver.cpp:237] Iteration 14920, loss = 4.41436
I0123 19:00:14.078286 29630 solver.cpp:253]     Train net output #0: loss = 4.41436 (* 1 = 4.41436 loss)
I0123 19:00:14.078294 29630 sgd_solver.cpp:106] Iteration 14920, lr = 0.01
I0123 19:00:21.397419 29630 solver.cpp:237] Iteration 14940, loss = 4.36061
I0123 19:00:21.397459 29630 solver.cpp:253]     Train net output #0: loss = 4.36061 (* 1 = 4.36061 loss)
I0123 19:00:21.397464 29630 sgd_solver.cpp:106] Iteration 14940, lr = 0.01
I0123 19:00:28.629710 29630 solver.cpp:237] Iteration 14960, loss = 4.34086
I0123 19:00:28.629751 29630 solver.cpp:253]     Train net output #0: loss = 4.34086 (* 1 = 4.34086 loss)
I0123 19:00:28.629770 29630 sgd_solver.cpp:106] Iteration 14960, lr = 0.01
I0123 19:00:35.903481 29630 solver.cpp:237] Iteration 14980, loss = 4.35862
I0123 19:00:35.903617 29630 solver.cpp:253]     Train net output #0: loss = 4.35862 (* 1 = 4.35862 loss)
I0123 19:00:35.903635 29630 sgd_solver.cpp:106] Iteration 14980, lr = 0.01
I0123 19:00:42.897760 29630 solver.cpp:341] Iteration 15000, Testing net (#0)
I0123 19:00:49.303776 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 19:01:56.493851 29630 solver.cpp:409]     Test net output #0: accuracy = 0.18834
I0123 19:01:56.494007 29630 solver.cpp:409]     Test net output #1: loss = 4.11908 (* 1 = 4.11908 loss)
I0123 19:01:56.534533 29630 solver.cpp:237] Iteration 15000, loss = 4.27822
I0123 19:01:56.534576 29630 solver.cpp:253]     Train net output #0: loss = 4.27822 (* 1 = 4.27822 loss)
I0123 19:01:56.534584 29630 sgd_solver.cpp:106] Iteration 15000, lr = 0.01
I0123 19:02:03.069383 29630 solver.cpp:237] Iteration 15020, loss = 4.41817
I0123 19:02:03.069422 29630 solver.cpp:253]     Train net output #0: loss = 4.41817 (* 1 = 4.41817 loss)
I0123 19:02:03.069427 29630 sgd_solver.cpp:106] Iteration 15020, lr = 0.01
I0123 19:02:10.283772 29630 solver.cpp:237] Iteration 15040, loss = 4.20525
I0123 19:02:10.283814 29630 solver.cpp:253]     Train net output #0: loss = 4.20525 (* 1 = 4.20525 loss)
I0123 19:02:10.283821 29630 sgd_solver.cpp:106] Iteration 15040, lr = 0.01
I0123 19:02:17.559537 29630 solver.cpp:237] Iteration 15060, loss = 4.21998
I0123 19:02:17.559576 29630 solver.cpp:253]     Train net output #0: loss = 4.21998 (* 1 = 4.21998 loss)
I0123 19:02:17.559582 29630 sgd_solver.cpp:106] Iteration 15060, lr = 0.01
I0123 19:02:24.807519 29630 solver.cpp:237] Iteration 15080, loss = 4.08598
I0123 19:02:24.807559 29630 solver.cpp:253]     Train net output #0: loss = 4.08598 (* 1 = 4.08598 loss)
I0123 19:02:24.807564 29630 sgd_solver.cpp:106] Iteration 15080, lr = 0.01
I0123 19:02:28.890488 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 19:02:32.113973 29630 solver.cpp:237] Iteration 15100, loss = 4.3385
I0123 19:02:32.114012 29630 solver.cpp:253]     Train net output #0: loss = 4.3385 (* 1 = 4.3385 loss)
I0123 19:02:32.114018 29630 sgd_solver.cpp:106] Iteration 15100, lr = 0.01
I0123 19:02:39.383874 29630 solver.cpp:237] Iteration 15120, loss = 4.54547
I0123 19:02:39.383913 29630 solver.cpp:253]     Train net output #0: loss = 4.54547 (* 1 = 4.54547 loss)
I0123 19:02:39.383919 29630 sgd_solver.cpp:106] Iteration 15120, lr = 0.01
I0123 19:02:46.628473 29630 solver.cpp:237] Iteration 15140, loss = 4.27038
I0123 19:02:46.628511 29630 solver.cpp:253]     Train net output #0: loss = 4.27038 (* 1 = 4.27038 loss)
I0123 19:02:46.628517 29630 sgd_solver.cpp:106] Iteration 15140, lr = 0.01
I0123 19:02:53.876406 29630 solver.cpp:237] Iteration 15160, loss = 4.36498
I0123 19:02:53.876446 29630 solver.cpp:253]     Train net output #0: loss = 4.36498 (* 1 = 4.36498 loss)
I0123 19:02:53.876451 29630 sgd_solver.cpp:106] Iteration 15160, lr = 0.01
I0123 19:03:01.141261 29630 solver.cpp:237] Iteration 15180, loss = 4.49509
I0123 19:03:01.141415 29630 solver.cpp:253]     Train net output #0: loss = 4.49509 (* 1 = 4.49509 loss)
I0123 19:03:01.141423 29630 sgd_solver.cpp:106] Iteration 15180, lr = 0.01
I0123 19:03:08.435279 29630 solver.cpp:237] Iteration 15200, loss = 4.104
I0123 19:03:08.435318 29630 solver.cpp:253]     Train net output #0: loss = 4.104 (* 1 = 4.104 loss)
I0123 19:03:08.435325 29630 sgd_solver.cpp:106] Iteration 15200, lr = 0.01
I0123 19:03:15.712652 29630 solver.cpp:237] Iteration 15220, loss = 4.39409
I0123 19:03:15.712692 29630 solver.cpp:253]     Train net output #0: loss = 4.39409 (* 1 = 4.39409 loss)
I0123 19:03:15.712697 29630 sgd_solver.cpp:106] Iteration 15220, lr = 0.01
I0123 19:03:23.018088 29630 solver.cpp:237] Iteration 15240, loss = 4.04776
I0123 19:03:23.018126 29630 solver.cpp:253]     Train net output #0: loss = 4.04776 (* 1 = 4.04776 loss)
I0123 19:03:23.018132 29630 sgd_solver.cpp:106] Iteration 15240, lr = 0.01
I0123 19:03:30.327690 29630 solver.cpp:237] Iteration 15260, loss = 4.227
I0123 19:03:30.327729 29630 solver.cpp:253]     Train net output #0: loss = 4.227 (* 1 = 4.227 loss)
I0123 19:03:30.327735 29630 sgd_solver.cpp:106] Iteration 15260, lr = 0.01
I0123 19:03:37.610970 29630 solver.cpp:237] Iteration 15280, loss = 4.28298
I0123 19:03:37.611156 29630 solver.cpp:253]     Train net output #0: loss = 4.28298 (* 1 = 4.28298 loss)
I0123 19:03:37.611166 29630 sgd_solver.cpp:106] Iteration 15280, lr = 0.01
I0123 19:03:44.877468 29630 solver.cpp:237] Iteration 15300, loss = 4.13934
I0123 19:03:44.877516 29630 solver.cpp:253]     Train net output #0: loss = 4.13934 (* 1 = 4.13934 loss)
I0123 19:03:44.877522 29630 sgd_solver.cpp:106] Iteration 15300, lr = 0.01
I0123 19:03:52.183054 29630 solver.cpp:237] Iteration 15320, loss = 4.45384
I0123 19:03:52.183094 29630 solver.cpp:253]     Train net output #0: loss = 4.45384 (* 1 = 4.45384 loss)
I0123 19:03:52.183099 29630 sgd_solver.cpp:106] Iteration 15320, lr = 0.01
I0123 19:03:59.597718 29630 solver.cpp:237] Iteration 15340, loss = 4.71767
I0123 19:03:59.597756 29630 solver.cpp:253]     Train net output #0: loss = 4.71767 (* 1 = 4.71767 loss)
I0123 19:03:59.597764 29630 sgd_solver.cpp:106] Iteration 15340, lr = 0.01
I0123 19:04:06.926478 29630 solver.cpp:237] Iteration 15360, loss = 4.20088
I0123 19:04:06.926517 29630 solver.cpp:253]     Train net output #0: loss = 4.20088 (* 1 = 4.20088 loss)
I0123 19:04:06.926522 29630 sgd_solver.cpp:106] Iteration 15360, lr = 0.01
I0123 19:04:14.277053 29630 solver.cpp:237] Iteration 15380, loss = 4.32097
I0123 19:04:14.277179 29630 solver.cpp:253]     Train net output #0: loss = 4.32097 (* 1 = 4.32097 loss)
I0123 19:04:14.277187 29630 sgd_solver.cpp:106] Iteration 15380, lr = 0.01
I0123 19:04:21.551928 29630 solver.cpp:237] Iteration 15400, loss = 4.07997
I0123 19:04:21.551966 29630 solver.cpp:253]     Train net output #0: loss = 4.07997 (* 1 = 4.07997 loss)
I0123 19:04:21.551973 29630 sgd_solver.cpp:106] Iteration 15400, lr = 0.01
I0123 19:04:28.796052 29630 solver.cpp:237] Iteration 15420, loss = 4.27582
I0123 19:04:28.796092 29630 solver.cpp:253]     Train net output #0: loss = 4.27582 (* 1 = 4.27582 loss)
I0123 19:04:28.796097 29630 sgd_solver.cpp:106] Iteration 15420, lr = 0.01
I0123 19:04:36.059734 29630 solver.cpp:237] Iteration 15440, loss = 4.16935
I0123 19:04:36.059775 29630 solver.cpp:253]     Train net output #0: loss = 4.16935 (* 1 = 4.16935 loss)
I0123 19:04:36.059782 29630 sgd_solver.cpp:106] Iteration 15440, lr = 0.01
I0123 19:04:43.327008 29630 solver.cpp:237] Iteration 15460, loss = 4.58428
I0123 19:04:43.327046 29630 solver.cpp:253]     Train net output #0: loss = 4.58428 (* 1 = 4.58428 loss)
I0123 19:04:43.327051 29630 sgd_solver.cpp:106] Iteration 15460, lr = 0.01
I0123 19:04:50.568749 29630 solver.cpp:237] Iteration 15480, loss = 4.27641
I0123 19:04:50.568862 29630 solver.cpp:253]     Train net output #0: loss = 4.27641 (* 1 = 4.27641 loss)
I0123 19:04:50.568869 29630 sgd_solver.cpp:106] Iteration 15480, lr = 0.01
I0123 19:04:57.845746 29630 solver.cpp:237] Iteration 15500, loss = 4.2909
I0123 19:04:57.845784 29630 solver.cpp:253]     Train net output #0: loss = 4.2909 (* 1 = 4.2909 loss)
I0123 19:04:57.845790 29630 sgd_solver.cpp:106] Iteration 15500, lr = 0.01
I0123 19:05:05.068754 29630 solver.cpp:237] Iteration 15520, loss = 4.42511
I0123 19:05:05.068794 29630 solver.cpp:253]     Train net output #0: loss = 4.42511 (* 1 = 4.42511 loss)
I0123 19:05:05.068801 29630 sgd_solver.cpp:106] Iteration 15520, lr = 0.01
I0123 19:05:12.286574 29630 solver.cpp:237] Iteration 15540, loss = 4.23634
I0123 19:05:12.286615 29630 solver.cpp:253]     Train net output #0: loss = 4.23634 (* 1 = 4.23634 loss)
I0123 19:05:12.286622 29630 sgd_solver.cpp:106] Iteration 15540, lr = 0.01
I0123 19:05:19.517823 29630 solver.cpp:237] Iteration 15560, loss = 4.47054
I0123 19:05:19.517863 29630 solver.cpp:253]     Train net output #0: loss = 4.47054 (* 1 = 4.47054 loss)
I0123 19:05:19.517870 29630 sgd_solver.cpp:106] Iteration 15560, lr = 0.01
I0123 19:05:26.775614 29630 solver.cpp:237] Iteration 15580, loss = 4.24997
I0123 19:05:26.775717 29630 solver.cpp:253]     Train net output #0: loss = 4.24997 (* 1 = 4.24997 loss)
I0123 19:05:26.775734 29630 sgd_solver.cpp:106] Iteration 15580, lr = 0.01
I0123 19:05:34.058791 29630 solver.cpp:237] Iteration 15600, loss = 4.36194
I0123 19:05:34.058830 29630 solver.cpp:253]     Train net output #0: loss = 4.36194 (* 1 = 4.36194 loss)
I0123 19:05:34.058836 29630 sgd_solver.cpp:106] Iteration 15600, lr = 0.01
I0123 19:05:41.276149 29630 solver.cpp:237] Iteration 15620, loss = 4.3553
I0123 19:05:41.276188 29630 solver.cpp:253]     Train net output #0: loss = 4.3553 (* 1 = 4.3553 loss)
I0123 19:05:41.276195 29630 sgd_solver.cpp:106] Iteration 15620, lr = 0.01
I0123 19:05:48.541635 29630 solver.cpp:237] Iteration 15640, loss = 4.02931
I0123 19:05:48.541674 29630 solver.cpp:253]     Train net output #0: loss = 4.02931 (* 1 = 4.02931 loss)
I0123 19:05:48.541681 29630 sgd_solver.cpp:106] Iteration 15640, lr = 0.01
I0123 19:05:55.703304 29630 solver.cpp:237] Iteration 15660, loss = 4.19036
I0123 19:05:55.703342 29630 solver.cpp:253]     Train net output #0: loss = 4.19036 (* 1 = 4.19036 loss)
I0123 19:05:55.703348 29630 sgd_solver.cpp:106] Iteration 15660, lr = 0.01
I0123 19:06:02.972421 29630 solver.cpp:237] Iteration 15680, loss = 4.12903
I0123 19:06:02.972600 29630 solver.cpp:253]     Train net output #0: loss = 4.12903 (* 1 = 4.12903 loss)
I0123 19:06:02.972609 29630 sgd_solver.cpp:106] Iteration 15680, lr = 0.01
I0123 19:06:10.199359 29630 solver.cpp:237] Iteration 15700, loss = 4.37432
I0123 19:06:10.199398 29630 solver.cpp:253]     Train net output #0: loss = 4.37432 (* 1 = 4.37432 loss)
I0123 19:06:10.199404 29630 sgd_solver.cpp:106] Iteration 15700, lr = 0.01
I0123 19:06:17.449393 29630 solver.cpp:237] Iteration 15720, loss = 4.29845
I0123 19:06:17.449431 29630 solver.cpp:253]     Train net output #0: loss = 4.29845 (* 1 = 4.29845 loss)
I0123 19:06:17.449437 29630 sgd_solver.cpp:106] Iteration 15720, lr = 0.01
I0123 19:06:24.698989 29630 solver.cpp:237] Iteration 15740, loss = 4.24578
I0123 19:06:24.699028 29630 solver.cpp:253]     Train net output #0: loss = 4.24578 (* 1 = 4.24578 loss)
I0123 19:06:24.699033 29630 sgd_solver.cpp:106] Iteration 15740, lr = 0.01
I0123 19:06:31.950621 29630 solver.cpp:237] Iteration 15760, loss = 4.25966
I0123 19:06:31.950661 29630 solver.cpp:253]     Train net output #0: loss = 4.25966 (* 1 = 4.25966 loss)
I0123 19:06:31.950667 29630 sgd_solver.cpp:106] Iteration 15760, lr = 0.01
I0123 19:06:39.195991 29630 solver.cpp:237] Iteration 15780, loss = 4.509
I0123 19:06:39.196156 29630 solver.cpp:253]     Train net output #0: loss = 4.509 (* 1 = 4.509 loss)
I0123 19:06:39.196164 29630 sgd_solver.cpp:106] Iteration 15780, lr = 0.01
I0123 19:06:46.416087 29630 solver.cpp:237] Iteration 15800, loss = 4.03585
I0123 19:06:46.416127 29630 solver.cpp:253]     Train net output #0: loss = 4.03585 (* 1 = 4.03585 loss)
I0123 19:06:46.416133 29630 sgd_solver.cpp:106] Iteration 15800, lr = 0.01
I0123 19:06:53.641950 29630 solver.cpp:237] Iteration 15820, loss = 4.34172
I0123 19:06:53.641988 29630 solver.cpp:253]     Train net output #0: loss = 4.34172 (* 1 = 4.34172 loss)
I0123 19:06:53.641993 29630 sgd_solver.cpp:106] Iteration 15820, lr = 0.01
I0123 19:07:00.929987 29630 solver.cpp:237] Iteration 15840, loss = 4.13654
I0123 19:07:00.930027 29630 solver.cpp:253]     Train net output #0: loss = 4.13654 (* 1 = 4.13654 loss)
I0123 19:07:00.930032 29630 sgd_solver.cpp:106] Iteration 15840, lr = 0.01
I0123 19:07:08.228510 29630 solver.cpp:237] Iteration 15860, loss = 3.99443
I0123 19:07:08.228566 29630 solver.cpp:253]     Train net output #0: loss = 3.99443 (* 1 = 3.99443 loss)
I0123 19:07:08.228574 29630 sgd_solver.cpp:106] Iteration 15860, lr = 0.01
I0123 19:07:15.478348 29630 solver.cpp:237] Iteration 15880, loss = 4.32435
I0123 19:07:15.478489 29630 solver.cpp:253]     Train net output #0: loss = 4.32435 (* 1 = 4.32435 loss)
I0123 19:07:15.478497 29630 sgd_solver.cpp:106] Iteration 15880, lr = 0.01
I0123 19:07:22.741821 29630 solver.cpp:237] Iteration 15900, loss = 4.16066
I0123 19:07:22.741850 29630 solver.cpp:253]     Train net output #0: loss = 4.16066 (* 1 = 4.16066 loss)
I0123 19:07:22.741857 29630 sgd_solver.cpp:106] Iteration 15900, lr = 0.01
I0123 19:07:30.006539 29630 solver.cpp:237] Iteration 15920, loss = 4.11177
I0123 19:07:30.006577 29630 solver.cpp:253]     Train net output #0: loss = 4.11177 (* 1 = 4.11177 loss)
I0123 19:07:30.006583 29630 sgd_solver.cpp:106] Iteration 15920, lr = 0.01
I0123 19:07:37.315764 29630 solver.cpp:237] Iteration 15940, loss = 4.23879
I0123 19:07:37.315804 29630 solver.cpp:253]     Train net output #0: loss = 4.23879 (* 1 = 4.23879 loss)
I0123 19:07:37.315809 29630 sgd_solver.cpp:106] Iteration 15940, lr = 0.01
I0123 19:07:44.666407 29630 solver.cpp:237] Iteration 15960, loss = 4.25798
I0123 19:07:44.666445 29630 solver.cpp:253]     Train net output #0: loss = 4.25798 (* 1 = 4.25798 loss)
I0123 19:07:44.666451 29630 sgd_solver.cpp:106] Iteration 15960, lr = 0.01
I0123 19:07:51.955286 29630 solver.cpp:237] Iteration 15980, loss = 4.23863
I0123 19:07:51.955462 29630 solver.cpp:253]     Train net output #0: loss = 4.23863 (* 1 = 4.23863 loss)
I0123 19:07:51.955471 29630 sgd_solver.cpp:106] Iteration 15980, lr = 0.01
I0123 19:07:58.962620 29630 solver.cpp:341] Iteration 16000, Testing net (#0)
I0123 19:08:05.979775 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 19:09:12.889576 29630 solver.cpp:409]     Test net output #0: accuracy = 0.19762
I0123 19:09:12.889735 29630 solver.cpp:409]     Test net output #1: loss = 4.03938 (* 1 = 4.03938 loss)
I0123 19:09:12.930256 29630 solver.cpp:237] Iteration 16000, loss = 4.28043
I0123 19:09:12.930294 29630 solver.cpp:253]     Train net output #0: loss = 4.28043 (* 1 = 4.28043 loss)
I0123 19:09:12.930300 29630 sgd_solver.cpp:106] Iteration 16000, lr = 0.01
I0123 19:09:19.484184 29630 solver.cpp:237] Iteration 16020, loss = 4.28197
I0123 19:09:19.484223 29630 solver.cpp:253]     Train net output #0: loss = 4.28197 (* 1 = 4.28197 loss)
I0123 19:09:19.484230 29630 sgd_solver.cpp:106] Iteration 16020, lr = 0.01
I0123 19:09:26.679204 29630 solver.cpp:237] Iteration 16040, loss = 4.00759
I0123 19:09:26.679244 29630 solver.cpp:253]     Train net output #0: loss = 4.00759 (* 1 = 4.00759 loss)
I0123 19:09:26.679250 29630 sgd_solver.cpp:106] Iteration 16040, lr = 0.01
I0123 19:09:33.900773 29630 solver.cpp:237] Iteration 16060, loss = 4.28206
I0123 19:09:33.900810 29630 solver.cpp:253]     Train net output #0: loss = 4.28206 (* 1 = 4.28206 loss)
I0123 19:09:33.900816 29630 sgd_solver.cpp:106] Iteration 16060, lr = 0.01
I0123 19:09:41.141499 29630 solver.cpp:237] Iteration 16080, loss = 4.2944
I0123 19:09:41.141537 29630 solver.cpp:253]     Train net output #0: loss = 4.2944 (* 1 = 4.2944 loss)
I0123 19:09:41.141543 29630 sgd_solver.cpp:106] Iteration 16080, lr = 0.01
I0123 19:09:47.369354 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 19:09:48.381208 29630 solver.cpp:237] Iteration 16100, loss = 4.09321
I0123 19:09:48.381248 29630 solver.cpp:253]     Train net output #0: loss = 4.09321 (* 1 = 4.09321 loss)
I0123 19:09:48.381254 29630 sgd_solver.cpp:106] Iteration 16100, lr = 0.01
I0123 19:09:55.636773 29630 solver.cpp:237] Iteration 16120, loss = 4.09586
I0123 19:09:55.636811 29630 solver.cpp:253]     Train net output #0: loss = 4.09586 (* 1 = 4.09586 loss)
I0123 19:09:55.636816 29630 sgd_solver.cpp:106] Iteration 16120, lr = 0.01
I0123 19:10:02.878520 29630 solver.cpp:237] Iteration 16140, loss = 4.03944
I0123 19:10:02.878556 29630 solver.cpp:253]     Train net output #0: loss = 4.03944 (* 1 = 4.03944 loss)
I0123 19:10:02.878562 29630 sgd_solver.cpp:106] Iteration 16140, lr = 0.01
I0123 19:10:10.131152 29630 solver.cpp:237] Iteration 16160, loss = 4.2135
I0123 19:10:10.131191 29630 solver.cpp:253]     Train net output #0: loss = 4.2135 (* 1 = 4.2135 loss)
I0123 19:10:10.131197 29630 sgd_solver.cpp:106] Iteration 16160, lr = 0.01
I0123 19:10:17.366832 29630 solver.cpp:237] Iteration 16180, loss = 4.39686
I0123 19:10:17.366870 29630 solver.cpp:253]     Train net output #0: loss = 4.39686 (* 1 = 4.39686 loss)
I0123 19:10:17.366878 29630 sgd_solver.cpp:106] Iteration 16180, lr = 0.01
I0123 19:10:24.598348 29630 solver.cpp:237] Iteration 16200, loss = 4.30977
I0123 19:10:24.598455 29630 solver.cpp:253]     Train net output #0: loss = 4.30977 (* 1 = 4.30977 loss)
I0123 19:10:24.598471 29630 sgd_solver.cpp:106] Iteration 16200, lr = 0.01
I0123 19:10:31.820538 29630 solver.cpp:237] Iteration 16220, loss = 4.27391
I0123 19:10:31.820580 29630 solver.cpp:253]     Train net output #0: loss = 4.27391 (* 1 = 4.27391 loss)
I0123 19:10:31.820585 29630 sgd_solver.cpp:106] Iteration 16220, lr = 0.01
I0123 19:10:39.036511 29630 solver.cpp:237] Iteration 16240, loss = 4.30569
I0123 19:10:39.036550 29630 solver.cpp:253]     Train net output #0: loss = 4.30569 (* 1 = 4.30569 loss)
I0123 19:10:39.036556 29630 sgd_solver.cpp:106] Iteration 16240, lr = 0.01
I0123 19:10:46.339864 29630 solver.cpp:237] Iteration 16260, loss = 4.22084
I0123 19:10:46.339902 29630 solver.cpp:253]     Train net output #0: loss = 4.22084 (* 1 = 4.22084 loss)
I0123 19:10:46.339908 29630 sgd_solver.cpp:106] Iteration 16260, lr = 0.01
I0123 19:10:53.634870 29630 solver.cpp:237] Iteration 16280, loss = 4.18362
I0123 19:10:53.634908 29630 solver.cpp:253]     Train net output #0: loss = 4.18362 (* 1 = 4.18362 loss)
I0123 19:10:53.634914 29630 sgd_solver.cpp:106] Iteration 16280, lr = 0.01
I0123 19:11:00.934839 29630 solver.cpp:237] Iteration 16300, loss = 4.2349
I0123 19:11:00.935011 29630 solver.cpp:253]     Train net output #0: loss = 4.2349 (* 1 = 4.2349 loss)
I0123 19:11:00.935019 29630 sgd_solver.cpp:106] Iteration 16300, lr = 0.01
I0123 19:11:08.235759 29630 solver.cpp:237] Iteration 16320, loss = 4.26809
I0123 19:11:08.235796 29630 solver.cpp:253]     Train net output #0: loss = 4.26809 (* 1 = 4.26809 loss)
I0123 19:11:08.235802 29630 sgd_solver.cpp:106] Iteration 16320, lr = 0.01
I0123 19:11:15.537783 29630 solver.cpp:237] Iteration 16340, loss = 4.30005
I0123 19:11:15.537820 29630 solver.cpp:253]     Train net output #0: loss = 4.30005 (* 1 = 4.30005 loss)
I0123 19:11:15.537827 29630 sgd_solver.cpp:106] Iteration 16340, lr = 0.01
I0123 19:11:22.830744 29630 solver.cpp:237] Iteration 16360, loss = 4.18174
I0123 19:11:22.830781 29630 solver.cpp:253]     Train net output #0: loss = 4.18174 (* 1 = 4.18174 loss)
I0123 19:11:22.830787 29630 sgd_solver.cpp:106] Iteration 16360, lr = 0.01
I0123 19:11:30.119160 29630 solver.cpp:237] Iteration 16380, loss = 4.41626
I0123 19:11:30.119199 29630 solver.cpp:253]     Train net output #0: loss = 4.41626 (* 1 = 4.41626 loss)
I0123 19:11:30.119205 29630 sgd_solver.cpp:106] Iteration 16380, lr = 0.01
I0123 19:11:37.390682 29630 solver.cpp:237] Iteration 16400, loss = 4.0864
I0123 19:11:37.390781 29630 solver.cpp:253]     Train net output #0: loss = 4.0864 (* 1 = 4.0864 loss)
I0123 19:11:37.390797 29630 sgd_solver.cpp:106] Iteration 16400, lr = 0.01
I0123 19:11:44.711642 29630 solver.cpp:237] Iteration 16420, loss = 3.9597
I0123 19:11:44.711680 29630 solver.cpp:253]     Train net output #0: loss = 3.9597 (* 1 = 3.9597 loss)
I0123 19:11:44.711686 29630 sgd_solver.cpp:106] Iteration 16420, lr = 0.01
I0123 19:11:51.974784 29630 solver.cpp:237] Iteration 16440, loss = 4.02949
I0123 19:11:51.974822 29630 solver.cpp:253]     Train net output #0: loss = 4.02949 (* 1 = 4.02949 loss)
I0123 19:11:51.974829 29630 sgd_solver.cpp:106] Iteration 16440, lr = 0.01
I0123 19:11:59.292543 29630 solver.cpp:237] Iteration 16460, loss = 4.23688
I0123 19:11:59.292592 29630 solver.cpp:253]     Train net output #0: loss = 4.23688 (* 1 = 4.23688 loss)
I0123 19:11:59.292598 29630 sgd_solver.cpp:106] Iteration 16460, lr = 0.01
I0123 19:12:06.621711 29630 solver.cpp:237] Iteration 16480, loss = 4.01939
I0123 19:12:06.621748 29630 solver.cpp:253]     Train net output #0: loss = 4.01939 (* 1 = 4.01939 loss)
I0123 19:12:06.621754 29630 sgd_solver.cpp:106] Iteration 16480, lr = 0.01
I0123 19:12:13.889130 29630 solver.cpp:237] Iteration 16500, loss = 4.11867
I0123 19:12:13.889263 29630 solver.cpp:253]     Train net output #0: loss = 4.11867 (* 1 = 4.11867 loss)
I0123 19:12:13.889279 29630 sgd_solver.cpp:106] Iteration 16500, lr = 0.01
I0123 19:12:21.217039 29630 solver.cpp:237] Iteration 16520, loss = 4.28141
I0123 19:12:21.217102 29630 solver.cpp:253]     Train net output #0: loss = 4.28141 (* 1 = 4.28141 loss)
I0123 19:12:21.217116 29630 sgd_solver.cpp:106] Iteration 16520, lr = 0.01
I0123 19:12:28.542717 29630 solver.cpp:237] Iteration 16540, loss = 4.17496
I0123 19:12:28.542755 29630 solver.cpp:253]     Train net output #0: loss = 4.17496 (* 1 = 4.17496 loss)
I0123 19:12:28.542762 29630 sgd_solver.cpp:106] Iteration 16540, lr = 0.01
I0123 19:12:35.810055 29630 solver.cpp:237] Iteration 16560, loss = 4.03832
I0123 19:12:35.810094 29630 solver.cpp:253]     Train net output #0: loss = 4.03832 (* 1 = 4.03832 loss)
I0123 19:12:35.810101 29630 sgd_solver.cpp:106] Iteration 16560, lr = 0.01
I0123 19:12:43.093904 29630 solver.cpp:237] Iteration 16580, loss = 4.17309
I0123 19:12:43.093942 29630 solver.cpp:253]     Train net output #0: loss = 4.17309 (* 1 = 4.17309 loss)
I0123 19:12:43.093948 29630 sgd_solver.cpp:106] Iteration 16580, lr = 0.01
I0123 19:12:50.348043 29630 solver.cpp:237] Iteration 16600, loss = 4.17362
I0123 19:12:50.348152 29630 solver.cpp:253]     Train net output #0: loss = 4.17362 (* 1 = 4.17362 loss)
I0123 19:12:50.348170 29630 sgd_solver.cpp:106] Iteration 16600, lr = 0.01
I0123 19:12:57.654737 29630 solver.cpp:237] Iteration 16620, loss = 4.27268
I0123 19:12:57.654777 29630 solver.cpp:253]     Train net output #0: loss = 4.27268 (* 1 = 4.27268 loss)
I0123 19:12:57.654783 29630 sgd_solver.cpp:106] Iteration 16620, lr = 0.01
I0123 19:13:04.943397 29630 solver.cpp:237] Iteration 16640, loss = 4.28222
I0123 19:13:04.943442 29630 solver.cpp:253]     Train net output #0: loss = 4.28222 (* 1 = 4.28222 loss)
I0123 19:13:04.943449 29630 sgd_solver.cpp:106] Iteration 16640, lr = 0.01
I0123 19:13:12.229140 29630 solver.cpp:237] Iteration 16660, loss = 4.05685
I0123 19:13:12.229169 29630 solver.cpp:253]     Train net output #0: loss = 4.05685 (* 1 = 4.05685 loss)
I0123 19:13:12.229176 29630 sgd_solver.cpp:106] Iteration 16660, lr = 0.01
I0123 19:13:19.483444 29630 solver.cpp:237] Iteration 16680, loss = 4.24234
I0123 19:13:19.483484 29630 solver.cpp:253]     Train net output #0: loss = 4.24234 (* 1 = 4.24234 loss)
I0123 19:13:19.483490 29630 sgd_solver.cpp:106] Iteration 16680, lr = 0.01
I0123 19:13:26.772125 29630 solver.cpp:237] Iteration 16700, loss = 4.34682
I0123 19:13:26.772269 29630 solver.cpp:253]     Train net output #0: loss = 4.34682 (* 1 = 4.34682 loss)
I0123 19:13:26.772286 29630 sgd_solver.cpp:106] Iteration 16700, lr = 0.01
I0123 19:13:34.033948 29630 solver.cpp:237] Iteration 16720, loss = 4.11121
I0123 19:13:34.033987 29630 solver.cpp:253]     Train net output #0: loss = 4.11121 (* 1 = 4.11121 loss)
I0123 19:13:34.033993 29630 sgd_solver.cpp:106] Iteration 16720, lr = 0.01
I0123 19:13:41.310853 29630 solver.cpp:237] Iteration 16740, loss = 4.21938
I0123 19:13:41.310892 29630 solver.cpp:253]     Train net output #0: loss = 4.21938 (* 1 = 4.21938 loss)
I0123 19:13:41.310899 29630 sgd_solver.cpp:106] Iteration 16740, lr = 0.01
I0123 19:13:48.590102 29630 solver.cpp:237] Iteration 16760, loss = 4.23701
I0123 19:13:48.590140 29630 solver.cpp:253]     Train net output #0: loss = 4.23701 (* 1 = 4.23701 loss)
I0123 19:13:48.590147 29630 sgd_solver.cpp:106] Iteration 16760, lr = 0.01
I0123 19:13:55.848629 29630 solver.cpp:237] Iteration 16780, loss = 4.16114
I0123 19:13:55.848670 29630 solver.cpp:253]     Train net output #0: loss = 4.16114 (* 1 = 4.16114 loss)
I0123 19:13:55.848675 29630 sgd_solver.cpp:106] Iteration 16780, lr = 0.01
I0123 19:14:03.082273 29630 solver.cpp:237] Iteration 16800, loss = 4.3616
I0123 19:14:03.082437 29630 solver.cpp:253]     Train net output #0: loss = 4.3616 (* 1 = 4.3616 loss)
I0123 19:14:03.082445 29630 sgd_solver.cpp:106] Iteration 16800, lr = 0.01
I0123 19:14:10.346132 29630 solver.cpp:237] Iteration 16820, loss = 4.10757
I0123 19:14:10.346171 29630 solver.cpp:253]     Train net output #0: loss = 4.10757 (* 1 = 4.10757 loss)
I0123 19:14:10.346177 29630 sgd_solver.cpp:106] Iteration 16820, lr = 0.01
I0123 19:14:17.603049 29630 solver.cpp:237] Iteration 16840, loss = 3.93088
I0123 19:14:17.603088 29630 solver.cpp:253]     Train net output #0: loss = 3.93088 (* 1 = 3.93088 loss)
I0123 19:14:17.603094 29630 sgd_solver.cpp:106] Iteration 16840, lr = 0.01
I0123 19:14:24.860854 29630 solver.cpp:237] Iteration 16860, loss = 4.39425
I0123 19:14:24.860893 29630 solver.cpp:253]     Train net output #0: loss = 4.39425 (* 1 = 4.39425 loss)
I0123 19:14:24.860900 29630 sgd_solver.cpp:106] Iteration 16860, lr = 0.01
I0123 19:14:32.077433 29630 solver.cpp:237] Iteration 16880, loss = 4.03854
I0123 19:14:32.077476 29630 solver.cpp:253]     Train net output #0: loss = 4.03854 (* 1 = 4.03854 loss)
I0123 19:14:32.077496 29630 sgd_solver.cpp:106] Iteration 16880, lr = 0.01
I0123 19:14:39.313622 29630 solver.cpp:237] Iteration 16900, loss = 4.4577
I0123 19:14:39.313721 29630 solver.cpp:253]     Train net output #0: loss = 4.4577 (* 1 = 4.4577 loss)
I0123 19:14:39.313737 29630 sgd_solver.cpp:106] Iteration 16900, lr = 0.01
I0123 19:14:46.571358 29630 solver.cpp:237] Iteration 16920, loss = 4.17694
I0123 19:14:46.571398 29630 solver.cpp:253]     Train net output #0: loss = 4.17694 (* 1 = 4.17694 loss)
I0123 19:14:46.571403 29630 sgd_solver.cpp:106] Iteration 16920, lr = 0.01
I0123 19:14:53.813971 29630 solver.cpp:237] Iteration 16940, loss = 4.2621
I0123 19:14:53.814009 29630 solver.cpp:253]     Train net output #0: loss = 4.2621 (* 1 = 4.2621 loss)
I0123 19:14:53.814015 29630 sgd_solver.cpp:106] Iteration 16940, lr = 0.01
I0123 19:15:01.063128 29630 solver.cpp:237] Iteration 16960, loss = 4.33689
I0123 19:15:01.063165 29630 solver.cpp:253]     Train net output #0: loss = 4.33689 (* 1 = 4.33689 loss)
I0123 19:15:01.063171 29630 sgd_solver.cpp:106] Iteration 16960, lr = 0.01
I0123 19:15:08.330019 29630 solver.cpp:237] Iteration 16980, loss = 4.10859
I0123 19:15:08.330057 29630 solver.cpp:253]     Train net output #0: loss = 4.10859 (* 1 = 4.10859 loss)
I0123 19:15:08.330063 29630 sgd_solver.cpp:106] Iteration 16980, lr = 0.01
I0123 19:15:15.345896 29630 solver.cpp:341] Iteration 17000, Testing net (#0)
I0123 19:15:22.682629 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 19:16:29.450167 29630 solver.cpp:409]     Test net output #0: accuracy = 0.20264
I0123 19:16:29.450294 29630 solver.cpp:409]     Test net output #1: loss = 4.01301 (* 1 = 4.01301 loss)
I0123 19:16:29.490908 29630 solver.cpp:237] Iteration 17000, loss = 4.31239
I0123 19:16:29.490947 29630 solver.cpp:253]     Train net output #0: loss = 4.31239 (* 1 = 4.31239 loss)
I0123 19:16:29.490955 29630 sgd_solver.cpp:106] Iteration 17000, lr = 0.01
I0123 19:16:36.027470 29630 solver.cpp:237] Iteration 17020, loss = 4.53786
I0123 19:16:36.027518 29630 solver.cpp:253]     Train net output #0: loss = 4.53786 (* 1 = 4.53786 loss)
I0123 19:16:36.027525 29630 sgd_solver.cpp:106] Iteration 17020, lr = 0.01
I0123 19:16:43.326387 29630 solver.cpp:237] Iteration 17040, loss = 3.92765
I0123 19:16:43.326423 29630 solver.cpp:253]     Train net output #0: loss = 3.92765 (* 1 = 3.92765 loss)
I0123 19:16:43.326431 29630 sgd_solver.cpp:106] Iteration 17040, lr = 0.01
I0123 19:16:50.632761 29630 solver.cpp:237] Iteration 17060, loss = 4.0232
I0123 19:16:50.632802 29630 solver.cpp:253]     Train net output #0: loss = 4.0232 (* 1 = 4.0232 loss)
I0123 19:16:50.632808 29630 sgd_solver.cpp:106] Iteration 17060, lr = 0.01
I0123 19:16:57.891155 29630 solver.cpp:237] Iteration 17080, loss = 4.038
I0123 19:16:57.891194 29630 solver.cpp:253]     Train net output #0: loss = 4.038 (* 1 = 4.038 loss)
I0123 19:16:57.891199 29630 sgd_solver.cpp:106] Iteration 17080, lr = 0.01
I0123 19:17:05.155602 29630 solver.cpp:237] Iteration 17100, loss = 4.19138
I0123 19:17:05.155735 29630 solver.cpp:253]     Train net output #0: loss = 4.19138 (* 1 = 4.19138 loss)
I0123 19:17:05.155750 29630 sgd_solver.cpp:106] Iteration 17100, lr = 0.01
I0123 19:17:06.312206 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 19:17:12.369982 29630 solver.cpp:237] Iteration 17120, loss = 4.19691
I0123 19:17:12.370020 29630 solver.cpp:253]     Train net output #0: loss = 4.19691 (* 1 = 4.19691 loss)
I0123 19:17:12.370026 29630 sgd_solver.cpp:106] Iteration 17120, lr = 0.01
I0123 19:17:19.626417 29630 solver.cpp:237] Iteration 17140, loss = 4.30576
I0123 19:17:19.626456 29630 solver.cpp:253]     Train net output #0: loss = 4.30576 (* 1 = 4.30576 loss)
I0123 19:17:19.626461 29630 sgd_solver.cpp:106] Iteration 17140, lr = 0.01
I0123 19:17:26.894706 29630 solver.cpp:237] Iteration 17160, loss = 4.04138
I0123 19:17:26.894744 29630 solver.cpp:253]     Train net output #0: loss = 4.04138 (* 1 = 4.04138 loss)
I0123 19:17:26.894752 29630 sgd_solver.cpp:106] Iteration 17160, lr = 0.01
I0123 19:17:34.144713 29630 solver.cpp:237] Iteration 17180, loss = 4.34605
I0123 19:17:34.144752 29630 solver.cpp:253]     Train net output #0: loss = 4.34605 (* 1 = 4.34605 loss)
I0123 19:17:34.144758 29630 sgd_solver.cpp:106] Iteration 17180, lr = 0.01
I0123 19:17:41.396761 29630 solver.cpp:237] Iteration 17200, loss = 4.16247
I0123 19:17:41.396909 29630 solver.cpp:253]     Train net output #0: loss = 4.16247 (* 1 = 4.16247 loss)
I0123 19:17:41.396917 29630 sgd_solver.cpp:106] Iteration 17200, lr = 0.01
I0123 19:17:48.668042 29630 solver.cpp:237] Iteration 17220, loss = 4.13199
I0123 19:17:48.668079 29630 solver.cpp:253]     Train net output #0: loss = 4.13199 (* 1 = 4.13199 loss)
I0123 19:17:48.668086 29630 sgd_solver.cpp:106] Iteration 17220, lr = 0.01
I0123 19:17:55.873379 29630 solver.cpp:237] Iteration 17240, loss = 4.32857
I0123 19:17:55.873415 29630 solver.cpp:253]     Train net output #0: loss = 4.32857 (* 1 = 4.32857 loss)
I0123 19:17:55.873422 29630 sgd_solver.cpp:106] Iteration 17240, lr = 0.01
I0123 19:18:03.169242 29630 solver.cpp:237] Iteration 17260, loss = 4.26879
I0123 19:18:03.169281 29630 solver.cpp:253]     Train net output #0: loss = 4.26879 (* 1 = 4.26879 loss)
I0123 19:18:03.169287 29630 sgd_solver.cpp:106] Iteration 17260, lr = 0.01
I0123 19:18:10.409065 29630 solver.cpp:237] Iteration 17280, loss = 4.089
I0123 19:18:10.409102 29630 solver.cpp:253]     Train net output #0: loss = 4.089 (* 1 = 4.089 loss)
I0123 19:18:10.409108 29630 sgd_solver.cpp:106] Iteration 17280, lr = 0.01
I0123 19:18:17.628692 29630 solver.cpp:237] Iteration 17300, loss = 4.20047
I0123 19:18:17.628826 29630 solver.cpp:253]     Train net output #0: loss = 4.20047 (* 1 = 4.20047 loss)
I0123 19:18:17.628834 29630 sgd_solver.cpp:106] Iteration 17300, lr = 0.01
I0123 19:18:24.886801 29630 solver.cpp:237] Iteration 17320, loss = 3.97069
I0123 19:18:24.886839 29630 solver.cpp:253]     Train net output #0: loss = 3.97069 (* 1 = 3.97069 loss)
I0123 19:18:24.886845 29630 sgd_solver.cpp:106] Iteration 17320, lr = 0.01
I0123 19:18:32.162190 29630 solver.cpp:237] Iteration 17340, loss = 4.12022
I0123 19:18:32.162228 29630 solver.cpp:253]     Train net output #0: loss = 4.12022 (* 1 = 4.12022 loss)
I0123 19:18:32.162235 29630 sgd_solver.cpp:106] Iteration 17340, lr = 0.01
I0123 19:18:39.403367 29630 solver.cpp:237] Iteration 17360, loss = 3.94164
I0123 19:18:39.403404 29630 solver.cpp:253]     Train net output #0: loss = 3.94164 (* 1 = 3.94164 loss)
I0123 19:18:39.403410 29630 sgd_solver.cpp:106] Iteration 17360, lr = 0.01
I0123 19:18:46.641428 29630 solver.cpp:237] Iteration 17380, loss = 4.26773
I0123 19:18:46.641469 29630 solver.cpp:253]     Train net output #0: loss = 4.26773 (* 1 = 4.26773 loss)
I0123 19:18:46.641474 29630 sgd_solver.cpp:106] Iteration 17380, lr = 0.01
I0123 19:18:53.893951 29630 solver.cpp:237] Iteration 17400, loss = 4.16713
I0123 19:18:53.894084 29630 solver.cpp:253]     Train net output #0: loss = 4.16713 (* 1 = 4.16713 loss)
I0123 19:18:53.894100 29630 sgd_solver.cpp:106] Iteration 17400, lr = 0.01
I0123 19:19:01.146952 29630 solver.cpp:237] Iteration 17420, loss = 4.26956
I0123 19:19:01.146991 29630 solver.cpp:253]     Train net output #0: loss = 4.26956 (* 1 = 4.26956 loss)
I0123 19:19:01.146997 29630 sgd_solver.cpp:106] Iteration 17420, lr = 0.01
I0123 19:19:08.402087 29630 solver.cpp:237] Iteration 17440, loss = 3.91706
I0123 19:19:08.402127 29630 solver.cpp:253]     Train net output #0: loss = 3.91706 (* 1 = 3.91706 loss)
I0123 19:19:08.402132 29630 sgd_solver.cpp:106] Iteration 17440, lr = 0.01
I0123 19:19:15.650475 29630 solver.cpp:237] Iteration 17460, loss = 4.13506
I0123 19:19:15.650513 29630 solver.cpp:253]     Train net output #0: loss = 4.13506 (* 1 = 4.13506 loss)
I0123 19:19:15.650519 29630 sgd_solver.cpp:106] Iteration 17460, lr = 0.01
I0123 19:19:22.896196 29630 solver.cpp:237] Iteration 17480, loss = 4.05169
I0123 19:19:22.896236 29630 solver.cpp:253]     Train net output #0: loss = 4.05169 (* 1 = 4.05169 loss)
I0123 19:19:22.896242 29630 sgd_solver.cpp:106] Iteration 17480, lr = 0.01
I0123 19:19:30.136834 29630 solver.cpp:237] Iteration 17500, loss = 4.2044
I0123 19:19:30.137011 29630 solver.cpp:253]     Train net output #0: loss = 4.2044 (* 1 = 4.2044 loss)
I0123 19:19:30.137018 29630 sgd_solver.cpp:106] Iteration 17500, lr = 0.01
I0123 19:19:37.438097 29630 solver.cpp:237] Iteration 17520, loss = 4.14838
I0123 19:19:37.438134 29630 solver.cpp:253]     Train net output #0: loss = 4.14838 (* 1 = 4.14838 loss)
I0123 19:19:37.438140 29630 sgd_solver.cpp:106] Iteration 17520, lr = 0.01
I0123 19:19:44.722766 29630 solver.cpp:237] Iteration 17540, loss = 4.2491
I0123 19:19:44.722805 29630 solver.cpp:253]     Train net output #0: loss = 4.2491 (* 1 = 4.2491 loss)
I0123 19:19:44.722810 29630 sgd_solver.cpp:106] Iteration 17540, lr = 0.01
I0123 19:19:51.975301 29630 solver.cpp:237] Iteration 17560, loss = 4.17747
I0123 19:19:51.975345 29630 solver.cpp:253]     Train net output #0: loss = 4.17747 (* 1 = 4.17747 loss)
I0123 19:19:51.975360 29630 sgd_solver.cpp:106] Iteration 17560, lr = 0.01
I0123 19:19:59.234448 29630 solver.cpp:237] Iteration 17580, loss = 4.16352
I0123 19:19:59.234486 29630 solver.cpp:253]     Train net output #0: loss = 4.16352 (* 1 = 4.16352 loss)
I0123 19:19:59.234493 29630 sgd_solver.cpp:106] Iteration 17580, lr = 0.01
I0123 19:20:06.491595 29630 solver.cpp:237] Iteration 17600, loss = 4.18295
I0123 19:20:06.491739 29630 solver.cpp:253]     Train net output #0: loss = 4.18295 (* 1 = 4.18295 loss)
I0123 19:20:06.491756 29630 sgd_solver.cpp:106] Iteration 17600, lr = 0.01
I0123 19:20:13.827690 29630 solver.cpp:237] Iteration 17620, loss = 4.03651
I0123 19:20:13.827728 29630 solver.cpp:253]     Train net output #0: loss = 4.03651 (* 1 = 4.03651 loss)
I0123 19:20:13.827734 29630 sgd_solver.cpp:106] Iteration 17620, lr = 0.01
I0123 19:20:21.079475 29630 solver.cpp:237] Iteration 17640, loss = 3.9802
I0123 19:20:21.079514 29630 solver.cpp:253]     Train net output #0: loss = 3.9802 (* 1 = 3.9802 loss)
I0123 19:20:21.079520 29630 sgd_solver.cpp:106] Iteration 17640, lr = 0.01
I0123 19:20:28.409324 29630 solver.cpp:237] Iteration 17660, loss = 3.91222
I0123 19:20:28.409385 29630 solver.cpp:253]     Train net output #0: loss = 3.91222 (* 1 = 3.91222 loss)
I0123 19:20:28.409394 29630 sgd_solver.cpp:106] Iteration 17660, lr = 0.01
I0123 19:20:35.682087 29630 solver.cpp:237] Iteration 17680, loss = 4.16671
I0123 19:20:35.682134 29630 solver.cpp:253]     Train net output #0: loss = 4.16671 (* 1 = 4.16671 loss)
I0123 19:20:35.682140 29630 sgd_solver.cpp:106] Iteration 17680, lr = 0.01
I0123 19:20:42.927219 29630 solver.cpp:237] Iteration 17700, loss = 3.88629
I0123 19:20:42.927366 29630 solver.cpp:253]     Train net output #0: loss = 3.88629 (* 1 = 3.88629 loss)
I0123 19:20:42.927374 29630 sgd_solver.cpp:106] Iteration 17700, lr = 0.01
I0123 19:20:50.169419 29630 solver.cpp:237] Iteration 17720, loss = 4.21804
I0123 19:20:50.169456 29630 solver.cpp:253]     Train net output #0: loss = 4.21804 (* 1 = 4.21804 loss)
I0123 19:20:50.169462 29630 sgd_solver.cpp:106] Iteration 17720, lr = 0.01
I0123 19:20:57.394415 29630 solver.cpp:237] Iteration 17740, loss = 4.14331
I0123 19:20:57.394455 29630 solver.cpp:253]     Train net output #0: loss = 4.14331 (* 1 = 4.14331 loss)
I0123 19:20:57.394461 29630 sgd_solver.cpp:106] Iteration 17740, lr = 0.01
I0123 19:21:04.658172 29630 solver.cpp:237] Iteration 17760, loss = 3.85534
I0123 19:21:04.658216 29630 solver.cpp:253]     Train net output #0: loss = 3.85534 (* 1 = 3.85534 loss)
I0123 19:21:04.658226 29630 sgd_solver.cpp:106] Iteration 17760, lr = 0.01
I0123 19:21:11.916498 29630 solver.cpp:237] Iteration 17780, loss = 3.92615
I0123 19:21:11.916538 29630 solver.cpp:253]     Train net output #0: loss = 3.92615 (* 1 = 3.92615 loss)
I0123 19:21:11.916543 29630 sgd_solver.cpp:106] Iteration 17780, lr = 0.01
I0123 19:21:19.145051 29630 solver.cpp:237] Iteration 17800, loss = 4.273
I0123 19:21:19.145143 29630 solver.cpp:253]     Train net output #0: loss = 4.273 (* 1 = 4.273 loss)
I0123 19:21:19.145150 29630 sgd_solver.cpp:106] Iteration 17800, lr = 0.01
I0123 19:21:26.398092 29630 solver.cpp:237] Iteration 17820, loss = 4.26715
I0123 19:21:26.398131 29630 solver.cpp:253]     Train net output #0: loss = 4.26715 (* 1 = 4.26715 loss)
I0123 19:21:26.398138 29630 sgd_solver.cpp:106] Iteration 17820, lr = 0.01
I0123 19:21:33.691174 29630 solver.cpp:237] Iteration 17840, loss = 4.21556
I0123 19:21:33.691213 29630 solver.cpp:253]     Train net output #0: loss = 4.21556 (* 1 = 4.21556 loss)
I0123 19:21:33.691220 29630 sgd_solver.cpp:106] Iteration 17840, lr = 0.01
I0123 19:21:40.912511 29630 solver.cpp:237] Iteration 17860, loss = 4.13611
I0123 19:21:40.912569 29630 solver.cpp:253]     Train net output #0: loss = 4.13611 (* 1 = 4.13611 loss)
I0123 19:21:40.912576 29630 sgd_solver.cpp:106] Iteration 17860, lr = 0.01
I0123 19:21:48.130229 29630 solver.cpp:237] Iteration 17880, loss = 4.16715
I0123 19:21:48.130269 29630 solver.cpp:253]     Train net output #0: loss = 4.16715 (* 1 = 4.16715 loss)
I0123 19:21:48.130275 29630 sgd_solver.cpp:106] Iteration 17880, lr = 0.01
I0123 19:21:55.359524 29630 solver.cpp:237] Iteration 17900, loss = 3.9823
I0123 19:21:55.359653 29630 solver.cpp:253]     Train net output #0: loss = 3.9823 (* 1 = 3.9823 loss)
I0123 19:21:55.359660 29630 sgd_solver.cpp:106] Iteration 17900, lr = 0.01
I0123 19:22:02.614586 29630 solver.cpp:237] Iteration 17920, loss = 4.14334
I0123 19:22:02.614624 29630 solver.cpp:253]     Train net output #0: loss = 4.14334 (* 1 = 4.14334 loss)
I0123 19:22:02.614630 29630 sgd_solver.cpp:106] Iteration 17920, lr = 0.01
I0123 19:22:09.852555 29630 solver.cpp:237] Iteration 17940, loss = 4.12051
I0123 19:22:09.852594 29630 solver.cpp:253]     Train net output #0: loss = 4.12051 (* 1 = 4.12051 loss)
I0123 19:22:09.852601 29630 sgd_solver.cpp:106] Iteration 17940, lr = 0.01
I0123 19:22:17.076269 29630 solver.cpp:237] Iteration 17960, loss = 4.167
I0123 19:22:17.076309 29630 solver.cpp:253]     Train net output #0: loss = 4.167 (* 1 = 4.167 loss)
I0123 19:22:17.076315 29630 sgd_solver.cpp:106] Iteration 17960, lr = 0.01
I0123 19:22:24.326994 29630 solver.cpp:237] Iteration 17980, loss = 4.01093
I0123 19:22:24.327033 29630 solver.cpp:253]     Train net output #0: loss = 4.01093 (* 1 = 4.01093 loss)
I0123 19:22:24.327039 29630 sgd_solver.cpp:106] Iteration 17980, lr = 0.01
I0123 19:22:31.303334 29630 solver.cpp:341] Iteration 18000, Testing net (#0)
I0123 19:22:39.051219 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 19:23:45.104854 29630 solver.cpp:409]     Test net output #0: accuracy = 0.20792
I0123 19:23:45.105025 29630 solver.cpp:409]     Test net output #1: loss = 3.95796 (* 1 = 3.95796 loss)
I0123 19:23:45.145589 29630 solver.cpp:237] Iteration 18000, loss = 4.22685
I0123 19:23:45.145625 29630 solver.cpp:253]     Train net output #0: loss = 4.22685 (* 1 = 4.22685 loss)
I0123 19:23:45.145633 29630 sgd_solver.cpp:106] Iteration 18000, lr = 0.01
I0123 19:23:51.731559 29630 solver.cpp:237] Iteration 18020, loss = 4.18532
I0123 19:23:51.731595 29630 solver.cpp:253]     Train net output #0: loss = 4.18532 (* 1 = 4.18532 loss)
I0123 19:23:51.731600 29630 sgd_solver.cpp:106] Iteration 18020, lr = 0.01
I0123 19:23:59.037674 29630 solver.cpp:237] Iteration 18040, loss = 4.18897
I0123 19:23:59.037713 29630 solver.cpp:253]     Train net output #0: loss = 4.18897 (* 1 = 4.18897 loss)
I0123 19:23:59.037719 29630 sgd_solver.cpp:106] Iteration 18040, lr = 0.01
I0123 19:24:06.313451 29630 solver.cpp:237] Iteration 18060, loss = 4.17697
I0123 19:24:06.313488 29630 solver.cpp:253]     Train net output #0: loss = 4.17697 (* 1 = 4.17697 loss)
I0123 19:24:06.313493 29630 sgd_solver.cpp:106] Iteration 18060, lr = 0.01
I0123 19:24:13.584363 29630 solver.cpp:237] Iteration 18080, loss = 4.03664
I0123 19:24:13.584401 29630 solver.cpp:253]     Train net output #0: loss = 4.03664 (* 1 = 4.03664 loss)
I0123 19:24:13.584408 29630 sgd_solver.cpp:106] Iteration 18080, lr = 0.01
I0123 19:24:20.905680 29630 solver.cpp:237] Iteration 18100, loss = 4.1328
I0123 19:24:20.905827 29630 solver.cpp:253]     Train net output #0: loss = 4.1328 (* 1 = 4.1328 loss)
I0123 19:24:20.905835 29630 sgd_solver.cpp:106] Iteration 18100, lr = 0.01
I0123 19:24:24.265007 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 19:24:28.242590 29630 solver.cpp:237] Iteration 18120, loss = 4.33671
I0123 19:24:28.242652 29630 solver.cpp:253]     Train net output #0: loss = 4.33671 (* 1 = 4.33671 loss)
I0123 19:24:28.242666 29630 sgd_solver.cpp:106] Iteration 18120, lr = 0.01
I0123 19:24:35.631973 29630 solver.cpp:237] Iteration 18140, loss = 4.26262
I0123 19:24:35.632011 29630 solver.cpp:253]     Train net output #0: loss = 4.26262 (* 1 = 4.26262 loss)
I0123 19:24:35.632019 29630 sgd_solver.cpp:106] Iteration 18140, lr = 0.01
I0123 19:24:42.895328 29630 solver.cpp:237] Iteration 18160, loss = 4.16157
I0123 19:24:42.895365 29630 solver.cpp:253]     Train net output #0: loss = 4.16157 (* 1 = 4.16157 loss)
I0123 19:24:42.895372 29630 sgd_solver.cpp:106] Iteration 18160, lr = 0.01
I0123 19:24:50.108666 29630 solver.cpp:237] Iteration 18180, loss = 4.07485
I0123 19:24:50.108703 29630 solver.cpp:253]     Train net output #0: loss = 4.07485 (* 1 = 4.07485 loss)
I0123 19:24:50.108711 29630 sgd_solver.cpp:106] Iteration 18180, lr = 0.01
I0123 19:24:57.380694 29630 solver.cpp:237] Iteration 18200, loss = 3.94909
I0123 19:24:57.380826 29630 solver.cpp:253]     Train net output #0: loss = 3.94909 (* 1 = 3.94909 loss)
I0123 19:24:57.380833 29630 sgd_solver.cpp:106] Iteration 18200, lr = 0.01
I0123 19:25:04.593732 29630 solver.cpp:237] Iteration 18220, loss = 4.17889
I0123 19:25:04.593770 29630 solver.cpp:253]     Train net output #0: loss = 4.17889 (* 1 = 4.17889 loss)
I0123 19:25:04.593776 29630 sgd_solver.cpp:106] Iteration 18220, lr = 0.01
I0123 19:25:11.821722 29630 solver.cpp:237] Iteration 18240, loss = 4.27411
I0123 19:25:11.821780 29630 solver.cpp:253]     Train net output #0: loss = 4.27411 (* 1 = 4.27411 loss)
I0123 19:25:11.821794 29630 sgd_solver.cpp:106] Iteration 18240, lr = 0.01
I0123 19:25:19.052157 29630 solver.cpp:237] Iteration 18260, loss = 4.07307
I0123 19:25:19.052197 29630 solver.cpp:253]     Train net output #0: loss = 4.07307 (* 1 = 4.07307 loss)
I0123 19:25:19.052203 29630 sgd_solver.cpp:106] Iteration 18260, lr = 0.01
I0123 19:25:26.286344 29630 solver.cpp:237] Iteration 18280, loss = 4.04795
I0123 19:25:26.286382 29630 solver.cpp:253]     Train net output #0: loss = 4.04795 (* 1 = 4.04795 loss)
I0123 19:25:26.286388 29630 sgd_solver.cpp:106] Iteration 18280, lr = 0.01
I0123 19:25:33.474062 29630 solver.cpp:237] Iteration 18300, loss = 3.8949
I0123 19:25:33.474207 29630 solver.cpp:253]     Train net output #0: loss = 3.8949 (* 1 = 3.8949 loss)
I0123 19:25:33.474215 29630 sgd_solver.cpp:106] Iteration 18300, lr = 0.01
I0123 19:25:40.715240 29630 solver.cpp:237] Iteration 18320, loss = 4.40289
I0123 19:25:40.715279 29630 solver.cpp:253]     Train net output #0: loss = 4.40289 (* 1 = 4.40289 loss)
I0123 19:25:40.715286 29630 sgd_solver.cpp:106] Iteration 18320, lr = 0.01
I0123 19:25:47.905760 29630 solver.cpp:237] Iteration 18340, loss = 4.07835
I0123 19:25:47.905800 29630 solver.cpp:253]     Train net output #0: loss = 4.07835 (* 1 = 4.07835 loss)
I0123 19:25:47.905807 29630 sgd_solver.cpp:106] Iteration 18340, lr = 0.01
I0123 19:25:55.125083 29630 solver.cpp:237] Iteration 18360, loss = 4.0739
I0123 19:25:55.125124 29630 solver.cpp:253]     Train net output #0: loss = 4.0739 (* 1 = 4.0739 loss)
I0123 19:25:55.125131 29630 sgd_solver.cpp:106] Iteration 18360, lr = 0.01
I0123 19:26:02.369695 29630 solver.cpp:237] Iteration 18380, loss = 4.04695
I0123 19:26:02.369734 29630 solver.cpp:253]     Train net output #0: loss = 4.04695 (* 1 = 4.04695 loss)
I0123 19:26:02.369740 29630 sgd_solver.cpp:106] Iteration 18380, lr = 0.01
I0123 19:26:09.618005 29630 solver.cpp:237] Iteration 18400, loss = 3.9848
I0123 19:26:09.618181 29630 solver.cpp:253]     Train net output #0: loss = 3.9848 (* 1 = 3.9848 loss)
I0123 19:26:09.618190 29630 sgd_solver.cpp:106] Iteration 18400, lr = 0.01
I0123 19:26:16.824285 29630 solver.cpp:237] Iteration 18420, loss = 4.11654
I0123 19:26:16.824324 29630 solver.cpp:253]     Train net output #0: loss = 4.11654 (* 1 = 4.11654 loss)
I0123 19:26:16.824331 29630 sgd_solver.cpp:106] Iteration 18420, lr = 0.01
I0123 19:26:24.015730 29630 solver.cpp:237] Iteration 18440, loss = 3.95054
I0123 19:26:24.015769 29630 solver.cpp:253]     Train net output #0: loss = 3.95054 (* 1 = 3.95054 loss)
I0123 19:26:24.015775 29630 sgd_solver.cpp:106] Iteration 18440, lr = 0.01
I0123 19:26:31.279999 29630 solver.cpp:237] Iteration 18460, loss = 4.27311
I0123 19:26:31.280040 29630 solver.cpp:253]     Train net output #0: loss = 4.27311 (* 1 = 4.27311 loss)
I0123 19:26:31.280045 29630 sgd_solver.cpp:106] Iteration 18460, lr = 0.01
I0123 19:26:38.518676 29630 solver.cpp:237] Iteration 18480, loss = 4.23226
I0123 19:26:38.518715 29630 solver.cpp:253]     Train net output #0: loss = 4.23226 (* 1 = 4.23226 loss)
I0123 19:26:38.518721 29630 sgd_solver.cpp:106] Iteration 18480, lr = 0.01
I0123 19:26:45.746529 29630 solver.cpp:237] Iteration 18500, loss = 4.18168
I0123 19:26:45.746659 29630 solver.cpp:253]     Train net output #0: loss = 4.18168 (* 1 = 4.18168 loss)
I0123 19:26:45.746666 29630 sgd_solver.cpp:106] Iteration 18500, lr = 0.01
I0123 19:26:52.925259 29630 solver.cpp:237] Iteration 18520, loss = 4.1119
I0123 19:26:52.925298 29630 solver.cpp:253]     Train net output #0: loss = 4.1119 (* 1 = 4.1119 loss)
I0123 19:26:52.925304 29630 sgd_solver.cpp:106] Iteration 18520, lr = 0.01
I0123 19:27:00.177814 29630 solver.cpp:237] Iteration 18540, loss = 4.15087
I0123 19:27:00.177852 29630 solver.cpp:253]     Train net output #0: loss = 4.15087 (* 1 = 4.15087 loss)
I0123 19:27:00.177858 29630 sgd_solver.cpp:106] Iteration 18540, lr = 0.01
I0123 19:27:07.433138 29630 solver.cpp:237] Iteration 18560, loss = 4.19835
I0123 19:27:07.433178 29630 solver.cpp:253]     Train net output #0: loss = 4.19835 (* 1 = 4.19835 loss)
I0123 19:27:07.433184 29630 sgd_solver.cpp:106] Iteration 18560, lr = 0.01
I0123 19:27:14.711503 29630 solver.cpp:237] Iteration 18580, loss = 3.91642
I0123 19:27:14.711542 29630 solver.cpp:253]     Train net output #0: loss = 3.91642 (* 1 = 3.91642 loss)
I0123 19:27:14.711549 29630 sgd_solver.cpp:106] Iteration 18580, lr = 0.01
I0123 19:27:21.951697 29630 solver.cpp:237] Iteration 18600, loss = 4.01196
I0123 19:27:21.951810 29630 solver.cpp:253]     Train net output #0: loss = 4.01196 (* 1 = 4.01196 loss)
I0123 19:27:21.951819 29630 sgd_solver.cpp:106] Iteration 18600, lr = 0.01
I0123 19:27:29.268476 29630 solver.cpp:237] Iteration 18620, loss = 4.38704
I0123 19:27:29.268510 29630 solver.cpp:253]     Train net output #0: loss = 4.38704 (* 1 = 4.38704 loss)
I0123 19:27:29.268517 29630 sgd_solver.cpp:106] Iteration 18620, lr = 0.01
I0123 19:27:36.513420 29630 solver.cpp:237] Iteration 18640, loss = 4.12138
I0123 19:27:36.513459 29630 solver.cpp:253]     Train net output #0: loss = 4.12138 (* 1 = 4.12138 loss)
I0123 19:27:36.513465 29630 sgd_solver.cpp:106] Iteration 18640, lr = 0.01
I0123 19:27:43.770903 29630 solver.cpp:237] Iteration 18660, loss = 4.16198
I0123 19:27:43.770942 29630 solver.cpp:253]     Train net output #0: loss = 4.16198 (* 1 = 4.16198 loss)
I0123 19:27:43.770947 29630 sgd_solver.cpp:106] Iteration 18660, lr = 0.01
I0123 19:27:50.987480 29630 solver.cpp:237] Iteration 18680, loss = 4.18584
I0123 19:27:50.987520 29630 solver.cpp:253]     Train net output #0: loss = 4.18584 (* 1 = 4.18584 loss)
I0123 19:27:50.987525 29630 sgd_solver.cpp:106] Iteration 18680, lr = 0.01
I0123 19:27:58.254014 29630 solver.cpp:237] Iteration 18700, loss = 4.19023
I0123 19:27:58.254191 29630 solver.cpp:253]     Train net output #0: loss = 4.19023 (* 1 = 4.19023 loss)
I0123 19:27:58.254199 29630 sgd_solver.cpp:106] Iteration 18700, lr = 0.01
I0123 19:28:05.540637 29630 solver.cpp:237] Iteration 18720, loss = 4.17162
I0123 19:28:05.540675 29630 solver.cpp:253]     Train net output #0: loss = 4.17162 (* 1 = 4.17162 loss)
I0123 19:28:05.540681 29630 sgd_solver.cpp:106] Iteration 18720, lr = 0.01
I0123 19:28:12.836856 29630 solver.cpp:237] Iteration 18740, loss = 3.88266
I0123 19:28:12.836904 29630 solver.cpp:253]     Train net output #0: loss = 3.88266 (* 1 = 3.88266 loss)
I0123 19:28:12.836910 29630 sgd_solver.cpp:106] Iteration 18740, lr = 0.01
I0123 19:28:20.160755 29630 solver.cpp:237] Iteration 18760, loss = 4.34137
I0123 19:28:20.160799 29630 solver.cpp:253]     Train net output #0: loss = 4.34137 (* 1 = 4.34137 loss)
I0123 19:28:20.160816 29630 sgd_solver.cpp:106] Iteration 18760, lr = 0.01
I0123 19:28:27.411483 29630 solver.cpp:237] Iteration 18780, loss = 4.38537
I0123 19:28:27.411521 29630 solver.cpp:253]     Train net output #0: loss = 4.38537 (* 1 = 4.38537 loss)
I0123 19:28:27.411527 29630 sgd_solver.cpp:106] Iteration 18780, lr = 0.01
I0123 19:28:34.702184 29630 solver.cpp:237] Iteration 18800, loss = 4.27081
I0123 19:28:34.702348 29630 solver.cpp:253]     Train net output #0: loss = 4.27081 (* 1 = 4.27081 loss)
I0123 19:28:34.702356 29630 sgd_solver.cpp:106] Iteration 18800, lr = 0.01
I0123 19:28:41.965939 29630 solver.cpp:237] Iteration 18820, loss = 4.12517
I0123 19:28:41.966017 29630 solver.cpp:253]     Train net output #0: loss = 4.12517 (* 1 = 4.12517 loss)
I0123 19:28:41.966032 29630 sgd_solver.cpp:106] Iteration 18820, lr = 0.01
I0123 19:28:49.236582 29630 solver.cpp:237] Iteration 18840, loss = 4.17982
I0123 19:28:49.236620 29630 solver.cpp:253]     Train net output #0: loss = 4.17982 (* 1 = 4.17982 loss)
I0123 19:28:49.236626 29630 sgd_solver.cpp:106] Iteration 18840, lr = 0.01
I0123 19:28:56.538261 29630 solver.cpp:237] Iteration 18860, loss = 4.21151
I0123 19:28:56.538300 29630 solver.cpp:253]     Train net output #0: loss = 4.21151 (* 1 = 4.21151 loss)
I0123 19:28:56.538306 29630 sgd_solver.cpp:106] Iteration 18860, lr = 0.01
I0123 19:29:03.783267 29630 solver.cpp:237] Iteration 18880, loss = 4.05405
I0123 19:29:03.783305 29630 solver.cpp:253]     Train net output #0: loss = 4.05405 (* 1 = 4.05405 loss)
I0123 19:29:03.783311 29630 sgd_solver.cpp:106] Iteration 18880, lr = 0.01
I0123 19:29:11.078562 29630 solver.cpp:237] Iteration 18900, loss = 3.98152
I0123 19:29:11.078730 29630 solver.cpp:253]     Train net output #0: loss = 3.98152 (* 1 = 3.98152 loss)
I0123 19:29:11.078742 29630 sgd_solver.cpp:106] Iteration 18900, lr = 0.01
I0123 19:29:18.339205 29630 solver.cpp:237] Iteration 18920, loss = 4.01323
I0123 19:29:18.339241 29630 solver.cpp:253]     Train net output #0: loss = 4.01323 (* 1 = 4.01323 loss)
I0123 19:29:18.339247 29630 sgd_solver.cpp:106] Iteration 18920, lr = 0.01
I0123 19:29:25.585234 29630 solver.cpp:237] Iteration 18940, loss = 4.22993
I0123 19:29:25.585273 29630 solver.cpp:253]     Train net output #0: loss = 4.22993 (* 1 = 4.22993 loss)
I0123 19:29:25.585278 29630 sgd_solver.cpp:106] Iteration 18940, lr = 0.01
I0123 19:29:32.866205 29630 solver.cpp:237] Iteration 18960, loss = 4.11593
I0123 19:29:32.866243 29630 solver.cpp:253]     Train net output #0: loss = 4.11593 (* 1 = 4.11593 loss)
I0123 19:29:32.866250 29630 sgd_solver.cpp:106] Iteration 18960, lr = 0.01
I0123 19:29:40.167089 29630 solver.cpp:237] Iteration 18980, loss = 3.98483
I0123 19:29:40.167129 29630 solver.cpp:253]     Train net output #0: loss = 3.98483 (* 1 = 3.98483 loss)
I0123 19:29:40.167135 29630 sgd_solver.cpp:106] Iteration 18980, lr = 0.01
I0123 19:29:47.157143 29630 solver.cpp:341] Iteration 19000, Testing net (#0)
I0123 19:29:55.329262 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 19:31:00.846628 29630 solver.cpp:409]     Test net output #0: accuracy = 0.21876
I0123 19:31:00.846760 29630 solver.cpp:409]     Test net output #1: loss = 3.88062 (* 1 = 3.88062 loss)
I0123 19:31:00.887570 29630 solver.cpp:237] Iteration 19000, loss = 4.08652
I0123 19:31:00.887609 29630 solver.cpp:253]     Train net output #0: loss = 4.08652 (* 1 = 4.08652 loss)
I0123 19:31:00.887614 29630 sgd_solver.cpp:106] Iteration 19000, lr = 0.01
I0123 19:31:07.418601 29630 solver.cpp:237] Iteration 19020, loss = 3.91913
I0123 19:31:07.418640 29630 solver.cpp:253]     Train net output #0: loss = 3.91913 (* 1 = 3.91913 loss)
I0123 19:31:07.418647 29630 sgd_solver.cpp:106] Iteration 19020, lr = 0.01
I0123 19:31:14.671514 29630 solver.cpp:237] Iteration 19040, loss = 3.90573
I0123 19:31:14.671553 29630 solver.cpp:253]     Train net output #0: loss = 3.90573 (* 1 = 3.90573 loss)
I0123 19:31:14.671560 29630 sgd_solver.cpp:106] Iteration 19040, lr = 0.01
I0123 19:31:21.926077 29630 solver.cpp:237] Iteration 19060, loss = 3.8705
I0123 19:31:21.926116 29630 solver.cpp:253]     Train net output #0: loss = 3.8705 (* 1 = 3.8705 loss)
I0123 19:31:21.926122 29630 sgd_solver.cpp:106] Iteration 19060, lr = 0.01
I0123 19:31:29.188164 29630 solver.cpp:237] Iteration 19080, loss = 4.1468
I0123 19:31:29.188205 29630 solver.cpp:253]     Train net output #0: loss = 4.1468 (* 1 = 4.1468 loss)
I0123 19:31:29.188210 29630 sgd_solver.cpp:106] Iteration 19080, lr = 0.01
I0123 19:31:36.431643 29630 solver.cpp:237] Iteration 19100, loss = 4.05066
I0123 19:31:36.431813 29630 solver.cpp:253]     Train net output #0: loss = 4.05066 (* 1 = 4.05066 loss)
I0123 19:31:36.431823 29630 sgd_solver.cpp:106] Iteration 19100, lr = 0.01
I0123 19:31:41.916229 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 19:31:43.667732 29630 solver.cpp:237] Iteration 19120, loss = 3.90375
I0123 19:31:43.667773 29630 solver.cpp:253]     Train net output #0: loss = 3.90375 (* 1 = 3.90375 loss)
I0123 19:31:43.667789 29630 sgd_solver.cpp:106] Iteration 19120, lr = 0.01
I0123 19:31:50.938024 29630 solver.cpp:237] Iteration 19140, loss = 4.30477
I0123 19:31:50.938061 29630 solver.cpp:253]     Train net output #0: loss = 4.30477 (* 1 = 4.30477 loss)
I0123 19:31:50.938067 29630 sgd_solver.cpp:106] Iteration 19140, lr = 0.01
I0123 19:31:58.176625 29630 solver.cpp:237] Iteration 19160, loss = 3.9913
I0123 19:31:58.176664 29630 solver.cpp:253]     Train net output #0: loss = 3.9913 (* 1 = 3.9913 loss)
I0123 19:31:58.176671 29630 sgd_solver.cpp:106] Iteration 19160, lr = 0.01
I0123 19:32:05.464854 29630 solver.cpp:237] Iteration 19180, loss = 3.95323
I0123 19:32:05.464892 29630 solver.cpp:253]     Train net output #0: loss = 3.95323 (* 1 = 3.95323 loss)
I0123 19:32:05.464898 29630 sgd_solver.cpp:106] Iteration 19180, lr = 0.01
I0123 19:32:12.804139 29630 solver.cpp:237] Iteration 19200, loss = 4.08663
I0123 19:32:12.804306 29630 solver.cpp:253]     Train net output #0: loss = 4.08663 (* 1 = 4.08663 loss)
I0123 19:32:12.804314 29630 sgd_solver.cpp:106] Iteration 19200, lr = 0.01
I0123 19:32:20.116538 29630 solver.cpp:237] Iteration 19220, loss = 4.04249
I0123 19:32:20.116577 29630 solver.cpp:253]     Train net output #0: loss = 4.04249 (* 1 = 4.04249 loss)
I0123 19:32:20.116583 29630 sgd_solver.cpp:106] Iteration 19220, lr = 0.01
I0123 19:32:27.364766 29630 solver.cpp:237] Iteration 19240, loss = 4.03972
I0123 19:32:27.364805 29630 solver.cpp:253]     Train net output #0: loss = 4.03972 (* 1 = 4.03972 loss)
I0123 19:32:27.364811 29630 sgd_solver.cpp:106] Iteration 19240, lr = 0.01
I0123 19:32:34.623447 29630 solver.cpp:237] Iteration 19260, loss = 4.00976
I0123 19:32:34.623486 29630 solver.cpp:253]     Train net output #0: loss = 4.00976 (* 1 = 4.00976 loss)
I0123 19:32:34.623492 29630 sgd_solver.cpp:106] Iteration 19260, lr = 0.01
I0123 19:32:41.932642 29630 solver.cpp:237] Iteration 19280, loss = 4.27527
I0123 19:32:41.932682 29630 solver.cpp:253]     Train net output #0: loss = 4.27527 (* 1 = 4.27527 loss)
I0123 19:32:41.932688 29630 sgd_solver.cpp:106] Iteration 19280, lr = 0.01
I0123 19:32:49.179428 29630 solver.cpp:237] Iteration 19300, loss = 4.09843
I0123 19:32:49.179544 29630 solver.cpp:253]     Train net output #0: loss = 4.09843 (* 1 = 4.09843 loss)
I0123 19:32:49.179551 29630 sgd_solver.cpp:106] Iteration 19300, lr = 0.01
I0123 19:32:56.429496 29630 solver.cpp:237] Iteration 19320, loss = 4.08733
I0123 19:32:56.429533 29630 solver.cpp:253]     Train net output #0: loss = 4.08733 (* 1 = 4.08733 loss)
I0123 19:32:56.429539 29630 sgd_solver.cpp:106] Iteration 19320, lr = 0.01
I0123 19:33:03.710589 29630 solver.cpp:237] Iteration 19340, loss = 3.91717
I0123 19:33:03.710628 29630 solver.cpp:253]     Train net output #0: loss = 3.91717 (* 1 = 3.91717 loss)
I0123 19:33:03.710635 29630 sgd_solver.cpp:106] Iteration 19340, lr = 0.01
I0123 19:33:10.927268 29630 solver.cpp:237] Iteration 19360, loss = 4.21828
I0123 19:33:10.927306 29630 solver.cpp:253]     Train net output #0: loss = 4.21828 (* 1 = 4.21828 loss)
I0123 19:33:10.927312 29630 sgd_solver.cpp:106] Iteration 19360, lr = 0.01
I0123 19:33:18.195722 29630 solver.cpp:237] Iteration 19380, loss = 4.01314
I0123 19:33:18.195761 29630 solver.cpp:253]     Train net output #0: loss = 4.01314 (* 1 = 4.01314 loss)
I0123 19:33:18.195767 29630 sgd_solver.cpp:106] Iteration 19380, lr = 0.01
I0123 19:33:25.411917 29630 solver.cpp:237] Iteration 19400, loss = 4.10966
I0123 19:33:25.412082 29630 solver.cpp:253]     Train net output #0: loss = 4.10966 (* 1 = 4.10966 loss)
I0123 19:33:25.412091 29630 sgd_solver.cpp:106] Iteration 19400, lr = 0.01
I0123 19:33:32.708037 29630 solver.cpp:237] Iteration 19420, loss = 4.08915
I0123 19:33:32.708081 29630 solver.cpp:253]     Train net output #0: loss = 4.08915 (* 1 = 4.08915 loss)
I0123 19:33:32.708089 29630 sgd_solver.cpp:106] Iteration 19420, lr = 0.01
I0123 19:33:39.983180 29630 solver.cpp:237] Iteration 19440, loss = 4.22427
I0123 19:33:39.983219 29630 solver.cpp:253]     Train net output #0: loss = 4.22427 (* 1 = 4.22427 loss)
I0123 19:33:39.983237 29630 sgd_solver.cpp:106] Iteration 19440, lr = 0.01
I0123 19:33:47.225592 29630 solver.cpp:237] Iteration 19460, loss = 3.86714
I0123 19:33:47.225631 29630 solver.cpp:253]     Train net output #0: loss = 3.86714 (* 1 = 3.86714 loss)
I0123 19:33:47.225638 29630 sgd_solver.cpp:106] Iteration 19460, lr = 0.01
I0123 19:33:54.473637 29630 solver.cpp:237] Iteration 19480, loss = 3.82453
I0123 19:33:54.473676 29630 solver.cpp:253]     Train net output #0: loss = 3.82453 (* 1 = 3.82453 loss)
I0123 19:33:54.473683 29630 sgd_solver.cpp:106] Iteration 19480, lr = 0.01
I0123 19:34:01.711227 29630 solver.cpp:237] Iteration 19500, loss = 4.23031
I0123 19:34:01.711405 29630 solver.cpp:253]     Train net output #0: loss = 4.23031 (* 1 = 4.23031 loss)
I0123 19:34:01.711413 29630 sgd_solver.cpp:106] Iteration 19500, lr = 0.01
I0123 19:34:08.963425 29630 solver.cpp:237] Iteration 19520, loss = 4.08005
I0123 19:34:08.963465 29630 solver.cpp:253]     Train net output #0: loss = 4.08005 (* 1 = 4.08005 loss)
I0123 19:34:08.963471 29630 sgd_solver.cpp:106] Iteration 19520, lr = 0.01
I0123 19:34:16.186501 29630 solver.cpp:237] Iteration 19540, loss = 4.15314
I0123 19:34:16.186539 29630 solver.cpp:253]     Train net output #0: loss = 4.15314 (* 1 = 4.15314 loss)
I0123 19:34:16.186545 29630 sgd_solver.cpp:106] Iteration 19540, lr = 0.01
I0123 19:34:23.409983 29630 solver.cpp:237] Iteration 19560, loss = 3.96863
I0123 19:34:23.410019 29630 solver.cpp:253]     Train net output #0: loss = 3.96863 (* 1 = 3.96863 loss)
I0123 19:34:23.410027 29630 sgd_solver.cpp:106] Iteration 19560, lr = 0.01
I0123 19:34:30.649802 29630 solver.cpp:237] Iteration 19580, loss = 3.77281
I0123 19:34:30.649840 29630 solver.cpp:253]     Train net output #0: loss = 3.77281 (* 1 = 3.77281 loss)
I0123 19:34:30.649847 29630 sgd_solver.cpp:106] Iteration 19580, lr = 0.01
I0123 19:34:37.876003 29630 solver.cpp:237] Iteration 19600, loss = 4.00307
I0123 19:34:37.876148 29630 solver.cpp:253]     Train net output #0: loss = 4.00307 (* 1 = 4.00307 loss)
I0123 19:34:37.876155 29630 sgd_solver.cpp:106] Iteration 19600, lr = 0.01
I0123 19:34:45.071043 29630 solver.cpp:237] Iteration 19620, loss = 4.01576
I0123 19:34:45.071080 29630 solver.cpp:253]     Train net output #0: loss = 4.01576 (* 1 = 4.01576 loss)
I0123 19:34:45.071086 29630 sgd_solver.cpp:106] Iteration 19620, lr = 0.01
I0123 19:34:52.230996 29630 solver.cpp:237] Iteration 19640, loss = 3.8896
I0123 19:34:52.231036 29630 solver.cpp:253]     Train net output #0: loss = 3.8896 (* 1 = 3.8896 loss)
I0123 19:34:52.231042 29630 sgd_solver.cpp:106] Iteration 19640, lr = 0.01
I0123 19:34:59.426735 29630 solver.cpp:237] Iteration 19660, loss = 4.26631
I0123 19:34:59.426774 29630 solver.cpp:253]     Train net output #0: loss = 4.26631 (* 1 = 4.26631 loss)
I0123 19:34:59.426780 29630 sgd_solver.cpp:106] Iteration 19660, lr = 0.01
I0123 19:35:06.627717 29630 solver.cpp:237] Iteration 19680, loss = 4.17076
I0123 19:35:06.627758 29630 solver.cpp:253]     Train net output #0: loss = 4.17076 (* 1 = 4.17076 loss)
I0123 19:35:06.627766 29630 sgd_solver.cpp:106] Iteration 19680, lr = 0.01
I0123 19:35:13.842728 29630 solver.cpp:237] Iteration 19700, loss = 3.9299
I0123 19:35:13.842841 29630 solver.cpp:253]     Train net output #0: loss = 3.9299 (* 1 = 3.9299 loss)
I0123 19:35:13.842859 29630 sgd_solver.cpp:106] Iteration 19700, lr = 0.01
I0123 19:35:21.083750 29630 solver.cpp:237] Iteration 19720, loss = 3.82765
I0123 19:35:21.083787 29630 solver.cpp:253]     Train net output #0: loss = 3.82765 (* 1 = 3.82765 loss)
I0123 19:35:21.083794 29630 sgd_solver.cpp:106] Iteration 19720, lr = 0.01
I0123 19:35:28.322518 29630 solver.cpp:237] Iteration 19740, loss = 4.16143
I0123 19:35:28.322562 29630 solver.cpp:253]     Train net output #0: loss = 4.16143 (* 1 = 4.16143 loss)
I0123 19:35:28.322568 29630 sgd_solver.cpp:106] Iteration 19740, lr = 0.01
I0123 19:35:35.575393 29630 solver.cpp:237] Iteration 19760, loss = 4.1334
I0123 19:35:35.575431 29630 solver.cpp:253]     Train net output #0: loss = 4.1334 (* 1 = 4.1334 loss)
I0123 19:35:35.575438 29630 sgd_solver.cpp:106] Iteration 19760, lr = 0.01
I0123 19:35:42.819363 29630 solver.cpp:237] Iteration 19780, loss = 3.78459
I0123 19:35:42.819403 29630 solver.cpp:253]     Train net output #0: loss = 3.78459 (* 1 = 3.78459 loss)
I0123 19:35:42.819409 29630 sgd_solver.cpp:106] Iteration 19780, lr = 0.01
I0123 19:35:50.063477 29630 solver.cpp:237] Iteration 19800, loss = 3.91252
I0123 19:35:50.063613 29630 solver.cpp:253]     Train net output #0: loss = 3.91252 (* 1 = 3.91252 loss)
I0123 19:35:50.063621 29630 sgd_solver.cpp:106] Iteration 19800, lr = 0.01
I0123 19:35:57.304512 29630 solver.cpp:237] Iteration 19820, loss = 3.82121
I0123 19:35:57.304550 29630 solver.cpp:253]     Train net output #0: loss = 3.82121 (* 1 = 3.82121 loss)
I0123 19:35:57.304556 29630 sgd_solver.cpp:106] Iteration 19820, lr = 0.01
I0123 19:36:04.529404 29630 solver.cpp:237] Iteration 19840, loss = 4.07164
I0123 19:36:04.529443 29630 solver.cpp:253]     Train net output #0: loss = 4.07164 (* 1 = 4.07164 loss)
I0123 19:36:04.529449 29630 sgd_solver.cpp:106] Iteration 19840, lr = 0.01
I0123 19:36:11.804355 29630 solver.cpp:237] Iteration 19860, loss = 4.25368
I0123 19:36:11.804393 29630 solver.cpp:253]     Train net output #0: loss = 4.25368 (* 1 = 4.25368 loss)
I0123 19:36:11.804399 29630 sgd_solver.cpp:106] Iteration 19860, lr = 0.01
I0123 19:36:19.099294 29630 solver.cpp:237] Iteration 19880, loss = 3.8571
I0123 19:36:19.099351 29630 solver.cpp:253]     Train net output #0: loss = 3.8571 (* 1 = 3.8571 loss)
I0123 19:36:19.099366 29630 sgd_solver.cpp:106] Iteration 19880, lr = 0.01
I0123 19:36:26.403350 29630 solver.cpp:237] Iteration 19900, loss = 4.17971
I0123 19:36:26.403494 29630 solver.cpp:253]     Train net output #0: loss = 4.17971 (* 1 = 4.17971 loss)
I0123 19:36:26.403502 29630 sgd_solver.cpp:106] Iteration 19900, lr = 0.01
I0123 19:36:33.631199 29630 solver.cpp:237] Iteration 19920, loss = 4.27838
I0123 19:36:33.631237 29630 solver.cpp:253]     Train net output #0: loss = 4.27838 (* 1 = 4.27838 loss)
I0123 19:36:33.631244 29630 sgd_solver.cpp:106] Iteration 19920, lr = 0.01
I0123 19:36:40.967192 29630 solver.cpp:237] Iteration 19940, loss = 4.06446
I0123 19:36:40.967232 29630 solver.cpp:253]     Train net output #0: loss = 4.06446 (* 1 = 4.06446 loss)
I0123 19:36:40.967239 29630 sgd_solver.cpp:106] Iteration 19940, lr = 0.01
I0123 19:36:48.206058 29630 solver.cpp:237] Iteration 19960, loss = 3.76631
I0123 19:36:48.206097 29630 solver.cpp:253]     Train net output #0: loss = 3.76631 (* 1 = 3.76631 loss)
I0123 19:36:48.206104 29630 sgd_solver.cpp:106] Iteration 19960, lr = 0.01
I0123 19:36:55.448346 29630 solver.cpp:237] Iteration 19980, loss = 4.11671
I0123 19:36:55.448385 29630 solver.cpp:253]     Train net output #0: loss = 4.11671 (* 1 = 4.11671 loss)
I0123 19:36:55.448391 29630 sgd_solver.cpp:106] Iteration 19980, lr = 0.01
I0123 19:37:02.425020 29630 solver.cpp:459] Snapshotting to binary proto file snapshots/caffenet128_lsuv_ycrcb_iter_20000.caffemodel
I0123 19:37:02.631645 29630 sgd_solver.cpp:269] Snapshotting solver state to binary proto file snapshots/caffenet128_lsuv_ycrcb_iter_20000.solverstate
I0123 19:37:02.692572 29630 solver.cpp:341] Iteration 20000, Testing net (#0)
I0123 19:37:11.321872 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 19:38:16.617162 29630 solver.cpp:409]     Test net output #0: accuracy = 0.2235
I0123 19:38:16.617290 29630 solver.cpp:409]     Test net output #1: loss = 3.87309 (* 1 = 3.87309 loss)
I0123 19:38:16.657855 29630 solver.cpp:237] Iteration 20000, loss = 4.0516
I0123 19:38:16.657883 29630 solver.cpp:253]     Train net output #0: loss = 4.0516 (* 1 = 4.0516 loss)
I0123 19:38:16.657891 29630 sgd_solver.cpp:106] Iteration 20000, lr = 0.01
I0123 19:38:23.170661 29630 solver.cpp:237] Iteration 20020, loss = 3.98279
I0123 19:38:23.170701 29630 solver.cpp:253]     Train net output #0: loss = 3.98279 (* 1 = 3.98279 loss)
I0123 19:38:23.170706 29630 sgd_solver.cpp:106] Iteration 20020, lr = 0.01
I0123 19:38:30.378020 29630 solver.cpp:237] Iteration 20040, loss = 4.11039
I0123 19:38:30.378047 29630 solver.cpp:253]     Train net output #0: loss = 4.11039 (* 1 = 4.11039 loss)
I0123 19:38:30.378054 29630 sgd_solver.cpp:106] Iteration 20040, lr = 0.01
I0123 19:38:37.586558 29630 solver.cpp:237] Iteration 20060, loss = 3.72405
I0123 19:38:37.586611 29630 solver.cpp:253]     Train net output #0: loss = 3.72405 (* 1 = 3.72405 loss)
I0123 19:38:37.586621 29630 sgd_solver.cpp:106] Iteration 20060, lr = 0.01
I0123 19:38:44.847357 29630 solver.cpp:237] Iteration 20080, loss = 4.03295
I0123 19:38:44.847394 29630 solver.cpp:253]     Train net output #0: loss = 4.03295 (* 1 = 4.03295 loss)
I0123 19:38:44.847400 29630 sgd_solver.cpp:106] Iteration 20080, lr = 0.01
I0123 19:38:52.119894 29630 solver.cpp:237] Iteration 20100, loss = 3.9848
I0123 19:38:52.120024 29630 solver.cpp:253]     Train net output #0: loss = 3.9848 (* 1 = 3.9848 loss)
I0123 19:38:52.120031 29630 sgd_solver.cpp:106] Iteration 20100, lr = 0.01
I0123 19:38:59.378289 29630 solver.cpp:237] Iteration 20120, loss = 4.02947
I0123 19:38:59.378368 29630 solver.cpp:253]     Train net output #0: loss = 4.02947 (* 1 = 4.02947 loss)
I0123 19:38:59.378384 29630 sgd_solver.cpp:106] Iteration 20120, lr = 0.01
I0123 19:38:59.821332 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 19:39:06.595234 29630 solver.cpp:237] Iteration 20140, loss = 3.89135
I0123 19:39:06.595273 29630 solver.cpp:253]     Train net output #0: loss = 3.89135 (* 1 = 3.89135 loss)
I0123 19:39:06.595279 29630 sgd_solver.cpp:106] Iteration 20140, lr = 0.01
I0123 19:39:13.779050 29630 solver.cpp:237] Iteration 20160, loss = 3.98421
I0123 19:39:13.779088 29630 solver.cpp:253]     Train net output #0: loss = 3.98421 (* 1 = 3.98421 loss)
I0123 19:39:13.779094 29630 sgd_solver.cpp:106] Iteration 20160, lr = 0.01
I0123 19:39:21.030722 29630 solver.cpp:237] Iteration 20180, loss = 4.0985
I0123 19:39:21.030761 29630 solver.cpp:253]     Train net output #0: loss = 4.0985 (* 1 = 4.0985 loss)
I0123 19:39:21.030767 29630 sgd_solver.cpp:106] Iteration 20180, lr = 0.01
I0123 19:39:28.267825 29630 solver.cpp:237] Iteration 20200, loss = 3.97485
I0123 19:39:28.268002 29630 solver.cpp:253]     Train net output #0: loss = 3.97485 (* 1 = 3.97485 loss)
I0123 19:39:28.268009 29630 sgd_solver.cpp:106] Iteration 20200, lr = 0.01
I0123 19:39:35.583909 29630 solver.cpp:237] Iteration 20220, loss = 4.11036
I0123 19:39:35.583947 29630 solver.cpp:253]     Train net output #0: loss = 4.11036 (* 1 = 4.11036 loss)
I0123 19:39:35.583953 29630 sgd_solver.cpp:106] Iteration 20220, lr = 0.01
I0123 19:39:42.880126 29630 solver.cpp:237] Iteration 20240, loss = 4.23376
I0123 19:39:42.880169 29630 solver.cpp:253]     Train net output #0: loss = 4.23376 (* 1 = 4.23376 loss)
I0123 19:39:42.880177 29630 sgd_solver.cpp:106] Iteration 20240, lr = 0.01
I0123 19:39:50.129505 29630 solver.cpp:237] Iteration 20260, loss = 4.21206
I0123 19:39:50.129545 29630 solver.cpp:253]     Train net output #0: loss = 4.21206 (* 1 = 4.21206 loss)
I0123 19:39:50.129551 29630 sgd_solver.cpp:106] Iteration 20260, lr = 0.01
I0123 19:39:57.367588 29630 solver.cpp:237] Iteration 20280, loss = 3.97427
I0123 19:39:57.367626 29630 solver.cpp:253]     Train net output #0: loss = 3.97427 (* 1 = 3.97427 loss)
I0123 19:39:57.367633 29630 sgd_solver.cpp:106] Iteration 20280, lr = 0.01
I0123 19:40:04.594866 29630 solver.cpp:237] Iteration 20300, loss = 3.76777
I0123 19:40:04.595043 29630 solver.cpp:253]     Train net output #0: loss = 3.76777 (* 1 = 3.76777 loss)
I0123 19:40:04.595052 29630 sgd_solver.cpp:106] Iteration 20300, lr = 0.01
I0123 19:40:11.867902 29630 solver.cpp:237] Iteration 20320, loss = 4.01581
I0123 19:40:11.867941 29630 solver.cpp:253]     Train net output #0: loss = 4.01581 (* 1 = 4.01581 loss)
I0123 19:40:11.867947 29630 sgd_solver.cpp:106] Iteration 20320, lr = 0.01
I0123 19:40:19.154628 29630 solver.cpp:237] Iteration 20340, loss = 4.20713
I0123 19:40:19.154669 29630 solver.cpp:253]     Train net output #0: loss = 4.20713 (* 1 = 4.20713 loss)
I0123 19:40:19.154675 29630 sgd_solver.cpp:106] Iteration 20340, lr = 0.01
I0123 19:40:26.442162 29630 solver.cpp:237] Iteration 20360, loss = 3.90749
I0123 19:40:26.442199 29630 solver.cpp:253]     Train net output #0: loss = 3.90749 (* 1 = 3.90749 loss)
I0123 19:40:26.442205 29630 sgd_solver.cpp:106] Iteration 20360, lr = 0.01
I0123 19:40:33.718364 29630 solver.cpp:237] Iteration 20380, loss = 4.22189
I0123 19:40:33.718402 29630 solver.cpp:253]     Train net output #0: loss = 4.22189 (* 1 = 4.22189 loss)
I0123 19:40:33.718408 29630 sgd_solver.cpp:106] Iteration 20380, lr = 0.01
I0123 19:40:40.966009 29630 solver.cpp:237] Iteration 20400, loss = 4.37384
I0123 19:40:40.966157 29630 solver.cpp:253]     Train net output #0: loss = 4.37384 (* 1 = 4.37384 loss)
I0123 19:40:40.966173 29630 sgd_solver.cpp:106] Iteration 20400, lr = 0.01
I0123 19:40:48.267902 29630 solver.cpp:237] Iteration 20420, loss = 4.09024
I0123 19:40:48.267940 29630 solver.cpp:253]     Train net output #0: loss = 4.09024 (* 1 = 4.09024 loss)
I0123 19:40:48.267947 29630 sgd_solver.cpp:106] Iteration 20420, lr = 0.01
I0123 19:40:55.480347 29630 solver.cpp:237] Iteration 20440, loss = 4.18448
I0123 19:40:55.480386 29630 solver.cpp:253]     Train net output #0: loss = 4.18448 (* 1 = 4.18448 loss)
I0123 19:40:55.480391 29630 sgd_solver.cpp:106] Iteration 20440, lr = 0.01
I0123 19:41:02.699296 29630 solver.cpp:237] Iteration 20460, loss = 4.09003
I0123 19:41:02.699334 29630 solver.cpp:253]     Train net output #0: loss = 4.09003 (* 1 = 4.09003 loss)
I0123 19:41:02.699342 29630 sgd_solver.cpp:106] Iteration 20460, lr = 0.01
I0123 19:41:09.986582 29630 solver.cpp:237] Iteration 20480, loss = 3.77434
I0123 19:41:09.986619 29630 solver.cpp:253]     Train net output #0: loss = 3.77434 (* 1 = 3.77434 loss)
I0123 19:41:09.986626 29630 sgd_solver.cpp:106] Iteration 20480, lr = 0.01
I0123 19:41:17.235636 29630 solver.cpp:237] Iteration 20500, loss = 3.87173
I0123 19:41:17.235785 29630 solver.cpp:253]     Train net output #0: loss = 3.87173 (* 1 = 3.87173 loss)
I0123 19:41:17.235793 29630 sgd_solver.cpp:106] Iteration 20500, lr = 0.01
I0123 19:41:24.478613 29630 solver.cpp:237] Iteration 20520, loss = 4.03783
I0123 19:41:24.478653 29630 solver.cpp:253]     Train net output #0: loss = 4.03783 (* 1 = 4.03783 loss)
I0123 19:41:24.478660 29630 sgd_solver.cpp:106] Iteration 20520, lr = 0.01
I0123 19:41:31.712055 29630 solver.cpp:237] Iteration 20540, loss = 4.06717
I0123 19:41:31.712093 29630 solver.cpp:253]     Train net output #0: loss = 4.06717 (* 1 = 4.06717 loss)
I0123 19:41:31.712100 29630 sgd_solver.cpp:106] Iteration 20540, lr = 0.01
I0123 19:41:38.967332 29630 solver.cpp:237] Iteration 20560, loss = 3.87544
I0123 19:41:38.967370 29630 solver.cpp:253]     Train net output #0: loss = 3.87544 (* 1 = 3.87544 loss)
I0123 19:41:38.967375 29630 sgd_solver.cpp:106] Iteration 20560, lr = 0.01
I0123 19:41:46.217015 29630 solver.cpp:237] Iteration 20580, loss = 3.96043
I0123 19:41:46.217051 29630 solver.cpp:253]     Train net output #0: loss = 3.96043 (* 1 = 3.96043 loss)
I0123 19:41:46.217058 29630 sgd_solver.cpp:106] Iteration 20580, lr = 0.01
I0123 19:41:53.468034 29630 solver.cpp:237] Iteration 20600, loss = 3.80238
I0123 19:41:53.468158 29630 solver.cpp:253]     Train net output #0: loss = 3.80238 (* 1 = 3.80238 loss)
I0123 19:41:53.468165 29630 sgd_solver.cpp:106] Iteration 20600, lr = 0.01
I0123 19:42:00.705358 29630 solver.cpp:237] Iteration 20620, loss = 4.1976
I0123 19:42:00.705396 29630 solver.cpp:253]     Train net output #0: loss = 4.1976 (* 1 = 4.1976 loss)
I0123 19:42:00.705404 29630 sgd_solver.cpp:106] Iteration 20620, lr = 0.01
I0123 19:42:07.944221 29630 solver.cpp:237] Iteration 20640, loss = 3.94196
I0123 19:42:07.944258 29630 solver.cpp:253]     Train net output #0: loss = 3.94196 (* 1 = 3.94196 loss)
I0123 19:42:07.944265 29630 sgd_solver.cpp:106] Iteration 20640, lr = 0.01
I0123 19:42:15.175617 29630 solver.cpp:237] Iteration 20660, loss = 4.03724
I0123 19:42:15.175657 29630 solver.cpp:253]     Train net output #0: loss = 4.03724 (* 1 = 4.03724 loss)
I0123 19:42:15.175662 29630 sgd_solver.cpp:106] Iteration 20660, lr = 0.01
I0123 19:42:22.425982 29630 solver.cpp:237] Iteration 20680, loss = 4.0206
I0123 19:42:22.426034 29630 solver.cpp:253]     Train net output #0: loss = 4.0206 (* 1 = 4.0206 loss)
I0123 19:42:22.426041 29630 sgd_solver.cpp:106] Iteration 20680, lr = 0.01
I0123 19:42:29.634011 29630 solver.cpp:237] Iteration 20700, loss = 3.92355
I0123 19:42:29.634143 29630 solver.cpp:253]     Train net output #0: loss = 3.92355 (* 1 = 3.92355 loss)
I0123 19:42:29.634151 29630 sgd_solver.cpp:106] Iteration 20700, lr = 0.01
I0123 19:42:36.826284 29630 solver.cpp:237] Iteration 20720, loss = 4.13462
I0123 19:42:36.826323 29630 solver.cpp:253]     Train net output #0: loss = 4.13462 (* 1 = 4.13462 loss)
I0123 19:42:36.826328 29630 sgd_solver.cpp:106] Iteration 20720, lr = 0.01
I0123 19:42:44.088207 29630 solver.cpp:237] Iteration 20740, loss = 3.97943
I0123 19:42:44.088248 29630 solver.cpp:253]     Train net output #0: loss = 3.97943 (* 1 = 3.97943 loss)
I0123 19:42:44.088255 29630 sgd_solver.cpp:106] Iteration 20740, lr = 0.01
I0123 19:42:51.328527 29630 solver.cpp:237] Iteration 20760, loss = 4.093
I0123 19:42:51.328565 29630 solver.cpp:253]     Train net output #0: loss = 4.093 (* 1 = 4.093 loss)
I0123 19:42:51.328572 29630 sgd_solver.cpp:106] Iteration 20760, lr = 0.01
I0123 19:42:58.567742 29630 solver.cpp:237] Iteration 20780, loss = 3.79969
I0123 19:42:58.567781 29630 solver.cpp:253]     Train net output #0: loss = 3.79969 (* 1 = 3.79969 loss)
I0123 19:42:58.567787 29630 sgd_solver.cpp:106] Iteration 20780, lr = 0.01
I0123 19:43:05.766121 29630 solver.cpp:237] Iteration 20800, loss = 3.98109
I0123 19:43:05.766294 29630 solver.cpp:253]     Train net output #0: loss = 3.98109 (* 1 = 3.98109 loss)
I0123 19:43:05.766311 29630 sgd_solver.cpp:106] Iteration 20800, lr = 0.01
I0123 19:43:12.961093 29630 solver.cpp:237] Iteration 20820, loss = 3.96133
I0123 19:43:12.961133 29630 solver.cpp:253]     Train net output #0: loss = 3.96133 (* 1 = 3.96133 loss)
I0123 19:43:12.961138 29630 sgd_solver.cpp:106] Iteration 20820, lr = 0.01
I0123 19:43:20.239763 29630 solver.cpp:237] Iteration 20840, loss = 4.2104
I0123 19:43:20.239801 29630 solver.cpp:253]     Train net output #0: loss = 4.2104 (* 1 = 4.2104 loss)
I0123 19:43:20.239809 29630 sgd_solver.cpp:106] Iteration 20840, lr = 0.01
I0123 19:43:27.513296 29630 solver.cpp:237] Iteration 20860, loss = 3.785
I0123 19:43:27.513335 29630 solver.cpp:253]     Train net output #0: loss = 3.785 (* 1 = 3.785 loss)
I0123 19:43:27.513342 29630 sgd_solver.cpp:106] Iteration 20860, lr = 0.01
I0123 19:43:34.755789 29630 solver.cpp:237] Iteration 20880, loss = 3.97974
I0123 19:43:34.755827 29630 solver.cpp:253]     Train net output #0: loss = 3.97974 (* 1 = 3.97974 loss)
I0123 19:43:34.755833 29630 sgd_solver.cpp:106] Iteration 20880, lr = 0.01
I0123 19:43:41.970439 29630 solver.cpp:237] Iteration 20900, loss = 3.89779
I0123 19:43:41.970549 29630 solver.cpp:253]     Train net output #0: loss = 3.89779 (* 1 = 3.89779 loss)
I0123 19:43:41.970556 29630 sgd_solver.cpp:106] Iteration 20900, lr = 0.01
I0123 19:43:49.214723 29630 solver.cpp:237] Iteration 20920, loss = 4.11349
I0123 19:43:49.214761 29630 solver.cpp:253]     Train net output #0: loss = 4.11349 (* 1 = 4.11349 loss)
I0123 19:43:49.214767 29630 sgd_solver.cpp:106] Iteration 20920, lr = 0.01
I0123 19:43:56.427034 29630 solver.cpp:237] Iteration 20940, loss = 4.07813
I0123 19:43:56.427079 29630 solver.cpp:253]     Train net output #0: loss = 4.07813 (* 1 = 4.07813 loss)
I0123 19:43:56.427086 29630 sgd_solver.cpp:106] Iteration 20940, lr = 0.01
I0123 19:44:03.696004 29630 solver.cpp:237] Iteration 20960, loss = 3.82133
I0123 19:44:03.696051 29630 solver.cpp:253]     Train net output #0: loss = 3.82133 (* 1 = 3.82133 loss)
I0123 19:44:03.696058 29630 sgd_solver.cpp:106] Iteration 20960, lr = 0.01
I0123 19:44:10.932667 29630 solver.cpp:237] Iteration 20980, loss = 4.20298
I0123 19:44:10.932705 29630 solver.cpp:253]     Train net output #0: loss = 4.20298 (* 1 = 4.20298 loss)
I0123 19:44:10.932711 29630 sgd_solver.cpp:106] Iteration 20980, lr = 0.01
I0123 19:44:17.897929 29630 solver.cpp:341] Iteration 21000, Testing net (#0)
I0123 19:44:26.976730 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 19:45:32.627471 29630 solver.cpp:409]     Test net output #0: accuracy = 0.23318
I0123 19:45:32.627540 29630 solver.cpp:409]     Test net output #1: loss = 3.80204 (* 1 = 3.80204 loss)
I0123 19:45:32.668198 29630 solver.cpp:237] Iteration 21000, loss = 3.98059
I0123 19:45:32.668227 29630 solver.cpp:253]     Train net output #0: loss = 3.98059 (* 1 = 3.98059 loss)
I0123 19:45:32.668234 29630 sgd_solver.cpp:106] Iteration 21000, lr = 0.01
I0123 19:45:39.216398 29630 solver.cpp:237] Iteration 21020, loss = 3.76545
I0123 19:45:39.216435 29630 solver.cpp:253]     Train net output #0: loss = 3.76545 (* 1 = 3.76545 loss)
I0123 19:45:39.216441 29630 sgd_solver.cpp:106] Iteration 21020, lr = 0.01
I0123 19:45:46.422703 29630 solver.cpp:237] Iteration 21040, loss = 4.05039
I0123 19:45:46.422741 29630 solver.cpp:253]     Train net output #0: loss = 4.05039 (* 1 = 4.05039 loss)
I0123 19:45:46.422747 29630 sgd_solver.cpp:106] Iteration 21040, lr = 0.01
I0123 19:45:53.642464 29630 solver.cpp:237] Iteration 21060, loss = 4.1861
I0123 19:45:53.642503 29630 solver.cpp:253]     Train net output #0: loss = 4.1861 (* 1 = 4.1861 loss)
I0123 19:45:53.642509 29630 sgd_solver.cpp:106] Iteration 21060, lr = 0.01
I0123 19:46:00.877418 29630 solver.cpp:237] Iteration 21080, loss = 4.08926
I0123 19:46:00.877457 29630 solver.cpp:253]     Train net output #0: loss = 4.08926 (* 1 = 4.08926 loss)
I0123 19:46:00.877463 29630 sgd_solver.cpp:106] Iteration 21080, lr = 0.01
I0123 19:46:08.193130 29630 solver.cpp:237] Iteration 21100, loss = 3.89219
I0123 19:46:08.193248 29630 solver.cpp:253]     Train net output #0: loss = 3.89219 (* 1 = 3.89219 loss)
I0123 19:46:08.193255 29630 sgd_solver.cpp:106] Iteration 21100, lr = 0.01
I0123 19:46:15.434984 29630 solver.cpp:237] Iteration 21120, loss = 4.05053
I0123 19:46:15.435022 29630 solver.cpp:253]     Train net output #0: loss = 4.05053 (* 1 = 4.05053 loss)
I0123 19:46:15.435029 29630 sgd_solver.cpp:106] Iteration 21120, lr = 0.01
I0123 19:46:18.063972 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 19:46:22.692443 29630 solver.cpp:237] Iteration 21140, loss = 4.07997
I0123 19:46:22.692483 29630 solver.cpp:253]     Train net output #0: loss = 4.07997 (* 1 = 4.07997 loss)
I0123 19:46:22.692489 29630 sgd_solver.cpp:106] Iteration 21140, lr = 0.01
I0123 19:46:29.966353 29630 solver.cpp:237] Iteration 21160, loss = 3.9261
I0123 19:46:29.966392 29630 solver.cpp:253]     Train net output #0: loss = 3.9261 (* 1 = 3.9261 loss)
I0123 19:46:29.966398 29630 sgd_solver.cpp:106] Iteration 21160, lr = 0.01
I0123 19:46:37.200273 29630 solver.cpp:237] Iteration 21180, loss = 4.0198
I0123 19:46:37.200312 29630 solver.cpp:253]     Train net output #0: loss = 4.0198 (* 1 = 4.0198 loss)
I0123 19:46:37.200319 29630 sgd_solver.cpp:106] Iteration 21180, lr = 0.01
I0123 19:46:44.446029 29630 solver.cpp:237] Iteration 21200, loss = 4.01185
I0123 19:46:44.446171 29630 solver.cpp:253]     Train net output #0: loss = 4.01185 (* 1 = 4.01185 loss)
I0123 19:46:44.446179 29630 sgd_solver.cpp:106] Iteration 21200, lr = 0.01
I0123 19:46:51.737751 29630 solver.cpp:237] Iteration 21220, loss = 3.88239
I0123 19:46:51.737789 29630 solver.cpp:253]     Train net output #0: loss = 3.88239 (* 1 = 3.88239 loss)
I0123 19:46:51.737795 29630 sgd_solver.cpp:106] Iteration 21220, lr = 0.01
I0123 19:46:58.980063 29630 solver.cpp:237] Iteration 21240, loss = 3.97729
I0123 19:46:58.980104 29630 solver.cpp:253]     Train net output #0: loss = 3.97729 (* 1 = 3.97729 loss)
I0123 19:46:58.980110 29630 sgd_solver.cpp:106] Iteration 21240, lr = 0.01
I0123 19:47:06.249169 29630 solver.cpp:237] Iteration 21260, loss = 3.90485
I0123 19:47:06.249199 29630 solver.cpp:253]     Train net output #0: loss = 3.90485 (* 1 = 3.90485 loss)
I0123 19:47:06.249205 29630 sgd_solver.cpp:106] Iteration 21260, lr = 0.01
I0123 19:47:13.526149 29630 solver.cpp:237] Iteration 21280, loss = 3.96932
I0123 19:47:13.526186 29630 solver.cpp:253]     Train net output #0: loss = 3.96932 (* 1 = 3.96932 loss)
I0123 19:47:13.526192 29630 sgd_solver.cpp:106] Iteration 21280, lr = 0.01
I0123 19:47:20.850667 29630 solver.cpp:237] Iteration 21300, loss = 3.9972
I0123 19:47:20.850791 29630 solver.cpp:253]     Train net output #0: loss = 3.9972 (* 1 = 3.9972 loss)
I0123 19:47:20.850798 29630 sgd_solver.cpp:106] Iteration 21300, lr = 0.01
I0123 19:47:28.141791 29630 solver.cpp:237] Iteration 21320, loss = 3.9509
I0123 19:47:28.141829 29630 solver.cpp:253]     Train net output #0: loss = 3.9509 (* 1 = 3.9509 loss)
I0123 19:47:28.141834 29630 sgd_solver.cpp:106] Iteration 21320, lr = 0.01
I0123 19:47:35.404881 29630 solver.cpp:237] Iteration 21340, loss = 4.08534
I0123 19:47:35.404917 29630 solver.cpp:253]     Train net output #0: loss = 4.08534 (* 1 = 4.08534 loss)
I0123 19:47:35.404922 29630 sgd_solver.cpp:106] Iteration 21340, lr = 0.01
I0123 19:47:42.687764 29630 solver.cpp:237] Iteration 21360, loss = 4.17808
I0123 19:47:42.687803 29630 solver.cpp:253]     Train net output #0: loss = 4.17808 (* 1 = 4.17808 loss)
I0123 19:47:42.687808 29630 sgd_solver.cpp:106] Iteration 21360, lr = 0.01
I0123 19:47:49.953871 29630 solver.cpp:237] Iteration 21380, loss = 3.94006
I0123 19:47:49.953909 29630 solver.cpp:253]     Train net output #0: loss = 3.94006 (* 1 = 3.94006 loss)
I0123 19:47:49.953915 29630 sgd_solver.cpp:106] Iteration 21380, lr = 0.01
I0123 19:47:57.203172 29630 solver.cpp:237] Iteration 21400, loss = 4.11378
I0123 19:47:57.203297 29630 solver.cpp:253]     Train net output #0: loss = 4.11378 (* 1 = 4.11378 loss)
I0123 19:47:57.203305 29630 sgd_solver.cpp:106] Iteration 21400, lr = 0.01
I0123 19:48:04.527066 29630 solver.cpp:237] Iteration 21420, loss = 3.94563
I0123 19:48:04.527104 29630 solver.cpp:253]     Train net output #0: loss = 3.94563 (* 1 = 3.94563 loss)
I0123 19:48:04.527110 29630 sgd_solver.cpp:106] Iteration 21420, lr = 0.01
I0123 19:48:11.845876 29630 solver.cpp:237] Iteration 21440, loss = 3.92676
I0123 19:48:11.845914 29630 solver.cpp:253]     Train net output #0: loss = 3.92676 (* 1 = 3.92676 loss)
I0123 19:48:11.845921 29630 sgd_solver.cpp:106] Iteration 21440, lr = 0.01
I0123 19:48:19.132346 29630 solver.cpp:237] Iteration 21460, loss = 4.04242
I0123 19:48:19.132385 29630 solver.cpp:253]     Train net output #0: loss = 4.04242 (* 1 = 4.04242 loss)
I0123 19:48:19.132391 29630 sgd_solver.cpp:106] Iteration 21460, lr = 0.01
I0123 19:48:26.399730 29630 solver.cpp:237] Iteration 21480, loss = 3.97318
I0123 19:48:26.399768 29630 solver.cpp:253]     Train net output #0: loss = 3.97318 (* 1 = 3.97318 loss)
I0123 19:48:26.399775 29630 sgd_solver.cpp:106] Iteration 21480, lr = 0.01
I0123 19:48:33.583089 29630 solver.cpp:237] Iteration 21500, loss = 4.17207
I0123 19:48:33.583243 29630 solver.cpp:253]     Train net output #0: loss = 4.17207 (* 1 = 4.17207 loss)
I0123 19:48:33.583258 29630 sgd_solver.cpp:106] Iteration 21500, lr = 0.01
I0123 19:48:40.934495 29630 solver.cpp:237] Iteration 21520, loss = 3.7932
I0123 19:48:40.934533 29630 solver.cpp:253]     Train net output #0: loss = 3.7932 (* 1 = 3.7932 loss)
I0123 19:48:40.934540 29630 sgd_solver.cpp:106] Iteration 21520, lr = 0.01
I0123 19:48:48.234242 29630 solver.cpp:237] Iteration 21540, loss = 4.11135
I0123 19:48:48.234282 29630 solver.cpp:253]     Train net output #0: loss = 4.11135 (* 1 = 4.11135 loss)
I0123 19:48:48.234287 29630 sgd_solver.cpp:106] Iteration 21540, lr = 0.01
I0123 19:48:55.512967 29630 solver.cpp:237] Iteration 21560, loss = 4.24828
I0123 19:48:55.513005 29630 solver.cpp:253]     Train net output #0: loss = 4.24828 (* 1 = 4.24828 loss)
I0123 19:48:55.513010 29630 sgd_solver.cpp:106] Iteration 21560, lr = 0.01
I0123 19:49:02.795194 29630 solver.cpp:237] Iteration 21580, loss = 3.87952
I0123 19:49:02.795233 29630 solver.cpp:253]     Train net output #0: loss = 3.87952 (* 1 = 3.87952 loss)
I0123 19:49:02.795238 29630 sgd_solver.cpp:106] Iteration 21580, lr = 0.01
I0123 19:49:10.029988 29630 solver.cpp:237] Iteration 21600, loss = 3.93666
I0123 19:49:10.030117 29630 solver.cpp:253]     Train net output #0: loss = 3.93666 (* 1 = 3.93666 loss)
I0123 19:49:10.030123 29630 sgd_solver.cpp:106] Iteration 21600, lr = 0.01
I0123 19:49:17.373054 29630 solver.cpp:237] Iteration 21620, loss = 3.83948
I0123 19:49:17.373093 29630 solver.cpp:253]     Train net output #0: loss = 3.83948 (* 1 = 3.83948 loss)
I0123 19:49:17.373100 29630 sgd_solver.cpp:106] Iteration 21620, lr = 0.01
I0123 19:49:24.621706 29630 solver.cpp:237] Iteration 21640, loss = 3.90006
I0123 19:49:24.621743 29630 solver.cpp:253]     Train net output #0: loss = 3.90006 (* 1 = 3.90006 loss)
I0123 19:49:24.621749 29630 sgd_solver.cpp:106] Iteration 21640, lr = 0.01
I0123 19:49:31.909333 29630 solver.cpp:237] Iteration 21660, loss = 3.59134
I0123 19:49:31.909373 29630 solver.cpp:253]     Train net output #0: loss = 3.59134 (* 1 = 3.59134 loss)
I0123 19:49:31.909379 29630 sgd_solver.cpp:106] Iteration 21660, lr = 0.01
I0123 19:49:39.189813 29630 solver.cpp:237] Iteration 21680, loss = 3.83233
I0123 19:49:39.189863 29630 solver.cpp:253]     Train net output #0: loss = 3.83233 (* 1 = 3.83233 loss)
I0123 19:49:39.189870 29630 sgd_solver.cpp:106] Iteration 21680, lr = 0.01
I0123 19:49:46.443534 29630 solver.cpp:237] Iteration 21700, loss = 3.92811
I0123 19:49:46.443645 29630 solver.cpp:253]     Train net output #0: loss = 3.92811 (* 1 = 3.92811 loss)
I0123 19:49:46.443662 29630 sgd_solver.cpp:106] Iteration 21700, lr = 0.01
I0123 19:49:53.728755 29630 solver.cpp:237] Iteration 21720, loss = 3.99864
I0123 19:49:53.728803 29630 solver.cpp:253]     Train net output #0: loss = 3.99864 (* 1 = 3.99864 loss)
I0123 19:49:53.728819 29630 sgd_solver.cpp:106] Iteration 21720, lr = 0.01
I0123 19:50:01.022192 29630 solver.cpp:237] Iteration 21740, loss = 3.931
I0123 19:50:01.022231 29630 solver.cpp:253]     Train net output #0: loss = 3.931 (* 1 = 3.931 loss)
I0123 19:50:01.022238 29630 sgd_solver.cpp:106] Iteration 21740, lr = 0.01
I0123 19:50:08.263285 29630 solver.cpp:237] Iteration 21760, loss = 4.03372
I0123 19:50:08.263324 29630 solver.cpp:253]     Train net output #0: loss = 4.03372 (* 1 = 4.03372 loss)
I0123 19:50:08.263330 29630 sgd_solver.cpp:106] Iteration 21760, lr = 0.01
I0123 19:50:15.502583 29630 solver.cpp:237] Iteration 21780, loss = 3.8124
I0123 19:50:15.502622 29630 solver.cpp:253]     Train net output #0: loss = 3.8124 (* 1 = 3.8124 loss)
I0123 19:50:15.502629 29630 sgd_solver.cpp:106] Iteration 21780, lr = 0.01
I0123 19:50:22.751557 29630 solver.cpp:237] Iteration 21800, loss = 4.17919
I0123 19:50:22.751727 29630 solver.cpp:253]     Train net output #0: loss = 4.17919 (* 1 = 4.17919 loss)
I0123 19:50:22.751745 29630 sgd_solver.cpp:106] Iteration 21800, lr = 0.01
I0123 19:50:29.991937 29630 solver.cpp:237] Iteration 21820, loss = 3.73717
I0123 19:50:29.991976 29630 solver.cpp:253]     Train net output #0: loss = 3.73717 (* 1 = 3.73717 loss)
I0123 19:50:29.991982 29630 sgd_solver.cpp:106] Iteration 21820, lr = 0.01
I0123 19:50:37.260232 29630 solver.cpp:237] Iteration 21840, loss = 3.91297
I0123 19:50:37.260285 29630 solver.cpp:253]     Train net output #0: loss = 3.91297 (* 1 = 3.91297 loss)
I0123 19:50:37.260293 29630 sgd_solver.cpp:106] Iteration 21840, lr = 0.01
I0123 19:50:44.538583 29630 solver.cpp:237] Iteration 21860, loss = 3.80712
I0123 19:50:44.538620 29630 solver.cpp:253]     Train net output #0: loss = 3.80712 (* 1 = 3.80712 loss)
I0123 19:50:44.538627 29630 sgd_solver.cpp:106] Iteration 21860, lr = 0.01
I0123 19:50:51.792830 29630 solver.cpp:237] Iteration 21880, loss = 3.95048
I0123 19:50:51.792868 29630 solver.cpp:253]     Train net output #0: loss = 3.95048 (* 1 = 3.95048 loss)
I0123 19:50:51.792875 29630 sgd_solver.cpp:106] Iteration 21880, lr = 0.01
I0123 19:50:59.114070 29630 solver.cpp:237] Iteration 21900, loss = 4.14077
I0123 19:50:59.114238 29630 solver.cpp:253]     Train net output #0: loss = 4.14077 (* 1 = 4.14077 loss)
I0123 19:50:59.114246 29630 sgd_solver.cpp:106] Iteration 21900, lr = 0.01
I0123 19:51:06.400879 29630 solver.cpp:237] Iteration 21920, loss = 3.7864
I0123 19:51:06.400923 29630 solver.cpp:253]     Train net output #0: loss = 3.7864 (* 1 = 3.7864 loss)
I0123 19:51:06.400929 29630 sgd_solver.cpp:106] Iteration 21920, lr = 0.01
I0123 19:51:13.699379 29630 solver.cpp:237] Iteration 21940, loss = 4.14844
I0123 19:51:13.699419 29630 solver.cpp:253]     Train net output #0: loss = 4.14844 (* 1 = 4.14844 loss)
I0123 19:51:13.699426 29630 sgd_solver.cpp:106] Iteration 21940, lr = 0.01
I0123 19:51:20.986726 29630 solver.cpp:237] Iteration 21960, loss = 4.07402
I0123 19:51:20.986764 29630 solver.cpp:253]     Train net output #0: loss = 4.07402 (* 1 = 4.07402 loss)
I0123 19:51:20.986770 29630 sgd_solver.cpp:106] Iteration 21960, lr = 0.01
I0123 19:51:28.265579 29630 solver.cpp:237] Iteration 21980, loss = 3.88305
I0123 19:51:28.265617 29630 solver.cpp:253]     Train net output #0: loss = 3.88305 (* 1 = 3.88305 loss)
I0123 19:51:28.265624 29630 sgd_solver.cpp:106] Iteration 21980, lr = 0.01
I0123 19:51:35.255239 29630 solver.cpp:341] Iteration 22000, Testing net (#0)
I0123 19:51:44.762070 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 19:52:49.043465 29630 solver.cpp:409]     Test net output #0: accuracy = 0.23028
I0123 19:52:49.043633 29630 solver.cpp:409]     Test net output #1: loss = 3.82458 (* 1 = 3.82458 loss)
I0123 19:52:49.084321 29630 solver.cpp:237] Iteration 22000, loss = 4.02081
I0123 19:52:49.084360 29630 solver.cpp:253]     Train net output #0: loss = 4.02081 (* 1 = 4.02081 loss)
I0123 19:52:49.084367 29630 sgd_solver.cpp:106] Iteration 22000, lr = 0.01
I0123 19:52:55.600615 29630 solver.cpp:237] Iteration 22020, loss = 4.17886
I0123 19:52:55.600672 29630 solver.cpp:253]     Train net output #0: loss = 4.17886 (* 1 = 4.17886 loss)
I0123 19:52:55.600677 29630 sgd_solver.cpp:106] Iteration 22020, lr = 0.01
I0123 19:53:02.863621 29630 solver.cpp:237] Iteration 22040, loss = 3.9744
I0123 19:53:02.863658 29630 solver.cpp:253]     Train net output #0: loss = 3.9744 (* 1 = 3.9744 loss)
I0123 19:53:02.863664 29630 sgd_solver.cpp:106] Iteration 22040, lr = 0.01
I0123 19:53:10.095064 29630 solver.cpp:237] Iteration 22060, loss = 3.88876
I0123 19:53:10.095103 29630 solver.cpp:253]     Train net output #0: loss = 3.88876 (* 1 = 3.88876 loss)
I0123 19:53:10.095109 29630 sgd_solver.cpp:106] Iteration 22060, lr = 0.01
I0123 19:53:17.413408 29630 solver.cpp:237] Iteration 22080, loss = 4.16619
I0123 19:53:17.413446 29630 solver.cpp:253]     Train net output #0: loss = 4.16619 (* 1 = 4.16619 loss)
I0123 19:53:17.413452 29630 sgd_solver.cpp:106] Iteration 22080, lr = 0.01
I0123 19:53:24.619285 29630 solver.cpp:237] Iteration 22100, loss = 4.01446
I0123 19:53:24.619379 29630 solver.cpp:253]     Train net output #0: loss = 4.01446 (* 1 = 4.01446 loss)
I0123 19:53:24.619386 29630 sgd_solver.cpp:106] Iteration 22100, lr = 0.01
I0123 19:53:31.882035 29630 solver.cpp:237] Iteration 22120, loss = 4.00726
I0123 19:53:31.882072 29630 solver.cpp:253]     Train net output #0: loss = 4.00726 (* 1 = 4.00726 loss)
I0123 19:53:31.882078 29630 sgd_solver.cpp:106] Iteration 22120, lr = 0.01
I0123 19:53:36.618623 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 19:53:39.107667 29630 solver.cpp:237] Iteration 22140, loss = 4.02699
I0123 19:53:39.107707 29630 solver.cpp:253]     Train net output #0: loss = 4.02699 (* 1 = 4.02699 loss)
I0123 19:53:39.107713 29630 sgd_solver.cpp:106] Iteration 22140, lr = 0.01
I0123 19:53:46.387573 29630 solver.cpp:237] Iteration 22160, loss = 3.83436
I0123 19:53:46.387611 29630 solver.cpp:253]     Train net output #0: loss = 3.83436 (* 1 = 3.83436 loss)
I0123 19:53:46.387617 29630 sgd_solver.cpp:106] Iteration 22160, lr = 0.01
I0123 19:53:53.657250 29630 solver.cpp:237] Iteration 22180, loss = 3.75668
I0123 19:53:53.657294 29630 solver.cpp:253]     Train net output #0: loss = 3.75668 (* 1 = 3.75668 loss)
I0123 19:53:53.657305 29630 sgd_solver.cpp:106] Iteration 22180, lr = 0.01
I0123 19:54:00.868521 29630 solver.cpp:237] Iteration 22200, loss = 3.82322
I0123 19:54:00.868691 29630 solver.cpp:253]     Train net output #0: loss = 3.82322 (* 1 = 3.82322 loss)
I0123 19:54:00.868700 29630 sgd_solver.cpp:106] Iteration 22200, lr = 0.01
I0123 19:54:08.101487 29630 solver.cpp:237] Iteration 22220, loss = 3.90852
I0123 19:54:08.101528 29630 solver.cpp:253]     Train net output #0: loss = 3.90852 (* 1 = 3.90852 loss)
I0123 19:54:08.101536 29630 sgd_solver.cpp:106] Iteration 22220, lr = 0.01
I0123 19:54:15.355265 29630 solver.cpp:237] Iteration 22240, loss = 3.98162
I0123 19:54:15.355319 29630 solver.cpp:253]     Train net output #0: loss = 3.98162 (* 1 = 3.98162 loss)
I0123 19:54:15.355326 29630 sgd_solver.cpp:106] Iteration 22240, lr = 0.01
I0123 19:54:22.606866 29630 solver.cpp:237] Iteration 22260, loss = 4.03407
I0123 19:54:22.606904 29630 solver.cpp:253]     Train net output #0: loss = 4.03407 (* 1 = 4.03407 loss)
I0123 19:54:22.606910 29630 sgd_solver.cpp:106] Iteration 22260, lr = 0.01
I0123 19:54:29.922821 29630 solver.cpp:237] Iteration 22280, loss = 3.77336
I0123 19:54:29.922860 29630 solver.cpp:253]     Train net output #0: loss = 3.77336 (* 1 = 3.77336 loss)
I0123 19:54:29.922866 29630 sgd_solver.cpp:106] Iteration 22280, lr = 0.01
I0123 19:54:37.157721 29630 solver.cpp:237] Iteration 22300, loss = 3.9316
I0123 19:54:37.157817 29630 solver.cpp:253]     Train net output #0: loss = 3.9316 (* 1 = 3.9316 loss)
I0123 19:54:37.157832 29630 sgd_solver.cpp:106] Iteration 22300, lr = 0.01
I0123 19:54:44.435740 29630 solver.cpp:237] Iteration 22320, loss = 3.77072
I0123 19:54:44.435780 29630 solver.cpp:253]     Train net output #0: loss = 3.77072 (* 1 = 3.77072 loss)
I0123 19:54:44.435786 29630 sgd_solver.cpp:106] Iteration 22320, lr = 0.01
I0123 19:54:51.689201 29630 solver.cpp:237] Iteration 22340, loss = 3.85761
I0123 19:54:51.689249 29630 solver.cpp:253]     Train net output #0: loss = 3.85761 (* 1 = 3.85761 loss)
I0123 19:54:51.689254 29630 sgd_solver.cpp:106] Iteration 22340, lr = 0.01
I0123 19:54:58.966459 29630 solver.cpp:237] Iteration 22360, loss = 3.92142
I0123 19:54:58.966497 29630 solver.cpp:253]     Train net output #0: loss = 3.92142 (* 1 = 3.92142 loss)
I0123 19:54:58.966503 29630 sgd_solver.cpp:106] Iteration 22360, lr = 0.01
I0123 19:55:06.211653 29630 solver.cpp:237] Iteration 22380, loss = 3.99528
I0123 19:55:06.211694 29630 solver.cpp:253]     Train net output #0: loss = 3.99528 (* 1 = 3.99528 loss)
I0123 19:55:06.211700 29630 sgd_solver.cpp:106] Iteration 22380, lr = 0.01
I0123 19:55:13.441329 29630 solver.cpp:237] Iteration 22400, loss = 3.96474
I0123 19:55:13.441474 29630 solver.cpp:253]     Train net output #0: loss = 3.96474 (* 1 = 3.96474 loss)
I0123 19:55:13.441483 29630 sgd_solver.cpp:106] Iteration 22400, lr = 0.01
I0123 19:55:20.722630 29630 solver.cpp:237] Iteration 22420, loss = 3.972
I0123 19:55:20.722668 29630 solver.cpp:253]     Train net output #0: loss = 3.972 (* 1 = 3.972 loss)
I0123 19:55:20.722676 29630 sgd_solver.cpp:106] Iteration 22420, lr = 0.01
I0123 19:55:27.994498 29630 solver.cpp:237] Iteration 22440, loss = 3.93524
I0123 19:55:27.994535 29630 solver.cpp:253]     Train net output #0: loss = 3.93524 (* 1 = 3.93524 loss)
I0123 19:55:27.994544 29630 sgd_solver.cpp:106] Iteration 22440, lr = 0.01
I0123 19:55:35.295855 29630 solver.cpp:237] Iteration 22460, loss = 4.02867
I0123 19:55:35.295894 29630 solver.cpp:253]     Train net output #0: loss = 4.02867 (* 1 = 4.02867 loss)
I0123 19:55:35.295900 29630 sgd_solver.cpp:106] Iteration 22460, lr = 0.01
I0123 19:55:42.517431 29630 solver.cpp:237] Iteration 22480, loss = 3.61789
I0123 19:55:42.517468 29630 solver.cpp:253]     Train net output #0: loss = 3.61789 (* 1 = 3.61789 loss)
I0123 19:55:42.517474 29630 sgd_solver.cpp:106] Iteration 22480, lr = 0.01
I0123 19:55:49.758765 29630 solver.cpp:237] Iteration 22500, loss = 4.10474
I0123 19:55:49.758893 29630 solver.cpp:253]     Train net output #0: loss = 4.10474 (* 1 = 4.10474 loss)
I0123 19:55:49.758901 29630 sgd_solver.cpp:106] Iteration 22500, lr = 0.01
I0123 19:55:56.998749 29630 solver.cpp:237] Iteration 22520, loss = 3.7988
I0123 19:55:56.998787 29630 solver.cpp:253]     Train net output #0: loss = 3.7988 (* 1 = 3.7988 loss)
I0123 19:55:56.998793 29630 sgd_solver.cpp:106] Iteration 22520, lr = 0.01
I0123 19:56:04.275835 29630 solver.cpp:237] Iteration 22540, loss = 3.58128
I0123 19:56:04.275874 29630 solver.cpp:253]     Train net output #0: loss = 3.58128 (* 1 = 3.58128 loss)
I0123 19:56:04.275881 29630 sgd_solver.cpp:106] Iteration 22540, lr = 0.01
I0123 19:56:11.523564 29630 solver.cpp:237] Iteration 22560, loss = 3.818
I0123 19:56:11.523602 29630 solver.cpp:253]     Train net output #0: loss = 3.818 (* 1 = 3.818 loss)
I0123 19:56:11.523608 29630 sgd_solver.cpp:106] Iteration 22560, lr = 0.01
I0123 19:56:18.795287 29630 solver.cpp:237] Iteration 22580, loss = 4.16136
I0123 19:56:18.795325 29630 solver.cpp:253]     Train net output #0: loss = 4.16136 (* 1 = 4.16136 loss)
I0123 19:56:18.795331 29630 sgd_solver.cpp:106] Iteration 22580, lr = 0.01
I0123 19:56:26.017736 29630 solver.cpp:237] Iteration 22600, loss = 3.82643
I0123 19:56:26.017843 29630 solver.cpp:253]     Train net output #0: loss = 3.82643 (* 1 = 3.82643 loss)
I0123 19:56:26.017860 29630 sgd_solver.cpp:106] Iteration 22600, lr = 0.01
I0123 19:56:33.272188 29630 solver.cpp:237] Iteration 22620, loss = 3.82793
I0123 19:56:33.272228 29630 solver.cpp:253]     Train net output #0: loss = 3.82793 (* 1 = 3.82793 loss)
I0123 19:56:33.272234 29630 sgd_solver.cpp:106] Iteration 22620, lr = 0.01
I0123 19:56:40.575788 29630 solver.cpp:237] Iteration 22640, loss = 3.82778
I0123 19:56:40.575819 29630 solver.cpp:253]     Train net output #0: loss = 3.82778 (* 1 = 3.82778 loss)
I0123 19:56:40.575824 29630 sgd_solver.cpp:106] Iteration 22640, lr = 0.01
I0123 19:56:47.894230 29630 solver.cpp:237] Iteration 22660, loss = 3.85672
I0123 19:56:47.894268 29630 solver.cpp:253]     Train net output #0: loss = 3.85672 (* 1 = 3.85672 loss)
I0123 19:56:47.894274 29630 sgd_solver.cpp:106] Iteration 22660, lr = 0.01
I0123 19:56:55.157320 29630 solver.cpp:237] Iteration 22680, loss = 3.9749
I0123 19:56:55.157357 29630 solver.cpp:253]     Train net output #0: loss = 3.9749 (* 1 = 3.9749 loss)
I0123 19:56:55.157364 29630 sgd_solver.cpp:106] Iteration 22680, lr = 0.01
I0123 19:57:02.406709 29630 solver.cpp:237] Iteration 22700, loss = 3.93285
I0123 19:57:02.406872 29630 solver.cpp:253]     Train net output #0: loss = 3.93285 (* 1 = 3.93285 loss)
I0123 19:57:02.406879 29630 sgd_solver.cpp:106] Iteration 22700, lr = 0.01
I0123 19:57:09.712848 29630 solver.cpp:237] Iteration 22720, loss = 3.85428
I0123 19:57:09.712887 29630 solver.cpp:253]     Train net output #0: loss = 3.85428 (* 1 = 3.85428 loss)
I0123 19:57:09.712893 29630 sgd_solver.cpp:106] Iteration 22720, lr = 0.01
I0123 19:57:16.923300 29630 solver.cpp:237] Iteration 22740, loss = 3.48822
I0123 19:57:16.923338 29630 solver.cpp:253]     Train net output #0: loss = 3.48822 (* 1 = 3.48822 loss)
I0123 19:57:16.923344 29630 sgd_solver.cpp:106] Iteration 22740, lr = 0.01
I0123 19:57:24.232662 29630 solver.cpp:237] Iteration 22760, loss = 3.98993
I0123 19:57:24.232700 29630 solver.cpp:253]     Train net output #0: loss = 3.98993 (* 1 = 3.98993 loss)
I0123 19:57:24.232707 29630 sgd_solver.cpp:106] Iteration 22760, lr = 0.01
I0123 19:57:31.473980 29630 solver.cpp:237] Iteration 22780, loss = 3.84482
I0123 19:57:31.474017 29630 solver.cpp:253]     Train net output #0: loss = 3.84482 (* 1 = 3.84482 loss)
I0123 19:57:31.474023 29630 sgd_solver.cpp:106] Iteration 22780, lr = 0.01
I0123 19:57:38.756896 29630 solver.cpp:237] Iteration 22800, loss = 4.20612
I0123 19:57:38.757074 29630 solver.cpp:253]     Train net output #0: loss = 4.20612 (* 1 = 4.20612 loss)
I0123 19:57:38.757083 29630 sgd_solver.cpp:106] Iteration 22800, lr = 0.01
I0123 19:57:46.006520 29630 solver.cpp:237] Iteration 22820, loss = 4.15231
I0123 19:57:46.006556 29630 solver.cpp:253]     Train net output #0: loss = 4.15231 (* 1 = 4.15231 loss)
I0123 19:57:46.006562 29630 sgd_solver.cpp:106] Iteration 22820, lr = 0.01
I0123 19:57:53.273088 29630 solver.cpp:237] Iteration 22840, loss = 3.87876
I0123 19:57:53.273126 29630 solver.cpp:253]     Train net output #0: loss = 3.87876 (* 1 = 3.87876 loss)
I0123 19:57:53.273133 29630 sgd_solver.cpp:106] Iteration 22840, lr = 0.01
I0123 19:58:00.519860 29630 solver.cpp:237] Iteration 22860, loss = 4.25207
I0123 19:58:00.519897 29630 solver.cpp:253]     Train net output #0: loss = 4.25207 (* 1 = 4.25207 loss)
I0123 19:58:00.519903 29630 sgd_solver.cpp:106] Iteration 22860, lr = 0.01
I0123 19:58:07.769207 29630 solver.cpp:237] Iteration 22880, loss = 4.00019
I0123 19:58:07.769245 29630 solver.cpp:253]     Train net output #0: loss = 4.00019 (* 1 = 4.00019 loss)
I0123 19:58:07.769251 29630 sgd_solver.cpp:106] Iteration 22880, lr = 0.01
I0123 19:58:15.023717 29630 solver.cpp:237] Iteration 22900, loss = 3.91436
I0123 19:58:15.023869 29630 solver.cpp:253]     Train net output #0: loss = 3.91436 (* 1 = 3.91436 loss)
I0123 19:58:15.023885 29630 sgd_solver.cpp:106] Iteration 22900, lr = 0.01
I0123 19:58:22.275460 29630 solver.cpp:237] Iteration 22920, loss = 3.82857
I0123 19:58:22.275497 29630 solver.cpp:253]     Train net output #0: loss = 3.82857 (* 1 = 3.82857 loss)
I0123 19:58:22.275504 29630 sgd_solver.cpp:106] Iteration 22920, lr = 0.01
I0123 19:58:29.500753 29630 solver.cpp:237] Iteration 22940, loss = 3.95482
I0123 19:58:29.500793 29630 solver.cpp:253]     Train net output #0: loss = 3.95482 (* 1 = 3.95482 loss)
I0123 19:58:29.500799 29630 sgd_solver.cpp:106] Iteration 22940, lr = 0.01
I0123 19:58:36.764447 29630 solver.cpp:237] Iteration 22960, loss = 4.04329
I0123 19:58:36.764485 29630 solver.cpp:253]     Train net output #0: loss = 4.04329 (* 1 = 4.04329 loss)
I0123 19:58:36.764492 29630 sgd_solver.cpp:106] Iteration 22960, lr = 0.01
I0123 19:58:44.016546 29630 solver.cpp:237] Iteration 22980, loss = 4.00954
I0123 19:58:44.016585 29630 solver.cpp:253]     Train net output #0: loss = 4.00954 (* 1 = 4.00954 loss)
I0123 19:58:44.016592 29630 sgd_solver.cpp:106] Iteration 22980, lr = 0.01
I0123 19:58:50.984670 29630 solver.cpp:341] Iteration 23000, Testing net (#0)
I0123 19:59:00.929504 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 20:00:04.694828 29630 solver.cpp:409]     Test net output #0: accuracy = 0.2394
I0123 20:00:04.694975 29630 solver.cpp:409]     Test net output #1: loss = 3.75127 (* 1 = 3.75127 loss)
I0123 20:00:04.735522 29630 solver.cpp:237] Iteration 23000, loss = 3.93916
I0123 20:00:04.735560 29630 solver.cpp:253]     Train net output #0: loss = 3.93916 (* 1 = 3.93916 loss)
I0123 20:00:04.735568 29630 sgd_solver.cpp:106] Iteration 23000, lr = 0.01
I0123 20:00:11.324786 29630 solver.cpp:237] Iteration 23020, loss = 3.54261
I0123 20:00:11.324826 29630 solver.cpp:253]     Train net output #0: loss = 3.54261 (* 1 = 3.54261 loss)
I0123 20:00:11.324832 29630 sgd_solver.cpp:106] Iteration 23020, lr = 0.01
I0123 20:00:18.627521 29630 solver.cpp:237] Iteration 23040, loss = 3.95144
I0123 20:00:18.627558 29630 solver.cpp:253]     Train net output #0: loss = 3.95144 (* 1 = 3.95144 loss)
I0123 20:00:18.627564 29630 sgd_solver.cpp:106] Iteration 23040, lr = 0.01
I0123 20:00:25.913123 29630 solver.cpp:237] Iteration 23060, loss = 3.85581
I0123 20:00:25.913161 29630 solver.cpp:253]     Train net output #0: loss = 3.85581 (* 1 = 3.85581 loss)
I0123 20:00:25.913168 29630 sgd_solver.cpp:106] Iteration 23060, lr = 0.01
I0123 20:00:33.145476 29630 solver.cpp:237] Iteration 23080, loss = 3.98037
I0123 20:00:33.145515 29630 solver.cpp:253]     Train net output #0: loss = 3.98037 (* 1 = 3.98037 loss)
I0123 20:00:33.145521 29630 sgd_solver.cpp:106] Iteration 23080, lr = 0.01
I0123 20:00:40.462635 29630 solver.cpp:237] Iteration 23100, loss = 4.0206
I0123 20:00:40.462779 29630 solver.cpp:253]     Train net output #0: loss = 4.0206 (* 1 = 4.0206 loss)
I0123 20:00:40.462787 29630 sgd_solver.cpp:106] Iteration 23100, lr = 0.01
I0123 20:00:47.785223 29630 solver.cpp:237] Iteration 23120, loss = 3.82926
I0123 20:00:47.785251 29630 solver.cpp:253]     Train net output #0: loss = 3.82926 (* 1 = 3.82926 loss)
I0123 20:00:47.785257 29630 sgd_solver.cpp:106] Iteration 23120, lr = 0.01
I0123 20:00:54.869439 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 20:00:55.170733 29630 solver.cpp:237] Iteration 23140, loss = 3.93255
I0123 20:00:55.170764 29630 solver.cpp:253]     Train net output #0: loss = 3.93255 (* 1 = 3.93255 loss)
I0123 20:00:55.170770 29630 sgd_solver.cpp:106] Iteration 23140, lr = 0.01
I0123 20:01:02.436745 29630 solver.cpp:237] Iteration 23160, loss = 3.99479
I0123 20:01:02.436784 29630 solver.cpp:253]     Train net output #0: loss = 3.99479 (* 1 = 3.99479 loss)
I0123 20:01:02.436790 29630 sgd_solver.cpp:106] Iteration 23160, lr = 0.01
I0123 20:01:09.688266 29630 solver.cpp:237] Iteration 23180, loss = 4.06108
I0123 20:01:09.688304 29630 solver.cpp:253]     Train net output #0: loss = 4.06108 (* 1 = 4.06108 loss)
I0123 20:01:09.688310 29630 sgd_solver.cpp:106] Iteration 23180, lr = 0.01
I0123 20:01:16.978533 29630 solver.cpp:237] Iteration 23200, loss = 3.75922
I0123 20:01:16.978682 29630 solver.cpp:253]     Train net output #0: loss = 3.75922 (* 1 = 3.75922 loss)
I0123 20:01:16.978689 29630 sgd_solver.cpp:106] Iteration 23200, lr = 0.01
I0123 20:01:24.239127 29630 solver.cpp:237] Iteration 23220, loss = 3.90346
I0123 20:01:24.239167 29630 solver.cpp:253]     Train net output #0: loss = 3.90346 (* 1 = 3.90346 loss)
I0123 20:01:24.239173 29630 sgd_solver.cpp:106] Iteration 23220, lr = 0.01
I0123 20:01:31.505930 29630 solver.cpp:237] Iteration 23240, loss = 3.98352
I0123 20:01:31.505985 29630 solver.cpp:253]     Train net output #0: loss = 3.98352 (* 1 = 3.98352 loss)
I0123 20:01:31.505995 29630 sgd_solver.cpp:106] Iteration 23240, lr = 0.01
I0123 20:01:38.784901 29630 solver.cpp:237] Iteration 23260, loss = 3.89149
I0123 20:01:38.784940 29630 solver.cpp:253]     Train net output #0: loss = 3.89149 (* 1 = 3.89149 loss)
I0123 20:01:38.784945 29630 sgd_solver.cpp:106] Iteration 23260, lr = 0.01
I0123 20:01:46.059594 29630 solver.cpp:237] Iteration 23280, loss = 3.95281
I0123 20:01:46.059633 29630 solver.cpp:253]     Train net output #0: loss = 3.95281 (* 1 = 3.95281 loss)
I0123 20:01:46.059639 29630 sgd_solver.cpp:106] Iteration 23280, lr = 0.01
I0123 20:01:53.303268 29630 solver.cpp:237] Iteration 23300, loss = 3.90507
I0123 20:01:53.303390 29630 solver.cpp:253]     Train net output #0: loss = 3.90507 (* 1 = 3.90507 loss)
I0123 20:01:53.303397 29630 sgd_solver.cpp:106] Iteration 23300, lr = 0.01
I0123 20:02:00.516928 29630 solver.cpp:237] Iteration 23320, loss = 3.89272
I0123 20:02:00.516966 29630 solver.cpp:253]     Train net output #0: loss = 3.89272 (* 1 = 3.89272 loss)
I0123 20:02:00.516973 29630 sgd_solver.cpp:106] Iteration 23320, lr = 0.01
I0123 20:02:07.742365 29630 solver.cpp:237] Iteration 23340, loss = 3.88217
I0123 20:02:07.742405 29630 solver.cpp:253]     Train net output #0: loss = 3.88217 (* 1 = 3.88217 loss)
I0123 20:02:07.742411 29630 sgd_solver.cpp:106] Iteration 23340, lr = 0.01
I0123 20:02:14.964987 29630 solver.cpp:237] Iteration 23360, loss = 4.0722
I0123 20:02:14.965024 29630 solver.cpp:253]     Train net output #0: loss = 4.0722 (* 1 = 4.0722 loss)
I0123 20:02:14.965030 29630 sgd_solver.cpp:106] Iteration 23360, lr = 0.01
I0123 20:02:22.242735 29630 solver.cpp:237] Iteration 23380, loss = 3.89153
I0123 20:02:22.242774 29630 solver.cpp:253]     Train net output #0: loss = 3.89153 (* 1 = 3.89153 loss)
I0123 20:02:22.242780 29630 sgd_solver.cpp:106] Iteration 23380, lr = 0.01
I0123 20:02:29.501076 29630 solver.cpp:237] Iteration 23400, loss = 3.85531
I0123 20:02:29.501237 29630 solver.cpp:253]     Train net output #0: loss = 3.85531 (* 1 = 3.85531 loss)
I0123 20:02:29.501255 29630 sgd_solver.cpp:106] Iteration 23400, lr = 0.01
I0123 20:02:36.746580 29630 solver.cpp:237] Iteration 23420, loss = 3.84578
I0123 20:02:36.746620 29630 solver.cpp:253]     Train net output #0: loss = 3.84578 (* 1 = 3.84578 loss)
I0123 20:02:36.746626 29630 sgd_solver.cpp:106] Iteration 23420, lr = 0.01
I0123 20:02:43.986261 29630 solver.cpp:237] Iteration 23440, loss = 4.09707
I0123 20:02:43.986299 29630 solver.cpp:253]     Train net output #0: loss = 4.09707 (* 1 = 4.09707 loss)
I0123 20:02:43.986305 29630 sgd_solver.cpp:106] Iteration 23440, lr = 0.01
I0123 20:02:51.243710 29630 solver.cpp:237] Iteration 23460, loss = 3.80613
I0123 20:02:51.243749 29630 solver.cpp:253]     Train net output #0: loss = 3.80613 (* 1 = 3.80613 loss)
I0123 20:02:51.243755 29630 sgd_solver.cpp:106] Iteration 23460, lr = 0.01
I0123 20:02:58.504065 29630 solver.cpp:237] Iteration 23480, loss = 3.84827
I0123 20:02:58.504103 29630 solver.cpp:253]     Train net output #0: loss = 3.84827 (* 1 = 3.84827 loss)
I0123 20:02:58.504109 29630 sgd_solver.cpp:106] Iteration 23480, lr = 0.01
I0123 20:03:05.751580 29630 solver.cpp:237] Iteration 23500, loss = 3.84594
I0123 20:03:05.751749 29630 solver.cpp:253]     Train net output #0: loss = 3.84594 (* 1 = 3.84594 loss)
I0123 20:03:05.751757 29630 sgd_solver.cpp:106] Iteration 23500, lr = 0.01
I0123 20:03:13.064357 29630 solver.cpp:237] Iteration 23520, loss = 4.01268
I0123 20:03:13.064395 29630 solver.cpp:253]     Train net output #0: loss = 4.01268 (* 1 = 4.01268 loss)
I0123 20:03:13.064402 29630 sgd_solver.cpp:106] Iteration 23520, lr = 0.01
I0123 20:03:20.293072 29630 solver.cpp:237] Iteration 23540, loss = 3.90001
I0123 20:03:20.293114 29630 solver.cpp:253]     Train net output #0: loss = 3.90001 (* 1 = 3.90001 loss)
I0123 20:03:20.293122 29630 sgd_solver.cpp:106] Iteration 23540, lr = 0.01
I0123 20:03:27.612177 29630 solver.cpp:237] Iteration 23560, loss = 3.84917
I0123 20:03:27.612218 29630 solver.cpp:253]     Train net output #0: loss = 3.84917 (* 1 = 3.84917 loss)
I0123 20:03:27.612224 29630 sgd_solver.cpp:106] Iteration 23560, lr = 0.01
I0123 20:03:34.850803 29630 solver.cpp:237] Iteration 23580, loss = 3.71846
I0123 20:03:34.850842 29630 solver.cpp:253]     Train net output #0: loss = 3.71846 (* 1 = 3.71846 loss)
I0123 20:03:34.850849 29630 sgd_solver.cpp:106] Iteration 23580, lr = 0.01
I0123 20:03:42.105798 29630 solver.cpp:237] Iteration 23600, loss = 3.75754
I0123 20:03:42.105979 29630 solver.cpp:253]     Train net output #0: loss = 3.75754 (* 1 = 3.75754 loss)
I0123 20:03:42.105996 29630 sgd_solver.cpp:106] Iteration 23600, lr = 0.01
I0123 20:03:49.381063 29630 solver.cpp:237] Iteration 23620, loss = 3.76549
I0123 20:03:49.381103 29630 solver.cpp:253]     Train net output #0: loss = 3.76549 (* 1 = 3.76549 loss)
I0123 20:03:49.381110 29630 sgd_solver.cpp:106] Iteration 23620, lr = 0.01
I0123 20:03:56.659572 29630 solver.cpp:237] Iteration 23640, loss = 3.64302
I0123 20:03:56.659611 29630 solver.cpp:253]     Train net output #0: loss = 3.64302 (* 1 = 3.64302 loss)
I0123 20:03:56.659617 29630 sgd_solver.cpp:106] Iteration 23640, lr = 0.01
I0123 20:04:03.927954 29630 solver.cpp:237] Iteration 23660, loss = 3.58316
I0123 20:04:03.927994 29630 solver.cpp:253]     Train net output #0: loss = 3.58316 (* 1 = 3.58316 loss)
I0123 20:04:03.927999 29630 sgd_solver.cpp:106] Iteration 23660, lr = 0.01
I0123 20:04:11.149294 29630 solver.cpp:237] Iteration 23680, loss = 3.89588
I0123 20:04:11.149335 29630 solver.cpp:253]     Train net output #0: loss = 3.89588 (* 1 = 3.89588 loss)
I0123 20:04:11.149343 29630 sgd_solver.cpp:106] Iteration 23680, lr = 0.01
I0123 20:04:18.402891 29630 solver.cpp:237] Iteration 23700, loss = 3.78564
I0123 20:04:18.403070 29630 solver.cpp:253]     Train net output #0: loss = 3.78564 (* 1 = 3.78564 loss)
I0123 20:04:18.403079 29630 sgd_solver.cpp:106] Iteration 23700, lr = 0.01
I0123 20:04:25.675673 29630 solver.cpp:237] Iteration 23720, loss = 3.96671
I0123 20:04:25.675710 29630 solver.cpp:253]     Train net output #0: loss = 3.96671 (* 1 = 3.96671 loss)
I0123 20:04:25.675716 29630 sgd_solver.cpp:106] Iteration 23720, lr = 0.01
I0123 20:04:32.951719 29630 solver.cpp:237] Iteration 23740, loss = 4.26877
I0123 20:04:32.951757 29630 solver.cpp:253]     Train net output #0: loss = 4.26877 (* 1 = 4.26877 loss)
I0123 20:04:32.951763 29630 sgd_solver.cpp:106] Iteration 23740, lr = 0.01
I0123 20:04:40.210714 29630 solver.cpp:237] Iteration 23760, loss = 3.87099
I0123 20:04:40.210752 29630 solver.cpp:253]     Train net output #0: loss = 3.87099 (* 1 = 3.87099 loss)
I0123 20:04:40.210758 29630 sgd_solver.cpp:106] Iteration 23760, lr = 0.01
I0123 20:04:47.498442 29630 solver.cpp:237] Iteration 23780, loss = 3.88206
I0123 20:04:47.498481 29630 solver.cpp:253]     Train net output #0: loss = 3.88206 (* 1 = 3.88206 loss)
I0123 20:04:47.498487 29630 sgd_solver.cpp:106] Iteration 23780, lr = 0.01
I0123 20:04:54.719504 29630 solver.cpp:237] Iteration 23800, loss = 3.75377
I0123 20:04:54.719672 29630 solver.cpp:253]     Train net output #0: loss = 3.75377 (* 1 = 3.75377 loss)
I0123 20:04:54.719681 29630 sgd_solver.cpp:106] Iteration 23800, lr = 0.01
I0123 20:05:02.019827 29630 solver.cpp:237] Iteration 23820, loss = 3.93778
I0123 20:05:02.019865 29630 solver.cpp:253]     Train net output #0: loss = 3.93778 (* 1 = 3.93778 loss)
I0123 20:05:02.019871 29630 sgd_solver.cpp:106] Iteration 23820, lr = 0.01
I0123 20:05:09.314726 29630 solver.cpp:237] Iteration 23840, loss = 3.85856
I0123 20:05:09.314766 29630 solver.cpp:253]     Train net output #0: loss = 3.85856 (* 1 = 3.85856 loss)
I0123 20:05:09.314772 29630 sgd_solver.cpp:106] Iteration 23840, lr = 0.01
I0123 20:05:16.577632 29630 solver.cpp:237] Iteration 23860, loss = 4.09925
I0123 20:05:16.577672 29630 solver.cpp:253]     Train net output #0: loss = 4.09925 (* 1 = 4.09925 loss)
I0123 20:05:16.577677 29630 sgd_solver.cpp:106] Iteration 23860, lr = 0.01
I0123 20:05:23.844106 29630 solver.cpp:237] Iteration 23880, loss = 3.61403
I0123 20:05:23.844146 29630 solver.cpp:253]     Train net output #0: loss = 3.61403 (* 1 = 3.61403 loss)
I0123 20:05:23.844151 29630 sgd_solver.cpp:106] Iteration 23880, lr = 0.01
I0123 20:05:31.134093 29630 solver.cpp:237] Iteration 23900, loss = 3.84327
I0123 20:05:31.134191 29630 solver.cpp:253]     Train net output #0: loss = 3.84327 (* 1 = 3.84327 loss)
I0123 20:05:31.134197 29630 sgd_solver.cpp:106] Iteration 23900, lr = 0.01
I0123 20:05:38.406157 29630 solver.cpp:237] Iteration 23920, loss = 3.73021
I0123 20:05:38.406198 29630 solver.cpp:253]     Train net output #0: loss = 3.73021 (* 1 = 3.73021 loss)
I0123 20:05:38.406203 29630 sgd_solver.cpp:106] Iteration 23920, lr = 0.01
I0123 20:05:45.657181 29630 solver.cpp:237] Iteration 23940, loss = 3.81316
I0123 20:05:45.657219 29630 solver.cpp:253]     Train net output #0: loss = 3.81316 (* 1 = 3.81316 loss)
I0123 20:05:45.657227 29630 sgd_solver.cpp:106] Iteration 23940, lr = 0.01
I0123 20:05:52.913310 29630 solver.cpp:237] Iteration 23960, loss = 4.06063
I0123 20:05:52.913364 29630 solver.cpp:253]     Train net output #0: loss = 4.06063 (* 1 = 4.06063 loss)
I0123 20:05:52.913377 29630 sgd_solver.cpp:106] Iteration 23960, lr = 0.01
I0123 20:06:00.239416 29630 solver.cpp:237] Iteration 23980, loss = 3.99991
I0123 20:06:00.239455 29630 solver.cpp:253]     Train net output #0: loss = 3.99991 (* 1 = 3.99991 loss)
I0123 20:06:00.239461 29630 sgd_solver.cpp:106] Iteration 23980, lr = 0.01
I0123 20:06:07.181144 29630 solver.cpp:341] Iteration 24000, Testing net (#0)
I0123 20:06:17.572466 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 20:07:20.876718 29630 solver.cpp:409]     Test net output #0: accuracy = 0.24716
I0123 20:07:20.876888 29630 solver.cpp:409]     Test net output #1: loss = 3.70713 (* 1 = 3.70713 loss)
I0123 20:07:20.917408 29630 solver.cpp:237] Iteration 24000, loss = 3.81391
I0123 20:07:20.917448 29630 solver.cpp:253]     Train net output #0: loss = 3.81391 (* 1 = 3.81391 loss)
I0123 20:07:20.917464 29630 sgd_solver.cpp:106] Iteration 24000, lr = 0.01
I0123 20:07:27.467579 29630 solver.cpp:237] Iteration 24020, loss = 3.63294
I0123 20:07:27.467618 29630 solver.cpp:253]     Train net output #0: loss = 3.63294 (* 1 = 3.63294 loss)
I0123 20:07:27.467624 29630 sgd_solver.cpp:106] Iteration 24020, lr = 0.01
I0123 20:07:34.753698 29630 solver.cpp:237] Iteration 24040, loss = 4.02524
I0123 20:07:34.753736 29630 solver.cpp:253]     Train net output #0: loss = 4.02524 (* 1 = 4.02524 loss)
I0123 20:07:34.753741 29630 sgd_solver.cpp:106] Iteration 24040, lr = 0.01
I0123 20:07:41.978641 29630 solver.cpp:237] Iteration 24060, loss = 3.69245
I0123 20:07:41.978682 29630 solver.cpp:253]     Train net output #0: loss = 3.69245 (* 1 = 3.69245 loss)
I0123 20:07:41.978688 29630 sgd_solver.cpp:106] Iteration 24060, lr = 0.01
I0123 20:07:49.245930 29630 solver.cpp:237] Iteration 24080, loss = 4.17159
I0123 20:07:49.245968 29630 solver.cpp:253]     Train net output #0: loss = 4.17159 (* 1 = 4.17159 loss)
I0123 20:07:49.245975 29630 sgd_solver.cpp:106] Iteration 24080, lr = 0.01
I0123 20:07:56.519868 29630 solver.cpp:237] Iteration 24100, loss = 3.77629
I0123 20:07:56.520011 29630 solver.cpp:253]     Train net output #0: loss = 3.77629 (* 1 = 3.77629 loss)
I0123 20:07:56.520018 29630 sgd_solver.cpp:106] Iteration 24100, lr = 0.01
I0123 20:08:03.815642 29630 solver.cpp:237] Iteration 24120, loss = 3.77325
I0123 20:08:03.815675 29630 solver.cpp:253]     Train net output #0: loss = 3.77325 (* 1 = 3.77325 loss)
I0123 20:08:03.815696 29630 sgd_solver.cpp:106] Iteration 24120, lr = 0.01
I0123 20:08:11.113560 29630 solver.cpp:237] Iteration 24140, loss = 3.90592
I0123 20:08:11.113592 29630 solver.cpp:253]     Train net output #0: loss = 3.90592 (* 1 = 3.90592 loss)
I0123 20:08:11.113598 29630 sgd_solver.cpp:106] Iteration 24140, lr = 0.01
I0123 20:08:12.992019 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 20:08:18.400766 29630 solver.cpp:237] Iteration 24160, loss = 3.66571
I0123 20:08:18.400805 29630 solver.cpp:253]     Train net output #0: loss = 3.66571 (* 1 = 3.66571 loss)
I0123 20:08:18.400811 29630 sgd_solver.cpp:106] Iteration 24160, lr = 0.01
I0123 20:08:25.672127 29630 solver.cpp:237] Iteration 24180, loss = 3.7294
I0123 20:08:25.672165 29630 solver.cpp:253]     Train net output #0: loss = 3.7294 (* 1 = 3.7294 loss)
I0123 20:08:25.672171 29630 sgd_solver.cpp:106] Iteration 24180, lr = 0.01
I0123 20:08:32.938235 29630 solver.cpp:237] Iteration 24200, loss = 3.78814
I0123 20:08:32.938376 29630 solver.cpp:253]     Train net output #0: loss = 3.78814 (* 1 = 3.78814 loss)
I0123 20:08:32.938392 29630 sgd_solver.cpp:106] Iteration 24200, lr = 0.01
I0123 20:08:40.174942 29630 solver.cpp:237] Iteration 24220, loss = 3.86624
I0123 20:08:40.174980 29630 solver.cpp:253]     Train net output #0: loss = 3.86624 (* 1 = 3.86624 loss)
I0123 20:08:40.174986 29630 sgd_solver.cpp:106] Iteration 24220, lr = 0.01
I0123 20:08:47.469288 29630 solver.cpp:237] Iteration 24240, loss = 3.92062
I0123 20:08:47.469327 29630 solver.cpp:253]     Train net output #0: loss = 3.92062 (* 1 = 3.92062 loss)
I0123 20:08:47.469333 29630 sgd_solver.cpp:106] Iteration 24240, lr = 0.01
I0123 20:08:54.701190 29630 solver.cpp:237] Iteration 24260, loss = 3.93857
I0123 20:08:54.701230 29630 solver.cpp:253]     Train net output #0: loss = 3.93857 (* 1 = 3.93857 loss)
I0123 20:08:54.701236 29630 sgd_solver.cpp:106] Iteration 24260, lr = 0.01
I0123 20:09:01.990111 29630 solver.cpp:237] Iteration 24280, loss = 3.60612
I0123 20:09:01.990151 29630 solver.cpp:253]     Train net output #0: loss = 3.60612 (* 1 = 3.60612 loss)
I0123 20:09:01.990159 29630 sgd_solver.cpp:106] Iteration 24280, lr = 0.01
I0123 20:09:09.233355 29630 solver.cpp:237] Iteration 24300, loss = 3.91003
I0123 20:09:09.233476 29630 solver.cpp:253]     Train net output #0: loss = 3.91003 (* 1 = 3.91003 loss)
I0123 20:09:09.233484 29630 sgd_solver.cpp:106] Iteration 24300, lr = 0.01
I0123 20:09:16.463726 29630 solver.cpp:237] Iteration 24320, loss = 3.77519
I0123 20:09:16.463755 29630 solver.cpp:253]     Train net output #0: loss = 3.77519 (* 1 = 3.77519 loss)
I0123 20:09:16.463762 29630 sgd_solver.cpp:106] Iteration 24320, lr = 0.01
I0123 20:09:23.765542 29630 solver.cpp:237] Iteration 24340, loss = 3.89518
I0123 20:09:23.765584 29630 solver.cpp:253]     Train net output #0: loss = 3.89518 (* 1 = 3.89518 loss)
I0123 20:09:23.765591 29630 sgd_solver.cpp:106] Iteration 24340, lr = 0.01
I0123 20:09:30.995937 29630 solver.cpp:237] Iteration 24360, loss = 3.9512
I0123 20:09:30.995975 29630 solver.cpp:253]     Train net output #0: loss = 3.9512 (* 1 = 3.9512 loss)
I0123 20:09:30.995980 29630 sgd_solver.cpp:106] Iteration 24360, lr = 0.01
I0123 20:09:38.293321 29630 solver.cpp:237] Iteration 24380, loss = 3.78263
I0123 20:09:38.293361 29630 solver.cpp:253]     Train net output #0: loss = 3.78263 (* 1 = 3.78263 loss)
I0123 20:09:38.293368 29630 sgd_solver.cpp:106] Iteration 24380, lr = 0.01
I0123 20:09:45.526057 29630 solver.cpp:237] Iteration 24400, loss = 4.04294
I0123 20:09:45.526178 29630 solver.cpp:253]     Train net output #0: loss = 4.04294 (* 1 = 4.04294 loss)
I0123 20:09:45.526195 29630 sgd_solver.cpp:106] Iteration 24400, lr = 0.01
I0123 20:09:52.792815 29630 solver.cpp:237] Iteration 24420, loss = 3.95321
I0123 20:09:52.792853 29630 solver.cpp:253]     Train net output #0: loss = 3.95321 (* 1 = 3.95321 loss)
I0123 20:09:52.792860 29630 sgd_solver.cpp:106] Iteration 24420, lr = 0.01
I0123 20:10:00.029631 29630 solver.cpp:237] Iteration 24440, loss = 3.77373
I0123 20:10:00.029681 29630 solver.cpp:253]     Train net output #0: loss = 3.77373 (* 1 = 3.77373 loss)
I0123 20:10:00.029700 29630 sgd_solver.cpp:106] Iteration 24440, lr = 0.01
I0123 20:10:07.244933 29630 solver.cpp:237] Iteration 24460, loss = 3.82476
I0123 20:10:07.244981 29630 solver.cpp:253]     Train net output #0: loss = 3.82476 (* 1 = 3.82476 loss)
I0123 20:10:07.244987 29630 sgd_solver.cpp:106] Iteration 24460, lr = 0.01
I0123 20:10:14.453030 29630 solver.cpp:237] Iteration 24480, loss = 3.76457
I0123 20:10:14.453068 29630 solver.cpp:253]     Train net output #0: loss = 3.76457 (* 1 = 3.76457 loss)
I0123 20:10:14.453075 29630 sgd_solver.cpp:106] Iteration 24480, lr = 0.01
I0123 20:10:21.731426 29630 solver.cpp:237] Iteration 24500, loss = 4.06797
I0123 20:10:21.731549 29630 solver.cpp:253]     Train net output #0: loss = 4.06797 (* 1 = 4.06797 loss)
I0123 20:10:21.731557 29630 sgd_solver.cpp:106] Iteration 24500, lr = 0.01
I0123 20:10:28.981026 29630 solver.cpp:237] Iteration 24520, loss = 3.70041
I0123 20:10:28.981066 29630 solver.cpp:253]     Train net output #0: loss = 3.70041 (* 1 = 3.70041 loss)
I0123 20:10:28.981075 29630 sgd_solver.cpp:106] Iteration 24520, lr = 0.01
I0123 20:10:36.205029 29630 solver.cpp:237] Iteration 24540, loss = 3.85935
I0123 20:10:36.205067 29630 solver.cpp:253]     Train net output #0: loss = 3.85935 (* 1 = 3.85935 loss)
I0123 20:10:36.205073 29630 sgd_solver.cpp:106] Iteration 24540, lr = 0.01
I0123 20:10:43.424906 29630 solver.cpp:237] Iteration 24560, loss = 3.97915
I0123 20:10:43.424945 29630 solver.cpp:253]     Train net output #0: loss = 3.97915 (* 1 = 3.97915 loss)
I0123 20:10:43.424952 29630 sgd_solver.cpp:106] Iteration 24560, lr = 0.01
I0123 20:10:50.682086 29630 solver.cpp:237] Iteration 24580, loss = 3.80249
I0123 20:10:50.682124 29630 solver.cpp:253]     Train net output #0: loss = 3.80249 (* 1 = 3.80249 loss)
I0123 20:10:50.682131 29630 sgd_solver.cpp:106] Iteration 24580, lr = 0.01
I0123 20:10:57.923156 29630 solver.cpp:237] Iteration 24600, loss = 4.04928
I0123 20:10:57.923276 29630 solver.cpp:253]     Train net output #0: loss = 4.04928 (* 1 = 4.04928 loss)
I0123 20:10:57.923283 29630 sgd_solver.cpp:106] Iteration 24600, lr = 0.01
I0123 20:11:05.189357 29630 solver.cpp:237] Iteration 24620, loss = 4.02762
I0123 20:11:05.189394 29630 solver.cpp:253]     Train net output #0: loss = 4.02762 (* 1 = 4.02762 loss)
I0123 20:11:05.189400 29630 sgd_solver.cpp:106] Iteration 24620, lr = 0.01
I0123 20:11:12.426923 29630 solver.cpp:237] Iteration 24640, loss = 3.90043
I0123 20:11:12.426960 29630 solver.cpp:253]     Train net output #0: loss = 3.90043 (* 1 = 3.90043 loss)
I0123 20:11:12.426966 29630 sgd_solver.cpp:106] Iteration 24640, lr = 0.01
I0123 20:11:19.694694 29630 solver.cpp:237] Iteration 24660, loss = 4.28419
I0123 20:11:19.694733 29630 solver.cpp:253]     Train net output #0: loss = 4.28419 (* 1 = 4.28419 loss)
I0123 20:11:19.694738 29630 sgd_solver.cpp:106] Iteration 24660, lr = 0.01
I0123 20:11:26.939767 29630 solver.cpp:237] Iteration 24680, loss = 3.55229
I0123 20:11:26.939797 29630 solver.cpp:253]     Train net output #0: loss = 3.55229 (* 1 = 3.55229 loss)
I0123 20:11:26.939805 29630 sgd_solver.cpp:106] Iteration 24680, lr = 0.01
I0123 20:11:34.234349 29630 solver.cpp:237] Iteration 24700, loss = 3.97245
I0123 20:11:34.234472 29630 solver.cpp:253]     Train net output #0: loss = 3.97245 (* 1 = 3.97245 loss)
I0123 20:11:34.234479 29630 sgd_solver.cpp:106] Iteration 24700, lr = 0.01
I0123 20:11:41.501471 29630 solver.cpp:237] Iteration 24720, loss = 3.82343
I0123 20:11:41.501510 29630 solver.cpp:253]     Train net output #0: loss = 3.82343 (* 1 = 3.82343 loss)
I0123 20:11:41.501516 29630 sgd_solver.cpp:106] Iteration 24720, lr = 0.01
I0123 20:11:48.771384 29630 solver.cpp:237] Iteration 24740, loss = 3.90909
I0123 20:11:48.771422 29630 solver.cpp:253]     Train net output #0: loss = 3.90909 (* 1 = 3.90909 loss)
I0123 20:11:48.771428 29630 sgd_solver.cpp:106] Iteration 24740, lr = 0.01
I0123 20:11:55.996098 29630 solver.cpp:237] Iteration 24760, loss = 3.88472
I0123 20:11:55.996137 29630 solver.cpp:253]     Train net output #0: loss = 3.88472 (* 1 = 3.88472 loss)
I0123 20:11:55.996143 29630 sgd_solver.cpp:106] Iteration 24760, lr = 0.01
I0123 20:12:03.275346 29630 solver.cpp:237] Iteration 24780, loss = 4.09772
I0123 20:12:03.275387 29630 solver.cpp:253]     Train net output #0: loss = 4.09772 (* 1 = 4.09772 loss)
I0123 20:12:03.275393 29630 sgd_solver.cpp:106] Iteration 24780, lr = 0.01
I0123 20:12:10.572907 29630 solver.cpp:237] Iteration 24800, loss = 3.59805
I0123 20:12:10.573053 29630 solver.cpp:253]     Train net output #0: loss = 3.59805 (* 1 = 3.59805 loss)
I0123 20:12:10.573060 29630 sgd_solver.cpp:106] Iteration 24800, lr = 0.01
I0123 20:12:17.872025 29630 solver.cpp:237] Iteration 24820, loss = 3.91308
I0123 20:12:17.872064 29630 solver.cpp:253]     Train net output #0: loss = 3.91308 (* 1 = 3.91308 loss)
I0123 20:12:17.872071 29630 sgd_solver.cpp:106] Iteration 24820, lr = 0.01
I0123 20:12:25.129295 29630 solver.cpp:237] Iteration 24840, loss = 3.96141
I0123 20:12:25.129333 29630 solver.cpp:253]     Train net output #0: loss = 3.96141 (* 1 = 3.96141 loss)
I0123 20:12:25.129339 29630 sgd_solver.cpp:106] Iteration 24840, lr = 0.01
I0123 20:12:32.345832 29630 solver.cpp:237] Iteration 24860, loss = 3.84573
I0123 20:12:32.345870 29630 solver.cpp:253]     Train net output #0: loss = 3.84573 (* 1 = 3.84573 loss)
I0123 20:12:32.345876 29630 sgd_solver.cpp:106] Iteration 24860, lr = 0.01
I0123 20:12:39.636879 29630 solver.cpp:237] Iteration 24880, loss = 3.93545
I0123 20:12:39.636957 29630 solver.cpp:253]     Train net output #0: loss = 3.93545 (* 1 = 3.93545 loss)
I0123 20:12:39.636972 29630 sgd_solver.cpp:106] Iteration 24880, lr = 0.01
I0123 20:12:46.938724 29630 solver.cpp:237] Iteration 24900, loss = 4.14524
I0123 20:12:46.938889 29630 solver.cpp:253]     Train net output #0: loss = 4.14524 (* 1 = 4.14524 loss)
I0123 20:12:46.938897 29630 sgd_solver.cpp:106] Iteration 24900, lr = 0.01
I0123 20:12:54.191447 29630 solver.cpp:237] Iteration 24920, loss = 3.92153
I0123 20:12:54.191486 29630 solver.cpp:253]     Train net output #0: loss = 3.92153 (* 1 = 3.92153 loss)
I0123 20:12:54.191493 29630 sgd_solver.cpp:106] Iteration 24920, lr = 0.01
I0123 20:13:01.515550 29630 solver.cpp:237] Iteration 24940, loss = 3.92433
I0123 20:13:01.515589 29630 solver.cpp:253]     Train net output #0: loss = 3.92433 (* 1 = 3.92433 loss)
I0123 20:13:01.515594 29630 sgd_solver.cpp:106] Iteration 24940, lr = 0.01
I0123 20:13:08.796479 29630 solver.cpp:237] Iteration 24960, loss = 3.62161
I0123 20:13:08.796519 29630 solver.cpp:253]     Train net output #0: loss = 3.62161 (* 1 = 3.62161 loss)
I0123 20:13:08.796525 29630 sgd_solver.cpp:106] Iteration 24960, lr = 0.01
I0123 20:13:16.070204 29630 solver.cpp:237] Iteration 24980, loss = 3.81791
I0123 20:13:16.070233 29630 solver.cpp:253]     Train net output #0: loss = 3.81791 (* 1 = 3.81791 loss)
I0123 20:13:16.070240 29630 sgd_solver.cpp:106] Iteration 24980, lr = 0.01
I0123 20:13:23.044265 29630 solver.cpp:341] Iteration 25000, Testing net (#0)
I0123 20:13:33.907212 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 20:14:36.811180 29630 solver.cpp:409]     Test net output #0: accuracy = 0.24656
I0123 20:14:36.811319 29630 solver.cpp:409]     Test net output #1: loss = 3.67655 (* 1 = 3.67655 loss)
I0123 20:14:36.851835 29630 solver.cpp:237] Iteration 25000, loss = 4.03176
I0123 20:14:36.851871 29630 solver.cpp:253]     Train net output #0: loss = 4.03176 (* 1 = 4.03176 loss)
I0123 20:14:36.851877 29630 sgd_solver.cpp:106] Iteration 25000, lr = 0.01
I0123 20:14:43.384101 29630 solver.cpp:237] Iteration 25020, loss = 4.22322
I0123 20:14:43.384140 29630 solver.cpp:253]     Train net output #0: loss = 4.22322 (* 1 = 4.22322 loss)
I0123 20:14:43.384145 29630 sgd_solver.cpp:106] Iteration 25020, lr = 0.01
I0123 20:14:50.613235 29630 solver.cpp:237] Iteration 25040, loss = 3.94153
I0123 20:14:50.613282 29630 solver.cpp:253]     Train net output #0: loss = 3.94153 (* 1 = 3.94153 loss)
I0123 20:14:50.613289 29630 sgd_solver.cpp:106] Iteration 25040, lr = 0.01
I0123 20:14:57.857555 29630 solver.cpp:237] Iteration 25060, loss = 3.60642
I0123 20:14:57.857596 29630 solver.cpp:253]     Train net output #0: loss = 3.60642 (* 1 = 3.60642 loss)
I0123 20:14:57.857602 29630 sgd_solver.cpp:106] Iteration 25060, lr = 0.01
I0123 20:15:05.093724 29630 solver.cpp:237] Iteration 25080, loss = 3.93458
I0123 20:15:05.093762 29630 solver.cpp:253]     Train net output #0: loss = 3.93458 (* 1 = 3.93458 loss)
I0123 20:15:05.093768 29630 sgd_solver.cpp:106] Iteration 25080, lr = 0.01
I0123 20:15:12.364709 29630 solver.cpp:237] Iteration 25100, loss = 4.00126
I0123 20:15:12.364825 29630 solver.cpp:253]     Train net output #0: loss = 4.00126 (* 1 = 4.00126 loss)
I0123 20:15:12.364832 29630 sgd_solver.cpp:106] Iteration 25100, lr = 0.01
I0123 20:15:19.614487 29630 solver.cpp:237] Iteration 25120, loss = 3.96335
I0123 20:15:19.614526 29630 solver.cpp:253]     Train net output #0: loss = 3.96335 (* 1 = 3.96335 loss)
I0123 20:15:19.614533 29630 sgd_solver.cpp:106] Iteration 25120, lr = 0.01
I0123 20:15:26.859973 29630 solver.cpp:237] Iteration 25140, loss = 3.67105
I0123 20:15:26.860014 29630 solver.cpp:253]     Train net output #0: loss = 3.67105 (* 1 = 3.67105 loss)
I0123 20:15:26.860020 29630 sgd_solver.cpp:106] Iteration 25140, lr = 0.01
I0123 20:15:30.925215 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 20:15:34.114995 29630 solver.cpp:237] Iteration 25160, loss = 4.01853
I0123 20:15:34.115059 29630 solver.cpp:253]     Train net output #0: loss = 4.01853 (* 1 = 4.01853 loss)
I0123 20:15:34.115070 29630 sgd_solver.cpp:106] Iteration 25160, lr = 0.01
I0123 20:15:41.408012 29630 solver.cpp:237] Iteration 25180, loss = 3.57698
I0123 20:15:41.408051 29630 solver.cpp:253]     Train net output #0: loss = 3.57698 (* 1 = 3.57698 loss)
I0123 20:15:41.408056 29630 sgd_solver.cpp:106] Iteration 25180, lr = 0.01
I0123 20:15:48.642987 29630 solver.cpp:237] Iteration 25200, loss = 3.67831
I0123 20:15:48.643108 29630 solver.cpp:253]     Train net output #0: loss = 3.67831 (* 1 = 3.67831 loss)
I0123 20:15:48.643116 29630 sgd_solver.cpp:106] Iteration 25200, lr = 0.01
I0123 20:15:55.959249 29630 solver.cpp:237] Iteration 25220, loss = 3.76493
I0123 20:15:55.959287 29630 solver.cpp:253]     Train net output #0: loss = 3.76493 (* 1 = 3.76493 loss)
I0123 20:15:55.959293 29630 sgd_solver.cpp:106] Iteration 25220, lr = 0.01
I0123 20:16:03.235038 29630 solver.cpp:237] Iteration 25240, loss = 3.92659
I0123 20:16:03.235076 29630 solver.cpp:253]     Train net output #0: loss = 3.92659 (* 1 = 3.92659 loss)
I0123 20:16:03.235082 29630 sgd_solver.cpp:106] Iteration 25240, lr = 0.01
I0123 20:16:10.509263 29630 solver.cpp:237] Iteration 25260, loss = 3.90687
I0123 20:16:10.509299 29630 solver.cpp:253]     Train net output #0: loss = 3.90687 (* 1 = 3.90687 loss)
I0123 20:16:10.509306 29630 sgd_solver.cpp:106] Iteration 25260, lr = 0.01
I0123 20:16:17.773664 29630 solver.cpp:237] Iteration 25280, loss = 3.94774
I0123 20:16:17.773705 29630 solver.cpp:253]     Train net output #0: loss = 3.94774 (* 1 = 3.94774 loss)
I0123 20:16:17.773710 29630 sgd_solver.cpp:106] Iteration 25280, lr = 0.01
I0123 20:16:25.041380 29630 solver.cpp:237] Iteration 25300, loss = 3.72842
I0123 20:16:25.041513 29630 solver.cpp:253]     Train net output #0: loss = 3.72842 (* 1 = 3.72842 loss)
I0123 20:16:25.041520 29630 sgd_solver.cpp:106] Iteration 25300, lr = 0.01
I0123 20:16:32.343901 29630 solver.cpp:237] Iteration 25320, loss = 4.0797
I0123 20:16:32.343940 29630 solver.cpp:253]     Train net output #0: loss = 4.0797 (* 1 = 4.0797 loss)
I0123 20:16:32.343945 29630 sgd_solver.cpp:106] Iteration 25320, lr = 0.01
I0123 20:16:39.605185 29630 solver.cpp:237] Iteration 25340, loss = 3.93463
I0123 20:16:39.605223 29630 solver.cpp:253]     Train net output #0: loss = 3.93463 (* 1 = 3.93463 loss)
I0123 20:16:39.605229 29630 sgd_solver.cpp:106] Iteration 25340, lr = 0.01
I0123 20:16:46.894613 29630 solver.cpp:237] Iteration 25360, loss = 3.83332
I0123 20:16:46.894651 29630 solver.cpp:253]     Train net output #0: loss = 3.83332 (* 1 = 3.83332 loss)
I0123 20:16:46.894659 29630 sgd_solver.cpp:106] Iteration 25360, lr = 0.01
I0123 20:16:54.180359 29630 solver.cpp:237] Iteration 25380, loss = 3.80145
I0123 20:16:54.180397 29630 solver.cpp:253]     Train net output #0: loss = 3.80145 (* 1 = 3.80145 loss)
I0123 20:16:54.180403 29630 sgd_solver.cpp:106] Iteration 25380, lr = 0.01
I0123 20:17:01.484724 29630 solver.cpp:237] Iteration 25400, loss = 4.1515
I0123 20:17:01.484889 29630 solver.cpp:253]     Train net output #0: loss = 4.1515 (* 1 = 4.1515 loss)
I0123 20:17:01.484896 29630 sgd_solver.cpp:106] Iteration 25400, lr = 0.01
I0123 20:17:08.787869 29630 solver.cpp:237] Iteration 25420, loss = 4.04914
I0123 20:17:08.787907 29630 solver.cpp:253]     Train net output #0: loss = 4.04914 (* 1 = 4.04914 loss)
I0123 20:17:08.787914 29630 sgd_solver.cpp:106] Iteration 25420, lr = 0.01
I0123 20:17:16.039417 29630 solver.cpp:237] Iteration 25440, loss = 4.02924
I0123 20:17:16.039456 29630 solver.cpp:253]     Train net output #0: loss = 4.02924 (* 1 = 4.02924 loss)
I0123 20:17:16.039463 29630 sgd_solver.cpp:106] Iteration 25440, lr = 0.01
I0123 20:17:23.326689 29630 solver.cpp:237] Iteration 25460, loss = 4.01608
I0123 20:17:23.326728 29630 solver.cpp:253]     Train net output #0: loss = 4.01608 (* 1 = 4.01608 loss)
I0123 20:17:23.326735 29630 sgd_solver.cpp:106] Iteration 25460, lr = 0.01
I0123 20:17:30.593142 29630 solver.cpp:237] Iteration 25480, loss = 3.92598
I0123 20:17:30.593183 29630 solver.cpp:253]     Train net output #0: loss = 3.92598 (* 1 = 3.92598 loss)
I0123 20:17:30.593189 29630 sgd_solver.cpp:106] Iteration 25480, lr = 0.01
I0123 20:17:37.834166 29630 solver.cpp:237] Iteration 25500, loss = 3.74218
I0123 20:17:37.834326 29630 solver.cpp:253]     Train net output #0: loss = 3.74218 (* 1 = 3.74218 loss)
I0123 20:17:37.834336 29630 sgd_solver.cpp:106] Iteration 25500, lr = 0.01
I0123 20:17:45.079926 29630 solver.cpp:237] Iteration 25520, loss = 3.74521
I0123 20:17:45.079964 29630 solver.cpp:253]     Train net output #0: loss = 3.74521 (* 1 = 3.74521 loss)
I0123 20:17:45.079972 29630 sgd_solver.cpp:106] Iteration 25520, lr = 0.01
I0123 20:17:52.333932 29630 solver.cpp:237] Iteration 25540, loss = 3.98711
I0123 20:17:52.333971 29630 solver.cpp:253]     Train net output #0: loss = 3.98711 (* 1 = 3.98711 loss)
I0123 20:17:52.333978 29630 sgd_solver.cpp:106] Iteration 25540, lr = 0.01
I0123 20:17:59.588215 29630 solver.cpp:237] Iteration 25560, loss = 4.10015
I0123 20:17:59.588254 29630 solver.cpp:253]     Train net output #0: loss = 4.10015 (* 1 = 4.10015 loss)
I0123 20:17:59.588260 29630 sgd_solver.cpp:106] Iteration 25560, lr = 0.01
I0123 20:18:06.812119 29630 solver.cpp:237] Iteration 25580, loss = 3.74764
I0123 20:18:06.812158 29630 solver.cpp:253]     Train net output #0: loss = 3.74764 (* 1 = 3.74764 loss)
I0123 20:18:06.812165 29630 sgd_solver.cpp:106] Iteration 25580, lr = 0.01
I0123 20:18:14.096505 29630 solver.cpp:237] Iteration 25600, loss = 3.73316
I0123 20:18:14.096634 29630 solver.cpp:253]     Train net output #0: loss = 3.73316 (* 1 = 3.73316 loss)
I0123 20:18:14.096642 29630 sgd_solver.cpp:106] Iteration 25600, lr = 0.01
I0123 20:18:21.336297 29630 solver.cpp:237] Iteration 25620, loss = 4.07194
I0123 20:18:21.336336 29630 solver.cpp:253]     Train net output #0: loss = 4.07194 (* 1 = 4.07194 loss)
I0123 20:18:21.336344 29630 sgd_solver.cpp:106] Iteration 25620, lr = 0.01
I0123 20:18:28.621848 29630 solver.cpp:237] Iteration 25640, loss = 3.84231
I0123 20:18:28.621887 29630 solver.cpp:253]     Train net output #0: loss = 3.84231 (* 1 = 3.84231 loss)
I0123 20:18:28.621893 29630 sgd_solver.cpp:106] Iteration 25640, lr = 0.01
I0123 20:18:35.848368 29630 solver.cpp:237] Iteration 25660, loss = 4.07026
I0123 20:18:35.848407 29630 solver.cpp:253]     Train net output #0: loss = 4.07026 (* 1 = 4.07026 loss)
I0123 20:18:35.848413 29630 sgd_solver.cpp:106] Iteration 25660, lr = 0.01
I0123 20:18:43.073235 29630 solver.cpp:237] Iteration 25680, loss = 4.00751
I0123 20:18:43.073276 29630 solver.cpp:253]     Train net output #0: loss = 4.00751 (* 1 = 4.00751 loss)
I0123 20:18:43.073282 29630 sgd_solver.cpp:106] Iteration 25680, lr = 0.01
I0123 20:18:50.289686 29630 solver.cpp:237] Iteration 25700, loss = 3.81314
I0123 20:18:50.289821 29630 solver.cpp:253]     Train net output #0: loss = 3.81314 (* 1 = 3.81314 loss)
I0123 20:18:50.289837 29630 sgd_solver.cpp:106] Iteration 25700, lr = 0.01
I0123 20:18:57.515436 29630 solver.cpp:237] Iteration 25720, loss = 3.88872
I0123 20:18:57.515476 29630 solver.cpp:253]     Train net output #0: loss = 3.88872 (* 1 = 3.88872 loss)
I0123 20:18:57.515482 29630 sgd_solver.cpp:106] Iteration 25720, lr = 0.01
I0123 20:19:04.789881 29630 solver.cpp:237] Iteration 25740, loss = 4.08743
I0123 20:19:04.789921 29630 solver.cpp:253]     Train net output #0: loss = 4.08743 (* 1 = 4.08743 loss)
I0123 20:19:04.789927 29630 sgd_solver.cpp:106] Iteration 25740, lr = 0.01
I0123 20:19:12.027016 29630 solver.cpp:237] Iteration 25760, loss = 4.21933
I0123 20:19:12.027058 29630 solver.cpp:253]     Train net output #0: loss = 4.21933 (* 1 = 4.21933 loss)
I0123 20:19:12.027065 29630 sgd_solver.cpp:106] Iteration 25760, lr = 0.01
I0123 20:19:19.314795 29630 solver.cpp:237] Iteration 25780, loss = 3.86741
I0123 20:19:19.314832 29630 solver.cpp:253]     Train net output #0: loss = 3.86741 (* 1 = 3.86741 loss)
I0123 20:19:19.314838 29630 sgd_solver.cpp:106] Iteration 25780, lr = 0.01
I0123 20:19:26.562366 29630 solver.cpp:237] Iteration 25800, loss = 3.71501
I0123 20:19:26.562508 29630 solver.cpp:253]     Train net output #0: loss = 3.71501 (* 1 = 3.71501 loss)
I0123 20:19:26.562516 29630 sgd_solver.cpp:106] Iteration 25800, lr = 0.01
I0123 20:19:33.796936 29630 solver.cpp:237] Iteration 25820, loss = 3.55523
I0123 20:19:33.796975 29630 solver.cpp:253]     Train net output #0: loss = 3.55523 (* 1 = 3.55523 loss)
I0123 20:19:33.796982 29630 sgd_solver.cpp:106] Iteration 25820, lr = 0.01
I0123 20:19:41.125298 29630 solver.cpp:237] Iteration 25840, loss = 3.72417
I0123 20:19:41.125336 29630 solver.cpp:253]     Train net output #0: loss = 3.72417 (* 1 = 3.72417 loss)
I0123 20:19:41.125342 29630 sgd_solver.cpp:106] Iteration 25840, lr = 0.01
I0123 20:19:48.404093 29630 solver.cpp:237] Iteration 25860, loss = 3.79256
I0123 20:19:48.404131 29630 solver.cpp:253]     Train net output #0: loss = 3.79256 (* 1 = 3.79256 loss)
I0123 20:19:48.404139 29630 sgd_solver.cpp:106] Iteration 25860, lr = 0.01
I0123 20:19:55.689924 29630 solver.cpp:237] Iteration 25880, loss = 3.8459
I0123 20:19:55.689962 29630 solver.cpp:253]     Train net output #0: loss = 3.8459 (* 1 = 3.8459 loss)
I0123 20:19:55.689968 29630 sgd_solver.cpp:106] Iteration 25880, lr = 0.01
I0123 20:20:02.947075 29630 solver.cpp:237] Iteration 25900, loss = 3.94845
I0123 20:20:02.947211 29630 solver.cpp:253]     Train net output #0: loss = 3.94845 (* 1 = 3.94845 loss)
I0123 20:20:02.947218 29630 sgd_solver.cpp:106] Iteration 25900, lr = 0.01
I0123 20:20:10.207772 29630 solver.cpp:237] Iteration 25920, loss = 3.85204
I0123 20:20:10.207811 29630 solver.cpp:253]     Train net output #0: loss = 3.85204 (* 1 = 3.85204 loss)
I0123 20:20:10.207818 29630 sgd_solver.cpp:106] Iteration 25920, lr = 0.01
I0123 20:20:17.479681 29630 solver.cpp:237] Iteration 25940, loss = 3.75965
I0123 20:20:17.479719 29630 solver.cpp:253]     Train net output #0: loss = 3.75965 (* 1 = 3.75965 loss)
I0123 20:20:17.479725 29630 sgd_solver.cpp:106] Iteration 25940, lr = 0.01
I0123 20:20:24.807126 29630 solver.cpp:237] Iteration 25960, loss = 3.82828
I0123 20:20:24.807164 29630 solver.cpp:253]     Train net output #0: loss = 3.82828 (* 1 = 3.82828 loss)
I0123 20:20:24.807170 29630 sgd_solver.cpp:106] Iteration 25960, lr = 0.01
I0123 20:20:32.079252 29630 solver.cpp:237] Iteration 25980, loss = 3.8746
I0123 20:20:32.079291 29630 solver.cpp:253]     Train net output #0: loss = 3.8746 (* 1 = 3.8746 loss)
I0123 20:20:32.079298 29630 sgd_solver.cpp:106] Iteration 25980, lr = 0.01
I0123 20:20:39.038816 29630 solver.cpp:341] Iteration 26000, Testing net (#0)
I0123 20:20:50.376384 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 20:21:52.906208 29630 solver.cpp:409]     Test net output #0: accuracy = 0.25508
I0123 20:21:52.906332 29630 solver.cpp:409]     Test net output #1: loss = 3.64597 (* 1 = 3.64597 loss)
I0123 20:21:52.947036 29630 solver.cpp:237] Iteration 26000, loss = 3.98285
I0123 20:21:52.947074 29630 solver.cpp:253]     Train net output #0: loss = 3.98285 (* 1 = 3.98285 loss)
I0123 20:21:52.947080 29630 sgd_solver.cpp:106] Iteration 26000, lr = 0.01
I0123 20:21:59.498422 29630 solver.cpp:237] Iteration 26020, loss = 3.61894
I0123 20:21:59.498461 29630 solver.cpp:253]     Train net output #0: loss = 3.61894 (* 1 = 3.61894 loss)
I0123 20:21:59.498466 29630 sgd_solver.cpp:106] Iteration 26020, lr = 0.01
I0123 20:22:06.719151 29630 solver.cpp:237] Iteration 26040, loss = 4.01165
I0123 20:22:06.719189 29630 solver.cpp:253]     Train net output #0: loss = 4.01165 (* 1 = 4.01165 loss)
I0123 20:22:06.719195 29630 sgd_solver.cpp:106] Iteration 26040, lr = 0.01
I0123 20:22:13.913761 29630 solver.cpp:237] Iteration 26060, loss = 3.81081
I0123 20:22:13.913800 29630 solver.cpp:253]     Train net output #0: loss = 3.81081 (* 1 = 3.81081 loss)
I0123 20:22:13.913806 29630 sgd_solver.cpp:106] Iteration 26060, lr = 0.01
I0123 20:22:21.152915 29630 solver.cpp:237] Iteration 26080, loss = 4.05969
I0123 20:22:21.152956 29630 solver.cpp:253]     Train net output #0: loss = 4.05969 (* 1 = 4.05969 loss)
I0123 20:22:21.152961 29630 sgd_solver.cpp:106] Iteration 26080, lr = 0.01
I0123 20:22:28.405755 29630 solver.cpp:237] Iteration 26100, loss = 3.81709
I0123 20:22:28.405932 29630 solver.cpp:253]     Train net output #0: loss = 3.81709 (* 1 = 3.81709 loss)
I0123 20:22:28.405941 29630 sgd_solver.cpp:106] Iteration 26100, lr = 0.01
I0123 20:22:35.659939 29630 solver.cpp:237] Iteration 26120, loss = 3.68788
I0123 20:22:35.659978 29630 solver.cpp:253]     Train net output #0: loss = 3.68788 (* 1 = 3.68788 loss)
I0123 20:22:35.659984 29630 sgd_solver.cpp:106] Iteration 26120, lr = 0.01
I0123 20:22:42.916625 29630 solver.cpp:237] Iteration 26140, loss = 3.67201
I0123 20:22:42.916663 29630 solver.cpp:253]     Train net output #0: loss = 3.67201 (* 1 = 3.67201 loss)
I0123 20:22:42.916669 29630 sgd_solver.cpp:106] Iteration 26140, lr = 0.01
I0123 20:22:49.149787 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 20:22:50.156643 29630 solver.cpp:237] Iteration 26160, loss = 3.45246
I0123 20:22:50.156682 29630 solver.cpp:253]     Train net output #0: loss = 3.45246 (* 1 = 3.45246 loss)
I0123 20:22:50.156688 29630 sgd_solver.cpp:106] Iteration 26160, lr = 0.01
I0123 20:22:57.401710 29630 solver.cpp:237] Iteration 26180, loss = 3.96827
I0123 20:22:57.401767 29630 solver.cpp:253]     Train net output #0: loss = 3.96827 (* 1 = 3.96827 loss)
I0123 20:22:57.401779 29630 sgd_solver.cpp:106] Iteration 26180, lr = 0.01
I0123 20:23:04.616320 29630 solver.cpp:237] Iteration 26200, loss = 3.73802
I0123 20:23:04.616449 29630 solver.cpp:253]     Train net output #0: loss = 3.73802 (* 1 = 3.73802 loss)
I0123 20:23:04.616457 29630 sgd_solver.cpp:106] Iteration 26200, lr = 0.01
I0123 20:23:11.848644 29630 solver.cpp:237] Iteration 26220, loss = 4.1308
I0123 20:23:11.848682 29630 solver.cpp:253]     Train net output #0: loss = 4.1308 (* 1 = 4.1308 loss)
I0123 20:23:11.848688 29630 sgd_solver.cpp:106] Iteration 26220, lr = 0.01
I0123 20:23:19.112550 29630 solver.cpp:237] Iteration 26240, loss = 3.96166
I0123 20:23:19.112587 29630 solver.cpp:253]     Train net output #0: loss = 3.96166 (* 1 = 3.96166 loss)
I0123 20:23:19.112594 29630 sgd_solver.cpp:106] Iteration 26240, lr = 0.01
I0123 20:23:26.379415 29630 solver.cpp:237] Iteration 26260, loss = 3.8602
I0123 20:23:26.379461 29630 solver.cpp:253]     Train net output #0: loss = 3.8602 (* 1 = 3.8602 loss)
I0123 20:23:26.379467 29630 sgd_solver.cpp:106] Iteration 26260, lr = 0.01
I0123 20:23:33.664696 29630 solver.cpp:237] Iteration 26280, loss = 3.73897
I0123 20:23:33.664731 29630 solver.cpp:253]     Train net output #0: loss = 3.73897 (* 1 = 3.73897 loss)
I0123 20:23:33.664738 29630 sgd_solver.cpp:106] Iteration 26280, lr = 0.01
I0123 20:23:40.963201 29630 solver.cpp:237] Iteration 26300, loss = 3.90628
I0123 20:23:40.963373 29630 solver.cpp:253]     Train net output #0: loss = 3.90628 (* 1 = 3.90628 loss)
I0123 20:23:40.963392 29630 sgd_solver.cpp:106] Iteration 26300, lr = 0.01
I0123 20:23:48.243618 29630 solver.cpp:237] Iteration 26320, loss = 3.63792
I0123 20:23:48.243659 29630 solver.cpp:253]     Train net output #0: loss = 3.63792 (* 1 = 3.63792 loss)
I0123 20:23:48.243664 29630 sgd_solver.cpp:106] Iteration 26320, lr = 0.01
I0123 20:23:55.501525 29630 solver.cpp:237] Iteration 26340, loss = 3.77822
I0123 20:23:55.501569 29630 solver.cpp:253]     Train net output #0: loss = 3.77822 (* 1 = 3.77822 loss)
I0123 20:23:55.501575 29630 sgd_solver.cpp:106] Iteration 26340, lr = 0.01
I0123 20:24:02.798452 29630 solver.cpp:237] Iteration 26360, loss = 4.00788
I0123 20:24:02.798491 29630 solver.cpp:253]     Train net output #0: loss = 4.00788 (* 1 = 4.00788 loss)
I0123 20:24:02.798498 29630 sgd_solver.cpp:106] Iteration 26360, lr = 0.01
I0123 20:24:10.041971 29630 solver.cpp:237] Iteration 26380, loss = 3.93527
I0123 20:24:10.042009 29630 solver.cpp:253]     Train net output #0: loss = 3.93527 (* 1 = 3.93527 loss)
I0123 20:24:10.042016 29630 sgd_solver.cpp:106] Iteration 26380, lr = 0.01
I0123 20:24:17.355523 29630 solver.cpp:237] Iteration 26400, loss = 3.74428
I0123 20:24:17.355700 29630 solver.cpp:253]     Train net output #0: loss = 3.74428 (* 1 = 3.74428 loss)
I0123 20:24:17.355711 29630 sgd_solver.cpp:106] Iteration 26400, lr = 0.01
I0123 20:24:24.670639 29630 solver.cpp:237] Iteration 26420, loss = 3.8434
I0123 20:24:24.670677 29630 solver.cpp:253]     Train net output #0: loss = 3.8434 (* 1 = 3.8434 loss)
I0123 20:24:24.670683 29630 sgd_solver.cpp:106] Iteration 26420, lr = 0.01
I0123 20:24:31.966008 29630 solver.cpp:237] Iteration 26440, loss = 3.95943
I0123 20:24:31.966050 29630 solver.cpp:253]     Train net output #0: loss = 3.95943 (* 1 = 3.95943 loss)
I0123 20:24:31.966060 29630 sgd_solver.cpp:106] Iteration 26440, lr = 0.01
I0123 20:24:39.253013 29630 solver.cpp:237] Iteration 26460, loss = 3.95291
I0123 20:24:39.253052 29630 solver.cpp:253]     Train net output #0: loss = 3.95291 (* 1 = 3.95291 loss)
I0123 20:24:39.253059 29630 sgd_solver.cpp:106] Iteration 26460, lr = 0.01
I0123 20:24:46.557096 29630 solver.cpp:237] Iteration 26480, loss = 3.85308
I0123 20:24:46.557135 29630 solver.cpp:253]     Train net output #0: loss = 3.85308 (* 1 = 3.85308 loss)
I0123 20:24:46.557142 29630 sgd_solver.cpp:106] Iteration 26480, lr = 0.01
I0123 20:24:53.738862 29630 solver.cpp:237] Iteration 26500, loss = 3.49267
I0123 20:24:53.739044 29630 solver.cpp:253]     Train net output #0: loss = 3.49267 (* 1 = 3.49267 loss)
I0123 20:24:53.739053 29630 sgd_solver.cpp:106] Iteration 26500, lr = 0.01
I0123 20:25:01.047564 29630 solver.cpp:237] Iteration 26520, loss = 3.44315
I0123 20:25:01.047605 29630 solver.cpp:253]     Train net output #0: loss = 3.44315 (* 1 = 3.44315 loss)
I0123 20:25:01.047611 29630 sgd_solver.cpp:106] Iteration 26520, lr = 0.01
I0123 20:25:08.349433 29630 solver.cpp:237] Iteration 26540, loss = 4.01281
I0123 20:25:08.349472 29630 solver.cpp:253]     Train net output #0: loss = 4.01281 (* 1 = 4.01281 loss)
I0123 20:25:08.349478 29630 sgd_solver.cpp:106] Iteration 26540, lr = 0.01
I0123 20:25:15.598805 29630 solver.cpp:237] Iteration 26560, loss = 3.75356
I0123 20:25:15.598845 29630 solver.cpp:253]     Train net output #0: loss = 3.75356 (* 1 = 3.75356 loss)
I0123 20:25:15.598850 29630 sgd_solver.cpp:106] Iteration 26560, lr = 0.01
I0123 20:25:22.890957 29630 solver.cpp:237] Iteration 26580, loss = 3.72247
I0123 20:25:22.890996 29630 solver.cpp:253]     Train net output #0: loss = 3.72247 (* 1 = 3.72247 loss)
I0123 20:25:22.891003 29630 sgd_solver.cpp:106] Iteration 26580, lr = 0.01
I0123 20:25:30.125116 29630 solver.cpp:237] Iteration 26600, loss = 3.75614
I0123 20:25:30.125244 29630 solver.cpp:253]     Train net output #0: loss = 3.75614 (* 1 = 3.75614 loss)
I0123 20:25:30.125252 29630 sgd_solver.cpp:106] Iteration 26600, lr = 0.01
I0123 20:25:37.388553 29630 solver.cpp:237] Iteration 26620, loss = 3.76446
I0123 20:25:37.388593 29630 solver.cpp:253]     Train net output #0: loss = 3.76446 (* 1 = 3.76446 loss)
I0123 20:25:37.388599 29630 sgd_solver.cpp:106] Iteration 26620, lr = 0.01
I0123 20:25:44.662987 29630 solver.cpp:237] Iteration 26640, loss = 3.64459
I0123 20:25:44.663025 29630 solver.cpp:253]     Train net output #0: loss = 3.64459 (* 1 = 3.64459 loss)
I0123 20:25:44.663031 29630 sgd_solver.cpp:106] Iteration 26640, lr = 0.01
I0123 20:25:51.910054 29630 solver.cpp:237] Iteration 26660, loss = 3.89431
I0123 20:25:51.910125 29630 solver.cpp:253]     Train net output #0: loss = 3.89431 (* 1 = 3.89431 loss)
I0123 20:25:51.910133 29630 sgd_solver.cpp:106] Iteration 26660, lr = 0.01
I0123 20:25:59.214778 29630 solver.cpp:237] Iteration 26680, loss = 3.72065
I0123 20:25:59.214818 29630 solver.cpp:253]     Train net output #0: loss = 3.72065 (* 1 = 3.72065 loss)
I0123 20:25:59.214823 29630 sgd_solver.cpp:106] Iteration 26680, lr = 0.01
I0123 20:26:06.479883 29630 solver.cpp:237] Iteration 26700, loss = 3.7991
I0123 20:26:06.480018 29630 solver.cpp:253]     Train net output #0: loss = 3.7991 (* 1 = 3.7991 loss)
I0123 20:26:06.480036 29630 sgd_solver.cpp:106] Iteration 26700, lr = 0.01
I0123 20:26:13.761943 29630 solver.cpp:237] Iteration 26720, loss = 3.84412
I0123 20:26:13.761981 29630 solver.cpp:253]     Train net output #0: loss = 3.84412 (* 1 = 3.84412 loss)
I0123 20:26:13.761987 29630 sgd_solver.cpp:106] Iteration 26720, lr = 0.01
I0123 20:26:21.012665 29630 solver.cpp:237] Iteration 26740, loss = 3.71482
I0123 20:26:21.012703 29630 solver.cpp:253]     Train net output #0: loss = 3.71482 (* 1 = 3.71482 loss)
I0123 20:26:21.012709 29630 sgd_solver.cpp:106] Iteration 26740, lr = 0.01
I0123 20:26:28.272716 29630 solver.cpp:237] Iteration 26760, loss = 3.81303
I0123 20:26:28.272754 29630 solver.cpp:253]     Train net output #0: loss = 3.81303 (* 1 = 3.81303 loss)
I0123 20:26:28.272761 29630 sgd_solver.cpp:106] Iteration 26760, lr = 0.01
I0123 20:26:35.511893 29630 solver.cpp:237] Iteration 26780, loss = 3.94834
I0123 20:26:35.511931 29630 solver.cpp:253]     Train net output #0: loss = 3.94834 (* 1 = 3.94834 loss)
I0123 20:26:35.511937 29630 sgd_solver.cpp:106] Iteration 26780, lr = 0.01
I0123 20:26:42.778795 29630 solver.cpp:237] Iteration 26800, loss = 3.88134
I0123 20:26:42.778954 29630 solver.cpp:253]     Train net output #0: loss = 3.88134 (* 1 = 3.88134 loss)
I0123 20:26:42.778971 29630 sgd_solver.cpp:106] Iteration 26800, lr = 0.01
I0123 20:26:50.005234 29630 solver.cpp:237] Iteration 26820, loss = 3.96282
I0123 20:26:50.005267 29630 solver.cpp:253]     Train net output #0: loss = 3.96282 (* 1 = 3.96282 loss)
I0123 20:26:50.005275 29630 sgd_solver.cpp:106] Iteration 26820, lr = 0.01
I0123 20:26:57.290012 29630 solver.cpp:237] Iteration 26840, loss = 3.83909
I0123 20:26:57.290051 29630 solver.cpp:253]     Train net output #0: loss = 3.83909 (* 1 = 3.83909 loss)
I0123 20:26:57.290057 29630 sgd_solver.cpp:106] Iteration 26840, lr = 0.01
I0123 20:27:04.547140 29630 solver.cpp:237] Iteration 26860, loss = 3.73209
I0123 20:27:04.547178 29630 solver.cpp:253]     Train net output #0: loss = 3.73209 (* 1 = 3.73209 loss)
I0123 20:27:04.547184 29630 sgd_solver.cpp:106] Iteration 26860, lr = 0.01
I0123 20:27:11.764235 29630 solver.cpp:237] Iteration 26880, loss = 3.86067
I0123 20:27:11.764272 29630 solver.cpp:253]     Train net output #0: loss = 3.86067 (* 1 = 3.86067 loss)
I0123 20:27:11.764278 29630 sgd_solver.cpp:106] Iteration 26880, lr = 0.01
I0123 20:27:19.058900 29630 solver.cpp:237] Iteration 26900, loss = 3.58748
I0123 20:27:19.059068 29630 solver.cpp:253]     Train net output #0: loss = 3.58748 (* 1 = 3.58748 loss)
I0123 20:27:19.059077 29630 sgd_solver.cpp:106] Iteration 26900, lr = 0.01
I0123 20:27:26.332586 29630 solver.cpp:237] Iteration 26920, loss = 3.71015
I0123 20:27:26.332623 29630 solver.cpp:253]     Train net output #0: loss = 3.71015 (* 1 = 3.71015 loss)
I0123 20:27:26.332629 29630 sgd_solver.cpp:106] Iteration 26920, lr = 0.01
I0123 20:27:33.593932 29630 solver.cpp:237] Iteration 26940, loss = 3.59904
I0123 20:27:33.593971 29630 solver.cpp:253]     Train net output #0: loss = 3.59904 (* 1 = 3.59904 loss)
I0123 20:27:33.593976 29630 sgd_solver.cpp:106] Iteration 26940, lr = 0.01
I0123 20:27:40.883082 29630 solver.cpp:237] Iteration 26960, loss = 3.65203
I0123 20:27:40.883121 29630 solver.cpp:253]     Train net output #0: loss = 3.65203 (* 1 = 3.65203 loss)
I0123 20:27:40.883126 29630 sgd_solver.cpp:106] Iteration 26960, lr = 0.01
I0123 20:27:48.139175 29630 solver.cpp:237] Iteration 26980, loss = 3.61999
I0123 20:27:48.139214 29630 solver.cpp:253]     Train net output #0: loss = 3.61999 (* 1 = 3.61999 loss)
I0123 20:27:48.139220 29630 sgd_solver.cpp:106] Iteration 26980, lr = 0.01
I0123 20:27:55.158417 29630 solver.cpp:341] Iteration 27000, Testing net (#0)
I0123 20:28:06.910522 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 20:29:09.132249 29630 solver.cpp:409]     Test net output #0: accuracy = 0.25332
I0123 20:29:09.132377 29630 solver.cpp:409]     Test net output #1: loss = 3.65373 (* 1 = 3.65373 loss)
I0123 20:29:09.174057 29630 solver.cpp:237] Iteration 27000, loss = 3.76477
I0123 20:29:09.174095 29630 solver.cpp:253]     Train net output #0: loss = 3.76477 (* 1 = 3.76477 loss)
I0123 20:29:09.174103 29630 sgd_solver.cpp:106] Iteration 27000, lr = 0.01
I0123 20:29:15.716351 29630 solver.cpp:237] Iteration 27020, loss = 3.86516
I0123 20:29:15.716390 29630 solver.cpp:253]     Train net output #0: loss = 3.86516 (* 1 = 3.86516 loss)
I0123 20:29:15.716397 29630 sgd_solver.cpp:106] Iteration 27020, lr = 0.01
I0123 20:29:22.950490 29630 solver.cpp:237] Iteration 27040, loss = 3.59605
I0123 20:29:22.950530 29630 solver.cpp:253]     Train net output #0: loss = 3.59605 (* 1 = 3.59605 loss)
I0123 20:29:22.950536 29630 sgd_solver.cpp:106] Iteration 27040, lr = 0.01
I0123 20:29:30.201315 29630 solver.cpp:237] Iteration 27060, loss = 3.90839
I0123 20:29:30.201355 29630 solver.cpp:253]     Train net output #0: loss = 3.90839 (* 1 = 3.90839 loss)
I0123 20:29:30.201361 29630 sgd_solver.cpp:106] Iteration 27060, lr = 0.01
I0123 20:29:37.456095 29630 solver.cpp:237] Iteration 27080, loss = 4.07684
I0123 20:29:37.456135 29630 solver.cpp:253]     Train net output #0: loss = 4.07684 (* 1 = 4.07684 loss)
I0123 20:29:37.456140 29630 sgd_solver.cpp:106] Iteration 27080, lr = 0.01
I0123 20:29:44.680838 29630 solver.cpp:237] Iteration 27100, loss = 3.70224
I0123 20:29:44.680968 29630 solver.cpp:253]     Train net output #0: loss = 3.70224 (* 1 = 3.70224 loss)
I0123 20:29:44.680975 29630 sgd_solver.cpp:106] Iteration 27100, lr = 0.01
I0123 20:29:51.909299 29630 solver.cpp:237] Iteration 27120, loss = 3.84134
I0123 20:29:51.909340 29630 solver.cpp:253]     Train net output #0: loss = 3.84134 (* 1 = 3.84134 loss)
I0123 20:29:51.909346 29630 sgd_solver.cpp:106] Iteration 27120, lr = 0.01
I0123 20:29:59.150250 29630 solver.cpp:237] Iteration 27140, loss = 3.65464
I0123 20:29:59.150288 29630 solver.cpp:253]     Train net output #0: loss = 3.65464 (* 1 = 3.65464 loss)
I0123 20:29:59.150295 29630 sgd_solver.cpp:106] Iteration 27140, lr = 0.01
I0123 20:30:06.451910 29630 solver.cpp:237] Iteration 27160, loss = 3.71023
I0123 20:30:06.451949 29630 solver.cpp:253]     Train net output #0: loss = 3.71023 (* 1 = 3.71023 loss)
I0123 20:30:06.451956 29630 sgd_solver.cpp:106] Iteration 27160, lr = 0.01
I0123 20:30:07.607942 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 20:30:13.717972 29630 solver.cpp:237] Iteration 27180, loss = 3.72049
I0123 20:30:13.718022 29630 solver.cpp:253]     Train net output #0: loss = 3.72049 (* 1 = 3.72049 loss)
I0123 20:30:13.718029 29630 sgd_solver.cpp:106] Iteration 27180, lr = 0.01
I0123 20:30:20.961688 29630 solver.cpp:237] Iteration 27200, loss = 3.82621
I0123 20:30:20.961819 29630 solver.cpp:253]     Train net output #0: loss = 3.82621 (* 1 = 3.82621 loss)
I0123 20:30:20.961827 29630 sgd_solver.cpp:106] Iteration 27200, lr = 0.01
I0123 20:30:28.177011 29630 solver.cpp:237] Iteration 27220, loss = 3.91652
I0123 20:30:28.177050 29630 solver.cpp:253]     Train net output #0: loss = 3.91652 (* 1 = 3.91652 loss)
I0123 20:30:28.177057 29630 sgd_solver.cpp:106] Iteration 27220, lr = 0.01
I0123 20:30:35.454380 29630 solver.cpp:237] Iteration 27240, loss = 3.90681
I0123 20:30:35.454418 29630 solver.cpp:253]     Train net output #0: loss = 3.90681 (* 1 = 3.90681 loss)
I0123 20:30:35.454424 29630 sgd_solver.cpp:106] Iteration 27240, lr = 0.01
I0123 20:30:42.710324 29630 solver.cpp:237] Iteration 27260, loss = 3.8114
I0123 20:30:42.710362 29630 solver.cpp:253]     Train net output #0: loss = 3.8114 (* 1 = 3.8114 loss)
I0123 20:30:42.710367 29630 sgd_solver.cpp:106] Iteration 27260, lr = 0.01
I0123 20:30:50.013152 29630 solver.cpp:237] Iteration 27280, loss = 3.72348
I0123 20:30:50.013191 29630 solver.cpp:253]     Train net output #0: loss = 3.72348 (* 1 = 3.72348 loss)
I0123 20:30:50.013197 29630 sgd_solver.cpp:106] Iteration 27280, lr = 0.01
I0123 20:30:57.231914 29630 solver.cpp:237] Iteration 27300, loss = 3.94281
I0123 20:30:57.232067 29630 solver.cpp:253]     Train net output #0: loss = 3.94281 (* 1 = 3.94281 loss)
I0123 20:30:57.232076 29630 sgd_solver.cpp:106] Iteration 27300, lr = 0.01
I0123 20:31:04.499557 29630 solver.cpp:237] Iteration 27320, loss = 3.63842
I0123 20:31:04.499596 29630 solver.cpp:253]     Train net output #0: loss = 3.63842 (* 1 = 3.63842 loss)
I0123 20:31:04.499603 29630 sgd_solver.cpp:106] Iteration 27320, lr = 0.01
I0123 20:31:11.779655 29630 solver.cpp:237] Iteration 27340, loss = 3.88123
I0123 20:31:11.779693 29630 solver.cpp:253]     Train net output #0: loss = 3.88123 (* 1 = 3.88123 loss)
I0123 20:31:11.779700 29630 sgd_solver.cpp:106] Iteration 27340, lr = 0.01
I0123 20:31:19.143900 29630 solver.cpp:237] Iteration 27360, loss = 3.76046
I0123 20:31:19.143939 29630 solver.cpp:253]     Train net output #0: loss = 3.76046 (* 1 = 3.76046 loss)
I0123 20:31:19.143944 29630 sgd_solver.cpp:106] Iteration 27360, lr = 0.01
I0123 20:31:26.388033 29630 solver.cpp:237] Iteration 27380, loss = 3.84342
I0123 20:31:26.388074 29630 solver.cpp:253]     Train net output #0: loss = 3.84342 (* 1 = 3.84342 loss)
I0123 20:31:26.388080 29630 sgd_solver.cpp:106] Iteration 27380, lr = 0.01
I0123 20:31:33.653271 29630 solver.cpp:237] Iteration 27400, loss = 3.56855
I0123 20:31:33.653446 29630 solver.cpp:253]     Train net output #0: loss = 3.56855 (* 1 = 3.56855 loss)
I0123 20:31:33.653456 29630 sgd_solver.cpp:106] Iteration 27400, lr = 0.01
I0123 20:31:40.909564 29630 solver.cpp:237] Iteration 27420, loss = 3.9159
I0123 20:31:40.909612 29630 solver.cpp:253]     Train net output #0: loss = 3.9159 (* 1 = 3.9159 loss)
I0123 20:31:40.909620 29630 sgd_solver.cpp:106] Iteration 27420, lr = 0.01
I0123 20:31:48.192081 29630 solver.cpp:237] Iteration 27440, loss = 3.65005
I0123 20:31:48.192119 29630 solver.cpp:253]     Train net output #0: loss = 3.65005 (* 1 = 3.65005 loss)
I0123 20:31:48.192126 29630 sgd_solver.cpp:106] Iteration 27440, lr = 0.01
I0123 20:31:55.467391 29630 solver.cpp:237] Iteration 27460, loss = 3.78739
I0123 20:31:55.467430 29630 solver.cpp:253]     Train net output #0: loss = 3.78739 (* 1 = 3.78739 loss)
I0123 20:31:55.467437 29630 sgd_solver.cpp:106] Iteration 27460, lr = 0.01
I0123 20:32:02.773576 29630 solver.cpp:237] Iteration 27480, loss = 3.44836
I0123 20:32:02.773613 29630 solver.cpp:253]     Train net output #0: loss = 3.44836 (* 1 = 3.44836 loss)
I0123 20:32:02.773620 29630 sgd_solver.cpp:106] Iteration 27480, lr = 0.01
I0123 20:32:10.035095 29630 solver.cpp:237] Iteration 27500, loss = 3.76632
I0123 20:32:10.035243 29630 solver.cpp:253]     Train net output #0: loss = 3.76632 (* 1 = 3.76632 loss)
I0123 20:32:10.035260 29630 sgd_solver.cpp:106] Iteration 27500, lr = 0.01
I0123 20:32:17.318497 29630 solver.cpp:237] Iteration 27520, loss = 3.50046
I0123 20:32:17.318536 29630 solver.cpp:253]     Train net output #0: loss = 3.50046 (* 1 = 3.50046 loss)
I0123 20:32:17.318542 29630 sgd_solver.cpp:106] Iteration 27520, lr = 0.01
I0123 20:32:24.612715 29630 solver.cpp:237] Iteration 27540, loss = 3.8658
I0123 20:32:24.612753 29630 solver.cpp:253]     Train net output #0: loss = 3.8658 (* 1 = 3.8658 loss)
I0123 20:32:24.612761 29630 sgd_solver.cpp:106] Iteration 27540, lr = 0.01
I0123 20:32:31.883249 29630 solver.cpp:237] Iteration 27560, loss = 3.65873
I0123 20:32:31.883286 29630 solver.cpp:253]     Train net output #0: loss = 3.65873 (* 1 = 3.65873 loss)
I0123 20:32:31.883292 29630 sgd_solver.cpp:106] Iteration 27560, lr = 0.01
I0123 20:32:39.163022 29630 solver.cpp:237] Iteration 27580, loss = 3.79361
I0123 20:32:39.163060 29630 solver.cpp:253]     Train net output #0: loss = 3.79361 (* 1 = 3.79361 loss)
I0123 20:32:39.163067 29630 sgd_solver.cpp:106] Iteration 27580, lr = 0.01
I0123 20:32:46.414160 29630 solver.cpp:237] Iteration 27600, loss = 3.64688
I0123 20:32:46.414280 29630 solver.cpp:253]     Train net output #0: loss = 3.64688 (* 1 = 3.64688 loss)
I0123 20:32:46.414286 29630 sgd_solver.cpp:106] Iteration 27600, lr = 0.01
I0123 20:32:53.683246 29630 solver.cpp:237] Iteration 27620, loss = 3.7482
I0123 20:32:53.683285 29630 solver.cpp:253]     Train net output #0: loss = 3.7482 (* 1 = 3.7482 loss)
I0123 20:32:53.683291 29630 sgd_solver.cpp:106] Iteration 27620, lr = 0.01
I0123 20:33:00.949234 29630 solver.cpp:237] Iteration 27640, loss = 3.94744
I0123 20:33:00.949272 29630 solver.cpp:253]     Train net output #0: loss = 3.94744 (* 1 = 3.94744 loss)
I0123 20:33:00.949278 29630 sgd_solver.cpp:106] Iteration 27640, lr = 0.01
I0123 20:33:08.193776 29630 solver.cpp:237] Iteration 27660, loss = 3.7819
I0123 20:33:08.193815 29630 solver.cpp:253]     Train net output #0: loss = 3.7819 (* 1 = 3.7819 loss)
I0123 20:33:08.193821 29630 sgd_solver.cpp:106] Iteration 27660, lr = 0.01
I0123 20:33:15.459535 29630 solver.cpp:237] Iteration 27680, loss = 3.81055
I0123 20:33:15.459571 29630 solver.cpp:253]     Train net output #0: loss = 3.81055 (* 1 = 3.81055 loss)
I0123 20:33:15.459578 29630 sgd_solver.cpp:106] Iteration 27680, lr = 0.01
I0123 20:33:22.690743 29630 solver.cpp:237] Iteration 27700, loss = 3.70684
I0123 20:33:22.690865 29630 solver.cpp:253]     Train net output #0: loss = 3.70684 (* 1 = 3.70684 loss)
I0123 20:33:22.690871 29630 sgd_solver.cpp:106] Iteration 27700, lr = 0.01
I0123 20:33:29.965041 29630 solver.cpp:237] Iteration 27720, loss = 3.94893
I0123 20:33:29.965078 29630 solver.cpp:253]     Train net output #0: loss = 3.94893 (* 1 = 3.94893 loss)
I0123 20:33:29.965085 29630 sgd_solver.cpp:106] Iteration 27720, lr = 0.01
I0123 20:33:37.175884 29630 solver.cpp:237] Iteration 27740, loss = 3.72962
I0123 20:33:37.175923 29630 solver.cpp:253]     Train net output #0: loss = 3.72962 (* 1 = 3.72962 loss)
I0123 20:33:37.175930 29630 sgd_solver.cpp:106] Iteration 27740, lr = 0.01
I0123 20:33:44.432834 29630 solver.cpp:237] Iteration 27760, loss = 3.73333
I0123 20:33:44.432873 29630 solver.cpp:253]     Train net output #0: loss = 3.73333 (* 1 = 3.73333 loss)
I0123 20:33:44.432878 29630 sgd_solver.cpp:106] Iteration 27760, lr = 0.01
I0123 20:33:51.719817 29630 solver.cpp:237] Iteration 27780, loss = 3.85102
I0123 20:33:51.719856 29630 solver.cpp:253]     Train net output #0: loss = 3.85102 (* 1 = 3.85102 loss)
I0123 20:33:51.719862 29630 sgd_solver.cpp:106] Iteration 27780, lr = 0.01
I0123 20:33:58.990984 29630 solver.cpp:237] Iteration 27800, loss = 3.80701
I0123 20:33:58.991128 29630 solver.cpp:253]     Train net output #0: loss = 3.80701 (* 1 = 3.80701 loss)
I0123 20:33:58.991144 29630 sgd_solver.cpp:106] Iteration 27800, lr = 0.01
I0123 20:34:06.264487 29630 solver.cpp:237] Iteration 27820, loss = 3.45952
I0123 20:34:06.264528 29630 solver.cpp:253]     Train net output #0: loss = 3.45952 (* 1 = 3.45952 loss)
I0123 20:34:06.264533 29630 sgd_solver.cpp:106] Iteration 27820, lr = 0.01
I0123 20:34:13.510563 29630 solver.cpp:237] Iteration 27840, loss = 3.65662
I0123 20:34:13.510601 29630 solver.cpp:253]     Train net output #0: loss = 3.65662 (* 1 = 3.65662 loss)
I0123 20:34:13.510607 29630 sgd_solver.cpp:106] Iteration 27840, lr = 0.01
I0123 20:34:20.790511 29630 solver.cpp:237] Iteration 27860, loss = 3.68359
I0123 20:34:20.790551 29630 solver.cpp:253]     Train net output #0: loss = 3.68359 (* 1 = 3.68359 loss)
I0123 20:34:20.790557 29630 sgd_solver.cpp:106] Iteration 27860, lr = 0.01
I0123 20:34:28.009754 29630 solver.cpp:237] Iteration 27880, loss = 3.88017
I0123 20:34:28.009793 29630 solver.cpp:253]     Train net output #0: loss = 3.88017 (* 1 = 3.88017 loss)
I0123 20:34:28.009799 29630 sgd_solver.cpp:106] Iteration 27880, lr = 0.01
I0123 20:34:35.304615 29630 solver.cpp:237] Iteration 27900, loss = 3.97364
I0123 20:34:35.304769 29630 solver.cpp:253]     Train net output #0: loss = 3.97364 (* 1 = 3.97364 loss)
I0123 20:34:35.304777 29630 sgd_solver.cpp:106] Iteration 27900, lr = 0.01
I0123 20:34:42.532588 29630 solver.cpp:237] Iteration 27920, loss = 3.65322
I0123 20:34:42.532625 29630 solver.cpp:253]     Train net output #0: loss = 3.65322 (* 1 = 3.65322 loss)
I0123 20:34:42.532631 29630 sgd_solver.cpp:106] Iteration 27920, lr = 0.01
I0123 20:34:49.783098 29630 solver.cpp:237] Iteration 27940, loss = 3.4842
I0123 20:34:49.783138 29630 solver.cpp:253]     Train net output #0: loss = 3.4842 (* 1 = 3.4842 loss)
I0123 20:34:49.783143 29630 sgd_solver.cpp:106] Iteration 27940, lr = 0.01
I0123 20:34:57.065973 29630 solver.cpp:237] Iteration 27960, loss = 3.69411
I0123 20:34:57.066025 29630 solver.cpp:253]     Train net output #0: loss = 3.69411 (* 1 = 3.69411 loss)
I0123 20:34:57.066032 29630 sgd_solver.cpp:106] Iteration 27960, lr = 0.01
I0123 20:35:04.312650 29630 solver.cpp:237] Iteration 27980, loss = 3.82877
I0123 20:35:04.312690 29630 solver.cpp:253]     Train net output #0: loss = 3.82877 (* 1 = 3.82877 loss)
I0123 20:35:04.312695 29630 sgd_solver.cpp:106] Iteration 27980, lr = 0.01
I0123 20:35:11.277452 29630 solver.cpp:341] Iteration 28000, Testing net (#0)
I0123 20:35:23.546084 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 20:36:25.461513 29630 solver.cpp:409]     Test net output #0: accuracy = 0.2625
I0123 20:36:25.461665 29630 solver.cpp:409]     Test net output #1: loss = 3.5899 (* 1 = 3.5899 loss)
I0123 20:36:25.502405 29630 solver.cpp:237] Iteration 28000, loss = 3.82682
I0123 20:36:25.502442 29630 solver.cpp:253]     Train net output #0: loss = 3.82682 (* 1 = 3.82682 loss)
I0123 20:36:25.502449 29630 sgd_solver.cpp:106] Iteration 28000, lr = 0.01
I0123 20:36:32.081886 29630 solver.cpp:237] Iteration 28020, loss = 3.81348
I0123 20:36:32.081923 29630 solver.cpp:253]     Train net output #0: loss = 3.81348 (* 1 = 3.81348 loss)
I0123 20:36:32.081929 29630 sgd_solver.cpp:106] Iteration 28020, lr = 0.01
I0123 20:36:39.360687 29630 solver.cpp:237] Iteration 28040, loss = 3.99982
I0123 20:36:39.360723 29630 solver.cpp:253]     Train net output #0: loss = 3.99982 (* 1 = 3.99982 loss)
I0123 20:36:39.360730 29630 sgd_solver.cpp:106] Iteration 28040, lr = 0.01
I0123 20:36:46.671356 29630 solver.cpp:237] Iteration 28060, loss = 3.77688
I0123 20:36:46.671394 29630 solver.cpp:253]     Train net output #0: loss = 3.77688 (* 1 = 3.77688 loss)
I0123 20:36:46.671401 29630 sgd_solver.cpp:106] Iteration 28060, lr = 0.01
I0123 20:36:53.916646 29630 solver.cpp:237] Iteration 28080, loss = 3.56949
I0123 20:36:53.916683 29630 solver.cpp:253]     Train net output #0: loss = 3.56949 (* 1 = 3.56949 loss)
I0123 20:36:53.916690 29630 sgd_solver.cpp:106] Iteration 28080, lr = 0.01
I0123 20:37:01.169275 29630 solver.cpp:237] Iteration 28100, loss = 3.74607
I0123 20:37:01.169404 29630 solver.cpp:253]     Train net output #0: loss = 3.74607 (* 1 = 3.74607 loss)
I0123 20:37:01.169410 29630 sgd_solver.cpp:106] Iteration 28100, lr = 0.01
I0123 20:37:08.436573 29630 solver.cpp:237] Iteration 28120, loss = 3.71126
I0123 20:37:08.436611 29630 solver.cpp:253]     Train net output #0: loss = 3.71126 (* 1 = 3.71126 loss)
I0123 20:37:08.436617 29630 sgd_solver.cpp:106] Iteration 28120, lr = 0.01
I0123 20:37:15.764801 29630 solver.cpp:237] Iteration 28140, loss = 3.37291
I0123 20:37:15.764839 29630 solver.cpp:253]     Train net output #0: loss = 3.37291 (* 1 = 3.37291 loss)
I0123 20:37:15.764845 29630 sgd_solver.cpp:106] Iteration 28140, lr = 0.01
I0123 20:37:23.018724 29630 solver.cpp:237] Iteration 28160, loss = 3.70324
I0123 20:37:23.018761 29630 solver.cpp:253]     Train net output #0: loss = 3.70324 (* 1 = 3.70324 loss)
I0123 20:37:23.018767 29630 sgd_solver.cpp:106] Iteration 28160, lr = 0.01
I0123 20:37:26.363867 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 20:37:30.284412 29630 solver.cpp:237] Iteration 28180, loss = 3.63542
I0123 20:37:30.284449 29630 solver.cpp:253]     Train net output #0: loss = 3.63542 (* 1 = 3.63542 loss)
I0123 20:37:30.284456 29630 sgd_solver.cpp:106] Iteration 28180, lr = 0.01
I0123 20:37:37.547886 29630 solver.cpp:237] Iteration 28200, loss = 3.76969
I0123 20:37:37.548013 29630 solver.cpp:253]     Train net output #0: loss = 3.76969 (* 1 = 3.76969 loss)
I0123 20:37:37.548030 29630 sgd_solver.cpp:106] Iteration 28200, lr = 0.01
I0123 20:37:44.783485 29630 solver.cpp:237] Iteration 28220, loss = 3.79707
I0123 20:37:44.783524 29630 solver.cpp:253]     Train net output #0: loss = 3.79707 (* 1 = 3.79707 loss)
I0123 20:37:44.783529 29630 sgd_solver.cpp:106] Iteration 28220, lr = 0.01
I0123 20:37:52.051354 29630 solver.cpp:237] Iteration 28240, loss = 4.10947
I0123 20:37:52.051393 29630 solver.cpp:253]     Train net output #0: loss = 4.10947 (* 1 = 4.10947 loss)
I0123 20:37:52.051399 29630 sgd_solver.cpp:106] Iteration 28240, lr = 0.01
I0123 20:37:59.270582 29630 solver.cpp:237] Iteration 28260, loss = 3.87734
I0123 20:37:59.270622 29630 solver.cpp:253]     Train net output #0: loss = 3.87734 (* 1 = 3.87734 loss)
I0123 20:37:59.270627 29630 sgd_solver.cpp:106] Iteration 28260, lr = 0.01
I0123 20:38:06.573441 29630 solver.cpp:237] Iteration 28280, loss = 3.83686
I0123 20:38:06.573478 29630 solver.cpp:253]     Train net output #0: loss = 3.83686 (* 1 = 3.83686 loss)
I0123 20:38:06.573485 29630 sgd_solver.cpp:106] Iteration 28280, lr = 0.01
I0123 20:38:13.810926 29630 solver.cpp:237] Iteration 28300, loss = 3.86538
I0123 20:38:13.811105 29630 solver.cpp:253]     Train net output #0: loss = 3.86538 (* 1 = 3.86538 loss)
I0123 20:38:13.811112 29630 sgd_solver.cpp:106] Iteration 28300, lr = 0.01
I0123 20:38:21.042364 29630 solver.cpp:237] Iteration 28320, loss = 3.65431
I0123 20:38:21.042404 29630 solver.cpp:253]     Train net output #0: loss = 3.65431 (* 1 = 3.65431 loss)
I0123 20:38:21.042410 29630 sgd_solver.cpp:106] Iteration 28320, lr = 0.01
I0123 20:38:28.262063 29630 solver.cpp:237] Iteration 28340, loss = 3.65711
I0123 20:38:28.262104 29630 solver.cpp:253]     Train net output #0: loss = 3.65711 (* 1 = 3.65711 loss)
I0123 20:38:28.262111 29630 sgd_solver.cpp:106] Iteration 28340, lr = 0.01
I0123 20:38:35.490275 29630 solver.cpp:237] Iteration 28360, loss = 3.93238
I0123 20:38:35.490332 29630 solver.cpp:253]     Train net output #0: loss = 3.93238 (* 1 = 3.93238 loss)
I0123 20:38:35.490339 29630 sgd_solver.cpp:106] Iteration 28360, lr = 0.01
I0123 20:38:42.763031 29630 solver.cpp:237] Iteration 28380, loss = 3.62903
I0123 20:38:42.763067 29630 solver.cpp:253]     Train net output #0: loss = 3.62903 (* 1 = 3.62903 loss)
I0123 20:38:42.763073 29630 sgd_solver.cpp:106] Iteration 28380, lr = 0.01
I0123 20:38:50.019775 29630 solver.cpp:237] Iteration 28400, loss = 3.57083
I0123 20:38:50.019902 29630 solver.cpp:253]     Train net output #0: loss = 3.57083 (* 1 = 3.57083 loss)
I0123 20:38:50.019918 29630 sgd_solver.cpp:106] Iteration 28400, lr = 0.01
I0123 20:38:57.281380 29630 solver.cpp:237] Iteration 28420, loss = 3.81895
I0123 20:38:57.281419 29630 solver.cpp:253]     Train net output #0: loss = 3.81895 (* 1 = 3.81895 loss)
I0123 20:38:57.281425 29630 sgd_solver.cpp:106] Iteration 28420, lr = 0.01
I0123 20:39:04.503398 29630 solver.cpp:237] Iteration 28440, loss = 3.88756
I0123 20:39:04.503440 29630 solver.cpp:253]     Train net output #0: loss = 3.88756 (* 1 = 3.88756 loss)
I0123 20:39:04.503458 29630 sgd_solver.cpp:106] Iteration 28440, lr = 0.01
I0123 20:39:11.730989 29630 solver.cpp:237] Iteration 28460, loss = 3.8566
I0123 20:39:11.731027 29630 solver.cpp:253]     Train net output #0: loss = 3.8566 (* 1 = 3.8566 loss)
I0123 20:39:11.731034 29630 sgd_solver.cpp:106] Iteration 28460, lr = 0.01
I0123 20:39:19.023404 29630 solver.cpp:237] Iteration 28480, loss = 3.63916
I0123 20:39:19.023442 29630 solver.cpp:253]     Train net output #0: loss = 3.63916 (* 1 = 3.63916 loss)
I0123 20:39:19.023449 29630 sgd_solver.cpp:106] Iteration 28480, lr = 0.01
I0123 20:39:26.288384 29630 solver.cpp:237] Iteration 28500, loss = 3.77619
I0123 20:39:26.288547 29630 solver.cpp:253]     Train net output #0: loss = 3.77619 (* 1 = 3.77619 loss)
I0123 20:39:26.288554 29630 sgd_solver.cpp:106] Iteration 28500, lr = 0.01
I0123 20:39:33.559948 29630 solver.cpp:237] Iteration 28520, loss = 3.63958
I0123 20:39:33.559986 29630 solver.cpp:253]     Train net output #0: loss = 3.63958 (* 1 = 3.63958 loss)
I0123 20:39:33.559993 29630 sgd_solver.cpp:106] Iteration 28520, lr = 0.01
I0123 20:39:40.805344 29630 solver.cpp:237] Iteration 28540, loss = 3.8276
I0123 20:39:40.805382 29630 solver.cpp:253]     Train net output #0: loss = 3.8276 (* 1 = 3.8276 loss)
I0123 20:39:40.805388 29630 sgd_solver.cpp:106] Iteration 28540, lr = 0.01
I0123 20:39:48.087456 29630 solver.cpp:237] Iteration 28560, loss = 3.6427
I0123 20:39:48.087496 29630 solver.cpp:253]     Train net output #0: loss = 3.6427 (* 1 = 3.6427 loss)
I0123 20:39:48.087502 29630 sgd_solver.cpp:106] Iteration 28560, lr = 0.01
I0123 20:39:55.364382 29630 solver.cpp:237] Iteration 28580, loss = 3.84619
I0123 20:39:55.364428 29630 solver.cpp:253]     Train net output #0: loss = 3.84619 (* 1 = 3.84619 loss)
I0123 20:39:55.364434 29630 sgd_solver.cpp:106] Iteration 28580, lr = 0.01
I0123 20:40:02.612900 29630 solver.cpp:237] Iteration 28600, loss = 3.93682
I0123 20:40:02.612994 29630 solver.cpp:253]     Train net output #0: loss = 3.93682 (* 1 = 3.93682 loss)
I0123 20:40:02.613003 29630 sgd_solver.cpp:106] Iteration 28600, lr = 0.01
I0123 20:40:09.920019 29630 solver.cpp:237] Iteration 28620, loss = 3.74281
I0123 20:40:09.920058 29630 solver.cpp:253]     Train net output #0: loss = 3.74281 (* 1 = 3.74281 loss)
I0123 20:40:09.920064 29630 sgd_solver.cpp:106] Iteration 28620, lr = 0.01
I0123 20:40:17.226215 29630 solver.cpp:237] Iteration 28640, loss = 3.68724
I0123 20:40:17.226254 29630 solver.cpp:253]     Train net output #0: loss = 3.68724 (* 1 = 3.68724 loss)
I0123 20:40:17.226260 29630 sgd_solver.cpp:106] Iteration 28640, lr = 0.01
I0123 20:40:24.515146 29630 solver.cpp:237] Iteration 28660, loss = 3.85615
I0123 20:40:24.515184 29630 solver.cpp:253]     Train net output #0: loss = 3.85615 (* 1 = 3.85615 loss)
I0123 20:40:24.515192 29630 sgd_solver.cpp:106] Iteration 28660, lr = 0.01
I0123 20:40:31.760195 29630 solver.cpp:237] Iteration 28680, loss = 3.5406
I0123 20:40:31.760234 29630 solver.cpp:253]     Train net output #0: loss = 3.5406 (* 1 = 3.5406 loss)
I0123 20:40:31.760241 29630 sgd_solver.cpp:106] Iteration 28680, lr = 0.01
I0123 20:40:39.031424 29630 solver.cpp:237] Iteration 28700, loss = 3.77874
I0123 20:40:39.031671 29630 solver.cpp:253]     Train net output #0: loss = 3.77874 (* 1 = 3.77874 loss)
I0123 20:40:39.031693 29630 sgd_solver.cpp:106] Iteration 28700, lr = 0.01
I0123 20:40:46.307854 29630 solver.cpp:237] Iteration 28720, loss = 3.75781
I0123 20:40:46.307893 29630 solver.cpp:253]     Train net output #0: loss = 3.75781 (* 1 = 3.75781 loss)
I0123 20:40:46.307898 29630 sgd_solver.cpp:106] Iteration 28720, lr = 0.01
I0123 20:40:53.564201 29630 solver.cpp:237] Iteration 28740, loss = 3.67807
I0123 20:40:53.564240 29630 solver.cpp:253]     Train net output #0: loss = 3.67807 (* 1 = 3.67807 loss)
I0123 20:40:53.564246 29630 sgd_solver.cpp:106] Iteration 28740, lr = 0.01
I0123 20:41:00.848520 29630 solver.cpp:237] Iteration 28760, loss = 3.66505
I0123 20:41:00.848557 29630 solver.cpp:253]     Train net output #0: loss = 3.66505 (* 1 = 3.66505 loss)
I0123 20:41:00.848564 29630 sgd_solver.cpp:106] Iteration 28760, lr = 0.01
I0123 20:41:08.097455 29630 solver.cpp:237] Iteration 28780, loss = 3.72152
I0123 20:41:08.097493 29630 solver.cpp:253]     Train net output #0: loss = 3.72152 (* 1 = 3.72152 loss)
I0123 20:41:08.097499 29630 sgd_solver.cpp:106] Iteration 28780, lr = 0.01
I0123 20:41:15.380393 29630 solver.cpp:237] Iteration 28800, loss = 3.87547
I0123 20:41:15.380501 29630 solver.cpp:253]     Train net output #0: loss = 3.87547 (* 1 = 3.87547 loss)
I0123 20:41:15.380518 29630 sgd_solver.cpp:106] Iteration 28800, lr = 0.01
I0123 20:41:22.683424 29630 solver.cpp:237] Iteration 28820, loss = 3.39013
I0123 20:41:22.683462 29630 solver.cpp:253]     Train net output #0: loss = 3.39013 (* 1 = 3.39013 loss)
I0123 20:41:22.683468 29630 sgd_solver.cpp:106] Iteration 28820, lr = 0.01
I0123 20:41:29.986474 29630 solver.cpp:237] Iteration 28840, loss = 4.05083
I0123 20:41:29.986511 29630 solver.cpp:253]     Train net output #0: loss = 4.05083 (* 1 = 4.05083 loss)
I0123 20:41:29.986517 29630 sgd_solver.cpp:106] Iteration 28840, lr = 0.01
I0123 20:41:37.210460 29630 solver.cpp:237] Iteration 28860, loss = 3.67952
I0123 20:41:37.210499 29630 solver.cpp:253]     Train net output #0: loss = 3.67952 (* 1 = 3.67952 loss)
I0123 20:41:37.210505 29630 sgd_solver.cpp:106] Iteration 28860, lr = 0.01
I0123 20:41:44.488268 29630 solver.cpp:237] Iteration 28880, loss = 3.62848
I0123 20:41:44.488306 29630 solver.cpp:253]     Train net output #0: loss = 3.62848 (* 1 = 3.62848 loss)
I0123 20:41:44.488313 29630 sgd_solver.cpp:106] Iteration 28880, lr = 0.01
I0123 20:41:51.770372 29630 solver.cpp:237] Iteration 28900, loss = 3.40575
I0123 20:41:51.770532 29630 solver.cpp:253]     Train net output #0: loss = 3.40575 (* 1 = 3.40575 loss)
I0123 20:41:51.770540 29630 sgd_solver.cpp:106] Iteration 28900, lr = 0.01
I0123 20:41:59.020867 29630 solver.cpp:237] Iteration 28920, loss = 3.7361
I0123 20:41:59.020905 29630 solver.cpp:253]     Train net output #0: loss = 3.7361 (* 1 = 3.7361 loss)
I0123 20:41:59.020911 29630 sgd_solver.cpp:106] Iteration 28920, lr = 0.01
I0123 20:42:06.274543 29630 solver.cpp:237] Iteration 28940, loss = 3.83265
I0123 20:42:06.274581 29630 solver.cpp:253]     Train net output #0: loss = 3.83265 (* 1 = 3.83265 loss)
I0123 20:42:06.274587 29630 sgd_solver.cpp:106] Iteration 28940, lr = 0.01
I0123 20:42:13.549049 29630 solver.cpp:237] Iteration 28960, loss = 3.86096
I0123 20:42:13.549088 29630 solver.cpp:253]     Train net output #0: loss = 3.86096 (* 1 = 3.86096 loss)
I0123 20:42:13.549094 29630 sgd_solver.cpp:106] Iteration 28960, lr = 0.01
I0123 20:42:20.848208 29630 solver.cpp:237] Iteration 28980, loss = 3.70004
I0123 20:42:20.848248 29630 solver.cpp:253]     Train net output #0: loss = 3.70004 (* 1 = 3.70004 loss)
I0123 20:42:20.848255 29630 sgd_solver.cpp:106] Iteration 28980, lr = 0.01
I0123 20:42:27.825417 29630 solver.cpp:341] Iteration 29000, Testing net (#0)
I0123 20:42:40.439756 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 20:43:41.550709 29630 solver.cpp:409]     Test net output #0: accuracy = 0.26588
I0123 20:43:41.550855 29630 solver.cpp:409]     Test net output #1: loss = 3.58363 (* 1 = 3.58363 loss)
I0123 20:43:41.591692 29630 solver.cpp:237] Iteration 29000, loss = 3.68866
I0123 20:43:41.591728 29630 solver.cpp:253]     Train net output #0: loss = 3.68866 (* 1 = 3.68866 loss)
I0123 20:43:41.591734 29630 sgd_solver.cpp:106] Iteration 29000, lr = 0.01
I0123 20:43:48.168982 29630 solver.cpp:237] Iteration 29020, loss = 3.8657
I0123 20:43:48.169019 29630 solver.cpp:253]     Train net output #0: loss = 3.8657 (* 1 = 3.8657 loss)
I0123 20:43:48.169025 29630 sgd_solver.cpp:106] Iteration 29020, lr = 0.01
I0123 20:43:55.489676 29630 solver.cpp:237] Iteration 29040, loss = 3.62589
I0123 20:43:55.489713 29630 solver.cpp:253]     Train net output #0: loss = 3.62589 (* 1 = 3.62589 loss)
I0123 20:43:55.489719 29630 sgd_solver.cpp:106] Iteration 29040, lr = 0.01
I0123 20:44:02.793676 29630 solver.cpp:237] Iteration 29060, loss = 3.53257
I0123 20:44:02.793714 29630 solver.cpp:253]     Train net output #0: loss = 3.53257 (* 1 = 3.53257 loss)
I0123 20:44:02.793720 29630 sgd_solver.cpp:106] Iteration 29060, lr = 0.01
I0123 20:44:10.106760 29630 solver.cpp:237] Iteration 29080, loss = 3.84179
I0123 20:44:10.106799 29630 solver.cpp:253]     Train net output #0: loss = 3.84179 (* 1 = 3.84179 loss)
I0123 20:44:10.106806 29630 sgd_solver.cpp:106] Iteration 29080, lr = 0.01
I0123 20:44:17.340801 29630 solver.cpp:237] Iteration 29100, loss = 3.8037
I0123 20:44:17.340956 29630 solver.cpp:253]     Train net output #0: loss = 3.8037 (* 1 = 3.8037 loss)
I0123 20:44:17.340973 29630 sgd_solver.cpp:106] Iteration 29100, lr = 0.01
I0123 20:44:24.640719 29630 solver.cpp:237] Iteration 29120, loss = 3.69754
I0123 20:44:24.640769 29630 solver.cpp:253]     Train net output #0: loss = 3.69754 (* 1 = 3.69754 loss)
I0123 20:44:24.640784 29630 sgd_solver.cpp:106] Iteration 29120, lr = 0.01
I0123 20:44:31.944577 29630 solver.cpp:237] Iteration 29140, loss = 3.70952
I0123 20:44:31.944615 29630 solver.cpp:253]     Train net output #0: loss = 3.70952 (* 1 = 3.70952 loss)
I0123 20:44:31.944622 29630 sgd_solver.cpp:106] Iteration 29140, lr = 0.01
I0123 20:44:39.257037 29630 solver.cpp:237] Iteration 29160, loss = 3.93978
I0123 20:44:39.257076 29630 solver.cpp:253]     Train net output #0: loss = 3.93978 (* 1 = 3.93978 loss)
I0123 20:44:39.257082 29630 sgd_solver.cpp:106] Iteration 29160, lr = 0.01
I0123 20:44:44.779397 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 20:44:46.533381 29630 solver.cpp:237] Iteration 29180, loss = 3.62315
I0123 20:44:46.533423 29630 solver.cpp:253]     Train net output #0: loss = 3.62315 (* 1 = 3.62315 loss)
I0123 20:44:46.533431 29630 sgd_solver.cpp:106] Iteration 29180, lr = 0.01
I0123 20:44:53.859845 29630 solver.cpp:237] Iteration 29200, loss = 3.56959
I0123 20:44:53.859994 29630 solver.cpp:253]     Train net output #0: loss = 3.56959 (* 1 = 3.56959 loss)
I0123 20:44:53.860003 29630 sgd_solver.cpp:106] Iteration 29200, lr = 0.01
I0123 20:45:01.204519 29630 solver.cpp:237] Iteration 29220, loss = 3.74469
I0123 20:45:01.204557 29630 solver.cpp:253]     Train net output #0: loss = 3.74469 (* 1 = 3.74469 loss)
I0123 20:45:01.204563 29630 sgd_solver.cpp:106] Iteration 29220, lr = 0.01
I0123 20:45:08.477809 29630 solver.cpp:237] Iteration 29240, loss = 3.64778
I0123 20:45:08.477846 29630 solver.cpp:253]     Train net output #0: loss = 3.64778 (* 1 = 3.64778 loss)
I0123 20:45:08.477852 29630 sgd_solver.cpp:106] Iteration 29240, lr = 0.01
I0123 20:45:15.785171 29630 solver.cpp:237] Iteration 29260, loss = 3.95234
I0123 20:45:15.785210 29630 solver.cpp:253]     Train net output #0: loss = 3.95234 (* 1 = 3.95234 loss)
I0123 20:45:15.785217 29630 sgd_solver.cpp:106] Iteration 29260, lr = 0.01
I0123 20:45:23.104863 29630 solver.cpp:237] Iteration 29280, loss = 3.97146
I0123 20:45:23.104902 29630 solver.cpp:253]     Train net output #0: loss = 3.97146 (* 1 = 3.97146 loss)
I0123 20:45:23.104907 29630 sgd_solver.cpp:106] Iteration 29280, lr = 0.01
I0123 20:45:30.342702 29630 solver.cpp:237] Iteration 29300, loss = 3.65231
I0123 20:45:30.342865 29630 solver.cpp:253]     Train net output #0: loss = 3.65231 (* 1 = 3.65231 loss)
I0123 20:45:30.342874 29630 sgd_solver.cpp:106] Iteration 29300, lr = 0.01
I0123 20:45:37.615993 29630 solver.cpp:237] Iteration 29320, loss = 3.78315
I0123 20:45:37.616031 29630 solver.cpp:253]     Train net output #0: loss = 3.78315 (* 1 = 3.78315 loss)
I0123 20:45:37.616039 29630 sgd_solver.cpp:106] Iteration 29320, lr = 0.01
I0123 20:45:44.850086 29630 solver.cpp:237] Iteration 29340, loss = 3.75265
I0123 20:45:44.850124 29630 solver.cpp:253]     Train net output #0: loss = 3.75265 (* 1 = 3.75265 loss)
I0123 20:45:44.850131 29630 sgd_solver.cpp:106] Iteration 29340, lr = 0.01
I0123 20:45:52.096122 29630 solver.cpp:237] Iteration 29360, loss = 3.69006
I0123 20:45:52.096161 29630 solver.cpp:253]     Train net output #0: loss = 3.69006 (* 1 = 3.69006 loss)
I0123 20:45:52.096168 29630 sgd_solver.cpp:106] Iteration 29360, lr = 0.01
I0123 20:45:59.361074 29630 solver.cpp:237] Iteration 29380, loss = 3.81799
I0123 20:45:59.361114 29630 solver.cpp:253]     Train net output #0: loss = 3.81799 (* 1 = 3.81799 loss)
I0123 20:45:59.361119 29630 sgd_solver.cpp:106] Iteration 29380, lr = 0.01
I0123 20:46:06.602300 29630 solver.cpp:237] Iteration 29400, loss = 3.29624
I0123 20:46:06.602418 29630 solver.cpp:253]     Train net output #0: loss = 3.29624 (* 1 = 3.29624 loss)
I0123 20:46:06.602426 29630 sgd_solver.cpp:106] Iteration 29400, lr = 0.01
I0123 20:46:13.896653 29630 solver.cpp:237] Iteration 29420, loss = 3.97723
I0123 20:46:13.896692 29630 solver.cpp:253]     Train net output #0: loss = 3.97723 (* 1 = 3.97723 loss)
I0123 20:46:13.896698 29630 sgd_solver.cpp:106] Iteration 29420, lr = 0.01
I0123 20:46:21.133291 29630 solver.cpp:237] Iteration 29440, loss = 3.64144
I0123 20:46:21.133328 29630 solver.cpp:253]     Train net output #0: loss = 3.64144 (* 1 = 3.64144 loss)
I0123 20:46:21.133335 29630 sgd_solver.cpp:106] Iteration 29440, lr = 0.01
I0123 20:46:28.377671 29630 solver.cpp:237] Iteration 29460, loss = 3.65831
I0123 20:46:28.377707 29630 solver.cpp:253]     Train net output #0: loss = 3.65831 (* 1 = 3.65831 loss)
I0123 20:46:28.377713 29630 sgd_solver.cpp:106] Iteration 29460, lr = 0.01
I0123 20:46:35.568183 29630 solver.cpp:237] Iteration 29480, loss = 4.07182
I0123 20:46:35.568222 29630 solver.cpp:253]     Train net output #0: loss = 4.07182 (* 1 = 4.07182 loss)
I0123 20:46:35.568228 29630 sgd_solver.cpp:106] Iteration 29480, lr = 0.01
I0123 20:46:42.818511 29630 solver.cpp:237] Iteration 29500, loss = 3.88127
I0123 20:46:42.818642 29630 solver.cpp:253]     Train net output #0: loss = 3.88127 (* 1 = 3.88127 loss)
I0123 20:46:42.818658 29630 sgd_solver.cpp:106] Iteration 29500, lr = 0.01
I0123 20:46:50.086443 29630 solver.cpp:237] Iteration 29520, loss = 3.87959
I0123 20:46:50.086483 29630 solver.cpp:253]     Train net output #0: loss = 3.87959 (* 1 = 3.87959 loss)
I0123 20:46:50.086488 29630 sgd_solver.cpp:106] Iteration 29520, lr = 0.01
I0123 20:46:57.321637 29630 solver.cpp:237] Iteration 29540, loss = 3.88704
I0123 20:46:57.321676 29630 solver.cpp:253]     Train net output #0: loss = 3.88704 (* 1 = 3.88704 loss)
I0123 20:46:57.321682 29630 sgd_solver.cpp:106] Iteration 29540, lr = 0.01
I0123 20:47:04.574077 29630 solver.cpp:237] Iteration 29560, loss = 3.69412
I0123 20:47:04.574116 29630 solver.cpp:253]     Train net output #0: loss = 3.69412 (* 1 = 3.69412 loss)
I0123 20:47:04.574122 29630 sgd_solver.cpp:106] Iteration 29560, lr = 0.01
I0123 20:47:11.803858 29630 solver.cpp:237] Iteration 29580, loss = 3.65358
I0123 20:47:11.803895 29630 solver.cpp:253]     Train net output #0: loss = 3.65358 (* 1 = 3.65358 loss)
I0123 20:47:11.803901 29630 sgd_solver.cpp:106] Iteration 29580, lr = 0.01
I0123 20:47:19.018205 29630 solver.cpp:237] Iteration 29600, loss = 3.63266
I0123 20:47:19.018385 29630 solver.cpp:253]     Train net output #0: loss = 3.63266 (* 1 = 3.63266 loss)
I0123 20:47:19.018404 29630 sgd_solver.cpp:106] Iteration 29600, lr = 0.01
I0123 20:47:26.267117 29630 solver.cpp:237] Iteration 29620, loss = 3.89673
I0123 20:47:26.267155 29630 solver.cpp:253]     Train net output #0: loss = 3.89673 (* 1 = 3.89673 loss)
I0123 20:47:26.267161 29630 sgd_solver.cpp:106] Iteration 29620, lr = 0.01
I0123 20:47:33.549254 29630 solver.cpp:237] Iteration 29640, loss = 3.57478
I0123 20:47:33.549291 29630 solver.cpp:253]     Train net output #0: loss = 3.57478 (* 1 = 3.57478 loss)
I0123 20:47:33.549298 29630 sgd_solver.cpp:106] Iteration 29640, lr = 0.01
I0123 20:47:40.796295 29630 solver.cpp:237] Iteration 29660, loss = 3.90957
I0123 20:47:40.796334 29630 solver.cpp:253]     Train net output #0: loss = 3.90957 (* 1 = 3.90957 loss)
I0123 20:47:40.796339 29630 sgd_solver.cpp:106] Iteration 29660, lr = 0.01
I0123 20:47:48.077419 29630 solver.cpp:237] Iteration 29680, loss = 3.72926
I0123 20:47:48.077456 29630 solver.cpp:253]     Train net output #0: loss = 3.72926 (* 1 = 3.72926 loss)
I0123 20:47:48.077462 29630 sgd_solver.cpp:106] Iteration 29680, lr = 0.01
I0123 20:47:55.340490 29630 solver.cpp:237] Iteration 29700, loss = 3.83059
I0123 20:47:55.340605 29630 solver.cpp:253]     Train net output #0: loss = 3.83059 (* 1 = 3.83059 loss)
I0123 20:47:55.340613 29630 sgd_solver.cpp:106] Iteration 29700, lr = 0.01
I0123 20:48:02.609310 29630 solver.cpp:237] Iteration 29720, loss = 3.66927
I0123 20:48:02.609349 29630 solver.cpp:253]     Train net output #0: loss = 3.66927 (* 1 = 3.66927 loss)
I0123 20:48:02.609355 29630 sgd_solver.cpp:106] Iteration 29720, lr = 0.01
I0123 20:48:09.890823 29630 solver.cpp:237] Iteration 29740, loss = 3.60313
I0123 20:48:09.890862 29630 solver.cpp:253]     Train net output #0: loss = 3.60313 (* 1 = 3.60313 loss)
I0123 20:48:09.890868 29630 sgd_solver.cpp:106] Iteration 29740, lr = 0.01
I0123 20:48:17.202551 29630 solver.cpp:237] Iteration 29760, loss = 3.64499
I0123 20:48:17.202589 29630 solver.cpp:253]     Train net output #0: loss = 3.64499 (* 1 = 3.64499 loss)
I0123 20:48:17.202595 29630 sgd_solver.cpp:106] Iteration 29760, lr = 0.01
I0123 20:48:24.516038 29630 solver.cpp:237] Iteration 29780, loss = 3.72917
I0123 20:48:24.516077 29630 solver.cpp:253]     Train net output #0: loss = 3.72917 (* 1 = 3.72917 loss)
I0123 20:48:24.516083 29630 sgd_solver.cpp:106] Iteration 29780, lr = 0.01
I0123 20:48:31.738025 29630 solver.cpp:237] Iteration 29800, loss = 3.63104
I0123 20:48:31.738199 29630 solver.cpp:253]     Train net output #0: loss = 3.63104 (* 1 = 3.63104 loss)
I0123 20:48:31.738207 29630 sgd_solver.cpp:106] Iteration 29800, lr = 0.01
I0123 20:48:39.064239 29630 solver.cpp:237] Iteration 29820, loss = 3.8578
I0123 20:48:39.064278 29630 solver.cpp:253]     Train net output #0: loss = 3.8578 (* 1 = 3.8578 loss)
I0123 20:48:39.064285 29630 sgd_solver.cpp:106] Iteration 29820, lr = 0.01
I0123 20:48:46.309424 29630 solver.cpp:237] Iteration 29840, loss = 3.47079
I0123 20:48:46.309464 29630 solver.cpp:253]     Train net output #0: loss = 3.47079 (* 1 = 3.47079 loss)
I0123 20:48:46.309471 29630 sgd_solver.cpp:106] Iteration 29840, lr = 0.01
I0123 20:48:53.526902 29630 solver.cpp:237] Iteration 29860, loss = 3.77412
I0123 20:48:53.526942 29630 solver.cpp:253]     Train net output #0: loss = 3.77412 (* 1 = 3.77412 loss)
I0123 20:48:53.526948 29630 sgd_solver.cpp:106] Iteration 29860, lr = 0.01
I0123 20:49:00.833394 29630 solver.cpp:237] Iteration 29880, loss = 3.84803
I0123 20:49:00.833432 29630 solver.cpp:253]     Train net output #0: loss = 3.84803 (* 1 = 3.84803 loss)
I0123 20:49:00.833439 29630 sgd_solver.cpp:106] Iteration 29880, lr = 0.01
I0123 20:49:08.130110 29630 solver.cpp:237] Iteration 29900, loss = 3.89589
I0123 20:49:08.130298 29630 solver.cpp:253]     Train net output #0: loss = 3.89589 (* 1 = 3.89589 loss)
I0123 20:49:08.130306 29630 sgd_solver.cpp:106] Iteration 29900, lr = 0.01
I0123 20:49:15.409574 29630 solver.cpp:237] Iteration 29920, loss = 3.80393
I0123 20:49:15.409611 29630 solver.cpp:253]     Train net output #0: loss = 3.80393 (* 1 = 3.80393 loss)
I0123 20:49:15.409616 29630 sgd_solver.cpp:106] Iteration 29920, lr = 0.01
I0123 20:49:22.720645 29630 solver.cpp:237] Iteration 29940, loss = 3.61818
I0123 20:49:22.720685 29630 solver.cpp:253]     Train net output #0: loss = 3.61818 (* 1 = 3.61818 loss)
I0123 20:49:22.720691 29630 sgd_solver.cpp:106] Iteration 29940, lr = 0.01
I0123 20:49:30.000843 29630 solver.cpp:237] Iteration 29960, loss = 3.80276
I0123 20:49:30.000880 29630 solver.cpp:253]     Train net output #0: loss = 3.80276 (* 1 = 3.80276 loss)
I0123 20:49:30.000886 29630 sgd_solver.cpp:106] Iteration 29960, lr = 0.01
I0123 20:49:37.280432 29630 solver.cpp:237] Iteration 29980, loss = 3.90027
I0123 20:49:37.280470 29630 solver.cpp:253]     Train net output #0: loss = 3.90027 (* 1 = 3.90027 loss)
I0123 20:49:37.280478 29630 sgd_solver.cpp:106] Iteration 29980, lr = 0.01
I0123 20:49:44.304383 29630 solver.cpp:459] Snapshotting to binary proto file snapshots/caffenet128_lsuv_ycrcb_iter_30000.caffemodel
I0123 20:49:44.466022 29630 sgd_solver.cpp:269] Snapshotting solver state to binary proto file snapshots/caffenet128_lsuv_ycrcb_iter_30000.solverstate
I0123 20:49:44.539360 29630 solver.cpp:341] Iteration 30000, Testing net (#0)
I0123 20:49:57.580571 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 20:50:58.751122 29630 solver.cpp:409]     Test net output #0: accuracy = 0.26668
I0123 20:50:58.751248 29630 solver.cpp:409]     Test net output #1: loss = 3.54821 (* 1 = 3.54821 loss)
I0123 20:50:58.791904 29630 solver.cpp:237] Iteration 30000, loss = 3.92428
I0123 20:50:58.791947 29630 solver.cpp:253]     Train net output #0: loss = 3.92428 (* 1 = 3.92428 loss)
I0123 20:50:58.791954 29630 sgd_solver.cpp:106] Iteration 30000, lr = 0.01
I0123 20:51:05.343128 29630 solver.cpp:237] Iteration 30020, loss = 3.62482
I0123 20:51:05.343168 29630 solver.cpp:253]     Train net output #0: loss = 3.62482 (* 1 = 3.62482 loss)
I0123 20:51:05.343173 29630 sgd_solver.cpp:106] Iteration 30020, lr = 0.01
I0123 20:51:12.635581 29630 solver.cpp:237] Iteration 30040, loss = 3.71101
I0123 20:51:12.635618 29630 solver.cpp:253]     Train net output #0: loss = 3.71101 (* 1 = 3.71101 loss)
I0123 20:51:12.635625 29630 sgd_solver.cpp:106] Iteration 30040, lr = 0.01
I0123 20:51:19.873628 29630 solver.cpp:237] Iteration 30060, loss = 3.75532
I0123 20:51:19.873667 29630 solver.cpp:253]     Train net output #0: loss = 3.75532 (* 1 = 3.75532 loss)
I0123 20:51:19.873672 29630 sgd_solver.cpp:106] Iteration 30060, lr = 0.01
I0123 20:51:27.119560 29630 solver.cpp:237] Iteration 30080, loss = 3.56558
I0123 20:51:27.119599 29630 solver.cpp:253]     Train net output #0: loss = 3.56558 (* 1 = 3.56558 loss)
I0123 20:51:27.119606 29630 sgd_solver.cpp:106] Iteration 30080, lr = 0.01
I0123 20:51:34.377605 29630 solver.cpp:237] Iteration 30100, loss = 3.66065
I0123 20:51:34.377738 29630 solver.cpp:253]     Train net output #0: loss = 3.66065 (* 1 = 3.66065 loss)
I0123 20:51:34.377746 29630 sgd_solver.cpp:106] Iteration 30100, lr = 0.01
I0123 20:51:41.664619 29630 solver.cpp:237] Iteration 30120, loss = 3.65938
I0123 20:51:41.664659 29630 solver.cpp:253]     Train net output #0: loss = 3.65938 (* 1 = 3.65938 loss)
I0123 20:51:41.664664 29630 sgd_solver.cpp:106] Iteration 30120, lr = 0.01
I0123 20:51:48.902740 29630 solver.cpp:237] Iteration 30140, loss = 3.86053
I0123 20:51:48.902778 29630 solver.cpp:253]     Train net output #0: loss = 3.86053 (* 1 = 3.86053 loss)
I0123 20:51:48.902784 29630 sgd_solver.cpp:106] Iteration 30140, lr = 0.01
I0123 20:51:56.175292 29630 solver.cpp:237] Iteration 30160, loss = 3.79814
I0123 20:51:56.175330 29630 solver.cpp:253]     Train net output #0: loss = 3.79814 (* 1 = 3.79814 loss)
I0123 20:51:56.175338 29630 sgd_solver.cpp:106] Iteration 30160, lr = 0.01
I0123 20:52:03.414672 29630 solver.cpp:237] Iteration 30180, loss = 3.4942
I0123 20:52:03.414710 29630 solver.cpp:253]     Train net output #0: loss = 3.4942 (* 1 = 3.4942 loss)
I0123 20:52:03.414717 29630 sgd_solver.cpp:106] Iteration 30180, lr = 0.01
I0123 20:52:03.841202 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 20:52:10.629220 29630 solver.cpp:237] Iteration 30200, loss = 3.47244
I0123 20:52:10.629391 29630 solver.cpp:253]     Train net output #0: loss = 3.47244 (* 1 = 3.47244 loss)
I0123 20:52:10.629400 29630 sgd_solver.cpp:106] Iteration 30200, lr = 0.01
I0123 20:52:17.954877 29630 solver.cpp:237] Iteration 30220, loss = 3.775
I0123 20:52:17.954921 29630 solver.cpp:253]     Train net output #0: loss = 3.775 (* 1 = 3.775 loss)
I0123 20:52:17.954937 29630 sgd_solver.cpp:106] Iteration 30220, lr = 0.01
I0123 20:52:25.262878 29630 solver.cpp:237] Iteration 30240, loss = 3.8567
I0123 20:52:25.262917 29630 solver.cpp:253]     Train net output #0: loss = 3.8567 (* 1 = 3.8567 loss)
I0123 20:52:25.262923 29630 sgd_solver.cpp:106] Iteration 30240, lr = 0.01
I0123 20:52:32.554020 29630 solver.cpp:237] Iteration 30260, loss = 3.84606
I0123 20:52:32.554069 29630 solver.cpp:253]     Train net output #0: loss = 3.84606 (* 1 = 3.84606 loss)
I0123 20:52:32.554083 29630 sgd_solver.cpp:106] Iteration 30260, lr = 0.01
I0123 20:52:39.891207 29630 solver.cpp:237] Iteration 30280, loss = 3.74887
I0123 20:52:39.891247 29630 solver.cpp:253]     Train net output #0: loss = 3.74887 (* 1 = 3.74887 loss)
I0123 20:52:39.891253 29630 sgd_solver.cpp:106] Iteration 30280, lr = 0.01
I0123 20:52:47.168138 29630 solver.cpp:237] Iteration 30300, loss = 3.72457
I0123 20:52:47.168292 29630 solver.cpp:253]     Train net output #0: loss = 3.72457 (* 1 = 3.72457 loss)
I0123 20:52:47.168299 29630 sgd_solver.cpp:106] Iteration 30300, lr = 0.01
I0123 20:52:54.443478 29630 solver.cpp:237] Iteration 30320, loss = 3.36282
I0123 20:52:54.443516 29630 solver.cpp:253]     Train net output #0: loss = 3.36282 (* 1 = 3.36282 loss)
I0123 20:52:54.443521 29630 sgd_solver.cpp:106] Iteration 30320, lr = 0.01
I0123 20:53:01.704319 29630 solver.cpp:237] Iteration 30340, loss = 3.68416
I0123 20:53:01.704358 29630 solver.cpp:253]     Train net output #0: loss = 3.68416 (* 1 = 3.68416 loss)
I0123 20:53:01.704365 29630 sgd_solver.cpp:106] Iteration 30340, lr = 0.01
I0123 20:53:08.960577 29630 solver.cpp:237] Iteration 30360, loss = 3.91135
I0123 20:53:08.960615 29630 solver.cpp:253]     Train net output #0: loss = 3.91135 (* 1 = 3.91135 loss)
I0123 20:53:08.960621 29630 sgd_solver.cpp:106] Iteration 30360, lr = 0.01
I0123 20:53:16.228243 29630 solver.cpp:237] Iteration 30380, loss = 3.75013
I0123 20:53:16.228286 29630 solver.cpp:253]     Train net output #0: loss = 3.75013 (* 1 = 3.75013 loss)
I0123 20:53:16.228302 29630 sgd_solver.cpp:106] Iteration 30380, lr = 0.01
I0123 20:53:23.497730 29630 solver.cpp:237] Iteration 30400, loss = 3.9392
I0123 20:53:23.497892 29630 solver.cpp:253]     Train net output #0: loss = 3.9392 (* 1 = 3.9392 loss)
I0123 20:53:23.497900 29630 sgd_solver.cpp:106] Iteration 30400, lr = 0.01
I0123 20:53:30.758633 29630 solver.cpp:237] Iteration 30420, loss = 3.89132
I0123 20:53:30.758671 29630 solver.cpp:253]     Train net output #0: loss = 3.89132 (* 1 = 3.89132 loss)
I0123 20:53:30.758678 29630 sgd_solver.cpp:106] Iteration 30420, lr = 0.01
I0123 20:53:38.029453 29630 solver.cpp:237] Iteration 30440, loss = 3.87188
I0123 20:53:38.029482 29630 solver.cpp:253]     Train net output #0: loss = 3.87188 (* 1 = 3.87188 loss)
I0123 20:53:38.029489 29630 sgd_solver.cpp:106] Iteration 30440, lr = 0.01
I0123 20:53:45.338392 29630 solver.cpp:237] Iteration 30460, loss = 3.77111
I0123 20:53:45.338430 29630 solver.cpp:253]     Train net output #0: loss = 3.77111 (* 1 = 3.77111 loss)
I0123 20:53:45.338438 29630 sgd_solver.cpp:106] Iteration 30460, lr = 0.01
I0123 20:53:52.614125 29630 solver.cpp:237] Iteration 30480, loss = 3.94763
I0123 20:53:52.614162 29630 solver.cpp:253]     Train net output #0: loss = 3.94763 (* 1 = 3.94763 loss)
I0123 20:53:52.614168 29630 sgd_solver.cpp:106] Iteration 30480, lr = 0.01
I0123 20:53:59.884711 29630 solver.cpp:237] Iteration 30500, loss = 3.64256
I0123 20:53:59.884835 29630 solver.cpp:253]     Train net output #0: loss = 3.64256 (* 1 = 3.64256 loss)
I0123 20:53:59.884842 29630 sgd_solver.cpp:106] Iteration 30500, lr = 0.01
I0123 20:54:07.113549 29630 solver.cpp:237] Iteration 30520, loss = 3.58313
I0123 20:54:07.113596 29630 solver.cpp:253]     Train net output #0: loss = 3.58313 (* 1 = 3.58313 loss)
I0123 20:54:07.113602 29630 sgd_solver.cpp:106] Iteration 30520, lr = 0.01
I0123 20:54:14.381644 29630 solver.cpp:237] Iteration 30540, loss = 3.55466
I0123 20:54:14.381681 29630 solver.cpp:253]     Train net output #0: loss = 3.55466 (* 1 = 3.55466 loss)
I0123 20:54:14.381688 29630 sgd_solver.cpp:106] Iteration 30540, lr = 0.01
I0123 20:54:21.605671 29630 solver.cpp:237] Iteration 30560, loss = 3.75938
I0123 20:54:21.605710 29630 solver.cpp:253]     Train net output #0: loss = 3.75938 (* 1 = 3.75938 loss)
I0123 20:54:21.605715 29630 sgd_solver.cpp:106] Iteration 30560, lr = 0.01
I0123 20:54:28.893760 29630 solver.cpp:237] Iteration 30580, loss = 3.82343
I0123 20:54:28.893796 29630 solver.cpp:253]     Train net output #0: loss = 3.82343 (* 1 = 3.82343 loss)
I0123 20:54:28.893802 29630 sgd_solver.cpp:106] Iteration 30580, lr = 0.01
I0123 20:54:36.167767 29630 solver.cpp:237] Iteration 30600, loss = 3.77211
I0123 20:54:36.167881 29630 solver.cpp:253]     Train net output #0: loss = 3.77211 (* 1 = 3.77211 loss)
I0123 20:54:36.167888 29630 sgd_solver.cpp:106] Iteration 30600, lr = 0.01
I0123 20:54:43.387799 29630 solver.cpp:237] Iteration 30620, loss = 3.56315
I0123 20:54:43.387840 29630 solver.cpp:253]     Train net output #0: loss = 3.56315 (* 1 = 3.56315 loss)
I0123 20:54:43.387847 29630 sgd_solver.cpp:106] Iteration 30620, lr = 0.01
I0123 20:54:50.642316 29630 solver.cpp:237] Iteration 30640, loss = 3.71822
I0123 20:54:50.642355 29630 solver.cpp:253]     Train net output #0: loss = 3.71822 (* 1 = 3.71822 loss)
I0123 20:54:50.642361 29630 sgd_solver.cpp:106] Iteration 30640, lr = 0.01
I0123 20:54:57.895066 29630 solver.cpp:237] Iteration 30660, loss = 3.53422
I0123 20:54:57.895105 29630 solver.cpp:253]     Train net output #0: loss = 3.53422 (* 1 = 3.53422 loss)
I0123 20:54:57.895112 29630 sgd_solver.cpp:106] Iteration 30660, lr = 0.01
I0123 20:55:05.120106 29630 solver.cpp:237] Iteration 30680, loss = 3.5075
I0123 20:55:05.120146 29630 solver.cpp:253]     Train net output #0: loss = 3.5075 (* 1 = 3.5075 loss)
I0123 20:55:05.120151 29630 sgd_solver.cpp:106] Iteration 30680, lr = 0.01
I0123 20:55:12.378725 29630 solver.cpp:237] Iteration 30700, loss = 3.71344
I0123 20:55:12.378839 29630 solver.cpp:253]     Train net output #0: loss = 3.71344 (* 1 = 3.71344 loss)
I0123 20:55:12.378847 29630 sgd_solver.cpp:106] Iteration 30700, lr = 0.01
I0123 20:55:19.576661 29630 solver.cpp:237] Iteration 30720, loss = 3.69309
I0123 20:55:19.576702 29630 solver.cpp:253]     Train net output #0: loss = 3.69309 (* 1 = 3.69309 loss)
I0123 20:55:19.576709 29630 sgd_solver.cpp:106] Iteration 30720, lr = 0.01
I0123 20:55:26.835672 29630 solver.cpp:237] Iteration 30740, loss = 3.75492
I0123 20:55:26.835712 29630 solver.cpp:253]     Train net output #0: loss = 3.75492 (* 1 = 3.75492 loss)
I0123 20:55:26.835719 29630 sgd_solver.cpp:106] Iteration 30740, lr = 0.01
I0123 20:55:34.105036 29630 solver.cpp:237] Iteration 30760, loss = 3.74666
I0123 20:55:34.105073 29630 solver.cpp:253]     Train net output #0: loss = 3.74666 (* 1 = 3.74666 loss)
I0123 20:55:34.105079 29630 sgd_solver.cpp:106] Iteration 30760, lr = 0.01
I0123 20:55:41.372515 29630 solver.cpp:237] Iteration 30780, loss = 3.81373
I0123 20:55:41.372556 29630 solver.cpp:253]     Train net output #0: loss = 3.81373 (* 1 = 3.81373 loss)
I0123 20:55:41.372563 29630 sgd_solver.cpp:106] Iteration 30780, lr = 0.01
I0123 20:55:48.587290 29630 solver.cpp:237] Iteration 30800, loss = 3.74863
I0123 20:55:48.587461 29630 solver.cpp:253]     Train net output #0: loss = 3.74863 (* 1 = 3.74863 loss)
I0123 20:55:48.587471 29630 sgd_solver.cpp:106] Iteration 30800, lr = 0.01
I0123 20:55:55.780973 29630 solver.cpp:237] Iteration 30820, loss = 3.69279
I0123 20:55:55.781014 29630 solver.cpp:253]     Train net output #0: loss = 3.69279 (* 1 = 3.69279 loss)
I0123 20:55:55.781020 29630 sgd_solver.cpp:106] Iteration 30820, lr = 0.01
I0123 20:56:03.035280 29630 solver.cpp:237] Iteration 30840, loss = 3.69647
I0123 20:56:03.035318 29630 solver.cpp:253]     Train net output #0: loss = 3.69647 (* 1 = 3.69647 loss)
I0123 20:56:03.035326 29630 sgd_solver.cpp:106] Iteration 30840, lr = 0.01
I0123 20:56:10.312865 29630 solver.cpp:237] Iteration 30860, loss = 3.79511
I0123 20:56:10.312903 29630 solver.cpp:253]     Train net output #0: loss = 3.79511 (* 1 = 3.79511 loss)
I0123 20:56:10.312911 29630 sgd_solver.cpp:106] Iteration 30860, lr = 0.01
I0123 20:56:17.601341 29630 solver.cpp:237] Iteration 30880, loss = 3.74593
I0123 20:56:17.601382 29630 solver.cpp:253]     Train net output #0: loss = 3.74593 (* 1 = 3.74593 loss)
I0123 20:56:17.601388 29630 sgd_solver.cpp:106] Iteration 30880, lr = 0.01
I0123 20:56:24.862161 29630 solver.cpp:237] Iteration 30900, loss = 3.43435
I0123 20:56:24.862305 29630 solver.cpp:253]     Train net output #0: loss = 3.43435 (* 1 = 3.43435 loss)
I0123 20:56:24.862313 29630 sgd_solver.cpp:106] Iteration 30900, lr = 0.01
I0123 20:56:32.133766 29630 solver.cpp:237] Iteration 30920, loss = 3.75802
I0123 20:56:32.133805 29630 solver.cpp:253]     Train net output #0: loss = 3.75802 (* 1 = 3.75802 loss)
I0123 20:56:32.133810 29630 sgd_solver.cpp:106] Iteration 30920, lr = 0.01
I0123 20:56:39.362457 29630 solver.cpp:237] Iteration 30940, loss = 3.53012
I0123 20:56:39.362495 29630 solver.cpp:253]     Train net output #0: loss = 3.53012 (* 1 = 3.53012 loss)
I0123 20:56:39.362501 29630 sgd_solver.cpp:106] Iteration 30940, lr = 0.01
I0123 20:56:46.683611 29630 solver.cpp:237] Iteration 30960, loss = 3.64095
I0123 20:56:46.683650 29630 solver.cpp:253]     Train net output #0: loss = 3.64095 (* 1 = 3.64095 loss)
I0123 20:56:46.683655 29630 sgd_solver.cpp:106] Iteration 30960, lr = 0.01
I0123 20:56:53.962554 29630 solver.cpp:237] Iteration 30980, loss = 3.84801
I0123 20:56:53.962594 29630 solver.cpp:253]     Train net output #0: loss = 3.84801 (* 1 = 3.84801 loss)
I0123 20:56:53.962602 29630 sgd_solver.cpp:106] Iteration 30980, lr = 0.01
I0123 20:57:00.924067 29630 solver.cpp:341] Iteration 31000, Testing net (#0)
I0123 20:57:14.482131 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 20:58:14.658633 29630 solver.cpp:409]     Test net output #0: accuracy = 0.26548
I0123 20:58:14.658759 29630 solver.cpp:409]     Test net output #1: loss = 3.56898 (* 1 = 3.56898 loss)
I0123 20:58:14.699503 29630 solver.cpp:237] Iteration 31000, loss = 3.49907
I0123 20:58:14.699532 29630 solver.cpp:253]     Train net output #0: loss = 3.49907 (* 1 = 3.49907 loss)
I0123 20:58:14.699538 29630 sgd_solver.cpp:106] Iteration 31000, lr = 0.01
I0123 20:58:21.219449 29630 solver.cpp:237] Iteration 31020, loss = 3.568
I0123 20:58:21.219487 29630 solver.cpp:253]     Train net output #0: loss = 3.568 (* 1 = 3.568 loss)
I0123 20:58:21.219493 29630 sgd_solver.cpp:106] Iteration 31020, lr = 0.01
I0123 20:58:28.487292 29630 solver.cpp:237] Iteration 31040, loss = 3.68361
I0123 20:58:28.487330 29630 solver.cpp:253]     Train net output #0: loss = 3.68361 (* 1 = 3.68361 loss)
I0123 20:58:28.487336 29630 sgd_solver.cpp:106] Iteration 31040, lr = 0.01
I0123 20:58:35.703244 29630 solver.cpp:237] Iteration 31060, loss = 3.76173
I0123 20:58:35.703284 29630 solver.cpp:253]     Train net output #0: loss = 3.76173 (* 1 = 3.76173 loss)
I0123 20:58:35.703290 29630 sgd_solver.cpp:106] Iteration 31060, lr = 0.01
I0123 20:58:42.936892 29630 solver.cpp:237] Iteration 31080, loss = 3.62471
I0123 20:58:42.936930 29630 solver.cpp:253]     Train net output #0: loss = 3.62471 (* 1 = 3.62471 loss)
I0123 20:58:42.936936 29630 sgd_solver.cpp:106] Iteration 31080, lr = 0.01
I0123 20:58:50.184980 29630 solver.cpp:237] Iteration 31100, loss = 3.86526
I0123 20:58:50.185089 29630 solver.cpp:253]     Train net output #0: loss = 3.86526 (* 1 = 3.86526 loss)
I0123 20:58:50.185107 29630 sgd_solver.cpp:106] Iteration 31100, lr = 0.01
I0123 20:58:57.427657 29630 solver.cpp:237] Iteration 31120, loss = 3.90302
I0123 20:58:57.427721 29630 solver.cpp:253]     Train net output #0: loss = 3.90302 (* 1 = 3.90302 loss)
I0123 20:58:57.427736 29630 sgd_solver.cpp:106] Iteration 31120, lr = 0.01
I0123 20:59:04.703897 29630 solver.cpp:237] Iteration 31140, loss = 3.55495
I0123 20:59:04.703936 29630 solver.cpp:253]     Train net output #0: loss = 3.55495 (* 1 = 3.55495 loss)
I0123 20:59:04.703943 29630 sgd_solver.cpp:106] Iteration 31140, lr = 0.01
I0123 20:59:12.024646 29630 solver.cpp:237] Iteration 31160, loss = 3.52682
I0123 20:59:12.024693 29630 solver.cpp:253]     Train net output #0: loss = 3.52682 (* 1 = 3.52682 loss)
I0123 20:59:12.024698 29630 sgd_solver.cpp:106] Iteration 31160, lr = 0.01
I0123 20:59:19.288753 29630 solver.cpp:237] Iteration 31180, loss = 4.05564
I0123 20:59:19.288792 29630 solver.cpp:253]     Train net output #0: loss = 4.05564 (* 1 = 4.05564 loss)
I0123 20:59:19.288800 29630 sgd_solver.cpp:106] Iteration 31180, lr = 0.01
I0123 20:59:21.895774 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 20:59:26.518085 29630 solver.cpp:237] Iteration 31200, loss = 3.77654
I0123 20:59:26.518123 29630 solver.cpp:253]     Train net output #0: loss = 3.77654 (* 1 = 3.77654 loss)
I0123 20:59:26.518129 29630 sgd_solver.cpp:106] Iteration 31200, lr = 0.01
I0123 20:59:33.792062 29630 solver.cpp:237] Iteration 31220, loss = 3.76857
I0123 20:59:33.792101 29630 solver.cpp:253]     Train net output #0: loss = 3.76857 (* 1 = 3.76857 loss)
I0123 20:59:33.792107 29630 sgd_solver.cpp:106] Iteration 31220, lr = 0.01
I0123 20:59:41.017699 29630 solver.cpp:237] Iteration 31240, loss = 3.60425
I0123 20:59:41.017729 29630 solver.cpp:253]     Train net output #0: loss = 3.60425 (* 1 = 3.60425 loss)
I0123 20:59:41.017746 29630 sgd_solver.cpp:106] Iteration 31240, lr = 0.01
I0123 20:59:48.297991 29630 solver.cpp:237] Iteration 31260, loss = 3.81981
I0123 20:59:48.298029 29630 solver.cpp:253]     Train net output #0: loss = 3.81981 (* 1 = 3.81981 loss)
I0123 20:59:48.298037 29630 sgd_solver.cpp:106] Iteration 31260, lr = 0.01
I0123 20:59:55.562191 29630 solver.cpp:237] Iteration 31280, loss = 3.83914
I0123 20:59:55.562306 29630 solver.cpp:253]     Train net output #0: loss = 3.83914 (* 1 = 3.83914 loss)
I0123 20:59:55.562314 29630 sgd_solver.cpp:106] Iteration 31280, lr = 0.01
I0123 21:00:02.832576 29630 solver.cpp:237] Iteration 31300, loss = 3.96823
I0123 21:00:02.832697 29630 solver.cpp:253]     Train net output #0: loss = 3.96823 (* 1 = 3.96823 loss)
I0123 21:00:02.832736 29630 sgd_solver.cpp:106] Iteration 31300, lr = 0.01
I0123 21:00:10.074719 29630 solver.cpp:237] Iteration 31320, loss = 3.90651
I0123 21:00:10.074759 29630 solver.cpp:253]     Train net output #0: loss = 3.90651 (* 1 = 3.90651 loss)
I0123 21:00:10.074764 29630 sgd_solver.cpp:106] Iteration 31320, lr = 0.01
I0123 21:00:17.330727 29630 solver.cpp:237] Iteration 31340, loss = 3.77103
I0123 21:00:17.330766 29630 solver.cpp:253]     Train net output #0: loss = 3.77103 (* 1 = 3.77103 loss)
I0123 21:00:17.330773 29630 sgd_solver.cpp:106] Iteration 31340, lr = 0.01
I0123 21:00:24.615605 29630 solver.cpp:237] Iteration 31360, loss = 3.65648
I0123 21:00:24.615644 29630 solver.cpp:253]     Train net output #0: loss = 3.65648 (* 1 = 3.65648 loss)
I0123 21:00:24.615651 29630 sgd_solver.cpp:106] Iteration 31360, lr = 0.01
I0123 21:00:31.898340 29630 solver.cpp:237] Iteration 31380, loss = 3.52971
I0123 21:00:31.898511 29630 solver.cpp:253]     Train net output #0: loss = 3.52971 (* 1 = 3.52971 loss)
I0123 21:00:31.898520 29630 sgd_solver.cpp:106] Iteration 31380, lr = 0.01
I0123 21:00:39.173360 29630 solver.cpp:237] Iteration 31400, loss = 3.87816
I0123 21:00:39.173389 29630 solver.cpp:253]     Train net output #0: loss = 3.87816 (* 1 = 3.87816 loss)
I0123 21:00:39.173395 29630 sgd_solver.cpp:106] Iteration 31400, lr = 0.01
I0123 21:00:46.467331 29630 solver.cpp:237] Iteration 31420, loss = 3.79402
I0123 21:00:46.467371 29630 solver.cpp:253]     Train net output #0: loss = 3.79402 (* 1 = 3.79402 loss)
I0123 21:00:46.467377 29630 sgd_solver.cpp:106] Iteration 31420, lr = 0.01
I0123 21:00:53.728945 29630 solver.cpp:237] Iteration 31440, loss = 3.55475
I0123 21:00:53.728982 29630 solver.cpp:253]     Train net output #0: loss = 3.55475 (* 1 = 3.55475 loss)
I0123 21:00:53.728989 29630 sgd_solver.cpp:106] Iteration 31440, lr = 0.01
I0123 21:01:01.015965 29630 solver.cpp:237] Iteration 31460, loss = 3.88689
I0123 21:01:01.015995 29630 solver.cpp:253]     Train net output #0: loss = 3.88689 (* 1 = 3.88689 loss)
I0123 21:01:01.016000 29630 sgd_solver.cpp:106] Iteration 31460, lr = 0.01
I0123 21:01:08.327953 29630 solver.cpp:237] Iteration 31480, loss = 3.68242
I0123 21:01:08.328080 29630 solver.cpp:253]     Train net output #0: loss = 3.68242 (* 1 = 3.68242 loss)
I0123 21:01:08.328088 29630 sgd_solver.cpp:106] Iteration 31480, lr = 0.01
I0123 21:01:15.564702 29630 solver.cpp:237] Iteration 31500, loss = 3.69931
I0123 21:01:15.564741 29630 solver.cpp:253]     Train net output #0: loss = 3.69931 (* 1 = 3.69931 loss)
I0123 21:01:15.564748 29630 sgd_solver.cpp:106] Iteration 31500, lr = 0.01
I0123 21:01:22.817649 29630 solver.cpp:237] Iteration 31520, loss = 3.44555
I0123 21:01:22.817688 29630 solver.cpp:253]     Train net output #0: loss = 3.44555 (* 1 = 3.44555 loss)
I0123 21:01:22.817693 29630 sgd_solver.cpp:106] Iteration 31520, lr = 0.01
I0123 21:01:30.084925 29630 solver.cpp:237] Iteration 31540, loss = 3.60525
I0123 21:01:30.084964 29630 solver.cpp:253]     Train net output #0: loss = 3.60525 (* 1 = 3.60525 loss)
I0123 21:01:30.084970 29630 sgd_solver.cpp:106] Iteration 31540, lr = 0.01
I0123 21:01:37.317152 29630 solver.cpp:237] Iteration 31560, loss = 3.96687
I0123 21:01:37.317189 29630 solver.cpp:253]     Train net output #0: loss = 3.96687 (* 1 = 3.96687 loss)
I0123 21:01:37.317196 29630 sgd_solver.cpp:106] Iteration 31560, lr = 0.01
I0123 21:01:44.595108 29630 solver.cpp:237] Iteration 31580, loss = 3.57899
I0123 21:01:44.595257 29630 solver.cpp:253]     Train net output #0: loss = 3.57899 (* 1 = 3.57899 loss)
I0123 21:01:44.595266 29630 sgd_solver.cpp:106] Iteration 31580, lr = 0.01
I0123 21:01:51.830348 29630 solver.cpp:237] Iteration 31600, loss = 3.79
I0123 21:01:51.830386 29630 solver.cpp:253]     Train net output #0: loss = 3.79 (* 1 = 3.79 loss)
I0123 21:01:51.830392 29630 sgd_solver.cpp:106] Iteration 31600, lr = 0.01
I0123 21:01:59.099624 29630 solver.cpp:237] Iteration 31620, loss = 3.63122
I0123 21:01:59.099663 29630 solver.cpp:253]     Train net output #0: loss = 3.63122 (* 1 = 3.63122 loss)
I0123 21:01:59.099670 29630 sgd_solver.cpp:106] Iteration 31620, lr = 0.01
I0123 21:02:06.379040 29630 solver.cpp:237] Iteration 31640, loss = 3.65379
I0123 21:02:06.379081 29630 solver.cpp:253]     Train net output #0: loss = 3.65379 (* 1 = 3.65379 loss)
I0123 21:02:06.379086 29630 sgd_solver.cpp:106] Iteration 31640, lr = 0.01
I0123 21:02:13.666518 29630 solver.cpp:237] Iteration 31660, loss = 3.40536
I0123 21:02:13.666558 29630 solver.cpp:253]     Train net output #0: loss = 3.40536 (* 1 = 3.40536 loss)
I0123 21:02:13.666563 29630 sgd_solver.cpp:106] Iteration 31660, lr = 0.01
I0123 21:02:20.953524 29630 solver.cpp:237] Iteration 31680, loss = 3.80901
I0123 21:02:20.953641 29630 solver.cpp:253]     Train net output #0: loss = 3.80901 (* 1 = 3.80901 loss)
I0123 21:02:20.953649 29630 sgd_solver.cpp:106] Iteration 31680, lr = 0.01
I0123 21:02:28.232929 29630 solver.cpp:237] Iteration 31700, loss = 3.64902
I0123 21:02:28.232966 29630 solver.cpp:253]     Train net output #0: loss = 3.64902 (* 1 = 3.64902 loss)
I0123 21:02:28.232972 29630 sgd_solver.cpp:106] Iteration 31700, lr = 0.01
I0123 21:02:35.538450 29630 solver.cpp:237] Iteration 31720, loss = 3.68723
I0123 21:02:35.538488 29630 solver.cpp:253]     Train net output #0: loss = 3.68723 (* 1 = 3.68723 loss)
I0123 21:02:35.538494 29630 sgd_solver.cpp:106] Iteration 31720, lr = 0.01
I0123 21:02:42.772321 29630 solver.cpp:237] Iteration 31740, loss = 3.52705
I0123 21:02:42.772359 29630 solver.cpp:253]     Train net output #0: loss = 3.52705 (* 1 = 3.52705 loss)
I0123 21:02:42.772366 29630 sgd_solver.cpp:106] Iteration 31740, lr = 0.01
I0123 21:02:50.038228 29630 solver.cpp:237] Iteration 31760, loss = 3.68395
I0123 21:02:50.038267 29630 solver.cpp:253]     Train net output #0: loss = 3.68395 (* 1 = 3.68395 loss)
I0123 21:02:50.038274 29630 sgd_solver.cpp:106] Iteration 31760, lr = 0.01
I0123 21:02:57.298847 29630 solver.cpp:237] Iteration 31780, loss = 3.66043
I0123 21:02:57.299011 29630 solver.cpp:253]     Train net output #0: loss = 3.66043 (* 1 = 3.66043 loss)
I0123 21:02:57.299020 29630 sgd_solver.cpp:106] Iteration 31780, lr = 0.01
I0123 21:03:04.560133 29630 solver.cpp:237] Iteration 31800, loss = 3.55256
I0123 21:03:04.560170 29630 solver.cpp:253]     Train net output #0: loss = 3.55256 (* 1 = 3.55256 loss)
I0123 21:03:04.560176 29630 sgd_solver.cpp:106] Iteration 31800, lr = 0.01
I0123 21:03:11.789000 29630 solver.cpp:237] Iteration 31820, loss = 3.52957
I0123 21:03:11.789038 29630 solver.cpp:253]     Train net output #0: loss = 3.52957 (* 1 = 3.52957 loss)
I0123 21:03:11.789046 29630 sgd_solver.cpp:106] Iteration 31820, lr = 0.01
I0123 21:03:19.042129 29630 solver.cpp:237] Iteration 31840, loss = 3.76071
I0123 21:03:19.042167 29630 solver.cpp:253]     Train net output #0: loss = 3.76071 (* 1 = 3.76071 loss)
I0123 21:03:19.042173 29630 sgd_solver.cpp:106] Iteration 31840, lr = 0.01
I0123 21:03:26.310582 29630 solver.cpp:237] Iteration 31860, loss = 3.69863
I0123 21:03:26.310621 29630 solver.cpp:253]     Train net output #0: loss = 3.69863 (* 1 = 3.69863 loss)
I0123 21:03:26.310628 29630 sgd_solver.cpp:106] Iteration 31860, lr = 0.01
I0123 21:03:33.501497 29630 solver.cpp:237] Iteration 31880, loss = 3.8343
I0123 21:03:33.501672 29630 solver.cpp:253]     Train net output #0: loss = 3.8343 (* 1 = 3.8343 loss)
I0123 21:03:33.501679 29630 sgd_solver.cpp:106] Iteration 31880, lr = 0.01
I0123 21:03:40.809353 29630 solver.cpp:237] Iteration 31900, loss = 3.79388
I0123 21:03:40.809392 29630 solver.cpp:253]     Train net output #0: loss = 3.79388 (* 1 = 3.79388 loss)
I0123 21:03:40.809398 29630 sgd_solver.cpp:106] Iteration 31900, lr = 0.01
I0123 21:03:48.014819 29630 solver.cpp:237] Iteration 31920, loss = 3.7763
I0123 21:03:48.014878 29630 solver.cpp:253]     Train net output #0: loss = 3.7763 (* 1 = 3.7763 loss)
I0123 21:03:48.014890 29630 sgd_solver.cpp:106] Iteration 31920, lr = 0.01
I0123 21:03:55.341508 29630 solver.cpp:237] Iteration 31940, loss = 3.79837
I0123 21:03:55.341547 29630 solver.cpp:253]     Train net output #0: loss = 3.79837 (* 1 = 3.79837 loss)
I0123 21:03:55.341552 29630 sgd_solver.cpp:106] Iteration 31940, lr = 0.01
I0123 21:04:02.647675 29630 solver.cpp:237] Iteration 31960, loss = 3.65211
I0123 21:04:02.647704 29630 solver.cpp:253]     Train net output #0: loss = 3.65211 (* 1 = 3.65211 loss)
I0123 21:04:02.647711 29630 sgd_solver.cpp:106] Iteration 31960, lr = 0.01
I0123 21:04:09.938832 29630 solver.cpp:237] Iteration 31980, loss = 3.80532
I0123 21:04:09.938994 29630 solver.cpp:253]     Train net output #0: loss = 3.80532 (* 1 = 3.80532 loss)
I0123 21:04:09.939003 29630 sgd_solver.cpp:106] Iteration 31980, lr = 0.01
I0123 21:04:16.947115 29630 solver.cpp:341] Iteration 32000, Testing net (#0)
I0123 21:04:30.896957 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 21:05:31.568900 29630 solver.cpp:409]     Test net output #0: accuracy = 0.27648
I0123 21:05:31.569057 29630 solver.cpp:409]     Test net output #1: loss = 3.48432 (* 1 = 3.48432 loss)
I0123 21:05:31.609514 29630 solver.cpp:237] Iteration 32000, loss = 3.58546
I0123 21:05:31.609550 29630 solver.cpp:253]     Train net output #0: loss = 3.58546 (* 1 = 3.58546 loss)
I0123 21:05:31.609557 29630 sgd_solver.cpp:106] Iteration 32000, lr = 0.01
I0123 21:05:38.133774 29630 solver.cpp:237] Iteration 32020, loss = 3.59957
I0123 21:05:38.133812 29630 solver.cpp:253]     Train net output #0: loss = 3.59957 (* 1 = 3.59957 loss)
I0123 21:05:38.133818 29630 sgd_solver.cpp:106] Iteration 32020, lr = 0.01
I0123 21:05:45.377434 29630 solver.cpp:237] Iteration 32040, loss = 3.98489
I0123 21:05:45.377472 29630 solver.cpp:253]     Train net output #0: loss = 3.98489 (* 1 = 3.98489 loss)
I0123 21:05:45.377480 29630 sgd_solver.cpp:106] Iteration 32040, lr = 0.01
I0123 21:05:52.627872 29630 solver.cpp:237] Iteration 32060, loss = 3.77723
I0123 21:05:52.627912 29630 solver.cpp:253]     Train net output #0: loss = 3.77723 (* 1 = 3.77723 loss)
I0123 21:05:52.627918 29630 sgd_solver.cpp:106] Iteration 32060, lr = 0.01
I0123 21:05:59.962833 29630 solver.cpp:237] Iteration 32080, loss = 3.7425
I0123 21:05:59.962873 29630 solver.cpp:253]     Train net output #0: loss = 3.7425 (* 1 = 3.7425 loss)
I0123 21:05:59.962880 29630 sgd_solver.cpp:106] Iteration 32080, lr = 0.01
I0123 21:06:07.168516 29630 solver.cpp:237] Iteration 32100, loss = 3.76816
I0123 21:06:07.168642 29630 solver.cpp:253]     Train net output #0: loss = 3.76816 (* 1 = 3.76816 loss)
I0123 21:06:07.168649 29630 sgd_solver.cpp:106] Iteration 32100, lr = 0.01
I0123 21:06:14.380897 29630 solver.cpp:237] Iteration 32120, loss = 3.66456
I0123 21:06:14.380936 29630 solver.cpp:253]     Train net output #0: loss = 3.66456 (* 1 = 3.66456 loss)
I0123 21:06:14.380942 29630 sgd_solver.cpp:106] Iteration 32120, lr = 0.01
I0123 21:06:21.603320 29630 solver.cpp:237] Iteration 32140, loss = 3.72465
I0123 21:06:21.603348 29630 solver.cpp:253]     Train net output #0: loss = 3.72465 (* 1 = 3.72465 loss)
I0123 21:06:21.603354 29630 sgd_solver.cpp:106] Iteration 32140, lr = 0.01
I0123 21:06:28.888543 29630 solver.cpp:237] Iteration 32160, loss = 3.73638
I0123 21:06:28.888582 29630 solver.cpp:253]     Train net output #0: loss = 3.73638 (* 1 = 3.73638 loss)
I0123 21:06:28.888588 29630 sgd_solver.cpp:106] Iteration 32160, lr = 0.01
I0123 21:06:36.195031 29630 solver.cpp:237] Iteration 32180, loss = 3.82271
I0123 21:06:36.195061 29630 solver.cpp:253]     Train net output #0: loss = 3.82271 (* 1 = 3.82271 loss)
I0123 21:06:36.195067 29630 sgd_solver.cpp:106] Iteration 32180, lr = 0.01
I0123 21:06:40.985409 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 21:06:43.454569 29630 solver.cpp:237] Iteration 32200, loss = 3.56817
I0123 21:06:43.454607 29630 solver.cpp:253]     Train net output #0: loss = 3.56817 (* 1 = 3.56817 loss)
I0123 21:06:43.454613 29630 sgd_solver.cpp:106] Iteration 32200, lr = 0.01
I0123 21:06:50.691656 29630 solver.cpp:237] Iteration 32220, loss = 3.67106
I0123 21:06:50.691696 29630 solver.cpp:253]     Train net output #0: loss = 3.67106 (* 1 = 3.67106 loss)
I0123 21:06:50.691702 29630 sgd_solver.cpp:106] Iteration 32220, lr = 0.01
I0123 21:06:57.913724 29630 solver.cpp:237] Iteration 32240, loss = 3.69496
I0123 21:06:57.913771 29630 solver.cpp:253]     Train net output #0: loss = 3.69496 (* 1 = 3.69496 loss)
I0123 21:06:57.913777 29630 sgd_solver.cpp:106] Iteration 32240, lr = 0.01
I0123 21:07:05.153952 29630 solver.cpp:237] Iteration 32260, loss = 3.65102
I0123 21:07:05.153990 29630 solver.cpp:253]     Train net output #0: loss = 3.65102 (* 1 = 3.65102 loss)
I0123 21:07:05.153996 29630 sgd_solver.cpp:106] Iteration 32260, lr = 0.01
I0123 21:07:12.447481 29630 solver.cpp:237] Iteration 32280, loss = 3.4794
I0123 21:07:12.447602 29630 solver.cpp:253]     Train net output #0: loss = 3.4794 (* 1 = 3.4794 loss)
I0123 21:07:12.447608 29630 sgd_solver.cpp:106] Iteration 32280, lr = 0.01
I0123 21:07:19.720340 29630 solver.cpp:237] Iteration 32300, loss = 3.53343
I0123 21:07:19.720379 29630 solver.cpp:253]     Train net output #0: loss = 3.53343 (* 1 = 3.53343 loss)
I0123 21:07:19.720387 29630 sgd_solver.cpp:106] Iteration 32300, lr = 0.01
I0123 21:07:26.966130 29630 solver.cpp:237] Iteration 32320, loss = 3.76167
I0123 21:07:26.966168 29630 solver.cpp:253]     Train net output #0: loss = 3.76167 (* 1 = 3.76167 loss)
I0123 21:07:26.966176 29630 sgd_solver.cpp:106] Iteration 32320, lr = 0.01
I0123 21:07:34.279595 29630 solver.cpp:237] Iteration 32340, loss = 3.57586
I0123 21:07:34.279633 29630 solver.cpp:253]     Train net output #0: loss = 3.57586 (* 1 = 3.57586 loss)
I0123 21:07:34.279639 29630 sgd_solver.cpp:106] Iteration 32340, lr = 0.01
I0123 21:07:41.591512 29630 solver.cpp:237] Iteration 32360, loss = 3.61059
I0123 21:07:41.591550 29630 solver.cpp:253]     Train net output #0: loss = 3.61059 (* 1 = 3.61059 loss)
I0123 21:07:41.591557 29630 sgd_solver.cpp:106] Iteration 32360, lr = 0.01
I0123 21:07:48.862763 29630 solver.cpp:237] Iteration 32380, loss = 3.68123
I0123 21:07:48.862956 29630 solver.cpp:253]     Train net output #0: loss = 3.68123 (* 1 = 3.68123 loss)
I0123 21:07:48.862972 29630 sgd_solver.cpp:106] Iteration 32380, lr = 0.01
I0123 21:07:56.123203 29630 solver.cpp:237] Iteration 32400, loss = 3.61477
I0123 21:07:56.123241 29630 solver.cpp:253]     Train net output #0: loss = 3.61477 (* 1 = 3.61477 loss)
I0123 21:07:56.123247 29630 sgd_solver.cpp:106] Iteration 32400, lr = 0.01
I0123 21:08:03.427073 29630 solver.cpp:237] Iteration 32420, loss = 3.61474
I0123 21:08:03.427101 29630 solver.cpp:253]     Train net output #0: loss = 3.61474 (* 1 = 3.61474 loss)
I0123 21:08:03.427108 29630 sgd_solver.cpp:106] Iteration 32420, lr = 0.01
I0123 21:08:10.690928 29630 solver.cpp:237] Iteration 32440, loss = 3.82803
I0123 21:08:10.690971 29630 solver.cpp:253]     Train net output #0: loss = 3.82803 (* 1 = 3.82803 loss)
I0123 21:08:10.690980 29630 sgd_solver.cpp:106] Iteration 32440, lr = 0.01
I0123 21:08:18.017668 29630 solver.cpp:237] Iteration 32460, loss = 3.77779
I0123 21:08:18.017707 29630 solver.cpp:253]     Train net output #0: loss = 3.77779 (* 1 = 3.77779 loss)
I0123 21:08:18.017714 29630 sgd_solver.cpp:106] Iteration 32460, lr = 0.01
I0123 21:08:25.285399 29630 solver.cpp:237] Iteration 32480, loss = 3.76454
I0123 21:08:25.285512 29630 solver.cpp:253]     Train net output #0: loss = 3.76454 (* 1 = 3.76454 loss)
I0123 21:08:25.285531 29630 sgd_solver.cpp:106] Iteration 32480, lr = 0.01
I0123 21:08:32.620179 29630 solver.cpp:237] Iteration 32500, loss = 3.70553
I0123 21:08:32.620219 29630 solver.cpp:253]     Train net output #0: loss = 3.70553 (* 1 = 3.70553 loss)
I0123 21:08:32.620225 29630 sgd_solver.cpp:106] Iteration 32500, lr = 0.01
I0123 21:08:39.877795 29630 solver.cpp:237] Iteration 32520, loss = 3.59976
I0123 21:08:39.877833 29630 solver.cpp:253]     Train net output #0: loss = 3.59976 (* 1 = 3.59976 loss)
I0123 21:08:39.877840 29630 sgd_solver.cpp:106] Iteration 32520, lr = 0.01
I0123 21:08:47.199220 29630 solver.cpp:237] Iteration 32540, loss = 3.92173
I0123 21:08:47.199259 29630 solver.cpp:253]     Train net output #0: loss = 3.92173 (* 1 = 3.92173 loss)
I0123 21:08:47.199265 29630 sgd_solver.cpp:106] Iteration 32540, lr = 0.01
I0123 21:08:54.461750 29630 solver.cpp:237] Iteration 32560, loss = 3.58216
I0123 21:08:54.461788 29630 solver.cpp:253]     Train net output #0: loss = 3.58216 (* 1 = 3.58216 loss)
I0123 21:08:54.461796 29630 sgd_solver.cpp:106] Iteration 32560, lr = 0.01
I0123 21:09:01.702265 29630 solver.cpp:237] Iteration 32580, loss = 3.74153
I0123 21:09:01.702365 29630 solver.cpp:253]     Train net output #0: loss = 3.74153 (* 1 = 3.74153 loss)
I0123 21:09:01.702373 29630 sgd_solver.cpp:106] Iteration 32580, lr = 0.01
I0123 21:09:09.002003 29630 solver.cpp:237] Iteration 32600, loss = 3.64046
I0123 21:09:09.002033 29630 solver.cpp:253]     Train net output #0: loss = 3.64046 (* 1 = 3.64046 loss)
I0123 21:09:09.002039 29630 sgd_solver.cpp:106] Iteration 32600, lr = 0.01
I0123 21:09:16.229727 29630 solver.cpp:237] Iteration 32620, loss = 3.75368
I0123 21:09:16.229765 29630 solver.cpp:253]     Train net output #0: loss = 3.75368 (* 1 = 3.75368 loss)
I0123 21:09:16.229771 29630 sgd_solver.cpp:106] Iteration 32620, lr = 0.01
I0123 21:09:23.521502 29630 solver.cpp:237] Iteration 32640, loss = 3.74794
I0123 21:09:23.521543 29630 solver.cpp:253]     Train net output #0: loss = 3.74794 (* 1 = 3.74794 loss)
I0123 21:09:23.521551 29630 sgd_solver.cpp:106] Iteration 32640, lr = 0.01
I0123 21:09:30.768136 29630 solver.cpp:237] Iteration 32660, loss = 3.53456
I0123 21:09:30.768175 29630 solver.cpp:253]     Train net output #0: loss = 3.53456 (* 1 = 3.53456 loss)
I0123 21:09:30.768192 29630 sgd_solver.cpp:106] Iteration 32660, lr = 0.01
I0123 21:09:38.053529 29630 solver.cpp:237] Iteration 32680, loss = 3.60692
I0123 21:09:38.053642 29630 solver.cpp:253]     Train net output #0: loss = 3.60692 (* 1 = 3.60692 loss)
I0123 21:09:38.053650 29630 sgd_solver.cpp:106] Iteration 32680, lr = 0.01
I0123 21:09:45.303513 29630 solver.cpp:237] Iteration 32700, loss = 3.5791
I0123 21:09:45.303553 29630 solver.cpp:253]     Train net output #0: loss = 3.5791 (* 1 = 3.5791 loss)
I0123 21:09:45.303560 29630 sgd_solver.cpp:106] Iteration 32700, lr = 0.01
I0123 21:09:52.571007 29630 solver.cpp:237] Iteration 32720, loss = 3.62283
I0123 21:09:52.571044 29630 solver.cpp:253]     Train net output #0: loss = 3.62283 (* 1 = 3.62283 loss)
I0123 21:09:52.571050 29630 sgd_solver.cpp:106] Iteration 32720, lr = 0.01
I0123 21:09:59.790036 29630 solver.cpp:237] Iteration 32740, loss = 3.85786
I0123 21:09:59.790076 29630 solver.cpp:253]     Train net output #0: loss = 3.85786 (* 1 = 3.85786 loss)
I0123 21:09:59.790081 29630 sgd_solver.cpp:106] Iteration 32740, lr = 0.01
I0123 21:10:07.043084 29630 solver.cpp:237] Iteration 32760, loss = 3.75993
I0123 21:10:07.043123 29630 solver.cpp:253]     Train net output #0: loss = 3.75993 (* 1 = 3.75993 loss)
I0123 21:10:07.043128 29630 sgd_solver.cpp:106] Iteration 32760, lr = 0.01
I0123 21:10:14.289794 29630 solver.cpp:237] Iteration 32780, loss = 3.63194
I0123 21:10:14.289935 29630 solver.cpp:253]     Train net output #0: loss = 3.63194 (* 1 = 3.63194 loss)
I0123 21:10:14.289943 29630 sgd_solver.cpp:106] Iteration 32780, lr = 0.01
I0123 21:10:21.557454 29630 solver.cpp:237] Iteration 32800, loss = 3.81418
I0123 21:10:21.557492 29630 solver.cpp:253]     Train net output #0: loss = 3.81418 (* 1 = 3.81418 loss)
I0123 21:10:21.557498 29630 sgd_solver.cpp:106] Iteration 32800, lr = 0.01
I0123 21:10:28.811316 29630 solver.cpp:237] Iteration 32820, loss = 3.78237
I0123 21:10:28.811353 29630 solver.cpp:253]     Train net output #0: loss = 3.78237 (* 1 = 3.78237 loss)
I0123 21:10:28.811359 29630 sgd_solver.cpp:106] Iteration 32820, lr = 0.01
I0123 21:10:36.107852 29630 solver.cpp:237] Iteration 32840, loss = 3.6673
I0123 21:10:36.107890 29630 solver.cpp:253]     Train net output #0: loss = 3.6673 (* 1 = 3.6673 loss)
I0123 21:10:36.107897 29630 sgd_solver.cpp:106] Iteration 32840, lr = 0.01
I0123 21:10:43.377236 29630 solver.cpp:237] Iteration 32860, loss = 3.50844
I0123 21:10:43.377274 29630 solver.cpp:253]     Train net output #0: loss = 3.50844 (* 1 = 3.50844 loss)
I0123 21:10:43.377280 29630 sgd_solver.cpp:106] Iteration 32860, lr = 0.01
I0123 21:10:50.620064 29630 solver.cpp:237] Iteration 32880, loss = 3.54939
I0123 21:10:50.620239 29630 solver.cpp:253]     Train net output #0: loss = 3.54939 (* 1 = 3.54939 loss)
I0123 21:10:50.620247 29630 sgd_solver.cpp:106] Iteration 32880, lr = 0.01
I0123 21:10:57.880956 29630 solver.cpp:237] Iteration 32900, loss = 3.54203
I0123 21:10:57.881006 29630 solver.cpp:253]     Train net output #0: loss = 3.54203 (* 1 = 3.54203 loss)
I0123 21:10:57.881011 29630 sgd_solver.cpp:106] Iteration 32900, lr = 0.01
I0123 21:11:05.108945 29630 solver.cpp:237] Iteration 32920, loss = 3.90355
I0123 21:11:05.108983 29630 solver.cpp:253]     Train net output #0: loss = 3.90355 (* 1 = 3.90355 loss)
I0123 21:11:05.108989 29630 sgd_solver.cpp:106] Iteration 32920, lr = 0.01
I0123 21:11:12.383507 29630 solver.cpp:237] Iteration 32940, loss = 3.46757
I0123 21:11:12.383546 29630 solver.cpp:253]     Train net output #0: loss = 3.46757 (* 1 = 3.46757 loss)
I0123 21:11:12.383553 29630 sgd_solver.cpp:106] Iteration 32940, lr = 0.01
I0123 21:11:19.618829 29630 solver.cpp:237] Iteration 32960, loss = 3.68229
I0123 21:11:19.618867 29630 solver.cpp:253]     Train net output #0: loss = 3.68229 (* 1 = 3.68229 loss)
I0123 21:11:19.618873 29630 sgd_solver.cpp:106] Iteration 32960, lr = 0.01
I0123 21:11:26.863088 29630 solver.cpp:237] Iteration 32980, loss = 3.66991
I0123 21:11:26.863263 29630 solver.cpp:253]     Train net output #0: loss = 3.66991 (* 1 = 3.66991 loss)
I0123 21:11:26.863271 29630 sgd_solver.cpp:106] Iteration 32980, lr = 0.01
I0123 21:11:33.824036 29630 solver.cpp:341] Iteration 33000, Testing net (#0)
I0123 21:11:48.231549 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 21:12:47.666456 29630 solver.cpp:409]     Test net output #0: accuracy = 0.27522
I0123 21:12:47.666579 29630 solver.cpp:409]     Test net output #1: loss = 3.50978 (* 1 = 3.50978 loss)
I0123 21:12:47.707659 29630 solver.cpp:237] Iteration 33000, loss = 3.79596
I0123 21:12:47.707727 29630 solver.cpp:253]     Train net output #0: loss = 3.79596 (* 1 = 3.79596 loss)
I0123 21:12:47.707746 29630 sgd_solver.cpp:106] Iteration 33000, lr = 0.01
I0123 21:12:54.265655 29630 solver.cpp:237] Iteration 33020, loss = 3.53974
I0123 21:12:54.265693 29630 solver.cpp:253]     Train net output #0: loss = 3.53974 (* 1 = 3.53974 loss)
I0123 21:12:54.265709 29630 sgd_solver.cpp:106] Iteration 33020, lr = 0.01
I0123 21:13:01.539233 29630 solver.cpp:237] Iteration 33040, loss = 3.65721
I0123 21:13:01.539271 29630 solver.cpp:253]     Train net output #0: loss = 3.65721 (* 1 = 3.65721 loss)
I0123 21:13:01.539278 29630 sgd_solver.cpp:106] Iteration 33040, lr = 0.01
I0123 21:13:08.853370 29630 solver.cpp:237] Iteration 33060, loss = 3.5074
I0123 21:13:08.853409 29630 solver.cpp:253]     Train net output #0: loss = 3.5074 (* 1 = 3.5074 loss)
I0123 21:13:08.853415 29630 sgd_solver.cpp:106] Iteration 33060, lr = 0.01
I0123 21:13:16.081254 29630 solver.cpp:237] Iteration 33080, loss = 3.57864
I0123 21:13:16.081293 29630 solver.cpp:253]     Train net output #0: loss = 3.57864 (* 1 = 3.57864 loss)
I0123 21:13:16.081300 29630 sgd_solver.cpp:106] Iteration 33080, lr = 0.01
I0123 21:13:23.335396 29630 solver.cpp:237] Iteration 33100, loss = 3.65345
I0123 21:13:23.335559 29630 solver.cpp:253]     Train net output #0: loss = 3.65345 (* 1 = 3.65345 loss)
I0123 21:13:23.335567 29630 sgd_solver.cpp:106] Iteration 33100, lr = 0.01
I0123 21:13:30.585655 29630 solver.cpp:237] Iteration 33120, loss = 3.49833
I0123 21:13:30.585695 29630 solver.cpp:253]     Train net output #0: loss = 3.49833 (* 1 = 3.49833 loss)
I0123 21:13:30.585700 29630 sgd_solver.cpp:106] Iteration 33120, lr = 0.01
I0123 21:13:37.913061 29630 solver.cpp:237] Iteration 33140, loss = 3.79876
I0123 21:13:37.913101 29630 solver.cpp:253]     Train net output #0: loss = 3.79876 (* 1 = 3.79876 loss)
I0123 21:13:37.913107 29630 sgd_solver.cpp:106] Iteration 33140, lr = 0.01
I0123 21:13:45.203246 29630 solver.cpp:237] Iteration 33160, loss = 3.72138
I0123 21:13:45.203285 29630 solver.cpp:253]     Train net output #0: loss = 3.72138 (* 1 = 3.72138 loss)
I0123 21:13:45.203291 29630 sgd_solver.cpp:106] Iteration 33160, lr = 0.01
I0123 21:13:52.480365 29630 solver.cpp:237] Iteration 33180, loss = 3.55749
I0123 21:13:52.480404 29630 solver.cpp:253]     Train net output #0: loss = 3.55749 (* 1 = 3.55749 loss)
I0123 21:13:52.480412 29630 sgd_solver.cpp:106] Iteration 33180, lr = 0.01
I0123 21:13:59.464486 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 21:13:59.753937 29630 solver.cpp:237] Iteration 33200, loss = 3.69817
I0123 21:13:59.753974 29630 solver.cpp:253]     Train net output #0: loss = 3.69817 (* 1 = 3.69817 loss)
I0123 21:13:59.753980 29630 sgd_solver.cpp:106] Iteration 33200, lr = 0.01
I0123 21:14:07.032762 29630 solver.cpp:237] Iteration 33220, loss = 3.65843
I0123 21:14:07.032799 29630 solver.cpp:253]     Train net output #0: loss = 3.65843 (* 1 = 3.65843 loss)
I0123 21:14:07.032805 29630 sgd_solver.cpp:106] Iteration 33220, lr = 0.01
I0123 21:14:14.278564 29630 solver.cpp:237] Iteration 33240, loss = 3.62583
I0123 21:14:14.278604 29630 solver.cpp:253]     Train net output #0: loss = 3.62583 (* 1 = 3.62583 loss)
I0123 21:14:14.278609 29630 sgd_solver.cpp:106] Iteration 33240, lr = 0.01
I0123 21:14:21.561398 29630 solver.cpp:237] Iteration 33260, loss = 3.7642
I0123 21:14:21.561436 29630 solver.cpp:253]     Train net output #0: loss = 3.7642 (* 1 = 3.7642 loss)
I0123 21:14:21.561442 29630 sgd_solver.cpp:106] Iteration 33260, lr = 0.01
I0123 21:14:28.883760 29630 solver.cpp:237] Iteration 33280, loss = 3.87332
I0123 21:14:28.883800 29630 solver.cpp:253]     Train net output #0: loss = 3.87332 (* 1 = 3.87332 loss)
I0123 21:14:28.883805 29630 sgd_solver.cpp:106] Iteration 33280, lr = 0.01
I0123 21:14:36.126742 29630 solver.cpp:237] Iteration 33300, loss = 4.02453
I0123 21:14:36.126865 29630 solver.cpp:253]     Train net output #0: loss = 4.02453 (* 1 = 4.02453 loss)
I0123 21:14:36.126873 29630 sgd_solver.cpp:106] Iteration 33300, lr = 0.01
I0123 21:14:43.353013 29630 solver.cpp:237] Iteration 33320, loss = 3.69258
I0123 21:14:43.353052 29630 solver.cpp:253]     Train net output #0: loss = 3.69258 (* 1 = 3.69258 loss)
I0123 21:14:43.353059 29630 sgd_solver.cpp:106] Iteration 33320, lr = 0.01
I0123 21:14:50.595901 29630 solver.cpp:237] Iteration 33340, loss = 3.61276
I0123 21:14:50.595966 29630 solver.cpp:253]     Train net output #0: loss = 3.61276 (* 1 = 3.61276 loss)
I0123 21:14:50.595983 29630 sgd_solver.cpp:106] Iteration 33340, lr = 0.01
I0123 21:14:57.870795 29630 solver.cpp:237] Iteration 33360, loss = 3.74764
I0123 21:14:57.870833 29630 solver.cpp:253]     Train net output #0: loss = 3.74764 (* 1 = 3.74764 loss)
I0123 21:14:57.870841 29630 sgd_solver.cpp:106] Iteration 33360, lr = 0.01
I0123 21:15:05.152565 29630 solver.cpp:237] Iteration 33380, loss = 3.7157
I0123 21:15:05.152602 29630 solver.cpp:253]     Train net output #0: loss = 3.7157 (* 1 = 3.7157 loss)
I0123 21:15:05.152608 29630 sgd_solver.cpp:106] Iteration 33380, lr = 0.01
I0123 21:15:12.374449 29630 solver.cpp:237] Iteration 33400, loss = 3.44327
I0123 21:15:12.374593 29630 solver.cpp:253]     Train net output #0: loss = 3.44327 (* 1 = 3.44327 loss)
I0123 21:15:12.374601 29630 sgd_solver.cpp:106] Iteration 33400, lr = 0.01
I0123 21:15:19.639905 29630 solver.cpp:237] Iteration 33420, loss = 3.67179
I0123 21:15:19.639945 29630 solver.cpp:253]     Train net output #0: loss = 3.67179 (* 1 = 3.67179 loss)
I0123 21:15:19.639950 29630 sgd_solver.cpp:106] Iteration 33420, lr = 0.01
I0123 21:15:26.874398 29630 solver.cpp:237] Iteration 33440, loss = 3.54684
I0123 21:15:26.874439 29630 solver.cpp:253]     Train net output #0: loss = 3.54684 (* 1 = 3.54684 loss)
I0123 21:15:26.874446 29630 sgd_solver.cpp:106] Iteration 33440, lr = 0.01
I0123 21:15:34.097146 29630 solver.cpp:237] Iteration 33460, loss = 3.62468
I0123 21:15:34.097183 29630 solver.cpp:253]     Train net output #0: loss = 3.62468 (* 1 = 3.62468 loss)
I0123 21:15:34.097189 29630 sgd_solver.cpp:106] Iteration 33460, lr = 0.01
I0123 21:15:41.405086 29630 solver.cpp:237] Iteration 33480, loss = 3.48123
I0123 21:15:41.405127 29630 solver.cpp:253]     Train net output #0: loss = 3.48123 (* 1 = 3.48123 loss)
I0123 21:15:41.405133 29630 sgd_solver.cpp:106] Iteration 33480, lr = 0.01
I0123 21:15:48.661208 29630 solver.cpp:237] Iteration 33500, loss = 3.9052
I0123 21:15:48.661387 29630 solver.cpp:253]     Train net output #0: loss = 3.9052 (* 1 = 3.9052 loss)
I0123 21:15:48.661396 29630 sgd_solver.cpp:106] Iteration 33500, lr = 0.01
I0123 21:15:55.966928 29630 solver.cpp:237] Iteration 33520, loss = 3.72895
I0123 21:15:55.966966 29630 solver.cpp:253]     Train net output #0: loss = 3.72895 (* 1 = 3.72895 loss)
I0123 21:15:55.966971 29630 sgd_solver.cpp:106] Iteration 33520, lr = 0.01
I0123 21:16:03.207722 29630 solver.cpp:237] Iteration 33540, loss = 3.44292
I0123 21:16:03.207762 29630 solver.cpp:253]     Train net output #0: loss = 3.44292 (* 1 = 3.44292 loss)
I0123 21:16:03.207768 29630 sgd_solver.cpp:106] Iteration 33540, lr = 0.01
I0123 21:16:10.469928 29630 solver.cpp:237] Iteration 33560, loss = 3.62025
I0123 21:16:10.469964 29630 solver.cpp:253]     Train net output #0: loss = 3.62025 (* 1 = 3.62025 loss)
I0123 21:16:10.469971 29630 sgd_solver.cpp:106] Iteration 33560, lr = 0.01
I0123 21:16:17.735750 29630 solver.cpp:237] Iteration 33580, loss = 3.68261
I0123 21:16:17.735790 29630 solver.cpp:253]     Train net output #0: loss = 3.68261 (* 1 = 3.68261 loss)
I0123 21:16:17.735795 29630 sgd_solver.cpp:106] Iteration 33580, lr = 0.01
I0123 21:16:25.019181 29630 solver.cpp:237] Iteration 33600, loss = 3.80186
I0123 21:16:25.019359 29630 solver.cpp:253]     Train net output #0: loss = 3.80186 (* 1 = 3.80186 loss)
I0123 21:16:25.019366 29630 sgd_solver.cpp:106] Iteration 33600, lr = 0.01
I0123 21:16:32.301069 29630 solver.cpp:237] Iteration 33620, loss = 3.6063
I0123 21:16:32.301107 29630 solver.cpp:253]     Train net output #0: loss = 3.6063 (* 1 = 3.6063 loss)
I0123 21:16:32.301113 29630 sgd_solver.cpp:106] Iteration 33620, lr = 0.01
I0123 21:16:39.584214 29630 solver.cpp:237] Iteration 33640, loss = 4.0019
I0123 21:16:39.584254 29630 solver.cpp:253]     Train net output #0: loss = 4.0019 (* 1 = 4.0019 loss)
I0123 21:16:39.584259 29630 sgd_solver.cpp:106] Iteration 33640, lr = 0.01
I0123 21:16:46.884908 29630 solver.cpp:237] Iteration 33660, loss = 3.60338
I0123 21:16:46.884955 29630 solver.cpp:253]     Train net output #0: loss = 3.60338 (* 1 = 3.60338 loss)
I0123 21:16:46.884961 29630 sgd_solver.cpp:106] Iteration 33660, lr = 0.01
I0123 21:16:54.169240 29630 solver.cpp:237] Iteration 33680, loss = 3.47097
I0123 21:16:54.169278 29630 solver.cpp:253]     Train net output #0: loss = 3.47097 (* 1 = 3.47097 loss)
I0123 21:16:54.169284 29630 sgd_solver.cpp:106] Iteration 33680, lr = 0.01
I0123 21:17:01.391032 29630 solver.cpp:237] Iteration 33700, loss = 3.9224
I0123 21:17:01.391165 29630 solver.cpp:253]     Train net output #0: loss = 3.9224 (* 1 = 3.9224 loss)
I0123 21:17:01.391180 29630 sgd_solver.cpp:106] Iteration 33700, lr = 0.01
I0123 21:17:08.696069 29630 solver.cpp:237] Iteration 33720, loss = 3.74454
I0123 21:17:08.696105 29630 solver.cpp:253]     Train net output #0: loss = 3.74454 (* 1 = 3.74454 loss)
I0123 21:17:08.696110 29630 sgd_solver.cpp:106] Iteration 33720, lr = 0.01
I0123 21:17:15.997537 29630 solver.cpp:237] Iteration 33740, loss = 3.78933
I0123 21:17:15.997580 29630 solver.cpp:253]     Train net output #0: loss = 3.78933 (* 1 = 3.78933 loss)
I0123 21:17:15.997586 29630 sgd_solver.cpp:106] Iteration 33740, lr = 0.01
I0123 21:17:23.296928 29630 solver.cpp:237] Iteration 33760, loss = 3.42644
I0123 21:17:23.296967 29630 solver.cpp:253]     Train net output #0: loss = 3.42644 (* 1 = 3.42644 loss)
I0123 21:17:23.296972 29630 sgd_solver.cpp:106] Iteration 33760, lr = 0.01
I0123 21:17:30.578991 29630 solver.cpp:237] Iteration 33780, loss = 3.86796
I0123 21:17:30.579030 29630 solver.cpp:253]     Train net output #0: loss = 3.86796 (* 1 = 3.86796 loss)
I0123 21:17:30.579036 29630 sgd_solver.cpp:106] Iteration 33780, lr = 0.01
I0123 21:17:37.850010 29630 solver.cpp:237] Iteration 33800, loss = 3.57941
I0123 21:17:37.850158 29630 solver.cpp:253]     Train net output #0: loss = 3.57941 (* 1 = 3.57941 loss)
I0123 21:17:37.850177 29630 sgd_solver.cpp:106] Iteration 33800, lr = 0.01
I0123 21:17:45.096863 29630 solver.cpp:237] Iteration 33820, loss = 3.70692
I0123 21:17:45.096900 29630 solver.cpp:253]     Train net output #0: loss = 3.70692 (* 1 = 3.70692 loss)
I0123 21:17:45.096906 29630 sgd_solver.cpp:106] Iteration 33820, lr = 0.01
I0123 21:17:52.418299 29630 solver.cpp:237] Iteration 33840, loss = 3.89353
I0123 21:17:52.418355 29630 solver.cpp:253]     Train net output #0: loss = 3.89353 (* 1 = 3.89353 loss)
I0123 21:17:52.418361 29630 sgd_solver.cpp:106] Iteration 33840, lr = 0.01
I0123 21:17:59.673939 29630 solver.cpp:237] Iteration 33860, loss = 3.62226
I0123 21:17:59.673976 29630 solver.cpp:253]     Train net output #0: loss = 3.62226 (* 1 = 3.62226 loss)
I0123 21:17:59.673984 29630 sgd_solver.cpp:106] Iteration 33860, lr = 0.01
I0123 21:18:06.968665 29630 solver.cpp:237] Iteration 33880, loss = 3.53752
I0123 21:18:06.968704 29630 solver.cpp:253]     Train net output #0: loss = 3.53752 (* 1 = 3.53752 loss)
I0123 21:18:06.968711 29630 sgd_solver.cpp:106] Iteration 33880, lr = 0.01
I0123 21:18:14.223624 29630 solver.cpp:237] Iteration 33900, loss = 3.72441
I0123 21:18:14.223747 29630 solver.cpp:253]     Train net output #0: loss = 3.72441 (* 1 = 3.72441 loss)
I0123 21:18:14.223754 29630 sgd_solver.cpp:106] Iteration 33900, lr = 0.01
I0123 21:18:21.464439 29630 solver.cpp:237] Iteration 33920, loss = 3.47162
I0123 21:18:21.464478 29630 solver.cpp:253]     Train net output #0: loss = 3.47162 (* 1 = 3.47162 loss)
I0123 21:18:21.464484 29630 sgd_solver.cpp:106] Iteration 33920, lr = 0.01
I0123 21:18:28.708268 29630 solver.cpp:237] Iteration 33940, loss = 3.73971
I0123 21:18:28.708307 29630 solver.cpp:253]     Train net output #0: loss = 3.73971 (* 1 = 3.73971 loss)
I0123 21:18:28.708312 29630 sgd_solver.cpp:106] Iteration 33940, lr = 0.01
I0123 21:18:35.942301 29630 solver.cpp:237] Iteration 33960, loss = 3.62108
I0123 21:18:35.942342 29630 solver.cpp:253]     Train net output #0: loss = 3.62108 (* 1 = 3.62108 loss)
I0123 21:18:35.942349 29630 sgd_solver.cpp:106] Iteration 33960, lr = 0.01
I0123 21:18:43.241317 29630 solver.cpp:237] Iteration 33980, loss = 3.64964
I0123 21:18:43.241355 29630 solver.cpp:253]     Train net output #0: loss = 3.64964 (* 1 = 3.64964 loss)
I0123 21:18:43.241363 29630 sgd_solver.cpp:106] Iteration 33980, lr = 0.01
I0123 21:18:50.236368 29630 solver.cpp:341] Iteration 34000, Testing net (#0)
I0123 21:19:05.043143 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 21:20:03.900228 29630 solver.cpp:409]     Test net output #0: accuracy = 0.28058
I0123 21:20:03.900357 29630 solver.cpp:409]     Test net output #1: loss = 3.4638 (* 1 = 3.4638 loss)
I0123 21:20:03.941059 29630 solver.cpp:237] Iteration 34000, loss = 3.67531
I0123 21:20:03.941097 29630 solver.cpp:253]     Train net output #0: loss = 3.67531 (* 1 = 3.67531 loss)
I0123 21:20:03.941102 29630 sgd_solver.cpp:106] Iteration 34000, lr = 0.01
I0123 21:20:10.487661 29630 solver.cpp:237] Iteration 34020, loss = 3.73398
I0123 21:20:10.487699 29630 solver.cpp:253]     Train net output #0: loss = 3.73398 (* 1 = 3.73398 loss)
I0123 21:20:10.487705 29630 sgd_solver.cpp:106] Iteration 34020, lr = 0.01
I0123 21:20:17.751937 29630 solver.cpp:237] Iteration 34040, loss = 3.74074
I0123 21:20:17.751976 29630 solver.cpp:253]     Train net output #0: loss = 3.74074 (* 1 = 3.74074 loss)
I0123 21:20:17.751982 29630 sgd_solver.cpp:106] Iteration 34040, lr = 0.01
I0123 21:20:25.017365 29630 solver.cpp:237] Iteration 34060, loss = 3.8829
I0123 21:20:25.017402 29630 solver.cpp:253]     Train net output #0: loss = 3.8829 (* 1 = 3.8829 loss)
I0123 21:20:25.017418 29630 sgd_solver.cpp:106] Iteration 34060, lr = 0.01
I0123 21:20:32.285120 29630 solver.cpp:237] Iteration 34080, loss = 3.82452
I0123 21:20:32.285158 29630 solver.cpp:253]     Train net output #0: loss = 3.82452 (* 1 = 3.82452 loss)
I0123 21:20:32.285166 29630 sgd_solver.cpp:106] Iteration 34080, lr = 0.01
I0123 21:20:39.497509 29630 solver.cpp:237] Iteration 34100, loss = 3.67736
I0123 21:20:39.497619 29630 solver.cpp:253]     Train net output #0: loss = 3.67736 (* 1 = 3.67736 loss)
I0123 21:20:39.497640 29630 sgd_solver.cpp:106] Iteration 34100, lr = 0.01
I0123 21:20:46.775506 29630 solver.cpp:237] Iteration 34120, loss = 3.35556
I0123 21:20:46.775544 29630 solver.cpp:253]     Train net output #0: loss = 3.35556 (* 1 = 3.35556 loss)
I0123 21:20:46.775552 29630 sgd_solver.cpp:106] Iteration 34120, lr = 0.01
I0123 21:20:54.056553 29630 solver.cpp:237] Iteration 34140, loss = 3.51929
I0123 21:20:54.056591 29630 solver.cpp:253]     Train net output #0: loss = 3.51929 (* 1 = 3.51929 loss)
I0123 21:20:54.056598 29630 sgd_solver.cpp:106] Iteration 34140, lr = 0.01
I0123 21:21:01.348454 29630 solver.cpp:237] Iteration 34160, loss = 3.75802
I0123 21:21:01.348494 29630 solver.cpp:253]     Train net output #0: loss = 3.75802 (* 1 = 3.75802 loss)
I0123 21:21:01.348500 29630 sgd_solver.cpp:106] Iteration 34160, lr = 0.01
I0123 21:21:08.612395 29630 solver.cpp:237] Iteration 34180, loss = 3.58087
I0123 21:21:08.612435 29630 solver.cpp:253]     Train net output #0: loss = 3.58087 (* 1 = 3.58087 loss)
I0123 21:21:08.612442 29630 sgd_solver.cpp:106] Iteration 34180, lr = 0.01
I0123 21:21:15.907721 29630 solver.cpp:237] Iteration 34200, loss = 3.50784
I0123 21:21:15.907836 29630 solver.cpp:253]     Train net output #0: loss = 3.50784 (* 1 = 3.50784 loss)
I0123 21:21:15.907842 29630 sgd_solver.cpp:106] Iteration 34200, lr = 0.01
I0123 21:21:17.808764 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 21:21:23.247984 29630 solver.cpp:237] Iteration 34220, loss = 3.64379
I0123 21:21:23.248024 29630 solver.cpp:253]     Train net output #0: loss = 3.64379 (* 1 = 3.64379 loss)
I0123 21:21:23.248030 29630 sgd_solver.cpp:106] Iteration 34220, lr = 0.01
I0123 21:21:30.496505 29630 solver.cpp:237] Iteration 34240, loss = 3.66252
I0123 21:21:30.496543 29630 solver.cpp:253]     Train net output #0: loss = 3.66252 (* 1 = 3.66252 loss)
I0123 21:21:30.496549 29630 sgd_solver.cpp:106] Iteration 34240, lr = 0.01
I0123 21:21:37.780484 29630 solver.cpp:237] Iteration 34260, loss = 3.79454
I0123 21:21:37.780524 29630 solver.cpp:253]     Train net output #0: loss = 3.79454 (* 1 = 3.79454 loss)
I0123 21:21:37.780529 29630 sgd_solver.cpp:106] Iteration 34260, lr = 0.01
I0123 21:21:45.044963 29630 solver.cpp:237] Iteration 34280, loss = 3.70123
I0123 21:21:45.045001 29630 solver.cpp:253]     Train net output #0: loss = 3.70123 (* 1 = 3.70123 loss)
I0123 21:21:45.045008 29630 sgd_solver.cpp:106] Iteration 34280, lr = 0.01
I0123 21:21:52.295147 29630 solver.cpp:237] Iteration 34300, loss = 3.59606
I0123 21:21:52.295310 29630 solver.cpp:253]     Train net output #0: loss = 3.59606 (* 1 = 3.59606 loss)
I0123 21:21:52.295318 29630 sgd_solver.cpp:106] Iteration 34300, lr = 0.01
I0123 21:21:59.564149 29630 solver.cpp:237] Iteration 34320, loss = 3.59361
I0123 21:21:59.564185 29630 solver.cpp:253]     Train net output #0: loss = 3.59361 (* 1 = 3.59361 loss)
I0123 21:21:59.564191 29630 sgd_solver.cpp:106] Iteration 34320, lr = 0.01
I0123 21:22:06.796916 29630 solver.cpp:237] Iteration 34340, loss = 3.56843
I0123 21:22:06.796955 29630 solver.cpp:253]     Train net output #0: loss = 3.56843 (* 1 = 3.56843 loss)
I0123 21:22:06.796962 29630 sgd_solver.cpp:106] Iteration 34340, lr = 0.01
I0123 21:22:14.054783 29630 solver.cpp:237] Iteration 34360, loss = 3.50519
I0123 21:22:14.054822 29630 solver.cpp:253]     Train net output #0: loss = 3.50519 (* 1 = 3.50519 loss)
I0123 21:22:14.054829 29630 sgd_solver.cpp:106] Iteration 34360, lr = 0.01
I0123 21:22:21.276113 29630 solver.cpp:237] Iteration 34380, loss = 3.67178
I0123 21:22:21.276151 29630 solver.cpp:253]     Train net output #0: loss = 3.67178 (* 1 = 3.67178 loss)
I0123 21:22:21.276160 29630 sgd_solver.cpp:106] Iteration 34380, lr = 0.01
I0123 21:22:28.548377 29630 solver.cpp:237] Iteration 34400, loss = 3.59598
I0123 21:22:28.548486 29630 solver.cpp:253]     Train net output #0: loss = 3.59598 (* 1 = 3.59598 loss)
I0123 21:22:28.548503 29630 sgd_solver.cpp:106] Iteration 34400, lr = 0.01
I0123 21:22:35.772073 29630 solver.cpp:237] Iteration 34420, loss = 3.61175
I0123 21:22:35.772111 29630 solver.cpp:253]     Train net output #0: loss = 3.61175 (* 1 = 3.61175 loss)
I0123 21:22:35.772117 29630 sgd_solver.cpp:106] Iteration 34420, lr = 0.01
I0123 21:22:43.053184 29630 solver.cpp:237] Iteration 34440, loss = 3.52124
I0123 21:22:43.053223 29630 solver.cpp:253]     Train net output #0: loss = 3.52124 (* 1 = 3.52124 loss)
I0123 21:22:43.053230 29630 sgd_solver.cpp:106] Iteration 34440, lr = 0.01
I0123 21:22:50.316112 29630 solver.cpp:237] Iteration 34460, loss = 3.53879
I0123 21:22:50.316150 29630 solver.cpp:253]     Train net output #0: loss = 3.53879 (* 1 = 3.53879 loss)
I0123 21:22:50.316156 29630 sgd_solver.cpp:106] Iteration 34460, lr = 0.01
I0123 21:22:57.518654 29630 solver.cpp:237] Iteration 34480, loss = 3.5164
I0123 21:22:57.518693 29630 solver.cpp:253]     Train net output #0: loss = 3.5164 (* 1 = 3.5164 loss)
I0123 21:22:57.518699 29630 sgd_solver.cpp:106] Iteration 34480, lr = 0.01
I0123 21:23:04.777427 29630 solver.cpp:237] Iteration 34500, loss = 3.43877
I0123 21:23:04.777606 29630 solver.cpp:253]     Train net output #0: loss = 3.43877 (* 1 = 3.43877 loss)
I0123 21:23:04.777614 29630 sgd_solver.cpp:106] Iteration 34500, lr = 0.01
I0123 21:23:12.068789 29630 solver.cpp:237] Iteration 34520, loss = 3.59011
I0123 21:23:12.068830 29630 solver.cpp:253]     Train net output #0: loss = 3.59011 (* 1 = 3.59011 loss)
I0123 21:23:12.068835 29630 sgd_solver.cpp:106] Iteration 34520, lr = 0.01
I0123 21:23:19.333350 29630 solver.cpp:237] Iteration 34540, loss = 3.58059
I0123 21:23:19.333389 29630 solver.cpp:253]     Train net output #0: loss = 3.58059 (* 1 = 3.58059 loss)
I0123 21:23:19.333395 29630 sgd_solver.cpp:106] Iteration 34540, lr = 0.01
I0123 21:23:26.578841 29630 solver.cpp:237] Iteration 34560, loss = 3.60605
I0123 21:23:26.578881 29630 solver.cpp:253]     Train net output #0: loss = 3.60605 (* 1 = 3.60605 loss)
I0123 21:23:26.578886 29630 sgd_solver.cpp:106] Iteration 34560, lr = 0.01
I0123 21:23:33.799067 29630 solver.cpp:237] Iteration 34580, loss = 4.06027
I0123 21:23:33.799105 29630 solver.cpp:253]     Train net output #0: loss = 4.06027 (* 1 = 4.06027 loss)
I0123 21:23:33.799111 29630 sgd_solver.cpp:106] Iteration 34580, lr = 0.01
I0123 21:23:41.054874 29630 solver.cpp:237] Iteration 34600, loss = 3.8743
I0123 21:23:41.055006 29630 solver.cpp:253]     Train net output #0: loss = 3.8743 (* 1 = 3.8743 loss)
I0123 21:23:41.055013 29630 sgd_solver.cpp:106] Iteration 34600, lr = 0.01
I0123 21:23:48.275913 29630 solver.cpp:237] Iteration 34620, loss = 3.64092
I0123 21:23:48.275951 29630 solver.cpp:253]     Train net output #0: loss = 3.64092 (* 1 = 3.64092 loss)
I0123 21:23:48.275957 29630 sgd_solver.cpp:106] Iteration 34620, lr = 0.01
I0123 21:23:55.530804 29630 solver.cpp:237] Iteration 34640, loss = 3.27936
I0123 21:23:55.530843 29630 solver.cpp:253]     Train net output #0: loss = 3.27936 (* 1 = 3.27936 loss)
I0123 21:23:55.530850 29630 sgd_solver.cpp:106] Iteration 34640, lr = 0.01
I0123 21:24:02.811666 29630 solver.cpp:237] Iteration 34660, loss = 3.35842
I0123 21:24:02.811703 29630 solver.cpp:253]     Train net output #0: loss = 3.35842 (* 1 = 3.35842 loss)
I0123 21:24:02.811709 29630 sgd_solver.cpp:106] Iteration 34660, lr = 0.01
I0123 21:24:10.044939 29630 solver.cpp:237] Iteration 34680, loss = 3.67144
I0123 21:24:10.044980 29630 solver.cpp:253]     Train net output #0: loss = 3.67144 (* 1 = 3.67144 loss)
I0123 21:24:10.044986 29630 sgd_solver.cpp:106] Iteration 34680, lr = 0.01
I0123 21:24:17.331828 29630 solver.cpp:237] Iteration 34700, loss = 3.41869
I0123 21:24:17.331950 29630 solver.cpp:253]     Train net output #0: loss = 3.41869 (* 1 = 3.41869 loss)
I0123 21:24:17.331966 29630 sgd_solver.cpp:106] Iteration 34700, lr = 0.01
I0123 21:24:24.600849 29630 solver.cpp:237] Iteration 34720, loss = 3.79774
I0123 21:24:24.600888 29630 solver.cpp:253]     Train net output #0: loss = 3.79774 (* 1 = 3.79774 loss)
I0123 21:24:24.600894 29630 sgd_solver.cpp:106] Iteration 34720, lr = 0.01
I0123 21:24:31.853117 29630 solver.cpp:237] Iteration 34740, loss = 3.42187
I0123 21:24:31.853155 29630 solver.cpp:253]     Train net output #0: loss = 3.42187 (* 1 = 3.42187 loss)
I0123 21:24:31.853162 29630 sgd_solver.cpp:106] Iteration 34740, lr = 0.01
I0123 21:24:39.181583 29630 solver.cpp:237] Iteration 34760, loss = 3.63679
I0123 21:24:39.181620 29630 solver.cpp:253]     Train net output #0: loss = 3.63679 (* 1 = 3.63679 loss)
I0123 21:24:39.181627 29630 sgd_solver.cpp:106] Iteration 34760, lr = 0.01
I0123 21:24:46.432219 29630 solver.cpp:237] Iteration 34780, loss = 3.65233
I0123 21:24:46.432281 29630 solver.cpp:253]     Train net output #0: loss = 3.65233 (* 1 = 3.65233 loss)
I0123 21:24:46.432293 29630 sgd_solver.cpp:106] Iteration 34780, lr = 0.01
I0123 21:24:53.701316 29630 solver.cpp:237] Iteration 34800, loss = 3.5488
I0123 21:24:53.701443 29630 solver.cpp:253]     Train net output #0: loss = 3.5488 (* 1 = 3.5488 loss)
I0123 21:24:53.701452 29630 sgd_solver.cpp:106] Iteration 34800, lr = 0.01
I0123 21:25:01.007333 29630 solver.cpp:237] Iteration 34820, loss = 3.82571
I0123 21:25:01.007372 29630 solver.cpp:253]     Train net output #0: loss = 3.82571 (* 1 = 3.82571 loss)
I0123 21:25:01.007378 29630 sgd_solver.cpp:106] Iteration 34820, lr = 0.01
I0123 21:25:08.255544 29630 solver.cpp:237] Iteration 34840, loss = 3.54201
I0123 21:25:08.255583 29630 solver.cpp:253]     Train net output #0: loss = 3.54201 (* 1 = 3.54201 loss)
I0123 21:25:08.255589 29630 sgd_solver.cpp:106] Iteration 34840, lr = 0.01
I0123 21:25:15.473618 29630 solver.cpp:237] Iteration 34860, loss = 3.63423
I0123 21:25:15.473656 29630 solver.cpp:253]     Train net output #0: loss = 3.63423 (* 1 = 3.63423 loss)
I0123 21:25:15.473662 29630 sgd_solver.cpp:106] Iteration 34860, lr = 0.01
I0123 21:25:22.823879 29630 solver.cpp:237] Iteration 34880, loss = 3.57695
I0123 21:25:22.823935 29630 solver.cpp:253]     Train net output #0: loss = 3.57695 (* 1 = 3.57695 loss)
I0123 21:25:22.823946 29630 sgd_solver.cpp:106] Iteration 34880, lr = 0.01
I0123 21:25:30.087131 29630 solver.cpp:237] Iteration 34900, loss = 3.72256
I0123 21:25:30.087261 29630 solver.cpp:253]     Train net output #0: loss = 3.72256 (* 1 = 3.72256 loss)
I0123 21:25:30.087271 29630 sgd_solver.cpp:106] Iteration 34900, lr = 0.01
I0123 21:25:37.353653 29630 solver.cpp:237] Iteration 34920, loss = 3.69148
I0123 21:25:37.353693 29630 solver.cpp:253]     Train net output #0: loss = 3.69148 (* 1 = 3.69148 loss)
I0123 21:25:37.353698 29630 sgd_solver.cpp:106] Iteration 34920, lr = 0.01
I0123 21:25:44.624573 29630 solver.cpp:237] Iteration 34940, loss = 3.62376
I0123 21:25:44.624613 29630 solver.cpp:253]     Train net output #0: loss = 3.62376 (* 1 = 3.62376 loss)
I0123 21:25:44.624619 29630 sgd_solver.cpp:106] Iteration 34940, lr = 0.01
I0123 21:25:51.962316 29630 solver.cpp:237] Iteration 34960, loss = 3.51531
I0123 21:25:51.962355 29630 solver.cpp:253]     Train net output #0: loss = 3.51531 (* 1 = 3.51531 loss)
I0123 21:25:51.962362 29630 sgd_solver.cpp:106] Iteration 34960, lr = 0.01
I0123 21:25:59.236963 29630 solver.cpp:237] Iteration 34980, loss = 3.7388
I0123 21:25:59.236991 29630 solver.cpp:253]     Train net output #0: loss = 3.7388 (* 1 = 3.7388 loss)
I0123 21:25:59.236999 29630 sgd_solver.cpp:106] Iteration 34980, lr = 0.01
I0123 21:26:06.242686 29630 solver.cpp:341] Iteration 35000, Testing net (#0)
I0123 21:26:21.527122 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 21:27:19.994469 29630 solver.cpp:409]     Test net output #0: accuracy = 0.28154
I0123 21:27:19.994622 29630 solver.cpp:409]     Test net output #1: loss = 3.4814 (* 1 = 3.4814 loss)
I0123 21:27:20.035171 29630 solver.cpp:237] Iteration 35000, loss = 3.41249
I0123 21:27:20.035198 29630 solver.cpp:253]     Train net output #0: loss = 3.41249 (* 1 = 3.41249 loss)
I0123 21:27:20.035205 29630 sgd_solver.cpp:106] Iteration 35000, lr = 0.01
I0123 21:27:26.599386 29630 solver.cpp:237] Iteration 35020, loss = 3.60936
I0123 21:27:26.599439 29630 solver.cpp:253]     Train net output #0: loss = 3.60936 (* 1 = 3.60936 loss)
I0123 21:27:26.599447 29630 sgd_solver.cpp:106] Iteration 35020, lr = 0.01
I0123 21:27:33.910614 29630 solver.cpp:237] Iteration 35040, loss = 3.61811
I0123 21:27:33.910658 29630 solver.cpp:253]     Train net output #0: loss = 3.61811 (* 1 = 3.61811 loss)
I0123 21:27:33.910665 29630 sgd_solver.cpp:106] Iteration 35040, lr = 0.01
I0123 21:27:41.176168 29630 solver.cpp:237] Iteration 35060, loss = 3.45627
I0123 21:27:41.176208 29630 solver.cpp:253]     Train net output #0: loss = 3.45627 (* 1 = 3.45627 loss)
I0123 21:27:41.176213 29630 sgd_solver.cpp:106] Iteration 35060, lr = 0.01
I0123 21:27:48.492559 29630 solver.cpp:237] Iteration 35080, loss = 3.60032
I0123 21:27:48.492597 29630 solver.cpp:253]     Train net output #0: loss = 3.60032 (* 1 = 3.60032 loss)
I0123 21:27:48.492604 29630 sgd_solver.cpp:106] Iteration 35080, lr = 0.01
I0123 21:27:55.832428 29630 solver.cpp:237] Iteration 35100, loss = 3.51582
I0123 21:27:55.832557 29630 solver.cpp:253]     Train net output #0: loss = 3.51582 (* 1 = 3.51582 loss)
I0123 21:27:55.832566 29630 sgd_solver.cpp:106] Iteration 35100, lr = 0.01
I0123 21:28:03.165258 29630 solver.cpp:237] Iteration 35120, loss = 3.61162
I0123 21:28:03.165298 29630 solver.cpp:253]     Train net output #0: loss = 3.61162 (* 1 = 3.61162 loss)
I0123 21:28:03.165307 29630 sgd_solver.cpp:106] Iteration 35120, lr = 0.01
I0123 21:28:10.490393 29630 solver.cpp:237] Iteration 35140, loss = 3.46838
I0123 21:28:10.490430 29630 solver.cpp:253]     Train net output #0: loss = 3.46838 (* 1 = 3.46838 loss)
I0123 21:28:10.490437 29630 sgd_solver.cpp:106] Iteration 35140, lr = 0.01
I0123 21:28:17.778043 29630 solver.cpp:237] Iteration 35160, loss = 3.60367
I0123 21:28:17.778084 29630 solver.cpp:253]     Train net output #0: loss = 3.60367 (* 1 = 3.60367 loss)
I0123 21:28:17.778091 29630 sgd_solver.cpp:106] Iteration 35160, lr = 0.01
I0123 21:28:25.040205 29630 solver.cpp:237] Iteration 35180, loss = 3.70945
I0123 21:28:25.040241 29630 solver.cpp:253]     Train net output #0: loss = 3.70945 (* 1 = 3.70945 loss)
I0123 21:28:25.040248 29630 sgd_solver.cpp:106] Iteration 35180, lr = 0.01
I0123 21:28:32.322031 29630 solver.cpp:237] Iteration 35200, loss = 3.78315
I0123 21:28:32.322211 29630 solver.cpp:253]     Train net output #0: loss = 3.78315 (* 1 = 3.78315 loss)
I0123 21:28:32.322219 29630 sgd_solver.cpp:106] Iteration 35200, lr = 0.01
I0123 21:28:36.409935 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 21:28:39.622802 29630 solver.cpp:237] Iteration 35220, loss = 3.41731
I0123 21:28:39.622841 29630 solver.cpp:253]     Train net output #0: loss = 3.41731 (* 1 = 3.41731 loss)
I0123 21:28:39.622848 29630 sgd_solver.cpp:106] Iteration 35220, lr = 0.01
I0123 21:28:46.910461 29630 solver.cpp:237] Iteration 35240, loss = 3.57348
I0123 21:28:46.910501 29630 solver.cpp:253]     Train net output #0: loss = 3.57348 (* 1 = 3.57348 loss)
I0123 21:28:46.910506 29630 sgd_solver.cpp:106] Iteration 35240, lr = 0.01
I0123 21:28:54.246510 29630 solver.cpp:237] Iteration 35260, loss = 3.63188
I0123 21:28:54.246547 29630 solver.cpp:253]     Train net output #0: loss = 3.63188 (* 1 = 3.63188 loss)
I0123 21:28:54.246553 29630 sgd_solver.cpp:106] Iteration 35260, lr = 0.01
I0123 21:29:01.508822 29630 solver.cpp:237] Iteration 35280, loss = 3.52119
I0123 21:29:01.508862 29630 solver.cpp:253]     Train net output #0: loss = 3.52119 (* 1 = 3.52119 loss)
I0123 21:29:01.508868 29630 sgd_solver.cpp:106] Iteration 35280, lr = 0.01
I0123 21:29:08.784821 29630 solver.cpp:237] Iteration 35300, loss = 3.43494
I0123 21:29:08.784997 29630 solver.cpp:253]     Train net output #0: loss = 3.43494 (* 1 = 3.43494 loss)
I0123 21:29:08.785006 29630 sgd_solver.cpp:106] Iteration 35300, lr = 0.01
I0123 21:29:16.119081 29630 solver.cpp:237] Iteration 35320, loss = 3.65508
I0123 21:29:16.119125 29630 solver.cpp:253]     Train net output #0: loss = 3.65508 (* 1 = 3.65508 loss)
I0123 21:29:16.119133 29630 sgd_solver.cpp:106] Iteration 35320, lr = 0.01
I0123 21:29:23.371829 29630 solver.cpp:237] Iteration 35340, loss = 3.80371
I0123 21:29:23.371912 29630 solver.cpp:253]     Train net output #0: loss = 3.80371 (* 1 = 3.80371 loss)
I0123 21:29:23.371933 29630 sgd_solver.cpp:106] Iteration 35340, lr = 0.01
I0123 21:29:30.689064 29630 solver.cpp:237] Iteration 35360, loss = 3.6511
I0123 21:29:30.689102 29630 solver.cpp:253]     Train net output #0: loss = 3.6511 (* 1 = 3.6511 loss)
I0123 21:29:30.689108 29630 sgd_solver.cpp:106] Iteration 35360, lr = 0.01
I0123 21:29:37.963667 29630 solver.cpp:237] Iteration 35380, loss = 3.42745
I0123 21:29:37.963706 29630 solver.cpp:253]     Train net output #0: loss = 3.42745 (* 1 = 3.42745 loss)
I0123 21:29:37.963713 29630 sgd_solver.cpp:106] Iteration 35380, lr = 0.01
I0123 21:29:45.269340 29630 solver.cpp:237] Iteration 35400, loss = 3.65351
I0123 21:29:45.269521 29630 solver.cpp:253]     Train net output #0: loss = 3.65351 (* 1 = 3.65351 loss)
I0123 21:29:45.269531 29630 sgd_solver.cpp:106] Iteration 35400, lr = 0.01
I0123 21:29:52.516322 29630 solver.cpp:237] Iteration 35420, loss = 3.41886
I0123 21:29:52.516362 29630 solver.cpp:253]     Train net output #0: loss = 3.41886 (* 1 = 3.41886 loss)
I0123 21:29:52.516368 29630 sgd_solver.cpp:106] Iteration 35420, lr = 0.01
I0123 21:29:59.753046 29630 solver.cpp:237] Iteration 35440, loss = 3.42327
I0123 21:29:59.753087 29630 solver.cpp:253]     Train net output #0: loss = 3.42327 (* 1 = 3.42327 loss)
I0123 21:29:59.753093 29630 sgd_solver.cpp:106] Iteration 35440, lr = 0.01
I0123 21:30:06.984752 29630 solver.cpp:237] Iteration 35460, loss = 3.80082
I0123 21:30:06.984791 29630 solver.cpp:253]     Train net output #0: loss = 3.80082 (* 1 = 3.80082 loss)
I0123 21:30:06.984797 29630 sgd_solver.cpp:106] Iteration 35460, lr = 0.01
I0123 21:30:14.243171 29630 solver.cpp:237] Iteration 35480, loss = 3.34602
I0123 21:30:14.243209 29630 solver.cpp:253]     Train net output #0: loss = 3.34602 (* 1 = 3.34602 loss)
I0123 21:30:14.243216 29630 sgd_solver.cpp:106] Iteration 35480, lr = 0.01
I0123 21:30:21.506681 29630 solver.cpp:237] Iteration 35500, loss = 3.59264
I0123 21:30:21.506806 29630 solver.cpp:253]     Train net output #0: loss = 3.59264 (* 1 = 3.59264 loss)
I0123 21:30:21.506814 29630 sgd_solver.cpp:106] Iteration 35500, lr = 0.01
I0123 21:30:28.792578 29630 solver.cpp:237] Iteration 35520, loss = 3.51787
I0123 21:30:28.792618 29630 solver.cpp:253]     Train net output #0: loss = 3.51787 (* 1 = 3.51787 loss)
I0123 21:30:28.792623 29630 sgd_solver.cpp:106] Iteration 35520, lr = 0.01
I0123 21:30:36.008800 29630 solver.cpp:237] Iteration 35540, loss = 3.64013
I0123 21:30:36.008837 29630 solver.cpp:253]     Train net output #0: loss = 3.64013 (* 1 = 3.64013 loss)
I0123 21:30:36.008843 29630 sgd_solver.cpp:106] Iteration 35540, lr = 0.01
I0123 21:30:43.266970 29630 solver.cpp:237] Iteration 35560, loss = 3.6315
I0123 21:30:43.267010 29630 solver.cpp:253]     Train net output #0: loss = 3.6315 (* 1 = 3.6315 loss)
I0123 21:30:43.267016 29630 sgd_solver.cpp:106] Iteration 35560, lr = 0.01
I0123 21:30:50.464565 29630 solver.cpp:237] Iteration 35580, loss = 3.65647
I0123 21:30:50.464604 29630 solver.cpp:253]     Train net output #0: loss = 3.65647 (* 1 = 3.65647 loss)
I0123 21:30:50.464610 29630 sgd_solver.cpp:106] Iteration 35580, lr = 0.01
I0123 21:30:57.745457 29630 solver.cpp:237] Iteration 35600, loss = 3.52806
I0123 21:30:57.745579 29630 solver.cpp:253]     Train net output #0: loss = 3.52806 (* 1 = 3.52806 loss)
I0123 21:30:57.745586 29630 sgd_solver.cpp:106] Iteration 35600, lr = 0.01
I0123 21:31:05.014483 29630 solver.cpp:237] Iteration 35620, loss = 3.67136
I0123 21:31:05.014523 29630 solver.cpp:253]     Train net output #0: loss = 3.67136 (* 1 = 3.67136 loss)
I0123 21:31:05.014530 29630 sgd_solver.cpp:106] Iteration 35620, lr = 0.01
I0123 21:31:12.310745 29630 solver.cpp:237] Iteration 35640, loss = 3.62007
I0123 21:31:12.310784 29630 solver.cpp:253]     Train net output #0: loss = 3.62007 (* 1 = 3.62007 loss)
I0123 21:31:12.310791 29630 sgd_solver.cpp:106] Iteration 35640, lr = 0.01
I0123 21:31:19.608523 29630 solver.cpp:237] Iteration 35660, loss = 3.77547
I0123 21:31:19.608562 29630 solver.cpp:253]     Train net output #0: loss = 3.77547 (* 1 = 3.77547 loss)
I0123 21:31:19.608568 29630 sgd_solver.cpp:106] Iteration 35660, lr = 0.01
I0123 21:31:26.803953 29630 solver.cpp:237] Iteration 35680, loss = 3.62553
I0123 21:31:26.803982 29630 solver.cpp:253]     Train net output #0: loss = 3.62553 (* 1 = 3.62553 loss)
I0123 21:31:26.803989 29630 sgd_solver.cpp:106] Iteration 35680, lr = 0.01
I0123 21:31:34.127187 29630 solver.cpp:237] Iteration 35700, loss = 3.64915
I0123 21:31:34.127286 29630 solver.cpp:253]     Train net output #0: loss = 3.64915 (* 1 = 3.64915 loss)
I0123 21:31:34.127293 29630 sgd_solver.cpp:106] Iteration 35700, lr = 0.01
I0123 21:31:41.375694 29630 solver.cpp:237] Iteration 35720, loss = 3.55516
I0123 21:31:41.375735 29630 solver.cpp:253]     Train net output #0: loss = 3.55516 (* 1 = 3.55516 loss)
I0123 21:31:41.375741 29630 sgd_solver.cpp:106] Iteration 35720, lr = 0.01
I0123 21:31:48.600564 29630 solver.cpp:237] Iteration 35740, loss = 3.65773
I0123 21:31:48.600601 29630 solver.cpp:253]     Train net output #0: loss = 3.65773 (* 1 = 3.65773 loss)
I0123 21:31:48.600607 29630 sgd_solver.cpp:106] Iteration 35740, lr = 0.01
I0123 21:31:55.875977 29630 solver.cpp:237] Iteration 35760, loss = 3.56009
I0123 21:31:55.876015 29630 solver.cpp:253]     Train net output #0: loss = 3.56009 (* 1 = 3.56009 loss)
I0123 21:31:55.876021 29630 sgd_solver.cpp:106] Iteration 35760, lr = 0.01
I0123 21:32:03.124605 29630 solver.cpp:237] Iteration 35780, loss = 3.5458
I0123 21:32:03.124644 29630 solver.cpp:253]     Train net output #0: loss = 3.5458 (* 1 = 3.5458 loss)
I0123 21:32:03.124650 29630 sgd_solver.cpp:106] Iteration 35780, lr = 0.01
I0123 21:32:10.392000 29630 solver.cpp:237] Iteration 35800, loss = 3.78174
I0123 21:32:10.392124 29630 solver.cpp:253]     Train net output #0: loss = 3.78174 (* 1 = 3.78174 loss)
I0123 21:32:10.392132 29630 sgd_solver.cpp:106] Iteration 35800, lr = 0.01
I0123 21:32:17.639204 29630 solver.cpp:237] Iteration 35820, loss = 3.46225
I0123 21:32:17.639241 29630 solver.cpp:253]     Train net output #0: loss = 3.46225 (* 1 = 3.46225 loss)
I0123 21:32:17.639248 29630 sgd_solver.cpp:106] Iteration 35820, lr = 0.01
I0123 21:32:24.871304 29630 solver.cpp:237] Iteration 35840, loss = 3.92398
I0123 21:32:24.871342 29630 solver.cpp:253]     Train net output #0: loss = 3.92398 (* 1 = 3.92398 loss)
I0123 21:32:24.871348 29630 sgd_solver.cpp:106] Iteration 35840, lr = 0.01
I0123 21:32:32.182766 29630 solver.cpp:237] Iteration 35860, loss = 3.64849
I0123 21:32:32.182807 29630 solver.cpp:253]     Train net output #0: loss = 3.64849 (* 1 = 3.64849 loss)
I0123 21:32:32.182813 29630 sgd_solver.cpp:106] Iteration 35860, lr = 0.01
I0123 21:32:39.479820 29630 solver.cpp:237] Iteration 35880, loss = 3.79982
I0123 21:32:39.479858 29630 solver.cpp:253]     Train net output #0: loss = 3.79982 (* 1 = 3.79982 loss)
I0123 21:32:39.479864 29630 sgd_solver.cpp:106] Iteration 35880, lr = 0.01
I0123 21:32:46.727892 29630 solver.cpp:237] Iteration 35900, loss = 3.50938
I0123 21:32:46.728044 29630 solver.cpp:253]     Train net output #0: loss = 3.50938 (* 1 = 3.50938 loss)
I0123 21:32:46.728052 29630 sgd_solver.cpp:106] Iteration 35900, lr = 0.01
I0123 21:32:54.012933 29630 solver.cpp:237] Iteration 35920, loss = 3.71668
I0123 21:32:54.012972 29630 solver.cpp:253]     Train net output #0: loss = 3.71668 (* 1 = 3.71668 loss)
I0123 21:32:54.012979 29630 sgd_solver.cpp:106] Iteration 35920, lr = 0.01
I0123 21:33:01.259594 29630 solver.cpp:237] Iteration 35940, loss = 3.61099
I0123 21:33:01.259634 29630 solver.cpp:253]     Train net output #0: loss = 3.61099 (* 1 = 3.61099 loss)
I0123 21:33:01.259640 29630 sgd_solver.cpp:106] Iteration 35940, lr = 0.01
I0123 21:33:08.514612 29630 solver.cpp:237] Iteration 35960, loss = 3.53023
I0123 21:33:08.514652 29630 solver.cpp:253]     Train net output #0: loss = 3.53023 (* 1 = 3.53023 loss)
I0123 21:33:08.514658 29630 sgd_solver.cpp:106] Iteration 35960, lr = 0.01
I0123 21:33:15.797588 29630 solver.cpp:237] Iteration 35980, loss = 3.34759
I0123 21:33:15.797627 29630 solver.cpp:253]     Train net output #0: loss = 3.34759 (* 1 = 3.34759 loss)
I0123 21:33:15.797633 29630 sgd_solver.cpp:106] Iteration 35980, lr = 0.01
I0123 21:33:22.771631 29630 solver.cpp:341] Iteration 36000, Testing net (#0)
I0123 21:33:38.561192 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 21:34:36.618989 29630 solver.cpp:409]     Test net output #0: accuracy = 0.27642
I0123 21:34:36.619148 29630 solver.cpp:409]     Test net output #1: loss = 3.5177 (* 1 = 3.5177 loss)
I0123 21:34:36.659684 29630 solver.cpp:237] Iteration 36000, loss = 3.71623
I0123 21:34:36.659713 29630 solver.cpp:253]     Train net output #0: loss = 3.71623 (* 1 = 3.71623 loss)
I0123 21:34:36.659719 29630 sgd_solver.cpp:106] Iteration 36000, lr = 0.01
I0123 21:34:43.161294 29630 solver.cpp:237] Iteration 36020, loss = 3.76701
I0123 21:34:43.161334 29630 solver.cpp:253]     Train net output #0: loss = 3.76701 (* 1 = 3.76701 loss)
I0123 21:34:43.161339 29630 sgd_solver.cpp:106] Iteration 36020, lr = 0.01
I0123 21:34:50.427856 29630 solver.cpp:237] Iteration 36040, loss = 3.78741
I0123 21:34:50.427894 29630 solver.cpp:253]     Train net output #0: loss = 3.78741 (* 1 = 3.78741 loss)
I0123 21:34:50.427901 29630 sgd_solver.cpp:106] Iteration 36040, lr = 0.01
I0123 21:34:57.678347 29630 solver.cpp:237] Iteration 36060, loss = 3.59269
I0123 21:34:57.678387 29630 solver.cpp:253]     Train net output #0: loss = 3.59269 (* 1 = 3.59269 loss)
I0123 21:34:57.678393 29630 sgd_solver.cpp:106] Iteration 36060, lr = 0.01
I0123 21:35:04.897280 29630 solver.cpp:237] Iteration 36080, loss = 3.59679
I0123 21:35:04.897328 29630 solver.cpp:253]     Train net output #0: loss = 3.59679 (* 1 = 3.59679 loss)
I0123 21:35:04.897335 29630 sgd_solver.cpp:106] Iteration 36080, lr = 0.01
I0123 21:35:12.167397 29630 solver.cpp:237] Iteration 36100, loss = 3.51985
I0123 21:35:12.167522 29630 solver.cpp:253]     Train net output #0: loss = 3.51985 (* 1 = 3.51985 loss)
I0123 21:35:12.167531 29630 sgd_solver.cpp:106] Iteration 36100, lr = 0.01
I0123 21:35:19.420614 29630 solver.cpp:237] Iteration 36120, loss = 3.77075
I0123 21:35:19.420651 29630 solver.cpp:253]     Train net output #0: loss = 3.77075 (* 1 = 3.77075 loss)
I0123 21:35:19.420657 29630 sgd_solver.cpp:106] Iteration 36120, lr = 0.01
I0123 21:35:26.691727 29630 solver.cpp:237] Iteration 36140, loss = 3.75697
I0123 21:35:26.691766 29630 solver.cpp:253]     Train net output #0: loss = 3.75697 (* 1 = 3.75697 loss)
I0123 21:35:26.691771 29630 sgd_solver.cpp:106] Iteration 36140, lr = 0.01
I0123 21:35:33.935632 29630 solver.cpp:237] Iteration 36160, loss = 3.5173
I0123 21:35:33.935670 29630 solver.cpp:253]     Train net output #0: loss = 3.5173 (* 1 = 3.5173 loss)
I0123 21:35:33.935677 29630 sgd_solver.cpp:106] Iteration 36160, lr = 0.01
I0123 21:35:41.195137 29630 solver.cpp:237] Iteration 36180, loss = 3.50819
I0123 21:35:41.195175 29630 solver.cpp:253]     Train net output #0: loss = 3.50819 (* 1 = 3.50819 loss)
I0123 21:35:41.195180 29630 sgd_solver.cpp:106] Iteration 36180, lr = 0.01
I0123 21:35:48.455536 29630 solver.cpp:237] Iteration 36200, loss = 3.72019
I0123 21:35:48.455669 29630 solver.cpp:253]     Train net output #0: loss = 3.72019 (* 1 = 3.72019 loss)
I0123 21:35:48.455687 29630 sgd_solver.cpp:106] Iteration 36200, lr = 0.01
I0123 21:35:54.698972 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 21:35:55.710892 29630 solver.cpp:237] Iteration 36220, loss = 3.60537
I0123 21:35:55.710930 29630 solver.cpp:253]     Train net output #0: loss = 3.60537 (* 1 = 3.60537 loss)
I0123 21:35:55.710937 29630 sgd_solver.cpp:106] Iteration 36220, lr = 0.01
I0123 21:36:02.982553 29630 solver.cpp:237] Iteration 36240, loss = 3.45475
I0123 21:36:02.982599 29630 solver.cpp:253]     Train net output #0: loss = 3.45475 (* 1 = 3.45475 loss)
I0123 21:36:02.982606 29630 sgd_solver.cpp:106] Iteration 36240, lr = 0.01
I0123 21:36:10.227885 29630 solver.cpp:237] Iteration 36260, loss = 3.49095
I0123 21:36:10.227923 29630 solver.cpp:253]     Train net output #0: loss = 3.49095 (* 1 = 3.49095 loss)
I0123 21:36:10.227929 29630 sgd_solver.cpp:106] Iteration 36260, lr = 0.01
I0123 21:36:17.558293 29630 solver.cpp:237] Iteration 36280, loss = 3.66019
I0123 21:36:17.558332 29630 solver.cpp:253]     Train net output #0: loss = 3.66019 (* 1 = 3.66019 loss)
I0123 21:36:17.558338 29630 sgd_solver.cpp:106] Iteration 36280, lr = 0.01
I0123 21:36:24.858474 29630 solver.cpp:237] Iteration 36300, loss = 3.46431
I0123 21:36:24.858621 29630 solver.cpp:253]     Train net output #0: loss = 3.46431 (* 1 = 3.46431 loss)
I0123 21:36:24.858629 29630 sgd_solver.cpp:106] Iteration 36300, lr = 0.01
I0123 21:36:32.126935 29630 solver.cpp:237] Iteration 36320, loss = 3.70132
I0123 21:36:32.126971 29630 solver.cpp:253]     Train net output #0: loss = 3.70132 (* 1 = 3.70132 loss)
I0123 21:36:32.126977 29630 sgd_solver.cpp:106] Iteration 36320, lr = 0.01
I0123 21:36:39.406210 29630 solver.cpp:237] Iteration 36340, loss = 3.48497
I0123 21:36:39.406250 29630 solver.cpp:253]     Train net output #0: loss = 3.48497 (* 1 = 3.48497 loss)
I0123 21:36:39.406256 29630 sgd_solver.cpp:106] Iteration 36340, lr = 0.01
I0123 21:36:46.684160 29630 solver.cpp:237] Iteration 36360, loss = 3.68055
I0123 21:36:46.684198 29630 solver.cpp:253]     Train net output #0: loss = 3.68055 (* 1 = 3.68055 loss)
I0123 21:36:46.684204 29630 sgd_solver.cpp:106] Iteration 36360, lr = 0.01
I0123 21:36:53.962995 29630 solver.cpp:237] Iteration 36380, loss = 3.34025
I0123 21:36:53.963034 29630 solver.cpp:253]     Train net output #0: loss = 3.34025 (* 1 = 3.34025 loss)
I0123 21:36:53.963040 29630 sgd_solver.cpp:106] Iteration 36380, lr = 0.01
I0123 21:37:01.220506 29630 solver.cpp:237] Iteration 36400, loss = 3.4651
I0123 21:37:01.220670 29630 solver.cpp:253]     Train net output #0: loss = 3.4651 (* 1 = 3.4651 loss)
I0123 21:37:01.220679 29630 sgd_solver.cpp:106] Iteration 36400, lr = 0.01
I0123 21:37:08.498745 29630 solver.cpp:237] Iteration 36420, loss = 3.55441
I0123 21:37:08.498783 29630 solver.cpp:253]     Train net output #0: loss = 3.55441 (* 1 = 3.55441 loss)
I0123 21:37:08.498790 29630 sgd_solver.cpp:106] Iteration 36420, lr = 0.01
I0123 21:37:15.785441 29630 solver.cpp:237] Iteration 36440, loss = 3.72539
I0123 21:37:15.785480 29630 solver.cpp:253]     Train net output #0: loss = 3.72539 (* 1 = 3.72539 loss)
I0123 21:37:15.785486 29630 sgd_solver.cpp:106] Iteration 36440, lr = 0.01
I0123 21:37:23.041781 29630 solver.cpp:237] Iteration 36460, loss = 3.6936
I0123 21:37:23.041821 29630 solver.cpp:253]     Train net output #0: loss = 3.6936 (* 1 = 3.6936 loss)
I0123 21:37:23.041828 29630 sgd_solver.cpp:106] Iteration 36460, lr = 0.01
I0123 21:37:30.345356 29630 solver.cpp:237] Iteration 36480, loss = 3.73398
I0123 21:37:30.345394 29630 solver.cpp:253]     Train net output #0: loss = 3.73398 (* 1 = 3.73398 loss)
I0123 21:37:30.345401 29630 sgd_solver.cpp:106] Iteration 36480, lr = 0.01
I0123 21:37:37.546816 29630 solver.cpp:237] Iteration 36500, loss = 3.53815
I0123 21:37:37.546916 29630 solver.cpp:253]     Train net output #0: loss = 3.53815 (* 1 = 3.53815 loss)
I0123 21:37:37.546932 29630 sgd_solver.cpp:106] Iteration 36500, lr = 0.01
I0123 21:37:44.796453 29630 solver.cpp:237] Iteration 36520, loss = 3.77868
I0123 21:37:44.796492 29630 solver.cpp:253]     Train net output #0: loss = 3.77868 (* 1 = 3.77868 loss)
I0123 21:37:44.796499 29630 sgd_solver.cpp:106] Iteration 36520, lr = 0.01
I0123 21:37:52.067163 29630 solver.cpp:237] Iteration 36540, loss = 3.79113
I0123 21:37:52.067204 29630 solver.cpp:253]     Train net output #0: loss = 3.79113 (* 1 = 3.79113 loss)
I0123 21:37:52.067212 29630 sgd_solver.cpp:106] Iteration 36540, lr = 0.01
I0123 21:37:59.323029 29630 solver.cpp:237] Iteration 36560, loss = 3.61826
I0123 21:37:59.323070 29630 solver.cpp:253]     Train net output #0: loss = 3.61826 (* 1 = 3.61826 loss)
I0123 21:37:59.323076 29630 sgd_solver.cpp:106] Iteration 36560, lr = 0.01
I0123 21:38:06.598351 29630 solver.cpp:237] Iteration 36580, loss = 3.71409
I0123 21:38:06.598390 29630 solver.cpp:253]     Train net output #0: loss = 3.71409 (* 1 = 3.71409 loss)
I0123 21:38:06.598397 29630 sgd_solver.cpp:106] Iteration 36580, lr = 0.01
I0123 21:38:13.877950 29630 solver.cpp:237] Iteration 36600, loss = 3.53661
I0123 21:38:13.878131 29630 solver.cpp:253]     Train net output #0: loss = 3.53661 (* 1 = 3.53661 loss)
I0123 21:38:13.878149 29630 sgd_solver.cpp:106] Iteration 36600, lr = 0.01
I0123 21:38:21.120434 29630 solver.cpp:237] Iteration 36620, loss = 3.73826
I0123 21:38:21.120473 29630 solver.cpp:253]     Train net output #0: loss = 3.73826 (* 1 = 3.73826 loss)
I0123 21:38:21.120481 29630 sgd_solver.cpp:106] Iteration 36620, lr = 0.01
I0123 21:38:28.382179 29630 solver.cpp:237] Iteration 36640, loss = 3.71212
I0123 21:38:28.382217 29630 solver.cpp:253]     Train net output #0: loss = 3.71212 (* 1 = 3.71212 loss)
I0123 21:38:28.382223 29630 sgd_solver.cpp:106] Iteration 36640, lr = 0.01
I0123 21:38:35.601089 29630 solver.cpp:237] Iteration 36660, loss = 3.63683
I0123 21:38:35.601127 29630 solver.cpp:253]     Train net output #0: loss = 3.63683 (* 1 = 3.63683 loss)
I0123 21:38:35.601133 29630 sgd_solver.cpp:106] Iteration 36660, lr = 0.01
I0123 21:38:42.905112 29630 solver.cpp:237] Iteration 36680, loss = 3.61492
I0123 21:38:42.905164 29630 solver.cpp:253]     Train net output #0: loss = 3.61492 (* 1 = 3.61492 loss)
I0123 21:38:42.905174 29630 sgd_solver.cpp:106] Iteration 36680, lr = 0.01
I0123 21:38:50.171896 29630 solver.cpp:237] Iteration 36700, loss = 3.85689
I0123 21:38:50.171996 29630 solver.cpp:253]     Train net output #0: loss = 3.85689 (* 1 = 3.85689 loss)
I0123 21:38:50.172013 29630 sgd_solver.cpp:106] Iteration 36700, lr = 0.01
I0123 21:38:57.410557 29630 solver.cpp:237] Iteration 36720, loss = 3.45917
I0123 21:38:57.410594 29630 solver.cpp:253]     Train net output #0: loss = 3.45917 (* 1 = 3.45917 loss)
I0123 21:38:57.410600 29630 sgd_solver.cpp:106] Iteration 36720, lr = 0.01
I0123 21:39:04.667482 29630 solver.cpp:237] Iteration 36740, loss = 3.80729
I0123 21:39:04.667520 29630 solver.cpp:253]     Train net output #0: loss = 3.80729 (* 1 = 3.80729 loss)
I0123 21:39:04.667526 29630 sgd_solver.cpp:106] Iteration 36740, lr = 0.01
I0123 21:39:11.898273 29630 solver.cpp:237] Iteration 36760, loss = 3.69484
I0123 21:39:11.898339 29630 solver.cpp:253]     Train net output #0: loss = 3.69484 (* 1 = 3.69484 loss)
I0123 21:39:11.898353 29630 sgd_solver.cpp:106] Iteration 36760, lr = 0.01
I0123 21:39:19.178199 29630 solver.cpp:237] Iteration 36780, loss = 3.70579
I0123 21:39:19.178236 29630 solver.cpp:253]     Train net output #0: loss = 3.70579 (* 1 = 3.70579 loss)
I0123 21:39:19.178242 29630 sgd_solver.cpp:106] Iteration 36780, lr = 0.01
I0123 21:39:26.447810 29630 solver.cpp:237] Iteration 36800, loss = 3.50224
I0123 21:39:26.447940 29630 solver.cpp:253]     Train net output #0: loss = 3.50224 (* 1 = 3.50224 loss)
I0123 21:39:26.447947 29630 sgd_solver.cpp:106] Iteration 36800, lr = 0.01
I0123 21:39:33.681908 29630 solver.cpp:237] Iteration 36820, loss = 3.66551
I0123 21:39:33.681947 29630 solver.cpp:253]     Train net output #0: loss = 3.66551 (* 1 = 3.66551 loss)
I0123 21:39:33.681954 29630 sgd_solver.cpp:106] Iteration 36820, lr = 0.01
I0123 21:39:40.932464 29630 solver.cpp:237] Iteration 36840, loss = 3.70444
I0123 21:39:40.932504 29630 solver.cpp:253]     Train net output #0: loss = 3.70444 (* 1 = 3.70444 loss)
I0123 21:39:40.932510 29630 sgd_solver.cpp:106] Iteration 36840, lr = 0.01
I0123 21:39:48.203953 29630 solver.cpp:237] Iteration 36860, loss = 3.40751
I0123 21:39:48.203991 29630 solver.cpp:253]     Train net output #0: loss = 3.40751 (* 1 = 3.40751 loss)
I0123 21:39:48.203999 29630 sgd_solver.cpp:106] Iteration 36860, lr = 0.01
I0123 21:39:55.464776 29630 solver.cpp:237] Iteration 36880, loss = 3.4795
I0123 21:39:55.464815 29630 solver.cpp:253]     Train net output #0: loss = 3.4795 (* 1 = 3.4795 loss)
I0123 21:39:55.464823 29630 sgd_solver.cpp:106] Iteration 36880, lr = 0.01
I0123 21:40:02.707777 29630 solver.cpp:237] Iteration 36900, loss = 3.57541
I0123 21:40:02.707909 29630 solver.cpp:253]     Train net output #0: loss = 3.57541 (* 1 = 3.57541 loss)
I0123 21:40:02.707926 29630 sgd_solver.cpp:106] Iteration 36900, lr = 0.01
I0123 21:40:09.973731 29630 solver.cpp:237] Iteration 36920, loss = 3.5397
I0123 21:40:09.973772 29630 solver.cpp:253]     Train net output #0: loss = 3.5397 (* 1 = 3.5397 loss)
I0123 21:40:09.973786 29630 sgd_solver.cpp:106] Iteration 36920, lr = 0.01
I0123 21:40:17.249904 29630 solver.cpp:237] Iteration 36940, loss = 3.53791
I0123 21:40:17.249941 29630 solver.cpp:253]     Train net output #0: loss = 3.53791 (* 1 = 3.53791 loss)
I0123 21:40:17.249948 29630 sgd_solver.cpp:106] Iteration 36940, lr = 0.01
I0123 21:40:24.513860 29630 solver.cpp:237] Iteration 36960, loss = 3.55527
I0123 21:40:24.513900 29630 solver.cpp:253]     Train net output #0: loss = 3.55527 (* 1 = 3.55527 loss)
I0123 21:40:24.513907 29630 sgd_solver.cpp:106] Iteration 36960, lr = 0.01
I0123 21:40:31.796082 29630 solver.cpp:237] Iteration 36980, loss = 3.72161
I0123 21:40:31.796120 29630 solver.cpp:253]     Train net output #0: loss = 3.72161 (* 1 = 3.72161 loss)
I0123 21:40:31.796126 29630 sgd_solver.cpp:106] Iteration 36980, lr = 0.01
I0123 21:40:38.789093 29630 solver.cpp:341] Iteration 37000, Testing net (#0)
I0123 21:40:55.025609 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 21:41:52.751904 29630 solver.cpp:409]     Test net output #0: accuracy = 0.2909
I0123 21:41:52.752045 29630 solver.cpp:409]     Test net output #1: loss = 3.41496 (* 1 = 3.41496 loss)
I0123 21:41:52.792758 29630 solver.cpp:237] Iteration 37000, loss = 3.59889
I0123 21:41:52.792798 29630 solver.cpp:253]     Train net output #0: loss = 3.59889 (* 1 = 3.59889 loss)
I0123 21:41:52.792804 29630 sgd_solver.cpp:106] Iteration 37000, lr = 0.01
I0123 21:41:59.331802 29630 solver.cpp:237] Iteration 37020, loss = 3.40099
I0123 21:41:59.331841 29630 solver.cpp:253]     Train net output #0: loss = 3.40099 (* 1 = 3.40099 loss)
I0123 21:41:59.331847 29630 sgd_solver.cpp:106] Iteration 37020, lr = 0.01
I0123 21:42:06.552211 29630 solver.cpp:237] Iteration 37040, loss = 3.62952
I0123 21:42:06.552248 29630 solver.cpp:253]     Train net output #0: loss = 3.62952 (* 1 = 3.62952 loss)
I0123 21:42:06.552253 29630 sgd_solver.cpp:106] Iteration 37040, lr = 0.01
I0123 21:42:13.805248 29630 solver.cpp:237] Iteration 37060, loss = 3.58333
I0123 21:42:13.805285 29630 solver.cpp:253]     Train net output #0: loss = 3.58333 (* 1 = 3.58333 loss)
I0123 21:42:13.805291 29630 sgd_solver.cpp:106] Iteration 37060, lr = 0.01
I0123 21:42:21.081575 29630 solver.cpp:237] Iteration 37080, loss = 3.76615
I0123 21:42:21.081614 29630 solver.cpp:253]     Train net output #0: loss = 3.76615 (* 1 = 3.76615 loss)
I0123 21:42:21.081619 29630 sgd_solver.cpp:106] Iteration 37080, lr = 0.01
I0123 21:42:28.297817 29630 solver.cpp:237] Iteration 37100, loss = 3.70522
I0123 21:42:28.297978 29630 solver.cpp:253]     Train net output #0: loss = 3.70522 (* 1 = 3.70522 loss)
I0123 21:42:28.297986 29630 sgd_solver.cpp:106] Iteration 37100, lr = 0.01
I0123 21:42:35.532395 29630 solver.cpp:237] Iteration 37120, loss = 3.65783
I0123 21:42:35.532433 29630 solver.cpp:253]     Train net output #0: loss = 3.65783 (* 1 = 3.65783 loss)
I0123 21:42:35.532439 29630 sgd_solver.cpp:106] Iteration 37120, lr = 0.01
I0123 21:42:42.744227 29630 solver.cpp:237] Iteration 37140, loss = 3.81938
I0123 21:42:42.744266 29630 solver.cpp:253]     Train net output #0: loss = 3.81938 (* 1 = 3.81938 loss)
I0123 21:42:42.744271 29630 sgd_solver.cpp:106] Iteration 37140, lr = 0.01
I0123 21:42:49.981914 29630 solver.cpp:237] Iteration 37160, loss = 3.46875
I0123 21:42:49.981952 29630 solver.cpp:253]     Train net output #0: loss = 3.46875 (* 1 = 3.46875 loss)
I0123 21:42:49.981958 29630 sgd_solver.cpp:106] Iteration 37160, lr = 0.01
I0123 21:42:57.268820 29630 solver.cpp:237] Iteration 37180, loss = 3.5879
I0123 21:42:57.268858 29630 solver.cpp:253]     Train net output #0: loss = 3.5879 (* 1 = 3.5879 loss)
I0123 21:42:57.268864 29630 sgd_solver.cpp:106] Iteration 37180, lr = 0.01
I0123 21:43:04.473136 29630 solver.cpp:237] Iteration 37200, loss = 3.68623
I0123 21:43:04.473284 29630 solver.cpp:253]     Train net output #0: loss = 3.68623 (* 1 = 3.68623 loss)
I0123 21:43:04.473292 29630 sgd_solver.cpp:106] Iteration 37200, lr = 0.01
I0123 21:43:11.731215 29630 solver.cpp:237] Iteration 37220, loss = 3.52735
I0123 21:43:11.731256 29630 solver.cpp:253]     Train net output #0: loss = 3.52735 (* 1 = 3.52735 loss)
I0123 21:43:11.731261 29630 sgd_solver.cpp:106] Iteration 37220, lr = 0.01
I0123 21:43:12.887575 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 21:43:19.015789 29630 solver.cpp:237] Iteration 37240, loss = 3.63979
I0123 21:43:19.015826 29630 solver.cpp:253]     Train net output #0: loss = 3.63979 (* 1 = 3.63979 loss)
I0123 21:43:19.015832 29630 sgd_solver.cpp:106] Iteration 37240, lr = 0.01
I0123 21:43:26.215641 29630 solver.cpp:237] Iteration 37260, loss = 3.51002
I0123 21:43:26.215680 29630 solver.cpp:253]     Train net output #0: loss = 3.51002 (* 1 = 3.51002 loss)
I0123 21:43:26.215687 29630 sgd_solver.cpp:106] Iteration 37260, lr = 0.01
I0123 21:43:33.489296 29630 solver.cpp:237] Iteration 37280, loss = 3.66461
I0123 21:43:33.489342 29630 solver.cpp:253]     Train net output #0: loss = 3.66461 (* 1 = 3.66461 loss)
I0123 21:43:33.489349 29630 sgd_solver.cpp:106] Iteration 37280, lr = 0.01
I0123 21:43:40.740687 29630 solver.cpp:237] Iteration 37300, loss = 3.57668
I0123 21:43:40.740799 29630 solver.cpp:253]     Train net output #0: loss = 3.57668 (* 1 = 3.57668 loss)
I0123 21:43:40.740816 29630 sgd_solver.cpp:106] Iteration 37300, lr = 0.01
I0123 21:43:47.977447 29630 solver.cpp:237] Iteration 37320, loss = 3.63155
I0123 21:43:47.977485 29630 solver.cpp:253]     Train net output #0: loss = 3.63155 (* 1 = 3.63155 loss)
I0123 21:43:47.977491 29630 sgd_solver.cpp:106] Iteration 37320, lr = 0.01
I0123 21:43:55.239104 29630 solver.cpp:237] Iteration 37340, loss = 3.96141
I0123 21:43:55.239141 29630 solver.cpp:253]     Train net output #0: loss = 3.96141 (* 1 = 3.96141 loss)
I0123 21:43:55.239148 29630 sgd_solver.cpp:106] Iteration 37340, lr = 0.01
I0123 21:44:02.554308 29630 solver.cpp:237] Iteration 37360, loss = 3.44564
I0123 21:44:02.554347 29630 solver.cpp:253]     Train net output #0: loss = 3.44564 (* 1 = 3.44564 loss)
I0123 21:44:02.554353 29630 sgd_solver.cpp:106] Iteration 37360, lr = 0.01
I0123 21:44:09.801360 29630 solver.cpp:237] Iteration 37380, loss = 3.68181
I0123 21:44:09.801398 29630 solver.cpp:253]     Train net output #0: loss = 3.68181 (* 1 = 3.68181 loss)
I0123 21:44:09.801405 29630 sgd_solver.cpp:106] Iteration 37380, lr = 0.01
I0123 21:44:17.067472 29630 solver.cpp:237] Iteration 37400, loss = 3.52017
I0123 21:44:17.067638 29630 solver.cpp:253]     Train net output #0: loss = 3.52017 (* 1 = 3.52017 loss)
I0123 21:44:17.067646 29630 sgd_solver.cpp:106] Iteration 37400, lr = 0.01
I0123 21:44:24.345278 29630 solver.cpp:237] Iteration 37420, loss = 3.64994
I0123 21:44:24.345316 29630 solver.cpp:253]     Train net output #0: loss = 3.64994 (* 1 = 3.64994 loss)
I0123 21:44:24.345322 29630 sgd_solver.cpp:106] Iteration 37420, lr = 0.01
I0123 21:44:31.583201 29630 solver.cpp:237] Iteration 37440, loss = 3.47967
I0123 21:44:31.583248 29630 solver.cpp:253]     Train net output #0: loss = 3.47967 (* 1 = 3.47967 loss)
I0123 21:44:31.583255 29630 sgd_solver.cpp:106] Iteration 37440, lr = 0.01
I0123 21:44:38.894294 29630 solver.cpp:237] Iteration 37460, loss = 3.63713
I0123 21:44:38.894333 29630 solver.cpp:253]     Train net output #0: loss = 3.63713 (* 1 = 3.63713 loss)
I0123 21:44:38.894340 29630 sgd_solver.cpp:106] Iteration 37460, lr = 0.01
I0123 21:44:46.181829 29630 solver.cpp:237] Iteration 37480, loss = 3.89516
I0123 21:44:46.181869 29630 solver.cpp:253]     Train net output #0: loss = 3.89516 (* 1 = 3.89516 loss)
I0123 21:44:46.181875 29630 sgd_solver.cpp:106] Iteration 37480, lr = 0.01
I0123 21:44:53.472554 29630 solver.cpp:237] Iteration 37500, loss = 3.42678
I0123 21:44:53.472666 29630 solver.cpp:253]     Train net output #0: loss = 3.42678 (* 1 = 3.42678 loss)
I0123 21:44:53.472682 29630 sgd_solver.cpp:106] Iteration 37500, lr = 0.01
I0123 21:45:00.790380 29630 solver.cpp:237] Iteration 37520, loss = 3.25921
I0123 21:45:00.790422 29630 solver.cpp:253]     Train net output #0: loss = 3.25921 (* 1 = 3.25921 loss)
I0123 21:45:00.790431 29630 sgd_solver.cpp:106] Iteration 37520, lr = 0.01
I0123 21:45:08.131533 29630 solver.cpp:237] Iteration 37540, loss = 3.62225
I0123 21:45:08.131572 29630 solver.cpp:253]     Train net output #0: loss = 3.62225 (* 1 = 3.62225 loss)
I0123 21:45:08.131578 29630 sgd_solver.cpp:106] Iteration 37540, lr = 0.01
I0123 21:45:15.437237 29630 solver.cpp:237] Iteration 37560, loss = 3.63136
I0123 21:45:15.437276 29630 solver.cpp:253]     Train net output #0: loss = 3.63136 (* 1 = 3.63136 loss)
I0123 21:45:15.437283 29630 sgd_solver.cpp:106] Iteration 37560, lr = 0.01
I0123 21:45:22.733464 29630 solver.cpp:237] Iteration 37580, loss = 3.60155
I0123 21:45:22.733501 29630 solver.cpp:253]     Train net output #0: loss = 3.60155 (* 1 = 3.60155 loss)
I0123 21:45:22.733507 29630 sgd_solver.cpp:106] Iteration 37580, lr = 0.01
I0123 21:45:30.047440 29630 solver.cpp:237] Iteration 37600, loss = 3.56768
I0123 21:45:30.047585 29630 solver.cpp:253]     Train net output #0: loss = 3.56768 (* 1 = 3.56768 loss)
I0123 21:45:30.047593 29630 sgd_solver.cpp:106] Iteration 37600, lr = 0.01
I0123 21:45:37.257398 29630 solver.cpp:237] Iteration 37620, loss = 3.48185
I0123 21:45:37.257436 29630 solver.cpp:253]     Train net output #0: loss = 3.48185 (* 1 = 3.48185 loss)
I0123 21:45:37.257443 29630 sgd_solver.cpp:106] Iteration 37620, lr = 0.01
I0123 21:45:44.556737 29630 solver.cpp:237] Iteration 37640, loss = 3.54752
I0123 21:45:44.556774 29630 solver.cpp:253]     Train net output #0: loss = 3.54752 (* 1 = 3.54752 loss)
I0123 21:45:44.556782 29630 sgd_solver.cpp:106] Iteration 37640, lr = 0.01
I0123 21:45:51.746738 29630 solver.cpp:237] Iteration 37660, loss = 3.754
I0123 21:45:51.746776 29630 solver.cpp:253]     Train net output #0: loss = 3.754 (* 1 = 3.754 loss)
I0123 21:45:51.746783 29630 sgd_solver.cpp:106] Iteration 37660, lr = 0.01
I0123 21:45:59.043117 29630 solver.cpp:237] Iteration 37680, loss = 3.74731
I0123 21:45:59.043155 29630 solver.cpp:253]     Train net output #0: loss = 3.74731 (* 1 = 3.74731 loss)
I0123 21:45:59.043161 29630 sgd_solver.cpp:106] Iteration 37680, lr = 0.01
I0123 21:46:06.263650 29630 solver.cpp:237] Iteration 37700, loss = 3.6872
I0123 21:46:06.263813 29630 solver.cpp:253]     Train net output #0: loss = 3.6872 (* 1 = 3.6872 loss)
I0123 21:46:06.263821 29630 sgd_solver.cpp:106] Iteration 37700, lr = 0.01
I0123 21:46:13.515425 29630 solver.cpp:237] Iteration 37720, loss = 3.58842
I0123 21:46:13.515462 29630 solver.cpp:253]     Train net output #0: loss = 3.58842 (* 1 = 3.58842 loss)
I0123 21:46:13.515468 29630 sgd_solver.cpp:106] Iteration 37720, lr = 0.01
I0123 21:46:20.733505 29630 solver.cpp:237] Iteration 37740, loss = 3.62726
I0123 21:46:20.733542 29630 solver.cpp:253]     Train net output #0: loss = 3.62726 (* 1 = 3.62726 loss)
I0123 21:46:20.733548 29630 sgd_solver.cpp:106] Iteration 37740, lr = 0.01
I0123 21:46:27.976336 29630 solver.cpp:237] Iteration 37760, loss = 3.55051
I0123 21:46:27.976374 29630 solver.cpp:253]     Train net output #0: loss = 3.55051 (* 1 = 3.55051 loss)
I0123 21:46:27.976380 29630 sgd_solver.cpp:106] Iteration 37760, lr = 0.01
I0123 21:46:35.226755 29630 solver.cpp:237] Iteration 37780, loss = 3.76984
I0123 21:46:35.226794 29630 solver.cpp:253]     Train net output #0: loss = 3.76984 (* 1 = 3.76984 loss)
I0123 21:46:35.226799 29630 sgd_solver.cpp:106] Iteration 37780, lr = 0.01
I0123 21:46:42.481812 29630 solver.cpp:237] Iteration 37800, loss = 3.49116
I0123 21:46:42.481978 29630 solver.cpp:253]     Train net output #0: loss = 3.49116 (* 1 = 3.49116 loss)
I0123 21:46:42.481987 29630 sgd_solver.cpp:106] Iteration 37800, lr = 0.01
I0123 21:46:49.704702 29630 solver.cpp:237] Iteration 37820, loss = 3.60823
I0123 21:46:49.704741 29630 solver.cpp:253]     Train net output #0: loss = 3.60823 (* 1 = 3.60823 loss)
I0123 21:46:49.704746 29630 sgd_solver.cpp:106] Iteration 37820, lr = 0.01
I0123 21:46:56.956655 29630 solver.cpp:237] Iteration 37840, loss = 3.67874
I0123 21:46:56.956693 29630 solver.cpp:253]     Train net output #0: loss = 3.67874 (* 1 = 3.67874 loss)
I0123 21:46:56.956698 29630 sgd_solver.cpp:106] Iteration 37840, lr = 0.01
I0123 21:47:04.214674 29630 solver.cpp:237] Iteration 37860, loss = 3.47006
I0123 21:47:04.214712 29630 solver.cpp:253]     Train net output #0: loss = 3.47006 (* 1 = 3.47006 loss)
I0123 21:47:04.214720 29630 sgd_solver.cpp:106] Iteration 37860, lr = 0.01
I0123 21:47:11.429954 29630 solver.cpp:237] Iteration 37880, loss = 3.66226
I0123 21:47:11.429992 29630 solver.cpp:253]     Train net output #0: loss = 3.66226 (* 1 = 3.66226 loss)
I0123 21:47:11.429999 29630 sgd_solver.cpp:106] Iteration 37880, lr = 0.01
I0123 21:47:18.707168 29630 solver.cpp:237] Iteration 37900, loss = 3.58253
I0123 21:47:18.707280 29630 solver.cpp:253]     Train net output #0: loss = 3.58253 (* 1 = 3.58253 loss)
I0123 21:47:18.707288 29630 sgd_solver.cpp:106] Iteration 37900, lr = 0.01
I0123 21:47:25.896787 29630 solver.cpp:237] Iteration 37920, loss = 3.57488
I0123 21:47:25.896826 29630 solver.cpp:253]     Train net output #0: loss = 3.57488 (* 1 = 3.57488 loss)
I0123 21:47:25.896833 29630 sgd_solver.cpp:106] Iteration 37920, lr = 0.01
I0123 21:47:33.184818 29630 solver.cpp:237] Iteration 37940, loss = 3.5057
I0123 21:47:33.184856 29630 solver.cpp:253]     Train net output #0: loss = 3.5057 (* 1 = 3.5057 loss)
I0123 21:47:33.184864 29630 sgd_solver.cpp:106] Iteration 37940, lr = 0.01
I0123 21:47:40.402125 29630 solver.cpp:237] Iteration 37960, loss = 3.52425
I0123 21:47:40.402164 29630 solver.cpp:253]     Train net output #0: loss = 3.52425 (* 1 = 3.52425 loss)
I0123 21:47:40.402170 29630 sgd_solver.cpp:106] Iteration 37960, lr = 0.01
I0123 21:47:47.619879 29630 solver.cpp:237] Iteration 37980, loss = 3.46468
I0123 21:47:47.619917 29630 solver.cpp:253]     Train net output #0: loss = 3.46468 (* 1 = 3.46468 loss)
I0123 21:47:47.619925 29630 sgd_solver.cpp:106] Iteration 37980, lr = 0.01
I0123 21:47:54.572258 29630 solver.cpp:341] Iteration 38000, Testing net (#0)
I0123 21:48:11.211009 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 21:49:08.591634 29630 solver.cpp:409]     Test net output #0: accuracy = 0.28904
I0123 21:49:08.591783 29630 solver.cpp:409]     Test net output #1: loss = 3.4236 (* 1 = 3.4236 loss)
I0123 21:49:08.632315 29630 solver.cpp:237] Iteration 38000, loss = 3.53656
I0123 21:49:08.632354 29630 solver.cpp:253]     Train net output #0: loss = 3.53656 (* 1 = 3.53656 loss)
I0123 21:49:08.632359 29630 sgd_solver.cpp:106] Iteration 38000, lr = 0.01
I0123 21:49:15.169576 29630 solver.cpp:237] Iteration 38020, loss = 3.72567
I0123 21:49:15.169615 29630 solver.cpp:253]     Train net output #0: loss = 3.72567 (* 1 = 3.72567 loss)
I0123 21:49:15.169620 29630 sgd_solver.cpp:106] Iteration 38020, lr = 0.01
I0123 21:49:22.461880 29630 solver.cpp:237] Iteration 38040, loss = 3.58577
I0123 21:49:22.461918 29630 solver.cpp:253]     Train net output #0: loss = 3.58577 (* 1 = 3.58577 loss)
I0123 21:49:22.461925 29630 sgd_solver.cpp:106] Iteration 38040, lr = 0.01
I0123 21:49:29.753417 29630 solver.cpp:237] Iteration 38060, loss = 3.58537
I0123 21:49:29.753454 29630 solver.cpp:253]     Train net output #0: loss = 3.58537 (* 1 = 3.58537 loss)
I0123 21:49:29.753460 29630 sgd_solver.cpp:106] Iteration 38060, lr = 0.01
I0123 21:49:37.038247 29630 solver.cpp:237] Iteration 38080, loss = 3.64354
I0123 21:49:37.038286 29630 solver.cpp:253]     Train net output #0: loss = 3.64354 (* 1 = 3.64354 loss)
I0123 21:49:37.038293 29630 sgd_solver.cpp:106] Iteration 38080, lr = 0.01
I0123 21:49:44.262469 29630 solver.cpp:237] Iteration 38100, loss = 3.47052
I0123 21:49:44.262619 29630 solver.cpp:253]     Train net output #0: loss = 3.47052 (* 1 = 3.47052 loss)
I0123 21:49:44.262626 29630 sgd_solver.cpp:106] Iteration 38100, lr = 0.01
I0123 21:49:51.537950 29630 solver.cpp:237] Iteration 38120, loss = 3.50074
I0123 21:49:51.537987 29630 solver.cpp:253]     Train net output #0: loss = 3.50074 (* 1 = 3.50074 loss)
I0123 21:49:51.538004 29630 sgd_solver.cpp:106] Iteration 38120, lr = 0.01
I0123 21:49:58.796418 29630 solver.cpp:237] Iteration 38140, loss = 3.43513
I0123 21:49:58.796457 29630 solver.cpp:253]     Train net output #0: loss = 3.43513 (* 1 = 3.43513 loss)
I0123 21:49:58.796463 29630 sgd_solver.cpp:106] Iteration 38140, lr = 0.01
I0123 21:50:06.109438 29630 solver.cpp:237] Iteration 38160, loss = 3.55012
I0123 21:50:06.109475 29630 solver.cpp:253]     Train net output #0: loss = 3.55012 (* 1 = 3.55012 loss)
I0123 21:50:06.109480 29630 sgd_solver.cpp:106] Iteration 38160, lr = 0.01
I0123 21:50:13.351600 29630 solver.cpp:237] Iteration 38180, loss = 3.57626
I0123 21:50:13.351639 29630 solver.cpp:253]     Train net output #0: loss = 3.57626 (* 1 = 3.57626 loss)
I0123 21:50:13.351645 29630 sgd_solver.cpp:106] Iteration 38180, lr = 0.01
I0123 21:50:20.591750 29630 solver.cpp:237] Iteration 38200, loss = 3.5611
I0123 21:50:20.591938 29630 solver.cpp:253]     Train net output #0: loss = 3.5611 (* 1 = 3.5611 loss)
I0123 21:50:20.591946 29630 sgd_solver.cpp:106] Iteration 38200, lr = 0.01
I0123 21:50:27.862210 29630 solver.cpp:237] Iteration 38220, loss = 3.59843
I0123 21:50:27.862247 29630 solver.cpp:253]     Train net output #0: loss = 3.59843 (* 1 = 3.59843 loss)
I0123 21:50:27.862253 29630 sgd_solver.cpp:106] Iteration 38220, lr = 0.01
I0123 21:50:31.178097 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 21:50:35.117228 29630 solver.cpp:237] Iteration 38240, loss = 3.78525
I0123 21:50:35.117266 29630 solver.cpp:253]     Train net output #0: loss = 3.78525 (* 1 = 3.78525 loss)
I0123 21:50:35.117272 29630 sgd_solver.cpp:106] Iteration 38240, lr = 0.01
I0123 21:50:42.375216 29630 solver.cpp:237] Iteration 38260, loss = 3.78765
I0123 21:50:42.375255 29630 solver.cpp:253]     Train net output #0: loss = 3.78765 (* 1 = 3.78765 loss)
I0123 21:50:42.375262 29630 sgd_solver.cpp:106] Iteration 38260, lr = 0.01
I0123 21:50:49.633558 29630 solver.cpp:237] Iteration 38280, loss = 3.4585
I0123 21:50:49.633600 29630 solver.cpp:253]     Train net output #0: loss = 3.4585 (* 1 = 3.4585 loss)
I0123 21:50:49.633606 29630 sgd_solver.cpp:106] Iteration 38280, lr = 0.01
I0123 21:50:56.842797 29630 solver.cpp:237] Iteration 38300, loss = 3.69899
I0123 21:50:56.842928 29630 solver.cpp:253]     Train net output #0: loss = 3.69899 (* 1 = 3.69899 loss)
I0123 21:50:56.842936 29630 sgd_solver.cpp:106] Iteration 38300, lr = 0.01
I0123 21:51:04.041877 29630 solver.cpp:237] Iteration 38320, loss = 3.49051
I0123 21:51:04.041914 29630 solver.cpp:253]     Train net output #0: loss = 3.49051 (* 1 = 3.49051 loss)
I0123 21:51:04.041920 29630 sgd_solver.cpp:106] Iteration 38320, lr = 0.01
I0123 21:51:11.302287 29630 solver.cpp:237] Iteration 38340, loss = 3.56487
I0123 21:51:11.302325 29630 solver.cpp:253]     Train net output #0: loss = 3.56487 (* 1 = 3.56487 loss)
I0123 21:51:11.302331 29630 sgd_solver.cpp:106] Iteration 38340, lr = 0.01
I0123 21:51:18.513900 29630 solver.cpp:237] Iteration 38360, loss = 3.48872
I0123 21:51:18.513938 29630 solver.cpp:253]     Train net output #0: loss = 3.48872 (* 1 = 3.48872 loss)
I0123 21:51:18.513944 29630 sgd_solver.cpp:106] Iteration 38360, lr = 0.01
I0123 21:51:25.765148 29630 solver.cpp:237] Iteration 38380, loss = 3.45182
I0123 21:51:25.765187 29630 solver.cpp:253]     Train net output #0: loss = 3.45182 (* 1 = 3.45182 loss)
I0123 21:51:25.765194 29630 sgd_solver.cpp:106] Iteration 38380, lr = 0.01
I0123 21:51:32.996088 29630 solver.cpp:237] Iteration 38400, loss = 3.50396
I0123 21:51:32.996243 29630 solver.cpp:253]     Train net output #0: loss = 3.50396 (* 1 = 3.50396 loss)
I0123 21:51:32.996251 29630 sgd_solver.cpp:106] Iteration 38400, lr = 0.01
I0123 21:51:40.230887 29630 solver.cpp:237] Iteration 38420, loss = 3.67661
I0123 21:51:40.230927 29630 solver.cpp:253]     Train net output #0: loss = 3.67661 (* 1 = 3.67661 loss)
I0123 21:51:40.230933 29630 sgd_solver.cpp:106] Iteration 38420, lr = 0.01
I0123 21:51:47.446898 29630 solver.cpp:237] Iteration 38440, loss = 3.3624
I0123 21:51:47.446946 29630 solver.cpp:253]     Train net output #0: loss = 3.3624 (* 1 = 3.3624 loss)
I0123 21:51:47.446952 29630 sgd_solver.cpp:106] Iteration 38440, lr = 0.01
I0123 21:51:54.684072 29630 solver.cpp:237] Iteration 38460, loss = 3.67876
I0123 21:51:54.684110 29630 solver.cpp:253]     Train net output #0: loss = 3.67876 (* 1 = 3.67876 loss)
I0123 21:51:54.684116 29630 sgd_solver.cpp:106] Iteration 38460, lr = 0.01
I0123 21:52:01.925796 29630 solver.cpp:237] Iteration 38480, loss = 3.42276
I0123 21:52:01.925833 29630 solver.cpp:253]     Train net output #0: loss = 3.42276 (* 1 = 3.42276 loss)
I0123 21:52:01.925840 29630 sgd_solver.cpp:106] Iteration 38480, lr = 0.01
I0123 21:52:09.187337 29630 solver.cpp:237] Iteration 38500, loss = 3.84614
I0123 21:52:09.187504 29630 solver.cpp:253]     Train net output #0: loss = 3.84614 (* 1 = 3.84614 loss)
I0123 21:52:09.187511 29630 sgd_solver.cpp:106] Iteration 38500, lr = 0.01
I0123 21:52:16.457798 29630 solver.cpp:237] Iteration 38520, loss = 3.4216
I0123 21:52:16.457836 29630 solver.cpp:253]     Train net output #0: loss = 3.4216 (* 1 = 3.4216 loss)
I0123 21:52:16.457844 29630 sgd_solver.cpp:106] Iteration 38520, lr = 0.01
I0123 21:52:23.728752 29630 solver.cpp:237] Iteration 38540, loss = 3.65939
I0123 21:52:23.728799 29630 solver.cpp:253]     Train net output #0: loss = 3.65939 (* 1 = 3.65939 loss)
I0123 21:52:23.728806 29630 sgd_solver.cpp:106] Iteration 38540, lr = 0.01
I0123 21:52:31.017403 29630 solver.cpp:237] Iteration 38560, loss = 3.57614
I0123 21:52:31.017441 29630 solver.cpp:253]     Train net output #0: loss = 3.57614 (* 1 = 3.57614 loss)
I0123 21:52:31.017448 29630 sgd_solver.cpp:106] Iteration 38560, lr = 0.01
I0123 21:52:38.299005 29630 solver.cpp:237] Iteration 38580, loss = 3.90808
I0123 21:52:38.299044 29630 solver.cpp:253]     Train net output #0: loss = 3.90808 (* 1 = 3.90808 loss)
I0123 21:52:38.299051 29630 sgd_solver.cpp:106] Iteration 38580, lr = 0.01
I0123 21:52:45.578305 29630 solver.cpp:237] Iteration 38600, loss = 3.53371
I0123 21:52:45.578436 29630 solver.cpp:253]     Train net output #0: loss = 3.53371 (* 1 = 3.53371 loss)
I0123 21:52:45.578444 29630 sgd_solver.cpp:106] Iteration 38600, lr = 0.01
I0123 21:52:52.827450 29630 solver.cpp:237] Iteration 38620, loss = 3.5345
I0123 21:52:52.827489 29630 solver.cpp:253]     Train net output #0: loss = 3.5345 (* 1 = 3.5345 loss)
I0123 21:52:52.827496 29630 sgd_solver.cpp:106] Iteration 38620, lr = 0.01
I0123 21:53:00.135341 29630 solver.cpp:237] Iteration 38640, loss = 3.72941
I0123 21:53:00.135378 29630 solver.cpp:253]     Train net output #0: loss = 3.72941 (* 1 = 3.72941 loss)
I0123 21:53:00.135385 29630 sgd_solver.cpp:106] Iteration 38640, lr = 0.01
I0123 21:53:07.455772 29630 solver.cpp:237] Iteration 38660, loss = 3.70865
I0123 21:53:07.455814 29630 solver.cpp:253]     Train net output #0: loss = 3.70865 (* 1 = 3.70865 loss)
I0123 21:53:07.455832 29630 sgd_solver.cpp:106] Iteration 38660, lr = 0.01
I0123 21:53:14.697211 29630 solver.cpp:237] Iteration 38680, loss = 3.66569
I0123 21:53:14.697250 29630 solver.cpp:253]     Train net output #0: loss = 3.66569 (* 1 = 3.66569 loss)
I0123 21:53:14.697257 29630 sgd_solver.cpp:106] Iteration 38680, lr = 0.01
I0123 21:53:21.944283 29630 solver.cpp:237] Iteration 38700, loss = 3.5801
I0123 21:53:21.944392 29630 solver.cpp:253]     Train net output #0: loss = 3.5801 (* 1 = 3.5801 loss)
I0123 21:53:21.944409 29630 sgd_solver.cpp:106] Iteration 38700, lr = 0.01
I0123 21:53:29.240391 29630 solver.cpp:237] Iteration 38720, loss = 3.48388
I0123 21:53:29.240430 29630 solver.cpp:253]     Train net output #0: loss = 3.48388 (* 1 = 3.48388 loss)
I0123 21:53:29.240437 29630 sgd_solver.cpp:106] Iteration 38720, lr = 0.01
I0123 21:53:36.533334 29630 solver.cpp:237] Iteration 38740, loss = 3.53295
I0123 21:53:36.533371 29630 solver.cpp:253]     Train net output #0: loss = 3.53295 (* 1 = 3.53295 loss)
I0123 21:53:36.533377 29630 sgd_solver.cpp:106] Iteration 38740, lr = 0.01
I0123 21:53:43.849419 29630 solver.cpp:237] Iteration 38760, loss = 3.62836
I0123 21:53:43.849458 29630 solver.cpp:253]     Train net output #0: loss = 3.62836 (* 1 = 3.62836 loss)
I0123 21:53:43.849463 29630 sgd_solver.cpp:106] Iteration 38760, lr = 0.01
I0123 21:53:51.152457 29630 solver.cpp:237] Iteration 38780, loss = 3.7273
I0123 21:53:51.152498 29630 solver.cpp:253]     Train net output #0: loss = 3.7273 (* 1 = 3.7273 loss)
I0123 21:53:51.152506 29630 sgd_solver.cpp:106] Iteration 38780, lr = 0.01
I0123 21:53:58.447108 29630 solver.cpp:237] Iteration 38800, loss = 3.56924
I0123 21:53:58.447276 29630 solver.cpp:253]     Train net output #0: loss = 3.56924 (* 1 = 3.56924 loss)
I0123 21:53:58.447284 29630 sgd_solver.cpp:106] Iteration 38800, lr = 0.01
I0123 21:54:05.717778 29630 solver.cpp:237] Iteration 38820, loss = 3.73798
I0123 21:54:05.717818 29630 solver.cpp:253]     Train net output #0: loss = 3.73798 (* 1 = 3.73798 loss)
I0123 21:54:05.717824 29630 sgd_solver.cpp:106] Iteration 38820, lr = 0.01
I0123 21:54:13.036308 29630 solver.cpp:237] Iteration 38840, loss = 3.29054
I0123 21:54:13.036346 29630 solver.cpp:253]     Train net output #0: loss = 3.29054 (* 1 = 3.29054 loss)
I0123 21:54:13.036352 29630 sgd_solver.cpp:106] Iteration 38840, lr = 0.01
I0123 21:54:20.270238 29630 solver.cpp:237] Iteration 38860, loss = 3.63681
I0123 21:54:20.270282 29630 solver.cpp:253]     Train net output #0: loss = 3.63681 (* 1 = 3.63681 loss)
I0123 21:54:20.270299 29630 sgd_solver.cpp:106] Iteration 38860, lr = 0.01
I0123 21:54:27.565481 29630 solver.cpp:237] Iteration 38880, loss = 3.58332
I0123 21:54:27.565521 29630 solver.cpp:253]     Train net output #0: loss = 3.58332 (* 1 = 3.58332 loss)
I0123 21:54:27.565528 29630 sgd_solver.cpp:106] Iteration 38880, lr = 0.01
I0123 21:54:34.774277 29630 solver.cpp:237] Iteration 38900, loss = 3.47838
I0123 21:54:34.774446 29630 solver.cpp:253]     Train net output #0: loss = 3.47838 (* 1 = 3.47838 loss)
I0123 21:54:34.774453 29630 sgd_solver.cpp:106] Iteration 38900, lr = 0.01
I0123 21:54:42.070411 29630 solver.cpp:237] Iteration 38920, loss = 3.50285
I0123 21:54:42.070449 29630 solver.cpp:253]     Train net output #0: loss = 3.50285 (* 1 = 3.50285 loss)
I0123 21:54:42.070456 29630 sgd_solver.cpp:106] Iteration 38920, lr = 0.01
I0123 21:54:49.263123 29630 solver.cpp:237] Iteration 38940, loss = 3.56211
I0123 21:54:49.263161 29630 solver.cpp:253]     Train net output #0: loss = 3.56211 (* 1 = 3.56211 loss)
I0123 21:54:49.263169 29630 sgd_solver.cpp:106] Iteration 38940, lr = 0.01
I0123 21:54:56.510732 29630 solver.cpp:237] Iteration 38960, loss = 3.56276
I0123 21:54:56.510771 29630 solver.cpp:253]     Train net output #0: loss = 3.56276 (* 1 = 3.56276 loss)
I0123 21:54:56.510777 29630 sgd_solver.cpp:106] Iteration 38960, lr = 0.01
I0123 21:55:03.764606 29630 solver.cpp:237] Iteration 38980, loss = 3.68188
I0123 21:55:03.764646 29630 solver.cpp:253]     Train net output #0: loss = 3.68188 (* 1 = 3.68188 loss)
I0123 21:55:03.764652 29630 sgd_solver.cpp:106] Iteration 38980, lr = 0.01
I0123 21:55:10.741534 29630 solver.cpp:341] Iteration 39000, Testing net (#0)
I0123 21:55:27.840178 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 21:56:24.655796 29630 solver.cpp:409]     Test net output #0: accuracy = 0.2899
I0123 21:56:24.655925 29630 solver.cpp:409]     Test net output #1: loss = 3.39852 (* 1 = 3.39852 loss)
I0123 21:56:24.696732 29630 solver.cpp:237] Iteration 39000, loss = 3.40064
I0123 21:56:24.696758 29630 solver.cpp:253]     Train net output #0: loss = 3.40064 (* 1 = 3.40064 loss)
I0123 21:56:24.696764 29630 sgd_solver.cpp:106] Iteration 39000, lr = 0.01
I0123 21:56:31.220082 29630 solver.cpp:237] Iteration 39020, loss = 3.59812
I0123 21:56:31.220130 29630 solver.cpp:253]     Train net output #0: loss = 3.59812 (* 1 = 3.59812 loss)
I0123 21:56:31.220137 29630 sgd_solver.cpp:106] Iteration 39020, lr = 0.01
I0123 21:56:38.472928 29630 solver.cpp:237] Iteration 39040, loss = 3.73688
I0123 21:56:38.472966 29630 solver.cpp:253]     Train net output #0: loss = 3.73688 (* 1 = 3.73688 loss)
I0123 21:56:38.472972 29630 sgd_solver.cpp:106] Iteration 39040, lr = 0.01
I0123 21:56:45.749505 29630 solver.cpp:237] Iteration 39060, loss = 3.32297
I0123 21:56:45.749542 29630 solver.cpp:253]     Train net output #0: loss = 3.32297 (* 1 = 3.32297 loss)
I0123 21:56:45.749549 29630 sgd_solver.cpp:106] Iteration 39060, lr = 0.01
I0123 21:56:52.992681 29630 solver.cpp:237] Iteration 39080, loss = 3.70221
I0123 21:56:52.992718 29630 solver.cpp:253]     Train net output #0: loss = 3.70221 (* 1 = 3.70221 loss)
I0123 21:56:52.992724 29630 sgd_solver.cpp:106] Iteration 39080, lr = 0.01
I0123 21:57:00.259604 29630 solver.cpp:237] Iteration 39100, loss = 3.39023
I0123 21:57:00.259739 29630 solver.cpp:253]     Train net output #0: loss = 3.39023 (* 1 = 3.39023 loss)
I0123 21:57:00.259757 29630 sgd_solver.cpp:106] Iteration 39100, lr = 0.01
I0123 21:57:07.539711 29630 solver.cpp:237] Iteration 39120, loss = 3.68887
I0123 21:57:07.539752 29630 solver.cpp:253]     Train net output #0: loss = 3.68887 (* 1 = 3.68887 loss)
I0123 21:57:07.539757 29630 sgd_solver.cpp:106] Iteration 39120, lr = 0.01
I0123 21:57:14.792793 29630 solver.cpp:237] Iteration 39140, loss = 3.46587
I0123 21:57:14.792832 29630 solver.cpp:253]     Train net output #0: loss = 3.46587 (* 1 = 3.46587 loss)
I0123 21:57:14.792839 29630 sgd_solver.cpp:106] Iteration 39140, lr = 0.01
I0123 21:57:22.111273 29630 solver.cpp:237] Iteration 39160, loss = 3.53235
I0123 21:57:22.111311 29630 solver.cpp:253]     Train net output #0: loss = 3.53235 (* 1 = 3.53235 loss)
I0123 21:57:22.111318 29630 sgd_solver.cpp:106] Iteration 39160, lr = 0.01
I0123 21:57:29.383790 29630 solver.cpp:237] Iteration 39180, loss = 3.67555
I0123 21:57:29.383829 29630 solver.cpp:253]     Train net output #0: loss = 3.67555 (* 1 = 3.67555 loss)
I0123 21:57:29.383836 29630 sgd_solver.cpp:106] Iteration 39180, lr = 0.01
I0123 21:57:36.645038 29630 solver.cpp:237] Iteration 39200, loss = 3.38751
I0123 21:57:36.645200 29630 solver.cpp:253]     Train net output #0: loss = 3.38751 (* 1 = 3.38751 loss)
I0123 21:57:36.645208 29630 sgd_solver.cpp:106] Iteration 39200, lr = 0.01
I0123 21:57:43.966395 29630 solver.cpp:237] Iteration 39220, loss = 3.54848
I0123 21:57:43.966434 29630 solver.cpp:253]     Train net output #0: loss = 3.54848 (* 1 = 3.54848 loss)
I0123 21:57:43.966440 29630 sgd_solver.cpp:106] Iteration 39220, lr = 0.01
I0123 21:57:49.480355 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 21:57:51.221158 29630 solver.cpp:237] Iteration 39240, loss = 3.49417
I0123 21:57:51.221197 29630 solver.cpp:253]     Train net output #0: loss = 3.49417 (* 1 = 3.49417 loss)
I0123 21:57:51.221204 29630 sgd_solver.cpp:106] Iteration 39240, lr = 0.01
I0123 21:57:58.459735 29630 solver.cpp:237] Iteration 39260, loss = 3.59209
I0123 21:57:58.459774 29630 solver.cpp:253]     Train net output #0: loss = 3.59209 (* 1 = 3.59209 loss)
I0123 21:57:58.459780 29630 sgd_solver.cpp:106] Iteration 39260, lr = 0.01
I0123 21:58:05.685305 29630 solver.cpp:237] Iteration 39280, loss = 3.69836
I0123 21:58:05.685344 29630 solver.cpp:253]     Train net output #0: loss = 3.69836 (* 1 = 3.69836 loss)
I0123 21:58:05.685350 29630 sgd_solver.cpp:106] Iteration 39280, lr = 0.01
I0123 21:58:12.956512 29630 solver.cpp:237] Iteration 39300, loss = 3.66753
I0123 21:58:12.956632 29630 solver.cpp:253]     Train net output #0: loss = 3.66753 (* 1 = 3.66753 loss)
I0123 21:58:12.956640 29630 sgd_solver.cpp:106] Iteration 39300, lr = 0.01
I0123 21:58:20.200639 29630 solver.cpp:237] Iteration 39320, loss = 3.56471
I0123 21:58:20.200678 29630 solver.cpp:253]     Train net output #0: loss = 3.56471 (* 1 = 3.56471 loss)
I0123 21:58:20.200685 29630 sgd_solver.cpp:106] Iteration 39320, lr = 0.01
I0123 21:58:27.480315 29630 solver.cpp:237] Iteration 39340, loss = 3.52049
I0123 21:58:27.480355 29630 solver.cpp:253]     Train net output #0: loss = 3.52049 (* 1 = 3.52049 loss)
I0123 21:58:27.480361 29630 sgd_solver.cpp:106] Iteration 39340, lr = 0.01
I0123 21:58:34.731649 29630 solver.cpp:237] Iteration 39360, loss = 3.38955
I0123 21:58:34.731688 29630 solver.cpp:253]     Train net output #0: loss = 3.38955 (* 1 = 3.38955 loss)
I0123 21:58:34.731695 29630 sgd_solver.cpp:106] Iteration 39360, lr = 0.01
I0123 21:58:41.954172 29630 solver.cpp:237] Iteration 39380, loss = 3.54256
I0123 21:58:41.954210 29630 solver.cpp:253]     Train net output #0: loss = 3.54256 (* 1 = 3.54256 loss)
I0123 21:58:41.954226 29630 sgd_solver.cpp:106] Iteration 39380, lr = 0.01
I0123 21:58:49.219674 29630 solver.cpp:237] Iteration 39400, loss = 3.32214
I0123 21:58:49.219836 29630 solver.cpp:253]     Train net output #0: loss = 3.32214 (* 1 = 3.32214 loss)
I0123 21:58:49.219858 29630 sgd_solver.cpp:106] Iteration 39400, lr = 0.01
I0123 21:58:56.449710 29630 solver.cpp:237] Iteration 39420, loss = 3.66342
I0123 21:58:56.449748 29630 solver.cpp:253]     Train net output #0: loss = 3.66342 (* 1 = 3.66342 loss)
I0123 21:58:56.449754 29630 sgd_solver.cpp:106] Iteration 39420, lr = 0.01
I0123 21:59:03.719179 29630 solver.cpp:237] Iteration 39440, loss = 3.79776
I0123 21:59:03.719218 29630 solver.cpp:253]     Train net output #0: loss = 3.79776 (* 1 = 3.79776 loss)
I0123 21:59:03.719224 29630 sgd_solver.cpp:106] Iteration 39440, lr = 0.01
I0123 21:59:10.956740 29630 solver.cpp:237] Iteration 39460, loss = 3.46584
I0123 21:59:10.956779 29630 solver.cpp:253]     Train net output #0: loss = 3.46584 (* 1 = 3.46584 loss)
I0123 21:59:10.956784 29630 sgd_solver.cpp:106] Iteration 39460, lr = 0.01
I0123 21:59:18.170732 29630 solver.cpp:237] Iteration 39480, loss = 3.59604
I0123 21:59:18.170771 29630 solver.cpp:253]     Train net output #0: loss = 3.59604 (* 1 = 3.59604 loss)
I0123 21:59:18.170778 29630 sgd_solver.cpp:106] Iteration 39480, lr = 0.01
I0123 21:59:25.436257 29630 solver.cpp:237] Iteration 39500, loss = 3.70448
I0123 21:59:25.436441 29630 solver.cpp:253]     Train net output #0: loss = 3.70448 (* 1 = 3.70448 loss)
I0123 21:59:25.436450 29630 sgd_solver.cpp:106] Iteration 39500, lr = 0.01
I0123 21:59:32.692256 29630 solver.cpp:237] Iteration 39520, loss = 3.52787
I0123 21:59:32.692294 29630 solver.cpp:253]     Train net output #0: loss = 3.52787 (* 1 = 3.52787 loss)
I0123 21:59:32.692301 29630 sgd_solver.cpp:106] Iteration 39520, lr = 0.01
I0123 21:59:39.942296 29630 solver.cpp:237] Iteration 39540, loss = 3.32743
I0123 21:59:39.942335 29630 solver.cpp:253]     Train net output #0: loss = 3.32743 (* 1 = 3.32743 loss)
I0123 21:59:39.942342 29630 sgd_solver.cpp:106] Iteration 39540, lr = 0.01
I0123 21:59:47.192747 29630 solver.cpp:237] Iteration 39560, loss = 3.5287
I0123 21:59:47.192786 29630 solver.cpp:253]     Train net output #0: loss = 3.5287 (* 1 = 3.5287 loss)
I0123 21:59:47.192792 29630 sgd_solver.cpp:106] Iteration 39560, lr = 0.01
I0123 21:59:54.465286 29630 solver.cpp:237] Iteration 39580, loss = 3.52004
I0123 21:59:54.465317 29630 solver.cpp:253]     Train net output #0: loss = 3.52004 (* 1 = 3.52004 loss)
I0123 21:59:54.465323 29630 sgd_solver.cpp:106] Iteration 39580, lr = 0.01
I0123 22:00:01.795727 29630 solver.cpp:237] Iteration 39600, loss = 3.39301
I0123 22:00:01.795847 29630 solver.cpp:253]     Train net output #0: loss = 3.39301 (* 1 = 3.39301 loss)
I0123 22:00:01.795855 29630 sgd_solver.cpp:106] Iteration 39600, lr = 0.01
I0123 22:00:09.029618 29630 solver.cpp:237] Iteration 39620, loss = 3.53468
I0123 22:00:09.029655 29630 solver.cpp:253]     Train net output #0: loss = 3.53468 (* 1 = 3.53468 loss)
I0123 22:00:09.029661 29630 sgd_solver.cpp:106] Iteration 39620, lr = 0.01
I0123 22:00:16.283291 29630 solver.cpp:237] Iteration 39640, loss = 3.3704
I0123 22:00:16.283329 29630 solver.cpp:253]     Train net output #0: loss = 3.3704 (* 1 = 3.3704 loss)
I0123 22:00:16.283345 29630 sgd_solver.cpp:106] Iteration 39640, lr = 0.01
I0123 22:00:23.568738 29630 solver.cpp:237] Iteration 39660, loss = 3.69777
I0123 22:00:23.568778 29630 solver.cpp:253]     Train net output #0: loss = 3.69777 (* 1 = 3.69777 loss)
I0123 22:00:23.568784 29630 sgd_solver.cpp:106] Iteration 39660, lr = 0.01
I0123 22:00:30.840621 29630 solver.cpp:237] Iteration 39680, loss = 3.62609
I0123 22:00:30.840659 29630 solver.cpp:253]     Train net output #0: loss = 3.62609 (* 1 = 3.62609 loss)
I0123 22:00:30.840667 29630 sgd_solver.cpp:106] Iteration 39680, lr = 0.01
I0123 22:00:38.117643 29630 solver.cpp:237] Iteration 39700, loss = 3.5441
I0123 22:00:38.117756 29630 solver.cpp:253]     Train net output #0: loss = 3.5441 (* 1 = 3.5441 loss)
I0123 22:00:38.117763 29630 sgd_solver.cpp:106] Iteration 39700, lr = 0.01
I0123 22:00:45.364284 29630 solver.cpp:237] Iteration 39720, loss = 3.60667
I0123 22:00:45.364322 29630 solver.cpp:253]     Train net output #0: loss = 3.60667 (* 1 = 3.60667 loss)
I0123 22:00:45.364330 29630 sgd_solver.cpp:106] Iteration 39720, lr = 0.01
I0123 22:00:52.636379 29630 solver.cpp:237] Iteration 39740, loss = 3.5663
I0123 22:00:52.636418 29630 solver.cpp:253]     Train net output #0: loss = 3.5663 (* 1 = 3.5663 loss)
I0123 22:00:52.636425 29630 sgd_solver.cpp:106] Iteration 39740, lr = 0.01
I0123 22:00:59.952587 29630 solver.cpp:237] Iteration 39760, loss = 3.66575
I0123 22:00:59.952627 29630 solver.cpp:253]     Train net output #0: loss = 3.66575 (* 1 = 3.66575 loss)
I0123 22:00:59.952635 29630 sgd_solver.cpp:106] Iteration 39760, lr = 0.01
I0123 22:01:07.244683 29630 solver.cpp:237] Iteration 39780, loss = 3.52899
I0123 22:01:07.244720 29630 solver.cpp:253]     Train net output #0: loss = 3.52899 (* 1 = 3.52899 loss)
I0123 22:01:07.244726 29630 sgd_solver.cpp:106] Iteration 39780, lr = 0.01
I0123 22:01:14.478250 29630 solver.cpp:237] Iteration 39800, loss = 3.70909
I0123 22:01:14.478374 29630 solver.cpp:253]     Train net output #0: loss = 3.70909 (* 1 = 3.70909 loss)
I0123 22:01:14.478382 29630 sgd_solver.cpp:106] Iteration 39800, lr = 0.01
I0123 22:01:21.757235 29630 solver.cpp:237] Iteration 39820, loss = 3.45104
I0123 22:01:21.757274 29630 solver.cpp:253]     Train net output #0: loss = 3.45104 (* 1 = 3.45104 loss)
I0123 22:01:21.757280 29630 sgd_solver.cpp:106] Iteration 39820, lr = 0.01
I0123 22:01:29.045143 29630 solver.cpp:237] Iteration 39840, loss = 3.47467
I0123 22:01:29.045181 29630 solver.cpp:253]     Train net output #0: loss = 3.47467 (* 1 = 3.47467 loss)
I0123 22:01:29.045187 29630 sgd_solver.cpp:106] Iteration 39840, lr = 0.01
I0123 22:01:36.281961 29630 solver.cpp:237] Iteration 39860, loss = 3.48448
I0123 22:01:36.282013 29630 solver.cpp:253]     Train net output #0: loss = 3.48448 (* 1 = 3.48448 loss)
I0123 22:01:36.282021 29630 sgd_solver.cpp:106] Iteration 39860, lr = 0.01
I0123 22:01:43.526309 29630 solver.cpp:237] Iteration 39880, loss = 3.85686
I0123 22:01:43.526347 29630 solver.cpp:253]     Train net output #0: loss = 3.85686 (* 1 = 3.85686 loss)
I0123 22:01:43.526355 29630 sgd_solver.cpp:106] Iteration 39880, lr = 0.01
I0123 22:01:50.801949 29630 solver.cpp:237] Iteration 39900, loss = 3.42747
I0123 22:01:50.802084 29630 solver.cpp:253]     Train net output #0: loss = 3.42747 (* 1 = 3.42747 loss)
I0123 22:01:50.802103 29630 sgd_solver.cpp:106] Iteration 39900, lr = 0.01
I0123 22:01:58.039504 29630 solver.cpp:237] Iteration 39920, loss = 3.72946
I0123 22:01:58.039561 29630 solver.cpp:253]     Train net output #0: loss = 3.72946 (* 1 = 3.72946 loss)
I0123 22:01:58.039572 29630 sgd_solver.cpp:106] Iteration 39920, lr = 0.01
I0123 22:02:05.275393 29630 solver.cpp:237] Iteration 39940, loss = 3.35219
I0123 22:02:05.275432 29630 solver.cpp:253]     Train net output #0: loss = 3.35219 (* 1 = 3.35219 loss)
I0123 22:02:05.275439 29630 sgd_solver.cpp:106] Iteration 39940, lr = 0.01
I0123 22:02:12.589756 29630 solver.cpp:237] Iteration 39960, loss = 3.36911
I0123 22:02:12.589793 29630 solver.cpp:253]     Train net output #0: loss = 3.36911 (* 1 = 3.36911 loss)
I0123 22:02:12.589799 29630 sgd_solver.cpp:106] Iteration 39960, lr = 0.01
I0123 22:02:19.844193 29630 solver.cpp:237] Iteration 39980, loss = 4.01744
I0123 22:02:19.844233 29630 solver.cpp:253]     Train net output #0: loss = 4.01744 (* 1 = 4.01744 loss)
I0123 22:02:19.844238 29630 sgd_solver.cpp:106] Iteration 39980, lr = 0.01
I0123 22:02:26.800573 29630 solver.cpp:459] Snapshotting to binary proto file snapshots/caffenet128_lsuv_ycrcb_iter_40000.caffemodel
I0123 22:02:26.975520 29630 sgd_solver.cpp:269] Snapshotting solver state to binary proto file snapshots/caffenet128_lsuv_ycrcb_iter_40000.solverstate
I0123 22:02:27.035334 29630 solver.cpp:341] Iteration 40000, Testing net (#0)
I0123 22:02:44.494500 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 22:03:41.052687 29630 solver.cpp:409]     Test net output #0: accuracy = 0.29542
I0123 22:03:41.052801 29630 solver.cpp:409]     Test net output #1: loss = 3.36745 (* 1 = 3.36745 loss)
I0123 22:03:41.093336 29630 solver.cpp:237] Iteration 40000, loss = 3.54642
I0123 22:03:41.093374 29630 solver.cpp:253]     Train net output #0: loss = 3.54642 (* 1 = 3.54642 loss)
I0123 22:03:41.093379 29630 sgd_solver.cpp:106] Iteration 40000, lr = 0.01
I0123 22:03:47.656839 29630 solver.cpp:237] Iteration 40020, loss = 3.48422
I0123 22:03:47.656890 29630 solver.cpp:253]     Train net output #0: loss = 3.48422 (* 1 = 3.48422 loss)
I0123 22:03:47.656898 29630 sgd_solver.cpp:106] Iteration 40020, lr = 0.01
I0123 22:03:54.925878 29630 solver.cpp:237] Iteration 40040, loss = 3.74325
I0123 22:03:54.925917 29630 solver.cpp:253]     Train net output #0: loss = 3.74325 (* 1 = 3.74325 loss)
I0123 22:03:54.925923 29630 sgd_solver.cpp:106] Iteration 40040, lr = 0.01
I0123 22:04:02.112177 29630 solver.cpp:237] Iteration 40060, loss = 3.41803
I0123 22:04:02.112216 29630 solver.cpp:253]     Train net output #0: loss = 3.41803 (* 1 = 3.41803 loss)
I0123 22:04:02.112222 29630 sgd_solver.cpp:106] Iteration 40060, lr = 0.01
I0123 22:04:09.374847 29630 solver.cpp:237] Iteration 40080, loss = 3.93101
I0123 22:04:09.374886 29630 solver.cpp:253]     Train net output #0: loss = 3.93101 (* 1 = 3.93101 loss)
I0123 22:04:09.374892 29630 sgd_solver.cpp:106] Iteration 40080, lr = 0.01
I0123 22:04:16.626451 29630 solver.cpp:237] Iteration 40100, loss = 3.73357
I0123 22:04:16.626621 29630 solver.cpp:253]     Train net output #0: loss = 3.73357 (* 1 = 3.73357 loss)
I0123 22:04:16.626631 29630 sgd_solver.cpp:106] Iteration 40100, lr = 0.01
I0123 22:04:23.953706 29630 solver.cpp:237] Iteration 40120, loss = 3.43047
I0123 22:04:23.953747 29630 solver.cpp:253]     Train net output #0: loss = 3.43047 (* 1 = 3.43047 loss)
I0123 22:04:23.953761 29630 sgd_solver.cpp:106] Iteration 40120, lr = 0.01
I0123 22:04:31.242705 29630 solver.cpp:237] Iteration 40140, loss = 3.57165
I0123 22:04:31.242734 29630 solver.cpp:253]     Train net output #0: loss = 3.57165 (* 1 = 3.57165 loss)
I0123 22:04:31.242741 29630 sgd_solver.cpp:106] Iteration 40140, lr = 0.01
I0123 22:04:38.489109 29630 solver.cpp:237] Iteration 40160, loss = 3.21403
I0123 22:04:38.489148 29630 solver.cpp:253]     Train net output #0: loss = 3.21403 (* 1 = 3.21403 loss)
I0123 22:04:38.489154 29630 sgd_solver.cpp:106] Iteration 40160, lr = 0.01
I0123 22:04:45.731638 29630 solver.cpp:237] Iteration 40180, loss = 3.19857
I0123 22:04:45.731676 29630 solver.cpp:253]     Train net output #0: loss = 3.19857 (* 1 = 3.19857 loss)
I0123 22:04:45.731683 29630 sgd_solver.cpp:106] Iteration 40180, lr = 0.01
I0123 22:04:52.988173 29630 solver.cpp:237] Iteration 40200, loss = 3.86284
I0123 22:04:52.988325 29630 solver.cpp:253]     Train net output #0: loss = 3.86284 (* 1 = 3.86284 loss)
I0123 22:04:52.988343 29630 sgd_solver.cpp:106] Iteration 40200, lr = 0.01
I0123 22:05:00.302686 29630 solver.cpp:237] Iteration 40220, loss = 3.46582
I0123 22:05:00.302726 29630 solver.cpp:253]     Train net output #0: loss = 3.46582 (* 1 = 3.46582 loss)
I0123 22:05:00.302731 29630 sgd_solver.cpp:106] Iteration 40220, lr = 0.01
I0123 22:05:07.629329 29630 solver.cpp:237] Iteration 40240, loss = 3.53339
I0123 22:05:07.629369 29630 solver.cpp:253]     Train net output #0: loss = 3.53339 (* 1 = 3.53339 loss)
I0123 22:05:07.629374 29630 sgd_solver.cpp:106] Iteration 40240, lr = 0.01
I0123 22:05:08.059803 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 22:05:14.903703 29630 solver.cpp:237] Iteration 40260, loss = 3.36447
I0123 22:05:14.903743 29630 solver.cpp:253]     Train net output #0: loss = 3.36447 (* 1 = 3.36447 loss)
I0123 22:05:14.903748 29630 sgd_solver.cpp:106] Iteration 40260, lr = 0.01
I0123 22:05:22.172471 29630 solver.cpp:237] Iteration 40280, loss = 4.07825
I0123 22:05:22.172508 29630 solver.cpp:253]     Train net output #0: loss = 4.07825 (* 1 = 4.07825 loss)
I0123 22:05:22.172514 29630 sgd_solver.cpp:106] Iteration 40280, lr = 0.01
I0123 22:05:29.442378 29630 solver.cpp:237] Iteration 40300, loss = 3.19032
I0123 22:05:29.442559 29630 solver.cpp:253]     Train net output #0: loss = 3.19032 (* 1 = 3.19032 loss)
I0123 22:05:29.442567 29630 sgd_solver.cpp:106] Iteration 40300, lr = 0.01
I0123 22:05:36.725664 29630 solver.cpp:237] Iteration 40320, loss = 3.46031
I0123 22:05:36.725728 29630 solver.cpp:253]     Train net output #0: loss = 3.46031 (* 1 = 3.46031 loss)
I0123 22:05:36.725749 29630 sgd_solver.cpp:106] Iteration 40320, lr = 0.01
I0123 22:05:43.985973 29630 solver.cpp:237] Iteration 40340, loss = 3.76514
I0123 22:05:43.986012 29630 solver.cpp:253]     Train net output #0: loss = 3.76514 (* 1 = 3.76514 loss)
I0123 22:05:43.986018 29630 sgd_solver.cpp:106] Iteration 40340, lr = 0.01
I0123 22:05:51.265715 29630 solver.cpp:237] Iteration 40360, loss = 3.37624
I0123 22:05:51.265754 29630 solver.cpp:253]     Train net output #0: loss = 3.37624 (* 1 = 3.37624 loss)
I0123 22:05:51.265761 29630 sgd_solver.cpp:106] Iteration 40360, lr = 0.01
I0123 22:05:58.556234 29630 solver.cpp:237] Iteration 40380, loss = 3.57216
I0123 22:05:58.556273 29630 solver.cpp:253]     Train net output #0: loss = 3.57216 (* 1 = 3.57216 loss)
I0123 22:05:58.556279 29630 sgd_solver.cpp:106] Iteration 40380, lr = 0.01
I0123 22:06:05.793280 29630 solver.cpp:237] Iteration 40400, loss = 3.26117
I0123 22:06:05.793444 29630 solver.cpp:253]     Train net output #0: loss = 3.26117 (* 1 = 3.26117 loss)
I0123 22:06:05.793462 29630 sgd_solver.cpp:106] Iteration 40400, lr = 0.01
I0123 22:06:13.050264 29630 solver.cpp:237] Iteration 40420, loss = 3.31264
I0123 22:06:13.050305 29630 solver.cpp:253]     Train net output #0: loss = 3.31264 (* 1 = 3.31264 loss)
I0123 22:06:13.050310 29630 sgd_solver.cpp:106] Iteration 40420, lr = 0.01
I0123 22:06:20.278949 29630 solver.cpp:237] Iteration 40440, loss = 3.45591
I0123 22:06:20.279005 29630 solver.cpp:253]     Train net output #0: loss = 3.45591 (* 1 = 3.45591 loss)
I0123 22:06:20.279014 29630 sgd_solver.cpp:106] Iteration 40440, lr = 0.01
I0123 22:06:27.541409 29630 solver.cpp:237] Iteration 40460, loss = 3.63127
I0123 22:06:27.541457 29630 solver.cpp:253]     Train net output #0: loss = 3.63127 (* 1 = 3.63127 loss)
I0123 22:06:27.541465 29630 sgd_solver.cpp:106] Iteration 40460, lr = 0.01
I0123 22:06:34.839578 29630 solver.cpp:237] Iteration 40480, loss = 3.63797
I0123 22:06:34.839618 29630 solver.cpp:253]     Train net output #0: loss = 3.63797 (* 1 = 3.63797 loss)
I0123 22:06:34.839624 29630 sgd_solver.cpp:106] Iteration 40480, lr = 0.01
I0123 22:06:42.084254 29630 solver.cpp:237] Iteration 40500, loss = 3.67175
I0123 22:06:42.084380 29630 solver.cpp:253]     Train net output #0: loss = 3.67175 (* 1 = 3.67175 loss)
I0123 22:06:42.084388 29630 sgd_solver.cpp:106] Iteration 40500, lr = 0.01
I0123 22:06:49.351573 29630 solver.cpp:237] Iteration 40520, loss = 3.20692
I0123 22:06:49.351611 29630 solver.cpp:253]     Train net output #0: loss = 3.20692 (* 1 = 3.20692 loss)
I0123 22:06:49.351618 29630 sgd_solver.cpp:106] Iteration 40520, lr = 0.01
I0123 22:06:56.590927 29630 solver.cpp:237] Iteration 40540, loss = 3.78171
I0123 22:06:56.590966 29630 solver.cpp:253]     Train net output #0: loss = 3.78171 (* 1 = 3.78171 loss)
I0123 22:06:56.590972 29630 sgd_solver.cpp:106] Iteration 40540, lr = 0.01
I0123 22:07:03.828697 29630 solver.cpp:237] Iteration 40560, loss = 3.30974
I0123 22:07:03.828738 29630 solver.cpp:253]     Train net output #0: loss = 3.30974 (* 1 = 3.30974 loss)
I0123 22:07:03.828745 29630 sgd_solver.cpp:106] Iteration 40560, lr = 0.01
I0123 22:07:11.094772 29630 solver.cpp:237] Iteration 40580, loss = 3.37331
I0123 22:07:11.094810 29630 solver.cpp:253]     Train net output #0: loss = 3.37331 (* 1 = 3.37331 loss)
I0123 22:07:11.094816 29630 sgd_solver.cpp:106] Iteration 40580, lr = 0.01
I0123 22:07:18.365205 29630 solver.cpp:237] Iteration 40600, loss = 3.68795
I0123 22:07:18.365325 29630 solver.cpp:253]     Train net output #0: loss = 3.68795 (* 1 = 3.68795 loss)
I0123 22:07:18.365332 29630 sgd_solver.cpp:106] Iteration 40600, lr = 0.01
I0123 22:07:25.625895 29630 solver.cpp:237] Iteration 40620, loss = 3.45912
I0123 22:07:25.625932 29630 solver.cpp:253]     Train net output #0: loss = 3.45912 (* 1 = 3.45912 loss)
I0123 22:07:25.625938 29630 sgd_solver.cpp:106] Iteration 40620, lr = 0.01
I0123 22:07:32.888059 29630 solver.cpp:237] Iteration 40640, loss = 3.36156
I0123 22:07:32.888099 29630 solver.cpp:253]     Train net output #0: loss = 3.36156 (* 1 = 3.36156 loss)
I0123 22:07:32.888105 29630 sgd_solver.cpp:106] Iteration 40640, lr = 0.01
I0123 22:07:40.150681 29630 solver.cpp:237] Iteration 40660, loss = 3.59615
I0123 22:07:40.150722 29630 solver.cpp:253]     Train net output #0: loss = 3.59615 (* 1 = 3.59615 loss)
I0123 22:07:40.150727 29630 sgd_solver.cpp:106] Iteration 40660, lr = 0.01
I0123 22:07:47.350582 29630 solver.cpp:237] Iteration 40680, loss = 3.36348
I0123 22:07:47.350620 29630 solver.cpp:253]     Train net output #0: loss = 3.36348 (* 1 = 3.36348 loss)
I0123 22:07:47.350627 29630 sgd_solver.cpp:106] Iteration 40680, lr = 0.01
I0123 22:07:54.629457 29630 solver.cpp:237] Iteration 40700, loss = 3.54477
I0123 22:07:54.629577 29630 solver.cpp:253]     Train net output #0: loss = 3.54477 (* 1 = 3.54477 loss)
I0123 22:07:54.629585 29630 sgd_solver.cpp:106] Iteration 40700, lr = 0.01
I0123 22:08:01.883891 29630 solver.cpp:237] Iteration 40720, loss = 3.50643
I0123 22:08:01.883930 29630 solver.cpp:253]     Train net output #0: loss = 3.50643 (* 1 = 3.50643 loss)
I0123 22:08:01.883937 29630 sgd_solver.cpp:106] Iteration 40720, lr = 0.01
I0123 22:08:09.133034 29630 solver.cpp:237] Iteration 40740, loss = 3.42098
I0123 22:08:09.133072 29630 solver.cpp:253]     Train net output #0: loss = 3.42098 (* 1 = 3.42098 loss)
I0123 22:08:09.133079 29630 sgd_solver.cpp:106] Iteration 40740, lr = 0.01
I0123 22:08:16.450533 29630 solver.cpp:237] Iteration 40760, loss = 3.5187
I0123 22:08:16.450562 29630 solver.cpp:253]     Train net output #0: loss = 3.5187 (* 1 = 3.5187 loss)
I0123 22:08:16.450568 29630 sgd_solver.cpp:106] Iteration 40760, lr = 0.01
I0123 22:08:23.743966 29630 solver.cpp:237] Iteration 40780, loss = 3.76835
I0123 22:08:23.744004 29630 solver.cpp:253]     Train net output #0: loss = 3.76835 (* 1 = 3.76835 loss)
I0123 22:08:23.744010 29630 sgd_solver.cpp:106] Iteration 40780, lr = 0.01
I0123 22:08:31.072645 29630 solver.cpp:237] Iteration 40800, loss = 3.41364
I0123 22:08:31.072765 29630 solver.cpp:253]     Train net output #0: loss = 3.41364 (* 1 = 3.41364 loss)
I0123 22:08:31.072783 29630 sgd_solver.cpp:106] Iteration 40800, lr = 0.01
I0123 22:08:38.284678 29630 solver.cpp:237] Iteration 40820, loss = 3.53357
I0123 22:08:38.284718 29630 solver.cpp:253]     Train net output #0: loss = 3.53357 (* 1 = 3.53357 loss)
I0123 22:08:38.284724 29630 sgd_solver.cpp:106] Iteration 40820, lr = 0.01
I0123 22:08:45.546789 29630 solver.cpp:237] Iteration 40840, loss = 3.55065
I0123 22:08:45.546828 29630 solver.cpp:253]     Train net output #0: loss = 3.55065 (* 1 = 3.55065 loss)
I0123 22:08:45.546834 29630 sgd_solver.cpp:106] Iteration 40840, lr = 0.01
I0123 22:08:52.851213 29630 solver.cpp:237] Iteration 40860, loss = 3.5677
I0123 22:08:52.851253 29630 solver.cpp:253]     Train net output #0: loss = 3.5677 (* 1 = 3.5677 loss)
I0123 22:08:52.851259 29630 sgd_solver.cpp:106] Iteration 40860, lr = 0.01
I0123 22:09:00.141218 29630 solver.cpp:237] Iteration 40880, loss = 3.38389
I0123 22:09:00.141255 29630 solver.cpp:253]     Train net output #0: loss = 3.38389 (* 1 = 3.38389 loss)
I0123 22:09:00.141261 29630 sgd_solver.cpp:106] Iteration 40880, lr = 0.01
I0123 22:09:07.460253 29630 solver.cpp:237] Iteration 40900, loss = 3.59156
I0123 22:09:07.460420 29630 solver.cpp:253]     Train net output #0: loss = 3.59156 (* 1 = 3.59156 loss)
I0123 22:09:07.460428 29630 sgd_solver.cpp:106] Iteration 40900, lr = 0.01
I0123 22:09:14.737665 29630 solver.cpp:237] Iteration 40920, loss = 3.61288
I0123 22:09:14.737704 29630 solver.cpp:253]     Train net output #0: loss = 3.61288 (* 1 = 3.61288 loss)
I0123 22:09:14.737709 29630 sgd_solver.cpp:106] Iteration 40920, lr = 0.01
I0123 22:09:22.002102 29630 solver.cpp:237] Iteration 40940, loss = 3.57948
I0123 22:09:22.002140 29630 solver.cpp:253]     Train net output #0: loss = 3.57948 (* 1 = 3.57948 loss)
I0123 22:09:22.002146 29630 sgd_solver.cpp:106] Iteration 40940, lr = 0.01
I0123 22:09:29.289990 29630 solver.cpp:237] Iteration 40960, loss = 3.55205
I0123 22:09:29.290030 29630 solver.cpp:253]     Train net output #0: loss = 3.55205 (* 1 = 3.55205 loss)
I0123 22:09:29.290036 29630 sgd_solver.cpp:106] Iteration 40960, lr = 0.01
I0123 22:09:36.603807 29630 solver.cpp:237] Iteration 40980, loss = 3.4562
I0123 22:09:36.603848 29630 solver.cpp:253]     Train net output #0: loss = 3.4562 (* 1 = 3.4562 loss)
I0123 22:09:36.603855 29630 sgd_solver.cpp:106] Iteration 40980, lr = 0.01
I0123 22:09:43.613260 29630 solver.cpp:341] Iteration 41000, Testing net (#0)
I0123 22:10:01.584408 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 22:10:57.363615 29630 solver.cpp:409]     Test net output #0: accuracy = 0.29316
I0123 22:10:57.363759 29630 solver.cpp:409]     Test net output #1: loss = 3.40103 (* 1 = 3.40103 loss)
I0123 22:10:57.404536 29630 solver.cpp:237] Iteration 41000, loss = 3.45283
I0123 22:10:57.404573 29630 solver.cpp:253]     Train net output #0: loss = 3.45283 (* 1 = 3.45283 loss)
I0123 22:10:57.404580 29630 sgd_solver.cpp:106] Iteration 41000, lr = 0.01
I0123 22:11:03.910794 29630 solver.cpp:237] Iteration 41020, loss = 3.30463
I0123 22:11:03.910832 29630 solver.cpp:253]     Train net output #0: loss = 3.30463 (* 1 = 3.30463 loss)
I0123 22:11:03.910838 29630 sgd_solver.cpp:106] Iteration 41020, lr = 0.01
I0123 22:11:11.168524 29630 solver.cpp:237] Iteration 41040, loss = 3.48845
I0123 22:11:11.168562 29630 solver.cpp:253]     Train net output #0: loss = 3.48845 (* 1 = 3.48845 loss)
I0123 22:11:11.168570 29630 sgd_solver.cpp:106] Iteration 41040, lr = 0.01
I0123 22:11:18.377828 29630 solver.cpp:237] Iteration 41060, loss = 3.52941
I0123 22:11:18.377867 29630 solver.cpp:253]     Train net output #0: loss = 3.52941 (* 1 = 3.52941 loss)
I0123 22:11:18.377873 29630 sgd_solver.cpp:106] Iteration 41060, lr = 0.01
I0123 22:11:25.620378 29630 solver.cpp:237] Iteration 41080, loss = 3.38342
I0123 22:11:25.620416 29630 solver.cpp:253]     Train net output #0: loss = 3.38342 (* 1 = 3.38342 loss)
I0123 22:11:25.620422 29630 sgd_solver.cpp:106] Iteration 41080, lr = 0.01
I0123 22:11:32.836196 29630 solver.cpp:237] Iteration 41100, loss = 3.44754
I0123 22:11:32.836361 29630 solver.cpp:253]     Train net output #0: loss = 3.44754 (* 1 = 3.44754 loss)
I0123 22:11:32.836369 29630 sgd_solver.cpp:106] Iteration 41100, lr = 0.01
I0123 22:11:40.069530 29630 solver.cpp:237] Iteration 41120, loss = 3.56507
I0123 22:11:40.069572 29630 solver.cpp:253]     Train net output #0: loss = 3.56507 (* 1 = 3.56507 loss)
I0123 22:11:40.069578 29630 sgd_solver.cpp:106] Iteration 41120, lr = 0.01
I0123 22:11:47.312719 29630 solver.cpp:237] Iteration 41140, loss = 3.56826
I0123 22:11:47.312757 29630 solver.cpp:253]     Train net output #0: loss = 3.56826 (* 1 = 3.56826 loss)
I0123 22:11:47.312763 29630 sgd_solver.cpp:106] Iteration 41140, lr = 0.01
I0123 22:11:54.584584 29630 solver.cpp:237] Iteration 41160, loss = 3.62667
I0123 22:11:54.584624 29630 solver.cpp:253]     Train net output #0: loss = 3.62667 (* 1 = 3.62667 loss)
I0123 22:11:54.584630 29630 sgd_solver.cpp:106] Iteration 41160, lr = 0.01
I0123 22:12:01.906594 29630 solver.cpp:237] Iteration 41180, loss = 3.61065
I0123 22:12:01.906632 29630 solver.cpp:253]     Train net output #0: loss = 3.61065 (* 1 = 3.61065 loss)
I0123 22:12:01.906640 29630 sgd_solver.cpp:106] Iteration 41180, lr = 0.01
I0123 22:12:09.153863 29630 solver.cpp:237] Iteration 41200, loss = 3.4884
I0123 22:12:09.153985 29630 solver.cpp:253]     Train net output #0: loss = 3.4884 (* 1 = 3.4884 loss)
I0123 22:12:09.153992 29630 sgd_solver.cpp:106] Iteration 41200, lr = 0.01
I0123 22:12:16.436815 29630 solver.cpp:237] Iteration 41220, loss = 3.58134
I0123 22:12:16.436853 29630 solver.cpp:253]     Train net output #0: loss = 3.58134 (* 1 = 3.58134 loss)
I0123 22:12:16.436859 29630 sgd_solver.cpp:106] Iteration 41220, lr = 0.01
I0123 22:12:23.729903 29630 solver.cpp:237] Iteration 41240, loss = 3.29455
I0123 22:12:23.729943 29630 solver.cpp:253]     Train net output #0: loss = 3.29455 (* 1 = 3.29455 loss)
I0123 22:12:23.729949 29630 sgd_solver.cpp:106] Iteration 41240, lr = 0.01
I0123 22:12:26.316476 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 22:12:30.950534 29630 solver.cpp:237] Iteration 41260, loss = 3.55367
I0123 22:12:30.950603 29630 solver.cpp:253]     Train net output #0: loss = 3.55367 (* 1 = 3.55367 loss)
I0123 22:12:30.950616 29630 sgd_solver.cpp:106] Iteration 41260, lr = 0.01
I0123 22:12:38.203501 29630 solver.cpp:237] Iteration 41280, loss = 3.41157
I0123 22:12:38.203541 29630 solver.cpp:253]     Train net output #0: loss = 3.41157 (* 1 = 3.41157 loss)
I0123 22:12:38.203547 29630 sgd_solver.cpp:106] Iteration 41280, lr = 0.01
I0123 22:12:45.500084 29630 solver.cpp:237] Iteration 41300, loss = 3.32882
I0123 22:12:45.500241 29630 solver.cpp:253]     Train net output #0: loss = 3.32882 (* 1 = 3.32882 loss)
I0123 22:12:45.500248 29630 sgd_solver.cpp:106] Iteration 41300, lr = 0.01
I0123 22:12:52.789863 29630 solver.cpp:237] Iteration 41320, loss = 3.53558
I0123 22:12:52.789901 29630 solver.cpp:253]     Train net output #0: loss = 3.53558 (* 1 = 3.53558 loss)
I0123 22:12:52.789908 29630 sgd_solver.cpp:106] Iteration 41320, lr = 0.01
I0123 22:13:00.049304 29630 solver.cpp:237] Iteration 41340, loss = 3.82324
I0123 22:13:00.049343 29630 solver.cpp:253]     Train net output #0: loss = 3.82324 (* 1 = 3.82324 loss)
I0123 22:13:00.049350 29630 sgd_solver.cpp:106] Iteration 41340, lr = 0.01
I0123 22:13:07.342200 29630 solver.cpp:237] Iteration 41360, loss = 3.5239
I0123 22:13:07.342238 29630 solver.cpp:253]     Train net output #0: loss = 3.5239 (* 1 = 3.5239 loss)
I0123 22:13:07.342244 29630 sgd_solver.cpp:106] Iteration 41360, lr = 0.01
I0123 22:13:14.663987 29630 solver.cpp:237] Iteration 41380, loss = 3.36372
I0123 22:13:14.664026 29630 solver.cpp:253]     Train net output #0: loss = 3.36372 (* 1 = 3.36372 loss)
I0123 22:13:14.664031 29630 sgd_solver.cpp:106] Iteration 41380, lr = 0.01
I0123 22:13:21.947680 29630 solver.cpp:237] Iteration 41400, loss = 3.59475
I0123 22:13:21.947857 29630 solver.cpp:253]     Train net output #0: loss = 3.59475 (* 1 = 3.59475 loss)
I0123 22:13:21.947865 29630 sgd_solver.cpp:106] Iteration 41400, lr = 0.01
I0123 22:13:29.229069 29630 solver.cpp:237] Iteration 41420, loss = 3.78866
I0123 22:13:29.229110 29630 solver.cpp:253]     Train net output #0: loss = 3.78866 (* 1 = 3.78866 loss)
I0123 22:13:29.229115 29630 sgd_solver.cpp:106] Iteration 41420, lr = 0.01
I0123 22:13:36.502393 29630 solver.cpp:237] Iteration 41440, loss = 3.31506
I0123 22:13:36.502431 29630 solver.cpp:253]     Train net output #0: loss = 3.31506 (* 1 = 3.31506 loss)
I0123 22:13:36.502437 29630 sgd_solver.cpp:106] Iteration 41440, lr = 0.01
I0123 22:13:43.778681 29630 solver.cpp:237] Iteration 41460, loss = 3.55955
I0123 22:13:43.778719 29630 solver.cpp:253]     Train net output #0: loss = 3.55955 (* 1 = 3.55955 loss)
I0123 22:13:43.778725 29630 sgd_solver.cpp:106] Iteration 41460, lr = 0.01
I0123 22:13:51.056102 29630 solver.cpp:237] Iteration 41480, loss = 3.55549
I0123 22:13:51.056141 29630 solver.cpp:253]     Train net output #0: loss = 3.55549 (* 1 = 3.55549 loss)
I0123 22:13:51.056148 29630 sgd_solver.cpp:106] Iteration 41480, lr = 0.01
I0123 22:13:58.315882 29630 solver.cpp:237] Iteration 41500, loss = 3.18094
I0123 22:13:58.315991 29630 solver.cpp:253]     Train net output #0: loss = 3.18094 (* 1 = 3.18094 loss)
I0123 22:13:58.316007 29630 sgd_solver.cpp:106] Iteration 41500, lr = 0.01
I0123 22:14:05.489128 29630 solver.cpp:237] Iteration 41520, loss = 3.48367
I0123 22:14:05.489167 29630 solver.cpp:253]     Train net output #0: loss = 3.48367 (* 1 = 3.48367 loss)
I0123 22:14:05.489173 29630 sgd_solver.cpp:106] Iteration 41520, lr = 0.01
I0123 22:14:12.766232 29630 solver.cpp:237] Iteration 41540, loss = 3.51341
I0123 22:14:12.766271 29630 solver.cpp:253]     Train net output #0: loss = 3.51341 (* 1 = 3.51341 loss)
I0123 22:14:12.766278 29630 sgd_solver.cpp:106] Iteration 41540, lr = 0.01
I0123 22:14:20.046656 29630 solver.cpp:237] Iteration 41560, loss = 3.35276
I0123 22:14:20.046696 29630 solver.cpp:253]     Train net output #0: loss = 3.35276 (* 1 = 3.35276 loss)
I0123 22:14:20.046702 29630 sgd_solver.cpp:106] Iteration 41560, lr = 0.01
I0123 22:14:27.330340 29630 solver.cpp:237] Iteration 41580, loss = 3.58157
I0123 22:14:27.330379 29630 solver.cpp:253]     Train net output #0: loss = 3.58157 (* 1 = 3.58157 loss)
I0123 22:14:27.330385 29630 sgd_solver.cpp:106] Iteration 41580, lr = 0.01
I0123 22:14:34.599709 29630 solver.cpp:237] Iteration 41600, loss = 3.67381
I0123 22:14:34.599889 29630 solver.cpp:253]     Train net output #0: loss = 3.67381 (* 1 = 3.67381 loss)
I0123 22:14:34.599896 29630 sgd_solver.cpp:106] Iteration 41600, lr = 0.01
I0123 22:14:41.788133 29630 solver.cpp:237] Iteration 41620, loss = 3.70092
I0123 22:14:41.788172 29630 solver.cpp:253]     Train net output #0: loss = 3.70092 (* 1 = 3.70092 loss)
I0123 22:14:41.788179 29630 sgd_solver.cpp:106] Iteration 41620, lr = 0.01
I0123 22:14:49.089484 29630 solver.cpp:237] Iteration 41640, loss = 3.54028
I0123 22:14:49.089522 29630 solver.cpp:253]     Train net output #0: loss = 3.54028 (* 1 = 3.54028 loss)
I0123 22:14:49.089529 29630 sgd_solver.cpp:106] Iteration 41640, lr = 0.01
I0123 22:14:56.326241 29630 solver.cpp:237] Iteration 41660, loss = 3.40032
I0123 22:14:56.326278 29630 solver.cpp:253]     Train net output #0: loss = 3.40032 (* 1 = 3.40032 loss)
I0123 22:14:56.326285 29630 sgd_solver.cpp:106] Iteration 41660, lr = 0.01
I0123 22:15:03.575698 29630 solver.cpp:237] Iteration 41680, loss = 3.90856
I0123 22:15:03.575736 29630 solver.cpp:253]     Train net output #0: loss = 3.90856 (* 1 = 3.90856 loss)
I0123 22:15:03.575742 29630 sgd_solver.cpp:106] Iteration 41680, lr = 0.01
I0123 22:15:10.828625 29630 solver.cpp:237] Iteration 41700, loss = 3.49079
I0123 22:15:10.828774 29630 solver.cpp:253]     Train net output #0: loss = 3.49079 (* 1 = 3.49079 loss)
I0123 22:15:10.828783 29630 sgd_solver.cpp:106] Iteration 41700, lr = 0.01
I0123 22:15:18.086678 29630 solver.cpp:237] Iteration 41720, loss = 3.34258
I0123 22:15:18.086717 29630 solver.cpp:253]     Train net output #0: loss = 3.34258 (* 1 = 3.34258 loss)
I0123 22:15:18.086724 29630 sgd_solver.cpp:106] Iteration 41720, lr = 0.01
I0123 22:15:25.340843 29630 solver.cpp:237] Iteration 41740, loss = 3.44103
I0123 22:15:25.340883 29630 solver.cpp:253]     Train net output #0: loss = 3.44103 (* 1 = 3.44103 loss)
I0123 22:15:25.340889 29630 sgd_solver.cpp:106] Iteration 41740, lr = 0.01
I0123 22:15:32.601991 29630 solver.cpp:237] Iteration 41760, loss = 3.39147
I0123 22:15:32.602028 29630 solver.cpp:253]     Train net output #0: loss = 3.39147 (* 1 = 3.39147 loss)
I0123 22:15:32.602035 29630 sgd_solver.cpp:106] Iteration 41760, lr = 0.01
I0123 22:15:39.862182 29630 solver.cpp:237] Iteration 41780, loss = 3.39143
I0123 22:15:39.862221 29630 solver.cpp:253]     Train net output #0: loss = 3.39143 (* 1 = 3.39143 loss)
I0123 22:15:39.862226 29630 sgd_solver.cpp:106] Iteration 41780, lr = 0.01
I0123 22:15:47.096824 29630 solver.cpp:237] Iteration 41800, loss = 3.69244
I0123 22:15:47.096962 29630 solver.cpp:253]     Train net output #0: loss = 3.69244 (* 1 = 3.69244 loss)
I0123 22:15:47.096971 29630 sgd_solver.cpp:106] Iteration 41800, lr = 0.01
I0123 22:15:54.328866 29630 solver.cpp:237] Iteration 41820, loss = 3.47295
I0123 22:15:54.328904 29630 solver.cpp:253]     Train net output #0: loss = 3.47295 (* 1 = 3.47295 loss)
I0123 22:15:54.328910 29630 sgd_solver.cpp:106] Iteration 41820, lr = 0.01
I0123 22:16:01.604063 29630 solver.cpp:237] Iteration 41840, loss = 3.36339
I0123 22:16:01.604100 29630 solver.cpp:253]     Train net output #0: loss = 3.36339 (* 1 = 3.36339 loss)
I0123 22:16:01.604106 29630 sgd_solver.cpp:106] Iteration 41840, lr = 0.01
I0123 22:16:08.888310 29630 solver.cpp:237] Iteration 41860, loss = 3.5213
I0123 22:16:08.888350 29630 solver.cpp:253]     Train net output #0: loss = 3.5213 (* 1 = 3.5213 loss)
I0123 22:16:08.888356 29630 sgd_solver.cpp:106] Iteration 41860, lr = 0.01
I0123 22:16:16.188792 29630 solver.cpp:237] Iteration 41880, loss = 3.66023
I0123 22:16:16.188832 29630 solver.cpp:253]     Train net output #0: loss = 3.66023 (* 1 = 3.66023 loss)
I0123 22:16:16.188838 29630 sgd_solver.cpp:106] Iteration 41880, lr = 0.01
I0123 22:16:23.458410 29630 solver.cpp:237] Iteration 41900, loss = 3.25762
I0123 22:16:23.458570 29630 solver.cpp:253]     Train net output #0: loss = 3.25762 (* 1 = 3.25762 loss)
I0123 22:16:23.458581 29630 sgd_solver.cpp:106] Iteration 41900, lr = 0.01
I0123 22:16:30.726114 29630 solver.cpp:237] Iteration 41920, loss = 3.42082
I0123 22:16:30.726150 29630 solver.cpp:253]     Train net output #0: loss = 3.42082 (* 1 = 3.42082 loss)
I0123 22:16:30.726156 29630 sgd_solver.cpp:106] Iteration 41920, lr = 0.01
I0123 22:16:38.027740 29630 solver.cpp:237] Iteration 41940, loss = 3.44572
I0123 22:16:38.027772 29630 solver.cpp:253]     Train net output #0: loss = 3.44572 (* 1 = 3.44572 loss)
I0123 22:16:38.027779 29630 sgd_solver.cpp:106] Iteration 41940, lr = 0.01
I0123 22:16:45.258874 29630 solver.cpp:237] Iteration 41960, loss = 3.41791
I0123 22:16:45.258919 29630 solver.cpp:253]     Train net output #0: loss = 3.41791 (* 1 = 3.41791 loss)
I0123 22:16:45.258935 29630 sgd_solver.cpp:106] Iteration 41960, lr = 0.01
I0123 22:16:52.573281 29630 solver.cpp:237] Iteration 41980, loss = 3.46656
I0123 22:16:52.573323 29630 solver.cpp:253]     Train net output #0: loss = 3.46656 (* 1 = 3.46656 loss)
I0123 22:16:52.573341 29630 sgd_solver.cpp:106] Iteration 41980, lr = 0.01
I0123 22:16:59.566854 29630 solver.cpp:341] Iteration 42000, Testing net (#0)
I0123 22:17:17.987684 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 22:18:13.364298 29630 solver.cpp:409]     Test net output #0: accuracy = 0.29066
I0123 22:18:13.364410 29630 solver.cpp:409]     Test net output #1: loss = 3.39605 (* 1 = 3.39605 loss)
I0123 22:18:13.404986 29630 solver.cpp:237] Iteration 42000, loss = 3.31347
I0123 22:18:13.405024 29630 solver.cpp:253]     Train net output #0: loss = 3.31347 (* 1 = 3.31347 loss)
I0123 22:18:13.405030 29630 sgd_solver.cpp:106] Iteration 42000, lr = 0.01
I0123 22:18:19.987505 29630 solver.cpp:237] Iteration 42020, loss = 3.57774
I0123 22:18:19.987542 29630 solver.cpp:253]     Train net output #0: loss = 3.57774 (* 1 = 3.57774 loss)
I0123 22:18:19.987558 29630 sgd_solver.cpp:106] Iteration 42020, lr = 0.01
I0123 22:18:27.254739 29630 solver.cpp:237] Iteration 42040, loss = 3.43149
I0123 22:18:27.254778 29630 solver.cpp:253]     Train net output #0: loss = 3.43149 (* 1 = 3.43149 loss)
I0123 22:18:27.254784 29630 sgd_solver.cpp:106] Iteration 42040, lr = 0.01
I0123 22:18:34.494411 29630 solver.cpp:237] Iteration 42060, loss = 3.62305
I0123 22:18:34.494451 29630 solver.cpp:253]     Train net output #0: loss = 3.62305 (* 1 = 3.62305 loss)
I0123 22:18:34.494457 29630 sgd_solver.cpp:106] Iteration 42060, lr = 0.01
I0123 22:18:41.742935 29630 solver.cpp:237] Iteration 42080, loss = 3.64572
I0123 22:18:41.742979 29630 solver.cpp:253]     Train net output #0: loss = 3.64572 (* 1 = 3.64572 loss)
I0123 22:18:41.742997 29630 sgd_solver.cpp:106] Iteration 42080, lr = 0.01
I0123 22:18:49.013767 29630 solver.cpp:237] Iteration 42100, loss = 3.61176
I0123 22:18:49.013913 29630 solver.cpp:253]     Train net output #0: loss = 3.61176 (* 1 = 3.61176 loss)
I0123 22:18:49.013921 29630 sgd_solver.cpp:106] Iteration 42100, lr = 0.01
I0123 22:18:56.222391 29630 solver.cpp:237] Iteration 42120, loss = 3.76831
I0123 22:18:56.222430 29630 solver.cpp:253]     Train net output #0: loss = 3.76831 (* 1 = 3.76831 loss)
I0123 22:18:56.222437 29630 sgd_solver.cpp:106] Iteration 42120, lr = 0.01
I0123 22:19:03.464495 29630 solver.cpp:237] Iteration 42140, loss = 3.75968
I0123 22:19:03.464534 29630 solver.cpp:253]     Train net output #0: loss = 3.75968 (* 1 = 3.75968 loss)
I0123 22:19:03.464540 29630 sgd_solver.cpp:106] Iteration 42140, lr = 0.01
I0123 22:19:10.690493 29630 solver.cpp:237] Iteration 42160, loss = 3.75087
I0123 22:19:10.690531 29630 solver.cpp:253]     Train net output #0: loss = 3.75087 (* 1 = 3.75087 loss)
I0123 22:19:10.690537 29630 sgd_solver.cpp:106] Iteration 42160, lr = 0.01
I0123 22:19:17.974503 29630 solver.cpp:237] Iteration 42180, loss = 3.4567
I0123 22:19:17.974541 29630 solver.cpp:253]     Train net output #0: loss = 3.4567 (* 1 = 3.4567 loss)
I0123 22:19:17.974548 29630 sgd_solver.cpp:106] Iteration 42180, lr = 0.01
I0123 22:19:25.243729 29630 solver.cpp:237] Iteration 42200, loss = 3.70921
I0123 22:19:25.243904 29630 solver.cpp:253]     Train net output #0: loss = 3.70921 (* 1 = 3.70921 loss)
I0123 22:19:25.243912 29630 sgd_solver.cpp:106] Iteration 42200, lr = 0.01
I0123 22:19:32.450403 29630 solver.cpp:237] Iteration 42220, loss = 3.32766
I0123 22:19:32.450453 29630 solver.cpp:253]     Train net output #0: loss = 3.32766 (* 1 = 3.32766 loss)
I0123 22:19:32.450459 29630 sgd_solver.cpp:106] Iteration 42220, lr = 0.01
I0123 22:19:39.702730 29630 solver.cpp:237] Iteration 42240, loss = 3.43748
I0123 22:19:39.702769 29630 solver.cpp:253]     Train net output #0: loss = 3.43748 (* 1 = 3.43748 loss)
I0123 22:19:39.702775 29630 sgd_solver.cpp:106] Iteration 42240, lr = 0.01
I0123 22:19:44.465242 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 22:19:46.907883 29630 solver.cpp:237] Iteration 42260, loss = 3.61642
I0123 22:19:46.907923 29630 solver.cpp:253]     Train net output #0: loss = 3.61642 (* 1 = 3.61642 loss)
I0123 22:19:46.907928 29630 sgd_solver.cpp:106] Iteration 42260, lr = 0.01
I0123 22:19:54.257032 29630 solver.cpp:237] Iteration 42280, loss = 3.60728
I0123 22:19:54.257072 29630 solver.cpp:253]     Train net output #0: loss = 3.60728 (* 1 = 3.60728 loss)
I0123 22:19:54.257078 29630 sgd_solver.cpp:106] Iteration 42280, lr = 0.01
I0123 22:20:01.543938 29630 solver.cpp:237] Iteration 42300, loss = 3.57806
I0123 22:20:01.544128 29630 solver.cpp:253]     Train net output #0: loss = 3.57806 (* 1 = 3.57806 loss)
I0123 22:20:01.544137 29630 sgd_solver.cpp:106] Iteration 42300, lr = 0.01
I0123 22:20:08.776916 29630 solver.cpp:237] Iteration 42320, loss = 3.61495
I0123 22:20:08.776955 29630 solver.cpp:253]     Train net output #0: loss = 3.61495 (* 1 = 3.61495 loss)
I0123 22:20:08.776962 29630 sgd_solver.cpp:106] Iteration 42320, lr = 0.01
I0123 22:20:16.082304 29630 solver.cpp:237] Iteration 42340, loss = 3.4912
I0123 22:20:16.082346 29630 solver.cpp:253]     Train net output #0: loss = 3.4912 (* 1 = 3.4912 loss)
I0123 22:20:16.082352 29630 sgd_solver.cpp:106] Iteration 42340, lr = 0.01
I0123 22:20:23.389343 29630 solver.cpp:237] Iteration 42360, loss = 3.52444
I0123 22:20:23.389389 29630 solver.cpp:253]     Train net output #0: loss = 3.52444 (* 1 = 3.52444 loss)
I0123 22:20:23.389394 29630 sgd_solver.cpp:106] Iteration 42360, lr = 0.01
I0123 22:20:30.672497 29630 solver.cpp:237] Iteration 42380, loss = 3.69173
I0123 22:20:30.672538 29630 solver.cpp:253]     Train net output #0: loss = 3.69173 (* 1 = 3.69173 loss)
I0123 22:20:30.672544 29630 sgd_solver.cpp:106] Iteration 42380, lr = 0.01
I0123 22:20:37.904678 29630 solver.cpp:237] Iteration 42400, loss = 3.80039
I0123 22:20:37.904832 29630 solver.cpp:253]     Train net output #0: loss = 3.80039 (* 1 = 3.80039 loss)
I0123 22:20:37.904840 29630 sgd_solver.cpp:106] Iteration 42400, lr = 0.01
I0123 22:20:45.147071 29630 solver.cpp:237] Iteration 42420, loss = 3.51253
I0123 22:20:45.147110 29630 solver.cpp:253]     Train net output #0: loss = 3.51253 (* 1 = 3.51253 loss)
I0123 22:20:45.147116 29630 sgd_solver.cpp:106] Iteration 42420, lr = 0.01
I0123 22:20:52.429687 29630 solver.cpp:237] Iteration 42440, loss = 3.38969
I0123 22:20:52.429725 29630 solver.cpp:253]     Train net output #0: loss = 3.38969 (* 1 = 3.38969 loss)
I0123 22:20:52.429731 29630 sgd_solver.cpp:106] Iteration 42440, lr = 0.01
I0123 22:20:59.709699 29630 solver.cpp:237] Iteration 42460, loss = 3.50756
I0123 22:20:59.709758 29630 solver.cpp:253]     Train net output #0: loss = 3.50756 (* 1 = 3.50756 loss)
I0123 22:20:59.709766 29630 sgd_solver.cpp:106] Iteration 42460, lr = 0.01
I0123 22:21:07.017364 29630 solver.cpp:237] Iteration 42480, loss = 3.87377
I0123 22:21:07.017402 29630 solver.cpp:253]     Train net output #0: loss = 3.87377 (* 1 = 3.87377 loss)
I0123 22:21:07.017408 29630 sgd_solver.cpp:106] Iteration 42480, lr = 0.01
I0123 22:21:14.263396 29630 solver.cpp:237] Iteration 42500, loss = 3.51694
I0123 22:21:14.263494 29630 solver.cpp:253]     Train net output #0: loss = 3.51694 (* 1 = 3.51694 loss)
I0123 22:21:14.263510 29630 sgd_solver.cpp:106] Iteration 42500, lr = 0.01
I0123 22:21:21.530587 29630 solver.cpp:237] Iteration 42520, loss = 3.3402
I0123 22:21:21.530627 29630 solver.cpp:253]     Train net output #0: loss = 3.3402 (* 1 = 3.3402 loss)
I0123 22:21:21.530633 29630 sgd_solver.cpp:106] Iteration 42520, lr = 0.01
I0123 22:21:28.818248 29630 solver.cpp:237] Iteration 42540, loss = 3.63409
I0123 22:21:28.818286 29630 solver.cpp:253]     Train net output #0: loss = 3.63409 (* 1 = 3.63409 loss)
I0123 22:21:28.818292 29630 sgd_solver.cpp:106] Iteration 42540, lr = 0.01
I0123 22:21:36.123050 29630 solver.cpp:237] Iteration 42560, loss = 3.48967
I0123 22:21:36.123088 29630 solver.cpp:253]     Train net output #0: loss = 3.48967 (* 1 = 3.48967 loss)
I0123 22:21:36.123095 29630 sgd_solver.cpp:106] Iteration 42560, lr = 0.01
I0123 22:21:43.357491 29630 solver.cpp:237] Iteration 42580, loss = 3.64338
I0123 22:21:43.357528 29630 solver.cpp:253]     Train net output #0: loss = 3.64338 (* 1 = 3.64338 loss)
I0123 22:21:43.357534 29630 sgd_solver.cpp:106] Iteration 42580, lr = 0.01
I0123 22:21:50.607089 29630 solver.cpp:237] Iteration 42600, loss = 3.45294
I0123 22:21:50.607208 29630 solver.cpp:253]     Train net output #0: loss = 3.45294 (* 1 = 3.45294 loss)
I0123 22:21:50.607224 29630 sgd_solver.cpp:106] Iteration 42600, lr = 0.01
I0123 22:21:57.829771 29630 solver.cpp:237] Iteration 42620, loss = 3.44048
I0123 22:21:57.829810 29630 solver.cpp:253]     Train net output #0: loss = 3.44048 (* 1 = 3.44048 loss)
I0123 22:21:57.829816 29630 sgd_solver.cpp:106] Iteration 42620, lr = 0.01
I0123 22:22:05.053076 29630 solver.cpp:237] Iteration 42640, loss = 3.50642
I0123 22:22:05.053115 29630 solver.cpp:253]     Train net output #0: loss = 3.50642 (* 1 = 3.50642 loss)
I0123 22:22:05.053122 29630 sgd_solver.cpp:106] Iteration 42640, lr = 0.01
I0123 22:22:12.261024 29630 solver.cpp:237] Iteration 42660, loss = 3.37896
I0123 22:22:12.261065 29630 solver.cpp:253]     Train net output #0: loss = 3.37896 (* 1 = 3.37896 loss)
I0123 22:22:12.261070 29630 sgd_solver.cpp:106] Iteration 42660, lr = 0.01
I0123 22:22:19.524068 29630 solver.cpp:237] Iteration 42680, loss = 3.46521
I0123 22:22:19.524106 29630 solver.cpp:253]     Train net output #0: loss = 3.46521 (* 1 = 3.46521 loss)
I0123 22:22:19.524112 29630 sgd_solver.cpp:106] Iteration 42680, lr = 0.01
I0123 22:22:26.756862 29630 solver.cpp:237] Iteration 42700, loss = 3.41896
I0123 22:22:26.756991 29630 solver.cpp:253]     Train net output #0: loss = 3.41896 (* 1 = 3.41896 loss)
I0123 22:22:26.756999 29630 sgd_solver.cpp:106] Iteration 42700, lr = 0.01
I0123 22:22:34.001907 29630 solver.cpp:237] Iteration 42720, loss = 3.51224
I0123 22:22:34.001945 29630 solver.cpp:253]     Train net output #0: loss = 3.51224 (* 1 = 3.51224 loss)
I0123 22:22:34.001952 29630 sgd_solver.cpp:106] Iteration 42720, lr = 0.01
I0123 22:22:41.261163 29630 solver.cpp:237] Iteration 42740, loss = 3.42846
I0123 22:22:41.261203 29630 solver.cpp:253]     Train net output #0: loss = 3.42846 (* 1 = 3.42846 loss)
I0123 22:22:41.261209 29630 sgd_solver.cpp:106] Iteration 42740, lr = 0.01
I0123 22:22:48.482810 29630 solver.cpp:237] Iteration 42760, loss = 3.50965
I0123 22:22:48.482848 29630 solver.cpp:253]     Train net output #0: loss = 3.50965 (* 1 = 3.50965 loss)
I0123 22:22:48.482854 29630 sgd_solver.cpp:106] Iteration 42760, lr = 0.01
I0123 22:22:55.735565 29630 solver.cpp:237] Iteration 42780, loss = 3.38311
I0123 22:22:55.735605 29630 solver.cpp:253]     Train net output #0: loss = 3.38311 (* 1 = 3.38311 loss)
I0123 22:22:55.735610 29630 sgd_solver.cpp:106] Iteration 42780, lr = 0.01
I0123 22:23:03.005820 29630 solver.cpp:237] Iteration 42800, loss = 3.4549
I0123 22:23:03.005981 29630 solver.cpp:253]     Train net output #0: loss = 3.4549 (* 1 = 3.4549 loss)
I0123 22:23:03.005990 29630 sgd_solver.cpp:106] Iteration 42800, lr = 0.01
I0123 22:23:10.219178 29630 solver.cpp:237] Iteration 42820, loss = 3.4405
I0123 22:23:10.219218 29630 solver.cpp:253]     Train net output #0: loss = 3.4405 (* 1 = 3.4405 loss)
I0123 22:23:10.219223 29630 sgd_solver.cpp:106] Iteration 42820, lr = 0.01
I0123 22:23:17.485862 29630 solver.cpp:237] Iteration 42840, loss = 3.71123
I0123 22:23:17.485900 29630 solver.cpp:253]     Train net output #0: loss = 3.71123 (* 1 = 3.71123 loss)
I0123 22:23:17.485906 29630 sgd_solver.cpp:106] Iteration 42840, lr = 0.01
I0123 22:23:24.775107 29630 solver.cpp:237] Iteration 42860, loss = 3.65121
I0123 22:23:24.775147 29630 solver.cpp:253]     Train net output #0: loss = 3.65121 (* 1 = 3.65121 loss)
I0123 22:23:24.775153 29630 sgd_solver.cpp:106] Iteration 42860, lr = 0.01
I0123 22:23:32.050992 29630 solver.cpp:237] Iteration 42880, loss = 3.54317
I0123 22:23:32.051020 29630 solver.cpp:253]     Train net output #0: loss = 3.54317 (* 1 = 3.54317 loss)
I0123 22:23:32.051026 29630 sgd_solver.cpp:106] Iteration 42880, lr = 0.01
I0123 22:23:39.261864 29630 solver.cpp:237] Iteration 42900, loss = 3.45103
I0123 22:23:39.261984 29630 solver.cpp:253]     Train net output #0: loss = 3.45103 (* 1 = 3.45103 loss)
I0123 22:23:39.262001 29630 sgd_solver.cpp:106] Iteration 42900, lr = 0.01
I0123 22:23:46.480437 29630 solver.cpp:237] Iteration 42920, loss = 3.50548
I0123 22:23:46.480474 29630 solver.cpp:253]     Train net output #0: loss = 3.50548 (* 1 = 3.50548 loss)
I0123 22:23:46.480481 29630 sgd_solver.cpp:106] Iteration 42920, lr = 0.01
I0123 22:23:53.722846 29630 solver.cpp:237] Iteration 42940, loss = 3.66425
I0123 22:23:53.722885 29630 solver.cpp:253]     Train net output #0: loss = 3.66425 (* 1 = 3.66425 loss)
I0123 22:23:53.722892 29630 sgd_solver.cpp:106] Iteration 42940, lr = 0.01
I0123 22:24:00.966039 29630 solver.cpp:237] Iteration 42960, loss = 3.38784
I0123 22:24:00.966078 29630 solver.cpp:253]     Train net output #0: loss = 3.38784 (* 1 = 3.38784 loss)
I0123 22:24:00.966084 29630 sgd_solver.cpp:106] Iteration 42960, lr = 0.01
I0123 22:24:08.230177 29630 solver.cpp:237] Iteration 42980, loss = 3.5386
I0123 22:24:08.230217 29630 solver.cpp:253]     Train net output #0: loss = 3.5386 (* 1 = 3.5386 loss)
I0123 22:24:08.230224 29630 sgd_solver.cpp:106] Iteration 42980, lr = 0.01
I0123 22:24:15.196364 29630 solver.cpp:341] Iteration 43000, Testing net (#0)
I0123 22:24:34.047165 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 22:25:29.809746 29630 solver.cpp:409]     Test net output #0: accuracy = 0.3033
I0123 22:25:29.809855 29630 solver.cpp:409]     Test net output #1: loss = 3.31908 (* 1 = 3.31908 loss)
I0123 22:25:29.850509 29630 solver.cpp:237] Iteration 43000, loss = 3.3704
I0123 22:25:29.850538 29630 solver.cpp:253]     Train net output #0: loss = 3.3704 (* 1 = 3.3704 loss)
I0123 22:25:29.850544 29630 sgd_solver.cpp:106] Iteration 43000, lr = 0.01
I0123 22:25:36.441195 29630 solver.cpp:237] Iteration 43020, loss = 3.40697
I0123 22:25:36.441232 29630 solver.cpp:253]     Train net output #0: loss = 3.40697 (* 1 = 3.40697 loss)
I0123 22:25:36.441238 29630 sgd_solver.cpp:106] Iteration 43020, lr = 0.01
I0123 22:25:43.679672 29630 solver.cpp:237] Iteration 43040, loss = 3.74292
I0123 22:25:43.679711 29630 solver.cpp:253]     Train net output #0: loss = 3.74292 (* 1 = 3.74292 loss)
I0123 22:25:43.679718 29630 sgd_solver.cpp:106] Iteration 43040, lr = 0.01
I0123 22:25:50.982079 29630 solver.cpp:237] Iteration 43060, loss = 3.94362
I0123 22:25:50.982132 29630 solver.cpp:253]     Train net output #0: loss = 3.94362 (* 1 = 3.94362 loss)
I0123 22:25:50.982141 29630 sgd_solver.cpp:106] Iteration 43060, lr = 0.01
I0123 22:25:58.285195 29630 solver.cpp:237] Iteration 43080, loss = 3.6277
I0123 22:25:58.285233 29630 solver.cpp:253]     Train net output #0: loss = 3.6277 (* 1 = 3.6277 loss)
I0123 22:25:58.285238 29630 sgd_solver.cpp:106] Iteration 43080, lr = 0.01
I0123 22:26:05.548486 29630 solver.cpp:237] Iteration 43100, loss = 3.25565
I0123 22:26:05.548666 29630 solver.cpp:253]     Train net output #0: loss = 3.25565 (* 1 = 3.25565 loss)
I0123 22:26:05.548674 29630 sgd_solver.cpp:106] Iteration 43100, lr = 0.01
I0123 22:26:12.879873 29630 solver.cpp:237] Iteration 43120, loss = 3.37423
I0123 22:26:12.879920 29630 solver.cpp:253]     Train net output #0: loss = 3.37423 (* 1 = 3.37423 loss)
I0123 22:26:12.879925 29630 sgd_solver.cpp:106] Iteration 43120, lr = 0.01
I0123 22:26:20.175493 29630 solver.cpp:237] Iteration 43140, loss = 3.44542
I0123 22:26:20.175532 29630 solver.cpp:253]     Train net output #0: loss = 3.44542 (* 1 = 3.44542 loss)
I0123 22:26:20.175539 29630 sgd_solver.cpp:106] Iteration 43140, lr = 0.01
I0123 22:26:27.495921 29630 solver.cpp:237] Iteration 43160, loss = 3.6121
I0123 22:26:27.495960 29630 solver.cpp:253]     Train net output #0: loss = 3.6121 (* 1 = 3.6121 loss)
I0123 22:26:27.495966 29630 sgd_solver.cpp:106] Iteration 43160, lr = 0.01
I0123 22:26:34.766458 29630 solver.cpp:237] Iteration 43180, loss = 3.52867
I0123 22:26:34.766496 29630 solver.cpp:253]     Train net output #0: loss = 3.52867 (* 1 = 3.52867 loss)
I0123 22:26:34.766502 29630 sgd_solver.cpp:106] Iteration 43180, lr = 0.01
I0123 22:26:41.989841 29630 solver.cpp:237] Iteration 43200, loss = 3.51415
I0123 22:26:41.990005 29630 solver.cpp:253]     Train net output #0: loss = 3.51415 (* 1 = 3.51415 loss)
I0123 22:26:41.990013 29630 sgd_solver.cpp:106] Iteration 43200, lr = 0.01
I0123 22:26:49.301013 29630 solver.cpp:237] Iteration 43220, loss = 3.47412
I0123 22:26:49.301051 29630 solver.cpp:253]     Train net output #0: loss = 3.47412 (* 1 = 3.47412 loss)
I0123 22:26:49.301056 29630 sgd_solver.cpp:106] Iteration 43220, lr = 0.01
I0123 22:26:56.507230 29630 solver.cpp:237] Iteration 43240, loss = 3.52185
I0123 22:26:56.507271 29630 solver.cpp:253]     Train net output #0: loss = 3.52185 (* 1 = 3.52185 loss)
I0123 22:26:56.507277 29630 sgd_solver.cpp:106] Iteration 43240, lr = 0.01
I0123 22:27:03.507239 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 22:27:03.803208 29630 solver.cpp:237] Iteration 43260, loss = 3.69781
I0123 22:27:03.803246 29630 solver.cpp:253]     Train net output #0: loss = 3.69781 (* 1 = 3.69781 loss)
I0123 22:27:03.803252 29630 sgd_solver.cpp:106] Iteration 43260, lr = 0.01
I0123 22:27:11.013952 29630 solver.cpp:237] Iteration 43280, loss = 3.44885
I0123 22:27:11.013989 29630 solver.cpp:253]     Train net output #0: loss = 3.44885 (* 1 = 3.44885 loss)
I0123 22:27:11.013995 29630 sgd_solver.cpp:106] Iteration 43280, lr = 0.01
I0123 22:27:18.260602 29630 solver.cpp:237] Iteration 43300, loss = 3.4231
I0123 22:27:18.260726 29630 solver.cpp:253]     Train net output #0: loss = 3.4231 (* 1 = 3.4231 loss)
I0123 22:27:18.260733 29630 sgd_solver.cpp:106] Iteration 43300, lr = 0.01
I0123 22:27:25.486863 29630 solver.cpp:237] Iteration 43320, loss = 3.82396
I0123 22:27:25.486902 29630 solver.cpp:253]     Train net output #0: loss = 3.82396 (* 1 = 3.82396 loss)
I0123 22:27:25.486908 29630 sgd_solver.cpp:106] Iteration 43320, lr = 0.01
I0123 22:27:32.695863 29630 solver.cpp:237] Iteration 43340, loss = 3.50169
I0123 22:27:32.695900 29630 solver.cpp:253]     Train net output #0: loss = 3.50169 (* 1 = 3.50169 loss)
I0123 22:27:32.695906 29630 sgd_solver.cpp:106] Iteration 43340, lr = 0.01
I0123 22:27:39.898044 29630 solver.cpp:237] Iteration 43360, loss = 3.27464
I0123 22:27:39.898082 29630 solver.cpp:253]     Train net output #0: loss = 3.27464 (* 1 = 3.27464 loss)
I0123 22:27:39.898088 29630 sgd_solver.cpp:106] Iteration 43360, lr = 0.01
I0123 22:27:47.124475 29630 solver.cpp:237] Iteration 43380, loss = 3.59563
I0123 22:27:47.124514 29630 solver.cpp:253]     Train net output #0: loss = 3.59563 (* 1 = 3.59563 loss)
I0123 22:27:47.124521 29630 sgd_solver.cpp:106] Iteration 43380, lr = 0.01
I0123 22:27:54.380372 29630 solver.cpp:237] Iteration 43400, loss = 3.53335
I0123 22:27:54.380532 29630 solver.cpp:253]     Train net output #0: loss = 3.53335 (* 1 = 3.53335 loss)
I0123 22:27:54.380550 29630 sgd_solver.cpp:106] Iteration 43400, lr = 0.01
I0123 22:28:01.629916 29630 solver.cpp:237] Iteration 43420, loss = 3.37763
I0123 22:28:01.629955 29630 solver.cpp:253]     Train net output #0: loss = 3.37763 (* 1 = 3.37763 loss)
I0123 22:28:01.629961 29630 sgd_solver.cpp:106] Iteration 43420, lr = 0.01
I0123 22:28:08.879500 29630 solver.cpp:237] Iteration 43440, loss = 3.63741
I0123 22:28:08.879539 29630 solver.cpp:253]     Train net output #0: loss = 3.63741 (* 1 = 3.63741 loss)
I0123 22:28:08.879544 29630 sgd_solver.cpp:106] Iteration 43440, lr = 0.01
I0123 22:28:16.117785 29630 solver.cpp:237] Iteration 43460, loss = 3.82767
I0123 22:28:16.117823 29630 solver.cpp:253]     Train net output #0: loss = 3.82767 (* 1 = 3.82767 loss)
I0123 22:28:16.117830 29630 sgd_solver.cpp:106] Iteration 43460, lr = 0.01
I0123 22:28:23.383909 29630 solver.cpp:237] Iteration 43480, loss = 3.59105
I0123 22:28:23.383947 29630 solver.cpp:253]     Train net output #0: loss = 3.59105 (* 1 = 3.59105 loss)
I0123 22:28:23.383955 29630 sgd_solver.cpp:106] Iteration 43480, lr = 0.01
I0123 22:28:30.660166 29630 solver.cpp:237] Iteration 43500, loss = 3.8011
I0123 22:28:30.660332 29630 solver.cpp:253]     Train net output #0: loss = 3.8011 (* 1 = 3.8011 loss)
I0123 22:28:30.660341 29630 sgd_solver.cpp:106] Iteration 43500, lr = 0.01
I0123 22:28:37.933877 29630 solver.cpp:237] Iteration 43520, loss = 3.36518
I0123 22:28:37.933918 29630 solver.cpp:253]     Train net output #0: loss = 3.36518 (* 1 = 3.36518 loss)
I0123 22:28:37.933926 29630 sgd_solver.cpp:106] Iteration 43520, lr = 0.01
I0123 22:28:45.207515 29630 solver.cpp:237] Iteration 43540, loss = 3.70271
I0123 22:28:45.207556 29630 solver.cpp:253]     Train net output #0: loss = 3.70271 (* 1 = 3.70271 loss)
I0123 22:28:45.207562 29630 sgd_solver.cpp:106] Iteration 43540, lr = 0.01
I0123 22:28:52.468791 29630 solver.cpp:237] Iteration 43560, loss = 3.49758
I0123 22:28:52.468828 29630 solver.cpp:253]     Train net output #0: loss = 3.49758 (* 1 = 3.49758 loss)
I0123 22:28:52.468834 29630 sgd_solver.cpp:106] Iteration 43560, lr = 0.01
I0123 22:28:59.776124 29630 solver.cpp:237] Iteration 43580, loss = 3.56596
I0123 22:28:59.776162 29630 solver.cpp:253]     Train net output #0: loss = 3.56596 (* 1 = 3.56596 loss)
I0123 22:28:59.776168 29630 sgd_solver.cpp:106] Iteration 43580, lr = 0.01
I0123 22:29:07.037858 29630 solver.cpp:237] Iteration 43600, loss = 3.73002
I0123 22:29:07.038060 29630 solver.cpp:253]     Train net output #0: loss = 3.73002 (* 1 = 3.73002 loss)
I0123 22:29:07.038069 29630 sgd_solver.cpp:106] Iteration 43600, lr = 0.01
I0123 22:29:14.293244 29630 solver.cpp:237] Iteration 43620, loss = 3.57291
I0123 22:29:14.293283 29630 solver.cpp:253]     Train net output #0: loss = 3.57291 (* 1 = 3.57291 loss)
I0123 22:29:14.293290 29630 sgd_solver.cpp:106] Iteration 43620, lr = 0.01
I0123 22:29:21.588881 29630 solver.cpp:237] Iteration 43640, loss = 3.4145
I0123 22:29:21.588948 29630 solver.cpp:253]     Train net output #0: loss = 3.4145 (* 1 = 3.4145 loss)
I0123 22:29:21.588960 29630 sgd_solver.cpp:106] Iteration 43640, lr = 0.01
I0123 22:29:28.888581 29630 solver.cpp:237] Iteration 43660, loss = 3.40692
I0123 22:29:28.888622 29630 solver.cpp:253]     Train net output #0: loss = 3.40692 (* 1 = 3.40692 loss)
I0123 22:29:28.888628 29630 sgd_solver.cpp:106] Iteration 43660, lr = 0.01
I0123 22:29:36.169561 29630 solver.cpp:237] Iteration 43680, loss = 3.41674
I0123 22:29:36.169602 29630 solver.cpp:253]     Train net output #0: loss = 3.41674 (* 1 = 3.41674 loss)
I0123 22:29:36.169610 29630 sgd_solver.cpp:106] Iteration 43680, lr = 0.01
I0123 22:29:43.391466 29630 solver.cpp:237] Iteration 43700, loss = 3.664
I0123 22:29:43.391573 29630 solver.cpp:253]     Train net output #0: loss = 3.664 (* 1 = 3.664 loss)
I0123 22:29:43.391590 29630 sgd_solver.cpp:106] Iteration 43700, lr = 0.01
I0123 22:29:50.640599 29630 solver.cpp:237] Iteration 43720, loss = 3.45653
I0123 22:29:50.640637 29630 solver.cpp:253]     Train net output #0: loss = 3.45653 (* 1 = 3.45653 loss)
I0123 22:29:50.640643 29630 sgd_solver.cpp:106] Iteration 43720, lr = 0.01
I0123 22:29:57.926997 29630 solver.cpp:237] Iteration 43740, loss = 3.58425
I0123 22:29:57.927037 29630 solver.cpp:253]     Train net output #0: loss = 3.58425 (* 1 = 3.58425 loss)
I0123 22:29:57.927043 29630 sgd_solver.cpp:106] Iteration 43740, lr = 0.01
I0123 22:30:05.192159 29630 solver.cpp:237] Iteration 43760, loss = 3.63979
I0123 22:30:05.192196 29630 solver.cpp:253]     Train net output #0: loss = 3.63979 (* 1 = 3.63979 loss)
I0123 22:30:05.192203 29630 sgd_solver.cpp:106] Iteration 43760, lr = 0.01
I0123 22:30:12.454062 29630 solver.cpp:237] Iteration 43780, loss = 3.47424
I0123 22:30:12.454119 29630 solver.cpp:253]     Train net output #0: loss = 3.47424 (* 1 = 3.47424 loss)
I0123 22:30:12.454128 29630 sgd_solver.cpp:106] Iteration 43780, lr = 0.01
I0123 22:30:19.671417 29630 solver.cpp:237] Iteration 43800, loss = 3.27834
I0123 22:30:19.671562 29630 solver.cpp:253]     Train net output #0: loss = 3.27834 (* 1 = 3.27834 loss)
I0123 22:30:19.671581 29630 sgd_solver.cpp:106] Iteration 43800, lr = 0.01
I0123 22:30:26.923768 29630 solver.cpp:237] Iteration 43820, loss = 3.47572
I0123 22:30:26.923806 29630 solver.cpp:253]     Train net output #0: loss = 3.47572 (* 1 = 3.47572 loss)
I0123 22:30:26.923812 29630 sgd_solver.cpp:106] Iteration 43820, lr = 0.01
I0123 22:30:34.155187 29630 solver.cpp:237] Iteration 43840, loss = 3.44995
I0123 22:30:34.155226 29630 solver.cpp:253]     Train net output #0: loss = 3.44995 (* 1 = 3.44995 loss)
I0123 22:30:34.155232 29630 sgd_solver.cpp:106] Iteration 43840, lr = 0.01
I0123 22:30:41.398664 29630 solver.cpp:237] Iteration 43860, loss = 3.38842
I0123 22:30:41.398725 29630 solver.cpp:253]     Train net output #0: loss = 3.38842 (* 1 = 3.38842 loss)
I0123 22:30:41.398731 29630 sgd_solver.cpp:106] Iteration 43860, lr = 0.01
I0123 22:30:48.659471 29630 solver.cpp:237] Iteration 43880, loss = 3.52389
I0123 22:30:48.659510 29630 solver.cpp:253]     Train net output #0: loss = 3.52389 (* 1 = 3.52389 loss)
I0123 22:30:48.659517 29630 sgd_solver.cpp:106] Iteration 43880, lr = 0.01
I0123 22:30:55.885738 29630 solver.cpp:237] Iteration 43900, loss = 3.7019
I0123 22:30:55.885905 29630 solver.cpp:253]     Train net output #0: loss = 3.7019 (* 1 = 3.7019 loss)
I0123 22:30:55.885913 29630 sgd_solver.cpp:106] Iteration 43900, lr = 0.01
I0123 22:31:03.180099 29630 solver.cpp:237] Iteration 43920, loss = 3.63411
I0123 22:31:03.180137 29630 solver.cpp:253]     Train net output #0: loss = 3.63411 (* 1 = 3.63411 loss)
I0123 22:31:03.180143 29630 sgd_solver.cpp:106] Iteration 43920, lr = 0.01
I0123 22:31:10.461688 29630 solver.cpp:237] Iteration 43940, loss = 3.39067
I0123 22:31:10.461719 29630 solver.cpp:253]     Train net output #0: loss = 3.39067 (* 1 = 3.39067 loss)
I0123 22:31:10.461725 29630 sgd_solver.cpp:106] Iteration 43940, lr = 0.01
I0123 22:31:17.736155 29630 solver.cpp:237] Iteration 43960, loss = 3.75446
I0123 22:31:17.736196 29630 solver.cpp:253]     Train net output #0: loss = 3.75446 (* 1 = 3.75446 loss)
I0123 22:31:17.736203 29630 sgd_solver.cpp:106] Iteration 43960, lr = 0.01
I0123 22:31:24.991330 29630 solver.cpp:237] Iteration 43980, loss = 3.7107
I0123 22:31:24.991369 29630 solver.cpp:253]     Train net output #0: loss = 3.7107 (* 1 = 3.7107 loss)
I0123 22:31:24.991376 29630 sgd_solver.cpp:106] Iteration 43980, lr = 0.01
I0123 22:31:31.974956 29630 solver.cpp:341] Iteration 44000, Testing net (#0)
I0123 22:31:51.204675 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 22:32:45.716231 29630 solver.cpp:409]     Test net output #0: accuracy = 0.30606
I0123 22:32:45.716361 29630 solver.cpp:409]     Test net output #1: loss = 3.29076 (* 1 = 3.29076 loss)
I0123 22:32:45.757125 29630 solver.cpp:237] Iteration 44000, loss = 3.33665
I0123 22:32:45.757164 29630 solver.cpp:253]     Train net output #0: loss = 3.33665 (* 1 = 3.33665 loss)
I0123 22:32:45.757170 29630 sgd_solver.cpp:106] Iteration 44000, lr = 0.01
I0123 22:32:52.267954 29630 solver.cpp:237] Iteration 44020, loss = 3.57216
I0123 22:32:52.267994 29630 solver.cpp:253]     Train net output #0: loss = 3.57216 (* 1 = 3.57216 loss)
I0123 22:32:52.267999 29630 sgd_solver.cpp:106] Iteration 44020, lr = 0.01
I0123 22:32:59.531839 29630 solver.cpp:237] Iteration 44040, loss = 3.54235
I0123 22:32:59.531878 29630 solver.cpp:253]     Train net output #0: loss = 3.54235 (* 1 = 3.54235 loss)
I0123 22:32:59.531885 29630 sgd_solver.cpp:106] Iteration 44040, lr = 0.01
I0123 22:33:06.799356 29630 solver.cpp:237] Iteration 44060, loss = 3.51305
I0123 22:33:06.799396 29630 solver.cpp:253]     Train net output #0: loss = 3.51305 (* 1 = 3.51305 loss)
I0123 22:33:06.799401 29630 sgd_solver.cpp:106] Iteration 44060, lr = 0.01
I0123 22:33:14.048400 29630 solver.cpp:237] Iteration 44080, loss = 3.57315
I0123 22:33:14.048439 29630 solver.cpp:253]     Train net output #0: loss = 3.57315 (* 1 = 3.57315 loss)
I0123 22:33:14.048445 29630 sgd_solver.cpp:106] Iteration 44080, lr = 0.01
I0123 22:33:21.329982 29630 solver.cpp:237] Iteration 44100, loss = 3.51634
I0123 22:33:21.330096 29630 solver.cpp:253]     Train net output #0: loss = 3.51634 (* 1 = 3.51634 loss)
I0123 22:33:21.330112 29630 sgd_solver.cpp:106] Iteration 44100, lr = 0.01
I0123 22:33:28.575011 29630 solver.cpp:237] Iteration 44120, loss = 3.48815
I0123 22:33:28.575048 29630 solver.cpp:253]     Train net output #0: loss = 3.48815 (* 1 = 3.48815 loss)
I0123 22:33:28.575053 29630 sgd_solver.cpp:106] Iteration 44120, lr = 0.01
I0123 22:33:35.837267 29630 solver.cpp:237] Iteration 44140, loss = 3.48253
I0123 22:33:35.837306 29630 solver.cpp:253]     Train net output #0: loss = 3.48253 (* 1 = 3.48253 loss)
I0123 22:33:35.837312 29630 sgd_solver.cpp:106] Iteration 44140, lr = 0.01
I0123 22:33:43.098991 29630 solver.cpp:237] Iteration 44160, loss = 3.63968
I0123 22:33:43.099031 29630 solver.cpp:253]     Train net output #0: loss = 3.63968 (* 1 = 3.63968 loss)
I0123 22:33:43.099037 29630 sgd_solver.cpp:106] Iteration 44160, lr = 0.01
I0123 22:33:50.331868 29630 solver.cpp:237] Iteration 44180, loss = 3.5804
I0123 22:33:50.331907 29630 solver.cpp:253]     Train net output #0: loss = 3.5804 (* 1 = 3.5804 loss)
I0123 22:33:50.331912 29630 sgd_solver.cpp:106] Iteration 44180, lr = 0.01
I0123 22:33:57.617429 29630 solver.cpp:237] Iteration 44200, loss = 3.50842
I0123 22:33:57.617557 29630 solver.cpp:253]     Train net output #0: loss = 3.50842 (* 1 = 3.50842 loss)
I0123 22:33:57.617564 29630 sgd_solver.cpp:106] Iteration 44200, lr = 0.01
I0123 22:34:04.893175 29630 solver.cpp:237] Iteration 44220, loss = 3.53578
I0123 22:34:04.893215 29630 solver.cpp:253]     Train net output #0: loss = 3.53578 (* 1 = 3.53578 loss)
I0123 22:34:04.893221 29630 sgd_solver.cpp:106] Iteration 44220, lr = 0.01
I0123 22:34:12.118219 29630 solver.cpp:237] Iteration 44240, loss = 3.22276
I0123 22:34:12.118258 29630 solver.cpp:253]     Train net output #0: loss = 3.22276 (* 1 = 3.22276 loss)
I0123 22:34:12.118264 29630 sgd_solver.cpp:106] Iteration 44240, lr = 0.01
I0123 22:34:19.333422 29630 solver.cpp:237] Iteration 44260, loss = 3.43657
I0123 22:34:19.333462 29630 solver.cpp:253]     Train net output #0: loss = 3.43657 (* 1 = 3.43657 loss)
I0123 22:34:19.333468 29630 sgd_solver.cpp:106] Iteration 44260, lr = 0.01
I0123 22:34:21.193208 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 22:34:26.561841 29630 solver.cpp:237] Iteration 44280, loss = 3.36042
I0123 22:34:26.561879 29630 solver.cpp:253]     Train net output #0: loss = 3.36042 (* 1 = 3.36042 loss)
I0123 22:34:26.561885 29630 sgd_solver.cpp:106] Iteration 44280, lr = 0.01
I0123 22:34:33.825160 29630 solver.cpp:237] Iteration 44300, loss = 3.65194
I0123 22:34:33.825251 29630 solver.cpp:253]     Train net output #0: loss = 3.65194 (* 1 = 3.65194 loss)
I0123 22:34:33.825258 29630 sgd_solver.cpp:106] Iteration 44300, lr = 0.01
I0123 22:34:41.052676 29630 solver.cpp:237] Iteration 44320, loss = 3.57298
I0123 22:34:41.052716 29630 solver.cpp:253]     Train net output #0: loss = 3.57298 (* 1 = 3.57298 loss)
I0123 22:34:41.052722 29630 sgd_solver.cpp:106] Iteration 44320, lr = 0.01
I0123 22:34:48.299057 29630 solver.cpp:237] Iteration 44340, loss = 3.5058
I0123 22:34:48.299096 29630 solver.cpp:253]     Train net output #0: loss = 3.5058 (* 1 = 3.5058 loss)
I0123 22:34:48.299103 29630 sgd_solver.cpp:106] Iteration 44340, lr = 0.01
I0123 22:34:55.578024 29630 solver.cpp:237] Iteration 44360, loss = 3.81478
I0123 22:34:55.578063 29630 solver.cpp:253]     Train net output #0: loss = 3.81478 (* 1 = 3.81478 loss)
I0123 22:34:55.578069 29630 sgd_solver.cpp:106] Iteration 44360, lr = 0.01
I0123 22:35:02.790325 29630 solver.cpp:237] Iteration 44380, loss = 3.54172
I0123 22:35:02.790364 29630 solver.cpp:253]     Train net output #0: loss = 3.54172 (* 1 = 3.54172 loss)
I0123 22:35:02.790370 29630 sgd_solver.cpp:106] Iteration 44380, lr = 0.01
I0123 22:35:10.066247 29630 solver.cpp:237] Iteration 44400, loss = 3.17904
I0123 22:35:10.066411 29630 solver.cpp:253]     Train net output #0: loss = 3.17904 (* 1 = 3.17904 loss)
I0123 22:35:10.066421 29630 sgd_solver.cpp:106] Iteration 44400, lr = 0.01
I0123 22:35:17.324934 29630 solver.cpp:237] Iteration 44420, loss = 3.61385
I0123 22:35:17.324972 29630 solver.cpp:253]     Train net output #0: loss = 3.61385 (* 1 = 3.61385 loss)
I0123 22:35:17.324977 29630 sgd_solver.cpp:106] Iteration 44420, lr = 0.01
I0123 22:35:24.607522 29630 solver.cpp:237] Iteration 44440, loss = 3.40733
I0123 22:35:24.607561 29630 solver.cpp:253]     Train net output #0: loss = 3.40733 (* 1 = 3.40733 loss)
I0123 22:35:24.607568 29630 sgd_solver.cpp:106] Iteration 44440, lr = 0.01
I0123 22:35:31.870337 29630 solver.cpp:237] Iteration 44460, loss = 3.23766
I0123 22:35:31.870376 29630 solver.cpp:253]     Train net output #0: loss = 3.23766 (* 1 = 3.23766 loss)
I0123 22:35:31.870383 29630 sgd_solver.cpp:106] Iteration 44460, lr = 0.01
I0123 22:35:39.088843 29630 solver.cpp:237] Iteration 44480, loss = 3.54295
I0123 22:35:39.088881 29630 solver.cpp:253]     Train net output #0: loss = 3.54295 (* 1 = 3.54295 loss)
I0123 22:35:39.088887 29630 sgd_solver.cpp:106] Iteration 44480, lr = 0.01
I0123 22:35:46.316263 29630 solver.cpp:237] Iteration 44500, loss = 3.45323
I0123 22:35:46.316429 29630 solver.cpp:253]     Train net output #0: loss = 3.45323 (* 1 = 3.45323 loss)
I0123 22:35:46.316437 29630 sgd_solver.cpp:106] Iteration 44500, lr = 0.01
I0123 22:35:53.577615 29630 solver.cpp:237] Iteration 44520, loss = 3.41963
I0123 22:35:53.577652 29630 solver.cpp:253]     Train net output #0: loss = 3.41963 (* 1 = 3.41963 loss)
I0123 22:35:53.577659 29630 sgd_solver.cpp:106] Iteration 44520, lr = 0.01
I0123 22:36:00.848745 29630 solver.cpp:237] Iteration 44540, loss = 3.56312
I0123 22:36:00.848784 29630 solver.cpp:253]     Train net output #0: loss = 3.56312 (* 1 = 3.56312 loss)
I0123 22:36:00.848790 29630 sgd_solver.cpp:106] Iteration 44540, lr = 0.01
I0123 22:36:08.083461 29630 solver.cpp:237] Iteration 44560, loss = 3.56218
I0123 22:36:08.083500 29630 solver.cpp:253]     Train net output #0: loss = 3.56218 (* 1 = 3.56218 loss)
I0123 22:36:08.083506 29630 sgd_solver.cpp:106] Iteration 44560, lr = 0.01
I0123 22:36:15.375102 29630 solver.cpp:237] Iteration 44580, loss = 3.36575
I0123 22:36:15.375140 29630 solver.cpp:253]     Train net output #0: loss = 3.36575 (* 1 = 3.36575 loss)
I0123 22:36:15.375147 29630 sgd_solver.cpp:106] Iteration 44580, lr = 0.01
I0123 22:36:22.657950 29630 solver.cpp:237] Iteration 44600, loss = 3.48753
I0123 22:36:22.658126 29630 solver.cpp:253]     Train net output #0: loss = 3.48753 (* 1 = 3.48753 loss)
I0123 22:36:22.658134 29630 sgd_solver.cpp:106] Iteration 44600, lr = 0.01
I0123 22:36:29.916132 29630 solver.cpp:237] Iteration 44620, loss = 3.25892
I0123 22:36:29.916170 29630 solver.cpp:253]     Train net output #0: loss = 3.25892 (* 1 = 3.25892 loss)
I0123 22:36:29.916177 29630 sgd_solver.cpp:106] Iteration 44620, lr = 0.01
I0123 22:36:37.161214 29630 solver.cpp:237] Iteration 44640, loss = 3.48837
I0123 22:36:37.161253 29630 solver.cpp:253]     Train net output #0: loss = 3.48837 (* 1 = 3.48837 loss)
I0123 22:36:37.161259 29630 sgd_solver.cpp:106] Iteration 44640, lr = 0.01
I0123 22:36:44.447744 29630 solver.cpp:237] Iteration 44660, loss = 3.52886
I0123 22:36:44.447782 29630 solver.cpp:253]     Train net output #0: loss = 3.52886 (* 1 = 3.52886 loss)
I0123 22:36:44.447788 29630 sgd_solver.cpp:106] Iteration 44660, lr = 0.01
I0123 22:36:51.723310 29630 solver.cpp:237] Iteration 44680, loss = 3.59443
I0123 22:36:51.723347 29630 solver.cpp:253]     Train net output #0: loss = 3.59443 (* 1 = 3.59443 loss)
I0123 22:36:51.723353 29630 sgd_solver.cpp:106] Iteration 44680, lr = 0.01
I0123 22:36:58.971469 29630 solver.cpp:237] Iteration 44700, loss = 3.57851
I0123 22:36:58.971581 29630 solver.cpp:253]     Train net output #0: loss = 3.57851 (* 1 = 3.57851 loss)
I0123 22:36:58.971598 29630 sgd_solver.cpp:106] Iteration 44700, lr = 0.01
I0123 22:37:06.250685 29630 solver.cpp:237] Iteration 44720, loss = 3.23986
I0123 22:37:06.250725 29630 solver.cpp:253]     Train net output #0: loss = 3.23986 (* 1 = 3.23986 loss)
I0123 22:37:06.250730 29630 sgd_solver.cpp:106] Iteration 44720, lr = 0.01
I0123 22:37:13.525744 29630 solver.cpp:237] Iteration 44740, loss = 3.5892
I0123 22:37:13.525784 29630 solver.cpp:253]     Train net output #0: loss = 3.5892 (* 1 = 3.5892 loss)
I0123 22:37:13.525789 29630 sgd_solver.cpp:106] Iteration 44740, lr = 0.01
I0123 22:37:20.847172 29630 solver.cpp:237] Iteration 44760, loss = 3.48221
I0123 22:37:20.847211 29630 solver.cpp:253]     Train net output #0: loss = 3.48221 (* 1 = 3.48221 loss)
I0123 22:37:20.847218 29630 sgd_solver.cpp:106] Iteration 44760, lr = 0.01
I0123 22:37:28.105329 29630 solver.cpp:237] Iteration 44780, loss = 3.58447
I0123 22:37:28.105367 29630 solver.cpp:253]     Train net output #0: loss = 3.58447 (* 1 = 3.58447 loss)
I0123 22:37:28.105373 29630 sgd_solver.cpp:106] Iteration 44780, lr = 0.01
I0123 22:37:35.416213 29630 solver.cpp:237] Iteration 44800, loss = 3.44317
I0123 22:37:35.416404 29630 solver.cpp:253]     Train net output #0: loss = 3.44317 (* 1 = 3.44317 loss)
I0123 22:37:35.416411 29630 sgd_solver.cpp:106] Iteration 44800, lr = 0.01
I0123 22:37:42.668323 29630 solver.cpp:237] Iteration 44820, loss = 3.28376
I0123 22:37:42.668362 29630 solver.cpp:253]     Train net output #0: loss = 3.28376 (* 1 = 3.28376 loss)
I0123 22:37:42.668368 29630 sgd_solver.cpp:106] Iteration 44820, lr = 0.01
I0123 22:37:49.936576 29630 solver.cpp:237] Iteration 44840, loss = 3.6637
I0123 22:37:49.936619 29630 solver.cpp:253]     Train net output #0: loss = 3.6637 (* 1 = 3.6637 loss)
I0123 22:37:49.936636 29630 sgd_solver.cpp:106] Iteration 44840, lr = 0.01
I0123 22:37:57.179422 29630 solver.cpp:237] Iteration 44860, loss = 3.42749
I0123 22:37:57.179461 29630 solver.cpp:253]     Train net output #0: loss = 3.42749 (* 1 = 3.42749 loss)
I0123 22:37:57.179466 29630 sgd_solver.cpp:106] Iteration 44860, lr = 0.01
I0123 22:38:04.405521 29630 solver.cpp:237] Iteration 44880, loss = 3.59916
I0123 22:38:04.405560 29630 solver.cpp:253]     Train net output #0: loss = 3.59916 (* 1 = 3.59916 loss)
I0123 22:38:04.405570 29630 sgd_solver.cpp:106] Iteration 44880, lr = 0.01
I0123 22:38:11.710968 29630 solver.cpp:237] Iteration 44900, loss = 3.75102
I0123 22:38:11.711097 29630 solver.cpp:253]     Train net output #0: loss = 3.75102 (* 1 = 3.75102 loss)
I0123 22:38:11.711104 29630 sgd_solver.cpp:106] Iteration 44900, lr = 0.01
I0123 22:38:18.984644 29630 solver.cpp:237] Iteration 44920, loss = 3.55419
I0123 22:38:18.984683 29630 solver.cpp:253]     Train net output #0: loss = 3.55419 (* 1 = 3.55419 loss)
I0123 22:38:18.984689 29630 sgd_solver.cpp:106] Iteration 44920, lr = 0.01
I0123 22:38:26.223758 29630 solver.cpp:237] Iteration 44940, loss = 3.23694
I0123 22:38:26.223798 29630 solver.cpp:253]     Train net output #0: loss = 3.23694 (* 1 = 3.23694 loss)
I0123 22:38:26.223803 29630 sgd_solver.cpp:106] Iteration 44940, lr = 0.01
I0123 22:38:33.544039 29630 solver.cpp:237] Iteration 44960, loss = 3.30108
I0123 22:38:33.544077 29630 solver.cpp:253]     Train net output #0: loss = 3.30108 (* 1 = 3.30108 loss)
I0123 22:38:33.544083 29630 sgd_solver.cpp:106] Iteration 44960, lr = 0.01
I0123 22:38:40.787335 29630 solver.cpp:237] Iteration 44980, loss = 3.25466
I0123 22:38:40.787374 29630 solver.cpp:253]     Train net output #0: loss = 3.25466 (* 1 = 3.25466 loss)
I0123 22:38:40.787381 29630 sgd_solver.cpp:106] Iteration 44980, lr = 0.01
I0123 22:38:47.735577 29630 solver.cpp:341] Iteration 45000, Testing net (#0)
I0123 22:39:07.378727 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 22:40:01.318905 29630 solver.cpp:409]     Test net output #0: accuracy = 0.30394
I0123 22:40:01.319031 29630 solver.cpp:409]     Test net output #1: loss = 3.33559 (* 1 = 3.33559 loss)
I0123 22:40:01.359514 29630 solver.cpp:237] Iteration 45000, loss = 3.5909
I0123 22:40:01.359556 29630 solver.cpp:253]     Train net output #0: loss = 3.5909 (* 1 = 3.5909 loss)
I0123 22:40:01.359566 29630 sgd_solver.cpp:106] Iteration 45000, lr = 0.01
I0123 22:40:07.943212 29630 solver.cpp:237] Iteration 45020, loss = 3.59069
I0123 22:40:07.943253 29630 solver.cpp:253]     Train net output #0: loss = 3.59069 (* 1 = 3.59069 loss)
I0123 22:40:07.943259 29630 sgd_solver.cpp:106] Iteration 45020, lr = 0.01
I0123 22:40:15.196141 29630 solver.cpp:237] Iteration 45040, loss = 3.54997
I0123 22:40:15.196182 29630 solver.cpp:253]     Train net output #0: loss = 3.54997 (* 1 = 3.54997 loss)
I0123 22:40:15.196189 29630 sgd_solver.cpp:106] Iteration 45040, lr = 0.01
I0123 22:40:22.466307 29630 solver.cpp:237] Iteration 45060, loss = 3.47988
I0123 22:40:22.466346 29630 solver.cpp:253]     Train net output #0: loss = 3.47988 (* 1 = 3.47988 loss)
I0123 22:40:22.466352 29630 sgd_solver.cpp:106] Iteration 45060, lr = 0.01
I0123 22:40:29.695505 29630 solver.cpp:237] Iteration 45080, loss = 3.50627
I0123 22:40:29.695544 29630 solver.cpp:253]     Train net output #0: loss = 3.50627 (* 1 = 3.50627 loss)
I0123 22:40:29.695549 29630 sgd_solver.cpp:106] Iteration 45080, lr = 0.01
I0123 22:40:36.977147 29630 solver.cpp:237] Iteration 45100, loss = 3.36346
I0123 22:40:36.977325 29630 solver.cpp:253]     Train net output #0: loss = 3.36346 (* 1 = 3.36346 loss)
I0123 22:40:36.977334 29630 sgd_solver.cpp:106] Iteration 45100, lr = 0.01
I0123 22:40:44.270509 29630 solver.cpp:237] Iteration 45120, loss = 3.42476
I0123 22:40:44.270546 29630 solver.cpp:253]     Train net output #0: loss = 3.42476 (* 1 = 3.42476 loss)
I0123 22:40:44.270552 29630 sgd_solver.cpp:106] Iteration 45120, lr = 0.01
I0123 22:40:51.579463 29630 solver.cpp:237] Iteration 45140, loss = 3.54724
I0123 22:40:51.579502 29630 solver.cpp:253]     Train net output #0: loss = 3.54724 (* 1 = 3.54724 loss)
I0123 22:40:51.579509 29630 sgd_solver.cpp:106] Iteration 45140, lr = 0.01
I0123 22:40:58.822598 29630 solver.cpp:237] Iteration 45160, loss = 3.56805
I0123 22:40:58.822636 29630 solver.cpp:253]     Train net output #0: loss = 3.56805 (* 1 = 3.56805 loss)
I0123 22:40:58.822643 29630 sgd_solver.cpp:106] Iteration 45160, lr = 0.01
I0123 22:41:06.111901 29630 solver.cpp:237] Iteration 45180, loss = 3.57462
I0123 22:41:06.111940 29630 solver.cpp:253]     Train net output #0: loss = 3.57462 (* 1 = 3.57462 loss)
I0123 22:41:06.111948 29630 sgd_solver.cpp:106] Iteration 45180, lr = 0.01
I0123 22:41:13.385828 29630 solver.cpp:237] Iteration 45200, loss = 3.71758
I0123 22:41:13.386003 29630 solver.cpp:253]     Train net output #0: loss = 3.71758 (* 1 = 3.71758 loss)
I0123 22:41:13.386013 29630 sgd_solver.cpp:106] Iteration 45200, lr = 0.01
I0123 22:41:20.666590 29630 solver.cpp:237] Iteration 45220, loss = 3.3011
I0123 22:41:20.666630 29630 solver.cpp:253]     Train net output #0: loss = 3.3011 (* 1 = 3.3011 loss)
I0123 22:41:20.666636 29630 sgd_solver.cpp:106] Iteration 45220, lr = 0.01
I0123 22:41:28.021539 29630 solver.cpp:237] Iteration 45240, loss = 3.32422
I0123 22:41:28.021580 29630 solver.cpp:253]     Train net output #0: loss = 3.32422 (* 1 = 3.32422 loss)
I0123 22:41:28.021587 29630 sgd_solver.cpp:106] Iteration 45240, lr = 0.01
I0123 22:41:35.339741 29630 solver.cpp:237] Iteration 45260, loss = 3.7258
I0123 22:41:35.339781 29630 solver.cpp:253]     Train net output #0: loss = 3.7258 (* 1 = 3.7258 loss)
I0123 22:41:35.339787 29630 sgd_solver.cpp:106] Iteration 45260, lr = 0.01
I0123 22:41:39.470998 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 22:41:42.688536 29630 solver.cpp:237] Iteration 45280, loss = 3.56606
I0123 22:41:42.688575 29630 solver.cpp:253]     Train net output #0: loss = 3.56606 (* 1 = 3.56606 loss)
I0123 22:41:42.688581 29630 sgd_solver.cpp:106] Iteration 45280, lr = 0.01
I0123 22:41:49.969276 29630 solver.cpp:237] Iteration 45300, loss = 3.71954
I0123 22:41:49.969374 29630 solver.cpp:253]     Train net output #0: loss = 3.71954 (* 1 = 3.71954 loss)
I0123 22:41:49.969391 29630 sgd_solver.cpp:106] Iteration 45300, lr = 0.01
I0123 22:41:57.262234 29630 solver.cpp:237] Iteration 45320, loss = 3.69252
I0123 22:41:57.262272 29630 solver.cpp:253]     Train net output #0: loss = 3.69252 (* 1 = 3.69252 loss)
I0123 22:41:57.262279 29630 sgd_solver.cpp:106] Iteration 45320, lr = 0.01
I0123 22:42:04.546003 29630 solver.cpp:237] Iteration 45340, loss = 3.52846
I0123 22:42:04.546041 29630 solver.cpp:253]     Train net output #0: loss = 3.52846 (* 1 = 3.52846 loss)
I0123 22:42:04.546047 29630 sgd_solver.cpp:106] Iteration 45340, lr = 0.01
I0123 22:42:11.752959 29630 solver.cpp:237] Iteration 45360, loss = 3.54789
I0123 22:42:11.752998 29630 solver.cpp:253]     Train net output #0: loss = 3.54789 (* 1 = 3.54789 loss)
I0123 22:42:11.753005 29630 sgd_solver.cpp:106] Iteration 45360, lr = 0.01
I0123 22:42:19.056459 29630 solver.cpp:237] Iteration 45380, loss = 3.60039
I0123 22:42:19.056488 29630 solver.cpp:253]     Train net output #0: loss = 3.60039 (* 1 = 3.60039 loss)
I0123 22:42:19.056495 29630 sgd_solver.cpp:106] Iteration 45380, lr = 0.01
I0123 22:42:26.320912 29630 solver.cpp:237] Iteration 45400, loss = 3.30382
I0123 22:42:26.321038 29630 solver.cpp:253]     Train net output #0: loss = 3.30382 (* 1 = 3.30382 loss)
I0123 22:42:26.321054 29630 sgd_solver.cpp:106] Iteration 45400, lr = 0.01
I0123 22:42:33.572772 29630 solver.cpp:237] Iteration 45420, loss = 3.43388
I0123 22:42:33.572811 29630 solver.cpp:253]     Train net output #0: loss = 3.43388 (* 1 = 3.43388 loss)
I0123 22:42:33.572818 29630 sgd_solver.cpp:106] Iteration 45420, lr = 0.01
I0123 22:42:40.820397 29630 solver.cpp:237] Iteration 45440, loss = 3.76752
I0123 22:42:40.820437 29630 solver.cpp:253]     Train net output #0: loss = 3.76752 (* 1 = 3.76752 loss)
I0123 22:42:40.820443 29630 sgd_solver.cpp:106] Iteration 45440, lr = 0.01
I0123 22:42:48.074048 29630 solver.cpp:237] Iteration 45460, loss = 3.22338
I0123 22:42:48.074087 29630 solver.cpp:253]     Train net output #0: loss = 3.22338 (* 1 = 3.22338 loss)
I0123 22:42:48.074093 29630 sgd_solver.cpp:106] Iteration 45460, lr = 0.01
I0123 22:42:55.385521 29630 solver.cpp:237] Iteration 45480, loss = 3.62887
I0123 22:42:55.385550 29630 solver.cpp:253]     Train net output #0: loss = 3.62887 (* 1 = 3.62887 loss)
I0123 22:42:55.385557 29630 sgd_solver.cpp:106] Iteration 45480, lr = 0.01
I0123 22:43:02.667824 29630 solver.cpp:237] Iteration 45500, loss = 3.5162
I0123 22:43:02.667973 29630 solver.cpp:253]     Train net output #0: loss = 3.5162 (* 1 = 3.5162 loss)
I0123 22:43:02.667980 29630 sgd_solver.cpp:106] Iteration 45500, lr = 0.01
I0123 22:43:09.946969 29630 solver.cpp:237] Iteration 45520, loss = 3.61138
I0123 22:43:09.947016 29630 solver.cpp:253]     Train net output #0: loss = 3.61138 (* 1 = 3.61138 loss)
I0123 22:43:09.947022 29630 sgd_solver.cpp:106] Iteration 45520, lr = 0.01
I0123 22:43:17.179558 29630 solver.cpp:237] Iteration 45540, loss = 3.44973
I0123 22:43:17.179596 29630 solver.cpp:253]     Train net output #0: loss = 3.44973 (* 1 = 3.44973 loss)
I0123 22:43:17.179602 29630 sgd_solver.cpp:106] Iteration 45540, lr = 0.01
I0123 22:43:24.426015 29630 solver.cpp:237] Iteration 45560, loss = 3.27673
I0123 22:43:24.426054 29630 solver.cpp:253]     Train net output #0: loss = 3.27673 (* 1 = 3.27673 loss)
I0123 22:43:24.426060 29630 sgd_solver.cpp:106] Iteration 45560, lr = 0.01
I0123 22:43:31.668006 29630 solver.cpp:237] Iteration 45580, loss = 3.33534
I0123 22:43:31.668045 29630 solver.cpp:253]     Train net output #0: loss = 3.33534 (* 1 = 3.33534 loss)
I0123 22:43:31.668051 29630 sgd_solver.cpp:106] Iteration 45580, lr = 0.01
I0123 22:43:38.910218 29630 solver.cpp:237] Iteration 45600, loss = 3.55607
I0123 22:43:38.910397 29630 solver.cpp:253]     Train net output #0: loss = 3.55607 (* 1 = 3.55607 loss)
I0123 22:43:38.910405 29630 sgd_solver.cpp:106] Iteration 45600, lr = 0.01
I0123 22:43:46.159358 29630 solver.cpp:237] Iteration 45620, loss = 3.34297
I0123 22:43:46.159397 29630 solver.cpp:253]     Train net output #0: loss = 3.34297 (* 1 = 3.34297 loss)
I0123 22:43:46.159404 29630 sgd_solver.cpp:106] Iteration 45620, lr = 0.01
I0123 22:43:53.421849 29630 solver.cpp:237] Iteration 45640, loss = 3.44883
I0123 22:43:53.421887 29630 solver.cpp:253]     Train net output #0: loss = 3.44883 (* 1 = 3.44883 loss)
I0123 22:43:53.421895 29630 sgd_solver.cpp:106] Iteration 45640, lr = 0.01
I0123 22:44:00.715562 29630 solver.cpp:237] Iteration 45660, loss = 3.62339
I0123 22:44:00.715601 29630 solver.cpp:253]     Train net output #0: loss = 3.62339 (* 1 = 3.62339 loss)
I0123 22:44:00.715608 29630 sgd_solver.cpp:106] Iteration 45660, lr = 0.01
I0123 22:44:07.970885 29630 solver.cpp:237] Iteration 45680, loss = 3.41339
I0123 22:44:07.970922 29630 solver.cpp:253]     Train net output #0: loss = 3.41339 (* 1 = 3.41339 loss)
I0123 22:44:07.970929 29630 sgd_solver.cpp:106] Iteration 45680, lr = 0.01
I0123 22:44:15.227540 29630 solver.cpp:237] Iteration 45700, loss = 3.50739
I0123 22:44:15.227711 29630 solver.cpp:253]     Train net output #0: loss = 3.50739 (* 1 = 3.50739 loss)
I0123 22:44:15.227720 29630 sgd_solver.cpp:106] Iteration 45700, lr = 0.01
I0123 22:44:22.514272 29630 solver.cpp:237] Iteration 45720, loss = 3.42761
I0123 22:44:22.514312 29630 solver.cpp:253]     Train net output #0: loss = 3.42761 (* 1 = 3.42761 loss)
I0123 22:44:22.514318 29630 sgd_solver.cpp:106] Iteration 45720, lr = 0.01
I0123 22:44:29.746865 29630 solver.cpp:237] Iteration 45740, loss = 3.4196
I0123 22:44:29.746904 29630 solver.cpp:253]     Train net output #0: loss = 3.4196 (* 1 = 3.4196 loss)
I0123 22:44:29.746909 29630 sgd_solver.cpp:106] Iteration 45740, lr = 0.01
I0123 22:44:37.068233 29630 solver.cpp:237] Iteration 45760, loss = 3.40006
I0123 22:44:37.068274 29630 solver.cpp:253]     Train net output #0: loss = 3.40006 (* 1 = 3.40006 loss)
I0123 22:44:37.068281 29630 sgd_solver.cpp:106] Iteration 45760, lr = 0.01
I0123 22:44:44.324246 29630 solver.cpp:237] Iteration 45780, loss = 3.52915
I0123 22:44:44.324287 29630 solver.cpp:253]     Train net output #0: loss = 3.52915 (* 1 = 3.52915 loss)
I0123 22:44:44.324293 29630 sgd_solver.cpp:106] Iteration 45780, lr = 0.01
I0123 22:44:51.610100 29630 solver.cpp:237] Iteration 45800, loss = 3.65548
I0123 22:44:51.610247 29630 solver.cpp:253]     Train net output #0: loss = 3.65548 (* 1 = 3.65548 loss)
I0123 22:44:51.610255 29630 sgd_solver.cpp:106] Iteration 45800, lr = 0.01
I0123 22:44:58.854380 29630 solver.cpp:237] Iteration 45820, loss = 3.40109
I0123 22:44:58.854418 29630 solver.cpp:253]     Train net output #0: loss = 3.40109 (* 1 = 3.40109 loss)
I0123 22:44:58.854423 29630 sgd_solver.cpp:106] Iteration 45820, lr = 0.01
I0123 22:45:06.134260 29630 solver.cpp:237] Iteration 45840, loss = 3.49494
I0123 22:45:06.134290 29630 solver.cpp:253]     Train net output #0: loss = 3.49494 (* 1 = 3.49494 loss)
I0123 22:45:06.134296 29630 sgd_solver.cpp:106] Iteration 45840, lr = 0.01
I0123 22:45:13.465636 29630 solver.cpp:237] Iteration 45860, loss = 3.55594
I0123 22:45:13.465689 29630 solver.cpp:253]     Train net output #0: loss = 3.55594 (* 1 = 3.55594 loss)
I0123 22:45:13.465698 29630 sgd_solver.cpp:106] Iteration 45860, lr = 0.01
I0123 22:45:20.749892 29630 solver.cpp:237] Iteration 45880, loss = 3.43476
I0123 22:45:20.749932 29630 solver.cpp:253]     Train net output #0: loss = 3.43476 (* 1 = 3.43476 loss)
I0123 22:45:20.749938 29630 sgd_solver.cpp:106] Iteration 45880, lr = 0.01
I0123 22:45:28.092536 29630 solver.cpp:237] Iteration 45900, loss = 3.59114
I0123 22:45:28.092684 29630 solver.cpp:253]     Train net output #0: loss = 3.59114 (* 1 = 3.59114 loss)
I0123 22:45:28.092691 29630 sgd_solver.cpp:106] Iteration 45900, lr = 0.01
I0123 22:45:35.319609 29630 solver.cpp:237] Iteration 45920, loss = 3.40061
I0123 22:45:35.319648 29630 solver.cpp:253]     Train net output #0: loss = 3.40061 (* 1 = 3.40061 loss)
I0123 22:45:35.319655 29630 sgd_solver.cpp:106] Iteration 45920, lr = 0.01
I0123 22:45:42.650562 29630 solver.cpp:237] Iteration 45940, loss = 3.56645
I0123 22:45:42.650600 29630 solver.cpp:253]     Train net output #0: loss = 3.56645 (* 1 = 3.56645 loss)
I0123 22:45:42.650606 29630 sgd_solver.cpp:106] Iteration 45940, lr = 0.01
I0123 22:45:49.904367 29630 solver.cpp:237] Iteration 45960, loss = 3.36422
I0123 22:45:49.904405 29630 solver.cpp:253]     Train net output #0: loss = 3.36422 (* 1 = 3.36422 loss)
I0123 22:45:49.904420 29630 sgd_solver.cpp:106] Iteration 45960, lr = 0.01
I0123 22:45:57.186543 29630 solver.cpp:237] Iteration 45980, loss = 3.64635
I0123 22:45:57.186583 29630 solver.cpp:253]     Train net output #0: loss = 3.64635 (* 1 = 3.64635 loss)
I0123 22:45:57.186589 29630 sgd_solver.cpp:106] Iteration 45980, lr = 0.01
I0123 22:46:04.146585 29630 solver.cpp:341] Iteration 46000, Testing net (#0)
I0123 22:46:24.280314 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 22:47:17.820209 29630 solver.cpp:409]     Test net output #0: accuracy = 0.30512
I0123 22:47:17.820328 29630 solver.cpp:409]     Test net output #1: loss = 3.30817 (* 1 = 3.30817 loss)
I0123 22:47:17.861481 29630 solver.cpp:237] Iteration 46000, loss = 3.49409
I0123 22:47:17.861553 29630 solver.cpp:253]     Train net output #0: loss = 3.49409 (* 1 = 3.49409 loss)
I0123 22:47:17.861573 29630 sgd_solver.cpp:106] Iteration 46000, lr = 0.01
I0123 22:47:24.390804 29630 solver.cpp:237] Iteration 46020, loss = 3.48521
I0123 22:47:24.390841 29630 solver.cpp:253]     Train net output #0: loss = 3.48521 (* 1 = 3.48521 loss)
I0123 22:47:24.390846 29630 sgd_solver.cpp:106] Iteration 46020, lr = 0.01
I0123 22:47:31.665910 29630 solver.cpp:237] Iteration 46040, loss = 3.54477
I0123 22:47:31.665948 29630 solver.cpp:253]     Train net output #0: loss = 3.54477 (* 1 = 3.54477 loss)
I0123 22:47:31.665956 29630 sgd_solver.cpp:106] Iteration 46040, lr = 0.01
I0123 22:47:38.866004 29630 solver.cpp:237] Iteration 46060, loss = 3.51706
I0123 22:47:38.866044 29630 solver.cpp:253]     Train net output #0: loss = 3.51706 (* 1 = 3.51706 loss)
I0123 22:47:38.866049 29630 sgd_solver.cpp:106] Iteration 46060, lr = 0.01
I0123 22:47:46.084134 29630 solver.cpp:237] Iteration 46080, loss = 3.30863
I0123 22:47:46.084172 29630 solver.cpp:253]     Train net output #0: loss = 3.30863 (* 1 = 3.30863 loss)
I0123 22:47:46.084178 29630 sgd_solver.cpp:106] Iteration 46080, lr = 0.01
I0123 22:47:53.332635 29630 solver.cpp:237] Iteration 46100, loss = 3.51977
I0123 22:47:53.332784 29630 solver.cpp:253]     Train net output #0: loss = 3.51977 (* 1 = 3.51977 loss)
I0123 22:47:53.332792 29630 sgd_solver.cpp:106] Iteration 46100, lr = 0.01
I0123 22:48:00.591591 29630 solver.cpp:237] Iteration 46120, loss = 3.4295
I0123 22:48:00.591630 29630 solver.cpp:253]     Train net output #0: loss = 3.4295 (* 1 = 3.4295 loss)
I0123 22:48:00.591636 29630 sgd_solver.cpp:106] Iteration 46120, lr = 0.01
I0123 22:48:07.852088 29630 solver.cpp:237] Iteration 46140, loss = 3.52808
I0123 22:48:07.852129 29630 solver.cpp:253]     Train net output #0: loss = 3.52808 (* 1 = 3.52808 loss)
I0123 22:48:07.852135 29630 sgd_solver.cpp:106] Iteration 46140, lr = 0.01
I0123 22:48:15.111639 29630 solver.cpp:237] Iteration 46160, loss = 3.21262
I0123 22:48:15.111678 29630 solver.cpp:253]     Train net output #0: loss = 3.21262 (* 1 = 3.21262 loss)
I0123 22:48:15.111685 29630 sgd_solver.cpp:106] Iteration 46160, lr = 0.01
I0123 22:48:22.392540 29630 solver.cpp:237] Iteration 46180, loss = 3.2537
I0123 22:48:22.392578 29630 solver.cpp:253]     Train net output #0: loss = 3.2537 (* 1 = 3.2537 loss)
I0123 22:48:22.392595 29630 sgd_solver.cpp:106] Iteration 46180, lr = 0.01
I0123 22:48:29.675429 29630 solver.cpp:237] Iteration 46200, loss = 3.30106
I0123 22:48:29.675616 29630 solver.cpp:253]     Train net output #0: loss = 3.30106 (* 1 = 3.30106 loss)
I0123 22:48:29.675624 29630 sgd_solver.cpp:106] Iteration 46200, lr = 0.01
I0123 22:48:36.946044 29630 solver.cpp:237] Iteration 46220, loss = 3.45068
I0123 22:48:36.946081 29630 solver.cpp:253]     Train net output #0: loss = 3.45068 (* 1 = 3.45068 loss)
I0123 22:48:36.946087 29630 sgd_solver.cpp:106] Iteration 46220, lr = 0.01
I0123 22:48:44.207238 29630 solver.cpp:237] Iteration 46240, loss = 3.57383
I0123 22:48:44.207278 29630 solver.cpp:253]     Train net output #0: loss = 3.57383 (* 1 = 3.57383 loss)
I0123 22:48:44.207295 29630 sgd_solver.cpp:106] Iteration 46240, lr = 0.01
I0123 22:48:51.500372 29630 solver.cpp:237] Iteration 46260, loss = 3.56109
I0123 22:48:51.500411 29630 solver.cpp:253]     Train net output #0: loss = 3.56109 (* 1 = 3.56109 loss)
I0123 22:48:51.500417 29630 sgd_solver.cpp:106] Iteration 46260, lr = 0.01
I0123 22:48:57.738736 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 22:48:58.783057 29630 solver.cpp:237] Iteration 46280, loss = 3.4191
I0123 22:48:58.783095 29630 solver.cpp:253]     Train net output #0: loss = 3.4191 (* 1 = 3.4191 loss)
I0123 22:48:58.783100 29630 sgd_solver.cpp:106] Iteration 46280, lr = 0.01
I0123 22:49:06.077455 29630 solver.cpp:237] Iteration 46300, loss = 3.61844
I0123 22:49:06.077589 29630 solver.cpp:253]     Train net output #0: loss = 3.61844 (* 1 = 3.61844 loss)
I0123 22:49:06.077599 29630 sgd_solver.cpp:106] Iteration 46300, lr = 0.01
I0123 22:49:13.353024 29630 solver.cpp:237] Iteration 46320, loss = 3.45785
I0123 22:49:13.353062 29630 solver.cpp:253]     Train net output #0: loss = 3.45785 (* 1 = 3.45785 loss)
I0123 22:49:13.353068 29630 sgd_solver.cpp:106] Iteration 46320, lr = 0.01
I0123 22:49:20.628289 29630 solver.cpp:237] Iteration 46340, loss = 3.52413
I0123 22:49:20.628329 29630 solver.cpp:253]     Train net output #0: loss = 3.52413 (* 1 = 3.52413 loss)
I0123 22:49:20.628334 29630 sgd_solver.cpp:106] Iteration 46340, lr = 0.01
I0123 22:49:27.914332 29630 solver.cpp:237] Iteration 46360, loss = 3.28991
I0123 22:49:27.914371 29630 solver.cpp:253]     Train net output #0: loss = 3.28991 (* 1 = 3.28991 loss)
I0123 22:49:27.914377 29630 sgd_solver.cpp:106] Iteration 46360, lr = 0.01
I0123 22:49:35.224190 29630 solver.cpp:237] Iteration 46380, loss = 3.42671
I0123 22:49:35.224228 29630 solver.cpp:253]     Train net output #0: loss = 3.42671 (* 1 = 3.42671 loss)
I0123 22:49:35.224234 29630 sgd_solver.cpp:106] Iteration 46380, lr = 0.01
I0123 22:49:42.467659 29630 solver.cpp:237] Iteration 46400, loss = 3.83435
I0123 22:49:42.467768 29630 solver.cpp:253]     Train net output #0: loss = 3.83435 (* 1 = 3.83435 loss)
I0123 22:49:42.467785 29630 sgd_solver.cpp:106] Iteration 46400, lr = 0.01
I0123 22:49:49.702407 29630 solver.cpp:237] Iteration 46420, loss = 3.32492
I0123 22:49:49.702446 29630 solver.cpp:253]     Train net output #0: loss = 3.32492 (* 1 = 3.32492 loss)
I0123 22:49:49.702452 29630 sgd_solver.cpp:106] Iteration 46420, lr = 0.01
I0123 22:49:56.993839 29630 solver.cpp:237] Iteration 46440, loss = 3.29775
I0123 22:49:56.993877 29630 solver.cpp:253]     Train net output #0: loss = 3.29775 (* 1 = 3.29775 loss)
I0123 22:49:56.993883 29630 sgd_solver.cpp:106] Iteration 46440, lr = 0.01
I0123 22:50:04.290904 29630 solver.cpp:237] Iteration 46460, loss = 3.59663
I0123 22:50:04.290942 29630 solver.cpp:253]     Train net output #0: loss = 3.59663 (* 1 = 3.59663 loss)
I0123 22:50:04.290948 29630 sgd_solver.cpp:106] Iteration 46460, lr = 0.01
I0123 22:50:11.549273 29630 solver.cpp:237] Iteration 46480, loss = 3.67795
I0123 22:50:11.549311 29630 solver.cpp:253]     Train net output #0: loss = 3.67795 (* 1 = 3.67795 loss)
I0123 22:50:11.549316 29630 sgd_solver.cpp:106] Iteration 46480, lr = 0.01
I0123 22:50:18.842913 29630 solver.cpp:237] Iteration 46500, loss = 3.75667
I0123 22:50:18.843077 29630 solver.cpp:253]     Train net output #0: loss = 3.75667 (* 1 = 3.75667 loss)
I0123 22:50:18.843086 29630 sgd_solver.cpp:106] Iteration 46500, lr = 0.01
I0123 22:50:26.034719 29630 solver.cpp:237] Iteration 46520, loss = 3.66159
I0123 22:50:26.034757 29630 solver.cpp:253]     Train net output #0: loss = 3.66159 (* 1 = 3.66159 loss)
I0123 22:50:26.034764 29630 sgd_solver.cpp:106] Iteration 46520, lr = 0.01
I0123 22:50:33.299207 29630 solver.cpp:237] Iteration 46540, loss = 3.39513
I0123 22:50:33.299262 29630 solver.cpp:253]     Train net output #0: loss = 3.39513 (* 1 = 3.39513 loss)
I0123 22:50:33.299268 29630 sgd_solver.cpp:106] Iteration 46540, lr = 0.01
I0123 22:50:40.561499 29630 solver.cpp:237] Iteration 46560, loss = 3.45874
I0123 22:50:40.561540 29630 solver.cpp:253]     Train net output #0: loss = 3.45874 (* 1 = 3.45874 loss)
I0123 22:50:40.561547 29630 sgd_solver.cpp:106] Iteration 46560, lr = 0.01
I0123 22:50:47.836005 29630 solver.cpp:237] Iteration 46580, loss = 3.50425
I0123 22:50:47.836043 29630 solver.cpp:253]     Train net output #0: loss = 3.50425 (* 1 = 3.50425 loss)
I0123 22:50:47.836050 29630 sgd_solver.cpp:106] Iteration 46580, lr = 0.01
I0123 22:50:55.102612 29630 solver.cpp:237] Iteration 46600, loss = 3.40072
I0123 22:50:55.102735 29630 solver.cpp:253]     Train net output #0: loss = 3.40072 (* 1 = 3.40072 loss)
I0123 22:50:55.102743 29630 sgd_solver.cpp:106] Iteration 46600, lr = 0.01
I0123 22:51:02.352495 29630 solver.cpp:237] Iteration 46620, loss = 3.62189
I0123 22:51:02.352535 29630 solver.cpp:253]     Train net output #0: loss = 3.62189 (* 1 = 3.62189 loss)
I0123 22:51:02.352541 29630 sgd_solver.cpp:106] Iteration 46620, lr = 0.01
I0123 22:51:09.659415 29630 solver.cpp:237] Iteration 46640, loss = 3.32965
I0123 22:51:09.659454 29630 solver.cpp:253]     Train net output #0: loss = 3.32965 (* 1 = 3.32965 loss)
I0123 22:51:09.659461 29630 sgd_solver.cpp:106] Iteration 46640, lr = 0.01
I0123 22:51:16.898809 29630 solver.cpp:237] Iteration 46660, loss = 3.46557
I0123 22:51:16.898847 29630 solver.cpp:253]     Train net output #0: loss = 3.46557 (* 1 = 3.46557 loss)
I0123 22:51:16.898854 29630 sgd_solver.cpp:106] Iteration 46660, lr = 0.01
I0123 22:51:24.160173 29630 solver.cpp:237] Iteration 46680, loss = 3.47089
I0123 22:51:24.160213 29630 solver.cpp:253]     Train net output #0: loss = 3.47089 (* 1 = 3.47089 loss)
I0123 22:51:24.160220 29630 sgd_solver.cpp:106] Iteration 46680, lr = 0.01
I0123 22:51:31.405392 29630 solver.cpp:237] Iteration 46700, loss = 3.58943
I0123 22:51:31.405556 29630 solver.cpp:253]     Train net output #0: loss = 3.58943 (* 1 = 3.58943 loss)
I0123 22:51:31.405565 29630 sgd_solver.cpp:106] Iteration 46700, lr = 0.01
I0123 22:51:38.657673 29630 solver.cpp:237] Iteration 46720, loss = 3.44166
I0123 22:51:38.657714 29630 solver.cpp:253]     Train net output #0: loss = 3.44166 (* 1 = 3.44166 loss)
I0123 22:51:38.657721 29630 sgd_solver.cpp:106] Iteration 46720, lr = 0.01
I0123 22:51:45.901154 29630 solver.cpp:237] Iteration 46740, loss = 3.37407
I0123 22:51:45.901192 29630 solver.cpp:253]     Train net output #0: loss = 3.37407 (* 1 = 3.37407 loss)
I0123 22:51:45.901198 29630 sgd_solver.cpp:106] Iteration 46740, lr = 0.01
I0123 22:51:53.165734 29630 solver.cpp:237] Iteration 46760, loss = 3.37781
I0123 22:51:53.165773 29630 solver.cpp:253]     Train net output #0: loss = 3.37781 (* 1 = 3.37781 loss)
I0123 22:51:53.165779 29630 sgd_solver.cpp:106] Iteration 46760, lr = 0.01
I0123 22:52:00.425652 29630 solver.cpp:237] Iteration 46780, loss = 3.65509
I0123 22:52:00.425691 29630 solver.cpp:253]     Train net output #0: loss = 3.65509 (* 1 = 3.65509 loss)
I0123 22:52:00.425698 29630 sgd_solver.cpp:106] Iteration 46780, lr = 0.01
I0123 22:52:07.698596 29630 solver.cpp:237] Iteration 46800, loss = 3.36156
I0123 22:52:07.698781 29630 solver.cpp:253]     Train net output #0: loss = 3.36156 (* 1 = 3.36156 loss)
I0123 22:52:07.698789 29630 sgd_solver.cpp:106] Iteration 46800, lr = 0.01
I0123 22:52:14.957484 29630 solver.cpp:237] Iteration 46820, loss = 3.72668
I0123 22:52:14.957525 29630 solver.cpp:253]     Train net output #0: loss = 3.72668 (* 1 = 3.72668 loss)
I0123 22:52:14.957530 29630 sgd_solver.cpp:106] Iteration 46820, lr = 0.01
I0123 22:52:22.206919 29630 solver.cpp:237] Iteration 46840, loss = 3.55801
I0123 22:52:22.206957 29630 solver.cpp:253]     Train net output #0: loss = 3.55801 (* 1 = 3.55801 loss)
I0123 22:52:22.206964 29630 sgd_solver.cpp:106] Iteration 46840, lr = 0.01
I0123 22:52:29.514704 29630 solver.cpp:237] Iteration 46860, loss = 3.41668
I0123 22:52:29.514744 29630 solver.cpp:253]     Train net output #0: loss = 3.41668 (* 1 = 3.41668 loss)
I0123 22:52:29.514750 29630 sgd_solver.cpp:106] Iteration 46860, lr = 0.01
I0123 22:52:36.815971 29630 solver.cpp:237] Iteration 46880, loss = 3.17847
I0123 22:52:36.816010 29630 solver.cpp:253]     Train net output #0: loss = 3.17847 (* 1 = 3.17847 loss)
I0123 22:52:36.816017 29630 sgd_solver.cpp:106] Iteration 46880, lr = 0.01
I0123 22:52:44.081825 29630 solver.cpp:237] Iteration 46900, loss = 3.38176
I0123 22:52:44.081991 29630 solver.cpp:253]     Train net output #0: loss = 3.38176 (* 1 = 3.38176 loss)
I0123 22:52:44.082000 29630 sgd_solver.cpp:106] Iteration 46900, lr = 0.01
I0123 22:52:51.352716 29630 solver.cpp:237] Iteration 46920, loss = 3.43102
I0123 22:52:51.352756 29630 solver.cpp:253]     Train net output #0: loss = 3.43102 (* 1 = 3.43102 loss)
I0123 22:52:51.352761 29630 sgd_solver.cpp:106] Iteration 46920, lr = 0.01
I0123 22:52:58.636607 29630 solver.cpp:237] Iteration 46940, loss = 3.68611
I0123 22:52:58.636646 29630 solver.cpp:253]     Train net output #0: loss = 3.68611 (* 1 = 3.68611 loss)
I0123 22:52:58.636651 29630 sgd_solver.cpp:106] Iteration 46940, lr = 0.01
I0123 22:53:05.938290 29630 solver.cpp:237] Iteration 46960, loss = 3.71747
I0123 22:53:05.938328 29630 solver.cpp:253]     Train net output #0: loss = 3.71747 (* 1 = 3.71747 loss)
I0123 22:53:05.938334 29630 sgd_solver.cpp:106] Iteration 46960, lr = 0.01
I0123 22:53:13.213624 29630 solver.cpp:237] Iteration 46980, loss = 3.49748
I0123 22:53:13.213662 29630 solver.cpp:253]     Train net output #0: loss = 3.49748 (* 1 = 3.49748 loss)
I0123 22:53:13.213670 29630 sgd_solver.cpp:106] Iteration 46980, lr = 0.01
I0123 22:53:20.191169 29630 solver.cpp:341] Iteration 47000, Testing net (#0)
I0123 22:53:40.854475 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 22:54:33.956364 29630 solver.cpp:409]     Test net output #0: accuracy = 0.30432
I0123 22:54:33.956468 29630 solver.cpp:409]     Test net output #1: loss = 3.30803 (* 1 = 3.30803 loss)
I0123 22:54:33.997037 29630 solver.cpp:237] Iteration 47000, loss = 3.39558
I0123 22:54:33.997104 29630 solver.cpp:253]     Train net output #0: loss = 3.39558 (* 1 = 3.39558 loss)
I0123 22:54:33.997123 29630 sgd_solver.cpp:106] Iteration 47000, lr = 0.01
I0123 22:54:40.582911 29630 solver.cpp:237] Iteration 47020, loss = 3.72207
I0123 22:54:40.582950 29630 solver.cpp:253]     Train net output #0: loss = 3.72207 (* 1 = 3.72207 loss)
I0123 22:54:40.582957 29630 sgd_solver.cpp:106] Iteration 47020, lr = 0.01
I0123 22:54:47.825145 29630 solver.cpp:237] Iteration 47040, loss = 3.5206
I0123 22:54:47.825184 29630 solver.cpp:253]     Train net output #0: loss = 3.5206 (* 1 = 3.5206 loss)
I0123 22:54:47.825191 29630 sgd_solver.cpp:106] Iteration 47040, lr = 0.01
I0123 22:54:55.059298 29630 solver.cpp:237] Iteration 47060, loss = 3.60081
I0123 22:54:55.059336 29630 solver.cpp:253]     Train net output #0: loss = 3.60081 (* 1 = 3.60081 loss)
I0123 22:54:55.059342 29630 sgd_solver.cpp:106] Iteration 47060, lr = 0.01
I0123 22:55:02.312409 29630 solver.cpp:237] Iteration 47080, loss = 3.46107
I0123 22:55:02.312466 29630 solver.cpp:253]     Train net output #0: loss = 3.46107 (* 1 = 3.46107 loss)
I0123 22:55:02.312479 29630 sgd_solver.cpp:106] Iteration 47080, lr = 0.01
I0123 22:55:09.639744 29630 solver.cpp:237] Iteration 47100, loss = 3.12251
I0123 22:55:09.639873 29630 solver.cpp:253]     Train net output #0: loss = 3.12251 (* 1 = 3.12251 loss)
I0123 22:55:09.639889 29630 sgd_solver.cpp:106] Iteration 47100, lr = 0.01
I0123 22:55:16.865814 29630 solver.cpp:237] Iteration 47120, loss = 3.59533
I0123 22:55:16.865852 29630 solver.cpp:253]     Train net output #0: loss = 3.59533 (* 1 = 3.59533 loss)
I0123 22:55:16.865859 29630 sgd_solver.cpp:106] Iteration 47120, lr = 0.01
I0123 22:55:24.124757 29630 solver.cpp:237] Iteration 47140, loss = 3.47722
I0123 22:55:24.124815 29630 solver.cpp:253]     Train net output #0: loss = 3.47722 (* 1 = 3.47722 loss)
I0123 22:55:24.124826 29630 sgd_solver.cpp:106] Iteration 47140, lr = 0.01
I0123 22:55:31.375468 29630 solver.cpp:237] Iteration 47160, loss = 3.35942
I0123 22:55:31.375505 29630 solver.cpp:253]     Train net output #0: loss = 3.35942 (* 1 = 3.35942 loss)
I0123 22:55:31.375511 29630 sgd_solver.cpp:106] Iteration 47160, lr = 0.01
I0123 22:55:38.703169 29630 solver.cpp:237] Iteration 47180, loss = 3.58641
I0123 22:55:38.703208 29630 solver.cpp:253]     Train net output #0: loss = 3.58641 (* 1 = 3.58641 loss)
I0123 22:55:38.703214 29630 sgd_solver.cpp:106] Iteration 47180, lr = 0.01
I0123 22:55:45.989969 29630 solver.cpp:237] Iteration 47200, loss = 3.27133
I0123 22:55:45.990142 29630 solver.cpp:253]     Train net output #0: loss = 3.27133 (* 1 = 3.27133 loss)
I0123 22:55:45.990150 29630 sgd_solver.cpp:106] Iteration 47200, lr = 0.01
I0123 22:55:53.270378 29630 solver.cpp:237] Iteration 47220, loss = 3.43198
I0123 22:55:53.270417 29630 solver.cpp:253]     Train net output #0: loss = 3.43198 (* 1 = 3.43198 loss)
I0123 22:55:53.270424 29630 sgd_solver.cpp:106] Iteration 47220, lr = 0.01
I0123 22:56:00.539465 29630 solver.cpp:237] Iteration 47240, loss = 3.63157
I0123 22:56:00.539504 29630 solver.cpp:253]     Train net output #0: loss = 3.63157 (* 1 = 3.63157 loss)
I0123 22:56:00.539510 29630 sgd_solver.cpp:106] Iteration 47240, lr = 0.01
I0123 22:56:07.847491 29630 solver.cpp:237] Iteration 47260, loss = 3.53756
I0123 22:56:07.847530 29630 solver.cpp:253]     Train net output #0: loss = 3.53756 (* 1 = 3.53756 loss)
I0123 22:56:07.847537 29630 sgd_solver.cpp:106] Iteration 47260, lr = 0.01
I0123 22:56:15.121387 29630 solver.cpp:237] Iteration 47280, loss = 3.4505
I0123 22:56:15.121424 29630 solver.cpp:253]     Train net output #0: loss = 3.4505 (* 1 = 3.4505 loss)
I0123 22:56:15.121431 29630 sgd_solver.cpp:106] Iteration 47280, lr = 0.01
I0123 22:56:16.273710 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 22:56:22.435880 29630 solver.cpp:237] Iteration 47300, loss = 3.20563
I0123 22:56:22.435919 29630 solver.cpp:253]     Train net output #0: loss = 3.20563 (* 1 = 3.20563 loss)
I0123 22:56:22.435925 29630 sgd_solver.cpp:106] Iteration 47300, lr = 0.01
I0123 22:56:29.693936 29630 solver.cpp:237] Iteration 47320, loss = 3.47362
I0123 22:56:29.693984 29630 solver.cpp:253]     Train net output #0: loss = 3.47362 (* 1 = 3.47362 loss)
I0123 22:56:29.693989 29630 sgd_solver.cpp:106] Iteration 47320, lr = 0.01
I0123 22:56:36.975083 29630 solver.cpp:237] Iteration 47340, loss = 3.52482
I0123 22:56:36.975131 29630 solver.cpp:253]     Train net output #0: loss = 3.52482 (* 1 = 3.52482 loss)
I0123 22:56:36.975137 29630 sgd_solver.cpp:106] Iteration 47340, lr = 0.01
I0123 22:56:44.240957 29630 solver.cpp:237] Iteration 47360, loss = 3.47191
I0123 22:56:44.240995 29630 solver.cpp:253]     Train net output #0: loss = 3.47191 (* 1 = 3.47191 loss)
I0123 22:56:44.241001 29630 sgd_solver.cpp:106] Iteration 47360, lr = 0.01
I0123 22:56:51.547719 29630 solver.cpp:237] Iteration 47380, loss = 3.24895
I0123 22:56:51.547842 29630 solver.cpp:253]     Train net output #0: loss = 3.24895 (* 1 = 3.24895 loss)
I0123 22:56:51.547849 29630 sgd_solver.cpp:106] Iteration 47380, lr = 0.01
I0123 22:56:58.798919 29630 solver.cpp:237] Iteration 47400, loss = 3.49045
I0123 22:56:58.798957 29630 solver.cpp:253]     Train net output #0: loss = 3.49045 (* 1 = 3.49045 loss)
I0123 22:56:58.798964 29630 sgd_solver.cpp:106] Iteration 47400, lr = 0.01
I0123 22:57:06.044836 29630 solver.cpp:237] Iteration 47420, loss = 3.52474
I0123 22:57:06.044873 29630 solver.cpp:253]     Train net output #0: loss = 3.52474 (* 1 = 3.52474 loss)
I0123 22:57:06.044879 29630 sgd_solver.cpp:106] Iteration 47420, lr = 0.01
I0123 22:57:13.341435 29630 solver.cpp:237] Iteration 47440, loss = 3.35398
I0123 22:57:13.341490 29630 solver.cpp:253]     Train net output #0: loss = 3.35398 (* 1 = 3.35398 loss)
I0123 22:57:13.341496 29630 sgd_solver.cpp:106] Iteration 47440, lr = 0.01
I0123 22:57:20.611690 29630 solver.cpp:237] Iteration 47460, loss = 3.45799
I0123 22:57:20.611732 29630 solver.cpp:253]     Train net output #0: loss = 3.45799 (* 1 = 3.45799 loss)
I0123 22:57:20.611739 29630 sgd_solver.cpp:106] Iteration 47460, lr = 0.01
I0123 22:57:27.916074 29630 solver.cpp:237] Iteration 47480, loss = 3.40163
I0123 22:57:27.916205 29630 solver.cpp:253]     Train net output #0: loss = 3.40163 (* 1 = 3.40163 loss)
I0123 22:57:27.916223 29630 sgd_solver.cpp:106] Iteration 47480, lr = 0.01
I0123 22:57:35.185111 29630 solver.cpp:237] Iteration 47500, loss = 3.40462
I0123 22:57:35.185149 29630 solver.cpp:253]     Train net output #0: loss = 3.40462 (* 1 = 3.40462 loss)
I0123 22:57:35.185156 29630 sgd_solver.cpp:106] Iteration 47500, lr = 0.01
I0123 22:57:42.443907 29630 solver.cpp:237] Iteration 47520, loss = 3.51723
I0123 22:57:42.443945 29630 solver.cpp:253]     Train net output #0: loss = 3.51723 (* 1 = 3.51723 loss)
I0123 22:57:42.443953 29630 sgd_solver.cpp:106] Iteration 47520, lr = 0.01
I0123 22:57:49.685988 29630 solver.cpp:237] Iteration 47540, loss = 3.2841
I0123 22:57:49.686028 29630 solver.cpp:253]     Train net output #0: loss = 3.2841 (* 1 = 3.2841 loss)
I0123 22:57:49.686033 29630 sgd_solver.cpp:106] Iteration 47540, lr = 0.01
I0123 22:57:56.961421 29630 solver.cpp:237] Iteration 47560, loss = 3.67277
I0123 22:57:56.961459 29630 solver.cpp:253]     Train net output #0: loss = 3.67277 (* 1 = 3.67277 loss)
I0123 22:57:56.961465 29630 sgd_solver.cpp:106] Iteration 47560, lr = 0.01
I0123 22:58:04.277271 29630 solver.cpp:237] Iteration 47580, loss = 3.39727
I0123 22:58:04.277400 29630 solver.cpp:253]     Train net output #0: loss = 3.39727 (* 1 = 3.39727 loss)
I0123 22:58:04.277408 29630 sgd_solver.cpp:106] Iteration 47580, lr = 0.01
I0123 22:58:11.554646 29630 solver.cpp:237] Iteration 47600, loss = 3.41836
I0123 22:58:11.554685 29630 solver.cpp:253]     Train net output #0: loss = 3.41836 (* 1 = 3.41836 loss)
I0123 22:58:11.554692 29630 sgd_solver.cpp:106] Iteration 47600, lr = 0.01
I0123 22:58:18.779409 29630 solver.cpp:237] Iteration 47620, loss = 3.49807
I0123 22:58:18.779448 29630 solver.cpp:253]     Train net output #0: loss = 3.49807 (* 1 = 3.49807 loss)
I0123 22:58:18.779454 29630 sgd_solver.cpp:106] Iteration 47620, lr = 0.01
I0123 22:58:26.004158 29630 solver.cpp:237] Iteration 47640, loss = 3.54465
I0123 22:58:26.004194 29630 solver.cpp:253]     Train net output #0: loss = 3.54465 (* 1 = 3.54465 loss)
I0123 22:58:26.004200 29630 sgd_solver.cpp:106] Iteration 47640, lr = 0.01
I0123 22:58:33.228667 29630 solver.cpp:237] Iteration 47660, loss = 3.34687
I0123 22:58:33.228705 29630 solver.cpp:253]     Train net output #0: loss = 3.34687 (* 1 = 3.34687 loss)
I0123 22:58:33.228711 29630 sgd_solver.cpp:106] Iteration 47660, lr = 0.01
I0123 22:58:40.499419 29630 solver.cpp:237] Iteration 47680, loss = 3.54671
I0123 22:58:40.499595 29630 solver.cpp:253]     Train net output #0: loss = 3.54671 (* 1 = 3.54671 loss)
I0123 22:58:40.499613 29630 sgd_solver.cpp:106] Iteration 47680, lr = 0.01
I0123 22:58:47.763881 29630 solver.cpp:237] Iteration 47700, loss = 3.78846
I0123 22:58:47.763919 29630 solver.cpp:253]     Train net output #0: loss = 3.78846 (* 1 = 3.78846 loss)
I0123 22:58:47.763926 29630 sgd_solver.cpp:106] Iteration 47700, lr = 0.01
I0123 22:58:54.987046 29630 solver.cpp:237] Iteration 47720, loss = 3.31672
I0123 22:58:54.987084 29630 solver.cpp:253]     Train net output #0: loss = 3.31672 (* 1 = 3.31672 loss)
I0123 22:58:54.987090 29630 sgd_solver.cpp:106] Iteration 47720, lr = 0.01
I0123 22:59:02.216243 29630 solver.cpp:237] Iteration 47740, loss = 3.7057
I0123 22:59:02.216289 29630 solver.cpp:253]     Train net output #0: loss = 3.7057 (* 1 = 3.7057 loss)
I0123 22:59:02.216295 29630 sgd_solver.cpp:106] Iteration 47740, lr = 0.01
I0123 22:59:09.467382 29630 solver.cpp:237] Iteration 47760, loss = 3.28051
I0123 22:59:09.467422 29630 solver.cpp:253]     Train net output #0: loss = 3.28051 (* 1 = 3.28051 loss)
I0123 22:59:09.467427 29630 sgd_solver.cpp:106] Iteration 47760, lr = 0.01
I0123 22:59:16.733782 29630 solver.cpp:237] Iteration 47780, loss = 3.21911
I0123 22:59:16.733922 29630 solver.cpp:253]     Train net output #0: loss = 3.21911 (* 1 = 3.21911 loss)
I0123 22:59:16.733930 29630 sgd_solver.cpp:106] Iteration 47780, lr = 0.01
I0123 22:59:24.018592 29630 solver.cpp:237] Iteration 47800, loss = 3.35006
I0123 22:59:24.018630 29630 solver.cpp:253]     Train net output #0: loss = 3.35006 (* 1 = 3.35006 loss)
I0123 22:59:24.018636 29630 sgd_solver.cpp:106] Iteration 47800, lr = 0.01
I0123 22:59:31.270723 29630 solver.cpp:237] Iteration 47820, loss = 3.64724
I0123 22:59:31.270781 29630 solver.cpp:253]     Train net output #0: loss = 3.64724 (* 1 = 3.64724 loss)
I0123 22:59:31.270797 29630 sgd_solver.cpp:106] Iteration 47820, lr = 0.01
I0123 22:59:38.531553 29630 solver.cpp:237] Iteration 47840, loss = 3.4776
I0123 22:59:38.531592 29630 solver.cpp:253]     Train net output #0: loss = 3.4776 (* 1 = 3.4776 loss)
I0123 22:59:38.531599 29630 sgd_solver.cpp:106] Iteration 47840, lr = 0.01
I0123 22:59:45.795420 29630 solver.cpp:237] Iteration 47860, loss = 3.23668
I0123 22:59:45.795464 29630 solver.cpp:253]     Train net output #0: loss = 3.23668 (* 1 = 3.23668 loss)
I0123 22:59:45.795482 29630 sgd_solver.cpp:106] Iteration 47860, lr = 0.01
I0123 22:59:53.049547 29630 solver.cpp:237] Iteration 47880, loss = 3.36943
I0123 22:59:53.049721 29630 solver.cpp:253]     Train net output #0: loss = 3.36943 (* 1 = 3.36943 loss)
I0123 22:59:53.049728 29630 sgd_solver.cpp:106] Iteration 47880, lr = 0.01
I0123 23:00:00.265043 29630 solver.cpp:237] Iteration 47900, loss = 3.30499
I0123 23:00:00.265080 29630 solver.cpp:253]     Train net output #0: loss = 3.30499 (* 1 = 3.30499 loss)
I0123 23:00:00.265086 29630 sgd_solver.cpp:106] Iteration 47900, lr = 0.01
I0123 23:00:07.555140 29630 solver.cpp:237] Iteration 47920, loss = 3.43158
I0123 23:00:07.555179 29630 solver.cpp:253]     Train net output #0: loss = 3.43158 (* 1 = 3.43158 loss)
I0123 23:00:07.555186 29630 sgd_solver.cpp:106] Iteration 47920, lr = 0.01
I0123 23:00:14.870034 29630 solver.cpp:237] Iteration 47940, loss = 3.49735
I0123 23:00:14.870074 29630 solver.cpp:253]     Train net output #0: loss = 3.49735 (* 1 = 3.49735 loss)
I0123 23:00:14.870079 29630 sgd_solver.cpp:106] Iteration 47940, lr = 0.01
I0123 23:00:22.088932 29630 solver.cpp:237] Iteration 47960, loss = 3.33016
I0123 23:00:22.088969 29630 solver.cpp:253]     Train net output #0: loss = 3.33016 (* 1 = 3.33016 loss)
I0123 23:00:22.088975 29630 sgd_solver.cpp:106] Iteration 47960, lr = 0.01
I0123 23:00:29.384925 29630 solver.cpp:237] Iteration 47980, loss = 3.33832
I0123 23:00:29.385068 29630 solver.cpp:253]     Train net output #0: loss = 3.33832 (* 1 = 3.33832 loss)
I0123 23:00:29.385076 29630 sgd_solver.cpp:106] Iteration 47980, lr = 0.01
I0123 23:00:36.429472 29630 solver.cpp:341] Iteration 48000, Testing net (#0)
I0123 23:00:57.532040 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 23:01:50.546599 29630 solver.cpp:409]     Test net output #0: accuracy = 0.3078
I0123 23:01:50.546727 29630 solver.cpp:409]     Test net output #1: loss = 3.27859 (* 1 = 3.27859 loss)
I0123 23:01:50.587235 29630 solver.cpp:237] Iteration 48000, loss = 3.56498
I0123 23:01:50.587265 29630 solver.cpp:253]     Train net output #0: loss = 3.56498 (* 1 = 3.56498 loss)
I0123 23:01:50.587270 29630 sgd_solver.cpp:106] Iteration 48000, lr = 0.01
I0123 23:01:57.155285 29630 solver.cpp:237] Iteration 48020, loss = 3.52334
I0123 23:01:57.155323 29630 solver.cpp:253]     Train net output #0: loss = 3.52334 (* 1 = 3.52334 loss)
I0123 23:01:57.155330 29630 sgd_solver.cpp:106] Iteration 48020, lr = 0.01
I0123 23:02:04.468123 29630 solver.cpp:237] Iteration 48040, loss = 3.45336
I0123 23:02:04.468161 29630 solver.cpp:253]     Train net output #0: loss = 3.45336 (* 1 = 3.45336 loss)
I0123 23:02:04.468168 29630 sgd_solver.cpp:106] Iteration 48040, lr = 0.01
I0123 23:02:11.733789 29630 solver.cpp:237] Iteration 48060, loss = 3.36716
I0123 23:02:11.733826 29630 solver.cpp:253]     Train net output #0: loss = 3.36716 (* 1 = 3.36716 loss)
I0123 23:02:11.733834 29630 sgd_solver.cpp:106] Iteration 48060, lr = 0.01
I0123 23:02:18.978765 29630 solver.cpp:237] Iteration 48080, loss = 3.34714
I0123 23:02:18.978802 29630 solver.cpp:253]     Train net output #0: loss = 3.34714 (* 1 = 3.34714 loss)
I0123 23:02:18.978809 29630 sgd_solver.cpp:106] Iteration 48080, lr = 0.01
I0123 23:02:26.199609 29630 solver.cpp:237] Iteration 48100, loss = 3.62204
I0123 23:02:26.199720 29630 solver.cpp:253]     Train net output #0: loss = 3.62204 (* 1 = 3.62204 loss)
I0123 23:02:26.199728 29630 sgd_solver.cpp:106] Iteration 48100, lr = 0.01
I0123 23:02:33.409050 29630 solver.cpp:237] Iteration 48120, loss = 3.46888
I0123 23:02:33.409090 29630 solver.cpp:253]     Train net output #0: loss = 3.46888 (* 1 = 3.46888 loss)
I0123 23:02:33.409096 29630 sgd_solver.cpp:106] Iteration 48120, lr = 0.01
I0123 23:02:40.700294 29630 solver.cpp:237] Iteration 48140, loss = 3.73326
I0123 23:02:40.700333 29630 solver.cpp:253]     Train net output #0: loss = 3.73326 (* 1 = 3.73326 loss)
I0123 23:02:40.700340 29630 sgd_solver.cpp:106] Iteration 48140, lr = 0.01
I0123 23:02:48.012665 29630 solver.cpp:237] Iteration 48160, loss = 3.46073
I0123 23:02:48.012704 29630 solver.cpp:253]     Train net output #0: loss = 3.46073 (* 1 = 3.46073 loss)
I0123 23:02:48.012712 29630 sgd_solver.cpp:106] Iteration 48160, lr = 0.01
I0123 23:02:55.257958 29630 solver.cpp:237] Iteration 48180, loss = 3.55677
I0123 23:02:55.257998 29630 solver.cpp:253]     Train net output #0: loss = 3.55677 (* 1 = 3.55677 loss)
I0123 23:02:55.258004 29630 sgd_solver.cpp:106] Iteration 48180, lr = 0.01
I0123 23:03:02.508000 29630 solver.cpp:237] Iteration 48200, loss = 3.40538
I0123 23:03:02.508131 29630 solver.cpp:253]     Train net output #0: loss = 3.40538 (* 1 = 3.40538 loss)
I0123 23:03:02.508138 29630 sgd_solver.cpp:106] Iteration 48200, lr = 0.01
I0123 23:03:09.771920 29630 solver.cpp:237] Iteration 48220, loss = 3.38994
I0123 23:03:09.771960 29630 solver.cpp:253]     Train net output #0: loss = 3.38994 (* 1 = 3.38994 loss)
I0123 23:03:09.771965 29630 sgd_solver.cpp:106] Iteration 48220, lr = 0.01
I0123 23:03:17.023211 29630 solver.cpp:237] Iteration 48240, loss = 3.38884
I0123 23:03:17.023249 29630 solver.cpp:253]     Train net output #0: loss = 3.38884 (* 1 = 3.38884 loss)
I0123 23:03:17.023255 29630 sgd_solver.cpp:106] Iteration 48240, lr = 0.01
I0123 23:03:24.257477 29630 solver.cpp:237] Iteration 48260, loss = 3.60175
I0123 23:03:24.257515 29630 solver.cpp:253]     Train net output #0: loss = 3.60175 (* 1 = 3.60175 loss)
I0123 23:03:24.257521 29630 sgd_solver.cpp:106] Iteration 48260, lr = 0.01
I0123 23:03:31.466820 29630 solver.cpp:237] Iteration 48280, loss = 3.16321
I0123 23:03:31.466861 29630 solver.cpp:253]     Train net output #0: loss = 3.16321 (* 1 = 3.16321 loss)
I0123 23:03:31.466866 29630 sgd_solver.cpp:106] Iteration 48280, lr = 0.01
I0123 23:03:34.814931 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 23:03:38.717551 29630 solver.cpp:237] Iteration 48300, loss = 3.59806
I0123 23:03:38.717593 29630 solver.cpp:253]     Train net output #0: loss = 3.59806 (* 1 = 3.59806 loss)
I0123 23:03:38.717600 29630 sgd_solver.cpp:106] Iteration 48300, lr = 0.01
I0123 23:03:45.950598 29630 solver.cpp:237] Iteration 48320, loss = 3.41542
I0123 23:03:45.950637 29630 solver.cpp:253]     Train net output #0: loss = 3.41542 (* 1 = 3.41542 loss)
I0123 23:03:45.950644 29630 sgd_solver.cpp:106] Iteration 48320, lr = 0.01
I0123 23:03:53.167462 29630 solver.cpp:237] Iteration 48340, loss = 3.32894
I0123 23:03:53.167500 29630 solver.cpp:253]     Train net output #0: loss = 3.32894 (* 1 = 3.32894 loss)
I0123 23:03:53.167505 29630 sgd_solver.cpp:106] Iteration 48340, lr = 0.01
I0123 23:04:00.409373 29630 solver.cpp:237] Iteration 48360, loss = 3.64937
I0123 23:04:00.409411 29630 solver.cpp:253]     Train net output #0: loss = 3.64937 (* 1 = 3.64937 loss)
I0123 23:04:00.409418 29630 sgd_solver.cpp:106] Iteration 48360, lr = 0.01
I0123 23:04:07.679883 29630 solver.cpp:237] Iteration 48380, loss = 3.60495
I0123 23:04:07.680050 29630 solver.cpp:253]     Train net output #0: loss = 3.60495 (* 1 = 3.60495 loss)
I0123 23:04:07.680068 29630 sgd_solver.cpp:106] Iteration 48380, lr = 0.01
I0123 23:04:14.937216 29630 solver.cpp:237] Iteration 48400, loss = 3.40058
I0123 23:04:14.937257 29630 solver.cpp:253]     Train net output #0: loss = 3.40058 (* 1 = 3.40058 loss)
I0123 23:04:14.937263 29630 sgd_solver.cpp:106] Iteration 48400, lr = 0.01
I0123 23:04:22.193646 29630 solver.cpp:237] Iteration 48420, loss = 3.50577
I0123 23:04:22.193687 29630 solver.cpp:253]     Train net output #0: loss = 3.50577 (* 1 = 3.50577 loss)
I0123 23:04:22.193694 29630 sgd_solver.cpp:106] Iteration 48420, lr = 0.01
I0123 23:04:29.500512 29630 solver.cpp:237] Iteration 48440, loss = 3.27613
I0123 23:04:29.500560 29630 solver.cpp:253]     Train net output #0: loss = 3.27613 (* 1 = 3.27613 loss)
I0123 23:04:29.500566 29630 sgd_solver.cpp:106] Iteration 48440, lr = 0.01
I0123 23:04:36.752445 29630 solver.cpp:237] Iteration 48460, loss = 3.36654
I0123 23:04:36.752485 29630 solver.cpp:253]     Train net output #0: loss = 3.36654 (* 1 = 3.36654 loss)
I0123 23:04:36.752490 29630 sgd_solver.cpp:106] Iteration 48460, lr = 0.01
I0123 23:04:44.028669 29630 solver.cpp:237] Iteration 48480, loss = 3.38387
I0123 23:04:44.028838 29630 solver.cpp:253]     Train net output #0: loss = 3.38387 (* 1 = 3.38387 loss)
I0123 23:04:44.028846 29630 sgd_solver.cpp:106] Iteration 48480, lr = 0.01
I0123 23:04:51.316951 29630 solver.cpp:237] Iteration 48500, loss = 3.38822
I0123 23:04:51.316990 29630 solver.cpp:253]     Train net output #0: loss = 3.38822 (* 1 = 3.38822 loss)
I0123 23:04:51.316997 29630 sgd_solver.cpp:106] Iteration 48500, lr = 0.01
I0123 23:04:58.563967 29630 solver.cpp:237] Iteration 48520, loss = 3.51735
I0123 23:04:58.564007 29630 solver.cpp:253]     Train net output #0: loss = 3.51735 (* 1 = 3.51735 loss)
I0123 23:04:58.564013 29630 sgd_solver.cpp:106] Iteration 48520, lr = 0.01
I0123 23:05:05.891028 29630 solver.cpp:237] Iteration 48540, loss = 3.52206
I0123 23:05:05.891067 29630 solver.cpp:253]     Train net output #0: loss = 3.52206 (* 1 = 3.52206 loss)
I0123 23:05:05.891072 29630 sgd_solver.cpp:106] Iteration 48540, lr = 0.01
I0123 23:05:13.155589 29630 solver.cpp:237] Iteration 48560, loss = 3.36149
I0123 23:05:13.155628 29630 solver.cpp:253]     Train net output #0: loss = 3.36149 (* 1 = 3.36149 loss)
I0123 23:05:13.155635 29630 sgd_solver.cpp:106] Iteration 48560, lr = 0.01
I0123 23:05:20.438701 29630 solver.cpp:237] Iteration 48580, loss = 3.52425
I0123 23:05:20.438877 29630 solver.cpp:253]     Train net output #0: loss = 3.52425 (* 1 = 3.52425 loss)
I0123 23:05:20.438895 29630 sgd_solver.cpp:106] Iteration 48580, lr = 0.01
I0123 23:05:27.703161 29630 solver.cpp:237] Iteration 48600, loss = 3.41447
I0123 23:05:27.703199 29630 solver.cpp:253]     Train net output #0: loss = 3.41447 (* 1 = 3.41447 loss)
I0123 23:05:27.703207 29630 sgd_solver.cpp:106] Iteration 48600, lr = 0.01
I0123 23:05:34.979975 29630 solver.cpp:237] Iteration 48620, loss = 3.65463
I0123 23:05:34.980015 29630 solver.cpp:253]     Train net output #0: loss = 3.65463 (* 1 = 3.65463 loss)
I0123 23:05:34.980021 29630 sgd_solver.cpp:106] Iteration 48620, lr = 0.01
I0123 23:05:42.246666 29630 solver.cpp:237] Iteration 48640, loss = 3.35273
I0123 23:05:42.246706 29630 solver.cpp:253]     Train net output #0: loss = 3.35273 (* 1 = 3.35273 loss)
I0123 23:05:42.246713 29630 sgd_solver.cpp:106] Iteration 48640, lr = 0.01
I0123 23:05:49.496840 29630 solver.cpp:237] Iteration 48660, loss = 3.37791
I0123 23:05:49.496879 29630 solver.cpp:253]     Train net output #0: loss = 3.37791 (* 1 = 3.37791 loss)
I0123 23:05:49.496886 29630 sgd_solver.cpp:106] Iteration 48660, lr = 0.01
I0123 23:05:56.754398 29630 solver.cpp:237] Iteration 48680, loss = 3.11803
I0123 23:05:56.754565 29630 solver.cpp:253]     Train net output #0: loss = 3.11803 (* 1 = 3.11803 loss)
I0123 23:05:56.754573 29630 sgd_solver.cpp:106] Iteration 48680, lr = 0.01
I0123 23:06:03.981984 29630 solver.cpp:237] Iteration 48700, loss = 3.5231
I0123 23:06:03.982023 29630 solver.cpp:253]     Train net output #0: loss = 3.5231 (* 1 = 3.5231 loss)
I0123 23:06:03.982029 29630 sgd_solver.cpp:106] Iteration 48700, lr = 0.01
I0123 23:06:11.238317 29630 solver.cpp:237] Iteration 48720, loss = 3.65094
I0123 23:06:11.238355 29630 solver.cpp:253]     Train net output #0: loss = 3.65094 (* 1 = 3.65094 loss)
I0123 23:06:11.238361 29630 sgd_solver.cpp:106] Iteration 48720, lr = 0.01
I0123 23:06:18.537171 29630 solver.cpp:237] Iteration 48740, loss = 3.58628
I0123 23:06:18.537200 29630 solver.cpp:253]     Train net output #0: loss = 3.58628 (* 1 = 3.58628 loss)
I0123 23:06:18.537206 29630 sgd_solver.cpp:106] Iteration 48740, lr = 0.01
I0123 23:06:25.886962 29630 solver.cpp:237] Iteration 48760, loss = 3.32546
I0123 23:06:25.887001 29630 solver.cpp:253]     Train net output #0: loss = 3.32546 (* 1 = 3.32546 loss)
I0123 23:06:25.887007 29630 sgd_solver.cpp:106] Iteration 48760, lr = 0.01
I0123 23:06:33.144569 29630 solver.cpp:237] Iteration 48780, loss = 3.20981
I0123 23:06:33.144744 29630 solver.cpp:253]     Train net output #0: loss = 3.20981 (* 1 = 3.20981 loss)
I0123 23:06:33.144752 29630 sgd_solver.cpp:106] Iteration 48780, lr = 0.01
I0123 23:06:40.394093 29630 solver.cpp:237] Iteration 48800, loss = 3.49338
I0123 23:06:40.394132 29630 solver.cpp:253]     Train net output #0: loss = 3.49338 (* 1 = 3.49338 loss)
I0123 23:06:40.394139 29630 sgd_solver.cpp:106] Iteration 48800, lr = 0.01
I0123 23:06:47.652411 29630 solver.cpp:237] Iteration 48820, loss = 3.55955
I0123 23:06:47.652449 29630 solver.cpp:253]     Train net output #0: loss = 3.55955 (* 1 = 3.55955 loss)
I0123 23:06:47.652456 29630 sgd_solver.cpp:106] Iteration 48820, lr = 0.01
I0123 23:06:54.958858 29630 solver.cpp:237] Iteration 48840, loss = 3.73665
I0123 23:06:54.958895 29630 solver.cpp:253]     Train net output #0: loss = 3.73665 (* 1 = 3.73665 loss)
I0123 23:06:54.958901 29630 sgd_solver.cpp:106] Iteration 48840, lr = 0.01
I0123 23:07:02.215023 29630 solver.cpp:237] Iteration 48860, loss = 3.37428
I0123 23:07:02.215060 29630 solver.cpp:253]     Train net output #0: loss = 3.37428 (* 1 = 3.37428 loss)
I0123 23:07:02.215066 29630 sgd_solver.cpp:106] Iteration 48860, lr = 0.01
I0123 23:07:09.471968 29630 solver.cpp:237] Iteration 48880, loss = 3.51132
I0123 23:07:09.472118 29630 solver.cpp:253]     Train net output #0: loss = 3.51132 (* 1 = 3.51132 loss)
I0123 23:07:09.472126 29630 sgd_solver.cpp:106] Iteration 48880, lr = 0.01
I0123 23:07:16.712398 29630 solver.cpp:237] Iteration 48900, loss = 3.2011
I0123 23:07:16.712436 29630 solver.cpp:253]     Train net output #0: loss = 3.2011 (* 1 = 3.2011 loss)
I0123 23:07:16.712442 29630 sgd_solver.cpp:106] Iteration 48900, lr = 0.01
I0123 23:07:23.978648 29630 solver.cpp:237] Iteration 48920, loss = 3.39254
I0123 23:07:23.978688 29630 solver.cpp:253]     Train net output #0: loss = 3.39254 (* 1 = 3.39254 loss)
I0123 23:07:23.978695 29630 sgd_solver.cpp:106] Iteration 48920, lr = 0.01
I0123 23:07:31.227094 29630 solver.cpp:237] Iteration 48940, loss = 3.45053
I0123 23:07:31.227135 29630 solver.cpp:253]     Train net output #0: loss = 3.45053 (* 1 = 3.45053 loss)
I0123 23:07:31.227143 29630 sgd_solver.cpp:106] Iteration 48940, lr = 0.01
I0123 23:07:38.480372 29630 solver.cpp:237] Iteration 48960, loss = 3.69295
I0123 23:07:38.480411 29630 solver.cpp:253]     Train net output #0: loss = 3.69295 (* 1 = 3.69295 loss)
I0123 23:07:38.480417 29630 sgd_solver.cpp:106] Iteration 48960, lr = 0.01
I0123 23:07:45.718690 29630 solver.cpp:237] Iteration 48980, loss = 3.50034
I0123 23:07:45.718866 29630 solver.cpp:253]     Train net output #0: loss = 3.50034 (* 1 = 3.50034 loss)
I0123 23:07:45.718874 29630 sgd_solver.cpp:106] Iteration 48980, lr = 0.01
I0123 23:07:52.722110 29630 solver.cpp:341] Iteration 49000, Testing net (#0)
I0123 23:08:14.199010 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 23:09:06.564679 29630 solver.cpp:409]     Test net output #0: accuracy = 0.30746
I0123 23:09:06.564839 29630 solver.cpp:409]     Test net output #1: loss = 3.29222 (* 1 = 3.29222 loss)
I0123 23:09:06.605650 29630 solver.cpp:237] Iteration 49000, loss = 3.59344
I0123 23:09:06.605687 29630 solver.cpp:253]     Train net output #0: loss = 3.59344 (* 1 = 3.59344 loss)
I0123 23:09:06.605695 29630 sgd_solver.cpp:106] Iteration 49000, lr = 0.01
I0123 23:09:13.194072 29630 solver.cpp:237] Iteration 49020, loss = 3.3667
I0123 23:09:13.194110 29630 solver.cpp:253]     Train net output #0: loss = 3.3667 (* 1 = 3.3667 loss)
I0123 23:09:13.194116 29630 sgd_solver.cpp:106] Iteration 49020, lr = 0.01
I0123 23:09:20.484107 29630 solver.cpp:237] Iteration 49040, loss = 3.33747
I0123 23:09:20.484145 29630 solver.cpp:253]     Train net output #0: loss = 3.33747 (* 1 = 3.33747 loss)
I0123 23:09:20.484150 29630 sgd_solver.cpp:106] Iteration 49040, lr = 0.01
I0123 23:09:27.785995 29630 solver.cpp:237] Iteration 49060, loss = 3.35336
I0123 23:09:27.786032 29630 solver.cpp:253]     Train net output #0: loss = 3.35336 (* 1 = 3.35336 loss)
I0123 23:09:27.786038 29630 sgd_solver.cpp:106] Iteration 49060, lr = 0.01
I0123 23:09:35.061576 29630 solver.cpp:237] Iteration 49080, loss = 3.23314
I0123 23:09:35.061614 29630 solver.cpp:253]     Train net output #0: loss = 3.23314 (* 1 = 3.23314 loss)
I0123 23:09:35.061620 29630 sgd_solver.cpp:106] Iteration 49080, lr = 0.01
I0123 23:09:42.316416 29630 solver.cpp:237] Iteration 49100, loss = 3.4617
I0123 23:09:42.316546 29630 solver.cpp:253]     Train net output #0: loss = 3.4617 (* 1 = 3.4617 loss)
I0123 23:09:42.316553 29630 sgd_solver.cpp:106] Iteration 49100, lr = 0.01
I0123 23:09:49.565794 29630 solver.cpp:237] Iteration 49120, loss = 3.53659
I0123 23:09:49.565824 29630 solver.cpp:253]     Train net output #0: loss = 3.53659 (* 1 = 3.53659 loss)
I0123 23:09:49.565830 29630 sgd_solver.cpp:106] Iteration 49120, lr = 0.01
I0123 23:09:56.853049 29630 solver.cpp:237] Iteration 49140, loss = 3.18702
I0123 23:09:56.853086 29630 solver.cpp:253]     Train net output #0: loss = 3.18702 (* 1 = 3.18702 loss)
I0123 23:09:56.853092 29630 sgd_solver.cpp:106] Iteration 49140, lr = 0.01
I0123 23:10:04.125295 29630 solver.cpp:237] Iteration 49160, loss = 3.715
I0123 23:10:04.125334 29630 solver.cpp:253]     Train net output #0: loss = 3.715 (* 1 = 3.715 loss)
I0123 23:10:04.125340 29630 sgd_solver.cpp:106] Iteration 49160, lr = 0.01
I0123 23:10:11.337766 29630 solver.cpp:237] Iteration 49180, loss = 3.52718
I0123 23:10:11.337805 29630 solver.cpp:253]     Train net output #0: loss = 3.52718 (* 1 = 3.52718 loss)
I0123 23:10:11.337812 29630 sgd_solver.cpp:106] Iteration 49180, lr = 0.01
I0123 23:10:18.574937 29630 solver.cpp:237] Iteration 49200, loss = 3.29601
I0123 23:10:18.575114 29630 solver.cpp:253]     Train net output #0: loss = 3.29601 (* 1 = 3.29601 loss)
I0123 23:10:18.575121 29630 sgd_solver.cpp:106] Iteration 49200, lr = 0.01
I0123 23:10:25.840579 29630 solver.cpp:237] Iteration 49220, loss = 3.34237
I0123 23:10:25.840617 29630 solver.cpp:253]     Train net output #0: loss = 3.34237 (* 1 = 3.34237 loss)
I0123 23:10:25.840622 29630 sgd_solver.cpp:106] Iteration 49220, lr = 0.01
I0123 23:10:33.091997 29630 solver.cpp:237] Iteration 49240, loss = 3.50201
I0123 23:10:33.092036 29630 solver.cpp:253]     Train net output #0: loss = 3.50201 (* 1 = 3.50201 loss)
I0123 23:10:33.092041 29630 sgd_solver.cpp:106] Iteration 49240, lr = 0.01
I0123 23:10:40.297539 29630 solver.cpp:237] Iteration 49260, loss = 3.32853
I0123 23:10:40.297580 29630 solver.cpp:253]     Train net output #0: loss = 3.32853 (* 1 = 3.32853 loss)
I0123 23:10:40.297586 29630 sgd_solver.cpp:106] Iteration 49260, lr = 0.01
I0123 23:10:47.566879 29630 solver.cpp:237] Iteration 49280, loss = 3.43196
I0123 23:10:47.566917 29630 solver.cpp:253]     Train net output #0: loss = 3.43196 (* 1 = 3.43196 loss)
I0123 23:10:47.566923 29630 sgd_solver.cpp:106] Iteration 49280, lr = 0.01
I0123 23:10:53.116751 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 23:10:54.873095 29630 solver.cpp:237] Iteration 49300, loss = 3.26904
I0123 23:10:54.873133 29630 solver.cpp:253]     Train net output #0: loss = 3.26904 (* 1 = 3.26904 loss)
I0123 23:10:54.873139 29630 sgd_solver.cpp:106] Iteration 49300, lr = 0.01
I0123 23:11:02.096681 29630 solver.cpp:237] Iteration 49320, loss = 3.48635
I0123 23:11:02.096719 29630 solver.cpp:253]     Train net output #0: loss = 3.48635 (* 1 = 3.48635 loss)
I0123 23:11:02.096725 29630 sgd_solver.cpp:106] Iteration 49320, lr = 0.01
I0123 23:11:09.336799 29630 solver.cpp:237] Iteration 49340, loss = 3.4057
I0123 23:11:09.336839 29630 solver.cpp:253]     Train net output #0: loss = 3.4057 (* 1 = 3.4057 loss)
I0123 23:11:09.336845 29630 sgd_solver.cpp:106] Iteration 49340, lr = 0.01
I0123 23:11:16.605857 29630 solver.cpp:237] Iteration 49360, loss = 3.65305
I0123 23:11:16.605896 29630 solver.cpp:253]     Train net output #0: loss = 3.65305 (* 1 = 3.65305 loss)
I0123 23:11:16.605902 29630 sgd_solver.cpp:106] Iteration 49360, lr = 0.01
I0123 23:11:23.816258 29630 solver.cpp:237] Iteration 49380, loss = 3.21516
I0123 23:11:23.816392 29630 solver.cpp:253]     Train net output #0: loss = 3.21516 (* 1 = 3.21516 loss)
I0123 23:11:23.816408 29630 sgd_solver.cpp:106] Iteration 49380, lr = 0.01
I0123 23:11:31.074473 29630 solver.cpp:237] Iteration 49400, loss = 3.40365
I0123 23:11:31.074512 29630 solver.cpp:253]     Train net output #0: loss = 3.40365 (* 1 = 3.40365 loss)
I0123 23:11:31.074517 29630 sgd_solver.cpp:106] Iteration 49400, lr = 0.01
I0123 23:11:38.287181 29630 solver.cpp:237] Iteration 49420, loss = 3.52073
I0123 23:11:38.287220 29630 solver.cpp:253]     Train net output #0: loss = 3.52073 (* 1 = 3.52073 loss)
I0123 23:11:38.287226 29630 sgd_solver.cpp:106] Iteration 49420, lr = 0.01
I0123 23:11:45.578877 29630 solver.cpp:237] Iteration 49440, loss = 3.43437
I0123 23:11:45.578905 29630 solver.cpp:253]     Train net output #0: loss = 3.43437 (* 1 = 3.43437 loss)
I0123 23:11:45.578912 29630 sgd_solver.cpp:106] Iteration 49440, lr = 0.01
I0123 23:11:52.842067 29630 solver.cpp:237] Iteration 49460, loss = 3.55721
I0123 23:11:52.842108 29630 solver.cpp:253]     Train net output #0: loss = 3.55721 (* 1 = 3.55721 loss)
I0123 23:11:52.842115 29630 sgd_solver.cpp:106] Iteration 49460, lr = 0.01
I0123 23:12:00.117285 29630 solver.cpp:237] Iteration 49480, loss = 3.19534
I0123 23:12:00.117408 29630 solver.cpp:253]     Train net output #0: loss = 3.19534 (* 1 = 3.19534 loss)
I0123 23:12:00.117415 29630 sgd_solver.cpp:106] Iteration 49480, lr = 0.01
I0123 23:12:07.350491 29630 solver.cpp:237] Iteration 49500, loss = 3.58187
I0123 23:12:07.350528 29630 solver.cpp:253]     Train net output #0: loss = 3.58187 (* 1 = 3.58187 loss)
I0123 23:12:07.350534 29630 sgd_solver.cpp:106] Iteration 49500, lr = 0.01
I0123 23:12:14.632760 29630 solver.cpp:237] Iteration 49520, loss = 3.50808
I0123 23:12:14.632798 29630 solver.cpp:253]     Train net output #0: loss = 3.50808 (* 1 = 3.50808 loss)
I0123 23:12:14.632804 29630 sgd_solver.cpp:106] Iteration 49520, lr = 0.01
I0123 23:12:21.913429 29630 solver.cpp:237] Iteration 49540, loss = 3.56369
I0123 23:12:21.913467 29630 solver.cpp:253]     Train net output #0: loss = 3.56369 (* 1 = 3.56369 loss)
I0123 23:12:21.913473 29630 sgd_solver.cpp:106] Iteration 49540, lr = 0.01
I0123 23:12:29.187502 29630 solver.cpp:237] Iteration 49560, loss = 3.54557
I0123 23:12:29.187541 29630 solver.cpp:253]     Train net output #0: loss = 3.54557 (* 1 = 3.54557 loss)
I0123 23:12:29.187546 29630 sgd_solver.cpp:106] Iteration 49560, lr = 0.01
I0123 23:12:36.438156 29630 solver.cpp:237] Iteration 49580, loss = 3.34381
I0123 23:12:36.438339 29630 solver.cpp:253]     Train net output #0: loss = 3.34381 (* 1 = 3.34381 loss)
I0123 23:12:36.438349 29630 sgd_solver.cpp:106] Iteration 49580, lr = 0.01
I0123 23:12:43.702492 29630 solver.cpp:237] Iteration 49600, loss = 3.58167
I0123 23:12:43.702532 29630 solver.cpp:253]     Train net output #0: loss = 3.58167 (* 1 = 3.58167 loss)
I0123 23:12:43.702538 29630 sgd_solver.cpp:106] Iteration 49600, lr = 0.01
I0123 23:12:50.943378 29630 solver.cpp:237] Iteration 49620, loss = 3.23645
I0123 23:12:50.943418 29630 solver.cpp:253]     Train net output #0: loss = 3.23645 (* 1 = 3.23645 loss)
I0123 23:12:50.943423 29630 sgd_solver.cpp:106] Iteration 49620, lr = 0.01
I0123 23:12:58.205157 29630 solver.cpp:237] Iteration 49640, loss = 3.59682
I0123 23:12:58.205195 29630 solver.cpp:253]     Train net output #0: loss = 3.59682 (* 1 = 3.59682 loss)
I0123 23:12:58.205202 29630 sgd_solver.cpp:106] Iteration 49640, lr = 0.01
I0123 23:13:05.447464 29630 solver.cpp:237] Iteration 49660, loss = 3.26579
I0123 23:13:05.447504 29630 solver.cpp:253]     Train net output #0: loss = 3.26579 (* 1 = 3.26579 loss)
I0123 23:13:05.447510 29630 sgd_solver.cpp:106] Iteration 49660, lr = 0.01
I0123 23:13:12.736662 29630 solver.cpp:237] Iteration 49680, loss = 3.6062
I0123 23:13:12.736815 29630 solver.cpp:253]     Train net output #0: loss = 3.6062 (* 1 = 3.6062 loss)
I0123 23:13:12.736824 29630 sgd_solver.cpp:106] Iteration 49680, lr = 0.01
I0123 23:13:20.015239 29630 solver.cpp:237] Iteration 49700, loss = 3.22568
I0123 23:13:20.015277 29630 solver.cpp:253]     Train net output #0: loss = 3.22568 (* 1 = 3.22568 loss)
I0123 23:13:20.015283 29630 sgd_solver.cpp:106] Iteration 49700, lr = 0.01
I0123 23:13:27.279213 29630 solver.cpp:237] Iteration 49720, loss = 3.5131
I0123 23:13:27.279253 29630 solver.cpp:253]     Train net output #0: loss = 3.5131 (* 1 = 3.5131 loss)
I0123 23:13:27.279258 29630 sgd_solver.cpp:106] Iteration 49720, lr = 0.01
I0123 23:13:34.551147 29630 solver.cpp:237] Iteration 49740, loss = 3.63481
I0123 23:13:34.551185 29630 solver.cpp:253]     Train net output #0: loss = 3.63481 (* 1 = 3.63481 loss)
I0123 23:13:34.551192 29630 sgd_solver.cpp:106] Iteration 49740, lr = 0.01
I0123 23:13:41.813040 29630 solver.cpp:237] Iteration 49760, loss = 3.54337
I0123 23:13:41.813078 29630 solver.cpp:253]     Train net output #0: loss = 3.54337 (* 1 = 3.54337 loss)
I0123 23:13:41.813084 29630 sgd_solver.cpp:106] Iteration 49760, lr = 0.01
I0123 23:13:49.069654 29630 solver.cpp:237] Iteration 49780, loss = 3.5332
I0123 23:13:49.069778 29630 solver.cpp:253]     Train net output #0: loss = 3.5332 (* 1 = 3.5332 loss)
I0123 23:13:49.069787 29630 sgd_solver.cpp:106] Iteration 49780, lr = 0.01
I0123 23:13:56.356221 29630 solver.cpp:237] Iteration 49800, loss = 3.32121
I0123 23:13:56.356261 29630 solver.cpp:253]     Train net output #0: loss = 3.32121 (* 1 = 3.32121 loss)
I0123 23:13:56.356267 29630 sgd_solver.cpp:106] Iteration 49800, lr = 0.01
I0123 23:14:03.592737 29630 solver.cpp:237] Iteration 49820, loss = 3.48338
I0123 23:14:03.592777 29630 solver.cpp:253]     Train net output #0: loss = 3.48338 (* 1 = 3.48338 loss)
I0123 23:14:03.592782 29630 sgd_solver.cpp:106] Iteration 49820, lr = 0.01
I0123 23:14:10.856632 29630 solver.cpp:237] Iteration 49840, loss = 3.48756
I0123 23:14:10.856672 29630 solver.cpp:253]     Train net output #0: loss = 3.48756 (* 1 = 3.48756 loss)
I0123 23:14:10.856678 29630 sgd_solver.cpp:106] Iteration 49840, lr = 0.01
I0123 23:14:18.081931 29630 solver.cpp:237] Iteration 49860, loss = 3.46049
I0123 23:14:18.081969 29630 solver.cpp:253]     Train net output #0: loss = 3.46049 (* 1 = 3.46049 loss)
I0123 23:14:18.081975 29630 sgd_solver.cpp:106] Iteration 49860, lr = 0.01
I0123 23:14:25.314461 29630 solver.cpp:237] Iteration 49880, loss = 3.49921
I0123 23:14:25.314615 29630 solver.cpp:253]     Train net output #0: loss = 3.49921 (* 1 = 3.49921 loss)
I0123 23:14:25.314622 29630 sgd_solver.cpp:106] Iteration 49880, lr = 0.01
I0123 23:14:32.590442 29630 solver.cpp:237] Iteration 49900, loss = 3.43353
I0123 23:14:32.590481 29630 solver.cpp:253]     Train net output #0: loss = 3.43353 (* 1 = 3.43353 loss)
I0123 23:14:32.590487 29630 sgd_solver.cpp:106] Iteration 49900, lr = 0.01
I0123 23:14:39.829641 29630 solver.cpp:237] Iteration 49920, loss = 3.53733
I0123 23:14:39.829680 29630 solver.cpp:253]     Train net output #0: loss = 3.53733 (* 1 = 3.53733 loss)
I0123 23:14:39.829686 29630 sgd_solver.cpp:106] Iteration 49920, lr = 0.01
I0123 23:14:47.047531 29630 solver.cpp:237] Iteration 49940, loss = 3.36173
I0123 23:14:47.047570 29630 solver.cpp:253]     Train net output #0: loss = 3.36173 (* 1 = 3.36173 loss)
I0123 23:14:47.047576 29630 sgd_solver.cpp:106] Iteration 49940, lr = 0.01
I0123 23:14:54.269421 29630 solver.cpp:237] Iteration 49960, loss = 3.40036
I0123 23:14:54.269461 29630 solver.cpp:253]     Train net output #0: loss = 3.40036 (* 1 = 3.40036 loss)
I0123 23:14:54.269467 29630 sgd_solver.cpp:106] Iteration 49960, lr = 0.01
I0123 23:15:01.489152 29630 solver.cpp:237] Iteration 49980, loss = 3.57504
I0123 23:15:01.489297 29630 solver.cpp:253]     Train net output #0: loss = 3.57504 (* 1 = 3.57504 loss)
I0123 23:15:01.489305 29630 sgd_solver.cpp:106] Iteration 49980, lr = 0.01
I0123 23:15:08.396049 29630 solver.cpp:459] Snapshotting to binary proto file snapshots/caffenet128_lsuv_ycrcb_iter_50000.caffemodel
I0123 23:15:08.578758 29630 sgd_solver.cpp:269] Snapshotting solver state to binary proto file snapshots/caffenet128_lsuv_ycrcb_iter_50000.solverstate
I0123 23:15:08.633571 29630 solver.cpp:341] Iteration 50000, Testing net (#0)
I0123 23:15:30.632483 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 23:16:22.509330 29630 solver.cpp:409]     Test net output #0: accuracy = 0.31128
I0123 23:16:22.509495 29630 solver.cpp:409]     Test net output #1: loss = 3.2704 (* 1 = 3.2704 loss)
I0123 23:16:22.550232 29630 solver.cpp:237] Iteration 50000, loss = 3.37395
I0123 23:16:22.550261 29630 solver.cpp:253]     Train net output #0: loss = 3.37395 (* 1 = 3.37395 loss)
I0123 23:16:22.550268 29630 sgd_solver.cpp:106] Iteration 50000, lr = 0.01
I0123 23:16:29.091311 29630 solver.cpp:237] Iteration 50020, loss = 3.53394
I0123 23:16:29.091351 29630 solver.cpp:253]     Train net output #0: loss = 3.53394 (* 1 = 3.53394 loss)
I0123 23:16:29.091356 29630 sgd_solver.cpp:106] Iteration 50020, lr = 0.01
I0123 23:16:36.352632 29630 solver.cpp:237] Iteration 50040, loss = 3.60505
I0123 23:16:36.352670 29630 solver.cpp:253]     Train net output #0: loss = 3.60505 (* 1 = 3.60505 loss)
I0123 23:16:36.352677 29630 sgd_solver.cpp:106] Iteration 50040, lr = 0.01
I0123 23:16:43.543956 29630 solver.cpp:237] Iteration 50060, loss = 3.4203
I0123 23:16:43.543995 29630 solver.cpp:253]     Train net output #0: loss = 3.4203 (* 1 = 3.4203 loss)
I0123 23:16:43.544001 29630 sgd_solver.cpp:106] Iteration 50060, lr = 0.01
I0123 23:16:50.767232 29630 solver.cpp:237] Iteration 50080, loss = 3.58962
I0123 23:16:50.767271 29630 solver.cpp:253]     Train net output #0: loss = 3.58962 (* 1 = 3.58962 loss)
I0123 23:16:50.767277 29630 sgd_solver.cpp:106] Iteration 50080, lr = 0.01
I0123 23:16:57.980779 29630 solver.cpp:237] Iteration 50100, loss = 3.48411
I0123 23:16:57.980931 29630 solver.cpp:253]     Train net output #0: loss = 3.48411 (* 1 = 3.48411 loss)
I0123 23:16:57.980948 29630 sgd_solver.cpp:106] Iteration 50100, lr = 0.01
I0123 23:17:05.230584 29630 solver.cpp:237] Iteration 50120, loss = 3.46467
I0123 23:17:05.230623 29630 solver.cpp:253]     Train net output #0: loss = 3.46467 (* 1 = 3.46467 loss)
I0123 23:17:05.230629 29630 sgd_solver.cpp:106] Iteration 50120, lr = 0.01
I0123 23:17:12.437988 29630 solver.cpp:237] Iteration 50140, loss = 3.35215
I0123 23:17:12.438025 29630 solver.cpp:253]     Train net output #0: loss = 3.35215 (* 1 = 3.35215 loss)
I0123 23:17:12.438031 29630 sgd_solver.cpp:106] Iteration 50140, lr = 0.01
I0123 23:17:19.650406 29630 solver.cpp:237] Iteration 50160, loss = 3.4584
I0123 23:17:19.650446 29630 solver.cpp:253]     Train net output #0: loss = 3.4584 (* 1 = 3.4584 loss)
I0123 23:17:19.650452 29630 sgd_solver.cpp:106] Iteration 50160, lr = 0.01
I0123 23:17:26.912292 29630 solver.cpp:237] Iteration 50180, loss = 3.25735
I0123 23:17:26.912330 29630 solver.cpp:253]     Train net output #0: loss = 3.25735 (* 1 = 3.25735 loss)
I0123 23:17:26.912338 29630 sgd_solver.cpp:106] Iteration 50180, lr = 0.01
I0123 23:17:34.119575 29630 solver.cpp:237] Iteration 50200, loss = 3.49613
I0123 23:17:34.119683 29630 solver.cpp:253]     Train net output #0: loss = 3.49613 (* 1 = 3.49613 loss)
I0123 23:17:34.119700 29630 sgd_solver.cpp:106] Iteration 50200, lr = 0.01
I0123 23:17:41.348811 29630 solver.cpp:237] Iteration 50220, loss = 3.57472
I0123 23:17:41.348850 29630 solver.cpp:253]     Train net output #0: loss = 3.57472 (* 1 = 3.57472 loss)
I0123 23:17:41.348855 29630 sgd_solver.cpp:106] Iteration 50220, lr = 0.01
I0123 23:17:48.620009 29630 solver.cpp:237] Iteration 50240, loss = 3.26051
I0123 23:17:48.620049 29630 solver.cpp:253]     Train net output #0: loss = 3.26051 (* 1 = 3.26051 loss)
I0123 23:17:48.620055 29630 sgd_solver.cpp:106] Iteration 50240, lr = 0.01
I0123 23:17:55.912562 29630 solver.cpp:237] Iteration 50260, loss = 3.48494
I0123 23:17:55.912600 29630 solver.cpp:253]     Train net output #0: loss = 3.48494 (* 1 = 3.48494 loss)
I0123 23:17:55.912606 29630 sgd_solver.cpp:106] Iteration 50260, lr = 0.01
I0123 23:18:03.187533 29630 solver.cpp:237] Iteration 50280, loss = 3.59279
I0123 23:18:03.187571 29630 solver.cpp:253]     Train net output #0: loss = 3.59279 (* 1 = 3.59279 loss)
I0123 23:18:03.187577 29630 sgd_solver.cpp:106] Iteration 50280, lr = 0.01
I0123 23:18:10.446710 29630 solver.cpp:237] Iteration 50300, loss = 3.25882
I0123 23:18:10.446836 29630 solver.cpp:253]     Train net output #0: loss = 3.25882 (* 1 = 3.25882 loss)
I0123 23:18:10.446853 29630 sgd_solver.cpp:106] Iteration 50300, lr = 0.01
I0123 23:18:10.876482 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 23:18:17.643000 29630 solver.cpp:237] Iteration 50320, loss = 3.27339
I0123 23:18:17.643041 29630 solver.cpp:253]     Train net output #0: loss = 3.27339 (* 1 = 3.27339 loss)
I0123 23:18:17.643048 29630 sgd_solver.cpp:106] Iteration 50320, lr = 0.01
I0123 23:18:24.963165 29630 solver.cpp:237] Iteration 50340, loss = 3.31265
I0123 23:18:24.963202 29630 solver.cpp:253]     Train net output #0: loss = 3.31265 (* 1 = 3.31265 loss)
I0123 23:18:24.963209 29630 sgd_solver.cpp:106] Iteration 50340, lr = 0.01
I0123 23:18:32.207486 29630 solver.cpp:237] Iteration 50360, loss = 3.45313
I0123 23:18:32.207526 29630 solver.cpp:253]     Train net output #0: loss = 3.45313 (* 1 = 3.45313 loss)
I0123 23:18:32.207532 29630 sgd_solver.cpp:106] Iteration 50360, lr = 0.01
I0123 23:18:39.455390 29630 solver.cpp:237] Iteration 50380, loss = 3.67275
I0123 23:18:39.455430 29630 solver.cpp:253]     Train net output #0: loss = 3.67275 (* 1 = 3.67275 loss)
I0123 23:18:39.455437 29630 sgd_solver.cpp:106] Iteration 50380, lr = 0.01
I0123 23:18:46.689764 29630 solver.cpp:237] Iteration 50400, loss = 3.34917
I0123 23:18:46.689934 29630 solver.cpp:253]     Train net output #0: loss = 3.34917 (* 1 = 3.34917 loss)
I0123 23:18:46.689941 29630 sgd_solver.cpp:106] Iteration 50400, lr = 0.01
I0123 23:18:53.952730 29630 solver.cpp:237] Iteration 50420, loss = 3.53961
I0123 23:18:53.952769 29630 solver.cpp:253]     Train net output #0: loss = 3.53961 (* 1 = 3.53961 loss)
I0123 23:18:53.952775 29630 sgd_solver.cpp:106] Iteration 50420, lr = 0.01
I0123 23:19:01.169229 29630 solver.cpp:237] Iteration 50440, loss = 3.51301
I0123 23:19:01.169268 29630 solver.cpp:253]     Train net output #0: loss = 3.51301 (* 1 = 3.51301 loss)
I0123 23:19:01.169275 29630 sgd_solver.cpp:106] Iteration 50440, lr = 0.01
I0123 23:19:08.389863 29630 solver.cpp:237] Iteration 50460, loss = 3.38053
I0123 23:19:08.389901 29630 solver.cpp:253]     Train net output #0: loss = 3.38053 (* 1 = 3.38053 loss)
I0123 23:19:08.389909 29630 sgd_solver.cpp:106] Iteration 50460, lr = 0.01
I0123 23:19:15.691143 29630 solver.cpp:237] Iteration 50480, loss = 3.6211
I0123 23:19:15.691181 29630 solver.cpp:253]     Train net output #0: loss = 3.6211 (* 1 = 3.6211 loss)
I0123 23:19:15.691189 29630 sgd_solver.cpp:106] Iteration 50480, lr = 0.01
I0123 23:19:22.964648 29630 solver.cpp:237] Iteration 50500, loss = 3.22269
I0123 23:19:22.964789 29630 solver.cpp:253]     Train net output #0: loss = 3.22269 (* 1 = 3.22269 loss)
I0123 23:19:22.964797 29630 sgd_solver.cpp:106] Iteration 50500, lr = 0.01
I0123 23:19:30.211704 29630 solver.cpp:237] Iteration 50520, loss = 3.50699
I0123 23:19:30.211742 29630 solver.cpp:253]     Train net output #0: loss = 3.50699 (* 1 = 3.50699 loss)
I0123 23:19:30.211748 29630 sgd_solver.cpp:106] Iteration 50520, lr = 0.01
I0123 23:19:37.440219 29630 solver.cpp:237] Iteration 50540, loss = 3.69418
I0123 23:19:37.440258 29630 solver.cpp:253]     Train net output #0: loss = 3.69418 (* 1 = 3.69418 loss)
I0123 23:19:37.440264 29630 sgd_solver.cpp:106] Iteration 50540, lr = 0.01
I0123 23:19:44.702505 29630 solver.cpp:237] Iteration 50560, loss = 3.16102
I0123 23:19:44.702543 29630 solver.cpp:253]     Train net output #0: loss = 3.16102 (* 1 = 3.16102 loss)
I0123 23:19:44.702549 29630 sgd_solver.cpp:106] Iteration 50560, lr = 0.01
I0123 23:19:51.939455 29630 solver.cpp:237] Iteration 50580, loss = 3.27987
I0123 23:19:51.939493 29630 solver.cpp:253]     Train net output #0: loss = 3.27987 (* 1 = 3.27987 loss)
I0123 23:19:51.939499 29630 sgd_solver.cpp:106] Iteration 50580, lr = 0.01
I0123 23:19:59.229666 29630 solver.cpp:237] Iteration 50600, loss = 3.28805
I0123 23:19:59.229789 29630 solver.cpp:253]     Train net output #0: loss = 3.28805 (* 1 = 3.28805 loss)
I0123 23:19:59.229795 29630 sgd_solver.cpp:106] Iteration 50600, lr = 0.01
I0123 23:20:06.498966 29630 solver.cpp:237] Iteration 50620, loss = 3.34859
I0123 23:20:06.499004 29630 solver.cpp:253]     Train net output #0: loss = 3.34859 (* 1 = 3.34859 loss)
I0123 23:20:06.499011 29630 sgd_solver.cpp:106] Iteration 50620, lr = 0.01
I0123 23:20:13.733760 29630 solver.cpp:237] Iteration 50640, loss = 3.32168
I0123 23:20:13.733800 29630 solver.cpp:253]     Train net output #0: loss = 3.32168 (* 1 = 3.32168 loss)
I0123 23:20:13.733808 29630 sgd_solver.cpp:106] Iteration 50640, lr = 0.01
I0123 23:20:21.003011 29630 solver.cpp:237] Iteration 50660, loss = 3.26626
I0123 23:20:21.003047 29630 solver.cpp:253]     Train net output #0: loss = 3.26626 (* 1 = 3.26626 loss)
I0123 23:20:21.003053 29630 sgd_solver.cpp:106] Iteration 50660, lr = 0.01
I0123 23:20:28.229905 29630 solver.cpp:237] Iteration 50680, loss = 3.54276
I0123 23:20:28.229944 29630 solver.cpp:253]     Train net output #0: loss = 3.54276 (* 1 = 3.54276 loss)
I0123 23:20:28.229950 29630 sgd_solver.cpp:106] Iteration 50680, lr = 0.01
I0123 23:20:35.432183 29630 solver.cpp:237] Iteration 50700, loss = 3.11854
I0123 23:20:35.432312 29630 solver.cpp:253]     Train net output #0: loss = 3.11854 (* 1 = 3.11854 loss)
I0123 23:20:35.432319 29630 sgd_solver.cpp:106] Iteration 50700, lr = 0.01
I0123 23:20:42.697469 29630 solver.cpp:237] Iteration 50720, loss = 3.16832
I0123 23:20:42.697510 29630 solver.cpp:253]     Train net output #0: loss = 3.16832 (* 1 = 3.16832 loss)
I0123 23:20:42.697516 29630 sgd_solver.cpp:106] Iteration 50720, lr = 0.01
I0123 23:20:49.903229 29630 solver.cpp:237] Iteration 50740, loss = 3.48129
I0123 23:20:49.903269 29630 solver.cpp:253]     Train net output #0: loss = 3.48129 (* 1 = 3.48129 loss)
I0123 23:20:49.903275 29630 sgd_solver.cpp:106] Iteration 50740, lr = 0.01
I0123 23:20:57.177667 29630 solver.cpp:237] Iteration 50760, loss = 3.81131
I0123 23:20:57.177705 29630 solver.cpp:253]     Train net output #0: loss = 3.81131 (* 1 = 3.81131 loss)
I0123 23:20:57.177711 29630 sgd_solver.cpp:106] Iteration 50760, lr = 0.01
I0123 23:21:04.435638 29630 solver.cpp:237] Iteration 50780, loss = 3.39642
I0123 23:21:04.435678 29630 solver.cpp:253]     Train net output #0: loss = 3.39642 (* 1 = 3.39642 loss)
I0123 23:21:04.435684 29630 sgd_solver.cpp:106] Iteration 50780, lr = 0.01
I0123 23:21:11.722838 29630 solver.cpp:237] Iteration 50800, loss = 3.2142
I0123 23:21:11.722928 29630 solver.cpp:253]     Train net output #0: loss = 3.2142 (* 1 = 3.2142 loss)
I0123 23:21:11.722934 29630 sgd_solver.cpp:106] Iteration 50800, lr = 0.01
I0123 23:21:18.976407 29630 solver.cpp:237] Iteration 50820, loss = 3.40371
I0123 23:21:18.976445 29630 solver.cpp:253]     Train net output #0: loss = 3.40371 (* 1 = 3.40371 loss)
I0123 23:21:18.976451 29630 sgd_solver.cpp:106] Iteration 50820, lr = 0.01
I0123 23:21:26.185546 29630 solver.cpp:237] Iteration 50840, loss = 3.23969
I0123 23:21:26.185590 29630 solver.cpp:253]     Train net output #0: loss = 3.23969 (* 1 = 3.23969 loss)
I0123 23:21:26.185609 29630 sgd_solver.cpp:106] Iteration 50840, lr = 0.01
I0123 23:21:33.474145 29630 solver.cpp:237] Iteration 50860, loss = 3.35186
I0123 23:21:33.474184 29630 solver.cpp:253]     Train net output #0: loss = 3.35186 (* 1 = 3.35186 loss)
I0123 23:21:33.474190 29630 sgd_solver.cpp:106] Iteration 50860, lr = 0.01
I0123 23:21:40.778767 29630 solver.cpp:237] Iteration 50880, loss = 3.61571
I0123 23:21:40.778805 29630 solver.cpp:253]     Train net output #0: loss = 3.61571 (* 1 = 3.61571 loss)
I0123 23:21:40.778811 29630 sgd_solver.cpp:106] Iteration 50880, lr = 0.01
I0123 23:21:48.054271 29630 solver.cpp:237] Iteration 50900, loss = 3.45434
I0123 23:21:48.054417 29630 solver.cpp:253]     Train net output #0: loss = 3.45434 (* 1 = 3.45434 loss)
I0123 23:21:48.054425 29630 sgd_solver.cpp:106] Iteration 50900, lr = 0.01
I0123 23:21:55.313500 29630 solver.cpp:237] Iteration 50920, loss = 3.27068
I0123 23:21:55.313540 29630 solver.cpp:253]     Train net output #0: loss = 3.27068 (* 1 = 3.27068 loss)
I0123 23:21:55.313546 29630 sgd_solver.cpp:106] Iteration 50920, lr = 0.01
I0123 23:22:02.589825 29630 solver.cpp:237] Iteration 50940, loss = 3.52771
I0123 23:22:02.589864 29630 solver.cpp:253]     Train net output #0: loss = 3.52771 (* 1 = 3.52771 loss)
I0123 23:22:02.589870 29630 sgd_solver.cpp:106] Iteration 50940, lr = 0.01
I0123 23:22:09.804656 29630 solver.cpp:237] Iteration 50960, loss = 3.32032
I0123 23:22:09.804693 29630 solver.cpp:253]     Train net output #0: loss = 3.32032 (* 1 = 3.32032 loss)
I0123 23:22:09.804699 29630 sgd_solver.cpp:106] Iteration 50960, lr = 0.01
I0123 23:22:17.023525 29630 solver.cpp:237] Iteration 50980, loss = 3.31273
I0123 23:22:17.023566 29630 solver.cpp:253]     Train net output #0: loss = 3.31273 (* 1 = 3.31273 loss)
I0123 23:22:17.023571 29630 sgd_solver.cpp:106] Iteration 50980, lr = 0.01
I0123 23:22:23.980003 29630 solver.cpp:341] Iteration 51000, Testing net (#0)
I0123 23:22:46.304955 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 23:23:37.834210 29630 solver.cpp:409]     Test net output #0: accuracy = 0.31388
I0123 23:23:37.834306 29630 solver.cpp:409]     Test net output #1: loss = 3.25878 (* 1 = 3.25878 loss)
I0123 23:23:37.874899 29630 solver.cpp:237] Iteration 51000, loss = 3.40703
I0123 23:23:37.874927 29630 solver.cpp:253]     Train net output #0: loss = 3.40703 (* 1 = 3.40703 loss)
I0123 23:23:37.874934 29630 sgd_solver.cpp:106] Iteration 51000, lr = 0.01
I0123 23:23:44.368242 29630 solver.cpp:237] Iteration 51020, loss = 3.56992
I0123 23:23:44.368281 29630 solver.cpp:253]     Train net output #0: loss = 3.56992 (* 1 = 3.56992 loss)
I0123 23:23:44.368288 29630 sgd_solver.cpp:106] Iteration 51020, lr = 0.01
I0123 23:23:51.616920 29630 solver.cpp:237] Iteration 51040, loss = 3.27227
I0123 23:23:51.616958 29630 solver.cpp:253]     Train net output #0: loss = 3.27227 (* 1 = 3.27227 loss)
I0123 23:23:51.616964 29630 sgd_solver.cpp:106] Iteration 51040, lr = 0.01
I0123 23:23:58.885474 29630 solver.cpp:237] Iteration 51060, loss = 3.46759
I0123 23:23:58.885514 29630 solver.cpp:253]     Train net output #0: loss = 3.46759 (* 1 = 3.46759 loss)
I0123 23:23:58.885520 29630 sgd_solver.cpp:106] Iteration 51060, lr = 0.01
I0123 23:24:06.080117 29630 solver.cpp:237] Iteration 51080, loss = 3.36336
I0123 23:24:06.080155 29630 solver.cpp:253]     Train net output #0: loss = 3.36336 (* 1 = 3.36336 loss)
I0123 23:24:06.080162 29630 sgd_solver.cpp:106] Iteration 51080, lr = 0.01
I0123 23:24:13.368432 29630 solver.cpp:237] Iteration 51100, loss = 3.20495
I0123 23:24:13.368621 29630 solver.cpp:253]     Train net output #0: loss = 3.20495 (* 1 = 3.20495 loss)
I0123 23:24:13.368638 29630 sgd_solver.cpp:106] Iteration 51100, lr = 0.01
I0123 23:24:20.643360 29630 solver.cpp:237] Iteration 51120, loss = 3.37031
I0123 23:24:20.643399 29630 solver.cpp:253]     Train net output #0: loss = 3.37031 (* 1 = 3.37031 loss)
I0123 23:24:20.643404 29630 sgd_solver.cpp:106] Iteration 51120, lr = 0.01
I0123 23:24:27.894214 29630 solver.cpp:237] Iteration 51140, loss = 3.52315
I0123 23:24:27.894254 29630 solver.cpp:253]     Train net output #0: loss = 3.52315 (* 1 = 3.52315 loss)
I0123 23:24:27.894260 29630 sgd_solver.cpp:106] Iteration 51140, lr = 0.01
I0123 23:24:35.156857 29630 solver.cpp:237] Iteration 51160, loss = 3.34345
I0123 23:24:35.156898 29630 solver.cpp:253]     Train net output #0: loss = 3.34345 (* 1 = 3.34345 loss)
I0123 23:24:35.156906 29630 sgd_solver.cpp:106] Iteration 51160, lr = 0.01
I0123 23:24:42.449000 29630 solver.cpp:237] Iteration 51180, loss = 3.63375
I0123 23:24:42.449039 29630 solver.cpp:253]     Train net output #0: loss = 3.63375 (* 1 = 3.63375 loss)
I0123 23:24:42.449045 29630 sgd_solver.cpp:106] Iteration 51180, lr = 0.01
I0123 23:24:49.712954 29630 solver.cpp:237] Iteration 51200, loss = 3.44462
I0123 23:24:49.713120 29630 solver.cpp:253]     Train net output #0: loss = 3.44462 (* 1 = 3.44462 loss)
I0123 23:24:49.713129 29630 sgd_solver.cpp:106] Iteration 51200, lr = 0.01
I0123 23:24:57.023980 29630 solver.cpp:237] Iteration 51220, loss = 3.59665
I0123 23:24:57.024019 29630 solver.cpp:253]     Train net output #0: loss = 3.59665 (* 1 = 3.59665 loss)
I0123 23:24:57.024025 29630 sgd_solver.cpp:106] Iteration 51220, lr = 0.01
I0123 23:25:04.263228 29630 solver.cpp:237] Iteration 51240, loss = 3.54414
I0123 23:25:04.263267 29630 solver.cpp:253]     Train net output #0: loss = 3.54414 (* 1 = 3.54414 loss)
I0123 23:25:04.263273 29630 sgd_solver.cpp:106] Iteration 51240, lr = 0.01
I0123 23:25:11.485648 29630 solver.cpp:237] Iteration 51260, loss = 3.37716
I0123 23:25:11.485687 29630 solver.cpp:253]     Train net output #0: loss = 3.37716 (* 1 = 3.37716 loss)
I0123 23:25:11.485692 29630 sgd_solver.cpp:106] Iteration 51260, lr = 0.01
I0123 23:25:18.774910 29630 solver.cpp:237] Iteration 51280, loss = 3.35854
I0123 23:25:18.774950 29630 solver.cpp:253]     Train net output #0: loss = 3.35854 (* 1 = 3.35854 loss)
I0123 23:25:18.774955 29630 sgd_solver.cpp:106] Iteration 51280, lr = 0.01
I0123 23:25:26.075974 29630 solver.cpp:237] Iteration 51300, loss = 3.62081
I0123 23:25:26.076145 29630 solver.cpp:253]     Train net output #0: loss = 3.62081 (* 1 = 3.62081 loss)
I0123 23:25:26.076153 29630 sgd_solver.cpp:106] Iteration 51300, lr = 0.01
I0123 23:25:28.700042 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 23:25:33.352036 29630 solver.cpp:237] Iteration 51320, loss = 3.45244
I0123 23:25:33.352083 29630 solver.cpp:253]     Train net output #0: loss = 3.45244 (* 1 = 3.45244 loss)
I0123 23:25:33.352089 29630 sgd_solver.cpp:106] Iteration 51320, lr = 0.01
I0123 23:25:40.629940 29630 solver.cpp:237] Iteration 51340, loss = 3.40849
I0123 23:25:40.629978 29630 solver.cpp:253]     Train net output #0: loss = 3.40849 (* 1 = 3.40849 loss)
I0123 23:25:40.629983 29630 sgd_solver.cpp:106] Iteration 51340, lr = 0.01
I0123 23:25:47.897124 29630 solver.cpp:237] Iteration 51360, loss = 3.44953
I0123 23:25:47.897162 29630 solver.cpp:253]     Train net output #0: loss = 3.44953 (* 1 = 3.44953 loss)
I0123 23:25:47.897168 29630 sgd_solver.cpp:106] Iteration 51360, lr = 0.01
I0123 23:25:55.177314 29630 solver.cpp:237] Iteration 51380, loss = 3.5906
I0123 23:25:55.177352 29630 solver.cpp:253]     Train net output #0: loss = 3.5906 (* 1 = 3.5906 loss)
I0123 23:25:55.177358 29630 sgd_solver.cpp:106] Iteration 51380, lr = 0.01
I0123 23:26:02.415880 29630 solver.cpp:237] Iteration 51400, loss = 3.5028
I0123 23:26:02.416033 29630 solver.cpp:253]     Train net output #0: loss = 3.5028 (* 1 = 3.5028 loss)
I0123 23:26:02.416054 29630 sgd_solver.cpp:106] Iteration 51400, lr = 0.01
I0123 23:26:09.666111 29630 solver.cpp:237] Iteration 51420, loss = 3.27529
I0123 23:26:09.666165 29630 solver.cpp:253]     Train net output #0: loss = 3.27529 (* 1 = 3.27529 loss)
I0123 23:26:09.666172 29630 sgd_solver.cpp:106] Iteration 51420, lr = 0.01
I0123 23:26:16.956743 29630 solver.cpp:237] Iteration 51440, loss = 3.73311
I0123 23:26:16.956782 29630 solver.cpp:253]     Train net output #0: loss = 3.73311 (* 1 = 3.73311 loss)
I0123 23:26:16.956789 29630 sgd_solver.cpp:106] Iteration 51440, lr = 0.01
I0123 23:26:24.207962 29630 solver.cpp:237] Iteration 51460, loss = 3.56995
I0123 23:26:24.208000 29630 solver.cpp:253]     Train net output #0: loss = 3.56995 (* 1 = 3.56995 loss)
I0123 23:26:24.208006 29630 sgd_solver.cpp:106] Iteration 51460, lr = 0.01
I0123 23:26:31.473217 29630 solver.cpp:237] Iteration 51480, loss = 3.47401
I0123 23:26:31.473255 29630 solver.cpp:253]     Train net output #0: loss = 3.47401 (* 1 = 3.47401 loss)
I0123 23:26:31.473261 29630 sgd_solver.cpp:106] Iteration 51480, lr = 0.01
I0123 23:26:38.717041 29630 solver.cpp:237] Iteration 51500, loss = 3.70327
I0123 23:26:38.717174 29630 solver.cpp:253]     Train net output #0: loss = 3.70327 (* 1 = 3.70327 loss)
I0123 23:26:38.717190 29630 sgd_solver.cpp:106] Iteration 51500, lr = 0.01
I0123 23:26:45.938851 29630 solver.cpp:237] Iteration 51520, loss = 3.22182
I0123 23:26:45.938889 29630 solver.cpp:253]     Train net output #0: loss = 3.22182 (* 1 = 3.22182 loss)
I0123 23:26:45.938895 29630 sgd_solver.cpp:106] Iteration 51520, lr = 0.01
I0123 23:26:53.230180 29630 solver.cpp:237] Iteration 51540, loss = 3.23496
I0123 23:26:53.230211 29630 solver.cpp:253]     Train net output #0: loss = 3.23496 (* 1 = 3.23496 loss)
I0123 23:26:53.230216 29630 sgd_solver.cpp:106] Iteration 51540, lr = 0.01
I0123 23:27:00.533473 29630 solver.cpp:237] Iteration 51560, loss = 3.40146
I0123 23:27:00.533529 29630 solver.cpp:253]     Train net output #0: loss = 3.40146 (* 1 = 3.40146 loss)
I0123 23:27:00.533536 29630 sgd_solver.cpp:106] Iteration 51560, lr = 0.01
I0123 23:27:07.778710 29630 solver.cpp:237] Iteration 51580, loss = 3.49511
I0123 23:27:07.778750 29630 solver.cpp:253]     Train net output #0: loss = 3.49511 (* 1 = 3.49511 loss)
I0123 23:27:07.778756 29630 sgd_solver.cpp:106] Iteration 51580, lr = 0.01
I0123 23:27:15.069556 29630 solver.cpp:237] Iteration 51600, loss = 3.51686
I0123 23:27:15.069759 29630 solver.cpp:253]     Train net output #0: loss = 3.51686 (* 1 = 3.51686 loss)
I0123 23:27:15.069766 29630 sgd_solver.cpp:106] Iteration 51600, lr = 0.01
I0123 23:27:22.303824 29630 solver.cpp:237] Iteration 51620, loss = 3.4969
I0123 23:27:22.303863 29630 solver.cpp:253]     Train net output #0: loss = 3.4969 (* 1 = 3.4969 loss)
I0123 23:27:22.303869 29630 sgd_solver.cpp:106] Iteration 51620, lr = 0.01
I0123 23:27:29.569041 29630 solver.cpp:237] Iteration 51640, loss = 3.768
I0123 23:27:29.569080 29630 solver.cpp:253]     Train net output #0: loss = 3.768 (* 1 = 3.768 loss)
I0123 23:27:29.569085 29630 sgd_solver.cpp:106] Iteration 51640, lr = 0.01
I0123 23:27:36.807936 29630 solver.cpp:237] Iteration 51660, loss = 3.69145
I0123 23:27:36.807984 29630 solver.cpp:253]     Train net output #0: loss = 3.69145 (* 1 = 3.69145 loss)
I0123 23:27:36.807993 29630 sgd_solver.cpp:106] Iteration 51660, lr = 0.01
I0123 23:27:44.049890 29630 solver.cpp:237] Iteration 51680, loss = 3.37986
I0123 23:27:44.049926 29630 solver.cpp:253]     Train net output #0: loss = 3.37986 (* 1 = 3.37986 loss)
I0123 23:27:44.049932 29630 sgd_solver.cpp:106] Iteration 51680, lr = 0.01
I0123 23:27:51.323160 29630 solver.cpp:237] Iteration 51700, loss = 3.39547
I0123 23:27:51.323326 29630 solver.cpp:253]     Train net output #0: loss = 3.39547 (* 1 = 3.39547 loss)
I0123 23:27:51.323335 29630 sgd_solver.cpp:106] Iteration 51700, lr = 0.01
I0123 23:27:58.592353 29630 solver.cpp:237] Iteration 51720, loss = 3.51709
I0123 23:27:58.592392 29630 solver.cpp:253]     Train net output #0: loss = 3.51709 (* 1 = 3.51709 loss)
I0123 23:27:58.592399 29630 sgd_solver.cpp:106] Iteration 51720, lr = 0.01
I0123 23:28:05.922499 29630 solver.cpp:237] Iteration 51740, loss = 3.27145
I0123 23:28:05.922528 29630 solver.cpp:253]     Train net output #0: loss = 3.27145 (* 1 = 3.27145 loss)
I0123 23:28:05.922534 29630 sgd_solver.cpp:106] Iteration 51740, lr = 0.01
I0123 23:28:13.186853 29630 solver.cpp:237] Iteration 51760, loss = 3.31426
I0123 23:28:13.186892 29630 solver.cpp:253]     Train net output #0: loss = 3.31426 (* 1 = 3.31426 loss)
I0123 23:28:13.186899 29630 sgd_solver.cpp:106] Iteration 51760, lr = 0.01
I0123 23:28:20.520109 29630 solver.cpp:237] Iteration 51780, loss = 3.52547
I0123 23:28:20.520148 29630 solver.cpp:253]     Train net output #0: loss = 3.52547 (* 1 = 3.52547 loss)
I0123 23:28:20.520155 29630 sgd_solver.cpp:106] Iteration 51780, lr = 0.01
I0123 23:28:27.817957 29630 solver.cpp:237] Iteration 51800, loss = 3.25755
I0123 23:28:27.818109 29630 solver.cpp:253]     Train net output #0: loss = 3.25755 (* 1 = 3.25755 loss)
I0123 23:28:27.818126 29630 sgd_solver.cpp:106] Iteration 51800, lr = 0.01
I0123 23:28:35.081113 29630 solver.cpp:237] Iteration 51820, loss = 3.2819
I0123 23:28:35.081152 29630 solver.cpp:253]     Train net output #0: loss = 3.2819 (* 1 = 3.2819 loss)
I0123 23:28:35.081157 29630 sgd_solver.cpp:106] Iteration 51820, lr = 0.01
I0123 23:28:42.334941 29630 solver.cpp:237] Iteration 51840, loss = 3.50985
I0123 23:28:42.334982 29630 solver.cpp:253]     Train net output #0: loss = 3.50985 (* 1 = 3.50985 loss)
I0123 23:28:42.334988 29630 sgd_solver.cpp:106] Iteration 51840, lr = 0.01
I0123 23:28:49.658226 29630 solver.cpp:237] Iteration 51860, loss = 3.45582
I0123 23:28:49.658264 29630 solver.cpp:253]     Train net output #0: loss = 3.45582 (* 1 = 3.45582 loss)
I0123 23:28:49.658272 29630 sgd_solver.cpp:106] Iteration 51860, lr = 0.01
I0123 23:28:56.991091 29630 solver.cpp:237] Iteration 51880, loss = 3.27022
I0123 23:28:56.991130 29630 solver.cpp:253]     Train net output #0: loss = 3.27022 (* 1 = 3.27022 loss)
I0123 23:28:56.991137 29630 sgd_solver.cpp:106] Iteration 51880, lr = 0.01
I0123 23:29:04.227221 29630 solver.cpp:237] Iteration 51900, loss = 3.39179
I0123 23:29:04.227349 29630 solver.cpp:253]     Train net output #0: loss = 3.39179 (* 1 = 3.39179 loss)
I0123 23:29:04.227356 29630 sgd_solver.cpp:106] Iteration 51900, lr = 0.01
I0123 23:29:11.519410 29630 solver.cpp:237] Iteration 51920, loss = 3.341
I0123 23:29:11.519449 29630 solver.cpp:253]     Train net output #0: loss = 3.341 (* 1 = 3.341 loss)
I0123 23:29:11.519455 29630 sgd_solver.cpp:106] Iteration 51920, lr = 0.01
I0123 23:29:18.771623 29630 solver.cpp:237] Iteration 51940, loss = 3.42834
I0123 23:29:18.771662 29630 solver.cpp:253]     Train net output #0: loss = 3.42834 (* 1 = 3.42834 loss)
I0123 23:29:18.771668 29630 sgd_solver.cpp:106] Iteration 51940, lr = 0.01
I0123 23:29:26.034307 29630 solver.cpp:237] Iteration 51960, loss = 3.29731
I0123 23:29:26.034345 29630 solver.cpp:253]     Train net output #0: loss = 3.29731 (* 1 = 3.29731 loss)
I0123 23:29:26.034353 29630 sgd_solver.cpp:106] Iteration 51960, lr = 0.01
I0123 23:29:33.314565 29630 solver.cpp:237] Iteration 51980, loss = 3.20562
I0123 23:29:33.314609 29630 solver.cpp:253]     Train net output #0: loss = 3.20562 (* 1 = 3.20562 loss)
I0123 23:29:33.314625 29630 sgd_solver.cpp:106] Iteration 51980, lr = 0.01
I0123 23:29:40.290041 29630 solver.cpp:341] Iteration 52000, Testing net (#0)
I0123 23:30:03.096382 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 23:30:54.589455 29630 solver.cpp:409]     Test net output #0: accuracy = 0.3124
I0123 23:30:54.589607 29630 solver.cpp:409]     Test net output #1: loss = 3.26434 (* 1 = 3.26434 loss)
I0123 23:30:54.630262 29630 solver.cpp:237] Iteration 52000, loss = 3.66563
I0123 23:30:54.630291 29630 solver.cpp:253]     Train net output #0: loss = 3.66563 (* 1 = 3.66563 loss)
I0123 23:30:54.630298 29630 sgd_solver.cpp:106] Iteration 52000, lr = 0.01
I0123 23:31:01.200670 29630 solver.cpp:237] Iteration 52020, loss = 3.27094
I0123 23:31:01.200708 29630 solver.cpp:253]     Train net output #0: loss = 3.27094 (* 1 = 3.27094 loss)
I0123 23:31:01.200716 29630 sgd_solver.cpp:106] Iteration 52020, lr = 0.01
I0123 23:31:08.434125 29630 solver.cpp:237] Iteration 52040, loss = 3.43098
I0123 23:31:08.434165 29630 solver.cpp:253]     Train net output #0: loss = 3.43098 (* 1 = 3.43098 loss)
I0123 23:31:08.434170 29630 sgd_solver.cpp:106] Iteration 52040, lr = 0.01
I0123 23:31:15.648696 29630 solver.cpp:237] Iteration 52060, loss = 3.56957
I0123 23:31:15.648735 29630 solver.cpp:253]     Train net output #0: loss = 3.56957 (* 1 = 3.56957 loss)
I0123 23:31:15.648741 29630 sgd_solver.cpp:106] Iteration 52060, lr = 0.01
I0123 23:31:22.937186 29630 solver.cpp:237] Iteration 52080, loss = 3.24256
I0123 23:31:22.937224 29630 solver.cpp:253]     Train net output #0: loss = 3.24256 (* 1 = 3.24256 loss)
I0123 23:31:22.937230 29630 sgd_solver.cpp:106] Iteration 52080, lr = 0.01
I0123 23:31:30.204906 29630 solver.cpp:237] Iteration 52100, loss = 3.26257
I0123 23:31:30.205005 29630 solver.cpp:253]     Train net output #0: loss = 3.26257 (* 1 = 3.26257 loss)
I0123 23:31:30.205020 29630 sgd_solver.cpp:106] Iteration 52100, lr = 0.01
I0123 23:31:37.408242 29630 solver.cpp:237] Iteration 52120, loss = 3.35068
I0123 23:31:37.408299 29630 solver.cpp:253]     Train net output #0: loss = 3.35068 (* 1 = 3.35068 loss)
I0123 23:31:37.408308 29630 sgd_solver.cpp:106] Iteration 52120, lr = 0.01
I0123 23:31:44.624586 29630 solver.cpp:237] Iteration 52140, loss = 3.55979
I0123 23:31:44.624625 29630 solver.cpp:253]     Train net output #0: loss = 3.55979 (* 1 = 3.55979 loss)
I0123 23:31:44.624631 29630 sgd_solver.cpp:106] Iteration 52140, lr = 0.01
I0123 23:31:51.874030 29630 solver.cpp:237] Iteration 52160, loss = 3.3244
I0123 23:31:51.874068 29630 solver.cpp:253]     Train net output #0: loss = 3.3244 (* 1 = 3.3244 loss)
I0123 23:31:51.874073 29630 sgd_solver.cpp:106] Iteration 52160, lr = 0.01
I0123 23:31:59.179947 29630 solver.cpp:237] Iteration 52180, loss = 3.32289
I0123 23:31:59.179986 29630 solver.cpp:253]     Train net output #0: loss = 3.32289 (* 1 = 3.32289 loss)
I0123 23:31:59.179992 29630 sgd_solver.cpp:106] Iteration 52180, lr = 0.01
I0123 23:32:06.467532 29630 solver.cpp:237] Iteration 52200, loss = 3.35854
I0123 23:32:06.467695 29630 solver.cpp:253]     Train net output #0: loss = 3.35854 (* 1 = 3.35854 loss)
I0123 23:32:06.467703 29630 sgd_solver.cpp:106] Iteration 52200, lr = 0.01
I0123 23:32:13.685461 29630 solver.cpp:237] Iteration 52220, loss = 3.46287
I0123 23:32:13.685499 29630 solver.cpp:253]     Train net output #0: loss = 3.46287 (* 1 = 3.46287 loss)
I0123 23:32:13.685505 29630 sgd_solver.cpp:106] Iteration 52220, lr = 0.01
I0123 23:32:20.959658 29630 solver.cpp:237] Iteration 52240, loss = 3.04597
I0123 23:32:20.959697 29630 solver.cpp:253]     Train net output #0: loss = 3.04597 (* 1 = 3.04597 loss)
I0123 23:32:20.959704 29630 sgd_solver.cpp:106] Iteration 52240, lr = 0.01
I0123 23:32:28.230029 29630 solver.cpp:237] Iteration 52260, loss = 3.4269
I0123 23:32:28.230068 29630 solver.cpp:253]     Train net output #0: loss = 3.4269 (* 1 = 3.4269 loss)
I0123 23:32:28.230074 29630 sgd_solver.cpp:106] Iteration 52260, lr = 0.01
I0123 23:32:35.496237 29630 solver.cpp:237] Iteration 52280, loss = 3.24021
I0123 23:32:35.496264 29630 solver.cpp:253]     Train net output #0: loss = 3.24021 (* 1 = 3.24021 loss)
I0123 23:32:35.496271 29630 sgd_solver.cpp:106] Iteration 52280, lr = 0.01
I0123 23:32:42.839910 29630 solver.cpp:237] Iteration 52300, loss = 3.7505
I0123 23:32:42.840082 29630 solver.cpp:253]     Train net output #0: loss = 3.7505 (* 1 = 3.7505 loss)
I0123 23:32:42.840090 29630 sgd_solver.cpp:106] Iteration 52300, lr = 0.01
I0123 23:32:47.613072 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 23:32:50.068905 29630 solver.cpp:237] Iteration 52320, loss = 3.39279
I0123 23:32:50.068945 29630 solver.cpp:253]     Train net output #0: loss = 3.39279 (* 1 = 3.39279 loss)
I0123 23:32:50.068951 29630 sgd_solver.cpp:106] Iteration 52320, lr = 0.01
I0123 23:32:57.338882 29630 solver.cpp:237] Iteration 52340, loss = 3.68003
I0123 23:32:57.338920 29630 solver.cpp:253]     Train net output #0: loss = 3.68003 (* 1 = 3.68003 loss)
I0123 23:32:57.338927 29630 sgd_solver.cpp:106] Iteration 52340, lr = 0.01
I0123 23:33:04.630825 29630 solver.cpp:237] Iteration 52360, loss = 3.43341
I0123 23:33:04.630863 29630 solver.cpp:253]     Train net output #0: loss = 3.43341 (* 1 = 3.43341 loss)
I0123 23:33:04.630869 29630 sgd_solver.cpp:106] Iteration 52360, lr = 0.01
I0123 23:33:11.908915 29630 solver.cpp:237] Iteration 52380, loss = 3.25987
I0123 23:33:11.908954 29630 solver.cpp:253]     Train net output #0: loss = 3.25987 (* 1 = 3.25987 loss)
I0123 23:33:11.908960 29630 sgd_solver.cpp:106] Iteration 52380, lr = 0.01
I0123 23:33:19.165344 29630 solver.cpp:237] Iteration 52400, loss = 3.11739
I0123 23:33:19.165518 29630 solver.cpp:253]     Train net output #0: loss = 3.11739 (* 1 = 3.11739 loss)
I0123 23:33:19.165526 29630 sgd_solver.cpp:106] Iteration 52400, lr = 0.01
I0123 23:33:26.470355 29630 solver.cpp:237] Iteration 52420, loss = 3.10452
I0123 23:33:26.470394 29630 solver.cpp:253]     Train net output #0: loss = 3.10452 (* 1 = 3.10452 loss)
I0123 23:33:26.470402 29630 sgd_solver.cpp:106] Iteration 52420, lr = 0.01
I0123 23:33:33.807474 29630 solver.cpp:237] Iteration 52440, loss = 3.38383
I0123 23:33:33.807513 29630 solver.cpp:253]     Train net output #0: loss = 3.38383 (* 1 = 3.38383 loss)
I0123 23:33:33.807518 29630 sgd_solver.cpp:106] Iteration 52440, lr = 0.01
I0123 23:33:41.111490 29630 solver.cpp:237] Iteration 52460, loss = 3.35298
I0123 23:33:41.111528 29630 solver.cpp:253]     Train net output #0: loss = 3.35298 (* 1 = 3.35298 loss)
I0123 23:33:41.111534 29630 sgd_solver.cpp:106] Iteration 52460, lr = 0.01
I0123 23:33:48.385169 29630 solver.cpp:237] Iteration 52480, loss = 3.43556
I0123 23:33:48.385207 29630 solver.cpp:253]     Train net output #0: loss = 3.43556 (* 1 = 3.43556 loss)
I0123 23:33:48.385213 29630 sgd_solver.cpp:106] Iteration 52480, lr = 0.01
I0123 23:33:55.627908 29630 solver.cpp:237] Iteration 52500, loss = 3.31934
I0123 23:33:55.628073 29630 solver.cpp:253]     Train net output #0: loss = 3.31934 (* 1 = 3.31934 loss)
I0123 23:33:55.628082 29630 sgd_solver.cpp:106] Iteration 52500, lr = 0.01
I0123 23:34:02.885694 29630 solver.cpp:237] Iteration 52520, loss = 3.4385
I0123 23:34:02.885731 29630 solver.cpp:253]     Train net output #0: loss = 3.4385 (* 1 = 3.4385 loss)
I0123 23:34:02.885737 29630 sgd_solver.cpp:106] Iteration 52520, lr = 0.01
I0123 23:34:10.147801 29630 solver.cpp:237] Iteration 52540, loss = 3.42988
I0123 23:34:10.147840 29630 solver.cpp:253]     Train net output #0: loss = 3.42988 (* 1 = 3.42988 loss)
I0123 23:34:10.147847 29630 sgd_solver.cpp:106] Iteration 52540, lr = 0.01
I0123 23:34:17.422168 29630 solver.cpp:237] Iteration 52560, loss = 3.54058
I0123 23:34:17.422205 29630 solver.cpp:253]     Train net output #0: loss = 3.54058 (* 1 = 3.54058 loss)
I0123 23:34:17.422211 29630 sgd_solver.cpp:106] Iteration 52560, lr = 0.01
I0123 23:34:24.667618 29630 solver.cpp:237] Iteration 52580, loss = 3.47312
I0123 23:34:24.667659 29630 solver.cpp:253]     Train net output #0: loss = 3.47312 (* 1 = 3.47312 loss)
I0123 23:34:24.667665 29630 sgd_solver.cpp:106] Iteration 52580, lr = 0.01
I0123 23:34:31.934550 29630 solver.cpp:237] Iteration 52600, loss = 3.48498
I0123 23:34:31.934656 29630 solver.cpp:253]     Train net output #0: loss = 3.48498 (* 1 = 3.48498 loss)
I0123 23:34:31.934665 29630 sgd_solver.cpp:106] Iteration 52600, lr = 0.01
I0123 23:34:39.149354 29630 solver.cpp:237] Iteration 52620, loss = 3.37191
I0123 23:34:39.149392 29630 solver.cpp:253]     Train net output #0: loss = 3.37191 (* 1 = 3.37191 loss)
I0123 23:34:39.149399 29630 sgd_solver.cpp:106] Iteration 52620, lr = 0.01
I0123 23:34:46.366036 29630 solver.cpp:237] Iteration 52640, loss = 3.20122
I0123 23:34:46.366075 29630 solver.cpp:253]     Train net output #0: loss = 3.20122 (* 1 = 3.20122 loss)
I0123 23:34:46.366080 29630 sgd_solver.cpp:106] Iteration 52640, lr = 0.01
I0123 23:34:53.611234 29630 solver.cpp:237] Iteration 52660, loss = 3.3961
I0123 23:34:53.611274 29630 solver.cpp:253]     Train net output #0: loss = 3.3961 (* 1 = 3.3961 loss)
I0123 23:34:53.611280 29630 sgd_solver.cpp:106] Iteration 52660, lr = 0.01
I0123 23:35:00.871194 29630 solver.cpp:237] Iteration 52680, loss = 3.46458
I0123 23:35:00.871234 29630 solver.cpp:253]     Train net output #0: loss = 3.46458 (* 1 = 3.46458 loss)
I0123 23:35:00.871240 29630 sgd_solver.cpp:106] Iteration 52680, lr = 0.01
I0123 23:35:08.111115 29630 solver.cpp:237] Iteration 52700, loss = 3.21468
I0123 23:35:08.111277 29630 solver.cpp:253]     Train net output #0: loss = 3.21468 (* 1 = 3.21468 loss)
I0123 23:35:08.111285 29630 sgd_solver.cpp:106] Iteration 52700, lr = 0.01
I0123 23:35:15.339609 29630 solver.cpp:237] Iteration 52720, loss = 3.11771
I0123 23:35:15.339648 29630 solver.cpp:253]     Train net output #0: loss = 3.11771 (* 1 = 3.11771 loss)
I0123 23:35:15.339655 29630 sgd_solver.cpp:106] Iteration 52720, lr = 0.01
I0123 23:35:22.620298 29630 solver.cpp:237] Iteration 52740, loss = 3.6232
I0123 23:35:22.620337 29630 solver.cpp:253]     Train net output #0: loss = 3.6232 (* 1 = 3.6232 loss)
I0123 23:35:22.620343 29630 sgd_solver.cpp:106] Iteration 52740, lr = 0.01
I0123 23:35:29.858181 29630 solver.cpp:237] Iteration 52760, loss = 3.05161
I0123 23:35:29.858218 29630 solver.cpp:253]     Train net output #0: loss = 3.05161 (* 1 = 3.05161 loss)
I0123 23:35:29.858225 29630 sgd_solver.cpp:106] Iteration 52760, lr = 0.01
I0123 23:35:37.124732 29630 solver.cpp:237] Iteration 52780, loss = 3.5827
I0123 23:35:37.124771 29630 solver.cpp:253]     Train net output #0: loss = 3.5827 (* 1 = 3.5827 loss)
I0123 23:35:37.124778 29630 sgd_solver.cpp:106] Iteration 52780, lr = 0.01
I0123 23:35:44.376010 29630 solver.cpp:237] Iteration 52800, loss = 3.33571
I0123 23:35:44.376148 29630 solver.cpp:253]     Train net output #0: loss = 3.33571 (* 1 = 3.33571 loss)
I0123 23:35:44.376157 29630 sgd_solver.cpp:106] Iteration 52800, lr = 0.01
I0123 23:35:51.696424 29630 solver.cpp:237] Iteration 52820, loss = 3.49344
I0123 23:35:51.696463 29630 solver.cpp:253]     Train net output #0: loss = 3.49344 (* 1 = 3.49344 loss)
I0123 23:35:51.696470 29630 sgd_solver.cpp:106] Iteration 52820, lr = 0.01
I0123 23:35:58.943311 29630 solver.cpp:237] Iteration 52840, loss = 3.72341
I0123 23:35:58.943351 29630 solver.cpp:253]     Train net output #0: loss = 3.72341 (* 1 = 3.72341 loss)
I0123 23:35:58.943357 29630 sgd_solver.cpp:106] Iteration 52840, lr = 0.01
I0123 23:36:06.220576 29630 solver.cpp:237] Iteration 52860, loss = 3.6045
I0123 23:36:06.220615 29630 solver.cpp:253]     Train net output #0: loss = 3.6045 (* 1 = 3.6045 loss)
I0123 23:36:06.220621 29630 sgd_solver.cpp:106] Iteration 52860, lr = 0.01
I0123 23:36:13.485311 29630 solver.cpp:237] Iteration 52880, loss = 3.37161
I0123 23:36:13.485348 29630 solver.cpp:253]     Train net output #0: loss = 3.37161 (* 1 = 3.37161 loss)
I0123 23:36:13.485354 29630 sgd_solver.cpp:106] Iteration 52880, lr = 0.01
I0123 23:36:20.748458 29630 solver.cpp:237] Iteration 52900, loss = 3.33883
I0123 23:36:20.748606 29630 solver.cpp:253]     Train net output #0: loss = 3.33883 (* 1 = 3.33883 loss)
I0123 23:36:20.748615 29630 sgd_solver.cpp:106] Iteration 52900, lr = 0.01
I0123 23:36:28.027029 29630 solver.cpp:237] Iteration 52920, loss = 3.30691
I0123 23:36:28.027089 29630 solver.cpp:253]     Train net output #0: loss = 3.30691 (* 1 = 3.30691 loss)
I0123 23:36:28.027101 29630 sgd_solver.cpp:106] Iteration 52920, lr = 0.01
I0123 23:36:35.250102 29630 solver.cpp:237] Iteration 52940, loss = 3.32013
I0123 23:36:35.250141 29630 solver.cpp:253]     Train net output #0: loss = 3.32013 (* 1 = 3.32013 loss)
I0123 23:36:35.250149 29630 sgd_solver.cpp:106] Iteration 52940, lr = 0.01
I0123 23:36:42.559965 29630 solver.cpp:237] Iteration 52960, loss = 3.51745
I0123 23:36:42.560003 29630 solver.cpp:253]     Train net output #0: loss = 3.51745 (* 1 = 3.51745 loss)
I0123 23:36:42.560009 29630 sgd_solver.cpp:106] Iteration 52960, lr = 0.01
I0123 23:36:49.843751 29630 solver.cpp:237] Iteration 52980, loss = 3.23172
I0123 23:36:49.843781 29630 solver.cpp:253]     Train net output #0: loss = 3.23172 (* 1 = 3.23172 loss)
I0123 23:36:49.843787 29630 sgd_solver.cpp:106] Iteration 52980, lr = 0.01
I0123 23:36:56.821738 29630 solver.cpp:341] Iteration 53000, Testing net (#0)
I0123 23:37:20.083880 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 23:38:10.718081 29630 solver.cpp:409]     Test net output #0: accuracy = 0.32378
I0123 23:38:10.718250 29630 solver.cpp:409]     Test net output #1: loss = 3.20524 (* 1 = 3.20524 loss)
I0123 23:38:10.759042 29630 solver.cpp:237] Iteration 53000, loss = 3.47931
I0123 23:38:10.759079 29630 solver.cpp:253]     Train net output #0: loss = 3.47931 (* 1 = 3.47931 loss)
I0123 23:38:10.759085 29630 sgd_solver.cpp:106] Iteration 53000, lr = 0.01
I0123 23:38:17.370101 29630 solver.cpp:237] Iteration 53020, loss = 3.34576
I0123 23:38:17.370139 29630 solver.cpp:253]     Train net output #0: loss = 3.34576 (* 1 = 3.34576 loss)
I0123 23:38:17.370146 29630 sgd_solver.cpp:106] Iteration 53020, lr = 0.01
I0123 23:38:24.615628 29630 solver.cpp:237] Iteration 53040, loss = 3.41349
I0123 23:38:24.615667 29630 solver.cpp:253]     Train net output #0: loss = 3.41349 (* 1 = 3.41349 loss)
I0123 23:38:24.615675 29630 sgd_solver.cpp:106] Iteration 53040, lr = 0.01
I0123 23:38:31.869202 29630 solver.cpp:237] Iteration 53060, loss = 3.58045
I0123 23:38:31.869245 29630 solver.cpp:253]     Train net output #0: loss = 3.58045 (* 1 = 3.58045 loss)
I0123 23:38:31.869252 29630 sgd_solver.cpp:106] Iteration 53060, lr = 0.01
I0123 23:38:39.120301 29630 solver.cpp:237] Iteration 53080, loss = 3.35916
I0123 23:38:39.120340 29630 solver.cpp:253]     Train net output #0: loss = 3.35916 (* 1 = 3.35916 loss)
I0123 23:38:39.120347 29630 sgd_solver.cpp:106] Iteration 53080, lr = 0.01
I0123 23:38:46.356127 29630 solver.cpp:237] Iteration 53100, loss = 3.56378
I0123 23:38:46.356290 29630 solver.cpp:253]     Train net output #0: loss = 3.56378 (* 1 = 3.56378 loss)
I0123 23:38:46.356298 29630 sgd_solver.cpp:106] Iteration 53100, lr = 0.01
I0123 23:38:53.567260 29630 solver.cpp:237] Iteration 53120, loss = 3.25404
I0123 23:38:53.567299 29630 solver.cpp:253]     Train net output #0: loss = 3.25404 (* 1 = 3.25404 loss)
I0123 23:38:53.567306 29630 sgd_solver.cpp:106] Iteration 53120, lr = 0.01
I0123 23:39:00.843014 29630 solver.cpp:237] Iteration 53140, loss = 3.62291
I0123 23:39:00.843052 29630 solver.cpp:253]     Train net output #0: loss = 3.62291 (* 1 = 3.62291 loss)
I0123 23:39:00.843058 29630 sgd_solver.cpp:106] Iteration 53140, lr = 0.01
I0123 23:39:08.180614 29630 solver.cpp:237] Iteration 53160, loss = 3.49206
I0123 23:39:08.180652 29630 solver.cpp:253]     Train net output #0: loss = 3.49206 (* 1 = 3.49206 loss)
I0123 23:39:08.180658 29630 sgd_solver.cpp:106] Iteration 53160, lr = 0.01
I0123 23:39:15.445396 29630 solver.cpp:237] Iteration 53180, loss = 3.27908
I0123 23:39:15.445435 29630 solver.cpp:253]     Train net output #0: loss = 3.27908 (* 1 = 3.27908 loss)
I0123 23:39:15.445441 29630 sgd_solver.cpp:106] Iteration 53180, lr = 0.01
I0123 23:39:22.680181 29630 solver.cpp:237] Iteration 53200, loss = 3.48316
I0123 23:39:22.680343 29630 solver.cpp:253]     Train net output #0: loss = 3.48316 (* 1 = 3.48316 loss)
I0123 23:39:22.680351 29630 sgd_solver.cpp:106] Iteration 53200, lr = 0.01
I0123 23:39:29.969178 29630 solver.cpp:237] Iteration 53220, loss = 3.51073
I0123 23:39:29.969218 29630 solver.cpp:253]     Train net output #0: loss = 3.51073 (* 1 = 3.51073 loss)
I0123 23:39:29.969224 29630 sgd_solver.cpp:106] Iteration 53220, lr = 0.01
I0123 23:39:37.229697 29630 solver.cpp:237] Iteration 53240, loss = 3.46656
I0123 23:39:37.229734 29630 solver.cpp:253]     Train net output #0: loss = 3.46656 (* 1 = 3.46656 loss)
I0123 23:39:37.229742 29630 sgd_solver.cpp:106] Iteration 53240, lr = 0.01
I0123 23:39:44.482055 29630 solver.cpp:237] Iteration 53260, loss = 3.64718
I0123 23:39:44.482094 29630 solver.cpp:253]     Train net output #0: loss = 3.64718 (* 1 = 3.64718 loss)
I0123 23:39:44.482100 29630 sgd_solver.cpp:106] Iteration 53260, lr = 0.01
I0123 23:39:51.732090 29630 solver.cpp:237] Iteration 53280, loss = 3.28837
I0123 23:39:51.732128 29630 solver.cpp:253]     Train net output #0: loss = 3.28837 (* 1 = 3.28837 loss)
I0123 23:39:51.732134 29630 sgd_solver.cpp:106] Iteration 53280, lr = 0.01
I0123 23:39:59.053210 29630 solver.cpp:237] Iteration 53300, loss = 3.32097
I0123 23:39:59.053390 29630 solver.cpp:253]     Train net output #0: loss = 3.32097 (* 1 = 3.32097 loss)
I0123 23:39:59.053398 29630 sgd_solver.cpp:106] Iteration 53300, lr = 0.01
I0123 23:40:06.005976 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 23:40:06.297060 29630 solver.cpp:237] Iteration 53320, loss = 3.35056
I0123 23:40:06.297098 29630 solver.cpp:253]     Train net output #0: loss = 3.35056 (* 1 = 3.35056 loss)
I0123 23:40:06.297104 29630 sgd_solver.cpp:106] Iteration 53320, lr = 0.01
I0123 23:40:13.533332 29630 solver.cpp:237] Iteration 53340, loss = 3.59436
I0123 23:40:13.533370 29630 solver.cpp:253]     Train net output #0: loss = 3.59436 (* 1 = 3.59436 loss)
I0123 23:40:13.533376 29630 sgd_solver.cpp:106] Iteration 53340, lr = 0.01
I0123 23:40:20.779759 29630 solver.cpp:237] Iteration 53360, loss = 3.20564
I0123 23:40:20.779798 29630 solver.cpp:253]     Train net output #0: loss = 3.20564 (* 1 = 3.20564 loss)
I0123 23:40:20.779803 29630 sgd_solver.cpp:106] Iteration 53360, lr = 0.01
I0123 23:40:28.004070 29630 solver.cpp:237] Iteration 53380, loss = 3.44734
I0123 23:40:28.004107 29630 solver.cpp:253]     Train net output #0: loss = 3.44734 (* 1 = 3.44734 loss)
I0123 23:40:28.004113 29630 sgd_solver.cpp:106] Iteration 53380, lr = 0.01
I0123 23:40:35.297395 29630 solver.cpp:237] Iteration 53400, loss = 3.45629
I0123 23:40:35.297577 29630 solver.cpp:253]     Train net output #0: loss = 3.45629 (* 1 = 3.45629 loss)
I0123 23:40:35.297585 29630 sgd_solver.cpp:106] Iteration 53400, lr = 0.01
I0123 23:40:42.550726 29630 solver.cpp:237] Iteration 53420, loss = 3.58697
I0123 23:40:42.550762 29630 solver.cpp:253]     Train net output #0: loss = 3.58697 (* 1 = 3.58697 loss)
I0123 23:40:42.550768 29630 sgd_solver.cpp:106] Iteration 53420, lr = 0.01
I0123 23:40:49.829911 29630 solver.cpp:237] Iteration 53440, loss = 3.37528
I0123 23:40:49.829949 29630 solver.cpp:253]     Train net output #0: loss = 3.37528 (* 1 = 3.37528 loss)
I0123 23:40:49.829955 29630 sgd_solver.cpp:106] Iteration 53440, lr = 0.01
I0123 23:40:57.129037 29630 solver.cpp:237] Iteration 53460, loss = 3.2679
I0123 23:40:57.129076 29630 solver.cpp:253]     Train net output #0: loss = 3.2679 (* 1 = 3.2679 loss)
I0123 23:40:57.129082 29630 sgd_solver.cpp:106] Iteration 53460, lr = 0.01
I0123 23:41:04.417235 29630 solver.cpp:237] Iteration 53480, loss = 3.54802
I0123 23:41:04.417275 29630 solver.cpp:253]     Train net output #0: loss = 3.54802 (* 1 = 3.54802 loss)
I0123 23:41:04.417281 29630 sgd_solver.cpp:106] Iteration 53480, lr = 0.01
I0123 23:41:11.758267 29630 solver.cpp:237] Iteration 53500, loss = 3.41176
I0123 23:41:11.758442 29630 solver.cpp:253]     Train net output #0: loss = 3.41176 (* 1 = 3.41176 loss)
I0123 23:41:11.758450 29630 sgd_solver.cpp:106] Iteration 53500, lr = 0.01
I0123 23:41:19.006712 29630 solver.cpp:237] Iteration 53520, loss = 3.61019
I0123 23:41:19.006752 29630 solver.cpp:253]     Train net output #0: loss = 3.61019 (* 1 = 3.61019 loss)
I0123 23:41:19.006758 29630 sgd_solver.cpp:106] Iteration 53520, lr = 0.01
I0123 23:41:26.277465 29630 solver.cpp:237] Iteration 53540, loss = 3.10186
I0123 23:41:26.277504 29630 solver.cpp:253]     Train net output #0: loss = 3.10186 (* 1 = 3.10186 loss)
I0123 23:41:26.277510 29630 sgd_solver.cpp:106] Iteration 53540, lr = 0.01
I0123 23:41:33.546200 29630 solver.cpp:237] Iteration 53560, loss = 3.356
I0123 23:41:33.546263 29630 solver.cpp:253]     Train net output #0: loss = 3.356 (* 1 = 3.356 loss)
I0123 23:41:33.546277 29630 sgd_solver.cpp:106] Iteration 53560, lr = 0.01
I0123 23:41:40.847932 29630 solver.cpp:237] Iteration 53580, loss = 3.35456
I0123 23:41:40.847972 29630 solver.cpp:253]     Train net output #0: loss = 3.35456 (* 1 = 3.35456 loss)
I0123 23:41:40.847978 29630 sgd_solver.cpp:106] Iteration 53580, lr = 0.01
I0123 23:41:48.063319 29630 solver.cpp:237] Iteration 53600, loss = 3.69534
I0123 23:41:48.063413 29630 solver.cpp:253]     Train net output #0: loss = 3.69534 (* 1 = 3.69534 loss)
I0123 23:41:48.063421 29630 sgd_solver.cpp:106] Iteration 53600, lr = 0.01
I0123 23:41:55.335460 29630 solver.cpp:237] Iteration 53620, loss = 3.42138
I0123 23:41:55.335499 29630 solver.cpp:253]     Train net output #0: loss = 3.42138 (* 1 = 3.42138 loss)
I0123 23:41:55.335505 29630 sgd_solver.cpp:106] Iteration 53620, lr = 0.01
I0123 23:42:02.641171 29630 solver.cpp:237] Iteration 53640, loss = 3.4073
I0123 23:42:02.641211 29630 solver.cpp:253]     Train net output #0: loss = 3.4073 (* 1 = 3.4073 loss)
I0123 23:42:02.641216 29630 sgd_solver.cpp:106] Iteration 53640, lr = 0.01
I0123 23:42:09.969646 29630 solver.cpp:237] Iteration 53660, loss = 3.34743
I0123 23:42:09.969694 29630 solver.cpp:253]     Train net output #0: loss = 3.34743 (* 1 = 3.34743 loss)
I0123 23:42:09.969699 29630 sgd_solver.cpp:106] Iteration 53660, lr = 0.01
I0123 23:42:17.256023 29630 solver.cpp:237] Iteration 53680, loss = 3.51025
I0123 23:42:17.256094 29630 solver.cpp:253]     Train net output #0: loss = 3.51025 (* 1 = 3.51025 loss)
I0123 23:42:17.256117 29630 sgd_solver.cpp:106] Iteration 53680, lr = 0.01
I0123 23:42:24.475045 29630 solver.cpp:237] Iteration 53700, loss = 3.30586
I0123 23:42:24.475227 29630 solver.cpp:253]     Train net output #0: loss = 3.30586 (* 1 = 3.30586 loss)
I0123 23:42:24.475235 29630 sgd_solver.cpp:106] Iteration 53700, lr = 0.01
I0123 23:42:31.706867 29630 solver.cpp:237] Iteration 53720, loss = 3.33467
I0123 23:42:31.706904 29630 solver.cpp:253]     Train net output #0: loss = 3.33467 (* 1 = 3.33467 loss)
I0123 23:42:31.706912 29630 sgd_solver.cpp:106] Iteration 53720, lr = 0.01
I0123 23:42:38.969959 29630 solver.cpp:237] Iteration 53740, loss = 3.54246
I0123 23:42:38.969995 29630 solver.cpp:253]     Train net output #0: loss = 3.54246 (* 1 = 3.54246 loss)
I0123 23:42:38.970001 29630 sgd_solver.cpp:106] Iteration 53740, lr = 0.01
I0123 23:42:46.246904 29630 solver.cpp:237] Iteration 53760, loss = 3.32749
I0123 23:42:46.246942 29630 solver.cpp:253]     Train net output #0: loss = 3.32749 (* 1 = 3.32749 loss)
I0123 23:42:46.246948 29630 sgd_solver.cpp:106] Iteration 53760, lr = 0.01
I0123 23:42:53.518137 29630 solver.cpp:237] Iteration 53780, loss = 3.32755
I0123 23:42:53.518175 29630 solver.cpp:253]     Train net output #0: loss = 3.32755 (* 1 = 3.32755 loss)
I0123 23:42:53.518182 29630 sgd_solver.cpp:106] Iteration 53780, lr = 0.01
I0123 23:43:00.749500 29630 solver.cpp:237] Iteration 53800, loss = 3.60837
I0123 23:43:00.749634 29630 solver.cpp:253]     Train net output #0: loss = 3.60837 (* 1 = 3.60837 loss)
I0123 23:43:00.749642 29630 sgd_solver.cpp:106] Iteration 53800, lr = 0.01
I0123 23:43:08.052191 29630 solver.cpp:237] Iteration 53820, loss = 3.25435
I0123 23:43:08.052230 29630 solver.cpp:253]     Train net output #0: loss = 3.25435 (* 1 = 3.25435 loss)
I0123 23:43:08.052237 29630 sgd_solver.cpp:106] Iteration 53820, lr = 0.01
I0123 23:43:15.299660 29630 solver.cpp:237] Iteration 53840, loss = 3.44718
I0123 23:43:15.299698 29630 solver.cpp:253]     Train net output #0: loss = 3.44718 (* 1 = 3.44718 loss)
I0123 23:43:15.299705 29630 sgd_solver.cpp:106] Iteration 53840, lr = 0.01
I0123 23:43:22.636072 29630 solver.cpp:237] Iteration 53860, loss = 3.2916
I0123 23:43:22.636111 29630 solver.cpp:253]     Train net output #0: loss = 3.2916 (* 1 = 3.2916 loss)
I0123 23:43:22.636117 29630 sgd_solver.cpp:106] Iteration 53860, lr = 0.01
I0123 23:43:29.887197 29630 solver.cpp:237] Iteration 53880, loss = 3.17768
I0123 23:43:29.887236 29630 solver.cpp:253]     Train net output #0: loss = 3.17768 (* 1 = 3.17768 loss)
I0123 23:43:29.887243 29630 sgd_solver.cpp:106] Iteration 53880, lr = 0.01
I0123 23:43:37.178520 29630 solver.cpp:237] Iteration 53900, loss = 3.38301
I0123 23:43:37.178616 29630 solver.cpp:253]     Train net output #0: loss = 3.38301 (* 1 = 3.38301 loss)
I0123 23:43:37.178622 29630 sgd_solver.cpp:106] Iteration 53900, lr = 0.01
I0123 23:43:44.422034 29630 solver.cpp:237] Iteration 53920, loss = 3.37448
I0123 23:43:44.422073 29630 solver.cpp:253]     Train net output #0: loss = 3.37448 (* 1 = 3.37448 loss)
I0123 23:43:44.422080 29630 sgd_solver.cpp:106] Iteration 53920, lr = 0.01
I0123 23:43:51.707363 29630 solver.cpp:237] Iteration 53940, loss = 3.47612
I0123 23:43:51.707402 29630 solver.cpp:253]     Train net output #0: loss = 3.47612 (* 1 = 3.47612 loss)
I0123 23:43:51.707408 29630 sgd_solver.cpp:106] Iteration 53940, lr = 0.01
I0123 23:43:58.982010 29630 solver.cpp:237] Iteration 53960, loss = 3.36428
I0123 23:43:58.982048 29630 solver.cpp:253]     Train net output #0: loss = 3.36428 (* 1 = 3.36428 loss)
I0123 23:43:58.982054 29630 sgd_solver.cpp:106] Iteration 53960, lr = 0.01
I0123 23:44:06.261620 29630 solver.cpp:237] Iteration 53980, loss = 3.3692
I0123 23:44:06.261661 29630 solver.cpp:253]     Train net output #0: loss = 3.3692 (* 1 = 3.3692 loss)
I0123 23:44:06.261667 29630 sgd_solver.cpp:106] Iteration 53980, lr = 0.01
I0123 23:44:13.295542 29630 solver.cpp:341] Iteration 54000, Testing net (#0)
I0123 23:44:37.066426 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 23:45:28.065469 29630 solver.cpp:409]     Test net output #0: accuracy = 0.31396
I0123 23:45:28.065664 29630 solver.cpp:409]     Test net output #1: loss = 3.24666 (* 1 = 3.24666 loss)
I0123 23:45:28.106061 29630 solver.cpp:237] Iteration 54000, loss = 3.21649
I0123 23:45:28.106093 29630 solver.cpp:253]     Train net output #0: loss = 3.21649 (* 1 = 3.21649 loss)
I0123 23:45:28.106101 29630 sgd_solver.cpp:106] Iteration 54000, lr = 0.01
I0123 23:45:34.682605 29630 solver.cpp:237] Iteration 54020, loss = 3.4014
I0123 23:45:34.682643 29630 solver.cpp:253]     Train net output #0: loss = 3.4014 (* 1 = 3.4014 loss)
I0123 23:45:34.682651 29630 sgd_solver.cpp:106] Iteration 54020, lr = 0.01
I0123 23:45:41.893651 29630 solver.cpp:237] Iteration 54040, loss = 3.23597
I0123 23:45:41.893688 29630 solver.cpp:253]     Train net output #0: loss = 3.23597 (* 1 = 3.23597 loss)
I0123 23:45:41.893694 29630 sgd_solver.cpp:106] Iteration 54040, lr = 0.01
I0123 23:45:49.141301 29630 solver.cpp:237] Iteration 54060, loss = 3.3814
I0123 23:45:49.141340 29630 solver.cpp:253]     Train net output #0: loss = 3.3814 (* 1 = 3.3814 loss)
I0123 23:45:49.141346 29630 sgd_solver.cpp:106] Iteration 54060, lr = 0.01
I0123 23:45:56.378325 29630 solver.cpp:237] Iteration 54080, loss = 3.38196
I0123 23:45:56.378366 29630 solver.cpp:253]     Train net output #0: loss = 3.38196 (* 1 = 3.38196 loss)
I0123 23:45:56.378373 29630 sgd_solver.cpp:106] Iteration 54080, lr = 0.01
I0123 23:46:03.646445 29630 solver.cpp:237] Iteration 54100, loss = 3.5654
I0123 23:46:03.646590 29630 solver.cpp:253]     Train net output #0: loss = 3.5654 (* 1 = 3.5654 loss)
I0123 23:46:03.646606 29630 sgd_solver.cpp:106] Iteration 54100, lr = 0.01
I0123 23:46:10.865007 29630 solver.cpp:237] Iteration 54120, loss = 3.52403
I0123 23:46:10.865046 29630 solver.cpp:253]     Train net output #0: loss = 3.52403 (* 1 = 3.52403 loss)
I0123 23:46:10.865051 29630 sgd_solver.cpp:106] Iteration 54120, lr = 0.01
I0123 23:46:18.127141 29630 solver.cpp:237] Iteration 54140, loss = 3.35112
I0123 23:46:18.127181 29630 solver.cpp:253]     Train net output #0: loss = 3.35112 (* 1 = 3.35112 loss)
I0123 23:46:18.127188 29630 sgd_solver.cpp:106] Iteration 54140, lr = 0.01
I0123 23:46:25.421052 29630 solver.cpp:237] Iteration 54160, loss = 3.25143
I0123 23:46:25.421092 29630 solver.cpp:253]     Train net output #0: loss = 3.25143 (* 1 = 3.25143 loss)
I0123 23:46:25.421098 29630 sgd_solver.cpp:106] Iteration 54160, lr = 0.01
I0123 23:46:32.703305 29630 solver.cpp:237] Iteration 54180, loss = 3.60784
I0123 23:46:32.703343 29630 solver.cpp:253]     Train net output #0: loss = 3.60784 (* 1 = 3.60784 loss)
I0123 23:46:32.703349 29630 sgd_solver.cpp:106] Iteration 54180, lr = 0.01
I0123 23:46:39.994256 29630 solver.cpp:237] Iteration 54200, loss = 3.38462
I0123 23:46:39.994431 29630 solver.cpp:253]     Train net output #0: loss = 3.38462 (* 1 = 3.38462 loss)
I0123 23:46:39.994438 29630 sgd_solver.cpp:106] Iteration 54200, lr = 0.01
I0123 23:46:47.301336 29630 solver.cpp:237] Iteration 54220, loss = 3.53567
I0123 23:46:47.301373 29630 solver.cpp:253]     Train net output #0: loss = 3.53567 (* 1 = 3.53567 loss)
I0123 23:46:47.301380 29630 sgd_solver.cpp:106] Iteration 54220, lr = 0.01
I0123 23:46:54.615550 29630 solver.cpp:237] Iteration 54240, loss = 3.31392
I0123 23:46:54.615589 29630 solver.cpp:253]     Train net output #0: loss = 3.31392 (* 1 = 3.31392 loss)
I0123 23:46:54.615595 29630 sgd_solver.cpp:106] Iteration 54240, lr = 0.01
I0123 23:47:01.828974 29630 solver.cpp:237] Iteration 54260, loss = 3.13334
I0123 23:47:01.829013 29630 solver.cpp:253]     Train net output #0: loss = 3.13334 (* 1 = 3.13334 loss)
I0123 23:47:01.829020 29630 sgd_solver.cpp:106] Iteration 54260, lr = 0.01
I0123 23:47:09.078455 29630 solver.cpp:237] Iteration 54280, loss = 3.54799
I0123 23:47:09.078495 29630 solver.cpp:253]     Train net output #0: loss = 3.54799 (* 1 = 3.54799 loss)
I0123 23:47:09.078501 29630 sgd_solver.cpp:106] Iteration 54280, lr = 0.01
I0123 23:47:16.354212 29630 solver.cpp:237] Iteration 54300, loss = 3.42747
I0123 23:47:16.354365 29630 solver.cpp:253]     Train net output #0: loss = 3.42747 (* 1 = 3.42747 loss)
I0123 23:47:16.354373 29630 sgd_solver.cpp:106] Iteration 54300, lr = 0.01
I0123 23:47:23.620483 29630 solver.cpp:237] Iteration 54320, loss = 3.29816
I0123 23:47:23.620522 29630 solver.cpp:253]     Train net output #0: loss = 3.29816 (* 1 = 3.29816 loss)
I0123 23:47:23.620527 29630 sgd_solver.cpp:106] Iteration 54320, lr = 0.01
I0123 23:47:25.486559 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 23:47:30.847482 29630 solver.cpp:237] Iteration 54340, loss = 3.26909
I0123 23:47:30.847522 29630 solver.cpp:253]     Train net output #0: loss = 3.26909 (* 1 = 3.26909 loss)
I0123 23:47:30.847527 29630 sgd_solver.cpp:106] Iteration 54340, lr = 0.01
I0123 23:47:38.110462 29630 solver.cpp:237] Iteration 54360, loss = 3.40927
I0123 23:47:38.110502 29630 solver.cpp:253]     Train net output #0: loss = 3.40927 (* 1 = 3.40927 loss)
I0123 23:47:38.110507 29630 sgd_solver.cpp:106] Iteration 54360, lr = 0.01
I0123 23:47:45.410131 29630 solver.cpp:237] Iteration 54380, loss = 3.27256
I0123 23:47:45.410184 29630 solver.cpp:253]     Train net output #0: loss = 3.27256 (* 1 = 3.27256 loss)
I0123 23:47:45.410189 29630 sgd_solver.cpp:106] Iteration 54380, lr = 0.01
I0123 23:47:52.629542 29630 solver.cpp:237] Iteration 54400, loss = 3.17314
I0123 23:47:52.629679 29630 solver.cpp:253]     Train net output #0: loss = 3.17314 (* 1 = 3.17314 loss)
I0123 23:47:52.629688 29630 sgd_solver.cpp:106] Iteration 54400, lr = 0.01
I0123 23:47:59.924098 29630 solver.cpp:237] Iteration 54420, loss = 3.52588
I0123 23:47:59.924136 29630 solver.cpp:253]     Train net output #0: loss = 3.52588 (* 1 = 3.52588 loss)
I0123 23:47:59.924144 29630 sgd_solver.cpp:106] Iteration 54420, lr = 0.01
I0123 23:48:07.211344 29630 solver.cpp:237] Iteration 54440, loss = 3.56553
I0123 23:48:07.211381 29630 solver.cpp:253]     Train net output #0: loss = 3.56553 (* 1 = 3.56553 loss)
I0123 23:48:07.211387 29630 sgd_solver.cpp:106] Iteration 54440, lr = 0.01
I0123 23:48:14.472865 29630 solver.cpp:237] Iteration 54460, loss = 3.40882
I0123 23:48:14.472905 29630 solver.cpp:253]     Train net output #0: loss = 3.40882 (* 1 = 3.40882 loss)
I0123 23:48:14.472913 29630 sgd_solver.cpp:106] Iteration 54460, lr = 0.01
I0123 23:48:21.724078 29630 solver.cpp:237] Iteration 54480, loss = 3.36067
I0123 23:48:21.724117 29630 solver.cpp:253]     Train net output #0: loss = 3.36067 (* 1 = 3.36067 loss)
I0123 23:48:21.724123 29630 sgd_solver.cpp:106] Iteration 54480, lr = 0.01
I0123 23:48:28.946249 29630 solver.cpp:237] Iteration 54500, loss = 3.32894
I0123 23:48:28.946339 29630 solver.cpp:253]     Train net output #0: loss = 3.32894 (* 1 = 3.32894 loss)
I0123 23:48:28.946347 29630 sgd_solver.cpp:106] Iteration 54500, lr = 0.01
I0123 23:48:36.195490 29630 solver.cpp:237] Iteration 54520, loss = 3.29357
I0123 23:48:36.195529 29630 solver.cpp:253]     Train net output #0: loss = 3.29357 (* 1 = 3.29357 loss)
I0123 23:48:36.195535 29630 sgd_solver.cpp:106] Iteration 54520, lr = 0.01
I0123 23:48:43.478150 29630 solver.cpp:237] Iteration 54540, loss = 3.46452
I0123 23:48:43.478188 29630 solver.cpp:253]     Train net output #0: loss = 3.46452 (* 1 = 3.46452 loss)
I0123 23:48:43.478193 29630 sgd_solver.cpp:106] Iteration 54540, lr = 0.01
I0123 23:48:50.751850 29630 solver.cpp:237] Iteration 54560, loss = 3.58659
I0123 23:48:50.751890 29630 solver.cpp:253]     Train net output #0: loss = 3.58659 (* 1 = 3.58659 loss)
I0123 23:48:50.751896 29630 sgd_solver.cpp:106] Iteration 54560, lr = 0.01
I0123 23:48:58.010696 29630 solver.cpp:237] Iteration 54580, loss = 3.18085
I0123 23:48:58.010736 29630 solver.cpp:253]     Train net output #0: loss = 3.18085 (* 1 = 3.18085 loss)
I0123 23:48:58.010742 29630 sgd_solver.cpp:106] Iteration 54580, lr = 0.01
I0123 23:49:05.265060 29630 solver.cpp:237] Iteration 54600, loss = 3.46205
I0123 23:49:05.265179 29630 solver.cpp:253]     Train net output #0: loss = 3.46205 (* 1 = 3.46205 loss)
I0123 23:49:05.265187 29630 sgd_solver.cpp:106] Iteration 54600, lr = 0.01
I0123 23:49:12.517351 29630 solver.cpp:237] Iteration 54620, loss = 3.43383
I0123 23:49:12.517390 29630 solver.cpp:253]     Train net output #0: loss = 3.43383 (* 1 = 3.43383 loss)
I0123 23:49:12.517396 29630 sgd_solver.cpp:106] Iteration 54620, lr = 0.01
I0123 23:49:19.757668 29630 solver.cpp:237] Iteration 54640, loss = 3.37783
I0123 23:49:19.757707 29630 solver.cpp:253]     Train net output #0: loss = 3.37783 (* 1 = 3.37783 loss)
I0123 23:49:19.757714 29630 sgd_solver.cpp:106] Iteration 54640, lr = 0.01
I0123 23:49:27.061604 29630 solver.cpp:237] Iteration 54660, loss = 3.31222
I0123 23:49:27.061643 29630 solver.cpp:253]     Train net output #0: loss = 3.31222 (* 1 = 3.31222 loss)
I0123 23:49:27.061652 29630 sgd_solver.cpp:106] Iteration 54660, lr = 0.01
I0123 23:49:34.336127 29630 solver.cpp:237] Iteration 54680, loss = 3.36185
I0123 23:49:34.336165 29630 solver.cpp:253]     Train net output #0: loss = 3.36185 (* 1 = 3.36185 loss)
I0123 23:49:34.336172 29630 sgd_solver.cpp:106] Iteration 54680, lr = 0.01
I0123 23:49:41.561792 29630 solver.cpp:237] Iteration 54700, loss = 3.44154
I0123 23:49:41.561929 29630 solver.cpp:253]     Train net output #0: loss = 3.44154 (* 1 = 3.44154 loss)
I0123 23:49:41.561939 29630 sgd_solver.cpp:106] Iteration 54700, lr = 0.01
I0123 23:49:48.820899 29630 solver.cpp:237] Iteration 54720, loss = 3.38552
I0123 23:49:48.820937 29630 solver.cpp:253]     Train net output #0: loss = 3.38552 (* 1 = 3.38552 loss)
I0123 23:49:48.820943 29630 sgd_solver.cpp:106] Iteration 54720, lr = 0.01
I0123 23:49:56.051241 29630 solver.cpp:237] Iteration 54740, loss = 3.28769
I0123 23:49:56.051280 29630 solver.cpp:253]     Train net output #0: loss = 3.28769 (* 1 = 3.28769 loss)
I0123 23:49:56.051286 29630 sgd_solver.cpp:106] Iteration 54740, lr = 0.01
I0123 23:50:03.343433 29630 solver.cpp:237] Iteration 54760, loss = 3.35729
I0123 23:50:03.343472 29630 solver.cpp:253]     Train net output #0: loss = 3.35729 (* 1 = 3.35729 loss)
I0123 23:50:03.343478 29630 sgd_solver.cpp:106] Iteration 54760, lr = 0.01
I0123 23:50:10.623355 29630 solver.cpp:237] Iteration 54780, loss = 3.17517
I0123 23:50:10.623394 29630 solver.cpp:253]     Train net output #0: loss = 3.17517 (* 1 = 3.17517 loss)
I0123 23:50:10.623399 29630 sgd_solver.cpp:106] Iteration 54780, lr = 0.01
I0123 23:50:17.935993 29630 solver.cpp:237] Iteration 54800, loss = 3.16986
I0123 23:50:17.936106 29630 solver.cpp:253]     Train net output #0: loss = 3.16986 (* 1 = 3.16986 loss)
I0123 23:50:17.936113 29630 sgd_solver.cpp:106] Iteration 54800, lr = 0.01
I0123 23:50:25.155014 29630 solver.cpp:237] Iteration 54820, loss = 3.22249
I0123 23:50:25.155052 29630 solver.cpp:253]     Train net output #0: loss = 3.22249 (* 1 = 3.22249 loss)
I0123 23:50:25.155060 29630 sgd_solver.cpp:106] Iteration 54820, lr = 0.01
I0123 23:50:32.457130 29630 solver.cpp:237] Iteration 54840, loss = 3.28742
I0123 23:50:32.457170 29630 solver.cpp:253]     Train net output #0: loss = 3.28742 (* 1 = 3.28742 loss)
I0123 23:50:32.457176 29630 sgd_solver.cpp:106] Iteration 54840, lr = 0.01
I0123 23:50:39.689965 29630 solver.cpp:237] Iteration 54860, loss = 3.52172
I0123 23:50:39.690001 29630 solver.cpp:253]     Train net output #0: loss = 3.52172 (* 1 = 3.52172 loss)
I0123 23:50:39.690008 29630 sgd_solver.cpp:106] Iteration 54860, lr = 0.01
I0123 23:50:46.902328 29630 solver.cpp:237] Iteration 54880, loss = 3.32671
I0123 23:50:46.902366 29630 solver.cpp:253]     Train net output #0: loss = 3.32671 (* 1 = 3.32671 loss)
I0123 23:50:46.902374 29630 sgd_solver.cpp:106] Iteration 54880, lr = 0.01
I0123 23:50:54.185186 29630 solver.cpp:237] Iteration 54900, loss = 3.4276
I0123 23:50:54.185334 29630 solver.cpp:253]     Train net output #0: loss = 3.4276 (* 1 = 3.4276 loss)
I0123 23:50:54.185343 29630 sgd_solver.cpp:106] Iteration 54900, lr = 0.01
I0123 23:51:01.490926 29630 solver.cpp:237] Iteration 54920, loss = 3.21891
I0123 23:51:01.490963 29630 solver.cpp:253]     Train net output #0: loss = 3.21891 (* 1 = 3.21891 loss)
I0123 23:51:01.490969 29630 sgd_solver.cpp:106] Iteration 54920, lr = 0.01
I0123 23:51:08.753031 29630 solver.cpp:237] Iteration 54940, loss = 3.57659
I0123 23:51:08.753068 29630 solver.cpp:253]     Train net output #0: loss = 3.57659 (* 1 = 3.57659 loss)
I0123 23:51:08.753074 29630 sgd_solver.cpp:106] Iteration 54940, lr = 0.01
I0123 23:51:16.022869 29630 solver.cpp:237] Iteration 54960, loss = 3.39824
I0123 23:51:16.022907 29630 solver.cpp:253]     Train net output #0: loss = 3.39824 (* 1 = 3.39824 loss)
I0123 23:51:16.022912 29630 sgd_solver.cpp:106] Iteration 54960, lr = 0.01
I0123 23:51:23.348470 29630 solver.cpp:237] Iteration 54980, loss = 3.4133
I0123 23:51:23.348510 29630 solver.cpp:253]     Train net output #0: loss = 3.4133 (* 1 = 3.4133 loss)
I0123 23:51:23.348515 29630 sgd_solver.cpp:106] Iteration 54980, lr = 0.01
I0123 23:51:30.282248 29630 solver.cpp:341] Iteration 55000, Testing net (#0)
I0123 23:51:54.463564 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 23:52:44.122112 29630 solver.cpp:409]     Test net output #0: accuracy = 0.3173
I0123 23:52:44.123158 29630 solver.cpp:409]     Test net output #1: loss = 3.2484 (* 1 = 3.2484 loss)
I0123 23:52:44.164602 29630 solver.cpp:237] Iteration 55000, loss = 3.44478
I0123 23:52:44.164640 29630 solver.cpp:253]     Train net output #0: loss = 3.44478 (* 1 = 3.44478 loss)
I0123 23:52:44.164646 29630 sgd_solver.cpp:106] Iteration 55000, lr = 0.01
I0123 23:52:50.747738 29630 solver.cpp:237] Iteration 55020, loss = 3.68219
I0123 23:52:50.747776 29630 solver.cpp:253]     Train net output #0: loss = 3.68219 (* 1 = 3.68219 loss)
I0123 23:52:50.747782 29630 sgd_solver.cpp:106] Iteration 55020, lr = 0.01
I0123 23:52:57.999675 29630 solver.cpp:237] Iteration 55040, loss = 3.24566
I0123 23:52:57.999713 29630 solver.cpp:253]     Train net output #0: loss = 3.24566 (* 1 = 3.24566 loss)
I0123 23:52:57.999719 29630 sgd_solver.cpp:106] Iteration 55040, lr = 0.01
I0123 23:53:05.227731 29630 solver.cpp:237] Iteration 55060, loss = 3.24714
I0123 23:53:05.227771 29630 solver.cpp:253]     Train net output #0: loss = 3.24714 (* 1 = 3.24714 loss)
I0123 23:53:05.227777 29630 sgd_solver.cpp:106] Iteration 55060, lr = 0.01
I0123 23:53:12.518735 29630 solver.cpp:237] Iteration 55080, loss = 3.3429
I0123 23:53:12.518776 29630 solver.cpp:253]     Train net output #0: loss = 3.3429 (* 1 = 3.3429 loss)
I0123 23:53:12.518782 29630 sgd_solver.cpp:106] Iteration 55080, lr = 0.01
I0123 23:53:19.823449 29630 solver.cpp:237] Iteration 55100, loss = 3.33591
I0123 23:53:19.823575 29630 solver.cpp:253]     Train net output #0: loss = 3.33591 (* 1 = 3.33591 loss)
I0123 23:53:19.823583 29630 sgd_solver.cpp:106] Iteration 55100, lr = 0.01
I0123 23:53:27.123558 29630 solver.cpp:237] Iteration 55120, loss = 3.41914
I0123 23:53:27.123605 29630 solver.cpp:253]     Train net output #0: loss = 3.41914 (* 1 = 3.41914 loss)
I0123 23:53:27.123612 29630 sgd_solver.cpp:106] Iteration 55120, lr = 0.01
I0123 23:53:34.477579 29630 solver.cpp:237] Iteration 55140, loss = 3.19786
I0123 23:53:34.477617 29630 solver.cpp:253]     Train net output #0: loss = 3.19786 (* 1 = 3.19786 loss)
I0123 23:53:34.477622 29630 sgd_solver.cpp:106] Iteration 55140, lr = 0.01
I0123 23:53:41.722877 29630 solver.cpp:237] Iteration 55160, loss = 3.4546
I0123 23:53:41.722913 29630 solver.cpp:253]     Train net output #0: loss = 3.4546 (* 1 = 3.4546 loss)
I0123 23:53:41.722919 29630 sgd_solver.cpp:106] Iteration 55160, lr = 0.01
I0123 23:53:48.970428 29630 solver.cpp:237] Iteration 55180, loss = 3.27631
I0123 23:53:48.970468 29630 solver.cpp:253]     Train net output #0: loss = 3.27631 (* 1 = 3.27631 loss)
I0123 23:53:48.970474 29630 sgd_solver.cpp:106] Iteration 55180, lr = 0.01
I0123 23:53:56.198824 29630 solver.cpp:237] Iteration 55200, loss = 3.11019
I0123 23:53:56.198978 29630 solver.cpp:253]     Train net output #0: loss = 3.11019 (* 1 = 3.11019 loss)
I0123 23:53:56.198987 29630 sgd_solver.cpp:106] Iteration 55200, lr = 0.01
I0123 23:54:03.463691 29630 solver.cpp:237] Iteration 55220, loss = 3.41403
I0123 23:54:03.463729 29630 solver.cpp:253]     Train net output #0: loss = 3.41403 (* 1 = 3.41403 loss)
I0123 23:54:03.463737 29630 sgd_solver.cpp:106] Iteration 55220, lr = 0.01
I0123 23:54:10.764783 29630 solver.cpp:237] Iteration 55240, loss = 3.16795
I0123 23:54:10.764822 29630 solver.cpp:253]     Train net output #0: loss = 3.16795 (* 1 = 3.16795 loss)
I0123 23:54:10.764828 29630 sgd_solver.cpp:106] Iteration 55240, lr = 0.01
I0123 23:54:18.046399 29630 solver.cpp:237] Iteration 55260, loss = 3.52309
I0123 23:54:18.046438 29630 solver.cpp:253]     Train net output #0: loss = 3.52309 (* 1 = 3.52309 loss)
I0123 23:54:18.046444 29630 sgd_solver.cpp:106] Iteration 55260, lr = 0.01
I0123 23:54:25.345013 29630 solver.cpp:237] Iteration 55280, loss = 3.40138
I0123 23:54:25.345054 29630 solver.cpp:253]     Train net output #0: loss = 3.40138 (* 1 = 3.40138 loss)
I0123 23:54:25.345060 29630 sgd_solver.cpp:106] Iteration 55280, lr = 0.01
I0123 23:54:32.643373 29630 solver.cpp:237] Iteration 55300, loss = 3.59161
I0123 23:54:32.643535 29630 solver.cpp:253]     Train net output #0: loss = 3.59161 (* 1 = 3.59161 loss)
I0123 23:54:32.643543 29630 sgd_solver.cpp:106] Iteration 55300, lr = 0.01
I0123 23:54:39.879396 29630 solver.cpp:237] Iteration 55320, loss = 3.29344
I0123 23:54:39.879436 29630 solver.cpp:253]     Train net output #0: loss = 3.29344 (* 1 = 3.29344 loss)
I0123 23:54:39.879443 29630 sgd_solver.cpp:106] Iteration 55320, lr = 0.01
I0123 23:54:43.934358 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 23:54:47.132083 29630 solver.cpp:237] Iteration 55340, loss = 3.2872
I0123 23:54:47.132122 29630 solver.cpp:253]     Train net output #0: loss = 3.2872 (* 1 = 3.2872 loss)
I0123 23:54:47.132128 29630 sgd_solver.cpp:106] Iteration 55340, lr = 0.01
I0123 23:54:54.369758 29630 solver.cpp:237] Iteration 55360, loss = 3.32704
I0123 23:54:54.369824 29630 solver.cpp:253]     Train net output #0: loss = 3.32704 (* 1 = 3.32704 loss)
I0123 23:54:54.369832 29630 sgd_solver.cpp:106] Iteration 55360, lr = 0.01
I0123 23:55:01.654176 29630 solver.cpp:237] Iteration 55380, loss = 3.40664
I0123 23:55:01.654216 29630 solver.cpp:253]     Train net output #0: loss = 3.40664 (* 1 = 3.40664 loss)
I0123 23:55:01.654223 29630 sgd_solver.cpp:106] Iteration 55380, lr = 0.01
I0123 23:55:08.953881 29630 solver.cpp:237] Iteration 55400, loss = 3.53489
I0123 23:55:08.954035 29630 solver.cpp:253]     Train net output #0: loss = 3.53489 (* 1 = 3.53489 loss)
I0123 23:55:08.954043 29630 sgd_solver.cpp:106] Iteration 55400, lr = 0.01
I0123 23:55:16.235055 29630 solver.cpp:237] Iteration 55420, loss = 3.44188
I0123 23:55:16.235092 29630 solver.cpp:253]     Train net output #0: loss = 3.44188 (* 1 = 3.44188 loss)
I0123 23:55:16.235100 29630 sgd_solver.cpp:106] Iteration 55420, lr = 0.01
I0123 23:55:23.511435 29630 solver.cpp:237] Iteration 55440, loss = 3.46069
I0123 23:55:23.511472 29630 solver.cpp:253]     Train net output #0: loss = 3.46069 (* 1 = 3.46069 loss)
I0123 23:55:23.511479 29630 sgd_solver.cpp:106] Iteration 55440, lr = 0.01
I0123 23:55:30.742478 29630 solver.cpp:237] Iteration 55460, loss = 3.29521
I0123 23:55:30.742516 29630 solver.cpp:253]     Train net output #0: loss = 3.29521 (* 1 = 3.29521 loss)
I0123 23:55:30.742522 29630 sgd_solver.cpp:106] Iteration 55460, lr = 0.01
I0123 23:55:37.943285 29630 solver.cpp:237] Iteration 55480, loss = 3.26832
I0123 23:55:37.943325 29630 solver.cpp:253]     Train net output #0: loss = 3.26832 (* 1 = 3.26832 loss)
I0123 23:55:37.943331 29630 sgd_solver.cpp:106] Iteration 55480, lr = 0.01
I0123 23:55:45.184391 29630 solver.cpp:237] Iteration 55500, loss = 3.52711
I0123 23:55:45.184567 29630 solver.cpp:253]     Train net output #0: loss = 3.52711 (* 1 = 3.52711 loss)
I0123 23:55:45.184576 29630 sgd_solver.cpp:106] Iteration 55500, lr = 0.01
I0123 23:55:52.440078 29630 solver.cpp:237] Iteration 55520, loss = 3.22909
I0123 23:55:52.440116 29630 solver.cpp:253]     Train net output #0: loss = 3.22909 (* 1 = 3.22909 loss)
I0123 23:55:52.440122 29630 sgd_solver.cpp:106] Iteration 55520, lr = 0.01
I0123 23:55:59.728873 29630 solver.cpp:237] Iteration 55540, loss = 3.1469
I0123 23:55:59.728912 29630 solver.cpp:253]     Train net output #0: loss = 3.1469 (* 1 = 3.1469 loss)
I0123 23:55:59.728919 29630 sgd_solver.cpp:106] Iteration 55540, lr = 0.01
I0123 23:56:06.990640 29630 solver.cpp:237] Iteration 55560, loss = 3.31827
I0123 23:56:06.990679 29630 solver.cpp:253]     Train net output #0: loss = 3.31827 (* 1 = 3.31827 loss)
I0123 23:56:06.990684 29630 sgd_solver.cpp:106] Iteration 55560, lr = 0.01
I0123 23:56:14.215397 29630 solver.cpp:237] Iteration 55580, loss = 3.37799
I0123 23:56:14.215435 29630 solver.cpp:253]     Train net output #0: loss = 3.37799 (* 1 = 3.37799 loss)
I0123 23:56:14.215441 29630 sgd_solver.cpp:106] Iteration 55580, lr = 0.01
I0123 23:56:21.436336 29630 solver.cpp:237] Iteration 55600, loss = 3.4906
I0123 23:56:21.436455 29630 solver.cpp:253]     Train net output #0: loss = 3.4906 (* 1 = 3.4906 loss)
I0123 23:56:21.436462 29630 sgd_solver.cpp:106] Iteration 55600, lr = 0.01
I0123 23:56:28.715677 29630 solver.cpp:237] Iteration 55620, loss = 3.22277
I0123 23:56:28.715715 29630 solver.cpp:253]     Train net output #0: loss = 3.22277 (* 1 = 3.22277 loss)
I0123 23:56:28.715721 29630 sgd_solver.cpp:106] Iteration 55620, lr = 0.01
I0123 23:56:35.943594 29630 solver.cpp:237] Iteration 55640, loss = 3.24209
I0123 23:56:35.943632 29630 solver.cpp:253]     Train net output #0: loss = 3.24209 (* 1 = 3.24209 loss)
I0123 23:56:35.943639 29630 sgd_solver.cpp:106] Iteration 55640, lr = 0.01
I0123 23:56:43.196302 29630 solver.cpp:237] Iteration 55660, loss = 3.46458
I0123 23:56:43.196342 29630 solver.cpp:253]     Train net output #0: loss = 3.46458 (* 1 = 3.46458 loss)
I0123 23:56:43.196348 29630 sgd_solver.cpp:106] Iteration 55660, lr = 0.01
I0123 23:56:50.472841 29630 solver.cpp:237] Iteration 55680, loss = 3.31246
I0123 23:56:50.472878 29630 solver.cpp:253]     Train net output #0: loss = 3.31246 (* 1 = 3.31246 loss)
I0123 23:56:50.472884 29630 sgd_solver.cpp:106] Iteration 55680, lr = 0.01
I0123 23:56:57.674216 29630 solver.cpp:237] Iteration 55700, loss = 3.17072
I0123 23:56:57.674361 29630 solver.cpp:253]     Train net output #0: loss = 3.17072 (* 1 = 3.17072 loss)
I0123 23:56:57.674370 29630 sgd_solver.cpp:106] Iteration 55700, lr = 0.01
I0123 23:57:04.943775 29630 solver.cpp:237] Iteration 55720, loss = 3.35818
I0123 23:57:04.943814 29630 solver.cpp:253]     Train net output #0: loss = 3.35818 (* 1 = 3.35818 loss)
I0123 23:57:04.943820 29630 sgd_solver.cpp:106] Iteration 55720, lr = 0.01
I0123 23:57:12.150960 29630 solver.cpp:237] Iteration 55740, loss = 3.36891
I0123 23:57:12.151000 29630 solver.cpp:253]     Train net output #0: loss = 3.36891 (* 1 = 3.36891 loss)
I0123 23:57:12.151006 29630 sgd_solver.cpp:106] Iteration 55740, lr = 0.01
I0123 23:57:19.412245 29630 solver.cpp:237] Iteration 55760, loss = 3.24915
I0123 23:57:19.412284 29630 solver.cpp:253]     Train net output #0: loss = 3.24915 (* 1 = 3.24915 loss)
I0123 23:57:19.412292 29630 sgd_solver.cpp:106] Iteration 55760, lr = 0.01
I0123 23:57:26.641860 29630 solver.cpp:237] Iteration 55780, loss = 3.26792
I0123 23:57:26.641898 29630 solver.cpp:253]     Train net output #0: loss = 3.26792 (* 1 = 3.26792 loss)
I0123 23:57:26.641906 29630 sgd_solver.cpp:106] Iteration 55780, lr = 0.01
I0123 23:57:33.881307 29630 solver.cpp:237] Iteration 55800, loss = 3.35678
I0123 23:57:33.881470 29630 solver.cpp:253]     Train net output #0: loss = 3.35678 (* 1 = 3.35678 loss)
I0123 23:57:33.881479 29630 sgd_solver.cpp:106] Iteration 55800, lr = 0.01
I0123 23:57:41.101349 29630 solver.cpp:237] Iteration 55820, loss = 3.27214
I0123 23:57:41.101388 29630 solver.cpp:253]     Train net output #0: loss = 3.27214 (* 1 = 3.27214 loss)
I0123 23:57:41.101394 29630 sgd_solver.cpp:106] Iteration 55820, lr = 0.01
I0123 23:57:48.278528 29630 solver.cpp:237] Iteration 55840, loss = 3.48635
I0123 23:57:48.278568 29630 solver.cpp:253]     Train net output #0: loss = 3.48635 (* 1 = 3.48635 loss)
I0123 23:57:48.278575 29630 sgd_solver.cpp:106] Iteration 55840, lr = 0.01
I0123 23:57:55.509325 29630 solver.cpp:237] Iteration 55860, loss = 3.29788
I0123 23:57:55.509364 29630 solver.cpp:253]     Train net output #0: loss = 3.29788 (* 1 = 3.29788 loss)
I0123 23:57:55.509371 29630 sgd_solver.cpp:106] Iteration 55860, lr = 0.01
I0123 23:58:02.784657 29630 solver.cpp:237] Iteration 55880, loss = 3.33515
I0123 23:58:02.784695 29630 solver.cpp:253]     Train net output #0: loss = 3.33515 (* 1 = 3.33515 loss)
I0123 23:58:02.784703 29630 sgd_solver.cpp:106] Iteration 55880, lr = 0.01
I0123 23:58:10.085049 29630 solver.cpp:237] Iteration 55900, loss = 3.44831
I0123 23:58:10.085214 29630 solver.cpp:253]     Train net output #0: loss = 3.44831 (* 1 = 3.44831 loss)
I0123 23:58:10.085222 29630 sgd_solver.cpp:106] Iteration 55900, lr = 0.01
I0123 23:58:17.304658 29630 solver.cpp:237] Iteration 55920, loss = 3.404
I0123 23:58:17.304697 29630 solver.cpp:253]     Train net output #0: loss = 3.404 (* 1 = 3.404 loss)
I0123 23:58:17.304702 29630 sgd_solver.cpp:106] Iteration 55920, lr = 0.01
I0123 23:58:24.603050 29630 solver.cpp:237] Iteration 55940, loss = 3.16432
I0123 23:58:24.603087 29630 solver.cpp:253]     Train net output #0: loss = 3.16432 (* 1 = 3.16432 loss)
I0123 23:58:24.603094 29630 sgd_solver.cpp:106] Iteration 55940, lr = 0.01
I0123 23:58:31.810674 29630 solver.cpp:237] Iteration 55960, loss = 3.38838
I0123 23:58:31.810711 29630 solver.cpp:253]     Train net output #0: loss = 3.38838 (* 1 = 3.38838 loss)
I0123 23:58:31.810727 29630 sgd_solver.cpp:106] Iteration 55960, lr = 0.01
I0123 23:58:39.041208 29630 solver.cpp:237] Iteration 55980, loss = 3.41725
I0123 23:58:39.041247 29630 solver.cpp:253]     Train net output #0: loss = 3.41725 (* 1 = 3.41725 loss)
I0123 23:58:39.041254 29630 sgd_solver.cpp:106] Iteration 55980, lr = 0.01
I0123 23:58:46.031272 29630 solver.cpp:341] Iteration 56000, Testing net (#0)
I0123 23:59:10.609077 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0123 23:59:59.751946 29630 solver.cpp:409]     Test net output #0: accuracy = 0.31962
I0123 23:59:59.752061 29630 solver.cpp:409]     Test net output #1: loss = 3.2408 (* 1 = 3.2408 loss)
I0123 23:59:59.792803 29630 solver.cpp:237] Iteration 56000, loss = 3.49838
I0123 23:59:59.792842 29630 solver.cpp:253]     Train net output #0: loss = 3.49838 (* 1 = 3.49838 loss)
I0123 23:59:59.792850 29630 sgd_solver.cpp:106] Iteration 56000, lr = 0.01
I0124 00:00:06.320070 29630 solver.cpp:237] Iteration 56020, loss = 3.53333
I0124 00:00:06.320107 29630 solver.cpp:253]     Train net output #0: loss = 3.53333 (* 1 = 3.53333 loss)
I0124 00:00:06.320113 29630 sgd_solver.cpp:106] Iteration 56020, lr = 0.01
I0124 00:00:13.568017 29630 solver.cpp:237] Iteration 56040, loss = 3.35971
I0124 00:00:13.568056 29630 solver.cpp:253]     Train net output #0: loss = 3.35971 (* 1 = 3.35971 loss)
I0124 00:00:13.568061 29630 sgd_solver.cpp:106] Iteration 56040, lr = 0.01
I0124 00:00:20.813242 29630 solver.cpp:237] Iteration 56060, loss = 3.31004
I0124 00:00:20.813282 29630 solver.cpp:253]     Train net output #0: loss = 3.31004 (* 1 = 3.31004 loss)
I0124 00:00:20.813287 29630 sgd_solver.cpp:106] Iteration 56060, lr = 0.01
I0124 00:00:28.034842 29630 solver.cpp:237] Iteration 56080, loss = 3.40232
I0124 00:00:28.034880 29630 solver.cpp:253]     Train net output #0: loss = 3.40232 (* 1 = 3.40232 loss)
I0124 00:00:28.034886 29630 sgd_solver.cpp:106] Iteration 56080, lr = 0.01
I0124 00:00:35.260504 29630 solver.cpp:237] Iteration 56100, loss = 3.40609
I0124 00:00:35.260627 29630 solver.cpp:253]     Train net output #0: loss = 3.40609 (* 1 = 3.40609 loss)
I0124 00:00:35.260633 29630 sgd_solver.cpp:106] Iteration 56100, lr = 0.01
I0124 00:00:42.537145 29630 solver.cpp:237] Iteration 56120, loss = 3.50777
I0124 00:00:42.537184 29630 solver.cpp:253]     Train net output #0: loss = 3.50777 (* 1 = 3.50777 loss)
I0124 00:00:42.537191 29630 sgd_solver.cpp:106] Iteration 56120, lr = 0.01
I0124 00:00:49.775473 29630 solver.cpp:237] Iteration 56140, loss = 3.3116
I0124 00:00:49.775511 29630 solver.cpp:253]     Train net output #0: loss = 3.3116 (* 1 = 3.3116 loss)
I0124 00:00:49.775517 29630 sgd_solver.cpp:106] Iteration 56140, lr = 0.01
I0124 00:00:57.055944 29630 solver.cpp:237] Iteration 56160, loss = 3.25188
I0124 00:00:57.055982 29630 solver.cpp:253]     Train net output #0: loss = 3.25188 (* 1 = 3.25188 loss)
I0124 00:00:57.055989 29630 sgd_solver.cpp:106] Iteration 56160, lr = 0.01
I0124 00:01:04.310377 29630 solver.cpp:237] Iteration 56180, loss = 3.44601
I0124 00:01:04.310415 29630 solver.cpp:253]     Train net output #0: loss = 3.44601 (* 1 = 3.44601 loss)
I0124 00:01:04.310422 29630 sgd_solver.cpp:106] Iteration 56180, lr = 0.01
I0124 00:01:11.595173 29630 solver.cpp:237] Iteration 56200, loss = 3.53048
I0124 00:01:11.595335 29630 solver.cpp:253]     Train net output #0: loss = 3.53048 (* 1 = 3.53048 loss)
I0124 00:01:11.595343 29630 sgd_solver.cpp:106] Iteration 56200, lr = 0.01
I0124 00:01:18.887470 29630 solver.cpp:237] Iteration 56220, loss = 3.64235
I0124 00:01:18.887508 29630 solver.cpp:253]     Train net output #0: loss = 3.64235 (* 1 = 3.64235 loss)
I0124 00:01:18.887514 29630 sgd_solver.cpp:106] Iteration 56220, lr = 0.01
I0124 00:01:26.158071 29630 solver.cpp:237] Iteration 56240, loss = 3.35185
I0124 00:01:26.158108 29630 solver.cpp:253]     Train net output #0: loss = 3.35185 (* 1 = 3.35185 loss)
I0124 00:01:26.158114 29630 sgd_solver.cpp:106] Iteration 56240, lr = 0.01
I0124 00:01:33.483722 29630 solver.cpp:237] Iteration 56260, loss = 3.35803
I0124 00:01:33.483762 29630 solver.cpp:253]     Train net output #0: loss = 3.35803 (* 1 = 3.35803 loss)
I0124 00:01:33.483768 29630 sgd_solver.cpp:106] Iteration 56260, lr = 0.01
I0124 00:01:40.773293 29630 solver.cpp:237] Iteration 56280, loss = 3.30693
I0124 00:01:40.773330 29630 solver.cpp:253]     Train net output #0: loss = 3.30693 (* 1 = 3.30693 loss)
I0124 00:01:40.773336 29630 sgd_solver.cpp:106] Iteration 56280, lr = 0.01
I0124 00:01:48.047648 29630 solver.cpp:237] Iteration 56300, loss = 3.28157
I0124 00:01:48.047827 29630 solver.cpp:253]     Train net output #0: loss = 3.28157 (* 1 = 3.28157 loss)
I0124 00:01:48.047837 29630 sgd_solver.cpp:106] Iteration 56300, lr = 0.01
I0124 00:01:55.323438 29630 solver.cpp:237] Iteration 56320, loss = 3.15583
I0124 00:01:55.323490 29630 solver.cpp:253]     Train net output #0: loss = 3.15583 (* 1 = 3.15583 loss)
I0124 00:01:55.323499 29630 sgd_solver.cpp:106] Iteration 56320, lr = 0.01
I0124 00:02:01.595001 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0124 00:02:02.615949 29630 solver.cpp:237] Iteration 56340, loss = 3.5107
I0124 00:02:02.615996 29630 solver.cpp:253]     Train net output #0: loss = 3.5107 (* 1 = 3.5107 loss)
I0124 00:02:02.616003 29630 sgd_solver.cpp:106] Iteration 56340, lr = 0.01
I0124 00:02:09.907694 29630 solver.cpp:237] Iteration 56360, loss = 3.24766
I0124 00:02:09.907733 29630 solver.cpp:253]     Train net output #0: loss = 3.24766 (* 1 = 3.24766 loss)
I0124 00:02:09.907739 29630 sgd_solver.cpp:106] Iteration 56360, lr = 0.01
I0124 00:02:17.207444 29630 solver.cpp:237] Iteration 56380, loss = 3.48548
I0124 00:02:17.207484 29630 solver.cpp:253]     Train net output #0: loss = 3.48548 (* 1 = 3.48548 loss)
I0124 00:02:17.207489 29630 sgd_solver.cpp:106] Iteration 56380, lr = 0.01
I0124 00:02:24.466361 29630 solver.cpp:237] Iteration 56400, loss = 3.529
I0124 00:02:24.466544 29630 solver.cpp:253]     Train net output #0: loss = 3.529 (* 1 = 3.529 loss)
I0124 00:02:24.466553 29630 sgd_solver.cpp:106] Iteration 56400, lr = 0.01
I0124 00:02:31.745445 29630 solver.cpp:237] Iteration 56420, loss = 3.50395
I0124 00:02:31.745482 29630 solver.cpp:253]     Train net output #0: loss = 3.50395 (* 1 = 3.50395 loss)
I0124 00:02:31.745489 29630 sgd_solver.cpp:106] Iteration 56420, lr = 0.01
I0124 00:02:39.036927 29630 solver.cpp:237] Iteration 56440, loss = 3.4231
I0124 00:02:39.036965 29630 solver.cpp:253]     Train net output #0: loss = 3.4231 (* 1 = 3.4231 loss)
I0124 00:02:39.036970 29630 sgd_solver.cpp:106] Iteration 56440, lr = 0.01
I0124 00:02:46.338176 29630 solver.cpp:237] Iteration 56460, loss = 3.21611
I0124 00:02:46.338214 29630 solver.cpp:253]     Train net output #0: loss = 3.21611 (* 1 = 3.21611 loss)
I0124 00:02:46.338220 29630 sgd_solver.cpp:106] Iteration 56460, lr = 0.01
I0124 00:02:53.661216 29630 solver.cpp:237] Iteration 56480, loss = 3.4874
I0124 00:02:53.661254 29630 solver.cpp:253]     Train net output #0: loss = 3.4874 (* 1 = 3.4874 loss)
I0124 00:02:53.661260 29630 sgd_solver.cpp:106] Iteration 56480, lr = 0.01
I0124 00:03:00.950935 29630 solver.cpp:237] Iteration 56500, loss = 3.04998
I0124 00:03:00.951112 29630 solver.cpp:253]     Train net output #0: loss = 3.04998 (* 1 = 3.04998 loss)
I0124 00:03:00.951119 29630 sgd_solver.cpp:106] Iteration 56500, lr = 0.01
I0124 00:03:08.151016 29630 solver.cpp:237] Iteration 56520, loss = 3.35389
I0124 00:03:08.151058 29630 solver.cpp:253]     Train net output #0: loss = 3.35389 (* 1 = 3.35389 loss)
I0124 00:03:08.151074 29630 sgd_solver.cpp:106] Iteration 56520, lr = 0.01
I0124 00:03:15.419322 29630 solver.cpp:237] Iteration 56540, loss = 3.47359
I0124 00:03:15.419361 29630 solver.cpp:253]     Train net output #0: loss = 3.47359 (* 1 = 3.47359 loss)
I0124 00:03:15.419368 29630 sgd_solver.cpp:106] Iteration 56540, lr = 0.01
I0124 00:03:22.688802 29630 solver.cpp:237] Iteration 56560, loss = 3.2327
I0124 00:03:22.688840 29630 solver.cpp:253]     Train net output #0: loss = 3.2327 (* 1 = 3.2327 loss)
I0124 00:03:22.688846 29630 sgd_solver.cpp:106] Iteration 56560, lr = 0.01
I0124 00:03:29.933110 29630 solver.cpp:237] Iteration 56580, loss = 3.39031
I0124 00:03:29.933150 29630 solver.cpp:253]     Train net output #0: loss = 3.39031 (* 1 = 3.39031 loss)
I0124 00:03:29.933156 29630 sgd_solver.cpp:106] Iteration 56580, lr = 0.01
I0124 00:03:37.211725 29630 solver.cpp:237] Iteration 56600, loss = 3.387
I0124 00:03:37.211940 29630 solver.cpp:253]     Train net output #0: loss = 3.387 (* 1 = 3.387 loss)
I0124 00:03:37.211947 29630 sgd_solver.cpp:106] Iteration 56600, lr = 0.01
I0124 00:03:44.459468 29630 solver.cpp:237] Iteration 56620, loss = 3.44702
I0124 00:03:44.459507 29630 solver.cpp:253]     Train net output #0: loss = 3.44702 (* 1 = 3.44702 loss)
I0124 00:03:44.459513 29630 sgd_solver.cpp:106] Iteration 56620, lr = 0.01
I0124 00:03:51.704285 29630 solver.cpp:237] Iteration 56640, loss = 3.28421
I0124 00:03:51.704324 29630 solver.cpp:253]     Train net output #0: loss = 3.28421 (* 1 = 3.28421 loss)
I0124 00:03:51.704330 29630 sgd_solver.cpp:106] Iteration 56640, lr = 0.01
I0124 00:03:58.992385 29630 solver.cpp:237] Iteration 56660, loss = 3.46221
I0124 00:03:58.992424 29630 solver.cpp:253]     Train net output #0: loss = 3.46221 (* 1 = 3.46221 loss)
I0124 00:03:58.992429 29630 sgd_solver.cpp:106] Iteration 56660, lr = 0.01
I0124 00:04:06.225428 29630 solver.cpp:237] Iteration 56680, loss = 3.42297
I0124 00:04:06.225466 29630 solver.cpp:253]     Train net output #0: loss = 3.42297 (* 1 = 3.42297 loss)
I0124 00:04:06.225473 29630 sgd_solver.cpp:106] Iteration 56680, lr = 0.01
I0124 00:04:13.507977 29630 solver.cpp:237] Iteration 56700, loss = 3.48421
I0124 00:04:13.508076 29630 solver.cpp:253]     Train net output #0: loss = 3.48421 (* 1 = 3.48421 loss)
I0124 00:04:13.508092 29630 sgd_solver.cpp:106] Iteration 56700, lr = 0.01
I0124 00:04:20.778234 29630 solver.cpp:237] Iteration 56720, loss = 3.33664
I0124 00:04:20.778271 29630 solver.cpp:253]     Train net output #0: loss = 3.33664 (* 1 = 3.33664 loss)
I0124 00:04:20.778277 29630 sgd_solver.cpp:106] Iteration 56720, lr = 0.01
I0124 00:04:28.045882 29630 solver.cpp:237] Iteration 56740, loss = 3.33151
I0124 00:04:28.045920 29630 solver.cpp:253]     Train net output #0: loss = 3.33151 (* 1 = 3.33151 loss)
I0124 00:04:28.045928 29630 sgd_solver.cpp:106] Iteration 56740, lr = 0.01
I0124 00:04:35.306381 29630 solver.cpp:237] Iteration 56760, loss = 3.31687
I0124 00:04:35.306419 29630 solver.cpp:253]     Train net output #0: loss = 3.31687 (* 1 = 3.31687 loss)
I0124 00:04:35.306424 29630 sgd_solver.cpp:106] Iteration 56760, lr = 0.01
I0124 00:04:42.561385 29630 solver.cpp:237] Iteration 56780, loss = 3.25538
I0124 00:04:42.561424 29630 solver.cpp:253]     Train net output #0: loss = 3.25538 (* 1 = 3.25538 loss)
I0124 00:04:42.561430 29630 sgd_solver.cpp:106] Iteration 56780, lr = 0.01
I0124 00:04:49.834477 29630 solver.cpp:237] Iteration 56800, loss = 3.45606
I0124 00:04:49.834641 29630 solver.cpp:253]     Train net output #0: loss = 3.45606 (* 1 = 3.45606 loss)
I0124 00:04:49.834660 29630 sgd_solver.cpp:106] Iteration 56800, lr = 0.01
I0124 00:04:57.119685 29630 solver.cpp:237] Iteration 56820, loss = 3.22922
I0124 00:04:57.119724 29630 solver.cpp:253]     Train net output #0: loss = 3.22922 (* 1 = 3.22922 loss)
I0124 00:04:57.119730 29630 sgd_solver.cpp:106] Iteration 56820, lr = 0.01
I0124 00:05:04.357563 29630 solver.cpp:237] Iteration 56840, loss = 3.49991
I0124 00:05:04.357605 29630 solver.cpp:253]     Train net output #0: loss = 3.49991 (* 1 = 3.49991 loss)
I0124 00:05:04.357611 29630 sgd_solver.cpp:106] Iteration 56840, lr = 0.01
I0124 00:05:11.618180 29630 solver.cpp:237] Iteration 56860, loss = 3.29441
I0124 00:05:11.618217 29630 solver.cpp:253]     Train net output #0: loss = 3.29441 (* 1 = 3.29441 loss)
I0124 00:05:11.618223 29630 sgd_solver.cpp:106] Iteration 56860, lr = 0.01
I0124 00:05:18.957273 29630 solver.cpp:237] Iteration 56880, loss = 3.36341
I0124 00:05:18.957311 29630 solver.cpp:253]     Train net output #0: loss = 3.36341 (* 1 = 3.36341 loss)
I0124 00:05:18.957319 29630 sgd_solver.cpp:106] Iteration 56880, lr = 0.01
I0124 00:05:26.231341 29630 solver.cpp:237] Iteration 56900, loss = 3.38132
I0124 00:05:26.231509 29630 solver.cpp:253]     Train net output #0: loss = 3.38132 (* 1 = 3.38132 loss)
I0124 00:05:26.231518 29630 sgd_solver.cpp:106] Iteration 56900, lr = 0.01
I0124 00:05:33.567031 29630 solver.cpp:237] Iteration 56920, loss = 3.30022
I0124 00:05:33.567070 29630 solver.cpp:253]     Train net output #0: loss = 3.30022 (* 1 = 3.30022 loss)
I0124 00:05:33.567077 29630 sgd_solver.cpp:106] Iteration 56920, lr = 0.01
I0124 00:05:40.849797 29630 solver.cpp:237] Iteration 56940, loss = 3.57951
I0124 00:05:40.849827 29630 solver.cpp:253]     Train net output #0: loss = 3.57951 (* 1 = 3.57951 loss)
I0124 00:05:40.849833 29630 sgd_solver.cpp:106] Iteration 56940, lr = 0.01
I0124 00:05:48.157606 29630 solver.cpp:237] Iteration 56960, loss = 3.32868
I0124 00:05:48.157645 29630 solver.cpp:253]     Train net output #0: loss = 3.32868 (* 1 = 3.32868 loss)
I0124 00:05:48.157652 29630 sgd_solver.cpp:106] Iteration 56960, lr = 0.01
I0124 00:05:55.401831 29630 solver.cpp:237] Iteration 56980, loss = 3.50959
I0124 00:05:55.401870 29630 solver.cpp:253]     Train net output #0: loss = 3.50959 (* 1 = 3.50959 loss)
I0124 00:05:55.401875 29630 sgd_solver.cpp:106] Iteration 56980, lr = 0.01
I0124 00:06:02.385272 29630 solver.cpp:341] Iteration 57000, Testing net (#0)
I0124 00:06:27.510831 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0124 00:07:16.436825 29630 solver.cpp:409]     Test net output #0: accuracy = 0.3177
I0124 00:07:16.436975 29630 solver.cpp:409]     Test net output #1: loss = 3.22606 (* 1 = 3.22606 loss)
I0124 00:07:16.477852 29630 solver.cpp:237] Iteration 57000, loss = 3.32199
I0124 00:07:16.477890 29630 solver.cpp:253]     Train net output #0: loss = 3.32199 (* 1 = 3.32199 loss)
I0124 00:07:16.477898 29630 sgd_solver.cpp:106] Iteration 57000, lr = 0.01
I0124 00:07:23.087956 29630 solver.cpp:237] Iteration 57020, loss = 3.41984
I0124 00:07:23.087995 29630 solver.cpp:253]     Train net output #0: loss = 3.41984 (* 1 = 3.41984 loss)
I0124 00:07:23.088001 29630 sgd_solver.cpp:106] Iteration 57020, lr = 0.01
I0124 00:07:30.382099 29630 solver.cpp:237] Iteration 57040, loss = 3.556
I0124 00:07:30.382138 29630 solver.cpp:253]     Train net output #0: loss = 3.556 (* 1 = 3.556 loss)
I0124 00:07:30.382143 29630 sgd_solver.cpp:106] Iteration 57040, lr = 0.01
I0124 00:07:37.587628 29630 solver.cpp:237] Iteration 57060, loss = 3.34403
I0124 00:07:37.587668 29630 solver.cpp:253]     Train net output #0: loss = 3.34403 (* 1 = 3.34403 loss)
I0124 00:07:37.587676 29630 sgd_solver.cpp:106] Iteration 57060, lr = 0.01
I0124 00:07:44.848850 29630 solver.cpp:237] Iteration 57080, loss = 3.41898
I0124 00:07:44.848887 29630 solver.cpp:253]     Train net output #0: loss = 3.41898 (* 1 = 3.41898 loss)
I0124 00:07:44.848894 29630 sgd_solver.cpp:106] Iteration 57080, lr = 0.01
I0124 00:07:52.140317 29630 solver.cpp:237] Iteration 57100, loss = 3.17325
I0124 00:07:52.140493 29630 solver.cpp:253]     Train net output #0: loss = 3.17325 (* 1 = 3.17325 loss)
I0124 00:07:52.140501 29630 sgd_solver.cpp:106] Iteration 57100, lr = 0.01
I0124 00:07:59.344089 29630 solver.cpp:237] Iteration 57120, loss = 3.30728
I0124 00:07:59.344126 29630 solver.cpp:253]     Train net output #0: loss = 3.30728 (* 1 = 3.30728 loss)
I0124 00:07:59.344141 29630 sgd_solver.cpp:106] Iteration 57120, lr = 0.01
I0124 00:08:06.562404 29630 solver.cpp:237] Iteration 57140, loss = 3.14441
I0124 00:08:06.562441 29630 solver.cpp:253]     Train net output #0: loss = 3.14441 (* 1 = 3.14441 loss)
I0124 00:08:06.562448 29630 sgd_solver.cpp:106] Iteration 57140, lr = 0.01
I0124 00:08:13.786216 29630 solver.cpp:237] Iteration 57160, loss = 3.33396
I0124 00:08:13.786255 29630 solver.cpp:253]     Train net output #0: loss = 3.33396 (* 1 = 3.33396 loss)
I0124 00:08:13.786262 29630 sgd_solver.cpp:106] Iteration 57160, lr = 0.01
I0124 00:08:21.081853 29630 solver.cpp:237] Iteration 57180, loss = 3.37803
I0124 00:08:21.081892 29630 solver.cpp:253]     Train net output #0: loss = 3.37803 (* 1 = 3.37803 loss)
I0124 00:08:21.081897 29630 sgd_solver.cpp:106] Iteration 57180, lr = 0.01
I0124 00:08:28.377596 29630 solver.cpp:237] Iteration 57200, loss = 3.30797
I0124 00:08:28.377753 29630 solver.cpp:253]     Train net output #0: loss = 3.30797 (* 1 = 3.30797 loss)
I0124 00:08:28.377759 29630 sgd_solver.cpp:106] Iteration 57200, lr = 0.01
I0124 00:08:35.599767 29630 solver.cpp:237] Iteration 57220, loss = 3.25742
I0124 00:08:35.599805 29630 solver.cpp:253]     Train net output #0: loss = 3.25742 (* 1 = 3.25742 loss)
I0124 00:08:35.599812 29630 sgd_solver.cpp:106] Iteration 57220, lr = 0.01
I0124 00:08:42.854099 29630 solver.cpp:237] Iteration 57240, loss = 3.40455
I0124 00:08:42.854137 29630 solver.cpp:253]     Train net output #0: loss = 3.40455 (* 1 = 3.40455 loss)
I0124 00:08:42.854143 29630 sgd_solver.cpp:106] Iteration 57240, lr = 0.01
I0124 00:08:50.106586 29630 solver.cpp:237] Iteration 57260, loss = 3.43249
I0124 00:08:50.106626 29630 solver.cpp:253]     Train net output #0: loss = 3.43249 (* 1 = 3.43249 loss)
I0124 00:08:50.106631 29630 sgd_solver.cpp:106] Iteration 57260, lr = 0.01
I0124 00:08:57.344080 29630 solver.cpp:237] Iteration 57280, loss = 3.40762
I0124 00:08:57.344120 29630 solver.cpp:253]     Train net output #0: loss = 3.40762 (* 1 = 3.40762 loss)
I0124 00:08:57.344126 29630 sgd_solver.cpp:106] Iteration 57280, lr = 0.01
I0124 00:09:04.634065 29630 solver.cpp:237] Iteration 57300, loss = 3.22801
I0124 00:09:04.634166 29630 solver.cpp:253]     Train net output #0: loss = 3.22801 (* 1 = 3.22801 loss)
I0124 00:09:04.634183 29630 sgd_solver.cpp:106] Iteration 57300, lr = 0.01
I0124 00:09:11.878602 29630 solver.cpp:237] Iteration 57320, loss = 3.40167
I0124 00:09:11.878640 29630 solver.cpp:253]     Train net output #0: loss = 3.40167 (* 1 = 3.40167 loss)
I0124 00:09:11.878646 29630 sgd_solver.cpp:106] Iteration 57320, lr = 0.01
I0124 00:09:19.140089 29630 solver.cpp:237] Iteration 57340, loss = 3.21961
I0124 00:09:19.140128 29630 solver.cpp:253]     Train net output #0: loss = 3.21961 (* 1 = 3.21961 loss)
I0124 00:09:19.140135 29630 sgd_solver.cpp:106] Iteration 57340, lr = 0.01
I0124 00:09:20.313498 29630 blocking_queue.cpp:50] Data layer prefetch queue empty
I0124 00:09:26.422132 29630 solver.cpp:237] Iteration 57360, loss = 3.32088
I0124 00:09:26.422171 29630 solver.cpp:253]     Train net output #0: loss = 3.32088 (* 1 = 3.32088 loss)
I0124 00:09:26.422178 29630 sgd_solver.cpp:106] Iteration 57360, lr = 0.01
I0124 00:09:33.710481 29630 solver.cpp:237] Iteration 57380, loss = 3.54442
I0124 00:09:33.710523 29630 solver.cpp:253]     Train net output #0: loss = 3.54442 (* 1 = 3.54442 loss)
I0124 00:09:33.710531 29630 sgd_solver.cpp:106] Iteration 57380, lr = 0.01
