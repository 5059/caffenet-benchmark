I0601 11:49:58.885972 24067 upgrade_proto.cpp:990] Attempting to upgrade input file specified using deprecated 'solver_type' field (enum)': caffenet_lsuv_no_lrn_BatchNormAfter_TanH.prototxt
I0601 11:49:58.886313 24067 upgrade_proto.cpp:997] Successfully upgraded file specified using deprecated 'solver_type' field (enum) to 'type' field (string).
W0601 11:49:58.886334 24067 upgrade_proto.cpp:999] Note that future Caffe releases will only support 'type' field (string) for a solver's type.
I0601 11:49:58.886471 24067 caffe.cpp:184] Using GPUs 2
I0601 11:49:59.216919 24067 solver.cpp:48] Initializing solver from parameters: 
test_iter: 1000
test_interval: 1000
base_lr: 0.01
display: 20
max_iter: 320000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 100000
snapshot: 10000
snapshot_prefix: "snapshots/caffenet128_no_lrn_lsuv_bn_after_TanH"
solver_mode: GPU
device_id: 2
net_param {
  name: "CaffeNet"
  layer {
    name: "data"
    type: "Data"
    top: "data"
    top: "label"
    include {
      phase: TRAIN
    }
    transform_param {
      scale: 0.04
      mirror: true
      crop_size: 128
      mean_value: 104
      mean_value: 117
      mean_value: 124
      force_color: true
    }
    data_param {
      source: "/local/temporary/imagenet144pxlmdb/ilsvrc12_128_train_lmdb"
      batch_size: 256
      backend: LMDB
    }
  }
  layer {
    name: "data"
    type: "Data"
    top: "data"
    top: "label"
    include {
      phase: TEST
    }
    transform_param {
      scale: 0.04
      mirror: false
      crop_size: 128
      mean_value: 104
      mean_value: 117
      mean_value: 123
      force_color: true
    }
    data_param {
      source: "/local/temporary/imagenet144pxlmdb/ilsvrc12_128_val_lmdb"
      batch_size: 50
      backend: LMDB
    }
  }
  layer {
    name: "conv1"
    type: "Convolution"
    bottom: "data"
    top: "conv1"
    param {
      lr_mult: 1
      decay_mult: 1
    }
    param {
      lr_mult: 2
      decay_mult: 0
    }
    convolution_param {
      num_output: 96
      kernel_size: 11
      stride: 4
      weight_filler {
        type: "gaussian"
        std: 0.01
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layer {
    name: "relu1"
    type: "TanH"
    bottom: "conv1"
    top: "relu1"
  }
  layer {
    name: "conv1_BN"
    type: "BatchNorm"
    bottom: "relu1"
    top: "conv1_BN"
    param {
      lr_mult: 0
      decay_mult: 0
    }
    param {
      lr_mult: 0
      decay_mult: 0
    }
    param {
      lr_mult: 0
      decay_mult: 0
    }
    include {
      phase: TRAIN
    }
    batch_norm_param {
      use_global_stats: false
      moving_average_fraction: 0.95
    }
  }
  layer {
    name: "conv1_BN"
    type: "BatchNorm"
    bottom: "relu1"
    top: "conv1_BN"
    param {
      lr_mult: 0
      decay_mult: 0
    }
    param {
      lr_mult: 0
      decay_mult: 0
    }
    param {
      lr_mult: 0
      decay_mult: 0
    }
    include {
      phase: TEST
    }
    batch_norm_param {
      use_global_stats: true
      moving_average_fraction: 0.95
    }
  }
  layer {
    name: "pool1"
    type: "Pooling"
    bottom: "conv1_BN"
    top: "pool1"
    pooling_param {
      pool: MAX
      kernel_size: 3
      stride: 2
    }
  }
  layer {
    name: "conv2"
    type: "Convolution"
    bottom: "pool1"
    top: "conv2"
    param {
      lr_mult: 1
      decay_mult: 1
    }
    param {
      lr_mult: 2
      decay_mult: 0
    }
    convolution_param {
      num_output: 256
      pad: 2
      kernel_size: 5
      group: 2
      weight_filler {
        type: "gaussian"
        std: 0.01
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layer {
    name: "relu2"
    type: "TanH"
    bottom: "conv2"
    top: "relu2"
  }
  layer {
    name: "conv2_BN"
    type: "BatchNorm"
    bottom: "relu2"
    top: "conv2_BN"
    param {
      lr_mult: 0
      decay_mult: 0
    }
    param {
      lr_mult: 0
      decay_mult: 0
    }
    param {
      lr_mult: 0
      decay_mult: 0
    }
    include {
      phase: TRAIN
    }
    batch_norm_param {
      use_global_stats: false
      moving_average_fraction: 0.95
    }
  }
  layer {
    name: "conv2_BN"
    type: "BatchNorm"
    bottom: "relu2"
    top: "conv2_BN"
    param {
      lr_mult: 0
      decay_mult: 0
    }
    param {
      lr_mult: 0
      decay_mult: 0
    }
    param {
      lr_mult: 0
      decay_mult: 0
    }
    include {
      phase: TEST
    }
    batch_norm_param {
      use_global_stats: true
      moving_average_fraction: 0.95
    }
  }
  layer {
    name: "pool2"
    type: "Pooling"
    bottom: "conv2_BN"
    top: "pool2"
    pooling_param {
      pool: MAX
      kernel_size: 3
      stride: 2
    }
  }
  layer {
    name: "conv3"
    type: "Convolution"
    bottom: "pool2"
    top: "conv3"
    param {
      lr_mult: 1
      decay_mult: 1
    }
    param {
      lr_mult: 2
      decay_mult: 0
    }
    convolution_param {
      num_output: 384
      pad: 1
      kernel_size: 3
      weight_filler {
        type: "gaussian"
        std: 0.01
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layer {
    name: "relu3"
    type: "TanH"
    bottom: "conv3"
    top: "relu3"
  }
  layer {
    name: "conv3_BN"
    type: "BatchNorm"
    bottom: "relu3"
    top: "conv3_BN"
    param {
      lr_mult: 0
      decay_mult: 0
    }
    param {
      lr_mult: 0
      decay_mult: 0
    }
    param {
      lr_mult: 0
      decay_mult: 0
    }
    include {
      phase: TRAIN
    }
    batch_norm_param {
      use_global_stats: false
      moving_average_fraction: 0.95
    }
  }
  layer {
    name: "conv3_BN"
    type: "BatchNorm"
    bottom: "relu3"
    top: "conv3_BN"
    param {
      lr_mult: 0
      decay_mult: 0
    }
    param {
      lr_mult: 0
      decay_mult: 0
    }
    param {
      lr_mult: 0
      decay_mult: 0
    }
    include {
      phase: TEST
    }
    batch_norm_param {
      use_global_stats: true
      moving_average_fraction: 0.95
    }
  }
  layer {
    name: "conv4"
    type: "Convolution"
    bottom: "conv3_BN"
    top: "conv4"
    param {
      lr_mult: 1
      decay_mult: 1
    }
    param {
      lr_mult: 2
      decay_mult: 0
    }
    convolution_param {
      num_output: 384
      pad: 1
      kernel_size: 3
      group: 2
      weight_filler {
        type: "gaussian"
        std: 0.01
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layer {
    name: "relu4"
    type: "TanH"
    bottom: "conv4"
    top: "relu4"
  }
  layer {
    name: "conv4_BN"
    type: "BatchNorm"
    bottom: "relu4"
    top: "conv4_BN"
    param {
      lr_mult: 0
      decay_mult: 0
    }
    param {
      lr_mult: 0
      decay_mult: 0
    }
    param {
      lr_mult: 0
      decay_mult: 0
    }
    include {
      phase: TRAIN
    }
    batch_norm_param {
      use_global_stats: false
      moving_average_fraction: 0.95
    }
  }
  layer {
    name: "conv4_BN"
    type: "BatchNorm"
    bottom: "relu4"
    top: "conv4_BN"
    param {
      lr_mult: 0
      decay_mult: 0
    }
    param {
      lr_mult: 0
      decay_mult: 0
    }
    param {
      lr_mult: 0
      decay_mult: 0
    }
    include {
      phase: TEST
    }
    batch_norm_param {
      use_global_stats: true
      moving_average_fraction: 0.95
    }
  }
  layer {
    name: "conv5"
    type: "Convolution"
    bottom: "conv4_BN"
    top: "conv5"
    param {
      lr_mult: 1
      decay_mult: 1
    }
    param {
      lr_mult: 2
      decay_mult: 0
    }
    convolution_param {
      num_output: 256
      pad: 1
      kernel_size: 3
      group: 2
      weight_filler {
        type: "gaussian"
        std: 0.01
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layer {
    name: "relu5"
    type: "TanH"
    bottom: "conv5"
    top: "relu5"
  }
  layer {
    name: "conv5_BN"
    type: "BatchNorm"
    bottom: "relu5"
    top: "conv5_BN"
    param {
      lr_mult: 0
      decay_mult: 0
    }
    param {
      lr_mult: 0
      decay_mult: 0
    }
    param {
      lr_mult: 0
      decay_mult: 0
    }
    include {
      phase: TRAIN
    }
    batch_norm_param {
      use_global_stats: false
      moving_average_fraction: 0.95
    }
  }
  layer {
    name: "conv5_BN"
    type: "BatchNorm"
    bottom: "relu5"
    top: "conv5_BN"
    param {
      lr_mult: 0
      decay_mult: 0
    }
    param {
      lr_mult: 0
      decay_mult: 0
    }
    param {
      lr_mult: 0
      decay_mult: 0
    }
    include {
      phase: TEST
    }
    batch_norm_param {
      use_global_stats: true
      moving_average_fraction: 0.95
    }
  }
  layer {
    name: "pool5"
    type: "Pooling"
    bottom: "conv5_BN"
    top: "pool5"
    pooling_param {
      pool: MAX
      kernel_size: 3
      stride: 2
    }
  }
  layer {
    name: "fc6"
    type: "InnerProduct"
    bottom: "pool5"
    top: "fc6"
    param {
      lr_mult: 1
      decay_mult: 1
    }
    param {
      lr_mult: 2
      decay_mult: 0
    }
    inner_product_param {
      num_output: 2048
      weight_filler {
        type: "gaussian"
        std: 0.005
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layer {
    name: "relu6"
    type: "TanH"
    bottom: "fc6"
    top: "relu6"
  }
  layer {
    name: "fc6_BN"
    type: "BatchNorm"
    bottom: "relu6"
    top: "fc6_BN"
    param {
      lr_mult: 0
      decay_mult: 0
    }
    param {
      lr_mult: 0
      decay_mult: 0
    }
    param {
      lr_mult: 0
      decay_mult: 0
    }
    include {
      phase: TRAIN
    }
    batch_norm_param {
      use_global_stats: false
      moving_average_fraction: 0.95
    }
  }
  layer {
    name: "fc6_BN"
    type: "BatchNorm"
    bottom: "relu6"
    top: "fc6_BN"
    param {
      lr_mult: 0
      decay_mult: 0
    }
    param {
      lr_mult: 0
      decay_mult: 0
    }
    param {
      lr_mult: 0
      decay_mult: 0
    }
    include {
      phase: TEST
    }
    batch_norm_param {
      use_global_stats: true
      moving_average_fraction: 0.95
    }
  }
  layer {
    name: "drop6"
    type: "Dropout"
    bottom: "fc6_BN"
    top: "drop6"
    dropout_param {
      dropout_ratio: 0.5
    }
  }
  layer {
    name: "fc7"
    type: "InnerProduct"
    bottom: "drop6"
    top: "fc7"
    param {
      lr_mult: 1
      decay_mult: 1
    }
    param {
      lr_mult: 2
      decay_mult: 0
    }
    inner_product_param {
      num_output: 2048
      weight_filler {
        type: "gaussian"
        std: 0.005
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layer {
    name: "relu7"
    type: "TanH"
    bottom: "fc7"
    top: "relu7"
  }
  layer {
    name: "fc7_BN"
    type: "BatchNorm"
    bottom: "relu7"
    top: "fc7_BN"
    param {
      lr_mult: 0
      decay_mult: 0
    }
    param {
      lr_mult: 0
      decay_mult: 0
    }
    param {
      lr_mult: 0
      decay_mult: 0
    }
    include {
      phase: TRAIN
    }
    batch_norm_param {
      use_global_stats: false
      moving_average_fraction: 0.95
    }
  }
  layer {
    name: "fc7_BN"
    type: "BatchNorm"
    bottom: "relu7"
    top: "fc7_BN"
    param {
      lr_mult: 0
      decay_mult: 0
    }
    param {
      lr_mult: 0
      decay_mult: 0
    }
    param {
      lr_mult: 0
      decay_mult: 0
    }
    include {
      phase: TEST
    }
    batch_norm_param {
      use_global_stats: true
      moving_average_fraction: 0.95
    }
  }
  layer {
    name: "drop7"
    type: "Dropout"
    bottom: "fc7_BN"
    top: "drop7"
    dropout_param {
      dropout_ratio: 0.5
    }
  }
  layer {
    name: "fc8"
    type: "InnerProduct"
    bottom: "drop7"
    top: "fc8"
    param {
      lr_mult: 1
      decay_mult: 1
    }
    param {
      lr_mult: 2
      decay_mult: 0
    }
    inner_product_param {
      num_output: 1000
      weight_filler {
        type: "gaussian"
        std: 0.01
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layer {
    name: "accuracy"
    type: "Accuracy"
    bottom: "fc8"
    bottom: "label"
    top: "accuracy"
    include {
      phase: TEST
    }
  }
  layer {
    name: "loss"
    type: "SoftmaxWithLoss"
    bottom: "fc8"
    bottom: "label"
    top: "loss"
  }
}
test_initialization: false
average_loss: 20
iter_size: 1
type: "SGD"
I0601 11:49:59.217806 24067 solver.cpp:86] Creating training net specified in net_param.
I0601 11:49:59.217967 24067 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0601 11:49:59.217998 24067 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer conv1_BN
I0601 11:49:59.218005 24067 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer conv2_BN
I0601 11:49:59.218013 24067 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer conv3_BN
I0601 11:49:59.218017 24067 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer conv4_BN
I0601 11:49:59.218024 24067 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer conv5_BN
I0601 11:49:59.218030 24067 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer fc6_BN
I0601 11:49:59.218036 24067 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer fc7_BN
I0601 11:49:59.218041 24067 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0601 11:49:59.218396 24067 net.cpp:49] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.04
    mirror: true
    crop_size: 128
    mean_value: 104
    mean_value: 117
    mean_value: 124
    force_color: true
  }
  data_param {
    source: "/local/temporary/imagenet144pxlmdb/ilsvrc12_128_train_lmdb"
    batch_size: 256
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "TanH"
  bottom: "conv1"
  top: "relu1"
}
layer {
  name: "conv1_BN"
  type: "BatchNorm"
  bottom: "relu1"
  top: "conv1_BN"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_BN"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "TanH"
  bottom: "conv2"
  top: "relu2"
}
layer {
  name: "conv2_BN"
  type: "BatchNorm"
  bottom: "relu2"
  top: "conv2_BN"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_BN"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "TanH"
  bottom: "conv3"
  top: "relu3"
}
layer {
  name: "conv3_BN"
  type: "BatchNorm"
  bottom: "relu3"
  top: "conv3_BN"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3_BN"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu4"
  type: "TanH"
  bottom: "conv4"
  top: "relu4"
}
layer {
  name: "conv4_BN"
  type: "BatchNorm"
  bottom: "relu4"
  top: "conv4_BN"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4_BN"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "TanH"
  bottom: "conv5"
  top: "relu5"
}
layer {
  name: "conv5_BN"
  type: "BatchNorm"
  bottom: "relu5"
  top: "conv5_BN"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_BN"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "TanH"
  bottom: "fc6"
  top: "relu6"
}
layer {
  name: "fc6_BN"
  type: "BatchNorm"
  bottom: "relu6"
  top: "fc6_BN"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6_BN"
  top: "drop6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "drop6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu7"
  type: "TanH"
  bottom: "fc7"
  top: "relu7"
}
layer {
  name: "fc7_BN"
  type: "BatchNorm"
  bottom: "relu7"
  top: "fc7_BN"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7_BN"
  top: "drop7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "drop7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0601 11:49:59.218539 24067 layer_factory.hpp:76] Creating layer data
I0601 11:49:59.219223 24067 net.cpp:106] Creating Layer data
I0601 11:49:59.219249 24067 net.cpp:411] data -> data
I0601 11:49:59.219276 24067 net.cpp:411] data -> label
I0601 11:49:59.220428 24103 db_lmdb.cpp:38] Opened lmdb /local/temporary/imagenet144pxlmdb/ilsvrc12_128_train_lmdb
I0601 11:49:59.243049 24067 data_layer.cpp:41] output data size: 256,3,128,128
I0601 11:49:59.352941 24067 net.cpp:150] Setting up data
I0601 11:49:59.352989 24067 net.cpp:157] Top shape: 256 3 128 128 (12582912)
I0601 11:49:59.352996 24067 net.cpp:157] Top shape: 256 (256)
I0601 11:49:59.353000 24067 net.cpp:165] Memory required for data: 50332672
I0601 11:49:59.353013 24067 layer_factory.hpp:76] Creating layer conv1
I0601 11:49:59.353035 24067 net.cpp:106] Creating Layer conv1
I0601 11:49:59.353044 24067 net.cpp:454] conv1 <- data
I0601 11:49:59.353065 24067 net.cpp:411] conv1 -> conv1
I0601 11:49:59.480341 24067 net.cpp:150] Setting up conv1
I0601 11:49:59.480393 24067 net.cpp:157] Top shape: 256 96 30 30 (22118400)
I0601 11:49:59.480398 24067 net.cpp:165] Memory required for data: 138806272
I0601 11:49:59.480419 24067 layer_factory.hpp:76] Creating layer relu1
I0601 11:49:59.480432 24067 net.cpp:106] Creating Layer relu1
I0601 11:49:59.480437 24067 net.cpp:454] relu1 <- conv1
I0601 11:49:59.480445 24067 net.cpp:411] relu1 -> relu1
I0601 11:49:59.480650 24067 net.cpp:150] Setting up relu1
I0601 11:49:59.480659 24067 net.cpp:157] Top shape: 256 96 30 30 (22118400)
I0601 11:49:59.480664 24067 net.cpp:165] Memory required for data: 227279872
I0601 11:49:59.480666 24067 layer_factory.hpp:76] Creating layer conv1_BN
I0601 11:49:59.480677 24067 net.cpp:106] Creating Layer conv1_BN
I0601 11:49:59.480681 24067 net.cpp:454] conv1_BN <- relu1
I0601 11:49:59.480689 24067 net.cpp:411] conv1_BN -> conv1_BN
I0601 11:49:59.480895 24067 net.cpp:150] Setting up conv1_BN
I0601 11:49:59.480903 24067 net.cpp:157] Top shape: 256 96 30 30 (22118400)
I0601 11:49:59.480906 24067 net.cpp:165] Memory required for data: 315753472
I0601 11:49:59.480921 24067 layer_factory.hpp:76] Creating layer pool1
I0601 11:49:59.480931 24067 net.cpp:106] Creating Layer pool1
I0601 11:49:59.480934 24067 net.cpp:454] pool1 <- conv1_BN
I0601 11:49:59.480939 24067 net.cpp:411] pool1 -> pool1
I0601 11:49:59.481276 24067 net.cpp:150] Setting up pool1
I0601 11:49:59.481287 24067 net.cpp:157] Top shape: 256 96 15 15 (5529600)
I0601 11:49:59.481302 24067 net.cpp:165] Memory required for data: 337871872
I0601 11:49:59.481304 24067 layer_factory.hpp:76] Creating layer conv2
I0601 11:49:59.481315 24067 net.cpp:106] Creating Layer conv2
I0601 11:49:59.481318 24067 net.cpp:454] conv2 <- pool1
I0601 11:49:59.481325 24067 net.cpp:411] conv2 -> conv2
I0601 11:49:59.491785 24067 net.cpp:150] Setting up conv2
I0601 11:49:59.491811 24067 net.cpp:157] Top shape: 256 256 15 15 (14745600)
I0601 11:49:59.491814 24067 net.cpp:165] Memory required for data: 396854272
I0601 11:49:59.491822 24067 layer_factory.hpp:76] Creating layer relu2
I0601 11:49:59.491827 24067 net.cpp:106] Creating Layer relu2
I0601 11:49:59.491830 24067 net.cpp:454] relu2 <- conv2
I0601 11:49:59.491837 24067 net.cpp:411] relu2 -> relu2
I0601 11:49:59.492040 24067 net.cpp:150] Setting up relu2
I0601 11:49:59.492053 24067 net.cpp:157] Top shape: 256 256 15 15 (14745600)
I0601 11:49:59.492056 24067 net.cpp:165] Memory required for data: 455836672
I0601 11:49:59.492060 24067 layer_factory.hpp:76] Creating layer conv2_BN
I0601 11:49:59.492066 24067 net.cpp:106] Creating Layer conv2_BN
I0601 11:49:59.492070 24067 net.cpp:454] conv2_BN <- relu2
I0601 11:49:59.492079 24067 net.cpp:411] conv2_BN -> conv2_BN
I0601 11:49:59.492269 24067 net.cpp:150] Setting up conv2_BN
I0601 11:49:59.492276 24067 net.cpp:157] Top shape: 256 256 15 15 (14745600)
I0601 11:49:59.492280 24067 net.cpp:165] Memory required for data: 514819072
I0601 11:49:59.492290 24067 layer_factory.hpp:76] Creating layer pool2
I0601 11:49:59.492302 24067 net.cpp:106] Creating Layer pool2
I0601 11:49:59.492306 24067 net.cpp:454] pool2 <- conv2_BN
I0601 11:49:59.492353 24067 net.cpp:411] pool2 -> pool2
I0601 11:49:59.492667 24067 net.cpp:150] Setting up pool2
I0601 11:49:59.492678 24067 net.cpp:157] Top shape: 256 256 7 7 (3211264)
I0601 11:49:59.492683 24067 net.cpp:165] Memory required for data: 527664128
I0601 11:49:59.492687 24067 layer_factory.hpp:76] Creating layer conv3
I0601 11:49:59.492698 24067 net.cpp:106] Creating Layer conv3
I0601 11:49:59.492702 24067 net.cpp:454] conv3 <- pool2
I0601 11:49:59.492719 24067 net.cpp:411] conv3 -> conv3
I0601 11:49:59.519264 24067 net.cpp:150] Setting up conv3
I0601 11:49:59.519291 24067 net.cpp:157] Top shape: 256 384 7 7 (4816896)
I0601 11:49:59.519295 24067 net.cpp:165] Memory required for data: 546931712
I0601 11:49:59.519304 24067 layer_factory.hpp:76] Creating layer relu3
I0601 11:49:59.519309 24067 net.cpp:106] Creating Layer relu3
I0601 11:49:59.519312 24067 net.cpp:454] relu3 <- conv3
I0601 11:49:59.519320 24067 net.cpp:411] relu3 -> relu3
I0601 11:49:59.519624 24067 net.cpp:150] Setting up relu3
I0601 11:49:59.519636 24067 net.cpp:157] Top shape: 256 384 7 7 (4816896)
I0601 11:49:59.519639 24067 net.cpp:165] Memory required for data: 566199296
I0601 11:49:59.519642 24067 layer_factory.hpp:76] Creating layer conv3_BN
I0601 11:49:59.519651 24067 net.cpp:106] Creating Layer conv3_BN
I0601 11:49:59.519659 24067 net.cpp:454] conv3_BN <- relu3
I0601 11:49:59.519665 24067 net.cpp:411] conv3_BN -> conv3_BN
I0601 11:49:59.519855 24067 net.cpp:150] Setting up conv3_BN
I0601 11:49:59.519861 24067 net.cpp:157] Top shape: 256 384 7 7 (4816896)
I0601 11:49:59.519865 24067 net.cpp:165] Memory required for data: 585466880
I0601 11:49:59.519871 24067 layer_factory.hpp:76] Creating layer conv4
I0601 11:49:59.519881 24067 net.cpp:106] Creating Layer conv4
I0601 11:49:59.519884 24067 net.cpp:454] conv4 <- conv3_BN
I0601 11:49:59.519891 24067 net.cpp:411] conv4 -> conv4
I0601 11:49:59.541159 24067 net.cpp:150] Setting up conv4
I0601 11:49:59.541173 24067 net.cpp:157] Top shape: 256 384 7 7 (4816896)
I0601 11:49:59.541178 24067 net.cpp:165] Memory required for data: 604734464
I0601 11:49:59.541203 24067 layer_factory.hpp:76] Creating layer relu4
I0601 11:49:59.541209 24067 net.cpp:106] Creating Layer relu4
I0601 11:49:59.541213 24067 net.cpp:454] relu4 <- conv4
I0601 11:49:59.541218 24067 net.cpp:411] relu4 -> relu4
I0601 11:49:59.541421 24067 net.cpp:150] Setting up relu4
I0601 11:49:59.541430 24067 net.cpp:157] Top shape: 256 384 7 7 (4816896)
I0601 11:49:59.541434 24067 net.cpp:165] Memory required for data: 624002048
I0601 11:49:59.541437 24067 layer_factory.hpp:76] Creating layer conv4_BN
I0601 11:49:59.541445 24067 net.cpp:106] Creating Layer conv4_BN
I0601 11:49:59.541450 24067 net.cpp:454] conv4_BN <- relu4
I0601 11:49:59.541458 24067 net.cpp:411] conv4_BN -> conv4_BN
I0601 11:49:59.541649 24067 net.cpp:150] Setting up conv4_BN
I0601 11:49:59.541656 24067 net.cpp:157] Top shape: 256 384 7 7 (4816896)
I0601 11:49:59.541659 24067 net.cpp:165] Memory required for data: 643269632
I0601 11:49:59.541666 24067 layer_factory.hpp:76] Creating layer conv5
I0601 11:49:59.541676 24067 net.cpp:106] Creating Layer conv5
I0601 11:49:59.541681 24067 net.cpp:454] conv5 <- conv4_BN
I0601 11:49:59.541687 24067 net.cpp:411] conv5 -> conv5
I0601 11:49:59.556135 24067 net.cpp:150] Setting up conv5
I0601 11:49:59.556161 24067 net.cpp:157] Top shape: 256 256 7 7 (3211264)
I0601 11:49:59.556165 24067 net.cpp:165] Memory required for data: 656114688
I0601 11:49:59.556172 24067 layer_factory.hpp:76] Creating layer relu5
I0601 11:49:59.556181 24067 net.cpp:106] Creating Layer relu5
I0601 11:49:59.556185 24067 net.cpp:454] relu5 <- conv5
I0601 11:49:59.556192 24067 net.cpp:411] relu5 -> relu5
I0601 11:49:59.556403 24067 net.cpp:150] Setting up relu5
I0601 11:49:59.556413 24067 net.cpp:157] Top shape: 256 256 7 7 (3211264)
I0601 11:49:59.556418 24067 net.cpp:165] Memory required for data: 668959744
I0601 11:49:59.556421 24067 layer_factory.hpp:76] Creating layer conv5_BN
I0601 11:49:59.556430 24067 net.cpp:106] Creating Layer conv5_BN
I0601 11:49:59.556455 24067 net.cpp:454] conv5_BN <- relu5
I0601 11:49:59.556462 24067 net.cpp:411] conv5_BN -> conv5_BN
I0601 11:49:59.556668 24067 net.cpp:150] Setting up conv5_BN
I0601 11:49:59.556674 24067 net.cpp:157] Top shape: 256 256 7 7 (3211264)
I0601 11:49:59.556677 24067 net.cpp:165] Memory required for data: 681804800
I0601 11:49:59.556685 24067 layer_factory.hpp:76] Creating layer pool5
I0601 11:49:59.556692 24067 net.cpp:106] Creating Layer pool5
I0601 11:49:59.556696 24067 net.cpp:454] pool5 <- conv5_BN
I0601 11:49:59.556704 24067 net.cpp:411] pool5 -> pool5
I0601 11:49:59.557041 24067 net.cpp:150] Setting up pool5
I0601 11:49:59.557051 24067 net.cpp:157] Top shape: 256 256 3 3 (589824)
I0601 11:49:59.557066 24067 net.cpp:165] Memory required for data: 684164096
I0601 11:49:59.557070 24067 layer_factory.hpp:76] Creating layer fc6
I0601 11:49:59.557076 24067 net.cpp:106] Creating Layer fc6
I0601 11:49:59.557080 24067 net.cpp:454] fc6 <- pool5
I0601 11:49:59.557087 24067 net.cpp:411] fc6 -> fc6
I0601 11:49:59.698899 24067 net.cpp:150] Setting up fc6
I0601 11:49:59.698930 24067 net.cpp:157] Top shape: 256 2048 (524288)
I0601 11:49:59.698935 24067 net.cpp:165] Memory required for data: 686261248
I0601 11:49:59.698946 24067 layer_factory.hpp:76] Creating layer relu6
I0601 11:49:59.698959 24067 net.cpp:106] Creating Layer relu6
I0601 11:49:59.698966 24067 net.cpp:454] relu6 <- fc6
I0601 11:49:59.698976 24067 net.cpp:411] relu6 -> relu6
I0601 11:49:59.699282 24067 net.cpp:150] Setting up relu6
I0601 11:49:59.699293 24067 net.cpp:157] Top shape: 256 2048 (524288)
I0601 11:49:59.699296 24067 net.cpp:165] Memory required for data: 688358400
I0601 11:49:59.699301 24067 layer_factory.hpp:76] Creating layer fc6_BN
I0601 11:49:59.699312 24067 net.cpp:106] Creating Layer fc6_BN
I0601 11:49:59.699316 24067 net.cpp:454] fc6_BN <- relu6
I0601 11:49:59.699323 24067 net.cpp:411] fc6_BN -> fc6_BN
I0601 11:49:59.699530 24067 net.cpp:150] Setting up fc6_BN
I0601 11:49:59.699538 24067 net.cpp:157] Top shape: 256 2048 (524288)
I0601 11:49:59.699542 24067 net.cpp:165] Memory required for data: 690455552
I0601 11:49:59.699551 24067 layer_factory.hpp:76] Creating layer drop6
I0601 11:49:59.699560 24067 net.cpp:106] Creating Layer drop6
I0601 11:49:59.699565 24067 net.cpp:454] drop6 <- fc6_BN
I0601 11:49:59.699570 24067 net.cpp:411] drop6 -> drop6
I0601 11:49:59.699615 24067 net.cpp:150] Setting up drop6
I0601 11:49:59.699621 24067 net.cpp:157] Top shape: 256 2048 (524288)
I0601 11:49:59.699625 24067 net.cpp:165] Memory required for data: 692552704
I0601 11:49:59.699628 24067 layer_factory.hpp:76] Creating layer fc7
I0601 11:49:59.699640 24067 net.cpp:106] Creating Layer fc7
I0601 11:49:59.699645 24067 net.cpp:454] fc7 <- drop6
I0601 11:49:59.699656 24067 net.cpp:411] fc7 -> fc7
I0601 11:49:59.834594 24067 net.cpp:150] Setting up fc7
I0601 11:49:59.834625 24067 net.cpp:157] Top shape: 256 2048 (524288)
I0601 11:49:59.834628 24067 net.cpp:165] Memory required for data: 694649856
I0601 11:49:59.834642 24067 layer_factory.hpp:76] Creating layer relu7
I0601 11:49:59.834663 24067 net.cpp:106] Creating Layer relu7
I0601 11:49:59.834669 24067 net.cpp:454] relu7 <- fc7
I0601 11:49:59.834688 24067 net.cpp:411] relu7 -> relu7
I0601 11:49:59.835237 24067 net.cpp:150] Setting up relu7
I0601 11:49:59.835250 24067 net.cpp:157] Top shape: 256 2048 (524288)
I0601 11:49:59.835253 24067 net.cpp:165] Memory required for data: 696747008
I0601 11:49:59.835260 24067 layer_factory.hpp:76] Creating layer fc7_BN
I0601 11:49:59.835271 24067 net.cpp:106] Creating Layer fc7_BN
I0601 11:49:59.835275 24067 net.cpp:454] fc7_BN <- relu7
I0601 11:49:59.835283 24067 net.cpp:411] fc7_BN -> fc7_BN
I0601 11:49:59.835501 24067 net.cpp:150] Setting up fc7_BN
I0601 11:49:59.835508 24067 net.cpp:157] Top shape: 256 2048 (524288)
I0601 11:49:59.835513 24067 net.cpp:165] Memory required for data: 698844160
I0601 11:49:59.835528 24067 layer_factory.hpp:76] Creating layer drop7
I0601 11:49:59.835537 24067 net.cpp:106] Creating Layer drop7
I0601 11:49:59.835541 24067 net.cpp:454] drop7 <- fc7_BN
I0601 11:49:59.835593 24067 net.cpp:411] drop7 -> drop7
I0601 11:49:59.835636 24067 net.cpp:150] Setting up drop7
I0601 11:49:59.835644 24067 net.cpp:157] Top shape: 256 2048 (524288)
I0601 11:49:59.835649 24067 net.cpp:165] Memory required for data: 700941312
I0601 11:49:59.835651 24067 layer_factory.hpp:76] Creating layer fc8
I0601 11:49:59.835660 24067 net.cpp:106] Creating Layer fc8
I0601 11:49:59.835664 24067 net.cpp:454] fc8 <- drop7
I0601 11:49:59.835671 24067 net.cpp:411] fc8 -> fc8
I0601 11:49:59.901231 24067 net.cpp:150] Setting up fc8
I0601 11:49:59.901253 24067 net.cpp:157] Top shape: 256 1000 (256000)
I0601 11:49:59.901257 24067 net.cpp:165] Memory required for data: 701965312
I0601 11:49:59.901268 24067 layer_factory.hpp:76] Creating layer loss
I0601 11:49:59.901283 24067 net.cpp:106] Creating Layer loss
I0601 11:49:59.901289 24067 net.cpp:454] loss <- fc8
I0601 11:49:59.901296 24067 net.cpp:454] loss <- label
I0601 11:49:59.901306 24067 net.cpp:411] loss -> loss
I0601 11:49:59.901320 24067 layer_factory.hpp:76] Creating layer loss
I0601 11:49:59.902490 24067 net.cpp:150] Setting up loss
I0601 11:49:59.902503 24067 net.cpp:157] Top shape: (1)
I0601 11:49:59.902505 24067 net.cpp:160]     with loss weight 1
I0601 11:49:59.902536 24067 net.cpp:165] Memory required for data: 701965316
I0601 11:49:59.902540 24067 net.cpp:226] loss needs backward computation.
I0601 11:49:59.902546 24067 net.cpp:226] fc8 needs backward computation.
I0601 11:49:59.902550 24067 net.cpp:226] drop7 needs backward computation.
I0601 11:49:59.902561 24067 net.cpp:226] fc7_BN needs backward computation.
I0601 11:49:59.902565 24067 net.cpp:226] relu7 needs backward computation.
I0601 11:49:59.902570 24067 net.cpp:226] fc7 needs backward computation.
I0601 11:49:59.902573 24067 net.cpp:226] drop6 needs backward computation.
I0601 11:49:59.902576 24067 net.cpp:226] fc6_BN needs backward computation.
I0601 11:49:59.902581 24067 net.cpp:226] relu6 needs backward computation.
I0601 11:49:59.902585 24067 net.cpp:226] fc6 needs backward computation.
I0601 11:49:59.902588 24067 net.cpp:226] pool5 needs backward computation.
I0601 11:49:59.902593 24067 net.cpp:226] conv5_BN needs backward computation.
I0601 11:49:59.902596 24067 net.cpp:226] relu5 needs backward computation.
I0601 11:49:59.902601 24067 net.cpp:226] conv5 needs backward computation.
I0601 11:49:59.902603 24067 net.cpp:226] conv4_BN needs backward computation.
I0601 11:49:59.902608 24067 net.cpp:226] relu4 needs backward computation.
I0601 11:49:59.902611 24067 net.cpp:226] conv4 needs backward computation.
I0601 11:49:59.902616 24067 net.cpp:226] conv3_BN needs backward computation.
I0601 11:49:59.902619 24067 net.cpp:226] relu3 needs backward computation.
I0601 11:49:59.902623 24067 net.cpp:226] conv3 needs backward computation.
I0601 11:49:59.902626 24067 net.cpp:226] pool2 needs backward computation.
I0601 11:49:59.902631 24067 net.cpp:226] conv2_BN needs backward computation.
I0601 11:49:59.902636 24067 net.cpp:226] relu2 needs backward computation.
I0601 11:49:59.902639 24067 net.cpp:226] conv2 needs backward computation.
I0601 11:49:59.902643 24067 net.cpp:226] pool1 needs backward computation.
I0601 11:49:59.902647 24067 net.cpp:226] conv1_BN needs backward computation.
I0601 11:49:59.902650 24067 net.cpp:226] relu1 needs backward computation.
I0601 11:49:59.902653 24067 net.cpp:226] conv1 needs backward computation.
I0601 11:49:59.902658 24067 net.cpp:228] data does not need backward computation.
I0601 11:49:59.902662 24067 net.cpp:270] This network produces output loss
I0601 11:49:59.902686 24067 net.cpp:283] Network initialization done.
I0601 11:49:59.902921 24067 solver.cpp:181] Creating test net (#0) specified by net_param
I0601 11:49:59.902992 24067 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0601 11:49:59.903002 24067 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer conv1_BN
I0601 11:49:59.903009 24067 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer conv2_BN
I0601 11:49:59.903038 24067 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer conv3_BN
I0601 11:49:59.903044 24067 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer conv4_BN
I0601 11:49:59.903050 24067 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer conv5_BN
I0601 11:49:59.903056 24067 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer fc6_BN
I0601 11:49:59.903064 24067 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer fc7_BN
I0601 11:49:59.903481 24067 net.cpp:49] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.04
    mirror: false
    crop_size: 128
    mean_value: 104
    mean_value: 117
    mean_value: 123
    force_color: true
  }
  data_param {
    source: "/local/temporary/imagenet144pxlmdb/ilsvrc12_128_val_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "TanH"
  bottom: "conv1"
  top: "relu1"
}
layer {
  name: "conv1_BN"
  type: "BatchNorm"
  bottom: "relu1"
  top: "conv1_BN"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_BN"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "TanH"
  bottom: "conv2"
  top: "relu2"
}
layer {
  name: "conv2_BN"
  type: "BatchNorm"
  bottom: "relu2"
  top: "conv2_BN"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_BN"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "TanH"
  bottom: "conv3"
  top: "relu3"
}
layer {
  name: "conv3_BN"
  type: "BatchNorm"
  bottom: "relu3"
  top: "conv3_BN"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3_BN"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu4"
  type: "TanH"
  bottom: "conv4"
  top: "relu4"
}
layer {
  name: "conv4_BN"
  type: "BatchNorm"
  bottom: "relu4"
  top: "conv4_BN"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4_BN"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "TanH"
  bottom: "conv5"
  top: "relu5"
}
layer {
  name: "conv5_BN"
  type: "BatchNorm"
  bottom: "relu5"
  top: "conv5_BN"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_BN"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "TanH"
  bottom: "fc6"
  top: "relu6"
}
layer {
  name: "fc6_BN"
  type: "BatchNorm"
  bottom: "relu6"
  top: "fc6_BN"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6_BN"
  top: "drop6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "drop6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu7"
  type: "TanH"
  bottom: "fc7"
  top: "relu7"
}
layer {
  name: "fc7_BN"
  type: "BatchNorm"
  bottom: "relu7"
  top: "fc7_BN"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7_BN"
  top: "drop7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "drop7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0601 11:49:59.903661 24067 layer_factory.hpp:76] Creating layer data
I0601 11:49:59.903766 24067 net.cpp:106] Creating Layer data
I0601 11:49:59.903775 24067 net.cpp:411] data -> data
I0601 11:49:59.903784 24067 net.cpp:411] data -> label
I0601 11:49:59.904909 24108 db_lmdb.cpp:38] Opened lmdb /local/temporary/imagenet144pxlmdb/ilsvrc12_128_val_lmdb
I0601 11:49:59.905900 24067 data_layer.cpp:41] output data size: 50,3,128,128
I0601 11:49:59.924466 24067 net.cpp:150] Setting up data
I0601 11:49:59.924490 24067 net.cpp:157] Top shape: 50 3 128 128 (2457600)
I0601 11:49:59.924499 24067 net.cpp:157] Top shape: 50 (50)
I0601 11:49:59.924501 24067 net.cpp:165] Memory required for data: 9830600
I0601 11:49:59.924512 24067 layer_factory.hpp:76] Creating layer label_data_1_split
I0601 11:49:59.924525 24067 net.cpp:106] Creating Layer label_data_1_split
I0601 11:49:59.924530 24067 net.cpp:454] label_data_1_split <- label
I0601 11:49:59.924536 24067 net.cpp:411] label_data_1_split -> label_data_1_split_0
I0601 11:49:59.924548 24067 net.cpp:411] label_data_1_split -> label_data_1_split_1
I0601 11:49:59.924693 24067 net.cpp:150] Setting up label_data_1_split
I0601 11:49:59.924702 24067 net.cpp:157] Top shape: 50 (50)
I0601 11:49:59.924707 24067 net.cpp:157] Top shape: 50 (50)
I0601 11:49:59.924710 24067 net.cpp:165] Memory required for data: 9831000
I0601 11:49:59.924715 24067 layer_factory.hpp:76] Creating layer conv1
I0601 11:49:59.924729 24067 net.cpp:106] Creating Layer conv1
I0601 11:49:59.924733 24067 net.cpp:454] conv1 <- data
I0601 11:49:59.924741 24067 net.cpp:411] conv1 -> conv1
I0601 11:49:59.927260 24067 net.cpp:150] Setting up conv1
I0601 11:49:59.927275 24067 net.cpp:157] Top shape: 50 96 30 30 (4320000)
I0601 11:49:59.927280 24067 net.cpp:165] Memory required for data: 27111000
I0601 11:49:59.927294 24067 layer_factory.hpp:76] Creating layer relu1
I0601 11:49:59.927302 24067 net.cpp:106] Creating Layer relu1
I0601 11:49:59.927307 24067 net.cpp:454] relu1 <- conv1
I0601 11:49:59.927314 24067 net.cpp:411] relu1 -> relu1
I0601 11:49:59.927660 24067 net.cpp:150] Setting up relu1
I0601 11:49:59.927673 24067 net.cpp:157] Top shape: 50 96 30 30 (4320000)
I0601 11:49:59.927683 24067 net.cpp:165] Memory required for data: 44391000
I0601 11:49:59.927688 24067 layer_factory.hpp:76] Creating layer conv1_BN
I0601 11:49:59.927711 24067 net.cpp:106] Creating Layer conv1_BN
I0601 11:49:59.927714 24067 net.cpp:454] conv1_BN <- relu1
I0601 11:49:59.927721 24067 net.cpp:411] conv1_BN -> conv1_BN
I0601 11:49:59.927973 24067 net.cpp:150] Setting up conv1_BN
I0601 11:49:59.927980 24067 net.cpp:157] Top shape: 50 96 30 30 (4320000)
I0601 11:49:59.927983 24067 net.cpp:165] Memory required for data: 61671000
I0601 11:49:59.927995 24067 layer_factory.hpp:76] Creating layer pool1
I0601 11:49:59.928005 24067 net.cpp:106] Creating Layer pool1
I0601 11:49:59.928009 24067 net.cpp:454] pool1 <- conv1_BN
I0601 11:49:59.928015 24067 net.cpp:411] pool1 -> pool1
I0601 11:49:59.929641 24067 net.cpp:150] Setting up pool1
I0601 11:49:59.929651 24067 net.cpp:157] Top shape: 50 96 15 15 (1080000)
I0601 11:49:59.929654 24067 net.cpp:165] Memory required for data: 65991000
I0601 11:49:59.929658 24067 layer_factory.hpp:76] Creating layer conv2
I0601 11:49:59.929668 24067 net.cpp:106] Creating Layer conv2
I0601 11:49:59.929672 24067 net.cpp:454] conv2 <- pool1
I0601 11:49:59.929679 24067 net.cpp:411] conv2 -> conv2
I0601 11:49:59.941471 24067 net.cpp:150] Setting up conv2
I0601 11:49:59.941485 24067 net.cpp:157] Top shape: 50 256 15 15 (2880000)
I0601 11:49:59.941488 24067 net.cpp:165] Memory required for data: 77511000
I0601 11:49:59.941496 24067 layer_factory.hpp:76] Creating layer relu2
I0601 11:49:59.941504 24067 net.cpp:106] Creating Layer relu2
I0601 11:49:59.941509 24067 net.cpp:454] relu2 <- conv2
I0601 11:49:59.941514 24067 net.cpp:411] relu2 -> relu2
I0601 11:49:59.941730 24067 net.cpp:150] Setting up relu2
I0601 11:49:59.941740 24067 net.cpp:157] Top shape: 50 256 15 15 (2880000)
I0601 11:49:59.941745 24067 net.cpp:165] Memory required for data: 89031000
I0601 11:49:59.941748 24067 layer_factory.hpp:76] Creating layer conv2_BN
I0601 11:49:59.941758 24067 net.cpp:106] Creating Layer conv2_BN
I0601 11:49:59.941763 24067 net.cpp:454] conv2_BN <- relu2
I0601 11:49:59.941771 24067 net.cpp:411] conv2_BN -> conv2_BN
I0601 11:49:59.942000 24067 net.cpp:150] Setting up conv2_BN
I0601 11:49:59.942030 24067 net.cpp:157] Top shape: 50 256 15 15 (2880000)
I0601 11:49:59.942034 24067 net.cpp:165] Memory required for data: 100551000
I0601 11:49:59.942044 24067 layer_factory.hpp:76] Creating layer pool2
I0601 11:49:59.942051 24067 net.cpp:106] Creating Layer pool2
I0601 11:49:59.942055 24067 net.cpp:454] pool2 <- conv2_BN
I0601 11:49:59.942060 24067 net.cpp:411] pool2 -> pool2
I0601 11:49:59.942427 24067 net.cpp:150] Setting up pool2
I0601 11:49:59.942441 24067 net.cpp:157] Top shape: 50 256 7 7 (627200)
I0601 11:49:59.942445 24067 net.cpp:165] Memory required for data: 103059800
I0601 11:49:59.942448 24067 layer_factory.hpp:76] Creating layer conv3
I0601 11:49:59.942457 24067 net.cpp:106] Creating Layer conv3
I0601 11:49:59.942461 24067 net.cpp:454] conv3 <- pool2
I0601 11:49:59.942468 24067 net.cpp:411] conv3 -> conv3
I0601 11:49:59.967965 24067 net.cpp:150] Setting up conv3
I0601 11:49:59.967978 24067 net.cpp:157] Top shape: 50 384 7 7 (940800)
I0601 11:49:59.967993 24067 net.cpp:165] Memory required for data: 106823000
I0601 11:49:59.968010 24067 layer_factory.hpp:76] Creating layer relu3
I0601 11:49:59.968019 24067 net.cpp:106] Creating Layer relu3
I0601 11:49:59.968021 24067 net.cpp:454] relu3 <- conv3
I0601 11:49:59.968026 24067 net.cpp:411] relu3 -> relu3
I0601 11:49:59.968224 24067 net.cpp:150] Setting up relu3
I0601 11:49:59.968232 24067 net.cpp:157] Top shape: 50 384 7 7 (940800)
I0601 11:49:59.968236 24067 net.cpp:165] Memory required for data: 110586200
I0601 11:49:59.968240 24067 layer_factory.hpp:76] Creating layer conv3_BN
I0601 11:49:59.968246 24067 net.cpp:106] Creating Layer conv3_BN
I0601 11:49:59.968250 24067 net.cpp:454] conv3_BN <- relu3
I0601 11:49:59.968256 24067 net.cpp:411] conv3_BN -> conv3_BN
I0601 11:49:59.968499 24067 net.cpp:150] Setting up conv3_BN
I0601 11:49:59.968508 24067 net.cpp:157] Top shape: 50 384 7 7 (940800)
I0601 11:49:59.968511 24067 net.cpp:165] Memory required for data: 114349400
I0601 11:49:59.968518 24067 layer_factory.hpp:76] Creating layer conv4
I0601 11:49:59.968528 24067 net.cpp:106] Creating Layer conv4
I0601 11:49:59.968533 24067 net.cpp:454] conv4 <- conv3_BN
I0601 11:49:59.968538 24067 net.cpp:411] conv4 -> conv4
I0601 11:49:59.989624 24067 net.cpp:150] Setting up conv4
I0601 11:49:59.989647 24067 net.cpp:157] Top shape: 50 384 7 7 (940800)
I0601 11:49:59.989651 24067 net.cpp:165] Memory required for data: 118112600
I0601 11:49:59.989660 24067 layer_factory.hpp:76] Creating layer relu4
I0601 11:49:59.989667 24067 net.cpp:106] Creating Layer relu4
I0601 11:49:59.989671 24067 net.cpp:454] relu4 <- conv4
I0601 11:49:59.989675 24067 net.cpp:411] relu4 -> relu4
I0601 11:49:59.989882 24067 net.cpp:150] Setting up relu4
I0601 11:49:59.989892 24067 net.cpp:157] Top shape: 50 384 7 7 (940800)
I0601 11:49:59.989897 24067 net.cpp:165] Memory required for data: 121875800
I0601 11:49:59.989899 24067 layer_factory.hpp:76] Creating layer conv4_BN
I0601 11:49:59.989908 24067 net.cpp:106] Creating Layer conv4_BN
I0601 11:49:59.989912 24067 net.cpp:454] conv4_BN <- relu4
I0601 11:49:59.989919 24067 net.cpp:411] conv4_BN -> conv4_BN
I0601 11:49:59.990139 24067 net.cpp:150] Setting up conv4_BN
I0601 11:49:59.990145 24067 net.cpp:157] Top shape: 50 384 7 7 (940800)
I0601 11:49:59.990147 24067 net.cpp:165] Memory required for data: 125639000
I0601 11:49:59.990154 24067 layer_factory.hpp:76] Creating layer conv5
I0601 11:49:59.990164 24067 net.cpp:106] Creating Layer conv5
I0601 11:49:59.990169 24067 net.cpp:454] conv5 <- conv4_BN
I0601 11:49:59.990176 24067 net.cpp:411] conv5 -> conv5
I0601 11:50:00.003630 24067 net.cpp:150] Setting up conv5
I0601 11:50:00.003655 24067 net.cpp:157] Top shape: 50 256 7 7 (627200)
I0601 11:50:00.003659 24067 net.cpp:165] Memory required for data: 128147800
I0601 11:50:00.003664 24067 layer_factory.hpp:76] Creating layer relu5
I0601 11:50:00.003670 24067 net.cpp:106] Creating Layer relu5
I0601 11:50:00.003675 24067 net.cpp:454] relu5 <- conv5
I0601 11:50:00.003680 24067 net.cpp:411] relu5 -> relu5
I0601 11:50:00.004045 24067 net.cpp:150] Setting up relu5
I0601 11:50:00.004066 24067 net.cpp:157] Top shape: 50 256 7 7 (627200)
I0601 11:50:00.004070 24067 net.cpp:165] Memory required for data: 130656600
I0601 11:50:00.004073 24067 layer_factory.hpp:76] Creating layer conv5_BN
I0601 11:50:00.004081 24067 net.cpp:106] Creating Layer conv5_BN
I0601 11:50:00.004084 24067 net.cpp:454] conv5_BN <- relu5
I0601 11:50:00.004091 24067 net.cpp:411] conv5_BN -> conv5_BN
I0601 11:50:00.004312 24067 net.cpp:150] Setting up conv5_BN
I0601 11:50:00.004322 24067 net.cpp:157] Top shape: 50 256 7 7 (627200)
I0601 11:50:00.004325 24067 net.cpp:165] Memory required for data: 133165400
I0601 11:50:00.004333 24067 layer_factory.hpp:76] Creating layer pool5
I0601 11:50:00.004341 24067 net.cpp:106] Creating Layer pool5
I0601 11:50:00.004345 24067 net.cpp:454] pool5 <- conv5_BN
I0601 11:50:00.004350 24067 net.cpp:411] pool5 -> pool5
I0601 11:50:00.004570 24067 net.cpp:150] Setting up pool5
I0601 11:50:00.004586 24067 net.cpp:157] Top shape: 50 256 3 3 (115200)
I0601 11:50:00.004588 24067 net.cpp:165] Memory required for data: 133626200
I0601 11:50:00.004593 24067 layer_factory.hpp:76] Creating layer fc6
I0601 11:50:00.004603 24067 net.cpp:106] Creating Layer fc6
I0601 11:50:00.004608 24067 net.cpp:454] fc6 <- pool5
I0601 11:50:00.004614 24067 net.cpp:411] fc6 -> fc6
I0601 11:50:00.130673 24067 net.cpp:150] Setting up fc6
I0601 11:50:00.130707 24067 net.cpp:157] Top shape: 50 2048 (102400)
I0601 11:50:00.130710 24067 net.cpp:165] Memory required for data: 134035800
I0601 11:50:00.130719 24067 layer_factory.hpp:76] Creating layer relu6
I0601 11:50:00.130729 24067 net.cpp:106] Creating Layer relu6
I0601 11:50:00.130733 24067 net.cpp:454] relu6 <- fc6
I0601 11:50:00.130741 24067 net.cpp:411] relu6 -> relu6
I0601 11:50:00.131198 24067 net.cpp:150] Setting up relu6
I0601 11:50:00.131209 24067 net.cpp:157] Top shape: 50 2048 (102400)
I0601 11:50:00.131213 24067 net.cpp:165] Memory required for data: 134445400
I0601 11:50:00.131228 24067 layer_factory.hpp:76] Creating layer fc6_BN
I0601 11:50:00.131249 24067 net.cpp:106] Creating Layer fc6_BN
I0601 11:50:00.131253 24067 net.cpp:454] fc6_BN <- relu6
I0601 11:50:00.131258 24067 net.cpp:411] fc6_BN -> fc6_BN
I0601 11:50:00.131471 24067 net.cpp:150] Setting up fc6_BN
I0601 11:50:00.131477 24067 net.cpp:157] Top shape: 50 2048 (102400)
I0601 11:50:00.131480 24067 net.cpp:165] Memory required for data: 134855000
I0601 11:50:00.131489 24067 layer_factory.hpp:76] Creating layer drop6
I0601 11:50:00.131496 24067 net.cpp:106] Creating Layer drop6
I0601 11:50:00.131501 24067 net.cpp:454] drop6 <- fc6_BN
I0601 11:50:00.131507 24067 net.cpp:411] drop6 -> drop6
I0601 11:50:00.131547 24067 net.cpp:150] Setting up drop6
I0601 11:50:00.131553 24067 net.cpp:157] Top shape: 50 2048 (102400)
I0601 11:50:00.131557 24067 net.cpp:165] Memory required for data: 135264600
I0601 11:50:00.131561 24067 layer_factory.hpp:76] Creating layer fc7
I0601 11:50:00.131570 24067 net.cpp:106] Creating Layer fc7
I0601 11:50:00.131574 24067 net.cpp:454] fc7 <- drop6
I0601 11:50:00.131580 24067 net.cpp:411] fc7 -> fc7
I0601 11:50:00.243085 24067 net.cpp:150] Setting up fc7
I0601 11:50:00.243104 24067 net.cpp:157] Top shape: 50 2048 (102400)
I0601 11:50:00.243108 24067 net.cpp:165] Memory required for data: 135674200
I0601 11:50:00.243116 24067 layer_factory.hpp:76] Creating layer relu7
I0601 11:50:00.243137 24067 net.cpp:106] Creating Layer relu7
I0601 11:50:00.243141 24067 net.cpp:454] relu7 <- fc7
I0601 11:50:00.243147 24067 net.cpp:411] relu7 -> relu7
I0601 11:50:00.243422 24067 net.cpp:150] Setting up relu7
I0601 11:50:00.243432 24067 net.cpp:157] Top shape: 50 2048 (102400)
I0601 11:50:00.243434 24067 net.cpp:165] Memory required for data: 136083800
I0601 11:50:00.243438 24067 layer_factory.hpp:76] Creating layer fc7_BN
I0601 11:50:00.243448 24067 net.cpp:106] Creating Layer fc7_BN
I0601 11:50:00.243453 24067 net.cpp:454] fc7_BN <- relu7
I0601 11:50:00.243459 24067 net.cpp:411] fc7_BN -> fc7_BN
I0601 11:50:00.243666 24067 net.cpp:150] Setting up fc7_BN
I0601 11:50:00.243697 24067 net.cpp:157] Top shape: 50 2048 (102400)
I0601 11:50:00.243701 24067 net.cpp:165] Memory required for data: 136493400
I0601 11:50:00.243713 24067 layer_factory.hpp:76] Creating layer drop7
I0601 11:50:00.243721 24067 net.cpp:106] Creating Layer drop7
I0601 11:50:00.243726 24067 net.cpp:454] drop7 <- fc7_BN
I0601 11:50:00.243732 24067 net.cpp:411] drop7 -> drop7
I0601 11:50:00.243787 24067 net.cpp:150] Setting up drop7
I0601 11:50:00.243793 24067 net.cpp:157] Top shape: 50 2048 (102400)
I0601 11:50:00.243795 24067 net.cpp:165] Memory required for data: 136903000
I0601 11:50:00.243798 24067 layer_factory.hpp:76] Creating layer fc8
I0601 11:50:00.243809 24067 net.cpp:106] Creating Layer fc8
I0601 11:50:00.243813 24067 net.cpp:454] fc8 <- drop7
I0601 11:50:00.243819 24067 net.cpp:411] fc8 -> fc8
I0601 11:50:00.298111 24067 net.cpp:150] Setting up fc8
I0601 11:50:00.298125 24067 net.cpp:157] Top shape: 50 1000 (50000)
I0601 11:50:00.298128 24067 net.cpp:165] Memory required for data: 137103000
I0601 11:50:00.298146 24067 layer_factory.hpp:76] Creating layer fc8_fc8_0_split
I0601 11:50:00.298152 24067 net.cpp:106] Creating Layer fc8_fc8_0_split
I0601 11:50:00.298156 24067 net.cpp:454] fc8_fc8_0_split <- fc8
I0601 11:50:00.298161 24067 net.cpp:411] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0601 11:50:00.298167 24067 net.cpp:411] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0601 11:50:00.298208 24067 net.cpp:150] Setting up fc8_fc8_0_split
I0601 11:50:00.298214 24067 net.cpp:157] Top shape: 50 1000 (50000)
I0601 11:50:00.298220 24067 net.cpp:157] Top shape: 50 1000 (50000)
I0601 11:50:00.298223 24067 net.cpp:165] Memory required for data: 137503000
I0601 11:50:00.298226 24067 layer_factory.hpp:76] Creating layer accuracy
I0601 11:50:00.298239 24067 net.cpp:106] Creating Layer accuracy
I0601 11:50:00.298243 24067 net.cpp:454] accuracy <- fc8_fc8_0_split_0
I0601 11:50:00.298248 24067 net.cpp:454] accuracy <- label_data_1_split_0
I0601 11:50:00.298252 24067 net.cpp:411] accuracy -> accuracy
I0601 11:50:00.298260 24067 net.cpp:150] Setting up accuracy
I0601 11:50:00.298265 24067 net.cpp:157] Top shape: (1)
I0601 11:50:00.298267 24067 net.cpp:165] Memory required for data: 137503004
I0601 11:50:00.298270 24067 layer_factory.hpp:76] Creating layer loss
I0601 11:50:00.298276 24067 net.cpp:106] Creating Layer loss
I0601 11:50:00.298280 24067 net.cpp:454] loss <- fc8_fc8_0_split_1
I0601 11:50:00.298283 24067 net.cpp:454] loss <- label_data_1_split_1
I0601 11:50:00.298287 24067 net.cpp:411] loss -> loss
I0601 11:50:00.298296 24067 layer_factory.hpp:76] Creating layer loss
I0601 11:50:00.298818 24067 net.cpp:150] Setting up loss
I0601 11:50:00.298828 24067 net.cpp:157] Top shape: (1)
I0601 11:50:00.298831 24067 net.cpp:160]     with loss weight 1
I0601 11:50:00.298866 24067 net.cpp:165] Memory required for data: 137503008
I0601 11:50:00.298869 24067 net.cpp:226] loss needs backward computation.
I0601 11:50:00.298876 24067 net.cpp:228] accuracy does not need backward computation.
I0601 11:50:00.298879 24067 net.cpp:226] fc8_fc8_0_split needs backward computation.
I0601 11:50:00.298882 24067 net.cpp:226] fc8 needs backward computation.
I0601 11:50:00.298884 24067 net.cpp:226] drop7 needs backward computation.
I0601 11:50:00.298887 24067 net.cpp:226] fc7_BN needs backward computation.
I0601 11:50:00.298890 24067 net.cpp:226] relu7 needs backward computation.
I0601 11:50:00.298892 24067 net.cpp:226] fc7 needs backward computation.
I0601 11:50:00.298895 24067 net.cpp:226] drop6 needs backward computation.
I0601 11:50:00.298899 24067 net.cpp:226] fc6_BN needs backward computation.
I0601 11:50:00.298903 24067 net.cpp:226] relu6 needs backward computation.
I0601 11:50:00.298907 24067 net.cpp:226] fc6 needs backward computation.
I0601 11:50:00.298909 24067 net.cpp:226] pool5 needs backward computation.
I0601 11:50:00.298913 24067 net.cpp:226] conv5_BN needs backward computation.
I0601 11:50:00.298918 24067 net.cpp:226] relu5 needs backward computation.
I0601 11:50:00.298920 24067 net.cpp:226] conv5 needs backward computation.
I0601 11:50:00.298948 24067 net.cpp:226] conv4_BN needs backward computation.
I0601 11:50:00.298951 24067 net.cpp:226] relu4 needs backward computation.
I0601 11:50:00.298954 24067 net.cpp:226] conv4 needs backward computation.
I0601 11:50:00.298957 24067 net.cpp:226] conv3_BN needs backward computation.
I0601 11:50:00.298960 24067 net.cpp:226] relu3 needs backward computation.
I0601 11:50:00.298964 24067 net.cpp:226] conv3 needs backward computation.
I0601 11:50:00.298967 24067 net.cpp:226] pool2 needs backward computation.
I0601 11:50:00.298970 24067 net.cpp:226] conv2_BN needs backward computation.
I0601 11:50:00.298974 24067 net.cpp:226] relu2 needs backward computation.
I0601 11:50:00.298976 24067 net.cpp:226] conv2 needs backward computation.
I0601 11:50:00.298980 24067 net.cpp:226] pool1 needs backward computation.
I0601 11:50:00.298984 24067 net.cpp:226] conv1_BN needs backward computation.
I0601 11:50:00.298986 24067 net.cpp:226] relu1 needs backward computation.
I0601 11:50:00.298990 24067 net.cpp:226] conv1 needs backward computation.
I0601 11:50:00.298993 24067 net.cpp:228] label_data_1_split does not need backward computation.
I0601 11:50:00.298997 24067 net.cpp:228] data does not need backward computation.
I0601 11:50:00.299000 24067 net.cpp:270] This network produces output accuracy
I0601 11:50:00.299003 24067 net.cpp:270] This network produces output loss
I0601 11:50:00.299031 24067 net.cpp:283] Network initialization done.
I0601 11:50:00.299232 24067 solver.cpp:60] Solver scaffolding done.
I0601 11:50:00.300559 24067 caffe.cpp:128] Finetuning from caffenet_lsuv_no_lrn_BatchNormAfter_TanH.prototxt.caffemodel
I0601 11:50:00.470669 24067 caffe.cpp:212] Starting Optimization
I0601 11:50:00.470700 24067 solver.cpp:288] Solving CaffeNet
I0601 11:50:00.470705 24067 solver.cpp:289] Learning Rate Policy: step
I0601 11:50:00.590612 24067 solver.cpp:237] Iteration 0, loss = 7.12749
I0601 11:50:00.590673 24067 solver.cpp:253]     Train net output #0: loss = 7.12749 (* 1 = 7.12749 loss)
I0601 11:50:00.590687 24067 sgd_solver.cpp:106] Iteration 0, lr = 0.01
I0601 11:50:06.019726 24067 solver.cpp:237] Iteration 20, loss = 7.11019
I0601 11:50:06.019776 24067 solver.cpp:253]     Train net output #0: loss = 7.11224 (* 1 = 7.11224 loss)
I0601 11:50:06.019784 24067 sgd_solver.cpp:106] Iteration 20, lr = 0.01
I0601 11:50:11.435045 24067 solver.cpp:237] Iteration 40, loss = 7.00638
I0601 11:50:11.435091 24067 solver.cpp:253]     Train net output #0: loss = 6.92844 (* 1 = 6.92844 loss)
I0601 11:50:11.435111 24067 sgd_solver.cpp:106] Iteration 40, lr = 0.01
I0601 11:50:16.858572 24067 solver.cpp:237] Iteration 60, loss = 6.90893
I0601 11:50:16.858618 24067 solver.cpp:253]     Train net output #0: loss = 6.89323 (* 1 = 6.89323 loss)
I0601 11:50:16.858626 24067 sgd_solver.cpp:106] Iteration 60, lr = 0.01
I0601 11:50:22.291939 24067 solver.cpp:237] Iteration 80, loss = 6.88011
I0601 11:50:22.291987 24067 solver.cpp:253]     Train net output #0: loss = 6.91787 (* 1 = 6.91787 loss)
I0601 11:50:22.291996 24067 sgd_solver.cpp:106] Iteration 80, lr = 0.01
I0601 11:50:27.734009 24067 solver.cpp:237] Iteration 100, loss = 6.85292
I0601 11:50:27.734053 24067 solver.cpp:253]     Train net output #0: loss = 6.77062 (* 1 = 6.77062 loss)
I0601 11:50:27.734061 24067 sgd_solver.cpp:106] Iteration 100, lr = 0.01
I0601 11:50:33.158360 24067 solver.cpp:237] Iteration 120, loss = 6.79838
I0601 11:50:33.158457 24067 solver.cpp:253]     Train net output #0: loss = 6.83522 (* 1 = 6.83522 loss)
I0601 11:50:33.158465 24067 sgd_solver.cpp:106] Iteration 120, lr = 0.01
I0601 11:50:38.592865 24067 solver.cpp:237] Iteration 140, loss = 6.73145
I0601 11:50:38.592911 24067 solver.cpp:253]     Train net output #0: loss = 6.67917 (* 1 = 6.67917 loss)
I0601 11:50:38.592919 24067 sgd_solver.cpp:106] Iteration 140, lr = 0.01
I0601 11:50:44.024803 24067 solver.cpp:237] Iteration 160, loss = 6.74259
I0601 11:50:44.024849 24067 solver.cpp:253]     Train net output #0: loss = 6.69547 (* 1 = 6.69547 loss)
I0601 11:50:44.024857 24067 sgd_solver.cpp:106] Iteration 160, lr = 0.01
I0601 11:50:49.469452 24067 solver.cpp:237] Iteration 180, loss = 6.69346
I0601 11:50:49.469496 24067 solver.cpp:253]     Train net output #0: loss = 6.76813 (* 1 = 6.76813 loss)
I0601 11:50:49.469503 24067 sgd_solver.cpp:106] Iteration 180, lr = 0.01
I0601 11:50:54.915371 24067 solver.cpp:237] Iteration 200, loss = 6.67246
I0601 11:50:54.915417 24067 solver.cpp:253]     Train net output #0: loss = 6.64878 (* 1 = 6.64878 loss)
I0601 11:50:54.915424 24067 sgd_solver.cpp:106] Iteration 200, lr = 0.01
I0601 11:51:00.363531 24067 solver.cpp:237] Iteration 220, loss = 6.62437
I0601 11:51:00.363577 24067 solver.cpp:253]     Train net output #0: loss = 6.67498 (* 1 = 6.67498 loss)
I0601 11:51:00.363586 24067 sgd_solver.cpp:106] Iteration 220, lr = 0.01
I0601 11:51:05.818573 24067 solver.cpp:237] Iteration 240, loss = 6.58023
I0601 11:51:05.818855 24067 solver.cpp:253]     Train net output #0: loss = 6.66953 (* 1 = 6.66953 loss)
I0601 11:51:05.818888 24067 sgd_solver.cpp:106] Iteration 240, lr = 0.01
I0601 11:51:11.276155 24067 solver.cpp:237] Iteration 260, loss = 6.59759
I0601 11:51:11.276204 24067 solver.cpp:253]     Train net output #0: loss = 6.56518 (* 1 = 6.56518 loss)
I0601 11:51:11.276211 24067 sgd_solver.cpp:106] Iteration 260, lr = 0.01
I0601 11:51:16.730696 24067 solver.cpp:237] Iteration 280, loss = 6.58195
I0601 11:51:16.730742 24067 solver.cpp:253]     Train net output #0: loss = 6.60323 (* 1 = 6.60323 loss)
I0601 11:51:16.730751 24067 sgd_solver.cpp:106] Iteration 280, lr = 0.01
I0601 11:51:22.164568 24067 solver.cpp:237] Iteration 300, loss = 6.54256
I0601 11:51:22.164615 24067 solver.cpp:253]     Train net output #0: loss = 6.48763 (* 1 = 6.48763 loss)
I0601 11:51:22.164624 24067 sgd_solver.cpp:106] Iteration 300, lr = 0.01
I0601 11:51:27.606335 24067 solver.cpp:237] Iteration 320, loss = 6.51898
I0601 11:51:27.606391 24067 solver.cpp:253]     Train net output #0: loss = 6.48015 (* 1 = 6.48015 loss)
I0601 11:51:27.606398 24067 sgd_solver.cpp:106] Iteration 320, lr = 0.01
I0601 11:51:33.054739 24067 solver.cpp:237] Iteration 340, loss = 6.50046
I0601 11:51:33.054787 24067 solver.cpp:253]     Train net output #0: loss = 6.48601 (* 1 = 6.48601 loss)
I0601 11:51:33.054796 24067 sgd_solver.cpp:106] Iteration 340, lr = 0.01
I0601 11:51:38.505547 24067 solver.cpp:237] Iteration 360, loss = 6.49926
I0601 11:51:38.505764 24067 solver.cpp:253]     Train net output #0: loss = 6.51336 (* 1 = 6.51336 loss)
I0601 11:51:38.505787 24067 sgd_solver.cpp:106] Iteration 360, lr = 0.01
I0601 11:51:43.956940 24067 solver.cpp:237] Iteration 380, loss = 6.48521
I0601 11:51:43.956990 24067 solver.cpp:253]     Train net output #0: loss = 6.62345 (* 1 = 6.62345 loss)
I0601 11:51:43.956995 24067 sgd_solver.cpp:106] Iteration 380, lr = 0.01
I0601 11:51:49.403266 24067 solver.cpp:237] Iteration 400, loss = 6.41505
I0601 11:51:49.403317 24067 solver.cpp:253]     Train net output #0: loss = 6.37569 (* 1 = 6.37569 loss)
I0601 11:51:49.403323 24067 sgd_solver.cpp:106] Iteration 400, lr = 0.01
I0601 11:51:54.857743 24067 solver.cpp:237] Iteration 420, loss = 6.41508
I0601 11:51:54.857796 24067 solver.cpp:253]     Train net output #0: loss = 6.33299 (* 1 = 6.33299 loss)
I0601 11:51:54.857802 24067 sgd_solver.cpp:106] Iteration 420, lr = 0.01
I0601 11:52:00.312875 24067 solver.cpp:237] Iteration 440, loss = 6.39575
I0601 11:52:00.312928 24067 solver.cpp:253]     Train net output #0: loss = 6.58032 (* 1 = 6.58032 loss)
I0601 11:52:00.312947 24067 sgd_solver.cpp:106] Iteration 440, lr = 0.01
I0601 11:52:05.769101 24067 solver.cpp:237] Iteration 460, loss = 6.40011
I0601 11:52:05.769150 24067 solver.cpp:253]     Train net output #0: loss = 6.45064 (* 1 = 6.45064 loss)
I0601 11:52:05.769155 24067 sgd_solver.cpp:106] Iteration 460, lr = 0.01
I0601 11:52:11.236742 24067 solver.cpp:237] Iteration 480, loss = 6.38717
I0601 11:52:11.237011 24067 solver.cpp:253]     Train net output #0: loss = 6.39001 (* 1 = 6.39001 loss)
I0601 11:52:11.237036 24067 sgd_solver.cpp:106] Iteration 480, lr = 0.01
I0601 11:52:16.707175 24067 solver.cpp:237] Iteration 500, loss = 6.39502
I0601 11:52:16.707218 24067 solver.cpp:253]     Train net output #0: loss = 6.29754 (* 1 = 6.29754 loss)
I0601 11:52:16.707224 24067 sgd_solver.cpp:106] Iteration 500, lr = 0.01
I0601 11:52:22.171594 24067 solver.cpp:237] Iteration 520, loss = 6.32736
I0601 11:52:22.171640 24067 solver.cpp:253]     Train net output #0: loss = 6.32082 (* 1 = 6.32082 loss)
I0601 11:52:22.171649 24067 sgd_solver.cpp:106] Iteration 520, lr = 0.01
I0601 11:52:27.635473 24067 solver.cpp:237] Iteration 540, loss = 6.33686
I0601 11:52:27.635519 24067 solver.cpp:253]     Train net output #0: loss = 6.31735 (* 1 = 6.31735 loss)
I0601 11:52:27.635525 24067 sgd_solver.cpp:106] Iteration 540, lr = 0.01
I0601 11:52:33.108281 24067 solver.cpp:237] Iteration 560, loss = 6.33975
I0601 11:52:33.108326 24067 solver.cpp:253]     Train net output #0: loss = 6.23456 (* 1 = 6.23456 loss)
I0601 11:52:33.108333 24067 sgd_solver.cpp:106] Iteration 560, lr = 0.01
I0601 11:52:38.572592 24067 solver.cpp:237] Iteration 580, loss = 6.31665
I0601 11:52:38.572639 24067 solver.cpp:253]     Train net output #0: loss = 6.39712 (* 1 = 6.39712 loss)
I0601 11:52:38.572649 24067 sgd_solver.cpp:106] Iteration 580, lr = 0.01
I0601 11:52:44.042774 24067 solver.cpp:237] Iteration 600, loss = 6.25485
I0601 11:52:44.042999 24067 solver.cpp:253]     Train net output #0: loss = 6.24537 (* 1 = 6.24537 loss)
I0601 11:52:44.043023 24067 sgd_solver.cpp:106] Iteration 600, lr = 0.01
I0601 11:52:49.513712 24067 solver.cpp:237] Iteration 620, loss = 6.2748
I0601 11:52:49.513753 24067 solver.cpp:253]     Train net output #0: loss = 6.31544 (* 1 = 6.31544 loss)
I0601 11:52:49.513759 24067 sgd_solver.cpp:106] Iteration 620, lr = 0.01
I0601 11:52:54.981376 24067 solver.cpp:237] Iteration 640, loss = 6.26746
I0601 11:52:54.981406 24067 solver.cpp:253]     Train net output #0: loss = 6.24135 (* 1 = 6.24135 loss)
I0601 11:52:54.981412 24067 sgd_solver.cpp:106] Iteration 640, lr = 0.01
I0601 11:53:00.452703 24067 solver.cpp:237] Iteration 660, loss = 6.20633
I0601 11:53:00.452754 24067 solver.cpp:253]     Train net output #0: loss = 6.24768 (* 1 = 6.24768 loss)
I0601 11:53:00.452761 24067 sgd_solver.cpp:106] Iteration 660, lr = 0.01
I0601 11:53:05.932097 24067 solver.cpp:237] Iteration 680, loss = 6.27465
I0601 11:53:05.932149 24067 solver.cpp:253]     Train net output #0: loss = 6.17241 (* 1 = 6.17241 loss)
I0601 11:53:05.932166 24067 sgd_solver.cpp:106] Iteration 680, lr = 0.01
I0601 11:53:11.413655 24067 solver.cpp:237] Iteration 700, loss = 6.20496
I0601 11:53:11.413710 24067 solver.cpp:253]     Train net output #0: loss = 6.13201 (* 1 = 6.13201 loss)
I0601 11:53:11.413717 24067 sgd_solver.cpp:106] Iteration 700, lr = 0.01
I0601 11:53:16.890883 24067 solver.cpp:237] Iteration 720, loss = 6.18078
I0601 11:53:16.891132 24067 solver.cpp:253]     Train net output #0: loss = 6.09266 (* 1 = 6.09266 loss)
I0601 11:53:16.891158 24067 sgd_solver.cpp:106] Iteration 720, lr = 0.01
I0601 11:53:22.369411 24067 solver.cpp:237] Iteration 740, loss = 6.17726
I0601 11:53:22.369460 24067 solver.cpp:253]     Train net output #0: loss = 6.04574 (* 1 = 6.04574 loss)
I0601 11:53:22.369467 24067 sgd_solver.cpp:106] Iteration 740, lr = 0.01
I0601 11:53:27.848639 24067 solver.cpp:237] Iteration 760, loss = 6.18844
I0601 11:53:27.848686 24067 solver.cpp:253]     Train net output #0: loss = 6.22916 (* 1 = 6.22916 loss)
I0601 11:53:27.848695 24067 sgd_solver.cpp:106] Iteration 760, lr = 0.01
I0601 11:53:33.325438 24067 solver.cpp:237] Iteration 780, loss = 6.15488
I0601 11:53:33.325484 24067 solver.cpp:253]     Train net output #0: loss = 6.09679 (* 1 = 6.09679 loss)
I0601 11:53:33.325491 24067 sgd_solver.cpp:106] Iteration 780, lr = 0.01
I0601 11:53:38.798554 24067 solver.cpp:237] Iteration 800, loss = 6.14897
I0601 11:53:38.798600 24067 solver.cpp:253]     Train net output #0: loss = 6.02178 (* 1 = 6.02178 loss)
I0601 11:53:38.798607 24067 sgd_solver.cpp:106] Iteration 800, lr = 0.01
I0601 11:53:44.274751 24067 solver.cpp:237] Iteration 820, loss = 6.14343
I0601 11:53:44.274798 24067 solver.cpp:253]     Train net output #0: loss = 6.16572 (* 1 = 6.16572 loss)
I0601 11:53:44.274806 24067 sgd_solver.cpp:106] Iteration 820, lr = 0.01
I0601 11:53:49.756974 24067 solver.cpp:237] Iteration 840, loss = 6.11509
I0601 11:53:49.757216 24067 solver.cpp:253]     Train net output #0: loss = 6.24622 (* 1 = 6.24622 loss)
I0601 11:53:49.757241 24067 sgd_solver.cpp:106] Iteration 840, lr = 0.01
I0601 11:53:55.241583 24067 solver.cpp:237] Iteration 860, loss = 6.10752
I0601 11:53:55.241631 24067 solver.cpp:253]     Train net output #0: loss = 6.11066 (* 1 = 6.11066 loss)
I0601 11:53:55.241638 24067 sgd_solver.cpp:106] Iteration 860, lr = 0.01
I0601 11:54:00.720813 24067 solver.cpp:237] Iteration 880, loss = 6.08835
I0601 11:54:00.720860 24067 solver.cpp:253]     Train net output #0: loss = 5.96167 (* 1 = 5.96167 loss)
I0601 11:54:00.720870 24067 sgd_solver.cpp:106] Iteration 880, lr = 0.01
I0601 11:54:06.192605 24067 solver.cpp:237] Iteration 900, loss = 6.09595
I0601 11:54:06.192637 24067 solver.cpp:253]     Train net output #0: loss = 6.08362 (* 1 = 6.08362 loss)
I0601 11:54:06.192646 24067 sgd_solver.cpp:106] Iteration 900, lr = 0.01
I0601 11:54:11.667196 24067 solver.cpp:237] Iteration 920, loss = 5.99902
I0601 11:54:11.667243 24067 solver.cpp:253]     Train net output #0: loss = 5.9364 (* 1 = 5.9364 loss)
I0601 11:54:11.667249 24067 sgd_solver.cpp:106] Iteration 920, lr = 0.01
I0601 11:54:17.144549 24067 solver.cpp:237] Iteration 940, loss = 6.03091
I0601 11:54:17.144585 24067 solver.cpp:253]     Train net output #0: loss = 6.3169 (* 1 = 6.3169 loss)
I0601 11:54:17.144593 24067 sgd_solver.cpp:106] Iteration 940, lr = 0.01
I0601 11:54:22.628787 24067 solver.cpp:237] Iteration 960, loss = 6.04197
I0601 11:54:22.629019 24067 solver.cpp:253]     Train net output #0: loss = 6.06357 (* 1 = 6.06357 loss)
I0601 11:54:22.629041 24067 sgd_solver.cpp:106] Iteration 960, lr = 0.01
I0601 11:54:28.096722 24067 solver.cpp:237] Iteration 980, loss = 6.02326
I0601 11:54:28.096771 24067 solver.cpp:253]     Train net output #0: loss = 6.1676 (* 1 = 6.1676 loss)
I0601 11:54:28.096778 24067 sgd_solver.cpp:106] Iteration 980, lr = 0.01
I0601 11:54:33.488921 24067 solver.cpp:341] Iteration 1000, Testing net (#0)
I0601 11:54:33.563141 24067 blocking_queue.cpp:50] Data layer prefetch queue empty
I0601 11:55:03.842293 24067 solver.cpp:409]     Test net output #0: accuracy = 0.0311602
I0601 11:55:03.842437 24067 solver.cpp:409]     Test net output #1: loss = 6.05869 (* 1 = 6.05869 loss)
I0601 11:55:03.922046 24067 solver.cpp:237] Iteration 1000, loss = 5.96125
I0601 11:55:03.922078 24067 solver.cpp:253]     Train net output #0: loss = 5.99183 (* 1 = 5.99183 loss)
I0601 11:55:03.922088 24067 sgd_solver.cpp:106] Iteration 1000, lr = 0.01
I0601 11:55:09.374259 24067 solver.cpp:237] Iteration 1020, loss = 5.97081
I0601 11:55:09.374308 24067 solver.cpp:253]     Train net output #0: loss = 6.13063 (* 1 = 6.13063 loss)
I0601 11:55:09.374317 24067 sgd_solver.cpp:106] Iteration 1020, lr = 0.01
I0601 11:55:14.824602 24067 solver.cpp:237] Iteration 1040, loss = 5.98327
I0601 11:55:14.824646 24067 solver.cpp:253]     Train net output #0: loss = 6.12319 (* 1 = 6.12319 loss)
I0601 11:55:14.824654 24067 sgd_solver.cpp:106] Iteration 1040, lr = 0.01
I0601 11:55:20.281968 24067 solver.cpp:237] Iteration 1060, loss = 5.93141
I0601 11:55:20.282014 24067 solver.cpp:253]     Train net output #0: loss = 6.04958 (* 1 = 6.04958 loss)
I0601 11:55:20.282023 24067 sgd_solver.cpp:106] Iteration 1060, lr = 0.01
I0601 11:55:25.742606 24067 solver.cpp:237] Iteration 1080, loss = 5.91102
I0601 11:55:25.742650 24067 solver.cpp:253]     Train net output #0: loss = 5.93108 (* 1 = 5.93108 loss)
I0601 11:55:25.742658 24067 sgd_solver.cpp:106] Iteration 1080, lr = 0.01
I0601 11:55:31.204432 24067 solver.cpp:237] Iteration 1100, loss = 5.93767
I0601 11:55:31.204481 24067 solver.cpp:253]     Train net output #0: loss = 5.92851 (* 1 = 5.92851 loss)
I0601 11:55:31.204489 24067 sgd_solver.cpp:106] Iteration 1100, lr = 0.01
I0601 11:55:36.669870 24067 solver.cpp:237] Iteration 1120, loss = 5.89311
I0601 11:55:36.670130 24067 solver.cpp:253]     Train net output #0: loss = 5.66071 (* 1 = 5.66071 loss)
I0601 11:55:36.670156 24067 sgd_solver.cpp:106] Iteration 1120, lr = 0.01
I0601 11:55:42.131052 24067 solver.cpp:237] Iteration 1140, loss = 5.91914
I0601 11:55:42.131104 24067 solver.cpp:253]     Train net output #0: loss = 5.86141 (* 1 = 5.86141 loss)
I0601 11:55:42.131113 24067 sgd_solver.cpp:106] Iteration 1140, lr = 0.01
I0601 11:55:47.590680 24067 solver.cpp:237] Iteration 1160, loss = 5.87615
I0601 11:55:47.590740 24067 solver.cpp:253]     Train net output #0: loss = 5.86096 (* 1 = 5.86096 loss)
I0601 11:55:47.590746 24067 sgd_solver.cpp:106] Iteration 1160, lr = 0.01
I0601 11:55:53.058542 24067 solver.cpp:237] Iteration 1180, loss = 5.91845
I0601 11:55:53.058589 24067 solver.cpp:253]     Train net output #0: loss = 6.03676 (* 1 = 6.03676 loss)
I0601 11:55:53.058598 24067 sgd_solver.cpp:106] Iteration 1180, lr = 0.01
I0601 11:55:58.529754 24067 solver.cpp:237] Iteration 1200, loss = 5.89602
I0601 11:55:58.529803 24067 solver.cpp:253]     Train net output #0: loss = 5.8852 (* 1 = 5.8852 loss)
I0601 11:55:58.529813 24067 sgd_solver.cpp:106] Iteration 1200, lr = 0.01
I0601 11:56:03.997593 24067 solver.cpp:237] Iteration 1220, loss = 5.96448
I0601 11:56:03.997640 24067 solver.cpp:253]     Train net output #0: loss = 6.01248 (* 1 = 6.01248 loss)
I0601 11:56:03.997648 24067 sgd_solver.cpp:106] Iteration 1220, lr = 0.01
I0601 11:56:09.468230 24067 solver.cpp:237] Iteration 1240, loss = 5.88548
I0601 11:56:09.468435 24067 solver.cpp:253]     Train net output #0: loss = 5.95808 (* 1 = 5.95808 loss)
I0601 11:56:09.468444 24067 sgd_solver.cpp:106] Iteration 1240, lr = 0.01
I0601 11:56:14.936522 24067 solver.cpp:237] Iteration 1260, loss = 5.87997
I0601 11:56:14.936558 24067 solver.cpp:253]     Train net output #0: loss = 5.86228 (* 1 = 5.86228 loss)
I0601 11:56:14.936565 24067 sgd_solver.cpp:106] Iteration 1260, lr = 0.01
I0601 11:56:20.407264 24067 solver.cpp:237] Iteration 1280, loss = 5.81817
I0601 11:56:20.407320 24067 solver.cpp:253]     Train net output #0: loss = 5.94977 (* 1 = 5.94977 loss)
I0601 11:56:20.407330 24067 sgd_solver.cpp:106] Iteration 1280, lr = 0.01
I0601 11:56:25.881909 24067 solver.cpp:237] Iteration 1300, loss = 5.92092
I0601 11:56:25.881953 24067 solver.cpp:253]     Train net output #0: loss = 5.73133 (* 1 = 5.73133 loss)
I0601 11:56:25.881961 24067 sgd_solver.cpp:106] Iteration 1300, lr = 0.01
I0601 11:56:31.350991 24067 solver.cpp:237] Iteration 1320, loss = 5.85244
I0601 11:56:31.351039 24067 solver.cpp:253]     Train net output #0: loss = 5.76222 (* 1 = 5.76222 loss)
I0601 11:56:31.351047 24067 sgd_solver.cpp:106] Iteration 1320, lr = 0.01
I0601 11:56:36.830885 24067 solver.cpp:237] Iteration 1340, loss = 5.81835
I0601 11:56:36.830929 24067 solver.cpp:253]     Train net output #0: loss = 5.88858 (* 1 = 5.88858 loss)
I0601 11:56:36.830936 24067 sgd_solver.cpp:106] Iteration 1340, lr = 0.01
I0601 11:56:42.311244 24067 solver.cpp:237] Iteration 1360, loss = 5.8389
I0601 11:56:42.311470 24067 solver.cpp:253]     Train net output #0: loss = 5.77196 (* 1 = 5.77196 loss)
I0601 11:56:42.311492 24067 sgd_solver.cpp:106] Iteration 1360, lr = 0.01
I0601 11:56:47.786363 24067 solver.cpp:237] Iteration 1380, loss = 5.82085
I0601 11:56:47.786392 24067 solver.cpp:253]     Train net output #0: loss = 5.72212 (* 1 = 5.72212 loss)
I0601 11:56:47.786398 24067 sgd_solver.cpp:106] Iteration 1380, lr = 0.01
I0601 11:56:53.261785 24067 solver.cpp:237] Iteration 1400, loss = 5.80512
I0601 11:56:53.261817 24067 solver.cpp:253]     Train net output #0: loss = 5.98228 (* 1 = 5.98228 loss)
I0601 11:56:53.261822 24067 sgd_solver.cpp:106] Iteration 1400, lr = 0.01
I0601 11:56:58.738402 24067 solver.cpp:237] Iteration 1420, loss = 5.81836
I0601 11:56:58.738446 24067 solver.cpp:253]     Train net output #0: loss = 5.79228 (* 1 = 5.79228 loss)
I0601 11:56:58.738452 24067 sgd_solver.cpp:106] Iteration 1420, lr = 0.01
I0601 11:57:04.206184 24067 solver.cpp:237] Iteration 1440, loss = 5.82577
I0601 11:57:04.206218 24067 solver.cpp:253]     Train net output #0: loss = 5.71702 (* 1 = 5.71702 loss)
I0601 11:57:04.206223 24067 sgd_solver.cpp:106] Iteration 1440, lr = 0.01
I0601 11:57:09.639026 24067 solver.cpp:237] Iteration 1460, loss = 5.76187
I0601 11:57:09.639070 24067 solver.cpp:253]     Train net output #0: loss = 5.66283 (* 1 = 5.66283 loss)
I0601 11:57:09.639077 24067 sgd_solver.cpp:106] Iteration 1460, lr = 0.01
I0601 11:57:15.382686 24067 solver.cpp:237] Iteration 1480, loss = 5.79365
I0601 11:57:15.382947 24067 solver.cpp:253]     Train net output #0: loss = 5.73097 (* 1 = 5.73097 loss)
I0601 11:57:15.382966 24067 sgd_solver.cpp:106] Iteration 1480, lr = 0.01
I0601 11:57:16.119712 24067 blocking_queue.cpp:50] Data layer prefetch queue empty
I0601 11:57:22.121944 24067 solver.cpp:237] Iteration 1500, loss = 5.81927
I0601 11:57:22.122000 24067 solver.cpp:253]     Train net output #0: loss = 5.64438 (* 1 = 5.64438 loss)
I0601 11:57:22.122012 24067 sgd_solver.cpp:106] Iteration 1500, lr = 0.01
I0601 11:57:28.376124 24067 solver.cpp:237] Iteration 1520, loss = 5.76856
I0601 11:57:28.376175 24067 solver.cpp:253]     Train net output #0: loss = 5.82073 (* 1 = 5.82073 loss)
I0601 11:57:28.376183 24067 sgd_solver.cpp:106] Iteration 1520, lr = 0.01
I0601 11:57:34.327428 24067 solver.cpp:237] Iteration 1540, loss = 5.82429
I0601 11:57:34.327478 24067 solver.cpp:253]     Train net output #0: loss = 5.93702 (* 1 = 5.93702 loss)
I0601 11:57:34.327486 24067 sgd_solver.cpp:106] Iteration 1540, lr = 0.01
I0601 11:57:39.798163 24067 solver.cpp:237] Iteration 1560, loss = 5.73481
I0601 11:57:39.798208 24067 solver.cpp:253]     Train net output #0: loss = 5.74694 (* 1 = 5.74694 loss)
I0601 11:57:39.798216 24067 sgd_solver.cpp:106] Iteration 1560, lr = 0.01
I0601 11:57:45.276877 24067 solver.cpp:237] Iteration 1580, loss = 5.75234
I0601 11:57:45.276923 24067 solver.cpp:253]     Train net output #0: loss = 5.67137 (* 1 = 5.67137 loss)
I0601 11:57:45.276932 24067 sgd_solver.cpp:106] Iteration 1580, lr = 0.01
I0601 11:57:50.752228 24067 solver.cpp:237] Iteration 1600, loss = 5.75992
I0601 11:57:50.752480 24067 solver.cpp:253]     Train net output #0: loss = 5.74255 (* 1 = 5.74255 loss)
I0601 11:57:50.752506 24067 sgd_solver.cpp:106] Iteration 1600, lr = 0.01
I0601 11:57:56.231353 24067 solver.cpp:237] Iteration 1620, loss = 5.72652
I0601 11:57:56.231400 24067 solver.cpp:253]     Train net output #0: loss = 5.61125 (* 1 = 5.61125 loss)
I0601 11:57:56.231406 24067 sgd_solver.cpp:106] Iteration 1620, lr = 0.01
I0601 11:58:01.711062 24067 solver.cpp:237] Iteration 1640, loss = 5.69781
I0601 11:58:01.711112 24067 solver.cpp:253]     Train net output #0: loss = 5.60872 (* 1 = 5.60872 loss)
I0601 11:58:01.711120 24067 sgd_solver.cpp:106] Iteration 1640, lr = 0.01
I0601 11:58:07.193092 24067 solver.cpp:237] Iteration 1660, loss = 5.65144
I0601 11:58:07.193140 24067 solver.cpp:253]     Train net output #0: loss = 5.95087 (* 1 = 5.95087 loss)
I0601 11:58:07.193146 24067 sgd_solver.cpp:106] Iteration 1660, lr = 0.01
I0601 11:58:12.677050 24067 solver.cpp:237] Iteration 1680, loss = 5.76101
I0601 11:58:12.677132 24067 solver.cpp:253]     Train net output #0: loss = 5.68339 (* 1 = 5.68339 loss)
I0601 11:58:12.677151 24067 sgd_solver.cpp:106] Iteration 1680, lr = 0.01
I0601 11:58:18.161654 24067 solver.cpp:237] Iteration 1700, loss = 5.65393
I0601 11:58:18.161705 24067 solver.cpp:253]     Train net output #0: loss = 5.44568 (* 1 = 5.44568 loss)
I0601 11:58:18.161715 24067 sgd_solver.cpp:106] Iteration 1700, lr = 0.01
I0601 11:58:23.642550 24067 solver.cpp:237] Iteration 1720, loss = 5.72268
I0601 11:58:23.642808 24067 solver.cpp:253]     Train net output #0: loss = 5.73359 (* 1 = 5.73359 loss)
I0601 11:58:23.642830 24067 sgd_solver.cpp:106] Iteration 1720, lr = 0.01
I0601 11:58:29.123106 24067 solver.cpp:237] Iteration 1740, loss = 5.72116
I0601 11:58:29.123157 24067 solver.cpp:253]     Train net output #0: loss = 5.50149 (* 1 = 5.50149 loss)
I0601 11:58:29.123164 24067 sgd_solver.cpp:106] Iteration 1740, lr = 0.01
I0601 11:58:34.602859 24067 solver.cpp:237] Iteration 1760, loss = 5.71327
I0601 11:58:34.602921 24067 solver.cpp:253]     Train net output #0: loss = 5.96928 (* 1 = 5.96928 loss)
I0601 11:58:34.602928 24067 sgd_solver.cpp:106] Iteration 1760, lr = 0.01
I0601 11:58:40.082334 24067 solver.cpp:237] Iteration 1780, loss = 5.66469
I0601 11:58:40.082384 24067 solver.cpp:253]     Train net output #0: loss = 5.70337 (* 1 = 5.70337 loss)
I0601 11:58:40.082391 24067 sgd_solver.cpp:106] Iteration 1780, lr = 0.01
I0601 11:58:45.569492 24067 solver.cpp:237] Iteration 1800, loss = 5.63544
I0601 11:58:45.569532 24067 solver.cpp:253]     Train net output #0: loss = 5.40989 (* 1 = 5.40989 loss)
I0601 11:58:45.569540 24067 sgd_solver.cpp:106] Iteration 1800, lr = 0.01
I0601 11:58:51.050992 24067 solver.cpp:237] Iteration 1820, loss = 5.64401
I0601 11:58:51.051041 24067 solver.cpp:253]     Train net output #0: loss = 5.64945 (* 1 = 5.64945 loss)
I0601 11:58:51.051049 24067 sgd_solver.cpp:106] Iteration 1820, lr = 0.01
I0601 11:58:56.523645 24067 solver.cpp:237] Iteration 1840, loss = 5.67874
I0601 11:58:56.523901 24067 solver.cpp:253]     Train net output #0: loss = 5.55375 (* 1 = 5.55375 loss)
I0601 11:58:56.523927 24067 sgd_solver.cpp:106] Iteration 1840, lr = 0.01
I0601 11:59:02.011631 24067 solver.cpp:237] Iteration 1860, loss = 5.60149
I0601 11:59:02.011662 24067 solver.cpp:253]     Train net output #0: loss = 5.66361 (* 1 = 5.66361 loss)
I0601 11:59:02.011668 24067 sgd_solver.cpp:106] Iteration 1860, lr = 0.01
I0601 11:59:07.498877 24067 solver.cpp:237] Iteration 1880, loss = 5.65134
I0601 11:59:07.498922 24067 solver.cpp:253]     Train net output #0: loss = 5.61331 (* 1 = 5.61331 loss)
I0601 11:59:07.498931 24067 sgd_solver.cpp:106] Iteration 1880, lr = 0.01
I0601 11:59:12.976433 24067 solver.cpp:237] Iteration 1900, loss = 5.67017
I0601 11:59:12.976477 24067 solver.cpp:253]     Train net output #0: loss = 5.59037 (* 1 = 5.59037 loss)
I0601 11:59:12.976486 24067 sgd_solver.cpp:106] Iteration 1900, lr = 0.01
I0601 11:59:18.458137 24067 solver.cpp:237] Iteration 1920, loss = 5.57644
I0601 11:59:18.458183 24067 solver.cpp:253]     Train net output #0: loss = 5.7499 (* 1 = 5.7499 loss)
I0601 11:59:18.458190 24067 sgd_solver.cpp:106] Iteration 1920, lr = 0.01
I0601 11:59:23.941632 24067 solver.cpp:237] Iteration 1940, loss = 5.66719
I0601 11:59:23.941679 24067 solver.cpp:253]     Train net output #0: loss = 5.84539 (* 1 = 5.84539 loss)
I0601 11:59:23.941687 24067 sgd_solver.cpp:106] Iteration 1940, lr = 0.01
I0601 11:59:29.432907 24067 solver.cpp:237] Iteration 1960, loss = 5.66969
I0601 11:59:29.433136 24067 solver.cpp:253]     Train net output #0: loss = 5.55658 (* 1 = 5.55658 loss)
I0601 11:59:29.433161 24067 sgd_solver.cpp:106] Iteration 1960, lr = 0.01
I0601 11:59:34.940217 24067 solver.cpp:237] Iteration 1980, loss = 5.59193
I0601 11:59:34.940260 24067 solver.cpp:253]     Train net output #0: loss = 5.5254 (* 1 = 5.5254 loss)
I0601 11:59:34.940276 24067 sgd_solver.cpp:106] Iteration 1980, lr = 0.01
I0601 11:59:40.331132 24067 solver.cpp:341] Iteration 2000, Testing net (#0)
I0601 12:00:11.616950 24067 blocking_queue.cpp:50] Data layer prefetch queue empty
I0601 12:00:15.731015 24067 solver.cpp:409]     Test net output #0: accuracy = 0.0574004
I0601 12:00:15.731062 24067 solver.cpp:409]     Test net output #1: loss = 5.52018 (* 1 = 5.52018 loss)
I0601 12:00:15.810853 24067 solver.cpp:237] Iteration 2000, loss = 5.54128
I0601 12:00:15.810890 24067 solver.cpp:253]     Train net output #0: loss = 5.74967 (* 1 = 5.74967 loss)
I0601 12:00:15.810899 24067 sgd_solver.cpp:106] Iteration 2000, lr = 0.01
I0601 12:00:21.254623 24067 solver.cpp:237] Iteration 2020, loss = 5.57228
I0601 12:00:21.254659 24067 solver.cpp:253]     Train net output #0: loss = 5.49361 (* 1 = 5.49361 loss)
I0601 12:00:21.254668 24067 sgd_solver.cpp:106] Iteration 2020, lr = 0.01
I0601 12:00:26.697638 24067 solver.cpp:237] Iteration 2040, loss = 5.61735
I0601 12:00:26.697685 24067 solver.cpp:253]     Train net output #0: loss = 5.66144 (* 1 = 5.66144 loss)
I0601 12:00:26.697695 24067 sgd_solver.cpp:106] Iteration 2040, lr = 0.01
I0601 12:00:32.144652 24067 solver.cpp:237] Iteration 2060, loss = 5.60098
I0601 12:00:32.144698 24067 solver.cpp:253]     Train net output #0: loss = 5.62764 (* 1 = 5.62764 loss)
I0601 12:00:32.144706 24067 sgd_solver.cpp:106] Iteration 2060, lr = 0.01
I0601 12:00:37.596967 24067 solver.cpp:237] Iteration 2080, loss = 5.59492
I0601 12:00:37.597018 24067 solver.cpp:253]     Train net output #0: loss = 5.51827 (* 1 = 5.51827 loss)
I0601 12:00:37.597026 24067 sgd_solver.cpp:106] Iteration 2080, lr = 0.01
I0601 12:00:43.050722 24067 solver.cpp:237] Iteration 2100, loss = 5.56758
I0601 12:00:43.050937 24067 solver.cpp:253]     Train net output #0: loss = 5.51628 (* 1 = 5.51628 loss)
I0601 12:00:43.050959 24067 sgd_solver.cpp:106] Iteration 2100, lr = 0.01
I0601 12:00:48.501330 24067 solver.cpp:237] Iteration 2120, loss = 5.57159
I0601 12:00:48.501369 24067 solver.cpp:253]     Train net output #0: loss = 5.57619 (* 1 = 5.57619 loss)
I0601 12:00:48.501377 24067 sgd_solver.cpp:106] Iteration 2120, lr = 0.01
I0601 12:00:53.925806 24067 solver.cpp:237] Iteration 2140, loss = 5.58665
I0601 12:00:53.925834 24067 solver.cpp:253]     Train net output #0: loss = 5.67194 (* 1 = 5.67194 loss)
I0601 12:00:53.925843 24067 sgd_solver.cpp:106] Iteration 2140, lr = 0.01
I0601 12:00:59.337009 24067 solver.cpp:237] Iteration 2160, loss = 5.57266
I0601 12:00:59.337047 24067 solver.cpp:253]     Train net output #0: loss = 5.6088 (* 1 = 5.6088 loss)
I0601 12:00:59.337054 24067 sgd_solver.cpp:106] Iteration 2160, lr = 0.01
I0601 12:01:04.747967 24067 solver.cpp:237] Iteration 2180, loss = 5.51195
I0601 12:01:04.748010 24067 solver.cpp:253]     Train net output #0: loss = 5.60986 (* 1 = 5.60986 loss)
I0601 12:01:04.748021 24067 sgd_solver.cpp:106] Iteration 2180, lr = 0.01
I0601 12:01:10.163425 24067 solver.cpp:237] Iteration 2200, loss = 5.53147
I0601 12:01:10.163466 24067 solver.cpp:253]     Train net output #0: loss = 5.74768 (* 1 = 5.74768 loss)
I0601 12:01:10.163487 24067 sgd_solver.cpp:106] Iteration 2200, lr = 0.01
I0601 12:01:15.581162 24067 solver.cpp:237] Iteration 2220, loss = 5.53995
I0601 12:01:15.581357 24067 solver.cpp:253]     Train net output #0: loss = 5.50301 (* 1 = 5.50301 loss)
I0601 12:01:15.581384 24067 sgd_solver.cpp:106] Iteration 2220, lr = 0.01
I0601 12:01:21.043545 24067 solver.cpp:237] Iteration 2240, loss = 5.57099
I0601 12:01:21.043577 24067 solver.cpp:253]     Train net output #0: loss = 5.51759 (* 1 = 5.51759 loss)
I0601 12:01:21.043589 24067 sgd_solver.cpp:106] Iteration 2240, lr = 0.01
I0601 12:01:26.511802 24067 solver.cpp:237] Iteration 2260, loss = 5.58268
I0601 12:01:26.511853 24067 solver.cpp:253]     Train net output #0: loss = 5.4245 (* 1 = 5.4245 loss)
I0601 12:01:26.511862 24067 sgd_solver.cpp:106] Iteration 2260, lr = 0.01
I0601 12:01:31.958235 24067 solver.cpp:237] Iteration 2280, loss = 5.56365
I0601 12:01:31.958274 24067 solver.cpp:253]     Train net output #0: loss = 5.19152 (* 1 = 5.19152 loss)
I0601 12:01:31.958282 24067 sgd_solver.cpp:106] Iteration 2280, lr = 0.01
I0601 12:01:37.393214 24067 solver.cpp:237] Iteration 2300, loss = 5.52693
I0601 12:01:37.393254 24067 solver.cpp:253]     Train net output #0: loss = 5.4404 (* 1 = 5.4404 loss)
I0601 12:01:37.393262 24067 sgd_solver.cpp:106] Iteration 2300, lr = 0.01
I0601 12:01:42.865311 24067 solver.cpp:237] Iteration 2320, loss = 5.49908
I0601 12:01:42.865352 24067 solver.cpp:253]     Train net output #0: loss = 5.3679 (* 1 = 5.3679 loss)
I0601 12:01:42.865361 24067 sgd_solver.cpp:106] Iteration 2320, lr = 0.01
I0601 12:01:48.326308 24067 solver.cpp:237] Iteration 2340, loss = 5.54289
I0601 12:01:48.326488 24067 solver.cpp:253]     Train net output #0: loss = 5.65424 (* 1 = 5.65424 loss)
I0601 12:01:48.326511 24067 sgd_solver.cpp:106] Iteration 2340, lr = 0.01
I0601 12:01:53.799017 24067 solver.cpp:237] Iteration 2360, loss = 5.55119
I0601 12:01:53.799072 24067 solver.cpp:253]     Train net output #0: loss = 5.39192 (* 1 = 5.39192 loss)
I0601 12:01:53.799078 24067 sgd_solver.cpp:106] Iteration 2360, lr = 0.01
I0601 12:01:59.260149 24067 solver.cpp:237] Iteration 2380, loss = 5.52174
I0601 12:01:59.260192 24067 solver.cpp:253]     Train net output #0: loss = 5.59098 (* 1 = 5.59098 loss)
I0601 12:01:59.260200 24067 sgd_solver.cpp:106] Iteration 2380, lr = 0.01
I0601 12:02:04.733168 24067 solver.cpp:237] Iteration 2400, loss = 5.54165
I0601 12:02:04.733203 24067 solver.cpp:253]     Train net output #0: loss = 5.57166 (* 1 = 5.57166 loss)
I0601 12:02:04.733213 24067 sgd_solver.cpp:106] Iteration 2400, lr = 0.01
I0601 12:02:10.212188 24067 solver.cpp:237] Iteration 2420, loss = 5.48675
I0601 12:02:10.212229 24067 solver.cpp:253]     Train net output #0: loss = 5.29986 (* 1 = 5.29986 loss)
I0601 12:02:10.212249 24067 sgd_solver.cpp:106] Iteration 2420, lr = 0.01
I0601 12:02:15.696573 24067 solver.cpp:237] Iteration 2440, loss = 5.47012
I0601 12:02:15.696612 24067 solver.cpp:253]     Train net output #0: loss = 5.49297 (* 1 = 5.49297 loss)
I0601 12:02:15.696621 24067 sgd_solver.cpp:106] Iteration 2440, lr = 0.01
I0601 12:02:21.184568 24067 solver.cpp:237] Iteration 2460, loss = 5.53869
I0601 12:02:21.184669 24067 solver.cpp:253]     Train net output #0: loss = 5.50752 (* 1 = 5.50752 loss)
I0601 12:02:21.184682 24067 sgd_solver.cpp:106] Iteration 2460, lr = 0.01
I0601 12:02:26.665912 24067 solver.cpp:237] Iteration 2480, loss = 5.49783
I0601 12:02:26.665946 24067 solver.cpp:253]     Train net output #0: loss = 5.57263 (* 1 = 5.57263 loss)
I0601 12:02:26.665956 24067 sgd_solver.cpp:106] Iteration 2480, lr = 0.01
I0601 12:02:32.149549 24067 solver.cpp:237] Iteration 2500, loss = 5.45419
I0601 12:02:32.149580 24067 solver.cpp:253]     Train net output #0: loss = 5.54516 (* 1 = 5.54516 loss)
I0601 12:02:32.149600 24067 sgd_solver.cpp:106] Iteration 2500, lr = 0.01
I0601 12:02:37.635395 24067 solver.cpp:237] Iteration 2520, loss = 5.47915
I0601 12:02:37.635449 24067 solver.cpp:253]     Train net output #0: loss = 5.55473 (* 1 = 5.55473 loss)
I0601 12:02:37.635470 24067 sgd_solver.cpp:106] Iteration 2520, lr = 0.01
I0601 12:02:43.121426 24067 solver.cpp:237] Iteration 2540, loss = 5.43908
I0601 12:02:43.121466 24067 solver.cpp:253]     Train net output #0: loss = 5.50846 (* 1 = 5.50846 loss)
I0601 12:02:43.121474 24067 sgd_solver.cpp:106] Iteration 2540, lr = 0.01
I0601 12:02:48.599189 24067 solver.cpp:237] Iteration 2560, loss = 5.50449
I0601 12:02:48.599227 24067 solver.cpp:253]     Train net output #0: loss = 5.48218 (* 1 = 5.48218 loss)
I0601 12:02:48.599234 24067 sgd_solver.cpp:106] Iteration 2560, lr = 0.01
I0601 12:02:54.070684 24067 solver.cpp:237] Iteration 2580, loss = 5.45813
I0601 12:02:54.070864 24067 solver.cpp:253]     Train net output #0: loss = 5.87758 (* 1 = 5.87758 loss)
I0601 12:02:54.070883 24067 sgd_solver.cpp:106] Iteration 2580, lr = 0.01
I0601 12:02:59.554544 24067 solver.cpp:237] Iteration 2600, loss = 5.46524
I0601 12:02:59.554579 24067 solver.cpp:253]     Train net output #0: loss = 5.57462 (* 1 = 5.57462 loss)
I0601 12:02:59.554585 24067 sgd_solver.cpp:106] Iteration 2600, lr = 0.01
I0601 12:03:05.033071 24067 solver.cpp:237] Iteration 2620, loss = 5.47337
I0601 12:03:05.033120 24067 solver.cpp:253]     Train net output #0: loss = 5.56918 (* 1 = 5.56918 loss)
I0601 12:03:05.033128 24067 sgd_solver.cpp:106] Iteration 2620, lr = 0.01
I0601 12:03:10.521731 24067 solver.cpp:237] Iteration 2640, loss = 5.50621
I0601 12:03:10.521759 24067 solver.cpp:253]     Train net output #0: loss = 5.32502 (* 1 = 5.32502 loss)
I0601 12:03:10.521780 24067 sgd_solver.cpp:106] Iteration 2640, lr = 0.01
I0601 12:03:16.009107 24067 solver.cpp:237] Iteration 2660, loss = 5.46543
I0601 12:03:16.009145 24067 solver.cpp:253]     Train net output #0: loss = 5.75294 (* 1 = 5.75294 loss)
I0601 12:03:16.009153 24067 sgd_solver.cpp:106] Iteration 2660, lr = 0.01
I0601 12:03:21.493919 24067 solver.cpp:237] Iteration 2680, loss = 5.47049
I0601 12:03:21.493968 24067 solver.cpp:253]     Train net output #0: loss = 5.37973 (* 1 = 5.37973 loss)
I0601 12:03:21.493979 24067 sgd_solver.cpp:106] Iteration 2680, lr = 0.01
I0601 12:03:26.937052 24067 solver.cpp:237] Iteration 2700, loss = 5.43321
I0601 12:03:26.937283 24067 solver.cpp:253]     Train net output #0: loss = 5.28649 (* 1 = 5.28649 loss)
I0601 12:03:26.937312 24067 sgd_solver.cpp:106] Iteration 2700, lr = 0.01
I0601 12:03:32.404733 24067 solver.cpp:237] Iteration 2720, loss = 5.45457
I0601 12:03:32.404783 24067 solver.cpp:253]     Train net output #0: loss = 5.5907 (* 1 = 5.5907 loss)
I0601 12:03:32.404791 24067 sgd_solver.cpp:106] Iteration 2720, lr = 0.01
I0601 12:03:37.884675 24067 solver.cpp:237] Iteration 2740, loss = 5.42035
I0601 12:03:37.884716 24067 solver.cpp:253]     Train net output #0: loss = 5.49728 (* 1 = 5.49728 loss)
I0601 12:03:37.884734 24067 sgd_solver.cpp:106] Iteration 2740, lr = 0.01
I0601 12:03:43.365752 24067 solver.cpp:237] Iteration 2760, loss = 5.36191
I0601 12:03:43.365800 24067 solver.cpp:253]     Train net output #0: loss = 5.31542 (* 1 = 5.31542 loss)
I0601 12:03:43.365808 24067 sgd_solver.cpp:106] Iteration 2760, lr = 0.01
I0601 12:03:48.851858 24067 solver.cpp:237] Iteration 2780, loss = 5.4276
I0601 12:03:48.851908 24067 solver.cpp:253]     Train net output #0: loss = 5.45296 (* 1 = 5.45296 loss)
I0601 12:03:48.851917 24067 sgd_solver.cpp:106] Iteration 2780, lr = 0.01
I0601 12:03:54.330935 24067 solver.cpp:237] Iteration 2800, loss = 5.43822
I0601 12:03:54.330976 24067 solver.cpp:253]     Train net output #0: loss = 5.28105 (* 1 = 5.28105 loss)
I0601 12:03:54.330983 24067 sgd_solver.cpp:106] Iteration 2800, lr = 0.01
I0601 12:03:59.797595 24067 solver.cpp:237] Iteration 2820, loss = 5.3746
I0601 12:03:59.797682 24067 solver.cpp:253]     Train net output #0: loss = 5.28249 (* 1 = 5.28249 loss)
I0601 12:03:59.797693 24067 sgd_solver.cpp:106] Iteration 2820, lr = 0.01
I0601 12:04:05.266820 24067 solver.cpp:237] Iteration 2840, loss = 5.45014
I0601 12:04:05.266860 24067 solver.cpp:253]     Train net output #0: loss = 5.27055 (* 1 = 5.27055 loss)
I0601 12:04:05.266878 24067 sgd_solver.cpp:106] Iteration 2840, lr = 0.01
I0601 12:04:10.752840 24067 solver.cpp:237] Iteration 2860, loss = 5.39364
I0601 12:04:10.752879 24067 solver.cpp:253]     Train net output #0: loss = 5.39097 (* 1 = 5.39097 loss)
I0601 12:04:10.752888 24067 sgd_solver.cpp:106] Iteration 2860, lr = 0.01
I0601 12:04:16.221806 24067 solver.cpp:237] Iteration 2880, loss = 5.41197
I0601 12:04:16.221839 24067 solver.cpp:253]     Train net output #0: loss = 5.34174 (* 1 = 5.34174 loss)
I0601 12:04:16.221845 24067 sgd_solver.cpp:106] Iteration 2880, lr = 0.01
I0601 12:04:21.698364 24067 solver.cpp:237] Iteration 2900, loss = 5.39646
I0601 12:04:21.698416 24067 solver.cpp:253]     Train net output #0: loss = 5.31935 (* 1 = 5.31935 loss)
I0601 12:04:21.698426 24067 sgd_solver.cpp:106] Iteration 2900, lr = 0.01
I0601 12:04:27.183429 24067 solver.cpp:237] Iteration 2920, loss = 5.45175
I0601 12:04:27.183459 24067 solver.cpp:253]     Train net output #0: loss = 5.32796 (* 1 = 5.32796 loss)
I0601 12:04:27.183465 24067 sgd_solver.cpp:106] Iteration 2920, lr = 0.01
I0601 12:04:32.660923 24067 solver.cpp:237] Iteration 2940, loss = 5.45874
I0601 12:04:32.661020 24067 solver.cpp:253]     Train net output #0: loss = 5.59229 (* 1 = 5.59229 loss)
I0601 12:04:32.661027 24067 sgd_solver.cpp:106] Iteration 2940, lr = 0.01
I0601 12:04:38.141101 24067 solver.cpp:237] Iteration 2960, loss = 5.39117
I0601 12:04:38.141140 24067 solver.cpp:253]     Train net output #0: loss = 5.45106 (* 1 = 5.45106 loss)
I0601 12:04:38.141147 24067 sgd_solver.cpp:106] Iteration 2960, lr = 0.01
I0601 12:04:43.627789 24067 solver.cpp:237] Iteration 2980, loss = 5.43436
I0601 12:04:43.627837 24067 solver.cpp:253]     Train net output #0: loss = 5.44821 (* 1 = 5.44821 loss)
I0601 12:04:43.627854 24067 sgd_solver.cpp:106] Iteration 2980, lr = 0.01
I0601 12:04:49.031740 24067 solver.cpp:341] Iteration 3000, Testing net (#0)
I0601 12:05:16.488910 24067 blocking_queue.cpp:50] Data layer prefetch queue empty
I0601 12:05:20.404201 24067 solver.cpp:409]     Test net output #0: accuracy = 0.0746002
I0601 12:05:20.404237 24067 solver.cpp:409]     Test net output #1: loss = 5.39079 (* 1 = 5.39079 loss)
I0601 12:05:20.483670 24067 solver.cpp:237] Iteration 3000, loss = 5.38245
I0601 12:05:20.483710 24067 solver.cpp:253]     Train net output #0: loss = 5.29388 (* 1 = 5.29388 loss)
I0601 12:05:20.483718 24067 sgd_solver.cpp:106] Iteration 3000, lr = 0.01
I0601 12:05:25.898253 24067 solver.cpp:237] Iteration 3020, loss = 5.35924
I0601 12:05:25.898303 24067 solver.cpp:253]     Train net output #0: loss = 5.38631 (* 1 = 5.38631 loss)
I0601 12:05:25.898309 24067 sgd_solver.cpp:106] Iteration 3020, lr = 0.01
I0601 12:05:31.345576 24067 solver.cpp:237] Iteration 3040, loss = 5.40847
I0601 12:05:31.345629 24067 solver.cpp:253]     Train net output #0: loss = 5.33348 (* 1 = 5.33348 loss)
I0601 12:05:31.345638 24067 sgd_solver.cpp:106] Iteration 3040, lr = 0.01
I0601 12:05:36.801476 24067 solver.cpp:237] Iteration 3060, loss = 5.42252
I0601 12:05:36.801520 24067 solver.cpp:253]     Train net output #0: loss = 5.4239 (* 1 = 5.4239 loss)
I0601 12:05:36.801528 24067 sgd_solver.cpp:106] Iteration 3060, lr = 0.01
I0601 12:05:42.262004 24067 solver.cpp:237] Iteration 3080, loss = 5.35918
I0601 12:05:42.262048 24067 solver.cpp:253]     Train net output #0: loss = 5.22674 (* 1 = 5.22674 loss)
I0601 12:05:42.262056 24067 sgd_solver.cpp:106] Iteration 3080, lr = 0.01
I0601 12:05:47.717882 24067 solver.cpp:237] Iteration 3100, loss = 5.39802
I0601 12:05:47.718039 24067 solver.cpp:253]     Train net output #0: loss = 5.60966 (* 1 = 5.60966 loss)
I0601 12:05:47.718062 24067 sgd_solver.cpp:106] Iteration 3100, lr = 0.01
I0601 12:05:53.190726 24067 solver.cpp:237] Iteration 3120, loss = 5.42325
I0601 12:05:53.190778 24067 solver.cpp:253]     Train net output #0: loss = 5.3054 (* 1 = 5.3054 loss)
I0601 12:05:53.190786 24067 sgd_solver.cpp:106] Iteration 3120, lr = 0.01
I0601 12:05:58.657920 24067 solver.cpp:237] Iteration 3140, loss = 5.33649
I0601 12:05:58.657968 24067 solver.cpp:253]     Train net output #0: loss = 5.38936 (* 1 = 5.38936 loss)
I0601 12:05:58.657976 24067 sgd_solver.cpp:106] Iteration 3140, lr = 0.01
I0601 12:06:04.127137 24067 solver.cpp:237] Iteration 3160, loss = 5.33838
I0601 12:06:04.127182 24067 solver.cpp:253]     Train net output #0: loss = 5.11524 (* 1 = 5.11524 loss)
I0601 12:06:04.127190 24067 sgd_solver.cpp:106] Iteration 3160, lr = 0.01
I0601 12:06:09.596967 24067 solver.cpp:237] Iteration 3180, loss = 5.33888
I0601 12:06:09.597018 24067 solver.cpp:253]     Train net output #0: loss = 5.3534 (* 1 = 5.3534 loss)
I0601 12:06:09.597026 24067 sgd_solver.cpp:106] Iteration 3180, lr = 0.01
I0601 12:06:15.070188 24067 solver.cpp:237] Iteration 3200, loss = 5.31029
I0601 12:06:15.070232 24067 solver.cpp:253]     Train net output #0: loss = 5.25421 (* 1 = 5.25421 loss)
I0601 12:06:15.070240 24067 sgd_solver.cpp:106] Iteration 3200, lr = 0.01
I0601 12:06:20.548765 24067 solver.cpp:237] Iteration 3220, loss = 5.36559
I0601 12:06:20.548944 24067 solver.cpp:253]     Train net output #0: loss = 5.33607 (* 1 = 5.33607 loss)
I0601 12:06:20.548957 24067 sgd_solver.cpp:106] Iteration 3220, lr = 0.01
I0601 12:06:26.021272 24067 solver.cpp:237] Iteration 3240, loss = 5.3337
I0601 12:06:26.021322 24067 solver.cpp:253]     Train net output #0: loss = 5.3152 (* 1 = 5.3152 loss)
I0601 12:06:26.021329 24067 sgd_solver.cpp:106] Iteration 3240, lr = 0.01
I0601 12:06:31.499533 24067 solver.cpp:237] Iteration 3260, loss = 5.31413
I0601 12:06:31.499584 24067 solver.cpp:253]     Train net output #0: loss = 5.0884 (* 1 = 5.0884 loss)
I0601 12:06:31.499593 24067 sgd_solver.cpp:106] Iteration 3260, lr = 0.01
I0601 12:06:36.978077 24067 solver.cpp:237] Iteration 3280, loss = 5.37452
I0601 12:06:36.978122 24067 solver.cpp:253]     Train net output #0: loss = 5.42663 (* 1 = 5.42663 loss)
I0601 12:06:36.978132 24067 sgd_solver.cpp:106] Iteration 3280, lr = 0.01
I0601 12:06:42.454634 24067 solver.cpp:237] Iteration 3300, loss = 5.3176
I0601 12:06:42.454681 24067 solver.cpp:253]     Train net output #0: loss = 5.27068 (* 1 = 5.27068 loss)
I0601 12:06:42.454690 24067 sgd_solver.cpp:106] Iteration 3300, lr = 0.01
I0601 12:06:47.940728 24067 solver.cpp:237] Iteration 3320, loss = 5.27628
I0601 12:06:47.940778 24067 solver.cpp:253]     Train net output #0: loss = 5.30858 (* 1 = 5.30858 loss)
I0601 12:06:47.940786 24067 sgd_solver.cpp:106] Iteration 3320, lr = 0.01
I0601 12:06:53.425004 24067 solver.cpp:237] Iteration 3340, loss = 5.34041
I0601 12:06:53.425107 24067 solver.cpp:253]     Train net output #0: loss = 5.29625 (* 1 = 5.29625 loss)
I0601 12:06:53.425127 24067 sgd_solver.cpp:106] Iteration 3340, lr = 0.01
I0601 12:06:58.883692 24067 solver.cpp:237] Iteration 3360, loss = 5.33249
I0601 12:06:58.883740 24067 solver.cpp:253]     Train net output #0: loss = 5.28605 (* 1 = 5.28605 loss)
I0601 12:06:58.883759 24067 sgd_solver.cpp:106] Iteration 3360, lr = 0.01
I0601 12:07:04.364558 24067 solver.cpp:237] Iteration 3380, loss = 5.34328
I0601 12:07:04.364598 24067 solver.cpp:253]     Train net output #0: loss = 5.3036 (* 1 = 5.3036 loss)
I0601 12:07:04.364606 24067 sgd_solver.cpp:106] Iteration 3380, lr = 0.01
I0601 12:07:09.819780 24067 solver.cpp:237] Iteration 3400, loss = 5.34257
I0601 12:07:09.819830 24067 solver.cpp:253]     Train net output #0: loss = 5.38417 (* 1 = 5.38417 loss)
I0601 12:07:09.819839 24067 sgd_solver.cpp:106] Iteration 3400, lr = 0.01
I0601 12:07:15.261225 24067 solver.cpp:237] Iteration 3420, loss = 5.24251
I0601 12:07:15.261268 24067 solver.cpp:253]     Train net output #0: loss = 5.21008 (* 1 = 5.21008 loss)
I0601 12:07:15.261274 24067 sgd_solver.cpp:106] Iteration 3420, lr = 0.01
I0601 12:07:20.714200 24067 solver.cpp:237] Iteration 3440, loss = 5.2924
I0601 12:07:20.714244 24067 solver.cpp:253]     Train net output #0: loss = 5.34744 (* 1 = 5.34744 loss)
I0601 12:07:20.714252 24067 sgd_solver.cpp:106] Iteration 3440, lr = 0.01
I0601 12:07:26.148964 24067 solver.cpp:237] Iteration 3460, loss = 5.31628
I0601 12:07:26.149127 24067 solver.cpp:253]     Train net output #0: loss = 5.30837 (* 1 = 5.30837 loss)
I0601 12:07:26.149138 24067 sgd_solver.cpp:106] Iteration 3460, lr = 0.01
I0601 12:07:31.623397 24067 solver.cpp:237] Iteration 3480, loss = 5.27133
I0601 12:07:31.623427 24067 solver.cpp:253]     Train net output #0: loss = 5.17308 (* 1 = 5.17308 loss)
I0601 12:07:31.623433 24067 sgd_solver.cpp:106] Iteration 3480, lr = 0.01
I0601 12:07:37.093147 24067 solver.cpp:237] Iteration 3500, loss = 5.29564
I0601 12:07:37.093191 24067 solver.cpp:253]     Train net output #0: loss = 5.50373 (* 1 = 5.50373 loss)
I0601 12:07:37.093199 24067 sgd_solver.cpp:106] Iteration 3500, lr = 0.01
I0601 12:07:42.555404 24067 solver.cpp:237] Iteration 3520, loss = 5.30983
I0601 12:07:42.555454 24067 solver.cpp:253]     Train net output #0: loss = 5.2081 (* 1 = 5.2081 loss)
I0601 12:07:42.555459 24067 sgd_solver.cpp:106] Iteration 3520, lr = 0.01
I0601 12:07:48.009873 24067 solver.cpp:237] Iteration 3540, loss = 5.36619
I0601 12:07:48.009902 24067 solver.cpp:253]     Train net output #0: loss = 5.42217 (* 1 = 5.42217 loss)
I0601 12:07:48.009908 24067 sgd_solver.cpp:106] Iteration 3540, lr = 0.01
I0601 12:07:53.443938 24067 solver.cpp:237] Iteration 3560, loss = 5.29267
I0601 12:07:53.443979 24067 solver.cpp:253]     Train net output #0: loss = 5.01844 (* 1 = 5.01844 loss)
I0601 12:07:53.443984 24067 sgd_solver.cpp:106] Iteration 3560, lr = 0.01
I0601 12:07:58.878072 24067 solver.cpp:237] Iteration 3580, loss = 5.27386
I0601 12:07:58.878222 24067 solver.cpp:253]     Train net output #0: loss = 5.1345 (* 1 = 5.1345 loss)
I0601 12:07:58.878239 24067 sgd_solver.cpp:106] Iteration 3580, lr = 0.01
I0601 12:08:04.358506 24067 solver.cpp:237] Iteration 3600, loss = 5.26563
I0601 12:08:04.358556 24067 solver.cpp:253]     Train net output #0: loss = 5.26256 (* 1 = 5.26256 loss)
I0601 12:08:04.358563 24067 sgd_solver.cpp:106] Iteration 3600, lr = 0.01
I0601 12:08:09.844806 24067 solver.cpp:237] Iteration 3620, loss = 5.27867
I0601 12:08:09.844830 24067 solver.cpp:253]     Train net output #0: loss = 5.11793 (* 1 = 5.11793 loss)
I0601 12:08:09.844836 24067 sgd_solver.cpp:106] Iteration 3620, lr = 0.01
I0601 12:08:15.334305 24067 solver.cpp:237] Iteration 3640, loss = 5.23927
I0601 12:08:15.334350 24067 solver.cpp:253]     Train net output #0: loss = 5.4163 (* 1 = 5.4163 loss)
I0601 12:08:15.334358 24067 sgd_solver.cpp:106] Iteration 3640, lr = 0.01
I0601 12:08:20.818635 24067 solver.cpp:237] Iteration 3660, loss = 5.22854
I0601 12:08:20.818680 24067 solver.cpp:253]     Train net output #0: loss = 5.25865 (* 1 = 5.25865 loss)
I0601 12:08:20.818686 24067 sgd_solver.cpp:106] Iteration 3660, lr = 0.01
I0601 12:08:26.302983 24067 solver.cpp:237] Iteration 3680, loss = 5.24427
I0601 12:08:26.303023 24067 solver.cpp:253]     Train net output #0: loss = 5.06072 (* 1 = 5.06072 loss)
I0601 12:08:26.303030 24067 sgd_solver.cpp:106] Iteration 3680, lr = 0.01
I0601 12:08:31.783121 24067 solver.cpp:237] Iteration 3700, loss = 5.28232
I0601 12:08:31.783321 24067 solver.cpp:253]     Train net output #0: loss = 5.36838 (* 1 = 5.36838 loss)
I0601 12:08:31.783344 24067 sgd_solver.cpp:106] Iteration 3700, lr = 0.01
I0601 12:08:37.271975 24067 solver.cpp:237] Iteration 3720, loss = 5.24456
I0601 12:08:37.272024 24067 solver.cpp:253]     Train net output #0: loss = 5.20173 (* 1 = 5.20173 loss)
I0601 12:08:37.272032 24067 sgd_solver.cpp:106] Iteration 3720, lr = 0.01
I0601 12:08:42.758175 24067 solver.cpp:237] Iteration 3740, loss = 5.27627
I0601 12:08:42.758222 24067 solver.cpp:253]     Train net output #0: loss = 5.41531 (* 1 = 5.41531 loss)
I0601 12:08:42.758229 24067 sgd_solver.cpp:106] Iteration 3740, lr = 0.01
I0601 12:08:48.245627 24067 solver.cpp:237] Iteration 3760, loss = 5.25971
I0601 12:08:48.245671 24067 solver.cpp:253]     Train net output #0: loss = 5.35764 (* 1 = 5.35764 loss)
I0601 12:08:48.245679 24067 sgd_solver.cpp:106] Iteration 3760, lr = 0.01
I0601 12:08:53.731423 24067 solver.cpp:237] Iteration 3780, loss = 5.28291
I0601 12:08:53.731469 24067 solver.cpp:253]     Train net output #0: loss = 5.36429 (* 1 = 5.36429 loss)
I0601 12:08:53.731478 24067 sgd_solver.cpp:106] Iteration 3780, lr = 0.01
I0601 12:08:59.214288 24067 solver.cpp:237] Iteration 3800, loss = 5.21336
I0601 12:08:59.214335 24067 solver.cpp:253]     Train net output #0: loss = 5.36518 (* 1 = 5.36518 loss)
I0601 12:08:59.214354 24067 sgd_solver.cpp:106] Iteration 3800, lr = 0.01
I0601 12:09:04.696578 24067 solver.cpp:237] Iteration 3820, loss = 5.21226
I0601 12:09:04.696791 24067 solver.cpp:253]     Train net output #0: loss = 5.37063 (* 1 = 5.37063 loss)
I0601 12:09:04.696821 24067 sgd_solver.cpp:106] Iteration 3820, lr = 0.01
I0601 12:09:10.181143 24067 solver.cpp:237] Iteration 3840, loss = 5.24923
I0601 12:09:10.181183 24067 solver.cpp:253]     Train net output #0: loss = 5.1498 (* 1 = 5.1498 loss)
I0601 12:09:10.181192 24067 sgd_solver.cpp:106] Iteration 3840, lr = 0.01
I0601 12:09:15.666738 24067 solver.cpp:237] Iteration 3860, loss = 5.20515
I0601 12:09:15.666801 24067 solver.cpp:253]     Train net output #0: loss = 5.16336 (* 1 = 5.16336 loss)
I0601 12:09:15.666807 24067 sgd_solver.cpp:106] Iteration 3860, lr = 0.01
I0601 12:09:21.149586 24067 solver.cpp:237] Iteration 3880, loss = 5.22509
I0601 12:09:21.149636 24067 solver.cpp:253]     Train net output #0: loss = 5.2433 (* 1 = 5.2433 loss)
I0601 12:09:21.149643 24067 sgd_solver.cpp:106] Iteration 3880, lr = 0.01
I0601 12:09:26.630215 24067 solver.cpp:237] Iteration 3900, loss = 5.2388
I0601 12:09:26.630264 24067 solver.cpp:253]     Train net output #0: loss = 5.2294 (* 1 = 5.2294 loss)
I0601 12:09:26.630270 24067 sgd_solver.cpp:106] Iteration 3900, lr = 0.01
I0601 12:09:32.111860 24067 solver.cpp:237] Iteration 3920, loss = 5.19655
I0601 12:09:32.111912 24067 solver.cpp:253]     Train net output #0: loss = 5.29959 (* 1 = 5.29959 loss)
I0601 12:09:32.111918 24067 sgd_solver.cpp:106] Iteration 3920, lr = 0.01
I0601 12:09:37.597817 24067 solver.cpp:237] Iteration 3940, loss = 5.2059
I0601 12:09:37.598031 24067 solver.cpp:253]     Train net output #0: loss = 5.11281 (* 1 = 5.11281 loss)
I0601 12:09:37.598064 24067 sgd_solver.cpp:106] Iteration 3940, lr = 0.01
I0601 12:09:43.077114 24067 solver.cpp:237] Iteration 3960, loss = 5.17851
I0601 12:09:43.077162 24067 solver.cpp:253]     Train net output #0: loss = 5.21911 (* 1 = 5.21911 loss)
I0601 12:09:43.077168 24067 sgd_solver.cpp:106] Iteration 3960, lr = 0.01
I0601 12:09:48.562149 24067 solver.cpp:237] Iteration 3980, loss = 5.19159
I0601 12:09:48.562233 24067 solver.cpp:253]     Train net output #0: loss = 5.06005 (* 1 = 5.06005 loss)
I0601 12:09:48.562252 24067 sgd_solver.cpp:106] Iteration 3980, lr = 0.01
I0601 12:09:54.285012 24067 solver.cpp:341] Iteration 4000, Testing net (#0)
I0601 12:10:27.483326 24067 blocking_queue.cpp:50] Data layer prefetch queue empty
I0601 12:10:31.410749 24067 solver.cpp:409]     Test net output #0: accuracy = 0.0854002
I0601 12:10:31.410794 24067 solver.cpp:409]     Test net output #1: loss = 5.26162 (* 1 = 5.26162 loss)
I0601 12:10:31.490198 24067 solver.cpp:237] Iteration 4000, loss = 5.2199
I0601 12:10:31.490236 24067 solver.cpp:253]     Train net output #0: loss = 5.30728 (* 1 = 5.30728 loss)
I0601 12:10:31.490245 24067 sgd_solver.cpp:106] Iteration 4000, lr = 0.01
I0601 12:10:36.936434 24067 solver.cpp:237] Iteration 4020, loss = 5.22233
I0601 12:10:36.936483 24067 solver.cpp:253]     Train net output #0: loss = 5.19593 (* 1 = 5.19593 loss)
I0601 12:10:36.936494 24067 sgd_solver.cpp:106] Iteration 4020, lr = 0.01
I0601 12:10:42.384621 24067 solver.cpp:237] Iteration 4040, loss = 5.17785
I0601 12:10:42.384675 24067 solver.cpp:253]     Train net output #0: loss = 5.10615 (* 1 = 5.10615 loss)
I0601 12:10:42.384683 24067 sgd_solver.cpp:106] Iteration 4040, lr = 0.01
I0601 12:10:47.843044 24067 solver.cpp:237] Iteration 4060, loss = 5.19805
I0601 12:10:47.843114 24067 solver.cpp:253]     Train net output #0: loss = 5.15597 (* 1 = 5.15597 loss)
I0601 12:10:47.843127 24067 sgd_solver.cpp:106] Iteration 4060, lr = 0.01
I0601 12:10:53.299391 24067 solver.cpp:237] Iteration 4080, loss = 5.13924
I0601 12:10:53.299435 24067 solver.cpp:253]     Train net output #0: loss = 5.00204 (* 1 = 5.00204 loss)
I0601 12:10:53.299458 24067 sgd_solver.cpp:106] Iteration 4080, lr = 0.01
I0601 12:10:58.754353 24067 solver.cpp:237] Iteration 4100, loss = 5.20412
I0601 12:10:58.754549 24067 solver.cpp:253]     Train net output #0: loss = 5.23335 (* 1 = 5.23335 loss)
I0601 12:10:58.754562 24067 sgd_solver.cpp:106] Iteration 4100, lr = 0.01
I0601 12:11:04.214406 24067 solver.cpp:237] Iteration 4120, loss = 5.23545
I0601 12:11:04.214463 24067 solver.cpp:253]     Train net output #0: loss = 5.11436 (* 1 = 5.11436 loss)
I0601 12:11:04.214475 24067 sgd_solver.cpp:106] Iteration 4120, lr = 0.01
I0601 12:11:09.679327 24067 solver.cpp:237] Iteration 4140, loss = 5.1917
I0601 12:11:09.679394 24067 solver.cpp:253]     Train net output #0: loss = 5.10378 (* 1 = 5.10378 loss)
I0601 12:11:09.679405 24067 sgd_solver.cpp:106] Iteration 4140, lr = 0.01
I0601 12:11:15.149657 24067 solver.cpp:237] Iteration 4160, loss = 5.20336
I0601 12:11:15.149729 24067 solver.cpp:253]     Train net output #0: loss = 4.97289 (* 1 = 4.97289 loss)
I0601 12:11:15.149740 24067 sgd_solver.cpp:106] Iteration 4160, lr = 0.01
I0601 12:11:20.616247 24067 solver.cpp:237] Iteration 4180, loss = 5.18242
I0601 12:11:20.616305 24067 solver.cpp:253]     Train net output #0: loss = 5.05886 (* 1 = 5.05886 loss)
I0601 12:11:20.616317 24067 sgd_solver.cpp:106] Iteration 4180, lr = 0.01
I0601 12:11:26.090155 24067 solver.cpp:237] Iteration 4200, loss = 5.22742
I0601 12:11:26.090203 24067 solver.cpp:253]     Train net output #0: loss = 5.0967 (* 1 = 5.0967 loss)
I0601 12:11:26.090214 24067 sgd_solver.cpp:106] Iteration 4200, lr = 0.01
I0601 12:11:31.560492 24067 solver.cpp:237] Iteration 4220, loss = 5.12968
I0601 12:11:31.560760 24067 solver.cpp:253]     Train net output #0: loss = 4.95788 (* 1 = 4.95788 loss)
I0601 12:11:31.560782 24067 sgd_solver.cpp:106] Iteration 4220, lr = 0.01
I0601 12:11:37.031198 24067 solver.cpp:237] Iteration 4240, loss = 5.24741
I0601 12:11:37.031249 24067 solver.cpp:253]     Train net output #0: loss = 4.99622 (* 1 = 4.99622 loss)
I0601 12:11:37.031255 24067 sgd_solver.cpp:106] Iteration 4240, lr = 0.01
I0601 12:11:42.505043 24067 solver.cpp:237] Iteration 4260, loss = 5.16903
I0601 12:11:42.505094 24067 solver.cpp:253]     Train net output #0: loss = 5.14253 (* 1 = 5.14253 loss)
I0601 12:11:42.505100 24067 sgd_solver.cpp:106] Iteration 4260, lr = 0.01
I0601 12:11:47.981225 24067 solver.cpp:237] Iteration 4280, loss = 5.14672
I0601 12:11:47.981272 24067 solver.cpp:253]     Train net output #0: loss = 4.96815 (* 1 = 4.96815 loss)
I0601 12:11:47.981279 24067 sgd_solver.cpp:106] Iteration 4280, lr = 0.01
I0601 12:11:53.463536 24067 solver.cpp:237] Iteration 4300, loss = 5.11302
I0601 12:11:53.463582 24067 solver.cpp:253]     Train net output #0: loss = 5.00288 (* 1 = 5.00288 loss)
I0601 12:11:53.463588 24067 sgd_solver.cpp:106] Iteration 4300, lr = 0.01
I0601 12:11:58.947701 24067 solver.cpp:237] Iteration 4320, loss = 5.21644
I0601 12:11:58.947753 24067 solver.cpp:253]     Train net output #0: loss = 5.25397 (* 1 = 5.25397 loss)
I0601 12:11:58.947762 24067 sgd_solver.cpp:106] Iteration 4320, lr = 0.01
I0601 12:12:04.426610 24067 solver.cpp:237] Iteration 4340, loss = 5.15795
I0601 12:12:04.426846 24067 solver.cpp:253]     Train net output #0: loss = 5.19698 (* 1 = 5.19698 loss)
I0601 12:12:04.426867 24067 sgd_solver.cpp:106] Iteration 4340, lr = 0.01
I0601 12:12:09.904495 24067 solver.cpp:237] Iteration 4360, loss = 5.16655
I0601 12:12:09.904551 24067 solver.cpp:253]     Train net output #0: loss = 5.00031 (* 1 = 5.00031 loss)
I0601 12:12:09.904559 24067 sgd_solver.cpp:106] Iteration 4360, lr = 0.01
I0601 12:12:15.385519 24067 solver.cpp:237] Iteration 4380, loss = 5.14623
I0601 12:12:15.385567 24067 solver.cpp:253]     Train net output #0: loss = 5.18065 (* 1 = 5.18065 loss)
I0601 12:12:15.385573 24067 sgd_solver.cpp:106] Iteration 4380, lr = 0.01
I0601 12:12:20.869329 24067 solver.cpp:237] Iteration 4400, loss = 5.14022
I0601 12:12:20.869379 24067 solver.cpp:253]     Train net output #0: loss = 5.20517 (* 1 = 5.20517 loss)
I0601 12:12:20.869385 24067 sgd_solver.cpp:106] Iteration 4400, lr = 0.01
I0601 12:12:26.354712 24067 solver.cpp:237] Iteration 4420, loss = 5.13123
I0601 12:12:26.354760 24067 solver.cpp:253]     Train net output #0: loss = 5.31803 (* 1 = 5.31803 loss)
I0601 12:12:26.354766 24067 sgd_solver.cpp:106] Iteration 4420, lr = 0.01
I0601 12:12:31.838538 24067 solver.cpp:237] Iteration 4440, loss = 5.16329
I0601 12:12:31.838587 24067 solver.cpp:253]     Train net output #0: loss = 5.28463 (* 1 = 5.28463 loss)
I0601 12:12:31.838594 24067 sgd_solver.cpp:106] Iteration 4440, lr = 0.01
I0601 12:12:37.322552 24067 solver.cpp:237] Iteration 4460, loss = 5.22556
I0601 12:12:37.322757 24067 solver.cpp:253]     Train net output #0: loss = 5.26244 (* 1 = 5.26244 loss)
I0601 12:12:37.322777 24067 sgd_solver.cpp:106] Iteration 4460, lr = 0.01
I0601 12:12:42.810888 24067 solver.cpp:237] Iteration 4480, loss = 5.19806
I0601 12:12:42.810936 24067 solver.cpp:253]     Train net output #0: loss = 5.02635 (* 1 = 5.02635 loss)
I0601 12:12:42.810945 24067 sgd_solver.cpp:106] Iteration 4480, lr = 0.01
I0601 12:12:48.298245 24067 solver.cpp:237] Iteration 4500, loss = 5.16434
I0601 12:12:48.298300 24067 solver.cpp:253]     Train net output #0: loss = 5.00247 (* 1 = 5.00247 loss)
I0601 12:12:48.298310 24067 sgd_solver.cpp:106] Iteration 4500, lr = 0.01
I0601 12:12:53.787012 24067 solver.cpp:237] Iteration 4520, loss = 5.14565
I0601 12:12:53.787061 24067 solver.cpp:253]     Train net output #0: loss = 5.13797 (* 1 = 5.13797 loss)
I0601 12:12:53.787081 24067 sgd_solver.cpp:106] Iteration 4520, lr = 0.01
I0601 12:12:59.275120 24067 solver.cpp:237] Iteration 4540, loss = 5.18919
I0601 12:12:59.275182 24067 solver.cpp:253]     Train net output #0: loss = 5.19697 (* 1 = 5.19697 loss)
I0601 12:12:59.275193 24067 sgd_solver.cpp:106] Iteration 4540, lr = 0.01
I0601 12:13:04.766532 24067 solver.cpp:237] Iteration 4560, loss = 5.12473
I0601 12:13:04.766583 24067 solver.cpp:253]     Train net output #0: loss = 5.25283 (* 1 = 5.25283 loss)
I0601 12:13:04.766592 24067 sgd_solver.cpp:106] Iteration 4560, lr = 0.01
I0601 12:13:10.249579 24067 solver.cpp:237] Iteration 4580, loss = 5.15629
I0601 12:13:10.249764 24067 solver.cpp:253]     Train net output #0: loss = 5.25752 (* 1 = 5.25752 loss)
I0601 12:13:10.249785 24067 sgd_solver.cpp:106] Iteration 4580, lr = 0.01
I0601 12:13:15.741449 24067 solver.cpp:237] Iteration 4600, loss = 5.14198
I0601 12:13:15.741498 24067 solver.cpp:253]     Train net output #0: loss = 5.29212 (* 1 = 5.29212 loss)
I0601 12:13:15.741506 24067 sgd_solver.cpp:106] Iteration 4600, lr = 0.01
I0601 12:13:21.235813 24067 solver.cpp:237] Iteration 4620, loss = 5.12025
I0601 12:13:21.235873 24067 solver.cpp:253]     Train net output #0: loss = 5.21037 (* 1 = 5.21037 loss)
I0601 12:13:21.235882 24067 sgd_solver.cpp:106] Iteration 4620, lr = 0.01
I0601 12:13:26.726826 24067 solver.cpp:237] Iteration 4640, loss = 5.05386
I0601 12:13:26.726878 24067 solver.cpp:253]     Train net output #0: loss = 5.30151 (* 1 = 5.30151 loss)
I0601 12:13:26.726887 24067 sgd_solver.cpp:106] Iteration 4640, lr = 0.01
I0601 12:13:32.213798 24067 solver.cpp:237] Iteration 4660, loss = 5.08694
I0601 12:13:32.213840 24067 solver.cpp:253]     Train net output #0: loss = 5.21531 (* 1 = 5.21531 loss)
I0601 12:13:32.213850 24067 sgd_solver.cpp:106] Iteration 4660, lr = 0.01
I0601 12:13:37.702968 24067 solver.cpp:237] Iteration 4680, loss = 5.05931
I0601 12:13:37.703017 24067 solver.cpp:253]     Train net output #0: loss = 5.16672 (* 1 = 5.16672 loss)
I0601 12:13:37.703024 24067 sgd_solver.cpp:106] Iteration 4680, lr = 0.01
I0601 12:13:43.190198 24067 solver.cpp:237] Iteration 4700, loss = 5.12684
I0601 12:13:43.190440 24067 solver.cpp:253]     Train net output #0: loss = 5.16957 (* 1 = 5.16957 loss)
I0601 12:13:43.190464 24067 sgd_solver.cpp:106] Iteration 4700, lr = 0.01
I0601 12:13:48.677691 24067 solver.cpp:237] Iteration 4720, loss = 5.08965
I0601 12:13:48.677742 24067 solver.cpp:253]     Train net output #0: loss = 5.10425 (* 1 = 5.10425 loss)
I0601 12:13:48.677750 24067 sgd_solver.cpp:106] Iteration 4720, lr = 0.01
I0601 12:13:54.161777 24067 solver.cpp:237] Iteration 4740, loss = 5.14235
I0601 12:13:54.161831 24067 solver.cpp:253]     Train net output #0: loss = 5.12091 (* 1 = 5.12091 loss)
I0601 12:13:54.161840 24067 sgd_solver.cpp:106] Iteration 4740, lr = 0.01
I0601 12:13:59.648424 24067 solver.cpp:237] Iteration 4760, loss = 5.1466
I0601 12:13:59.648469 24067 solver.cpp:253]     Train net output #0: loss = 5.2468 (* 1 = 5.2468 loss)
I0601 12:13:59.648478 24067 sgd_solver.cpp:106] Iteration 4760, lr = 0.01
I0601 12:14:05.135504 24067 solver.cpp:237] Iteration 4780, loss = 5.13058
I0601 12:14:05.135565 24067 solver.cpp:253]     Train net output #0: loss = 5.07817 (* 1 = 5.07817 loss)
I0601 12:14:05.135574 24067 sgd_solver.cpp:106] Iteration 4780, lr = 0.01
I0601 12:14:10.625320 24067 solver.cpp:237] Iteration 4800, loss = 5.14307
I0601 12:14:10.625372 24067 solver.cpp:253]     Train net output #0: loss = 5.24011 (* 1 = 5.24011 loss)
I0601 12:14:10.625392 24067 sgd_solver.cpp:106] Iteration 4800, lr = 0.01
I0601 12:14:16.117133 24067 solver.cpp:237] Iteration 4820, loss = 5.11271
I0601 12:14:16.117357 24067 solver.cpp:253]     Train net output #0: loss = 5.44502 (* 1 = 5.44502 loss)
I0601 12:14:16.117379 24067 sgd_solver.cpp:106] Iteration 4820, lr = 0.01
I0601 12:14:21.611451 24067 solver.cpp:237] Iteration 4840, loss = 5.10791
I0601 12:14:21.611501 24067 solver.cpp:253]     Train net output #0: loss = 5.1081 (* 1 = 5.1081 loss)
I0601 12:14:21.611510 24067 sgd_solver.cpp:106] Iteration 4840, lr = 0.01
I0601 12:14:27.099314 24067 solver.cpp:237] Iteration 4860, loss = 5.11428
I0601 12:14:27.099364 24067 solver.cpp:253]     Train net output #0: loss = 5.01835 (* 1 = 5.01835 loss)
I0601 12:14:27.099371 24067 sgd_solver.cpp:106] Iteration 4860, lr = 0.01
I0601 12:14:32.591738 24067 solver.cpp:237] Iteration 4880, loss = 5.11826
I0601 12:14:32.591786 24067 solver.cpp:253]     Train net output #0: loss = 5.01699 (* 1 = 5.01699 loss)
I0601 12:14:32.591794 24067 sgd_solver.cpp:106] Iteration 4880, lr = 0.01
I0601 12:14:38.083086 24067 solver.cpp:237] Iteration 4900, loss = 5.13793
I0601 12:14:38.083129 24067 solver.cpp:253]     Train net output #0: loss = 5.1111 (* 1 = 5.1111 loss)
I0601 12:14:38.083137 24067 sgd_solver.cpp:106] Iteration 4900, lr = 0.01
I0601 12:14:43.576028 24067 solver.cpp:237] Iteration 4920, loss = 5.09171
I0601 12:14:43.576076 24067 solver.cpp:253]     Train net output #0: loss = 5.07803 (* 1 = 5.07803 loss)
I0601 12:14:43.576082 24067 sgd_solver.cpp:106] Iteration 4920, lr = 0.01
I0601 12:14:49.063777 24067 solver.cpp:237] Iteration 4940, loss = 5.10525
I0601 12:14:49.063993 24067 solver.cpp:253]     Train net output #0: loss = 4.879 (* 1 = 4.879 loss)
I0601 12:14:49.064002 24067 sgd_solver.cpp:106] Iteration 4940, lr = 0.01
I0601 12:14:54.556239 24067 solver.cpp:237] Iteration 4960, loss = 5.09847
I0601 12:14:54.556272 24067 solver.cpp:253]     Train net output #0: loss = 5.19678 (* 1 = 5.19678 loss)
I0601 12:14:54.556278 24067 sgd_solver.cpp:106] Iteration 4960, lr = 0.01
I0601 12:15:00.049888 24067 solver.cpp:237] Iteration 4980, loss = 5.1245
I0601 12:15:00.049926 24067 solver.cpp:253]     Train net output #0: loss = 5.38009 (* 1 = 5.38009 loss)
I0601 12:15:00.049933 24067 sgd_solver.cpp:106] Iteration 4980, lr = 0.01
I0601 12:15:05.455895 24067 solver.cpp:341] Iteration 5000, Testing net (#0)
I0601 12:15:33.900343 24067 blocking_queue.cpp:50] Data layer prefetch queue empty
I0601 12:15:37.986493 24067 solver.cpp:409]     Test net output #0: accuracy = 0.1019
I0601 12:15:37.986541 24067 solver.cpp:409]     Test net output #1: loss = 4.97401 (* 1 = 4.97401 loss)
I0601 12:15:38.067235 24067 solver.cpp:237] Iteration 5000, loss = 5.08756
I0601 12:15:38.067284 24067 solver.cpp:253]     Train net output #0: loss = 5.12337 (* 1 = 5.12337 loss)
I0601 12:15:38.067293 24067 sgd_solver.cpp:106] Iteration 5000, lr = 0.01
I0601 12:15:43.505542 24067 solver.cpp:237] Iteration 5020, loss = 5.13485
I0601 12:15:43.505589 24067 solver.cpp:253]     Train net output #0: loss = 4.96031 (* 1 = 4.96031 loss)
I0601 12:15:43.505596 24067 sgd_solver.cpp:106] Iteration 5020, lr = 0.01
I0601 12:15:48.953913 24067 solver.cpp:237] Iteration 5040, loss = 5.06056
I0601 12:15:48.953963 24067 solver.cpp:253]     Train net output #0: loss = 5.09731 (* 1 = 5.09731 loss)
I0601 12:15:48.953970 24067 sgd_solver.cpp:106] Iteration 5040, lr = 0.01
I0601 12:15:54.403709 24067 solver.cpp:237] Iteration 5060, loss = 5.12973
I0601 12:15:54.403758 24067 solver.cpp:253]     Train net output #0: loss = 5.32499 (* 1 = 5.32499 loss)
I0601 12:15:54.403764 24067 sgd_solver.cpp:106] Iteration 5060, lr = 0.01
I0601 12:15:59.862313 24067 solver.cpp:237] Iteration 5080, loss = 5.14182
I0601 12:15:59.862360 24067 solver.cpp:253]     Train net output #0: loss = 5.00902 (* 1 = 5.00902 loss)
I0601 12:15:59.862366 24067 sgd_solver.cpp:106] Iteration 5080, lr = 0.01
I0601 12:16:05.324605 24067 solver.cpp:237] Iteration 5100, loss = 5.06531
I0601 12:16:05.324858 24067 solver.cpp:253]     Train net output #0: loss = 5.05335 (* 1 = 5.05335 loss)
I0601 12:16:05.324885 24067 sgd_solver.cpp:106] Iteration 5100, lr = 0.01
I0601 12:16:10.789885 24067 solver.cpp:237] Iteration 5120, loss = 5.10878
I0601 12:16:10.789942 24067 solver.cpp:253]     Train net output #0: loss = 4.97218 (* 1 = 4.97218 loss)
I0601 12:16:10.789949 24067 sgd_solver.cpp:106] Iteration 5120, lr = 0.01
I0601 12:16:16.254395 24067 solver.cpp:237] Iteration 5140, loss = 5.07854
I0601 12:16:16.254449 24067 solver.cpp:253]     Train net output #0: loss = 4.94543 (* 1 = 4.94543 loss)
I0601 12:16:16.254456 24067 sgd_solver.cpp:106] Iteration 5140, lr = 0.01
I0601 12:16:21.716866 24067 solver.cpp:237] Iteration 5160, loss = 5.06255
I0601 12:16:21.716919 24067 solver.cpp:253]     Train net output #0: loss = 5.06378 (* 1 = 5.06378 loss)
I0601 12:16:21.716927 24067 sgd_solver.cpp:106] Iteration 5160, lr = 0.01
I0601 12:16:27.183048 24067 solver.cpp:237] Iteration 5180, loss = 5.02738
I0601 12:16:27.183099 24067 solver.cpp:253]     Train net output #0: loss = 4.78722 (* 1 = 4.78722 loss)
I0601 12:16:27.183107 24067 sgd_solver.cpp:106] Iteration 5180, lr = 0.01
I0601 12:16:32.657800 24067 solver.cpp:237] Iteration 5200, loss = 5.0627
I0601 12:16:32.657856 24067 solver.cpp:253]     Train net output #0: loss = 5.16564 (* 1 = 5.16564 loss)
I0601 12:16:32.657866 24067 sgd_solver.cpp:106] Iteration 5200, lr = 0.01
I0601 12:16:38.128623 24067 solver.cpp:237] Iteration 5220, loss = 5.08062
I0601 12:16:38.128847 24067 solver.cpp:253]     Train net output #0: loss = 5.18016 (* 1 = 5.18016 loss)
I0601 12:16:38.128857 24067 sgd_solver.cpp:106] Iteration 5220, lr = 0.01
I0601 12:16:43.602788 24067 solver.cpp:237] Iteration 5240, loss = 5.0039
I0601 12:16:43.602846 24067 solver.cpp:253]     Train net output #0: loss = 4.99693 (* 1 = 4.99693 loss)
I0601 12:16:43.602852 24067 sgd_solver.cpp:106] Iteration 5240, lr = 0.01
I0601 12:16:49.081492 24067 solver.cpp:237] Iteration 5260, loss = 5.03751
I0601 12:16:49.081539 24067 solver.cpp:253]     Train net output #0: loss = 4.95676 (* 1 = 4.95676 loss)
I0601 12:16:49.081548 24067 sgd_solver.cpp:106] Iteration 5260, lr = 0.01
I0601 12:16:54.562019 24067 solver.cpp:237] Iteration 5280, loss = 4.99949
I0601 12:16:54.562070 24067 solver.cpp:253]     Train net output #0: loss = 5.14457 (* 1 = 5.14457 loss)
I0601 12:16:54.562077 24067 sgd_solver.cpp:106] Iteration 5280, lr = 0.01
I0601 12:17:00.048084 24067 solver.cpp:237] Iteration 5300, loss = 5.03968
I0601 12:17:00.048130 24067 solver.cpp:253]     Train net output #0: loss = 5.04883 (* 1 = 5.04883 loss)
I0601 12:17:00.048137 24067 sgd_solver.cpp:106] Iteration 5300, lr = 0.01
I0601 12:17:05.519251 24067 solver.cpp:237] Iteration 5320, loss = 5.06797
I0601 12:17:05.519301 24067 solver.cpp:253]     Train net output #0: loss = 4.97453 (* 1 = 4.97453 loss)
I0601 12:17:05.519309 24067 sgd_solver.cpp:106] Iteration 5320, lr = 0.01
I0601 12:17:11.000504 24067 solver.cpp:237] Iteration 5340, loss = 5.1009
I0601 12:17:11.000665 24067 solver.cpp:253]     Train net output #0: loss = 5.32361 (* 1 = 5.32361 loss)
I0601 12:17:11.000675 24067 sgd_solver.cpp:106] Iteration 5340, lr = 0.01
I0601 12:17:16.485013 24067 solver.cpp:237] Iteration 5360, loss = 5.062
I0601 12:17:16.485064 24067 solver.cpp:253]     Train net output #0: loss = 5.10608 (* 1 = 5.10608 loss)
I0601 12:17:16.485071 24067 sgd_solver.cpp:106] Iteration 5360, lr = 0.01
I0601 12:17:21.970181 24067 solver.cpp:237] Iteration 5380, loss = 5.04998
I0601 12:17:21.970237 24067 solver.cpp:253]     Train net output #0: loss = 5.02489 (* 1 = 5.02489 loss)
I0601 12:17:21.970244 24067 sgd_solver.cpp:106] Iteration 5380, lr = 0.01
I0601 12:17:27.460026 24067 solver.cpp:237] Iteration 5400, loss = 5.05717
I0601 12:17:27.460078 24067 solver.cpp:253]     Train net output #0: loss = 4.90922 (* 1 = 4.90922 loss)
I0601 12:17:27.460086 24067 sgd_solver.cpp:106] Iteration 5400, lr = 0.01
I0601 12:17:32.949138 24067 solver.cpp:237] Iteration 5420, loss = 5.04951
I0601 12:17:32.949192 24067 solver.cpp:253]     Train net output #0: loss = 4.99302 (* 1 = 4.99302 loss)
I0601 12:17:32.949198 24067 sgd_solver.cpp:106] Iteration 5420, lr = 0.01
I0601 12:17:38.435044 24067 solver.cpp:237] Iteration 5440, loss = 4.9729
I0601 12:17:38.435093 24067 solver.cpp:253]     Train net output #0: loss = 4.72336 (* 1 = 4.72336 loss)
I0601 12:17:38.435101 24067 sgd_solver.cpp:106] Iteration 5440, lr = 0.01
I0601 12:17:43.919087 24067 solver.cpp:237] Iteration 5460, loss = 5.0256
I0601 12:17:43.919311 24067 solver.cpp:253]     Train net output #0: loss = 4.92176 (* 1 = 4.92176 loss)
I0601 12:17:43.919337 24067 sgd_solver.cpp:106] Iteration 5460, lr = 0.01
I0601 12:17:49.404110 24067 solver.cpp:237] Iteration 5480, loss = 5.07472
I0601 12:17:49.404160 24067 solver.cpp:253]     Train net output #0: loss = 5.27347 (* 1 = 5.27347 loss)
I0601 12:17:49.404170 24067 sgd_solver.cpp:106] Iteration 5480, lr = 0.01
I0601 12:17:54.884940 24067 solver.cpp:237] Iteration 5500, loss = 5.08659
I0601 12:17:54.884984 24067 solver.cpp:253]     Train net output #0: loss = 5.1298 (* 1 = 5.1298 loss)
I0601 12:17:54.884992 24067 sgd_solver.cpp:106] Iteration 5500, lr = 0.01
I0601 12:18:00.370820 24067 solver.cpp:237] Iteration 5520, loss = 5.04138
I0601 12:18:00.370868 24067 solver.cpp:253]     Train net output #0: loss = 5.1092 (* 1 = 5.1092 loss)
I0601 12:18:00.370889 24067 sgd_solver.cpp:106] Iteration 5520, lr = 0.01
I0601 12:18:05.855964 24067 solver.cpp:237] Iteration 5540, loss = 5.08904
I0601 12:18:05.856011 24067 solver.cpp:253]     Train net output #0: loss = 5.2752 (* 1 = 5.2752 loss)
I0601 12:18:05.856020 24067 sgd_solver.cpp:106] Iteration 5540, lr = 0.01
I0601 12:18:11.339617 24067 solver.cpp:237] Iteration 5560, loss = 5.00046
I0601 12:18:11.339661 24067 solver.cpp:253]     Train net output #0: loss = 5.0735 (* 1 = 5.0735 loss)
I0601 12:18:11.339669 24067 sgd_solver.cpp:106] Iteration 5560, lr = 0.01
I0601 12:18:16.820113 24067 solver.cpp:237] Iteration 5580, loss = 5.03985
I0601 12:18:16.820273 24067 solver.cpp:253]     Train net output #0: loss = 5.0493 (* 1 = 5.0493 loss)
I0601 12:18:16.820281 24067 sgd_solver.cpp:106] Iteration 5580, lr = 0.01
I0601 12:18:22.296104 24067 solver.cpp:237] Iteration 5600, loss = 5.04553
I0601 12:18:22.296149 24067 solver.cpp:253]     Train net output #0: loss = 5.23689 (* 1 = 5.23689 loss)
I0601 12:18:22.296156 24067 sgd_solver.cpp:106] Iteration 5600, lr = 0.01
I0601 12:18:27.733582 24067 solver.cpp:237] Iteration 5620, loss = 5.02549
I0601 12:18:27.733629 24067 solver.cpp:253]     Train net output #0: loss = 4.96891 (* 1 = 4.96891 loss)
I0601 12:18:27.733635 24067 sgd_solver.cpp:106] Iteration 5620, lr = 0.01
I0601 12:18:33.177994 24067 solver.cpp:237] Iteration 5640, loss = 5.02884
I0601 12:18:33.178036 24067 solver.cpp:253]     Train net output #0: loss = 5.2081 (* 1 = 5.2081 loss)
I0601 12:18:33.178042 24067 sgd_solver.cpp:106] Iteration 5640, lr = 0.01
I0601 12:18:38.619309 24067 solver.cpp:237] Iteration 5660, loss = 4.99636
I0601 12:18:38.619354 24067 solver.cpp:253]     Train net output #0: loss = 5.1901 (* 1 = 5.1901 loss)
I0601 12:18:38.619360 24067 sgd_solver.cpp:106] Iteration 5660, lr = 0.01
I0601 12:18:44.064343 24067 solver.cpp:237] Iteration 5680, loss = 5.03258
I0601 12:18:44.064414 24067 solver.cpp:253]     Train net output #0: loss = 5.00058 (* 1 = 5.00058 loss)
I0601 12:18:44.064424 24067 sgd_solver.cpp:106] Iteration 5680, lr = 0.01
I0601 12:18:49.522886 24067 solver.cpp:237] Iteration 5700, loss = 5.03635
I0601 12:18:49.523121 24067 solver.cpp:253]     Train net output #0: loss = 4.99879 (* 1 = 4.99879 loss)
I0601 12:18:49.523142 24067 sgd_solver.cpp:106] Iteration 5700, lr = 0.01
I0601 12:18:55.016556 24067 solver.cpp:237] Iteration 5720, loss = 4.8911
I0601 12:18:55.016593 24067 solver.cpp:253]     Train net output #0: loss = 4.71225 (* 1 = 4.71225 loss)
I0601 12:18:55.016599 24067 sgd_solver.cpp:106] Iteration 5720, lr = 0.01
I0601 12:19:00.506335 24067 solver.cpp:237] Iteration 5740, loss = 4.97488
I0601 12:19:00.506369 24067 solver.cpp:253]     Train net output #0: loss = 4.81536 (* 1 = 4.81536 loss)
I0601 12:19:00.506377 24067 sgd_solver.cpp:106] Iteration 5740, lr = 0.01
I0601 12:19:05.989769 24067 solver.cpp:237] Iteration 5760, loss = 4.99696
I0601 12:19:05.989809 24067 solver.cpp:253]     Train net output #0: loss = 4.81874 (* 1 = 4.81874 loss)
I0601 12:19:05.989815 24067 sgd_solver.cpp:106] Iteration 5760, lr = 0.01
I0601 12:19:11.479684 24067 solver.cpp:237] Iteration 5780, loss = 4.98624
I0601 12:19:11.479722 24067 solver.cpp:253]     Train net output #0: loss = 5.08787 (* 1 = 5.08787 loss)
I0601 12:19:11.479729 24067 sgd_solver.cpp:106] Iteration 5780, lr = 0.01
I0601 12:19:16.970124 24067 solver.cpp:237] Iteration 5800, loss = 5.04018
I0601 12:19:16.970161 24067 solver.cpp:253]     Train net output #0: loss = 4.71127 (* 1 = 4.71127 loss)
I0601 12:19:16.970167 24067 sgd_solver.cpp:106] Iteration 5800, lr = 0.01
I0601 12:19:22.457381 24067 solver.cpp:237] Iteration 5820, loss = 5.04911
I0601 12:19:22.457618 24067 solver.cpp:253]     Train net output #0: loss = 5.0648 (* 1 = 5.0648 loss)
I0601 12:19:22.457643 24067 sgd_solver.cpp:106] Iteration 5820, lr = 0.01
I0601 12:19:27.949724 24067 solver.cpp:237] Iteration 5840, loss = 4.94849
I0601 12:19:27.949776 24067 solver.cpp:253]     Train net output #0: loss = 4.86672 (* 1 = 4.86672 loss)
I0601 12:19:27.949785 24067 sgd_solver.cpp:106] Iteration 5840, lr = 0.01
I0601 12:19:33.437273 24067 solver.cpp:237] Iteration 5860, loss = 5.00507
I0601 12:19:33.437321 24067 solver.cpp:253]     Train net output #0: loss = 5.22102 (* 1 = 5.22102 loss)
I0601 12:19:33.437330 24067 sgd_solver.cpp:106] Iteration 5860, lr = 0.01
I0601 12:19:38.922268 24067 solver.cpp:237] Iteration 5880, loss = 5.05437
I0601 12:19:38.922317 24067 solver.cpp:253]     Train net output #0: loss = 5.24101 (* 1 = 5.24101 loss)
I0601 12:19:38.922325 24067 sgd_solver.cpp:106] Iteration 5880, lr = 0.01
I0601 12:19:44.407248 24067 solver.cpp:237] Iteration 5900, loss = 5.059
I0601 12:19:44.407297 24067 solver.cpp:253]     Train net output #0: loss = 4.97682 (* 1 = 4.97682 loss)
I0601 12:19:44.407306 24067 sgd_solver.cpp:106] Iteration 5900, lr = 0.01
I0601 12:19:49.903753 24067 solver.cpp:237] Iteration 5920, loss = 4.9839
I0601 12:19:49.903797 24067 solver.cpp:253]     Train net output #0: loss = 4.92929 (* 1 = 4.92929 loss)
I0601 12:19:49.903806 24067 sgd_solver.cpp:106] Iteration 5920, lr = 0.01
I0601 12:19:55.386239 24067 solver.cpp:237] Iteration 5940, loss = 4.9525
I0601 12:19:55.386463 24067 solver.cpp:253]     Train net output #0: loss = 5.08955 (* 1 = 5.08955 loss)
I0601 12:19:55.386487 24067 sgd_solver.cpp:106] Iteration 5940, lr = 0.01
I0601 12:20:00.872100 24067 solver.cpp:237] Iteration 5960, loss = 5.0114
I0601 12:20:00.872148 24067 solver.cpp:253]     Train net output #0: loss = 4.93854 (* 1 = 4.93854 loss)
I0601 12:20:00.872155 24067 sgd_solver.cpp:106] Iteration 5960, lr = 0.01
I0601 12:20:06.361006 24067 solver.cpp:237] Iteration 5980, loss = 4.97286
I0601 12:20:06.361060 24067 solver.cpp:253]     Train net output #0: loss = 4.74859 (* 1 = 4.74859 loss)
I0601 12:20:06.361069 24067 sgd_solver.cpp:106] Iteration 5980, lr = 0.01
I0601 12:20:11.767235 24067 solver.cpp:341] Iteration 6000, Testing net (#0)
I0601 12:20:39.628870 24067 blocking_queue.cpp:50] Data layer prefetch queue empty
I0601 12:20:43.573519 24067 solver.cpp:409]     Test net output #0: accuracy = 0.10858
I0601 12:20:43.573575 24067 solver.cpp:409]     Test net output #1: loss = 4.91962 (* 1 = 4.91962 loss)
I0601 12:20:43.654626 24067 solver.cpp:237] Iteration 6000, loss = 4.98107
I0601 12:20:43.654670 24067 solver.cpp:253]     Train net output #0: loss = 4.81237 (* 1 = 4.81237 loss)
I0601 12:20:43.654683 24067 sgd_solver.cpp:106] Iteration 6000, lr = 0.01
I0601 12:20:49.100589 24067 solver.cpp:237] Iteration 6020, loss = 4.96375
I0601 12:20:49.100639 24067 solver.cpp:253]     Train net output #0: loss = 4.91507 (* 1 = 4.91507 loss)
I0601 12:20:49.100648 24067 sgd_solver.cpp:106] Iteration 6020, lr = 0.01
I0601 12:20:54.545127 24067 solver.cpp:237] Iteration 6040, loss = 4.9747
I0601 12:20:54.545182 24067 solver.cpp:253]     Train net output #0: loss = 5.00929 (* 1 = 5.00929 loss)
I0601 12:20:54.545191 24067 sgd_solver.cpp:106] Iteration 6040, lr = 0.01
I0601 12:20:59.998739 24067 solver.cpp:237] Iteration 6060, loss = 4.94197
I0601 12:20:59.998788 24067 solver.cpp:253]     Train net output #0: loss = 4.88287 (* 1 = 4.88287 loss)
I0601 12:20:59.998795 24067 sgd_solver.cpp:106] Iteration 6060, lr = 0.01
I0601 12:21:05.452369 24067 solver.cpp:237] Iteration 6080, loss = 4.9478
I0601 12:21:05.452421 24067 solver.cpp:253]     Train net output #0: loss = 5.02519 (* 1 = 5.02519 loss)
I0601 12:21:05.452442 24067 sgd_solver.cpp:106] Iteration 6080, lr = 0.01
I0601 12:21:10.908761 24067 solver.cpp:237] Iteration 6100, loss = 4.96319
I0601 12:21:10.908987 24067 solver.cpp:253]     Train net output #0: loss = 4.77492 (* 1 = 4.77492 loss)
I0601 12:21:10.909006 24067 sgd_solver.cpp:106] Iteration 6100, lr = 0.01
I0601 12:21:16.372148 24067 solver.cpp:237] Iteration 6120, loss = 4.96208
I0601 12:21:16.372197 24067 solver.cpp:253]     Train net output #0: loss = 5.1617 (* 1 = 5.1617 loss)
I0601 12:21:16.372205 24067 sgd_solver.cpp:106] Iteration 6120, lr = 0.01
I0601 12:21:21.834817 24067 solver.cpp:237] Iteration 6140, loss = 4.97184
I0601 12:21:21.834867 24067 solver.cpp:253]     Train net output #0: loss = 4.9934 (* 1 = 4.9934 loss)
I0601 12:21:21.834874 24067 sgd_solver.cpp:106] Iteration 6140, lr = 0.01
I0601 12:21:27.295871 24067 solver.cpp:237] Iteration 6160, loss = 4.96554
I0601 12:21:27.295922 24067 solver.cpp:253]     Train net output #0: loss = 5.13843 (* 1 = 5.13843 loss)
I0601 12:21:27.295928 24067 sgd_solver.cpp:106] Iteration 6160, lr = 0.01
I0601 12:21:32.769295 24067 solver.cpp:237] Iteration 6180, loss = 4.9675
I0601 12:21:32.769345 24067 solver.cpp:253]     Train net output #0: loss = 4.93196 (* 1 = 4.93196 loss)
I0601 12:21:32.769351 24067 sgd_solver.cpp:106] Iteration 6180, lr = 0.01
I0601 12:21:38.241910 24067 solver.cpp:237] Iteration 6200, loss = 4.91143
I0601 12:21:38.241961 24067 solver.cpp:253]     Train net output #0: loss = 4.80919 (* 1 = 4.80919 loss)
I0601 12:21:38.241969 24067 sgd_solver.cpp:106] Iteration 6200, lr = 0.01
I0601 12:21:43.709179 24067 solver.cpp:237] Iteration 6220, loss = 5.00438
I0601 12:21:43.709434 24067 solver.cpp:253]     Train net output #0: loss = 5.00849 (* 1 = 5.00849 loss)
I0601 12:21:43.709452 24067 sgd_solver.cpp:106] Iteration 6220, lr = 0.01
I0601 12:21:49.183584 24067 solver.cpp:237] Iteration 6240, loss = 4.97277
I0601 12:21:49.183632 24067 solver.cpp:253]     Train net output #0: loss = 4.88626 (* 1 = 4.88626 loss)
I0601 12:21:49.183640 24067 sgd_solver.cpp:106] Iteration 6240, lr = 0.01
I0601 12:21:54.653319 24067 solver.cpp:237] Iteration 6260, loss = 5.01437
I0601 12:21:54.653372 24067 solver.cpp:253]     Train net output #0: loss = 4.80132 (* 1 = 4.80132 loss)
I0601 12:21:54.653378 24067 sgd_solver.cpp:106] Iteration 6260, lr = 0.01
I0601 12:22:00.130935 24067 solver.cpp:237] Iteration 6280, loss = 4.96702
I0601 12:22:00.130992 24067 solver.cpp:253]     Train net output #0: loss = 4.78345 (* 1 = 4.78345 loss)
I0601 12:22:00.131009 24067 sgd_solver.cpp:106] Iteration 6280, lr = 0.01
I0601 12:22:05.607888 24067 solver.cpp:237] Iteration 6300, loss = 4.99964
I0601 12:22:05.607933 24067 solver.cpp:253]     Train net output #0: loss = 4.90652 (* 1 = 4.90652 loss)
I0601 12:22:05.607940 24067 sgd_solver.cpp:106] Iteration 6300, lr = 0.01
I0601 12:22:11.092495 24067 solver.cpp:237] Iteration 6320, loss = 4.98667
I0601 12:22:11.092546 24067 solver.cpp:253]     Train net output #0: loss = 4.88427 (* 1 = 4.88427 loss)
I0601 12:22:11.092553 24067 sgd_solver.cpp:106] Iteration 6320, lr = 0.01
I0601 12:22:16.573259 24067 solver.cpp:237] Iteration 6340, loss = 4.94352
I0601 12:22:16.573500 24067 solver.cpp:253]     Train net output #0: loss = 4.76702 (* 1 = 4.76702 loss)
I0601 12:22:16.573523 24067 sgd_solver.cpp:106] Iteration 6340, lr = 0.01
I0601 12:22:22.056154 24067 solver.cpp:237] Iteration 6360, loss = 4.94508
I0601 12:22:22.056205 24067 solver.cpp:253]     Train net output #0: loss = 4.7643 (* 1 = 4.7643 loss)
I0601 12:22:22.056213 24067 sgd_solver.cpp:106] Iteration 6360, lr = 0.01
I0601 12:22:27.540315 24067 solver.cpp:237] Iteration 6380, loss = 4.99128
I0601 12:22:27.540364 24067 solver.cpp:253]     Train net output #0: loss = 5.05275 (* 1 = 5.05275 loss)
I0601 12:22:27.540376 24067 sgd_solver.cpp:106] Iteration 6380, lr = 0.01
I0601 12:22:33.026518 24067 solver.cpp:237] Iteration 6400, loss = 4.90525
I0601 12:22:33.026568 24067 solver.cpp:253]     Train net output #0: loss = 5.09508 (* 1 = 5.09508 loss)
I0601 12:22:33.026578 24067 sgd_solver.cpp:106] Iteration 6400, lr = 0.01
I0601 12:22:38.511994 24067 solver.cpp:237] Iteration 6420, loss = 4.97733
I0601 12:22:38.512043 24067 solver.cpp:253]     Train net output #0: loss = 4.95443 (* 1 = 4.95443 loss)
I0601 12:22:38.512053 24067 sgd_solver.cpp:106] Iteration 6420, lr = 0.01
I0601 12:22:44.001837 24067 solver.cpp:237] Iteration 6440, loss = 4.95429
I0601 12:22:44.001889 24067 solver.cpp:253]     Train net output #0: loss = 4.99047 (* 1 = 4.99047 loss)
I0601 12:22:44.001899 24067 sgd_solver.cpp:106] Iteration 6440, lr = 0.01
I0601 12:22:49.486065 24067 solver.cpp:237] Iteration 6460, loss = 4.97674
I0601 12:22:49.486289 24067 solver.cpp:253]     Train net output #0: loss = 4.95914 (* 1 = 4.95914 loss)
I0601 12:22:49.486311 24067 sgd_solver.cpp:106] Iteration 6460, lr = 0.01
I0601 12:22:54.972671 24067 solver.cpp:237] Iteration 6480, loss = 4.92218
I0601 12:22:54.972740 24067 solver.cpp:253]     Train net output #0: loss = 5.01818 (* 1 = 5.01818 loss)
I0601 12:22:54.972748 24067 sgd_solver.cpp:106] Iteration 6480, lr = 0.01
I0601 12:23:00.461055 24067 solver.cpp:237] Iteration 6500, loss = 4.97055
I0601 12:23:00.461108 24067 solver.cpp:253]     Train net output #0: loss = 4.79968 (* 1 = 4.79968 loss)
I0601 12:23:00.461117 24067 sgd_solver.cpp:106] Iteration 6500, lr = 0.01
I0601 12:23:05.950906 24067 solver.cpp:237] Iteration 6520, loss = 4.91957
I0601 12:23:05.950960 24067 solver.cpp:253]     Train net output #0: loss = 4.87435 (* 1 = 4.87435 loss)
I0601 12:23:05.950968 24067 sgd_solver.cpp:106] Iteration 6520, lr = 0.01
I0601 12:23:11.445304 24067 solver.cpp:237] Iteration 6540, loss = 4.94038
I0601 12:23:11.445349 24067 solver.cpp:253]     Train net output #0: loss = 4.93491 (* 1 = 4.93491 loss)
I0601 12:23:11.445356 24067 sgd_solver.cpp:106] Iteration 6540, lr = 0.01
I0601 12:23:16.933094 24067 solver.cpp:237] Iteration 6560, loss = 4.92517
I0601 12:23:16.933145 24067 solver.cpp:253]     Train net output #0: loss = 4.80745 (* 1 = 4.80745 loss)
I0601 12:23:16.933152 24067 sgd_solver.cpp:106] Iteration 6560, lr = 0.01
I0601 12:23:22.419569 24067 solver.cpp:237] Iteration 6580, loss = 4.94038
I0601 12:23:22.419811 24067 solver.cpp:253]     Train net output #0: loss = 5.06615 (* 1 = 5.06615 loss)
I0601 12:23:22.419836 24067 sgd_solver.cpp:106] Iteration 6580, lr = 0.01
I0601 12:23:27.909561 24067 solver.cpp:237] Iteration 6600, loss = 4.96568
I0601 12:23:27.909611 24067 solver.cpp:253]     Train net output #0: loss = 5.07245 (* 1 = 5.07245 loss)
I0601 12:23:27.909621 24067 sgd_solver.cpp:106] Iteration 6600, lr = 0.01
I0601 12:23:33.401440 24067 solver.cpp:237] Iteration 6620, loss = 4.90942
I0601 12:23:33.401489 24067 solver.cpp:253]     Train net output #0: loss = 5.08186 (* 1 = 5.08186 loss)
I0601 12:23:33.401499 24067 sgd_solver.cpp:106] Iteration 6620, lr = 0.01
I0601 12:23:38.892467 24067 solver.cpp:237] Iteration 6640, loss = 4.88189
I0601 12:23:38.892503 24067 solver.cpp:253]     Train net output #0: loss = 5.16844 (* 1 = 5.16844 loss)
I0601 12:23:38.892511 24067 sgd_solver.cpp:106] Iteration 6640, lr = 0.01
I0601 12:23:44.381315 24067 solver.cpp:237] Iteration 6660, loss = 4.85158
I0601 12:23:44.381363 24067 solver.cpp:253]     Train net output #0: loss = 4.81304 (* 1 = 4.81304 loss)
I0601 12:23:44.381372 24067 sgd_solver.cpp:106] Iteration 6660, lr = 0.01
I0601 12:23:49.872426 24067 solver.cpp:237] Iteration 6680, loss = 4.95771
I0601 12:23:49.872478 24067 solver.cpp:253]     Train net output #0: loss = 5.09445 (* 1 = 5.09445 loss)
I0601 12:23:49.872491 24067 sgd_solver.cpp:106] Iteration 6680, lr = 0.01
I0601 12:23:55.365571 24067 solver.cpp:237] Iteration 6700, loss = 4.86656
I0601 12:23:55.365789 24067 solver.cpp:253]     Train net output #0: loss = 5.02076 (* 1 = 5.02076 loss)
I0601 12:23:55.365815 24067 sgd_solver.cpp:106] Iteration 6700, lr = 0.01
I0601 12:24:00.854945 24067 solver.cpp:237] Iteration 6720, loss = 4.87583
I0601 12:24:00.854997 24067 solver.cpp:253]     Train net output #0: loss = 5.15397 (* 1 = 5.15397 loss)
I0601 12:24:00.855005 24067 sgd_solver.cpp:106] Iteration 6720, lr = 0.01
I0601 12:24:06.345048 24067 solver.cpp:237] Iteration 6740, loss = 4.94497
I0601 12:24:06.345099 24067 solver.cpp:253]     Train net output #0: loss = 4.95054 (* 1 = 4.95054 loss)
I0601 12:24:06.345105 24067 sgd_solver.cpp:106] Iteration 6740, lr = 0.01
I0601 12:24:11.827745 24067 solver.cpp:237] Iteration 6760, loss = 4.89954
I0601 12:24:11.827788 24067 solver.cpp:253]     Train net output #0: loss = 4.84187 (* 1 = 4.84187 loss)
I0601 12:24:11.827796 24067 sgd_solver.cpp:106] Iteration 6760, lr = 0.01
I0601 12:24:17.315526 24067 solver.cpp:237] Iteration 6780, loss = 4.86131
I0601 12:24:17.315570 24067 solver.cpp:253]     Train net output #0: loss = 4.4349 (* 1 = 4.4349 loss)
I0601 12:24:17.315577 24067 sgd_solver.cpp:106] Iteration 6780, lr = 0.01
I0601 12:24:22.796150 24067 solver.cpp:237] Iteration 6800, loss = 4.89581
I0601 12:24:22.796198 24067 solver.cpp:253]     Train net output #0: loss = 4.98533 (* 1 = 4.98533 loss)
I0601 12:24:22.796205 24067 sgd_solver.cpp:106] Iteration 6800, lr = 0.01
I0601 12:24:28.237629 24067 solver.cpp:237] Iteration 6820, loss = 4.86153
I0601 12:24:28.237860 24067 solver.cpp:253]     Train net output #0: loss = 4.83603 (* 1 = 4.83603 loss)
I0601 12:24:28.237890 24067 sgd_solver.cpp:106] Iteration 6820, lr = 0.01
I0601 12:24:33.672855 24067 solver.cpp:237] Iteration 6840, loss = 4.90816
I0601 12:24:33.672902 24067 solver.cpp:253]     Train net output #0: loss = 4.94397 (* 1 = 4.94397 loss)
I0601 12:24:33.672909 24067 sgd_solver.cpp:106] Iteration 6840, lr = 0.01
I0601 12:24:39.153333 24067 solver.cpp:237] Iteration 6860, loss = 4.87405
I0601 12:24:39.153388 24067 solver.cpp:253]     Train net output #0: loss = 4.90578 (* 1 = 4.90578 loss)
I0601 12:24:39.153409 24067 sgd_solver.cpp:106] Iteration 6860, lr = 0.01
I0601 12:24:44.645359 24067 solver.cpp:237] Iteration 6880, loss = 4.88164
I0601 12:24:44.645413 24067 solver.cpp:253]     Train net output #0: loss = 4.95997 (* 1 = 4.95997 loss)
I0601 12:24:44.645422 24067 sgd_solver.cpp:106] Iteration 6880, lr = 0.01
I0601 12:24:50.134371 24067 solver.cpp:237] Iteration 6900, loss = 4.90798
I0601 12:24:50.134414 24067 solver.cpp:253]     Train net output #0: loss = 4.92327 (* 1 = 4.92327 loss)
I0601 12:24:50.134423 24067 sgd_solver.cpp:106] Iteration 6900, lr = 0.01
I0601 12:24:55.626725 24067 solver.cpp:237] Iteration 6920, loss = 4.82558
I0601 12:24:55.626765 24067 solver.cpp:253]     Train net output #0: loss = 4.95772 (* 1 = 4.95772 loss)
I0601 12:24:55.626773 24067 sgd_solver.cpp:106] Iteration 6920, lr = 0.01
I0601 12:25:01.112624 24067 solver.cpp:237] Iteration 6940, loss = 4.90221
I0601 12:25:01.112766 24067 solver.cpp:253]     Train net output #0: loss = 5.0064 (* 1 = 5.0064 loss)
I0601 12:25:01.112773 24067 sgd_solver.cpp:106] Iteration 6940, lr = 0.01
I0601 12:25:06.590631 24067 solver.cpp:237] Iteration 6960, loss = 4.96061
I0601 12:25:06.590682 24067 solver.cpp:253]     Train net output #0: loss = 5.08544 (* 1 = 5.08544 loss)
I0601 12:25:06.590688 24067 sgd_solver.cpp:106] Iteration 6960, lr = 0.01
I0601 12:25:12.072227 24067 solver.cpp:237] Iteration 6980, loss = 4.90765
I0601 12:25:12.072275 24067 solver.cpp:253]     Train net output #0: loss = 4.68081 (* 1 = 4.68081 loss)
I0601 12:25:12.072281 24067 sgd_solver.cpp:106] Iteration 6980, lr = 0.01
I0601 12:25:17.465067 24067 solver.cpp:341] Iteration 7000, Testing net (#0)
I0601 12:25:45.709435 24067 blocking_queue.cpp:50] Data layer prefetch queue empty
I0601 12:25:49.600682 24067 solver.cpp:409]     Test net output #0: accuracy = 0.12702
I0601 12:25:49.600733 24067 solver.cpp:409]     Test net output #1: loss = 4.67737 (* 1 = 4.67737 loss)
I0601 12:25:49.680531 24067 solver.cpp:237] Iteration 7000, loss = 4.86075
I0601 12:25:49.680569 24067 solver.cpp:253]     Train net output #0: loss = 4.71506 (* 1 = 4.71506 loss)
I0601 12:25:49.680580 24067 sgd_solver.cpp:106] Iteration 7000, lr = 0.01
I0601 12:25:55.130292 24067 solver.cpp:237] Iteration 7020, loss = 4.82428
I0601 12:25:55.130343 24067 solver.cpp:253]     Train net output #0: loss = 5.00046 (* 1 = 5.00046 loss)
I0601 12:25:55.130352 24067 sgd_solver.cpp:106] Iteration 7020, lr = 0.01
I0601 12:26:00.578727 24067 solver.cpp:237] Iteration 7040, loss = 4.86948
I0601 12:26:00.578773 24067 solver.cpp:253]     Train net output #0: loss = 4.97722 (* 1 = 4.97722 loss)
I0601 12:26:00.578781 24067 sgd_solver.cpp:106] Iteration 7040, lr = 0.01
I0601 12:26:06.005833 24067 solver.cpp:237] Iteration 7060, loss = 4.90609
I0601 12:26:06.005887 24067 solver.cpp:253]     Train net output #0: loss = 4.95646 (* 1 = 4.95646 loss)
I0601 12:26:06.005894 24067 sgd_solver.cpp:106] Iteration 7060, lr = 0.01
I0601 12:26:11.420838 24067 solver.cpp:237] Iteration 7080, loss = 4.91799
I0601 12:26:11.420888 24067 solver.cpp:253]     Train net output #0: loss = 4.86751 (* 1 = 4.86751 loss)
I0601 12:26:11.420894 24067 sgd_solver.cpp:106] Iteration 7080, lr = 0.01
I0601 12:26:16.860898 24067 solver.cpp:237] Iteration 7100, loss = 4.88653
I0601 12:26:16.861069 24067 solver.cpp:253]     Train net output #0: loss = 4.93936 (* 1 = 4.93936 loss)
I0601 12:26:16.861083 24067 sgd_solver.cpp:106] Iteration 7100, lr = 0.01
I0601 12:26:22.309957 24067 solver.cpp:237] Iteration 7120, loss = 4.8288
I0601 12:26:22.310010 24067 solver.cpp:253]     Train net output #0: loss = 4.56112 (* 1 = 4.56112 loss)
I0601 12:26:22.310017 24067 sgd_solver.cpp:106] Iteration 7120, lr = 0.01
I0601 12:26:27.766950 24067 solver.cpp:237] Iteration 7140, loss = 4.8606
I0601 12:26:27.766991 24067 solver.cpp:253]     Train net output #0: loss = 4.86753 (* 1 = 4.86753 loss)
I0601 12:26:27.767001 24067 sgd_solver.cpp:106] Iteration 7140, lr = 0.01
I0601 12:26:33.230059 24067 solver.cpp:237] Iteration 7160, loss = 4.87633
I0601 12:26:33.230099 24067 solver.cpp:253]     Train net output #0: loss = 4.96691 (* 1 = 4.96691 loss)
I0601 12:26:33.230106 24067 sgd_solver.cpp:106] Iteration 7160, lr = 0.01
I0601 12:26:38.696513 24067 solver.cpp:237] Iteration 7180, loss = 4.78612
I0601 12:26:38.696564 24067 solver.cpp:253]     Train net output #0: loss = 4.7578 (* 1 = 4.7578 loss)
I0601 12:26:38.696573 24067 sgd_solver.cpp:106] Iteration 7180, lr = 0.01
I0601 12:26:44.166646 24067 solver.cpp:237] Iteration 7200, loss = 4.81079
I0601 12:26:44.166697 24067 solver.cpp:253]     Train net output #0: loss = 5.03498 (* 1 = 5.03498 loss)
I0601 12:26:44.166718 24067 sgd_solver.cpp:106] Iteration 7200, lr = 0.01
I0601 12:26:49.642595 24067 solver.cpp:237] Iteration 7220, loss = 4.82389
I0601 12:26:49.642838 24067 solver.cpp:253]     Train net output #0: loss = 4.71858 (* 1 = 4.71858 loss)
I0601 12:26:49.642860 24067 sgd_solver.cpp:106] Iteration 7220, lr = 0.01
I0601 12:26:55.112385 24067 solver.cpp:237] Iteration 7240, loss = 4.87974
I0601 12:26:55.112422 24067 solver.cpp:253]     Train net output #0: loss = 5.11765 (* 1 = 5.11765 loss)
I0601 12:26:55.112429 24067 sgd_solver.cpp:106] Iteration 7240, lr = 0.01
I0601 12:27:00.595763 24067 solver.cpp:237] Iteration 7260, loss = 4.91418
I0601 12:27:00.595813 24067 solver.cpp:253]     Train net output #0: loss = 4.98437 (* 1 = 4.98437 loss)
I0601 12:27:00.595819 24067 sgd_solver.cpp:106] Iteration 7260, lr = 0.01
I0601 12:27:06.056717 24067 solver.cpp:237] Iteration 7280, loss = 4.87383
I0601 12:27:06.056764 24067 solver.cpp:253]     Train net output #0: loss = 4.85665 (* 1 = 4.85665 loss)
I0601 12:27:06.056771 24067 sgd_solver.cpp:106] Iteration 7280, lr = 0.01
I0601 12:27:11.497205 24067 solver.cpp:237] Iteration 7300, loss = 4.87956
I0601 12:27:11.497253 24067 solver.cpp:253]     Train net output #0: loss = 4.8729 (* 1 = 4.8729 loss)
I0601 12:27:11.497262 24067 sgd_solver.cpp:106] Iteration 7300, lr = 0.01
I0601 12:27:16.973327 24067 solver.cpp:237] Iteration 7320, loss = 4.8464
I0601 12:27:16.973378 24067 solver.cpp:253]     Train net output #0: loss = 4.83349 (* 1 = 4.83349 loss)
I0601 12:27:16.973386 24067 sgd_solver.cpp:106] Iteration 7320, lr = 0.01
I0601 12:27:22.424337 24067 solver.cpp:237] Iteration 7340, loss = 4.85126
I0601 12:27:22.424546 24067 solver.cpp:253]     Train net output #0: loss = 4.81833 (* 1 = 4.81833 loss)
I0601 12:27:22.424568 24067 sgd_solver.cpp:106] Iteration 7340, lr = 0.01
I0601 12:27:27.890760 24067 solver.cpp:237] Iteration 7360, loss = 4.8362
I0601 12:27:27.890805 24067 solver.cpp:253]     Train net output #0: loss = 4.89227 (* 1 = 4.89227 loss)
I0601 12:27:27.890811 24067 sgd_solver.cpp:106] Iteration 7360, lr = 0.01
I0601 12:27:33.344353 24067 solver.cpp:237] Iteration 7380, loss = 4.93846
I0601 12:27:33.344413 24067 solver.cpp:253]     Train net output #0: loss = 4.87354 (* 1 = 4.87354 loss)
I0601 12:27:33.344419 24067 sgd_solver.cpp:106] Iteration 7380, lr = 0.01
I0601 12:27:38.797000 24067 solver.cpp:237] Iteration 7400, loss = 4.90634
I0601 12:27:38.797046 24067 solver.cpp:253]     Train net output #0: loss = 4.89036 (* 1 = 4.89036 loss)
I0601 12:27:38.797054 24067 sgd_solver.cpp:106] Iteration 7400, lr = 0.01
I0601 12:27:44.276341 24067 solver.cpp:237] Iteration 7420, loss = 4.86445
I0601 12:27:44.276407 24067 solver.cpp:253]     Train net output #0: loss = 5.0382 (* 1 = 5.0382 loss)
I0601 12:27:44.276417 24067 sgd_solver.cpp:106] Iteration 7420, lr = 0.01
I0601 12:27:49.761008 24067 solver.cpp:237] Iteration 7440, loss = 4.8491
I0601 12:27:49.761055 24067 solver.cpp:253]     Train net output #0: loss = 4.8758 (* 1 = 4.8758 loss)
I0601 12:27:49.761065 24067 sgd_solver.cpp:106] Iteration 7440, lr = 0.01
I0601 12:27:55.245437 24067 solver.cpp:237] Iteration 7460, loss = 4.8851
I0601 12:27:55.245676 24067 solver.cpp:253]     Train net output #0: loss = 5.06913 (* 1 = 5.06913 loss)
I0601 12:27:55.245697 24067 sgd_solver.cpp:106] Iteration 7460, lr = 0.01
I0601 12:28:00.733937 24067 solver.cpp:237] Iteration 7480, loss = 4.86039
I0601 12:28:00.733984 24067 solver.cpp:253]     Train net output #0: loss = 4.69306 (* 1 = 4.69306 loss)
I0601 12:28:00.733991 24067 sgd_solver.cpp:106] Iteration 7480, lr = 0.01
I0601 12:28:06.219862 24067 solver.cpp:237] Iteration 7500, loss = 4.83594
I0601 12:28:06.219912 24067 solver.cpp:253]     Train net output #0: loss = 4.80151 (* 1 = 4.80151 loss)
I0601 12:28:06.219918 24067 sgd_solver.cpp:106] Iteration 7500, lr = 0.01
I0601 12:28:11.706363 24067 solver.cpp:237] Iteration 7520, loss = 4.83815
I0601 12:28:11.706413 24067 solver.cpp:253]     Train net output #0: loss = 5.07145 (* 1 = 5.07145 loss)
I0601 12:28:11.706420 24067 sgd_solver.cpp:106] Iteration 7520, lr = 0.01
I0601 12:28:17.186317 24067 solver.cpp:237] Iteration 7540, loss = 4.80146
I0601 12:28:17.186367 24067 solver.cpp:253]     Train net output #0: loss = 4.71251 (* 1 = 4.71251 loss)
I0601 12:28:17.186375 24067 sgd_solver.cpp:106] Iteration 7540, lr = 0.01
I0601 12:28:22.670632 24067 solver.cpp:237] Iteration 7560, loss = 4.86946
I0601 12:28:22.670682 24067 solver.cpp:253]     Train net output #0: loss = 4.85388 (* 1 = 4.85388 loss)
I0601 12:28:22.670691 24067 sgd_solver.cpp:106] Iteration 7560, lr = 0.01
I0601 12:28:28.157609 24067 solver.cpp:237] Iteration 7580, loss = 4.80491
I0601 12:28:28.157838 24067 solver.cpp:253]     Train net output #0: loss = 4.79942 (* 1 = 4.79942 loss)
I0601 12:28:28.157862 24067 sgd_solver.cpp:106] Iteration 7580, lr = 0.01
I0601 12:28:33.649236 24067 solver.cpp:237] Iteration 7600, loss = 4.82561
I0601 12:28:33.649283 24067 solver.cpp:253]     Train net output #0: loss = 4.91212 (* 1 = 4.91212 loss)
I0601 12:28:33.649291 24067 sgd_solver.cpp:106] Iteration 7600, lr = 0.01
I0601 12:28:39.135459 24067 solver.cpp:237] Iteration 7620, loss = 4.8318
I0601 12:28:39.135507 24067 solver.cpp:253]     Train net output #0: loss = 4.80043 (* 1 = 4.80043 loss)
I0601 12:28:39.135516 24067 sgd_solver.cpp:106] Iteration 7620, lr = 0.01
I0601 12:28:44.628512 24067 solver.cpp:237] Iteration 7640, loss = 4.90909
I0601 12:28:44.628551 24067 solver.cpp:253]     Train net output #0: loss = 4.82816 (* 1 = 4.82816 loss)
I0601 12:28:44.628558 24067 sgd_solver.cpp:106] Iteration 7640, lr = 0.01
I0601 12:28:50.115273 24067 solver.cpp:237] Iteration 7660, loss = 4.87132
I0601 12:28:50.115330 24067 solver.cpp:253]     Train net output #0: loss = 4.70619 (* 1 = 4.70619 loss)
I0601 12:28:50.115339 24067 sgd_solver.cpp:106] Iteration 7660, lr = 0.01
I0601 12:28:55.607556 24067 solver.cpp:237] Iteration 7680, loss = 4.90302
I0601 12:28:55.607607 24067 solver.cpp:253]     Train net output #0: loss = 4.90234 (* 1 = 4.90234 loss)
I0601 12:28:55.607616 24067 sgd_solver.cpp:106] Iteration 7680, lr = 0.01
I0601 12:29:01.096145 24067 solver.cpp:237] Iteration 7700, loss = 4.8274
I0601 12:29:01.096463 24067 solver.cpp:253]     Train net output #0: loss = 4.66187 (* 1 = 4.66187 loss)
I0601 12:29:01.096490 24067 sgd_solver.cpp:106] Iteration 7700, lr = 0.01
I0601 12:29:06.596791 24067 solver.cpp:237] Iteration 7720, loss = 4.82034
I0601 12:29:06.596827 24067 solver.cpp:253]     Train net output #0: loss = 5.00286 (* 1 = 5.00286 loss)
I0601 12:29:06.596834 24067 sgd_solver.cpp:106] Iteration 7720, lr = 0.01
I0601 12:29:12.088008 24067 solver.cpp:237] Iteration 7740, loss = 4.84628
I0601 12:29:12.088047 24067 solver.cpp:253]     Train net output #0: loss = 5.02143 (* 1 = 5.02143 loss)
I0601 12:29:12.088052 24067 sgd_solver.cpp:106] Iteration 7740, lr = 0.01
I0601 12:29:17.585167 24067 solver.cpp:237] Iteration 7760, loss = 4.80778
I0601 12:29:17.585216 24067 solver.cpp:253]     Train net output #0: loss = 4.95401 (* 1 = 4.95401 loss)
I0601 12:29:17.585223 24067 sgd_solver.cpp:106] Iteration 7760, lr = 0.01
I0601 12:29:23.075953 24067 solver.cpp:237] Iteration 7780, loss = 4.80117
I0601 12:29:23.076004 24067 solver.cpp:253]     Train net output #0: loss = 4.81037 (* 1 = 4.81037 loss)
I0601 12:29:23.076011 24067 sgd_solver.cpp:106] Iteration 7780, lr = 0.01
I0601 12:29:28.567986 24067 solver.cpp:237] Iteration 7800, loss = 4.85217
I0601 12:29:28.568027 24067 solver.cpp:253]     Train net output #0: loss = 4.86535 (* 1 = 4.86535 loss)
I0601 12:29:28.568033 24067 sgd_solver.cpp:106] Iteration 7800, lr = 0.01
I0601 12:29:34.056763 24067 solver.cpp:237] Iteration 7820, loss = 4.82531
I0601 12:29:34.057018 24067 solver.cpp:253]     Train net output #0: loss = 4.71539 (* 1 = 4.71539 loss)
I0601 12:29:34.057046 24067 sgd_solver.cpp:106] Iteration 7820, lr = 0.01
I0601 12:29:39.536082 24067 solver.cpp:237] Iteration 7840, loss = 4.83295
I0601 12:29:39.536142 24067 solver.cpp:253]     Train net output #0: loss = 4.84206 (* 1 = 4.84206 loss)
I0601 12:29:39.536151 24067 sgd_solver.cpp:106] Iteration 7840, lr = 0.01
I0601 12:29:44.993268 24067 solver.cpp:237] Iteration 7860, loss = 4.88853
I0601 12:29:44.993311 24067 solver.cpp:253]     Train net output #0: loss = 4.84067 (* 1 = 4.84067 loss)
I0601 12:29:44.993319 24067 sgd_solver.cpp:106] Iteration 7860, lr = 0.01
I0601 12:29:50.438311 24067 solver.cpp:237] Iteration 7880, loss = 4.80694
I0601 12:29:50.438359 24067 solver.cpp:253]     Train net output #0: loss = 4.86324 (* 1 = 4.86324 loss)
I0601 12:29:50.438365 24067 sgd_solver.cpp:106] Iteration 7880, lr = 0.01
I0601 12:29:55.885536 24067 solver.cpp:237] Iteration 7900, loss = 4.78518
I0601 12:29:55.885588 24067 solver.cpp:253]     Train net output #0: loss = 4.66154 (* 1 = 4.66154 loss)
I0601 12:29:55.885598 24067 sgd_solver.cpp:106] Iteration 7900, lr = 0.01
I0601 12:30:01.359798 24067 solver.cpp:237] Iteration 7920, loss = 4.85903
I0601 12:30:01.359834 24067 solver.cpp:253]     Train net output #0: loss = 5.0195 (* 1 = 5.0195 loss)
I0601 12:30:01.359853 24067 sgd_solver.cpp:106] Iteration 7920, lr = 0.01
I0601 12:30:06.846990 24067 solver.cpp:237] Iteration 7940, loss = 4.80068
I0601 12:30:06.847208 24067 solver.cpp:253]     Train net output #0: loss = 4.92689 (* 1 = 4.92689 loss)
I0601 12:30:06.847231 24067 sgd_solver.cpp:106] Iteration 7940, lr = 0.01
I0601 12:30:12.338819 24067 solver.cpp:237] Iteration 7960, loss = 4.86777
I0601 12:30:12.338863 24067 solver.cpp:253]     Train net output #0: loss = 4.91611 (* 1 = 4.91611 loss)
I0601 12:30:12.338871 24067 sgd_solver.cpp:106] Iteration 7960, lr = 0.01
I0601 12:30:17.819614 24067 solver.cpp:237] Iteration 7980, loss = 4.79199
I0601 12:30:17.819670 24067 solver.cpp:253]     Train net output #0: loss = 4.63302 (* 1 = 4.63302 loss)
I0601 12:30:17.819675 24067 sgd_solver.cpp:106] Iteration 7980, lr = 0.01
I0601 12:30:23.222580 24067 solver.cpp:341] Iteration 8000, Testing net (#0)
I0601 12:30:51.820150 24067 blocking_queue.cpp:50] Data layer prefetch queue empty
I0601 12:30:55.666286 24067 solver.cpp:409]     Test net output #0: accuracy = 0.13414
I0601 12:30:55.666329 24067 solver.cpp:409]     Test net output #1: loss = 4.63903 (* 1 = 4.63903 loss)
I0601 12:30:55.747601 24067 solver.cpp:237] Iteration 8000, loss = 4.80918
I0601 12:30:55.747654 24067 solver.cpp:253]     Train net output #0: loss = 4.87322 (* 1 = 4.87322 loss)
I0601 12:30:55.747665 24067 sgd_solver.cpp:106] Iteration 8000, lr = 0.01
I0601 12:31:01.151651 24067 solver.cpp:237] Iteration 8020, loss = 4.76034
I0601 12:31:01.151700 24067 solver.cpp:253]     Train net output #0: loss = 4.62501 (* 1 = 4.62501 loss)
I0601 12:31:01.151718 24067 sgd_solver.cpp:106] Iteration 8020, lr = 0.01
I0601 12:31:06.559043 24067 solver.cpp:237] Iteration 8040, loss = 4.80977
I0601 12:31:06.559092 24067 solver.cpp:253]     Train net output #0: loss = 4.77489 (* 1 = 4.77489 loss)
I0601 12:31:06.559098 24067 sgd_solver.cpp:106] Iteration 8040, lr = 0.01
I0601 12:31:11.997265 24067 solver.cpp:237] Iteration 8060, loss = 4.8734
I0601 12:31:11.997308 24067 solver.cpp:253]     Train net output #0: loss = 5.00881 (* 1 = 5.00881 loss)
I0601 12:31:11.997316 24067 sgd_solver.cpp:106] Iteration 8060, lr = 0.01
I0601 12:31:17.455391 24067 solver.cpp:237] Iteration 8080, loss = 4.76533
I0601 12:31:17.455430 24067 solver.cpp:253]     Train net output #0: loss = 4.81884 (* 1 = 4.81884 loss)
I0601 12:31:17.455437 24067 sgd_solver.cpp:106] Iteration 8080, lr = 0.01
I0601 12:31:22.923074 24067 solver.cpp:237] Iteration 8100, loss = 4.86449
I0601 12:31:22.923271 24067 solver.cpp:253]     Train net output #0: loss = 4.74063 (* 1 = 4.74063 loss)
I0601 12:31:22.923297 24067 sgd_solver.cpp:106] Iteration 8100, lr = 0.01
I0601 12:31:28.383973 24067 solver.cpp:237] Iteration 8120, loss = 4.87415
I0601 12:31:28.384033 24067 solver.cpp:253]     Train net output #0: loss = 4.77256 (* 1 = 4.77256 loss)
I0601 12:31:28.384053 24067 sgd_solver.cpp:106] Iteration 8120, lr = 0.01
I0601 12:31:33.843405 24067 solver.cpp:237] Iteration 8140, loss = 4.80998
I0601 12:31:33.843456 24067 solver.cpp:253]     Train net output #0: loss = 4.75133 (* 1 = 4.75133 loss)
I0601 12:31:33.843464 24067 sgd_solver.cpp:106] Iteration 8140, lr = 0.01
I0601 12:31:39.309926 24067 solver.cpp:237] Iteration 8160, loss = 4.76957
I0601 12:31:39.309976 24067 solver.cpp:253]     Train net output #0: loss = 4.78986 (* 1 = 4.78986 loss)
I0601 12:31:39.309984 24067 sgd_solver.cpp:106] Iteration 8160, lr = 0.01
I0601 12:31:44.775456 24067 solver.cpp:237] Iteration 8180, loss = 4.77202
I0601 12:31:44.775506 24067 solver.cpp:253]     Train net output #0: loss = 4.96678 (* 1 = 4.96678 loss)
I0601 12:31:44.775513 24067 sgd_solver.cpp:106] Iteration 8180, lr = 0.01
I0601 12:31:50.241940 24067 solver.cpp:237] Iteration 8200, loss = 4.74473
I0601 12:31:50.241982 24067 solver.cpp:253]     Train net output #0: loss = 4.86156 (* 1 = 4.86156 loss)
I0601 12:31:50.241991 24067 sgd_solver.cpp:106] Iteration 8200, lr = 0.01
I0601 12:31:55.712431 24067 solver.cpp:237] Iteration 8220, loss = 4.81564
I0601 12:31:55.712609 24067 solver.cpp:253]     Train net output #0: loss = 4.77982 (* 1 = 4.77982 loss)
I0601 12:31:55.712617 24067 sgd_solver.cpp:106] Iteration 8220, lr = 0.01
I0601 12:32:01.181823 24067 solver.cpp:237] Iteration 8240, loss = 4.8367
I0601 12:32:01.181870 24067 solver.cpp:253]     Train net output #0: loss = 4.81087 (* 1 = 4.81087 loss)
I0601 12:32:01.181879 24067 sgd_solver.cpp:106] Iteration 8240, lr = 0.01
I0601 12:32:06.652055 24067 solver.cpp:237] Iteration 8260, loss = 4.78799
I0601 12:32:06.652104 24067 solver.cpp:253]     Train net output #0: loss = 4.9004 (* 1 = 4.9004 loss)
I0601 12:32:06.652112 24067 sgd_solver.cpp:106] Iteration 8260, lr = 0.01
I0601 12:32:12.130295 24067 solver.cpp:237] Iteration 8280, loss = 4.85259
I0601 12:32:12.130339 24067 solver.cpp:253]     Train net output #0: loss = 4.78331 (* 1 = 4.78331 loss)
I0601 12:32:12.130347 24067 sgd_solver.cpp:106] Iteration 8280, lr = 0.01
I0601 12:32:17.607826 24067 solver.cpp:237] Iteration 8300, loss = 4.78172
I0601 12:32:17.607873 24067 solver.cpp:253]     Train net output #0: loss = 4.93852 (* 1 = 4.93852 loss)
I0601 12:32:17.607882 24067 sgd_solver.cpp:106] Iteration 8300, lr = 0.01
I0601 12:32:23.086567 24067 solver.cpp:237] Iteration 8320, loss = 4.74013
I0601 12:32:23.086632 24067 solver.cpp:253]     Train net output #0: loss = 4.75686 (* 1 = 4.75686 loss)
I0601 12:32:23.086640 24067 sgd_solver.cpp:106] Iteration 8320, lr = 0.01
I0601 12:32:28.567140 24067 solver.cpp:237] Iteration 8340, loss = 4.84231
I0601 12:32:28.567351 24067 solver.cpp:253]     Train net output #0: loss = 4.75112 (* 1 = 4.75112 loss)
I0601 12:32:28.567378 24067 sgd_solver.cpp:106] Iteration 8340, lr = 0.01
I0601 12:32:34.051671 24067 solver.cpp:237] Iteration 8360, loss = 4.78585
I0601 12:32:34.051718 24067 solver.cpp:253]     Train net output #0: loss = 4.93 (* 1 = 4.93 loss)
I0601 12:32:34.051725 24067 sgd_solver.cpp:106] Iteration 8360, lr = 0.01
I0601 12:32:39.533535 24067 solver.cpp:237] Iteration 8380, loss = 4.78146
I0601 12:32:39.533582 24067 solver.cpp:253]     Train net output #0: loss = 4.78519 (* 1 = 4.78519 loss)
I0601 12:32:39.533589 24067 sgd_solver.cpp:106] Iteration 8380, lr = 0.01
I0601 12:32:45.015964 24067 solver.cpp:237] Iteration 8400, loss = 4.78624
I0601 12:32:45.016010 24067 solver.cpp:253]     Train net output #0: loss = 4.68623 (* 1 = 4.68623 loss)
I0601 12:32:45.016026 24067 sgd_solver.cpp:106] Iteration 8400, lr = 0.01
I0601 12:32:50.505837 24067 solver.cpp:237] Iteration 8420, loss = 4.75551
I0601 12:32:50.505894 24067 solver.cpp:253]     Train net output #0: loss = 4.7259 (* 1 = 4.7259 loss)
I0601 12:32:50.505902 24067 sgd_solver.cpp:106] Iteration 8420, lr = 0.01
I0601 12:32:55.988976 24067 solver.cpp:237] Iteration 8440, loss = 4.77303
I0601 12:32:55.989024 24067 solver.cpp:253]     Train net output #0: loss = 4.59309 (* 1 = 4.59309 loss)
I0601 12:32:55.989032 24067 sgd_solver.cpp:106] Iteration 8440, lr = 0.01
I0601 12:33:01.477160 24067 solver.cpp:237] Iteration 8460, loss = 4.76917
I0601 12:33:01.477367 24067 solver.cpp:253]     Train net output #0: loss = 4.78912 (* 1 = 4.78912 loss)
I0601 12:33:01.477392 24067 sgd_solver.cpp:106] Iteration 8460, lr = 0.01
I0601 12:33:06.961333 24067 solver.cpp:237] Iteration 8480, loss = 4.79917
I0601 12:33:06.961395 24067 solver.cpp:253]     Train net output #0: loss = 4.94957 (* 1 = 4.94957 loss)
I0601 12:33:06.961403 24067 sgd_solver.cpp:106] Iteration 8480, lr = 0.01
I0601 12:33:12.441664 24067 solver.cpp:237] Iteration 8500, loss = 4.75347
I0601 12:33:12.441718 24067 solver.cpp:253]     Train net output #0: loss = 4.83949 (* 1 = 4.83949 loss)
I0601 12:33:12.441726 24067 sgd_solver.cpp:106] Iteration 8500, lr = 0.01
I0601 12:33:17.928247 24067 solver.cpp:237] Iteration 8520, loss = 4.82422
I0601 12:33:17.928293 24067 solver.cpp:253]     Train net output #0: loss = 4.64194 (* 1 = 4.64194 loss)
I0601 12:33:17.928300 24067 sgd_solver.cpp:106] Iteration 8520, lr = 0.01
I0601 12:33:23.394265 24067 solver.cpp:237] Iteration 8540, loss = 4.82128
I0601 12:33:23.394309 24067 solver.cpp:253]     Train net output #0: loss = 5.16002 (* 1 = 5.16002 loss)
I0601 12:33:23.394315 24067 sgd_solver.cpp:106] Iteration 8540, lr = 0.01
I0601 12:33:28.828428 24067 solver.cpp:237] Iteration 8560, loss = 4.81034
I0601 12:33:28.828464 24067 solver.cpp:253]     Train net output #0: loss = 4.93461 (* 1 = 4.93461 loss)
I0601 12:33:28.828485 24067 sgd_solver.cpp:106] Iteration 8560, lr = 0.01
I0601 12:33:34.306318 24067 solver.cpp:237] Iteration 8580, loss = 4.77114
I0601 12:33:34.306490 24067 solver.cpp:253]     Train net output #0: loss = 4.51395 (* 1 = 4.51395 loss)
I0601 12:33:34.306511 24067 sgd_solver.cpp:106] Iteration 8580, lr = 0.01
I0601 12:33:39.789255 24067 solver.cpp:237] Iteration 8600, loss = 4.73741
I0601 12:33:39.789314 24067 solver.cpp:253]     Train net output #0: loss = 4.75477 (* 1 = 4.75477 loss)
I0601 12:33:39.789335 24067 sgd_solver.cpp:106] Iteration 8600, lr = 0.01
I0601 12:33:45.277597 24067 solver.cpp:237] Iteration 8620, loss = 4.76465
I0601 12:33:45.277633 24067 solver.cpp:253]     Train net output #0: loss = 4.88378 (* 1 = 4.88378 loss)
I0601 12:33:45.277642 24067 sgd_solver.cpp:106] Iteration 8620, lr = 0.01
I0601 12:33:50.768509 24067 solver.cpp:237] Iteration 8640, loss = 4.7828
I0601 12:33:50.768544 24067 solver.cpp:253]     Train net output #0: loss = 4.80963 (* 1 = 4.80963 loss)
I0601 12:33:50.768553 24067 sgd_solver.cpp:106] Iteration 8640, lr = 0.01
I0601 12:33:56.247556 24067 solver.cpp:237] Iteration 8660, loss = 4.73342
I0601 12:33:56.247599 24067 solver.cpp:253]     Train net output #0: loss = 4.60307 (* 1 = 4.60307 loss)
I0601 12:33:56.247607 24067 sgd_solver.cpp:106] Iteration 8660, lr = 0.01
I0601 12:34:01.726537 24067 solver.cpp:237] Iteration 8680, loss = 4.84116
I0601 12:34:01.726593 24067 solver.cpp:253]     Train net output #0: loss = 5.05866 (* 1 = 5.05866 loss)
I0601 12:34:01.726600 24067 sgd_solver.cpp:106] Iteration 8680, lr = 0.01
I0601 12:34:07.201720 24067 solver.cpp:237] Iteration 8700, loss = 4.78409
I0601 12:34:07.201974 24067 solver.cpp:253]     Train net output #0: loss = 4.63641 (* 1 = 4.63641 loss)
I0601 12:34:07.201998 24067 sgd_solver.cpp:106] Iteration 8700, lr = 0.01
I0601 12:34:12.665122 24067 solver.cpp:237] Iteration 8720, loss = 4.73315
I0601 12:34:12.665174 24067 solver.cpp:253]     Train net output #0: loss = 4.72444 (* 1 = 4.72444 loss)
I0601 12:34:12.665190 24067 sgd_solver.cpp:106] Iteration 8720, lr = 0.01
I0601 12:34:18.148669 24067 solver.cpp:237] Iteration 8740, loss = 4.75189
I0601 12:34:18.148747 24067 solver.cpp:253]     Train net output #0: loss = 4.73624 (* 1 = 4.73624 loss)
I0601 12:34:18.148758 24067 sgd_solver.cpp:106] Iteration 8740, lr = 0.01
I0601 12:34:23.635737 24067 solver.cpp:237] Iteration 8760, loss = 4.75501
I0601 12:34:23.635799 24067 solver.cpp:253]     Train net output #0: loss = 4.68248 (* 1 = 4.68248 loss)
I0601 12:34:23.635808 24067 sgd_solver.cpp:106] Iteration 8760, lr = 0.01
I0601 12:34:29.107780 24067 solver.cpp:237] Iteration 8780, loss = 4.78048
I0601 12:34:29.107834 24067 solver.cpp:253]     Train net output #0: loss = 4.5974 (* 1 = 4.5974 loss)
I0601 12:34:29.107843 24067 sgd_solver.cpp:106] Iteration 8780, lr = 0.01
I0601 12:34:34.584102 24067 solver.cpp:237] Iteration 8800, loss = 4.73011
I0601 12:34:34.584144 24067 solver.cpp:253]     Train net output #0: loss = 4.60058 (* 1 = 4.60058 loss)
I0601 12:34:34.584152 24067 sgd_solver.cpp:106] Iteration 8800, lr = 0.01
I0601 12:34:40.072737 24067 solver.cpp:237] Iteration 8820, loss = 4.71553
I0601 12:34:40.073724 24067 solver.cpp:253]     Train net output #0: loss = 4.53762 (* 1 = 4.53762 loss)
I0601 12:34:40.073731 24067 sgd_solver.cpp:106] Iteration 8820, lr = 0.01
I0601 12:34:45.551138 24067 solver.cpp:237] Iteration 8840, loss = 4.75256
I0601 12:34:45.551173 24067 solver.cpp:253]     Train net output #0: loss = 4.73833 (* 1 = 4.73833 loss)
I0601 12:34:45.551180 24067 sgd_solver.cpp:106] Iteration 8840, lr = 0.01
I0601 12:34:51.034595 24067 solver.cpp:237] Iteration 8860, loss = 4.72374
I0601 12:34:51.034629 24067 solver.cpp:253]     Train net output #0: loss = 4.9689 (* 1 = 4.9689 loss)
I0601 12:34:51.034634 24067 sgd_solver.cpp:106] Iteration 8860, lr = 0.01
I0601 12:34:56.511358 24067 solver.cpp:237] Iteration 8880, loss = 4.72149
I0601 12:34:56.511389 24067 solver.cpp:253]     Train net output #0: loss = 4.68339 (* 1 = 4.68339 loss)
I0601 12:34:56.511395 24067 sgd_solver.cpp:106] Iteration 8880, lr = 0.01
I0601 12:35:01.989183 24067 solver.cpp:237] Iteration 8900, loss = 4.77821
I0601 12:35:01.989228 24067 solver.cpp:253]     Train net output #0: loss = 5.00422 (* 1 = 5.00422 loss)
I0601 12:35:01.989235 24067 sgd_solver.cpp:106] Iteration 8900, lr = 0.01
I0601 12:35:07.472544 24067 solver.cpp:237] Iteration 8920, loss = 4.80071
I0601 12:35:07.472589 24067 solver.cpp:253]     Train net output #0: loss = 4.7745 (* 1 = 4.7745 loss)
I0601 12:35:07.472599 24067 sgd_solver.cpp:106] Iteration 8920, lr = 0.01
I0601 12:35:12.954219 24067 solver.cpp:237] Iteration 8940, loss = 4.76034
I0601 12:35:12.954437 24067 solver.cpp:253]     Train net output #0: loss = 4.74827 (* 1 = 4.74827 loss)
I0601 12:35:12.954464 24067 sgd_solver.cpp:106] Iteration 8940, lr = 0.01
I0601 12:35:18.447136 24067 solver.cpp:237] Iteration 8960, loss = 4.71224
I0601 12:35:18.447185 24067 solver.cpp:253]     Train net output #0: loss = 4.64449 (* 1 = 4.64449 loss)
I0601 12:35:18.447193 24067 sgd_solver.cpp:106] Iteration 8960, lr = 0.01
I0601 12:35:23.916676 24067 solver.cpp:237] Iteration 8980, loss = 4.75571
I0601 12:35:23.916703 24067 solver.cpp:253]     Train net output #0: loss = 4.83246 (* 1 = 4.83246 loss)
I0601 12:35:23.916709 24067 sgd_solver.cpp:106] Iteration 8980, lr = 0.01
I0601 12:35:29.281275 24067 solver.cpp:341] Iteration 9000, Testing net (#0)
I0601 12:35:57.177937 24067 blocking_queue.cpp:50] Data layer prefetch queue empty
I0601 12:36:00.518450 24067 solver.cpp:409]     Test net output #0: accuracy = 0.1314
I0601 12:36:00.518497 24067 solver.cpp:409]     Test net output #1: loss = 4.70147 (* 1 = 4.70147 loss)
I0601 12:36:00.597499 24067 solver.cpp:237] Iteration 9000, loss = 4.7285
I0601 12:36:00.597537 24067 solver.cpp:253]     Train net output #0: loss = 4.69622 (* 1 = 4.69622 loss)
I0601 12:36:00.597545 24067 sgd_solver.cpp:106] Iteration 9000, lr = 0.01
I0601 12:36:06.049468 24067 solver.cpp:237] Iteration 9020, loss = 4.76892
I0601 12:36:06.049517 24067 solver.cpp:253]     Train net output #0: loss = 4.64895 (* 1 = 4.64895 loss)
I0601 12:36:06.049525 24067 sgd_solver.cpp:106] Iteration 9020, lr = 0.01
I0601 12:36:11.505251 24067 solver.cpp:237] Iteration 9040, loss = 4.77821
I0601 12:36:11.505298 24067 solver.cpp:253]     Train net output #0: loss = 4.66557 (* 1 = 4.66557 loss)
I0601 12:36:11.505306 24067 sgd_solver.cpp:106] Iteration 9040, lr = 0.01
I0601 12:36:16.965158 24067 solver.cpp:237] Iteration 9060, loss = 4.7281
I0601 12:36:16.965206 24067 solver.cpp:253]     Train net output #0: loss = 4.70262 (* 1 = 4.70262 loss)
I0601 12:36:16.965214 24067 sgd_solver.cpp:106] Iteration 9060, lr = 0.01
I0601 12:36:22.428522 24067 solver.cpp:237] Iteration 9080, loss = 4.67987
I0601 12:36:22.428566 24067 solver.cpp:253]     Train net output #0: loss = 4.49767 (* 1 = 4.49767 loss)
I0601 12:36:22.428573 24067 sgd_solver.cpp:106] Iteration 9080, lr = 0.01
I0601 12:36:27.894932 24067 solver.cpp:237] Iteration 9100, loss = 4.72479
I0601 12:36:27.895208 24067 solver.cpp:253]     Train net output #0: loss = 4.79533 (* 1 = 4.79533 loss)
I0601 12:36:27.895236 24067 sgd_solver.cpp:106] Iteration 9100, lr = 0.01
I0601 12:36:33.358086 24067 solver.cpp:237] Iteration 9120, loss = 4.74962
I0601 12:36:33.358135 24067 solver.cpp:253]     Train net output #0: loss = 4.58641 (* 1 = 4.58641 loss)
I0601 12:36:33.358144 24067 sgd_solver.cpp:106] Iteration 9120, lr = 0.01
I0601 12:36:38.821732 24067 solver.cpp:237] Iteration 9140, loss = 4.7477
I0601 12:36:38.821786 24067 solver.cpp:253]     Train net output #0: loss = 4.67189 (* 1 = 4.67189 loss)
I0601 12:36:38.821794 24067 sgd_solver.cpp:106] Iteration 9140, lr = 0.01
I0601 12:36:44.280367 24067 solver.cpp:237] Iteration 9160, loss = 4.74676
I0601 12:36:44.280416 24067 solver.cpp:253]     Train net output #0: loss = 4.8798 (* 1 = 4.8798 loss)
I0601 12:36:44.280424 24067 sgd_solver.cpp:106] Iteration 9160, lr = 0.01
I0601 12:36:49.744673 24067 solver.cpp:237] Iteration 9180, loss = 4.75297
I0601 12:36:49.744722 24067 solver.cpp:253]     Train net output #0: loss = 4.63557 (* 1 = 4.63557 loss)
I0601 12:36:49.744741 24067 sgd_solver.cpp:106] Iteration 9180, lr = 0.01
I0601 12:36:55.208984 24067 solver.cpp:237] Iteration 9200, loss = 4.72525
I0601 12:36:55.209045 24067 solver.cpp:253]     Train net output #0: loss = 4.6093 (* 1 = 4.6093 loss)
I0601 12:36:55.209053 24067 sgd_solver.cpp:106] Iteration 9200, lr = 0.01
I0601 12:37:00.682734 24067 solver.cpp:237] Iteration 9220, loss = 4.69702
I0601 12:37:00.682953 24067 solver.cpp:253]     Train net output #0: loss = 4.79288 (* 1 = 4.79288 loss)
I0601 12:37:00.682968 24067 sgd_solver.cpp:106] Iteration 9220, lr = 0.01
I0601 12:37:06.156204 24067 solver.cpp:237] Iteration 9240, loss = 4.73942
I0601 12:37:06.156258 24067 solver.cpp:253]     Train net output #0: loss = 4.63227 (* 1 = 4.63227 loss)
I0601 12:37:06.156265 24067 sgd_solver.cpp:106] Iteration 9240, lr = 0.01
I0601 12:37:11.633790 24067 solver.cpp:237] Iteration 9260, loss = 4.69361
I0601 12:37:11.633846 24067 solver.cpp:253]     Train net output #0: loss = 4.75451 (* 1 = 4.75451 loss)
I0601 12:37:11.633854 24067 sgd_solver.cpp:106] Iteration 9260, lr = 0.01
I0601 12:37:17.111799 24067 solver.cpp:237] Iteration 9280, loss = 4.68109
I0601 12:37:17.111847 24067 solver.cpp:253]     Train net output #0: loss = 4.75863 (* 1 = 4.75863 loss)
I0601 12:37:17.111866 24067 sgd_solver.cpp:106] Iteration 9280, lr = 0.01
I0601 12:37:22.585350 24067 solver.cpp:237] Iteration 9300, loss = 4.72055
I0601 12:37:22.585402 24067 solver.cpp:253]     Train net output #0: loss = 4.47396 (* 1 = 4.47396 loss)
I0601 12:37:22.585412 24067 sgd_solver.cpp:106] Iteration 9300, lr = 0.01
I0601 12:37:28.070147 24067 solver.cpp:237] Iteration 9320, loss = 4.70145
I0601 12:37:28.070195 24067 solver.cpp:253]     Train net output #0: loss = 4.77208 (* 1 = 4.77208 loss)
I0601 12:37:28.070201 24067 sgd_solver.cpp:106] Iteration 9320, lr = 0.01
I0601 12:37:33.515228 24067 solver.cpp:237] Iteration 9340, loss = 4.69631
I0601 12:37:33.515416 24067 solver.cpp:253]     Train net output #0: loss = 4.69234 (* 1 = 4.69234 loss)
I0601 12:37:33.515435 24067 sgd_solver.cpp:106] Iteration 9340, lr = 0.01
I0601 12:37:38.993067 24067 solver.cpp:237] Iteration 9360, loss = 4.75895
I0601 12:37:38.993114 24067 solver.cpp:253]     Train net output #0: loss = 4.73842 (* 1 = 4.73842 loss)
I0601 12:37:38.993122 24067 sgd_solver.cpp:106] Iteration 9360, lr = 0.01
I0601 12:37:44.475486 24067 solver.cpp:237] Iteration 9380, loss = 4.63502
I0601 12:37:44.475533 24067 solver.cpp:253]     Train net output #0: loss = 4.7575 (* 1 = 4.7575 loss)
I0601 12:37:44.475540 24067 sgd_solver.cpp:106] Iteration 9380, lr = 0.01
I0601 12:37:49.964182 24067 solver.cpp:237] Iteration 9400, loss = 4.68259
I0601 12:37:49.964232 24067 solver.cpp:253]     Train net output #0: loss = 4.91902 (* 1 = 4.91902 loss)
I0601 12:37:49.964241 24067 sgd_solver.cpp:106] Iteration 9400, lr = 0.01
I0601 12:37:55.449414 24067 solver.cpp:237] Iteration 9420, loss = 4.65657
I0601 12:37:55.449470 24067 solver.cpp:253]     Train net output #0: loss = 4.81375 (* 1 = 4.81375 loss)
I0601 12:37:55.449477 24067 sgd_solver.cpp:106] Iteration 9420, lr = 0.01
I0601 12:38:00.928335 24067 solver.cpp:237] Iteration 9440, loss = 4.71943
I0601 12:38:00.928400 24067 solver.cpp:253]     Train net output #0: loss = 4.7026 (* 1 = 4.7026 loss)
I0601 12:38:00.928409 24067 sgd_solver.cpp:106] Iteration 9440, lr = 0.01
I0601 12:38:06.416558 24067 solver.cpp:237] Iteration 9460, loss = 4.79467
I0601 12:38:06.416740 24067 solver.cpp:253]     Train net output #0: loss = 4.79104 (* 1 = 4.79104 loss)
I0601 12:38:06.416750 24067 sgd_solver.cpp:106] Iteration 9460, lr = 0.01
I0601 12:38:11.899785 24067 solver.cpp:237] Iteration 9480, loss = 4.74492
I0601 12:38:11.899833 24067 solver.cpp:253]     Train net output #0: loss = 4.80999 (* 1 = 4.80999 loss)
I0601 12:38:11.899842 24067 sgd_solver.cpp:106] Iteration 9480, lr = 0.01
I0601 12:38:17.389313 24067 solver.cpp:237] Iteration 9500, loss = 4.71611
I0601 12:38:17.389365 24067 solver.cpp:253]     Train net output #0: loss = 4.58823 (* 1 = 4.58823 loss)
I0601 12:38:17.389379 24067 sgd_solver.cpp:106] Iteration 9500, lr = 0.01
I0601 12:38:22.874824 24067 solver.cpp:237] Iteration 9520, loss = 4.72908
I0601 12:38:22.874868 24067 solver.cpp:253]     Train net output #0: loss = 4.47631 (* 1 = 4.47631 loss)
I0601 12:38:22.874876 24067 sgd_solver.cpp:106] Iteration 9520, lr = 0.01
I0601 12:38:28.359921 24067 solver.cpp:237] Iteration 9540, loss = 4.74691
I0601 12:38:28.359961 24067 solver.cpp:253]     Train net output #0: loss = 4.4969 (* 1 = 4.4969 loss)
I0601 12:38:28.359972 24067 sgd_solver.cpp:106] Iteration 9540, lr = 0.01
I0601 12:38:33.843958 24067 solver.cpp:237] Iteration 9560, loss = 4.67969
I0601 12:38:33.844007 24067 solver.cpp:253]     Train net output #0: loss = 4.75024 (* 1 = 4.75024 loss)
I0601 12:38:33.844015 24067 sgd_solver.cpp:106] Iteration 9560, lr = 0.01
I0601 12:38:39.307090 24067 solver.cpp:237] Iteration 9580, loss = 4.74088
I0601 12:38:39.307333 24067 solver.cpp:253]     Train net output #0: loss = 4.6644 (* 1 = 4.6644 loss)
I0601 12:38:39.307356 24067 sgd_solver.cpp:106] Iteration 9580, lr = 0.01
I0601 12:38:44.796475 24067 solver.cpp:237] Iteration 9600, loss = 4.71174
I0601 12:38:44.796521 24067 solver.cpp:253]     Train net output #0: loss = 4.6792 (* 1 = 4.6792 loss)
I0601 12:38:44.796528 24067 sgd_solver.cpp:106] Iteration 9600, lr = 0.01
I0601 12:38:50.281138 24067 solver.cpp:237] Iteration 9620, loss = 4.6838
I0601 12:38:50.281186 24067 solver.cpp:253]     Train net output #0: loss = 4.74554 (* 1 = 4.74554 loss)
I0601 12:38:50.281193 24067 sgd_solver.cpp:106] Iteration 9620, lr = 0.01
I0601 12:38:55.766577 24067 solver.cpp:237] Iteration 9640, loss = 4.69649
I0601 12:38:55.766623 24067 solver.cpp:253]     Train net output #0: loss = 4.62016 (* 1 = 4.62016 loss)
I0601 12:38:55.766629 24067 sgd_solver.cpp:106] Iteration 9640, lr = 0.01
I0601 12:39:01.220037 24067 solver.cpp:237] Iteration 9660, loss = 4.66959
I0601 12:39:01.220082 24067 solver.cpp:253]     Train net output #0: loss = 4.75893 (* 1 = 4.75893 loss)
I0601 12:39:01.220088 24067 sgd_solver.cpp:106] Iteration 9660, lr = 0.01
I0601 12:39:06.657591 24067 solver.cpp:237] Iteration 9680, loss = 4.65682
I0601 12:39:06.657635 24067 solver.cpp:253]     Train net output #0: loss = 4.30682 (* 1 = 4.30682 loss)
I0601 12:39:06.657640 24067 sgd_solver.cpp:106] Iteration 9680, lr = 0.01
I0601 12:39:12.126257 24067 solver.cpp:237] Iteration 9700, loss = 4.7294
I0601 12:39:12.126395 24067 solver.cpp:253]     Train net output #0: loss = 5.0406 (* 1 = 5.0406 loss)
I0601 12:39:12.126405 24067 sgd_solver.cpp:106] Iteration 9700, lr = 0.01
I0601 12:39:17.594259 24067 solver.cpp:237] Iteration 9720, loss = 4.69996
I0601 12:39:17.594306 24067 solver.cpp:253]     Train net output #0: loss = 4.61404 (* 1 = 4.61404 loss)
I0601 12:39:17.594312 24067 sgd_solver.cpp:106] Iteration 9720, lr = 0.01
I0601 12:39:23.047787 24067 solver.cpp:237] Iteration 9740, loss = 4.70232
I0601 12:39:23.047832 24067 solver.cpp:253]     Train net output #0: loss = 4.44632 (* 1 = 4.44632 loss)
I0601 12:39:23.047837 24067 sgd_solver.cpp:106] Iteration 9740, lr = 0.01
I0601 12:39:28.482090 24067 solver.cpp:237] Iteration 9760, loss = 4.7368
I0601 12:39:28.482134 24067 solver.cpp:253]     Train net output #0: loss = 4.91342 (* 1 = 4.91342 loss)
I0601 12:39:28.482141 24067 sgd_solver.cpp:106] Iteration 9760, lr = 0.01
I0601 12:39:33.915863 24067 solver.cpp:237] Iteration 9780, loss = 4.68947
I0601 12:39:33.915907 24067 solver.cpp:253]     Train net output #0: loss = 4.59887 (* 1 = 4.59887 loss)
I0601 12:39:33.915913 24067 sgd_solver.cpp:106] Iteration 9780, lr = 0.01
I0601 12:39:39.355345 24067 solver.cpp:237] Iteration 9800, loss = 4.65761
I0601 12:39:39.355391 24067 solver.cpp:253]     Train net output #0: loss = 4.49029 (* 1 = 4.49029 loss)
I0601 12:39:39.355398 24067 sgd_solver.cpp:106] Iteration 9800, lr = 0.01
I0601 12:39:44.792181 24067 solver.cpp:237] Iteration 9820, loss = 4.6797
I0601 12:39:44.792260 24067 solver.cpp:253]     Train net output #0: loss = 4.87489 (* 1 = 4.87489 loss)
I0601 12:39:44.792268 24067 sgd_solver.cpp:106] Iteration 9820, lr = 0.01
I0601 12:39:50.229939 24067 solver.cpp:237] Iteration 9840, loss = 4.69384
I0601 12:39:50.229980 24067 solver.cpp:253]     Train net output #0: loss = 4.71405 (* 1 = 4.71405 loss)
I0601 12:39:50.229992 24067 sgd_solver.cpp:106] Iteration 9840, lr = 0.01
I0601 12:39:55.670411 24067 solver.cpp:237] Iteration 9860, loss = 4.67407
I0601 12:39:55.670464 24067 solver.cpp:253]     Train net output #0: loss = 5.0062 (* 1 = 5.0062 loss)
I0601 12:39:55.670475 24067 sgd_solver.cpp:106] Iteration 9860, lr = 0.01
I0601 12:40:01.102188 24067 solver.cpp:237] Iteration 9880, loss = 4.6959
I0601 12:40:01.102260 24067 solver.cpp:253]     Train net output #0: loss = 4.64013 (* 1 = 4.64013 loss)
I0601 12:40:01.102272 24067 sgd_solver.cpp:106] Iteration 9880, lr = 0.01
I0601 12:40:06.565701 24067 solver.cpp:237] Iteration 9900, loss = 4.69204
I0601 12:40:06.565744 24067 solver.cpp:253]     Train net output #0: loss = 4.84282 (* 1 = 4.84282 loss)
I0601 12:40:06.565752 24067 sgd_solver.cpp:106] Iteration 9900, lr = 0.01
I0601 12:40:12.060144 24067 solver.cpp:237] Iteration 9920, loss = 4.6777
I0601 12:40:12.060201 24067 solver.cpp:253]     Train net output #0: loss = 4.7209 (* 1 = 4.7209 loss)
I0601 12:40:12.060209 24067 sgd_solver.cpp:106] Iteration 9920, lr = 0.01
I0601 12:40:17.547031 24067 solver.cpp:237] Iteration 9940, loss = 4.69177
I0601 12:40:17.547291 24067 solver.cpp:253]     Train net output #0: loss = 4.64533 (* 1 = 4.64533 loss)
I0601 12:40:17.547327 24067 sgd_solver.cpp:106] Iteration 9940, lr = 0.01
I0601 12:40:23.043054 24067 solver.cpp:237] Iteration 9960, loss = 4.66357
I0601 12:40:23.043097 24067 solver.cpp:253]     Train net output #0: loss = 4.46394 (* 1 = 4.46394 loss)
I0601 12:40:23.043104 24067 sgd_solver.cpp:106] Iteration 9960, lr = 0.01
I0601 12:40:28.531935 24067 solver.cpp:237] Iteration 9980, loss = 4.72549
I0601 12:40:28.531981 24067 solver.cpp:253]     Train net output #0: loss = 4.40099 (* 1 = 4.40099 loss)
I0601 12:40:28.531992 24067 sgd_solver.cpp:106] Iteration 9980, lr = 0.01
I0601 12:40:33.940315 24067 solver.cpp:459] Snapshotting to binary proto file snapshots/caffenet128_no_lrn_lsuv_bn_after_TanH_iter_10000.caffemodel
I0601 12:40:35.202457 24067 sgd_solver.cpp:269] Snapshotting solver state to binary proto file snapshots/caffenet128_no_lrn_lsuv_bn_after_TanH_iter_10000.solverstate
I0601 12:40:36.231847 24067 solver.cpp:341] Iteration 10000, Testing net (#0)
I0601 12:41:03.129851 24067 blocking_queue.cpp:50] Data layer prefetch queue empty
I0601 12:41:06.380139 24067 solver.cpp:409]     Test net output #0: accuracy = 0.14624
I0601 12:41:06.380177 24067 solver.cpp:409]     Test net output #1: loss = 4.53125 (* 1 = 4.53125 loss)
I0601 12:41:06.459345 24067 solver.cpp:237] Iteration 10000, loss = 4.70325
I0601 12:41:06.459386 24067 solver.cpp:253]     Train net output #0: loss = 4.63553 (* 1 = 4.63553 loss)
I0601 12:41:06.459398 24067 sgd_solver.cpp:106] Iteration 10000, lr = 0.01
I0601 12:41:11.915515 24067 solver.cpp:237] Iteration 10020, loss = 4.70347
I0601 12:41:11.915555 24067 solver.cpp:253]     Train net output #0: loss = 4.85636 (* 1 = 4.85636 loss)
I0601 12:41:11.915562 24067 sgd_solver.cpp:106] Iteration 10020, lr = 0.01
I0601 12:41:17.372794 24067 solver.cpp:237] Iteration 10040, loss = 4.61858
I0601 12:41:17.372831 24067 solver.cpp:253]     Train net output #0: loss = 4.46423 (* 1 = 4.46423 loss)
I0601 12:41:17.372839 24067 sgd_solver.cpp:106] Iteration 10040, lr = 0.01
I0601 12:41:22.834540 24067 solver.cpp:237] Iteration 10060, loss = 4.70684
I0601 12:41:22.834591 24067 solver.cpp:253]     Train net output #0: loss = 4.64667 (* 1 = 4.64667 loss)
I0601 12:41:22.834600 24067 sgd_solver.cpp:106] Iteration 10060, lr = 0.01
I0601 12:41:28.302688 24067 solver.cpp:237] Iteration 10080, loss = 4.72605
I0601 12:41:28.302736 24067 solver.cpp:253]     Train net output #0: loss = 4.60134 (* 1 = 4.60134 loss)
I0601 12:41:28.302745 24067 sgd_solver.cpp:106] Iteration 10080, lr = 0.01
I0601 12:41:33.765913 24067 solver.cpp:237] Iteration 10100, loss = 4.66332
I0601 12:41:33.766160 24067 solver.cpp:253]     Train net output #0: loss = 4.61427 (* 1 = 4.61427 loss)
I0601 12:41:33.766187 24067 sgd_solver.cpp:106] Iteration 10100, lr = 0.01
I0601 12:41:39.232452 24067 solver.cpp:237] Iteration 10120, loss = 4.69247
I0601 12:41:39.232506 24067 solver.cpp:253]     Train net output #0: loss = 4.55432 (* 1 = 4.55432 loss)
I0601 12:41:39.232516 24067 sgd_solver.cpp:106] Iteration 10120, lr = 0.01
I0601 12:41:44.699491 24067 solver.cpp:237] Iteration 10140, loss = 4.70348
I0601 12:41:44.699534 24067 solver.cpp:253]     Train net output #0: loss = 4.52913 (* 1 = 4.52913 loss)
I0601 12:41:44.699544 24067 sgd_solver.cpp:106] Iteration 10140, lr = 0.01
I0601 12:41:50.170004 24067 solver.cpp:237] Iteration 10160, loss = 4.6829
I0601 12:41:50.170050 24067 solver.cpp:253]     Train net output #0: loss = 4.93409 (* 1 = 4.93409 loss)
I0601 12:41:50.170060 24067 sgd_solver.cpp:106] Iteration 10160, lr = 0.01
I0601 12:41:55.614092 24067 solver.cpp:237] Iteration 10180, loss = 4.66286
I0601 12:41:55.614133 24067 solver.cpp:253]     Train net output #0: loss = 4.69759 (* 1 = 4.69759 loss)
I0601 12:41:55.614143 24067 sgd_solver.cpp:106] Iteration 10180, lr = 0.01
I0601 12:42:01.088531 24067 solver.cpp:237] Iteration 10200, loss = 4.64818
I0601 12:42:01.088572 24067 solver.cpp:253]     Train net output #0: loss = 4.9046 (* 1 = 4.9046 loss)
I0601 12:42:01.088580 24067 sgd_solver.cpp:106] Iteration 10200, lr = 0.01
I0601 12:42:06.567267 24067 solver.cpp:237] Iteration 10220, loss = 4.67771
I0601 12:42:06.567474 24067 solver.cpp:253]     Train net output #0: loss = 4.56392 (* 1 = 4.56392 loss)
I0601 12:42:06.567487 24067 sgd_solver.cpp:106] Iteration 10220, lr = 0.01
I0601 12:42:12.008206 24067 solver.cpp:237] Iteration 10240, loss = 4.59877
I0601 12:42:12.008250 24067 solver.cpp:253]     Train net output #0: loss = 4.91567 (* 1 = 4.91567 loss)
I0601 12:42:12.008257 24067 sgd_solver.cpp:106] Iteration 10240, lr = 0.01
I0601 12:42:17.437691 24067 solver.cpp:237] Iteration 10260, loss = 4.69373
I0601 12:42:17.437738 24067 solver.cpp:253]     Train net output #0: loss = 4.63518 (* 1 = 4.63518 loss)
I0601 12:42:17.437746 24067 sgd_solver.cpp:106] Iteration 10260, lr = 0.01
I0601 12:42:22.900046 24067 solver.cpp:237] Iteration 10280, loss = 4.65416
I0601 12:42:22.900084 24067 solver.cpp:253]     Train net output #0: loss = 4.50586 (* 1 = 4.50586 loss)
I0601 12:42:22.900094 24067 sgd_solver.cpp:106] Iteration 10280, lr = 0.01
I0601 12:42:28.370195 24067 solver.cpp:237] Iteration 10300, loss = 4.63564
I0601 12:42:28.370237 24067 solver.cpp:253]     Train net output #0: loss = 4.5501 (* 1 = 4.5501 loss)
I0601 12:42:28.370245 24067 sgd_solver.cpp:106] Iteration 10300, lr = 0.01
I0601 12:42:33.817251 24067 solver.cpp:237] Iteration 10320, loss = 4.67266
I0601 12:42:33.817286 24067 solver.cpp:253]     Train net output #0: loss = 4.8253 (* 1 = 4.8253 loss)
I0601 12:42:33.817296 24067 sgd_solver.cpp:106] Iteration 10320, lr = 0.01
I0601 12:42:39.252537 24067 solver.cpp:237] Iteration 10340, loss = 4.69474
I0601 12:42:39.252735 24067 solver.cpp:253]     Train net output #0: loss = 4.8518 (* 1 = 4.8518 loss)
I0601 12:42:39.252758 24067 sgd_solver.cpp:106] Iteration 10340, lr = 0.01
I0601 12:42:44.681136 24067 solver.cpp:237] Iteration 10360, loss = 4.69836
I0601 12:42:44.681186 24067 solver.cpp:253]     Train net output #0: loss = 4.75722 (* 1 = 4.75722 loss)
I0601 12:42:44.681193 24067 sgd_solver.cpp:106] Iteration 10360, lr = 0.01
I0601 12:42:50.158375 24067 solver.cpp:237] Iteration 10380, loss = 4.64886
I0601 12:42:50.158439 24067 solver.cpp:253]     Train net output #0: loss = 4.83478 (* 1 = 4.83478 loss)
I0601 12:42:50.158453 24067 sgd_solver.cpp:106] Iteration 10380, lr = 0.01
I0601 12:42:55.642812 24067 solver.cpp:237] Iteration 10400, loss = 4.6148
I0601 12:42:55.642855 24067 solver.cpp:253]     Train net output #0: loss = 4.50482 (* 1 = 4.50482 loss)
I0601 12:42:55.642866 24067 sgd_solver.cpp:106] Iteration 10400, lr = 0.01
I0601 12:43:01.132803 24067 solver.cpp:237] Iteration 10420, loss = 4.63975
I0601 12:43:01.132849 24067 solver.cpp:253]     Train net output #0: loss = 4.64014 (* 1 = 4.64014 loss)
I0601 12:43:01.132860 24067 sgd_solver.cpp:106] Iteration 10420, lr = 0.01
I0601 12:43:06.622683 24067 solver.cpp:237] Iteration 10440, loss = 4.61441
I0601 12:43:06.622748 24067 solver.cpp:253]     Train net output #0: loss = 4.59343 (* 1 = 4.59343 loss)
I0601 12:43:06.622761 24067 sgd_solver.cpp:106] Iteration 10440, lr = 0.01
I0601 12:43:12.103575 24067 solver.cpp:237] Iteration 10460, loss = 4.64609
I0601 12:43:12.103770 24067 solver.cpp:253]     Train net output #0: loss = 4.45364 (* 1 = 4.45364 loss)
I0601 12:43:12.103799 24067 sgd_solver.cpp:106] Iteration 10460, lr = 0.01
I0601 12:43:17.594041 24067 solver.cpp:237] Iteration 10480, loss = 4.65496
I0601 12:43:17.594105 24067 solver.cpp:253]     Train net output #0: loss = 4.69524 (* 1 = 4.69524 loss)
I0601 12:43:17.594120 24067 sgd_solver.cpp:106] Iteration 10480, lr = 0.01
I0601 12:43:23.086658 24067 solver.cpp:237] Iteration 10500, loss = 4.64322
I0601 12:43:23.086709 24067 solver.cpp:253]     Train net output #0: loss = 4.23028 (* 1 = 4.23028 loss)
I0601 12:43:23.086717 24067 sgd_solver.cpp:106] Iteration 10500, lr = 0.01
I0601 12:43:28.574393 24067 solver.cpp:237] Iteration 10520, loss = 4.68996
I0601 12:43:28.574443 24067 solver.cpp:253]     Train net output #0: loss = 4.73201 (* 1 = 4.73201 loss)
I0601 12:43:28.574451 24067 sgd_solver.cpp:106] Iteration 10520, lr = 0.01
I0601 12:43:34.050776 24067 solver.cpp:237] Iteration 10540, loss = 4.6672
I0601 12:43:34.050829 24067 solver.cpp:253]     Train net output #0: loss = 4.70677 (* 1 = 4.70677 loss)
I0601 12:43:34.050842 24067 sgd_solver.cpp:106] Iteration 10540, lr = 0.01
I0601 12:43:39.538539 24067 solver.cpp:237] Iteration 10560, loss = 4.66765
I0601 12:43:39.538590 24067 solver.cpp:253]     Train net output #0: loss = 4.70271 (* 1 = 4.70271 loss)
I0601 12:43:39.538599 24067 sgd_solver.cpp:106] Iteration 10560, lr = 0.01
I0601 12:43:45.029551 24067 solver.cpp:237] Iteration 10580, loss = 4.71586
I0601 12:43:45.029784 24067 solver.cpp:253]     Train net output #0: loss = 4.6974 (* 1 = 4.6974 loss)
I0601 12:43:45.029815 24067 sgd_solver.cpp:106] Iteration 10580, lr = 0.01
I0601 12:43:50.524261 24067 solver.cpp:237] Iteration 10600, loss = 4.69731
I0601 12:43:50.524312 24067 solver.cpp:253]     Train net output #0: loss = 4.75473 (* 1 = 4.75473 loss)
I0601 12:43:50.524320 24067 sgd_solver.cpp:106] Iteration 10600, lr = 0.01
I0601 12:43:56.012671 24067 solver.cpp:237] Iteration 10620, loss = 4.68994
I0601 12:43:56.012707 24067 solver.cpp:253]     Train net output #0: loss = 4.56556 (* 1 = 4.56556 loss)
I0601 12:43:56.012715 24067 sgd_solver.cpp:106] Iteration 10620, lr = 0.01
I0601 12:44:01.500010 24067 solver.cpp:237] Iteration 10640, loss = 4.68483
I0601 12:44:01.500072 24067 solver.cpp:253]     Train net output #0: loss = 4.47184 (* 1 = 4.47184 loss)
I0601 12:44:01.500080 24067 sgd_solver.cpp:106] Iteration 10640, lr = 0.01
I0601 12:44:06.985601 24067 solver.cpp:237] Iteration 10660, loss = 4.61677
I0601 12:44:06.985651 24067 solver.cpp:253]     Train net output #0: loss = 4.5553 (* 1 = 4.5553 loss)
I0601 12:44:06.985658 24067 sgd_solver.cpp:106] Iteration 10660, lr = 0.01
I0601 12:44:12.472168 24067 solver.cpp:237] Iteration 10680, loss = 4.70846
I0601 12:44:12.472218 24067 solver.cpp:253]     Train net output #0: loss = 4.5972 (* 1 = 4.5972 loss)
I0601 12:44:12.472224 24067 sgd_solver.cpp:106] Iteration 10680, lr = 0.01
I0601 12:44:17.954391 24067 solver.cpp:237] Iteration 10700, loss = 4.65846
I0601 12:44:17.954577 24067 solver.cpp:253]     Train net output #0: loss = 4.50651 (* 1 = 4.50651 loss)
I0601 12:44:17.954605 24067 sgd_solver.cpp:106] Iteration 10700, lr = 0.01
I0601 12:44:23.395136 24067 solver.cpp:237] Iteration 10720, loss = 4.59307
I0601 12:44:23.395187 24067 solver.cpp:253]     Train net output #0: loss = 4.50462 (* 1 = 4.50462 loss)
I0601 12:44:23.395195 24067 sgd_solver.cpp:106] Iteration 10720, lr = 0.01
I0601 12:44:28.875951 24067 solver.cpp:237] Iteration 10740, loss = 4.62594
I0601 12:44:28.876013 24067 solver.cpp:253]     Train net output #0: loss = 4.64601 (* 1 = 4.64601 loss)
I0601 12:44:28.876021 24067 sgd_solver.cpp:106] Iteration 10740, lr = 0.01
I0601 12:44:34.367660 24067 solver.cpp:237] Iteration 10760, loss = 4.60184
I0601 12:44:34.367710 24067 solver.cpp:253]     Train net output #0: loss = 4.48588 (* 1 = 4.48588 loss)
I0601 12:44:34.367717 24067 sgd_solver.cpp:106] Iteration 10760, lr = 0.01
I0601 12:44:39.850630 24067 solver.cpp:237] Iteration 10780, loss = 4.65174
I0601 12:44:39.850683 24067 solver.cpp:253]     Train net output #0: loss = 4.38845 (* 1 = 4.38845 loss)
I0601 12:44:39.850692 24067 sgd_solver.cpp:106] Iteration 10780, lr = 0.01
I0601 12:44:45.338907 24067 solver.cpp:237] Iteration 10800, loss = 4.65112
I0601 12:44:45.338956 24067 solver.cpp:253]     Train net output #0: loss = 4.64486 (* 1 = 4.64486 loss)
I0601 12:44:45.338975 24067 sgd_solver.cpp:106] Iteration 10800, lr = 0.01
I0601 12:44:50.828277 24067 solver.cpp:237] Iteration 10820, loss = 4.62739
I0601 12:44:50.828505 24067 solver.cpp:253]     Train net output #0: loss = 4.65217 (* 1 = 4.65217 loss)
I0601 12:44:50.828541 24067 sgd_solver.cpp:106] Iteration 10820, lr = 0.01
I0601 12:44:56.322583 24067 solver.cpp:237] Iteration 10840, loss = 4.57242
I0601 12:44:56.322630 24067 solver.cpp:253]     Train net output #0: loss = 4.38618 (* 1 = 4.38618 loss)
I0601 12:44:56.322638 24067 sgd_solver.cpp:106] Iteration 10840, lr = 0.01
I0601 12:45:01.807181 24067 solver.cpp:237] Iteration 10860, loss = 4.60417
I0601 12:45:01.807229 24067 solver.cpp:253]     Train net output #0: loss = 4.3146 (* 1 = 4.3146 loss)
I0601 12:45:01.807240 24067 sgd_solver.cpp:106] Iteration 10860, lr = 0.01
I0601 12:45:07.289033 24067 solver.cpp:237] Iteration 10880, loss = 4.65361
I0601 12:45:07.289082 24067 solver.cpp:253]     Train net output #0: loss = 4.59727 (* 1 = 4.59727 loss)
I0601 12:45:07.289090 24067 sgd_solver.cpp:106] Iteration 10880, lr = 0.01
I0601 12:45:12.774840 24067 solver.cpp:237] Iteration 10900, loss = 4.62259
I0601 12:45:12.774899 24067 solver.cpp:253]     Train net output #0: loss = 4.25622 (* 1 = 4.25622 loss)
I0601 12:45:12.774909 24067 sgd_solver.cpp:106] Iteration 10900, lr = 0.01
I0601 12:45:18.263105 24067 solver.cpp:237] Iteration 10920, loss = 4.67373
I0601 12:45:18.263151 24067 solver.cpp:253]     Train net output #0: loss = 4.69373 (* 1 = 4.69373 loss)
I0601 12:45:18.263159 24067 sgd_solver.cpp:106] Iteration 10920, lr = 0.01
I0601 12:45:23.753428 24067 solver.cpp:237] Iteration 10940, loss = 4.5457
I0601 12:45:23.753672 24067 solver.cpp:253]     Train net output #0: loss = 4.51665 (* 1 = 4.51665 loss)
I0601 12:45:23.753697 24067 sgd_solver.cpp:106] Iteration 10940, lr = 0.01
I0601 12:45:29.244211 24067 solver.cpp:237] Iteration 10960, loss = 4.63828
I0601 12:45:29.244268 24067 solver.cpp:253]     Train net output #0: loss = 4.68485 (* 1 = 4.68485 loss)
I0601 12:45:29.244277 24067 sgd_solver.cpp:106] Iteration 10960, lr = 0.01
I0601 12:45:34.729919 24067 solver.cpp:237] Iteration 10980, loss = 4.61806
I0601 12:45:34.729970 24067 solver.cpp:253]     Train net output #0: loss = 4.81686 (* 1 = 4.81686 loss)
I0601 12:45:34.729979 24067 sgd_solver.cpp:106] Iteration 10980, lr = 0.01
I0601 12:45:40.134954 24067 solver.cpp:341] Iteration 11000, Testing net (#0)
I0601 12:46:06.803903 24067 blocking_queue.cpp:50] Data layer prefetch queue empty
I0601 12:46:10.073714 24067 solver.cpp:409]     Test net output #0: accuracy = 0.15032
I0601 12:46:10.073760 24067 solver.cpp:409]     Test net output #1: loss = 4.4838 (* 1 = 4.4838 loss)
I0601 12:46:10.152806 24067 solver.cpp:237] Iteration 11000, loss = 4.63774
I0601 12:46:10.152848 24067 solver.cpp:253]     Train net output #0: loss = 4.76747 (* 1 = 4.76747 loss)
I0601 12:46:10.152858 24067 sgd_solver.cpp:106] Iteration 11000, lr = 0.01
I0601 12:46:15.609426 24067 solver.cpp:237] Iteration 11020, loss = 4.60062
I0601 12:46:15.609469 24067 solver.cpp:253]     Train net output #0: loss = 4.80893 (* 1 = 4.80893 loss)
I0601 12:46:15.609477 24067 sgd_solver.cpp:106] Iteration 11020, lr = 0.01
I0601 12:46:21.069356 24067 solver.cpp:237] Iteration 11040, loss = 4.53461
I0601 12:46:21.069406 24067 solver.cpp:253]     Train net output #0: loss = 4.66007 (* 1 = 4.66007 loss)
I0601 12:46:21.069412 24067 sgd_solver.cpp:106] Iteration 11040, lr = 0.01
I0601 12:46:26.535099 24067 solver.cpp:237] Iteration 11060, loss = 4.58925
I0601 12:46:26.535148 24067 solver.cpp:253]     Train net output #0: loss = 4.57912 (* 1 = 4.57912 loss)
I0601 12:46:26.535156 24067 sgd_solver.cpp:106] Iteration 11060, lr = 0.01
I0601 12:46:32.003581 24067 solver.cpp:237] Iteration 11080, loss = 4.57865
I0601 12:46:32.003650 24067 solver.cpp:253]     Train net output #0: loss = 4.62474 (* 1 = 4.62474 loss)
I0601 12:46:32.003659 24067 sgd_solver.cpp:106] Iteration 11080, lr = 0.01
I0601 12:46:37.470986 24067 solver.cpp:237] Iteration 11100, loss = 4.60029
I0601 12:46:37.471181 24067 solver.cpp:253]     Train net output #0: loss = 4.43895 (* 1 = 4.43895 loss)
I0601 12:46:37.471212 24067 sgd_solver.cpp:106] Iteration 11100, lr = 0.01
I0601 12:46:42.947491 24067 solver.cpp:237] Iteration 11120, loss = 4.58899
I0601 12:46:42.947537 24067 solver.cpp:253]     Train net output #0: loss = 4.55561 (* 1 = 4.55561 loss)
I0601 12:46:42.947545 24067 sgd_solver.cpp:106] Iteration 11120, lr = 0.01
I0601 12:46:48.421272 24067 solver.cpp:237] Iteration 11140, loss = 4.58784
I0601 12:46:48.421321 24067 solver.cpp:253]     Train net output #0: loss = 4.76959 (* 1 = 4.76959 loss)
I0601 12:46:48.421329 24067 sgd_solver.cpp:106] Iteration 11140, lr = 0.01
I0601 12:46:53.893502 24067 solver.cpp:237] Iteration 11160, loss = 4.6338
I0601 12:46:53.893550 24067 solver.cpp:253]     Train net output #0: loss = 4.52042 (* 1 = 4.52042 loss)
I0601 12:46:53.893559 24067 sgd_solver.cpp:106] Iteration 11160, lr = 0.01
I0601 12:46:59.375659 24067 solver.cpp:237] Iteration 11180, loss = 4.64538
I0601 12:46:59.375705 24067 solver.cpp:253]     Train net output #0: loss = 4.65759 (* 1 = 4.65759 loss)
I0601 12:46:59.375713 24067 sgd_solver.cpp:106] Iteration 11180, lr = 0.01
I0601 12:47:04.858302 24067 solver.cpp:237] Iteration 11200, loss = 4.58855
I0601 12:47:04.858350 24067 solver.cpp:253]     Train net output #0: loss = 4.60894 (* 1 = 4.60894 loss)
I0601 12:47:04.858358 24067 sgd_solver.cpp:106] Iteration 11200, lr = 0.01
I0601 12:47:10.339643 24067 solver.cpp:237] Iteration 11220, loss = 4.62419
I0601 12:47:10.339808 24067 solver.cpp:253]     Train net output #0: loss = 4.91712 (* 1 = 4.91712 loss)
I0601 12:47:10.339819 24067 sgd_solver.cpp:106] Iteration 11220, lr = 0.01
I0601 12:47:15.824441 24067 solver.cpp:237] Iteration 11240, loss = 4.62292
I0601 12:47:15.824491 24067 solver.cpp:253]     Train net output #0: loss = 4.75474 (* 1 = 4.75474 loss)
I0601 12:47:15.824498 24067 sgd_solver.cpp:106] Iteration 11240, lr = 0.01
I0601 12:47:21.303279 24067 solver.cpp:237] Iteration 11260, loss = 4.65641
I0601 12:47:21.303326 24067 solver.cpp:253]     Train net output #0: loss = 4.76416 (* 1 = 4.76416 loss)
I0601 12:47:21.303335 24067 sgd_solver.cpp:106] Iteration 11260, lr = 0.01
I0601 12:47:26.784441 24067 solver.cpp:237] Iteration 11280, loss = 4.69175
I0601 12:47:26.784497 24067 solver.cpp:253]     Train net output #0: loss = 4.61694 (* 1 = 4.61694 loss)
I0601 12:47:26.784504 24067 sgd_solver.cpp:106] Iteration 11280, lr = 0.01
I0601 12:47:32.262028 24067 solver.cpp:237] Iteration 11300, loss = 4.61553
I0601 12:47:32.262075 24067 solver.cpp:253]     Train net output #0: loss = 4.65048 (* 1 = 4.65048 loss)
I0601 12:47:32.262084 24067 sgd_solver.cpp:106] Iteration 11300, lr = 0.01
I0601 12:47:37.756718 24067 solver.cpp:237] Iteration 11320, loss = 4.62322
I0601 12:47:37.756767 24067 solver.cpp:253]     Train net output #0: loss = 4.60046 (* 1 = 4.60046 loss)
I0601 12:47:37.756775 24067 sgd_solver.cpp:106] Iteration 11320, lr = 0.01
I0601 12:47:43.242274 24067 solver.cpp:237] Iteration 11340, loss = 4.61224
I0601 12:47:43.242503 24067 solver.cpp:253]     Train net output #0: loss = 4.65826 (* 1 = 4.65826 loss)
I0601 12:47:43.242528 24067 sgd_solver.cpp:106] Iteration 11340, lr = 0.01
I0601 12:47:48.726023 24067 solver.cpp:237] Iteration 11360, loss = 4.62173
I0601 12:47:48.726071 24067 solver.cpp:253]     Train net output #0: loss = 4.34162 (* 1 = 4.34162 loss)
I0601 12:47:48.726079 24067 sgd_solver.cpp:106] Iteration 11360, lr = 0.01
I0601 12:47:54.207739 24067 solver.cpp:237] Iteration 11380, loss = 4.59552
I0601 12:47:54.207799 24067 solver.cpp:253]     Train net output #0: loss = 4.65395 (* 1 = 4.65395 loss)
I0601 12:47:54.207808 24067 sgd_solver.cpp:106] Iteration 11380, lr = 0.01
I0601 12:47:59.689790 24067 solver.cpp:237] Iteration 11400, loss = 4.54406
I0601 12:47:59.689841 24067 solver.cpp:253]     Train net output #0: loss = 4.41565 (* 1 = 4.41565 loss)
I0601 12:47:59.689848 24067 sgd_solver.cpp:106] Iteration 11400, lr = 0.01
I0601 12:48:05.179237 24067 solver.cpp:237] Iteration 11420, loss = 4.63146
I0601 12:48:05.179286 24067 solver.cpp:253]     Train net output #0: loss = 4.65951 (* 1 = 4.65951 loss)
I0601 12:48:05.179294 24067 sgd_solver.cpp:106] Iteration 11420, lr = 0.01
I0601 12:48:10.665051 24067 solver.cpp:237] Iteration 11440, loss = 4.63598
I0601 12:48:10.665105 24067 solver.cpp:253]     Train net output #0: loss = 4.68572 (* 1 = 4.68572 loss)
I0601 12:48:10.665112 24067 sgd_solver.cpp:106] Iteration 11440, lr = 0.01
I0601 12:48:16.150576 24067 solver.cpp:237] Iteration 11460, loss = 4.67417
I0601 12:48:16.150809 24067 solver.cpp:253]     Train net output #0: loss = 4.60781 (* 1 = 4.60781 loss)
I0601 12:48:16.150832 24067 sgd_solver.cpp:106] Iteration 11460, lr = 0.01
I0601 12:48:21.636916 24067 solver.cpp:237] Iteration 11480, loss = 4.52883
I0601 12:48:21.636963 24067 solver.cpp:253]     Train net output #0: loss = 4.68033 (* 1 = 4.68033 loss)
I0601 12:48:21.636971 24067 sgd_solver.cpp:106] Iteration 11480, lr = 0.01
I0601 12:48:27.131687 24067 solver.cpp:237] Iteration 11500, loss = 4.66631
I0601 12:48:27.131736 24067 solver.cpp:253]     Train net output #0: loss = 4.69376 (* 1 = 4.69376 loss)
I0601 12:48:27.131745 24067 sgd_solver.cpp:106] Iteration 11500, lr = 0.01
I0601 12:48:32.623536 24067 solver.cpp:237] Iteration 11520, loss = 4.59548
I0601 12:48:32.623585 24067 solver.cpp:253]     Train net output #0: loss = 4.52157 (* 1 = 4.52157 loss)
I0601 12:48:32.623594 24067 sgd_solver.cpp:106] Iteration 11520, lr = 0.01
I0601 12:48:38.109315 24067 solver.cpp:237] Iteration 11540, loss = 4.60523
I0601 12:48:38.109366 24067 solver.cpp:253]     Train net output #0: loss = 4.89131 (* 1 = 4.89131 loss)
I0601 12:48:38.109376 24067 sgd_solver.cpp:106] Iteration 11540, lr = 0.01
I0601 12:48:43.595912 24067 solver.cpp:237] Iteration 11560, loss = 4.63565
I0601 12:48:43.595975 24067 solver.cpp:253]     Train net output #0: loss = 4.72173 (* 1 = 4.72173 loss)
I0601 12:48:43.595984 24067 sgd_solver.cpp:106] Iteration 11560, lr = 0.01
I0601 12:48:49.092180 24067 solver.cpp:237] Iteration 11580, loss = 4.58794
I0601 12:48:49.092509 24067 solver.cpp:253]     Train net output #0: loss = 4.83364 (* 1 = 4.83364 loss)
I0601 12:48:49.092536 24067 sgd_solver.cpp:106] Iteration 11580, lr = 0.01
I0601 12:48:54.578246 24067 solver.cpp:237] Iteration 11600, loss = 4.62328
I0601 12:48:54.578297 24067 solver.cpp:253]     Train net output #0: loss = 4.84793 (* 1 = 4.84793 loss)
I0601 12:48:54.578306 24067 sgd_solver.cpp:106] Iteration 11600, lr = 0.01
I0601 12:49:00.068615 24067 solver.cpp:237] Iteration 11620, loss = 4.63992
I0601 12:49:00.068667 24067 solver.cpp:253]     Train net output #0: loss = 4.94108 (* 1 = 4.94108 loss)
I0601 12:49:00.068678 24067 sgd_solver.cpp:106] Iteration 11620, lr = 0.01
I0601 12:49:05.561075 24067 solver.cpp:237] Iteration 11640, loss = 4.54699
I0601 12:49:05.561125 24067 solver.cpp:253]     Train net output #0: loss = 4.66414 (* 1 = 4.66414 loss)
I0601 12:49:05.561134 24067 sgd_solver.cpp:106] Iteration 11640, lr = 0.01
I0601 12:49:11.041877 24067 solver.cpp:237] Iteration 11660, loss = 4.55208
I0601 12:49:11.041923 24067 solver.cpp:253]     Train net output #0: loss = 4.50103 (* 1 = 4.50103 loss)
I0601 12:49:11.041932 24067 sgd_solver.cpp:106] Iteration 11660, lr = 0.01
I0601 12:49:16.530588 24067 solver.cpp:237] Iteration 11680, loss = 4.63238
I0601 12:49:16.530642 24067 solver.cpp:253]     Train net output #0: loss = 4.74368 (* 1 = 4.74368 loss)
I0601 12:49:16.530652 24067 sgd_solver.cpp:106] Iteration 11680, lr = 0.01
I0601 12:49:22.011648 24067 solver.cpp:237] Iteration 11700, loss = 4.58449
I0601 12:49:22.011826 24067 solver.cpp:253]     Train net output #0: loss = 4.48432 (* 1 = 4.48432 loss)
I0601 12:49:22.011837 24067 sgd_solver.cpp:106] Iteration 11700, lr = 0.01
I0601 12:49:27.495285 24067 solver.cpp:237] Iteration 11720, loss = 4.52798
I0601 12:49:27.495337 24067 solver.cpp:253]     Train net output #0: loss = 4.53354 (* 1 = 4.53354 loss)
I0601 12:49:27.495347 24067 sgd_solver.cpp:106] Iteration 11720, lr = 0.01
I0601 12:49:32.983624 24067 solver.cpp:237] Iteration 11740, loss = 4.62655
I0601 12:49:32.983675 24067 solver.cpp:253]     Train net output #0: loss = 4.40773 (* 1 = 4.40773 loss)
I0601 12:49:32.983683 24067 sgd_solver.cpp:106] Iteration 11740, lr = 0.01
I0601 12:49:38.473064 24067 solver.cpp:237] Iteration 11760, loss = 4.57851
I0601 12:49:38.473116 24067 solver.cpp:253]     Train net output #0: loss = 4.56422 (* 1 = 4.56422 loss)
I0601 12:49:38.473124 24067 sgd_solver.cpp:106] Iteration 11760, lr = 0.01
I0601 12:49:43.961195 24067 solver.cpp:237] Iteration 11780, loss = 4.60256
I0601 12:49:43.961251 24067 solver.cpp:253]     Train net output #0: loss = 4.29355 (* 1 = 4.29355 loss)
I0601 12:49:43.961261 24067 sgd_solver.cpp:106] Iteration 11780, lr = 0.01
I0601 12:49:49.453816 24067 solver.cpp:237] Iteration 11800, loss = 4.55601
I0601 12:49:49.453868 24067 solver.cpp:253]     Train net output #0: loss = 4.61891 (* 1 = 4.61891 loss)
I0601 12:49:49.453876 24067 sgd_solver.cpp:106] Iteration 11800, lr = 0.01
I0601 12:49:54.938642 24067 solver.cpp:237] Iteration 11820, loss = 4.57117
I0601 12:49:54.938874 24067 solver.cpp:253]     Train net output #0: loss = 4.59868 (* 1 = 4.59868 loss)
I0601 12:49:54.938910 24067 sgd_solver.cpp:106] Iteration 11820, lr = 0.01
I0601 12:50:00.432622 24067 solver.cpp:237] Iteration 11840, loss = 4.59901
I0601 12:50:00.432669 24067 solver.cpp:253]     Train net output #0: loss = 4.67026 (* 1 = 4.67026 loss)
I0601 12:50:00.432678 24067 sgd_solver.cpp:106] Iteration 11840, lr = 0.01
I0601 12:50:05.927330 24067 solver.cpp:237] Iteration 11860, loss = 4.59795
I0601 12:50:05.927376 24067 solver.cpp:253]     Train net output #0: loss = 4.52192 (* 1 = 4.52192 loss)
I0601 12:50:05.927383 24067 sgd_solver.cpp:106] Iteration 11860, lr = 0.01
I0601 12:50:11.417371 24067 solver.cpp:237] Iteration 11880, loss = 4.54338
I0601 12:50:11.417419 24067 solver.cpp:253]     Train net output #0: loss = 4.63879 (* 1 = 4.63879 loss)
I0601 12:50:11.417426 24067 sgd_solver.cpp:106] Iteration 11880, lr = 0.01
I0601 12:50:16.910732 24067 solver.cpp:237] Iteration 11900, loss = 4.60648
I0601 12:50:16.910781 24067 solver.cpp:253]     Train net output #0: loss = 4.74081 (* 1 = 4.74081 loss)
I0601 12:50:16.910801 24067 sgd_solver.cpp:106] Iteration 11900, lr = 0.01
I0601 12:50:22.401881 24067 solver.cpp:237] Iteration 11920, loss = 4.54555
I0601 12:50:22.401932 24067 solver.cpp:253]     Train net output #0: loss = 4.374 (* 1 = 4.374 loss)
I0601 12:50:22.401939 24067 sgd_solver.cpp:106] Iteration 11920, lr = 0.01
I0601 12:50:27.889272 24067 solver.cpp:237] Iteration 11940, loss = 4.55048
I0601 12:50:27.889497 24067 solver.cpp:253]     Train net output #0: loss = 4.47627 (* 1 = 4.47627 loss)
I0601 12:50:27.889521 24067 sgd_solver.cpp:106] Iteration 11940, lr = 0.01
I0601 12:50:33.349495 24067 solver.cpp:237] Iteration 11960, loss = 4.60826
I0601 12:50:33.349545 24067 solver.cpp:253]     Train net output #0: loss = 4.62716 (* 1 = 4.62716 loss)
I0601 12:50:33.349551 24067 sgd_solver.cpp:106] Iteration 11960, lr = 0.01
I0601 12:50:38.786432 24067 solver.cpp:237] Iteration 11980, loss = 4.61423
I0601 12:50:38.786489 24067 solver.cpp:253]     Train net output #0: loss = 4.79464 (* 1 = 4.79464 loss)
I0601 12:50:38.786496 24067 sgd_solver.cpp:106] Iteration 11980, lr = 0.01
I0601 12:50:44.142279 24067 solver.cpp:341] Iteration 12000, Testing net (#0)
I0601 12:51:10.762812 24067 blocking_queue.cpp:50] Data layer prefetch queue empty
I0601 12:51:13.847913 24067 solver.cpp:409]     Test net output #0: accuracy = 0.15412
I0601 12:51:13.847965 24067 solver.cpp:409]     Test net output #1: loss = 4.47489 (* 1 = 4.47489 loss)
I0601 12:51:13.927331 24067 solver.cpp:237] Iteration 12000, loss = 4.54405
I0601 12:51:13.927381 24067 solver.cpp:253]     Train net output #0: loss = 4.26803 (* 1 = 4.26803 loss)
I0601 12:51:13.927389 24067 sgd_solver.cpp:106] Iteration 12000, lr = 0.01
I0601 12:51:19.387536 24067 solver.cpp:237] Iteration 12020, loss = 4.5328
I0601 12:51:19.387584 24067 solver.cpp:253]     Train net output #0: loss = 4.67134 (* 1 = 4.67134 loss)
I0601 12:51:19.387591 24067 sgd_solver.cpp:106] Iteration 12020, lr = 0.01
I0601 12:51:24.861095 24067 solver.cpp:237] Iteration 12040, loss = 4.52983
I0601 12:51:24.861142 24067 solver.cpp:253]     Train net output #0: loss = 4.65227 (* 1 = 4.65227 loss)
I0601 12:51:24.861150 24067 sgd_solver.cpp:106] Iteration 12040, lr = 0.01
I0601 12:51:30.327397 24067 solver.cpp:237] Iteration 12060, loss = 4.57392
I0601 12:51:30.327455 24067 solver.cpp:253]     Train net output #0: loss = 4.42175 (* 1 = 4.42175 loss)
I0601 12:51:30.327462 24067 sgd_solver.cpp:106] Iteration 12060, lr = 0.01
I0601 12:51:35.802083 24067 solver.cpp:237] Iteration 12080, loss = 4.6043
I0601 12:51:35.802124 24067 solver.cpp:253]     Train net output #0: loss = 4.49955 (* 1 = 4.49955 loss)
I0601 12:51:35.802131 24067 sgd_solver.cpp:106] Iteration 12080, lr = 0.01
I0601 12:51:41.266672 24067 solver.cpp:237] Iteration 12100, loss = 4.56421
I0601 12:51:41.266890 24067 solver.cpp:253]     Train net output #0: loss = 4.60576 (* 1 = 4.60576 loss)
I0601 12:51:41.266914 24067 sgd_solver.cpp:106] Iteration 12100, lr = 0.01
I0601 12:51:46.699674 24067 solver.cpp:237] Iteration 12120, loss = 4.58993
I0601 12:51:46.699730 24067 solver.cpp:253]     Train net output #0: loss = 4.85352 (* 1 = 4.85352 loss)
I0601 12:51:46.699738 24067 sgd_solver.cpp:106] Iteration 12120, lr = 0.01
I0601 12:51:52.176057 24067 solver.cpp:237] Iteration 12140, loss = 4.54882
I0601 12:51:52.176117 24067 solver.cpp:253]     Train net output #0: loss = 4.56698 (* 1 = 4.56698 loss)
I0601 12:51:52.176126 24067 sgd_solver.cpp:106] Iteration 12140, lr = 0.01
I0601 12:51:57.657218 24067 solver.cpp:237] Iteration 12160, loss = 4.59868
I0601 12:51:57.657272 24067 solver.cpp:253]     Train net output #0: loss = 4.46474 (* 1 = 4.46474 loss)
I0601 12:51:57.657282 24067 sgd_solver.cpp:106] Iteration 12160, lr = 0.01
I0601 12:52:03.129436 24067 solver.cpp:237] Iteration 12180, loss = 4.52218
I0601 12:52:03.129484 24067 solver.cpp:253]     Train net output #0: loss = 4.45305 (* 1 = 4.45305 loss)
I0601 12:52:03.129492 24067 sgd_solver.cpp:106] Iteration 12180, lr = 0.01
I0601 12:52:08.605378 24067 solver.cpp:237] Iteration 12200, loss = 4.51314
I0601 12:52:08.605429 24067 solver.cpp:253]     Train net output #0: loss = 4.53745 (* 1 = 4.53745 loss)
I0601 12:52:08.605439 24067 sgd_solver.cpp:106] Iteration 12200, lr = 0.01
I0601 12:52:14.082891 24067 solver.cpp:237] Iteration 12220, loss = 4.49743
I0601 12:52:14.083134 24067 solver.cpp:253]     Train net output #0: loss = 4.57644 (* 1 = 4.57644 loss)
I0601 12:52:14.083158 24067 sgd_solver.cpp:106] Iteration 12220, lr = 0.01
I0601 12:52:19.565980 24067 solver.cpp:237] Iteration 12240, loss = 4.61027
I0601 12:52:19.566030 24067 solver.cpp:253]     Train net output #0: loss = 4.487 (* 1 = 4.487 loss)
I0601 12:52:19.566038 24067 sgd_solver.cpp:106] Iteration 12240, lr = 0.01
I0601 12:52:25.055285 24067 solver.cpp:237] Iteration 12260, loss = 4.60037
I0601 12:52:25.055333 24067 solver.cpp:253]     Train net output #0: loss = 4.35226 (* 1 = 4.35226 loss)
I0601 12:52:25.055341 24067 sgd_solver.cpp:106] Iteration 12260, lr = 0.01
I0601 12:52:30.539971 24067 solver.cpp:237] Iteration 12280, loss = 4.57584
I0601 12:52:30.540017 24067 solver.cpp:253]     Train net output #0: loss = 4.60839 (* 1 = 4.60839 loss)
I0601 12:52:30.540025 24067 sgd_solver.cpp:106] Iteration 12280, lr = 0.01
I0601 12:52:36.026048 24067 solver.cpp:237] Iteration 12300, loss = 4.58844
I0601 12:52:36.026096 24067 solver.cpp:253]     Train net output #0: loss = 4.77037 (* 1 = 4.77037 loss)
I0601 12:52:36.026103 24067 sgd_solver.cpp:106] Iteration 12300, lr = 0.01
I0601 12:52:41.512518 24067 solver.cpp:237] Iteration 12320, loss = 4.57958
I0601 12:52:41.512567 24067 solver.cpp:253]     Train net output #0: loss = 4.58989 (* 1 = 4.58989 loss)
I0601 12:52:41.512575 24067 sgd_solver.cpp:106] Iteration 12320, lr = 0.01
I0601 12:52:47.008908 24067 solver.cpp:237] Iteration 12340, loss = 4.55243
I0601 12:52:47.009129 24067 solver.cpp:253]     Train net output #0: loss = 4.62458 (* 1 = 4.62458 loss)
I0601 12:52:47.009166 24067 sgd_solver.cpp:106] Iteration 12340, lr = 0.01
I0601 12:52:52.490375 24067 solver.cpp:237] Iteration 12360, loss = 4.52274
I0601 12:52:52.490422 24067 solver.cpp:253]     Train net output #0: loss = 4.59464 (* 1 = 4.59464 loss)
I0601 12:52:52.490430 24067 sgd_solver.cpp:106] Iteration 12360, lr = 0.01
I0601 12:52:57.972450 24067 solver.cpp:237] Iteration 12380, loss = 4.65511
I0601 12:52:57.972504 24067 solver.cpp:253]     Train net output #0: loss = 4.30324 (* 1 = 4.30324 loss)
I0601 12:52:57.972514 24067 sgd_solver.cpp:106] Iteration 12380, lr = 0.01
I0601 12:53:03.457438 24067 solver.cpp:237] Iteration 12400, loss = 4.63099
I0601 12:53:03.457490 24067 solver.cpp:253]     Train net output #0: loss = 4.55065 (* 1 = 4.55065 loss)
I0601 12:53:03.457499 24067 sgd_solver.cpp:106] Iteration 12400, lr = 0.01
I0601 12:53:08.946754 24067 solver.cpp:237] Iteration 12420, loss = 4.5736
I0601 12:53:08.946805 24067 solver.cpp:253]     Train net output #0: loss = 4.51327 (* 1 = 4.51327 loss)
I0601 12:53:08.946815 24067 sgd_solver.cpp:106] Iteration 12420, lr = 0.01
I0601 12:53:14.438923 24067 solver.cpp:237] Iteration 12440, loss = 4.51168
I0601 12:53:14.438972 24067 solver.cpp:253]     Train net output #0: loss = 4.48798 (* 1 = 4.48798 loss)
I0601 12:53:14.438982 24067 sgd_solver.cpp:106] Iteration 12440, lr = 0.01
I0601 12:53:19.925318 24067 solver.cpp:237] Iteration 12460, loss = 4.54346
I0601 12:53:19.925525 24067 solver.cpp:253]     Train net output #0: loss = 4.42527 (* 1 = 4.42527 loss)
I0601 12:53:19.925549 24067 sgd_solver.cpp:106] Iteration 12460, lr = 0.01
I0601 12:53:25.411530 24067 solver.cpp:237] Iteration 12480, loss = 4.55535
I0601 12:53:25.411581 24067 solver.cpp:253]     Train net output #0: loss = 4.57982 (* 1 = 4.57982 loss)
I0601 12:53:25.411589 24067 sgd_solver.cpp:106] Iteration 12480, lr = 0.01
I0601 12:53:30.900488 24067 solver.cpp:237] Iteration 12500, loss = 4.58429
I0601 12:53:30.900537 24067 solver.cpp:253]     Train net output #0: loss = 4.43732 (* 1 = 4.43732 loss)
I0601 12:53:30.900544 24067 sgd_solver.cpp:106] Iteration 12500, lr = 0.01
I0601 12:53:36.384732 24067 solver.cpp:237] Iteration 12520, loss = 4.51807
I0601 12:53:36.384780 24067 solver.cpp:253]     Train net output #0: loss = 4.65878 (* 1 = 4.65878 loss)
I0601 12:53:36.384788 24067 sgd_solver.cpp:106] Iteration 12520, lr = 0.01
I0601 12:53:41.876762 24067 solver.cpp:237] Iteration 12540, loss = 4.53514
I0601 12:53:41.876812 24067 solver.cpp:253]     Train net output #0: loss = 4.6027 (* 1 = 4.6027 loss)
I0601 12:53:41.876819 24067 sgd_solver.cpp:106] Iteration 12540, lr = 0.01
I0601 12:53:47.362241 24067 solver.cpp:237] Iteration 12560, loss = 4.53568
I0601 12:53:47.362292 24067 solver.cpp:253]     Train net output #0: loss = 4.71543 (* 1 = 4.71543 loss)
I0601 12:53:47.362306 24067 sgd_solver.cpp:106] Iteration 12560, lr = 0.01
I0601 12:53:52.842032 24067 solver.cpp:237] Iteration 12580, loss = 4.56068
I0601 12:53:52.842231 24067 solver.cpp:253]     Train net output #0: loss = 4.38114 (* 1 = 4.38114 loss)
I0601 12:53:52.842252 24067 sgd_solver.cpp:106] Iteration 12580, lr = 0.01
I0601 12:53:58.333127 24067 solver.cpp:237] Iteration 12600, loss = 4.52672
I0601 12:53:58.333163 24067 solver.cpp:253]     Train net output #0: loss = 4.37183 (* 1 = 4.37183 loss)
I0601 12:53:58.333173 24067 sgd_solver.cpp:106] Iteration 12600, lr = 0.01
I0601 12:54:03.826645 24067 solver.cpp:237] Iteration 12620, loss = 4.58609
I0601 12:54:03.826699 24067 solver.cpp:253]     Train net output #0: loss = 4.3914 (* 1 = 4.3914 loss)
I0601 12:54:03.826709 24067 sgd_solver.cpp:106] Iteration 12620, lr = 0.01
I0601 12:54:09.320832 24067 solver.cpp:237] Iteration 12640, loss = 4.57274
I0601 12:54:09.320885 24067 solver.cpp:253]     Train net output #0: loss = 4.55582 (* 1 = 4.55582 loss)
I0601 12:54:09.320906 24067 sgd_solver.cpp:106] Iteration 12640, lr = 0.01
I0601 12:54:14.808581 24067 solver.cpp:237] Iteration 12660, loss = 4.59569
I0601 12:54:14.808629 24067 solver.cpp:253]     Train net output #0: loss = 4.62631 (* 1 = 4.62631 loss)
I0601 12:54:14.808637 24067 sgd_solver.cpp:106] Iteration 12660, lr = 0.01
I0601 12:54:20.297536 24067 solver.cpp:237] Iteration 12680, loss = 4.60979
I0601 12:54:20.297587 24067 solver.cpp:253]     Train net output #0: loss = 4.77536 (* 1 = 4.77536 loss)
I0601 12:54:20.297607 24067 sgd_solver.cpp:106] Iteration 12680, lr = 0.01
I0601 12:54:25.785125 24067 solver.cpp:237] Iteration 12700, loss = 4.52031
I0601 12:54:25.785382 24067 solver.cpp:253]     Train net output #0: loss = 4.7968 (* 1 = 4.7968 loss)
I0601 12:54:25.785401 24067 sgd_solver.cpp:106] Iteration 12700, lr = 0.01
I0601 12:54:31.269481 24067 solver.cpp:237] Iteration 12720, loss = 4.52092
I0601 12:54:31.269529 24067 solver.cpp:253]     Train net output #0: loss = 4.73385 (* 1 = 4.73385 loss)
I0601 12:54:31.269536 24067 sgd_solver.cpp:106] Iteration 12720, lr = 0.01
I0601 12:54:36.756809 24067 solver.cpp:237] Iteration 12740, loss = 4.53019
I0601 12:54:36.756855 24067 solver.cpp:253]     Train net output #0: loss = 4.39486 (* 1 = 4.39486 loss)
I0601 12:54:36.756861 24067 sgd_solver.cpp:106] Iteration 12740, lr = 0.01
I0601 12:54:42.245313 24067 solver.cpp:237] Iteration 12760, loss = 4.53709
I0601 12:54:42.245358 24067 solver.cpp:253]     Train net output #0: loss = 4.3753 (* 1 = 4.3753 loss)
I0601 12:54:42.245373 24067 sgd_solver.cpp:106] Iteration 12760, lr = 0.01
I0601 12:54:47.736234 24067 solver.cpp:237] Iteration 12780, loss = 4.5931
I0601 12:54:47.736284 24067 solver.cpp:253]     Train net output #0: loss = 4.54579 (* 1 = 4.54579 loss)
I0601 12:54:47.736299 24067 sgd_solver.cpp:106] Iteration 12780, lr = 0.01
I0601 12:54:53.226393 24067 solver.cpp:237] Iteration 12800, loss = 4.58632
I0601 12:54:53.226440 24067 solver.cpp:253]     Train net output #0: loss = 4.20482 (* 1 = 4.20482 loss)
I0601 12:54:53.226447 24067 sgd_solver.cpp:106] Iteration 12800, lr = 0.01
I0601 12:54:58.714695 24067 solver.cpp:237] Iteration 12820, loss = 4.55343
I0601 12:54:58.714933 24067 solver.cpp:253]     Train net output #0: loss = 4.80548 (* 1 = 4.80548 loss)
I0601 12:54:58.714968 24067 sgd_solver.cpp:106] Iteration 12820, lr = 0.01
I0601 12:55:04.205432 24067 solver.cpp:237] Iteration 12840, loss = 4.52857
I0601 12:55:04.205483 24067 solver.cpp:253]     Train net output #0: loss = 4.54139 (* 1 = 4.54139 loss)
I0601 12:55:04.205492 24067 sgd_solver.cpp:106] Iteration 12840, lr = 0.01
I0601 12:55:09.697696 24067 solver.cpp:237] Iteration 12860, loss = 4.58495
I0601 12:55:09.697758 24067 solver.cpp:253]     Train net output #0: loss = 4.71715 (* 1 = 4.71715 loss)
I0601 12:55:09.697769 24067 sgd_solver.cpp:106] Iteration 12860, lr = 0.01
I0601 12:55:15.186765 24067 solver.cpp:237] Iteration 12880, loss = 4.57774
I0601 12:55:15.186816 24067 solver.cpp:253]     Train net output #0: loss = 4.56851 (* 1 = 4.56851 loss)
I0601 12:55:15.186825 24067 sgd_solver.cpp:106] Iteration 12880, lr = 0.01
I0601 12:55:20.674912 24067 solver.cpp:237] Iteration 12900, loss = 4.50697
I0601 12:55:20.674952 24067 solver.cpp:253]     Train net output #0: loss = 4.11205 (* 1 = 4.11205 loss)
I0601 12:55:20.674959 24067 sgd_solver.cpp:106] Iteration 12900, lr = 0.01
I0601 12:55:26.161247 24067 solver.cpp:237] Iteration 12920, loss = 4.57425
I0601 12:55:26.161314 24067 solver.cpp:253]     Train net output #0: loss = 4.50548 (* 1 = 4.50548 loss)
I0601 12:55:26.161326 24067 sgd_solver.cpp:106] Iteration 12920, lr = 0.01
I0601 12:55:31.644351 24067 solver.cpp:237] Iteration 12940, loss = 4.49717
I0601 12:55:31.644525 24067 solver.cpp:253]     Train net output #0: loss = 4.56237 (* 1 = 4.56237 loss)
I0601 12:55:31.644534 24067 sgd_solver.cpp:106] Iteration 12940, lr = 0.01
I0601 12:55:37.131528 24067 solver.cpp:237] Iteration 12960, loss = 4.63077
I0601 12:55:37.131580 24067 solver.cpp:253]     Train net output #0: loss = 4.67836 (* 1 = 4.67836 loss)
I0601 12:55:37.131590 24067 sgd_solver.cpp:106] Iteration 12960, lr = 0.01
I0601 12:55:42.621351 24067 solver.cpp:237] Iteration 12980, loss = 4.55703
I0601 12:55:42.621403 24067 solver.cpp:253]     Train net output #0: loss = 4.51826 (* 1 = 4.51826 loss)
I0601 12:55:42.621413 24067 sgd_solver.cpp:106] Iteration 12980, lr = 0.01
I0601 12:55:48.028411 24067 solver.cpp:341] Iteration 13000, Testing net (#0)
I0601 12:56:17.113212 24067 blocking_queue.cpp:50] Data layer prefetch queue empty
I0601 12:56:20.362979 24067 solver.cpp:409]     Test net output #0: accuracy = 0.1711
I0601 12:56:20.363028 24067 solver.cpp:409]     Test net output #1: loss = 4.31626 (* 1 = 4.31626 loss)
I0601 12:56:20.442260 24067 solver.cpp:237] Iteration 13000, loss = 4.50847
I0601 12:56:20.442303 24067 solver.cpp:253]     Train net output #0: loss = 4.6646 (* 1 = 4.6646 loss)
I0601 12:56:20.442312 24067 sgd_solver.cpp:106] Iteration 13000, lr = 0.01
I0601 12:56:25.896479 24067 solver.cpp:237] Iteration 13020, loss = 4.51527
I0601 12:56:25.896533 24067 solver.cpp:253]     Train net output #0: loss = 4.71601 (* 1 = 4.71601 loss)
I0601 12:56:25.896543 24067 sgd_solver.cpp:106] Iteration 13020, lr = 0.01
I0601 12:56:31.352509 24067 solver.cpp:237] Iteration 13040, loss = 4.51762
I0601 12:56:31.352550 24067 solver.cpp:253]     Train net output #0: loss = 4.50957 (* 1 = 4.50957 loss)
I0601 12:56:31.352556 24067 sgd_solver.cpp:106] Iteration 13040, lr = 0.01
I0601 12:56:36.761832 24067 solver.cpp:237] Iteration 13060, loss = 4.57556
I0601 12:56:36.761873 24067 solver.cpp:253]     Train net output #0: loss = 4.67752 (* 1 = 4.67752 loss)
I0601 12:56:36.761879 24067 sgd_solver.cpp:106] Iteration 13060, lr = 0.01
I0601 12:56:42.167438 24067 solver.cpp:237] Iteration 13080, loss = 4.53304
I0601 12:56:42.167486 24067 solver.cpp:253]     Train net output #0: loss = 4.42114 (* 1 = 4.42114 loss)
I0601 12:56:42.167492 24067 sgd_solver.cpp:106] Iteration 13080, lr = 0.01
I0601 12:56:47.577822 24067 solver.cpp:237] Iteration 13100, loss = 4.58892
I0601 12:56:47.578039 24067 solver.cpp:253]     Train net output #0: loss = 4.66995 (* 1 = 4.66995 loss)
I0601 12:56:47.578080 24067 sgd_solver.cpp:106] Iteration 13100, lr = 0.01
I0601 12:56:52.999361 24067 solver.cpp:237] Iteration 13120, loss = 4.57136
I0601 12:56:52.999409 24067 solver.cpp:253]     Train net output #0: loss = 4.45819 (* 1 = 4.45819 loss)
I0601 12:56:52.999419 24067 sgd_solver.cpp:106] Iteration 13120, lr = 0.01
I0601 12:56:58.420101 24067 solver.cpp:237] Iteration 13140, loss = 4.56674
I0601 12:56:58.420150 24067 solver.cpp:253]     Train net output #0: loss = 4.63646 (* 1 = 4.63646 loss)
I0601 12:56:58.420159 24067 sgd_solver.cpp:106] Iteration 13140, lr = 0.01
I0601 12:57:03.896342 24067 solver.cpp:237] Iteration 13160, loss = 4.52833
I0601 12:57:03.896414 24067 solver.cpp:253]     Train net output #0: loss = 4.47715 (* 1 = 4.47715 loss)
I0601 12:57:03.896430 24067 sgd_solver.cpp:106] Iteration 13160, lr = 0.01
I0601 12:57:09.370410 24067 solver.cpp:237] Iteration 13180, loss = 4.50724
I0601 12:57:09.370462 24067 solver.cpp:253]     Train net output #0: loss = 4.69302 (* 1 = 4.69302 loss)
I0601 12:57:09.370473 24067 sgd_solver.cpp:106] Iteration 13180, lr = 0.01
I0601 12:57:14.842088 24067 solver.cpp:237] Iteration 13200, loss = 4.49584
I0601 12:57:14.842138 24067 solver.cpp:253]     Train net output #0: loss = 4.7338 (* 1 = 4.7338 loss)
I0601 12:57:14.842147 24067 sgd_solver.cpp:106] Iteration 13200, lr = 0.01
I0601 12:57:20.321905 24067 solver.cpp:237] Iteration 13220, loss = 4.53909
I0601 12:57:20.322147 24067 solver.cpp:253]     Train net output #0: loss = 4.41044 (* 1 = 4.41044 loss)
I0601 12:57:20.322181 24067 sgd_solver.cpp:106] Iteration 13220, lr = 0.01
I0601 12:57:25.769237 24067 solver.cpp:237] Iteration 13240, loss = 4.54475
I0601 12:57:25.769285 24067 solver.cpp:253]     Train net output #0: loss = 4.50385 (* 1 = 4.50385 loss)
I0601 12:57:25.769291 24067 sgd_solver.cpp:106] Iteration 13240, lr = 0.01
I0601 12:57:31.242911 24067 solver.cpp:237] Iteration 13260, loss = 4.50653
I0601 12:57:31.242954 24067 solver.cpp:253]     Train net output #0: loss = 4.74935 (* 1 = 4.74935 loss)
I0601 12:57:31.242959 24067 sgd_solver.cpp:106] Iteration 13260, lr = 0.01
I0601 12:57:36.713516 24067 solver.cpp:237] Iteration 13280, loss = 4.56426
I0601 12:57:36.713565 24067 solver.cpp:253]     Train net output #0: loss = 4.84258 (* 1 = 4.84258 loss)
I0601 12:57:36.713578 24067 sgd_solver.cpp:106] Iteration 13280, lr = 0.01
I0601 12:57:42.192152 24067 solver.cpp:237] Iteration 13300, loss = 4.55015
I0601 12:57:42.192193 24067 solver.cpp:253]     Train net output #0: loss = 4.36746 (* 1 = 4.36746 loss)
I0601 12:57:42.192199 24067 sgd_solver.cpp:106] Iteration 13300, lr = 0.01
I0601 12:57:47.647976 24067 solver.cpp:237] Iteration 13320, loss = 4.49215
I0601 12:57:47.648015 24067 solver.cpp:253]     Train net output #0: loss = 4.42554 (* 1 = 4.42554 loss)
I0601 12:57:47.648021 24067 sgd_solver.cpp:106] Iteration 13320, lr = 0.01
I0601 12:57:53.114434 24067 solver.cpp:237] Iteration 13340, loss = 4.54093
I0601 12:57:53.114663 24067 solver.cpp:253]     Train net output #0: loss = 4.3864 (* 1 = 4.3864 loss)
I0601 12:57:53.114694 24067 sgd_solver.cpp:106] Iteration 13340, lr = 0.01
I0601 12:57:58.596271 24067 solver.cpp:237] Iteration 13360, loss = 4.50827
I0601 12:57:58.596317 24067 solver.cpp:253]     Train net output #0: loss = 4.70832 (* 1 = 4.70832 loss)
I0601 12:57:58.596323 24067 sgd_solver.cpp:106] Iteration 13360, lr = 0.01
I0601 12:58:04.080075 24067 solver.cpp:237] Iteration 13380, loss = 4.57511
I0601 12:58:04.080118 24067 solver.cpp:253]     Train net output #0: loss = 4.33377 (* 1 = 4.33377 loss)
I0601 12:58:04.080126 24067 sgd_solver.cpp:106] Iteration 13380, lr = 0.01
I0601 12:58:09.560919 24067 solver.cpp:237] Iteration 13400, loss = 4.57243
I0601 12:58:09.560948 24067 solver.cpp:253]     Train net output #0: loss = 4.52452 (* 1 = 4.52452 loss)
I0601 12:58:09.560955 24067 sgd_solver.cpp:106] Iteration 13400, lr = 0.01
I0601 12:58:15.007874 24067 solver.cpp:237] Iteration 13420, loss = 4.50329
I0601 12:58:15.007905 24067 solver.cpp:253]     Train net output #0: loss = 4.34782 (* 1 = 4.34782 loss)
I0601 12:58:15.007910 24067 sgd_solver.cpp:106] Iteration 13420, lr = 0.01
I0601 12:58:20.448348 24067 solver.cpp:237] Iteration 13440, loss = 4.46969
I0601 12:58:20.448395 24067 solver.cpp:253]     Train net output #0: loss = 4.53296 (* 1 = 4.53296 loss)
I0601 12:58:20.448403 24067 sgd_solver.cpp:106] Iteration 13440, lr = 0.01
I0601 12:58:25.907552 24067 solver.cpp:237] Iteration 13460, loss = 4.43284
I0601 12:58:25.907778 24067 solver.cpp:253]     Train net output #0: loss = 4.4455 (* 1 = 4.4455 loss)
I0601 12:58:25.907799 24067 sgd_solver.cpp:106] Iteration 13460, lr = 0.01
I0601 12:58:31.341347 24067 solver.cpp:237] Iteration 13480, loss = 4.53709
I0601 12:58:31.341397 24067 solver.cpp:253]     Train net output #0: loss = 4.40123 (* 1 = 4.40123 loss)
I0601 12:58:31.341406 24067 sgd_solver.cpp:106] Iteration 13480, lr = 0.01
I0601 12:58:36.776348 24067 solver.cpp:237] Iteration 13500, loss = 4.45246
I0601 12:58:36.776404 24067 solver.cpp:253]     Train net output #0: loss = 4.41363 (* 1 = 4.41363 loss)
I0601 12:58:36.776414 24067 sgd_solver.cpp:106] Iteration 13500, lr = 0.01
I0601 12:58:42.213673 24067 solver.cpp:237] Iteration 13520, loss = 4.54306
I0601 12:58:42.213723 24067 solver.cpp:253]     Train net output #0: loss = 4.31777 (* 1 = 4.31777 loss)
I0601 12:58:42.213733 24067 sgd_solver.cpp:106] Iteration 13520, lr = 0.01
I0601 12:58:47.697085 24067 solver.cpp:237] Iteration 13540, loss = 4.54349
I0601 12:58:47.697147 24067 solver.cpp:253]     Train net output #0: loss = 4.49574 (* 1 = 4.49574 loss)
I0601 12:58:47.697159 24067 sgd_solver.cpp:106] Iteration 13540, lr = 0.01
I0601 12:58:53.183646 24067 solver.cpp:237] Iteration 13560, loss = 4.56665
I0601 12:58:53.183707 24067 solver.cpp:253]     Train net output #0: loss = 4.39158 (* 1 = 4.39158 loss)
I0601 12:58:53.183717 24067 sgd_solver.cpp:106] Iteration 13560, lr = 0.01
I0601 12:58:58.668517 24067 solver.cpp:237] Iteration 13580, loss = 4.49855
I0601 12:58:58.668761 24067 solver.cpp:253]     Train net output #0: loss = 4.5447 (* 1 = 4.5447 loss)
I0601 12:58:58.668784 24067 sgd_solver.cpp:106] Iteration 13580, lr = 0.01
I0601 12:59:04.157493 24067 solver.cpp:237] Iteration 13600, loss = 4.47371
I0601 12:59:04.157541 24067 solver.cpp:253]     Train net output #0: loss = 4.39877 (* 1 = 4.39877 loss)
I0601 12:59:04.157548 24067 sgd_solver.cpp:106] Iteration 13600, lr = 0.01
I0601 12:59:09.648399 24067 solver.cpp:237] Iteration 13620, loss = 4.51467
I0601 12:59:09.648445 24067 solver.cpp:253]     Train net output #0: loss = 4.3629 (* 1 = 4.3629 loss)
I0601 12:59:09.648452 24067 sgd_solver.cpp:106] Iteration 13620, lr = 0.01
I0601 12:59:15.130153 24067 solver.cpp:237] Iteration 13640, loss = 4.57659
I0601 12:59:15.130199 24067 solver.cpp:253]     Train net output #0: loss = 4.67187 (* 1 = 4.67187 loss)
I0601 12:59:15.130206 24067 sgd_solver.cpp:106] Iteration 13640, lr = 0.01
I0601 12:59:20.620555 24067 solver.cpp:237] Iteration 13660, loss = 4.44107
I0601 12:59:20.620587 24067 solver.cpp:253]     Train net output #0: loss = 4.33382 (* 1 = 4.33382 loss)
I0601 12:59:20.620596 24067 sgd_solver.cpp:106] Iteration 13660, lr = 0.01
I0601 12:59:26.107378 24067 solver.cpp:237] Iteration 13680, loss = 4.50047
I0601 12:59:26.107429 24067 solver.cpp:253]     Train net output #0: loss = 4.47241 (* 1 = 4.47241 loss)
I0601 12:59:26.107436 24067 sgd_solver.cpp:106] Iteration 13680, lr = 0.01
I0601 12:59:31.598302 24067 solver.cpp:237] Iteration 13700, loss = 4.49924
I0601 12:59:31.598507 24067 solver.cpp:253]     Train net output #0: loss = 4.47995 (* 1 = 4.47995 loss)
I0601 12:59:31.598526 24067 sgd_solver.cpp:106] Iteration 13700, lr = 0.01
I0601 12:59:37.042516 24067 solver.cpp:237] Iteration 13720, loss = 4.47232
I0601 12:59:37.042562 24067 solver.cpp:253]     Train net output #0: loss = 4.05945 (* 1 = 4.05945 loss)
I0601 12:59:37.042570 24067 sgd_solver.cpp:106] Iteration 13720, lr = 0.01
I0601 12:59:42.479027 24067 solver.cpp:237] Iteration 13740, loss = 4.49487
I0601 12:59:42.479074 24067 solver.cpp:253]     Train net output #0: loss = 4.51327 (* 1 = 4.51327 loss)
I0601 12:59:42.479080 24067 sgd_solver.cpp:106] Iteration 13740, lr = 0.01
I0601 12:59:47.918848 24067 solver.cpp:237] Iteration 13760, loss = 4.4594
I0601 12:59:47.918895 24067 solver.cpp:253]     Train net output #0: loss = 4.4679 (* 1 = 4.4679 loss)
I0601 12:59:47.918900 24067 sgd_solver.cpp:106] Iteration 13760, lr = 0.01
I0601 12:59:53.386176 24067 solver.cpp:237] Iteration 13780, loss = 4.51636
I0601 12:59:53.386215 24067 solver.cpp:253]     Train net output #0: loss = 4.73759 (* 1 = 4.73759 loss)
I0601 12:59:53.386222 24067 sgd_solver.cpp:106] Iteration 13780, lr = 0.01
I0601 12:59:58.872473 24067 solver.cpp:237] Iteration 13800, loss = 4.50298
I0601 12:59:58.872522 24067 solver.cpp:253]     Train net output #0: loss = 4.38085 (* 1 = 4.38085 loss)
I0601 12:59:58.872530 24067 sgd_solver.cpp:106] Iteration 13800, lr = 0.01
I0601 13:00:04.359714 24067 solver.cpp:237] Iteration 13820, loss = 4.47616
I0601 13:00:04.359958 24067 solver.cpp:253]     Train net output #0: loss = 4.39703 (* 1 = 4.39703 loss)
I0601 13:00:04.359985 24067 sgd_solver.cpp:106] Iteration 13820, lr = 0.01
I0601 13:00:09.848680 24067 solver.cpp:237] Iteration 13840, loss = 4.44318
I0601 13:00:09.848719 24067 solver.cpp:253]     Train net output #0: loss = 4.58446 (* 1 = 4.58446 loss)
I0601 13:00:09.848729 24067 sgd_solver.cpp:106] Iteration 13840, lr = 0.01
I0601 13:00:15.338557 24067 solver.cpp:237] Iteration 13860, loss = 4.49071
I0601 13:00:15.338603 24067 solver.cpp:253]     Train net output #0: loss = 4.26854 (* 1 = 4.26854 loss)
I0601 13:00:15.338610 24067 sgd_solver.cpp:106] Iteration 13860, lr = 0.01
I0601 13:00:20.829741 24067 solver.cpp:237] Iteration 13880, loss = 4.50499
I0601 13:00:20.829787 24067 solver.cpp:253]     Train net output #0: loss = 4.55726 (* 1 = 4.55726 loss)
I0601 13:00:20.829795 24067 sgd_solver.cpp:106] Iteration 13880, lr = 0.01
I0601 13:00:26.325911 24067 solver.cpp:237] Iteration 13900, loss = 4.50949
I0601 13:00:26.325963 24067 solver.cpp:253]     Train net output #0: loss = 4.39988 (* 1 = 4.39988 loss)
I0601 13:00:26.325970 24067 sgd_solver.cpp:106] Iteration 13900, lr = 0.01
I0601 13:00:31.817953 24067 solver.cpp:237] Iteration 13920, loss = 4.50954
I0601 13:00:31.818007 24067 solver.cpp:253]     Train net output #0: loss = 4.37211 (* 1 = 4.37211 loss)
I0601 13:00:31.818019 24067 sgd_solver.cpp:106] Iteration 13920, lr = 0.01
I0601 13:00:37.303915 24067 solver.cpp:237] Iteration 13940, loss = 4.53275
I0601 13:00:37.304180 24067 solver.cpp:253]     Train net output #0: loss = 4.68444 (* 1 = 4.68444 loss)
I0601 13:00:37.304203 24067 sgd_solver.cpp:106] Iteration 13940, lr = 0.01
I0601 13:00:42.789427 24067 solver.cpp:237] Iteration 13960, loss = 4.50916
I0601 13:00:42.789474 24067 solver.cpp:253]     Train net output #0: loss = 4.56061 (* 1 = 4.56061 loss)
I0601 13:00:42.789480 24067 sgd_solver.cpp:106] Iteration 13960, lr = 0.01
I0601 13:00:48.275571 24067 solver.cpp:237] Iteration 13980, loss = 4.48563
I0601 13:00:48.275604 24067 solver.cpp:253]     Train net output #0: loss = 4.43501 (* 1 = 4.43501 loss)
I0601 13:00:48.275609 24067 sgd_solver.cpp:106] Iteration 13980, lr = 0.01
I0601 13:00:53.681144 24067 solver.cpp:341] Iteration 14000, Testing net (#0)
I0601 13:01:22.224074 24067 blocking_queue.cpp:50] Data layer prefetch queue empty
I0601 13:01:25.282485 24067 solver.cpp:409]     Test net output #0: accuracy = 0.17736
I0601 13:01:25.282527 24067 solver.cpp:409]     Test net output #1: loss = 4.24978 (* 1 = 4.24978 loss)
I0601 13:01:25.362937 24067 solver.cpp:237] Iteration 14000, loss = 4.50788
I0601 13:01:25.362982 24067 solver.cpp:253]     Train net output #0: loss = 4.64863 (* 1 = 4.64863 loss)
I0601 13:01:25.362993 24067 sgd_solver.cpp:106] Iteration 14000, lr = 0.01
I0601 13:01:30.821774 24067 solver.cpp:237] Iteration 14020, loss = 4.46883
I0601 13:01:30.821825 24067 solver.cpp:253]     Train net output #0: loss = 4.74318 (* 1 = 4.74318 loss)
I0601 13:01:30.821833 24067 sgd_solver.cpp:106] Iteration 14020, lr = 0.01
I0601 13:01:36.274572 24067 solver.cpp:237] Iteration 14040, loss = 4.50584
I0601 13:01:36.274621 24067 solver.cpp:253]     Train net output #0: loss = 4.49124 (* 1 = 4.49124 loss)
I0601 13:01:36.274631 24067 sgd_solver.cpp:106] Iteration 14040, lr = 0.01
I0601 13:01:41.732318 24067 solver.cpp:237] Iteration 14060, loss = 4.51264
I0601 13:01:41.732403 24067 solver.cpp:253]     Train net output #0: loss = 4.4978 (* 1 = 4.4978 loss)
I0601 13:01:41.732414 24067 sgd_solver.cpp:106] Iteration 14060, lr = 0.01
I0601 13:01:47.193387 24067 solver.cpp:237] Iteration 14080, loss = 4.47879
I0601 13:01:47.193437 24067 solver.cpp:253]     Train net output #0: loss = 4.33555 (* 1 = 4.33555 loss)
I0601 13:01:47.193446 24067 sgd_solver.cpp:106] Iteration 14080, lr = 0.01
I0601 13:01:52.657107 24067 solver.cpp:237] Iteration 14100, loss = 4.48117
I0601 13:01:52.657277 24067 solver.cpp:253]     Train net output #0: loss = 4.64046 (* 1 = 4.64046 loss)
I0601 13:01:52.657291 24067 sgd_solver.cpp:106] Iteration 14100, lr = 0.01
I0601 13:01:58.124423 24067 solver.cpp:237] Iteration 14120, loss = 4.4833
I0601 13:01:58.124487 24067 solver.cpp:253]     Train net output #0: loss = 4.51721 (* 1 = 4.51721 loss)
I0601 13:01:58.124496 24067 sgd_solver.cpp:106] Iteration 14120, lr = 0.01
I0601 13:02:03.595944 24067 solver.cpp:237] Iteration 14140, loss = 4.49493
I0601 13:02:03.595990 24067 solver.cpp:253]     Train net output #0: loss = 4.54798 (* 1 = 4.54798 loss)
I0601 13:02:03.595999 24067 sgd_solver.cpp:106] Iteration 14140, lr = 0.01
I0601 13:02:09.065909 24067 solver.cpp:237] Iteration 14160, loss = 4.49974
I0601 13:02:09.065949 24067 solver.cpp:253]     Train net output #0: loss = 4.47307 (* 1 = 4.47307 loss)
I0601 13:02:09.065960 24067 sgd_solver.cpp:106] Iteration 14160, lr = 0.01
I0601 13:02:14.539575 24067 solver.cpp:237] Iteration 14180, loss = 4.53882
I0601 13:02:14.539625 24067 solver.cpp:253]     Train net output #0: loss = 4.54219 (* 1 = 4.54219 loss)
I0601 13:02:14.539636 24067 sgd_solver.cpp:106] Iteration 14180, lr = 0.01
I0601 13:02:20.007766 24067 solver.cpp:237] Iteration 14200, loss = 4.49023
I0601 13:02:20.007812 24067 solver.cpp:253]     Train net output #0: loss = 4.73181 (* 1 = 4.73181 loss)
I0601 13:02:20.007822 24067 sgd_solver.cpp:106] Iteration 14200, lr = 0.01
I0601 13:02:25.480418 24067 solver.cpp:237] Iteration 14220, loss = 4.48288
I0601 13:02:25.480635 24067 solver.cpp:253]     Train net output #0: loss = 4.5017 (* 1 = 4.5017 loss)
I0601 13:02:25.480659 24067 sgd_solver.cpp:106] Iteration 14220, lr = 0.01
I0601 13:02:30.959750 24067 solver.cpp:237] Iteration 14240, loss = 4.43634
I0601 13:02:30.959805 24067 solver.cpp:253]     Train net output #0: loss = 4.49483 (* 1 = 4.49483 loss)
I0601 13:02:30.959816 24067 sgd_solver.cpp:106] Iteration 14240, lr = 0.01
I0601 13:02:36.437531 24067 solver.cpp:237] Iteration 14260, loss = 4.50019
I0601 13:02:36.437579 24067 solver.cpp:253]     Train net output #0: loss = 4.46506 (* 1 = 4.46506 loss)
I0601 13:02:36.437587 24067 sgd_solver.cpp:106] Iteration 14260, lr = 0.01
I0601 13:02:41.913568 24067 solver.cpp:237] Iteration 14280, loss = 4.39856
I0601 13:02:41.913616 24067 solver.cpp:253]     Train net output #0: loss = 4.20028 (* 1 = 4.20028 loss)
I0601 13:02:41.913626 24067 sgd_solver.cpp:106] Iteration 14280, lr = 0.01
I0601 13:02:47.389767 24067 solver.cpp:237] Iteration 14300, loss = 4.46593
I0601 13:02:47.389816 24067 solver.cpp:253]     Train net output #0: loss = 4.71934 (* 1 = 4.71934 loss)
I0601 13:02:47.389824 24067 sgd_solver.cpp:106] Iteration 14300, lr = 0.01
I0601 13:02:52.864148 24067 solver.cpp:237] Iteration 14320, loss = 4.49083
I0601 13:02:52.864198 24067 solver.cpp:253]     Train net output #0: loss = 4.50485 (* 1 = 4.50485 loss)
I0601 13:02:52.864207 24067 sgd_solver.cpp:106] Iteration 14320, lr = 0.01
I0601 13:02:58.344640 24067 solver.cpp:237] Iteration 14340, loss = 4.44001
I0601 13:02:58.344882 24067 solver.cpp:253]     Train net output #0: loss = 4.38238 (* 1 = 4.38238 loss)
I0601 13:02:58.344903 24067 sgd_solver.cpp:106] Iteration 14340, lr = 0.01
I0601 13:03:03.827306 24067 solver.cpp:237] Iteration 14360, loss = 4.47286
I0601 13:03:03.827347 24067 solver.cpp:253]     Train net output #0: loss = 4.55076 (* 1 = 4.55076 loss)
I0601 13:03:03.827353 24067 sgd_solver.cpp:106] Iteration 14360, lr = 0.01
I0601 13:03:09.314785 24067 solver.cpp:237] Iteration 14380, loss = 4.41742
I0601 13:03:09.314828 24067 solver.cpp:253]     Train net output #0: loss = 4.29952 (* 1 = 4.29952 loss)
I0601 13:03:09.314836 24067 sgd_solver.cpp:106] Iteration 14380, lr = 0.01
I0601 13:03:14.796847 24067 solver.cpp:237] Iteration 14400, loss = 4.49176
I0601 13:03:14.796886 24067 solver.cpp:253]     Train net output #0: loss = 4.62438 (* 1 = 4.62438 loss)
I0601 13:03:14.796892 24067 sgd_solver.cpp:106] Iteration 14400, lr = 0.01
I0601 13:03:20.271600 24067 solver.cpp:237] Iteration 14420, loss = 4.42116
I0601 13:03:20.271646 24067 solver.cpp:253]     Train net output #0: loss = 4.48449 (* 1 = 4.48449 loss)
I0601 13:03:20.271651 24067 sgd_solver.cpp:106] Iteration 14420, lr = 0.01
I0601 13:03:25.729957 24067 solver.cpp:237] Iteration 14440, loss = 4.47918
I0601 13:03:25.730002 24067 solver.cpp:253]     Train net output #0: loss = 4.31287 (* 1 = 4.31287 loss)
I0601 13:03:25.730008 24067 sgd_solver.cpp:106] Iteration 14440, lr = 0.01
I0601 13:03:31.202100 24067 solver.cpp:237] Iteration 14460, loss = 4.47415
I0601 13:03:31.202314 24067 solver.cpp:253]     Train net output #0: loss = 4.33506 (* 1 = 4.33506 loss)
I0601 13:03:31.202342 24067 sgd_solver.cpp:106] Iteration 14460, lr = 0.01
I0601 13:03:36.700248 24067 solver.cpp:237] Iteration 14480, loss = 4.53587
I0601 13:03:36.700304 24067 solver.cpp:253]     Train net output #0: loss = 4.54341 (* 1 = 4.54341 loss)
I0601 13:03:36.700314 24067 sgd_solver.cpp:106] Iteration 14480, lr = 0.01
I0601 13:03:42.186864 24067 solver.cpp:237] Iteration 14500, loss = 4.50991
I0601 13:03:42.186919 24067 solver.cpp:253]     Train net output #0: loss = 4.73591 (* 1 = 4.73591 loss)
I0601 13:03:42.186928 24067 sgd_solver.cpp:106] Iteration 14500, lr = 0.01
I0601 13:03:47.675276 24067 solver.cpp:237] Iteration 14520, loss = 4.51542
I0601 13:03:47.675326 24067 solver.cpp:253]     Train net output #0: loss = 4.50186 (* 1 = 4.50186 loss)
I0601 13:03:47.675336 24067 sgd_solver.cpp:106] Iteration 14520, lr = 0.01
I0601 13:03:53.163349 24067 solver.cpp:237] Iteration 14540, loss = 4.49331
I0601 13:03:53.163398 24067 solver.cpp:253]     Train net output #0: loss = 4.43704 (* 1 = 4.43704 loss)
I0601 13:03:53.163408 24067 sgd_solver.cpp:106] Iteration 14540, lr = 0.01
I0601 13:03:58.653275 24067 solver.cpp:237] Iteration 14560, loss = 4.42798
I0601 13:03:58.653321 24067 solver.cpp:253]     Train net output #0: loss = 4.6063 (* 1 = 4.6063 loss)
I0601 13:03:58.653328 24067 sgd_solver.cpp:106] Iteration 14560, lr = 0.01
I0601 13:04:04.133443 24067 solver.cpp:237] Iteration 14580, loss = 4.54182
I0601 13:04:04.133656 24067 solver.cpp:253]     Train net output #0: loss = 4.31625 (* 1 = 4.31625 loss)
I0601 13:04:04.133687 24067 sgd_solver.cpp:106] Iteration 14580, lr = 0.01
I0601 13:04:09.567518 24067 solver.cpp:237] Iteration 14600, loss = 4.47058
I0601 13:04:09.567565 24067 solver.cpp:253]     Train net output #0: loss = 4.56991 (* 1 = 4.56991 loss)
I0601 13:04:09.567574 24067 sgd_solver.cpp:106] Iteration 14600, lr = 0.01
I0601 13:04:15.019467 24067 solver.cpp:237] Iteration 14620, loss = 4.42945
I0601 13:04:15.019515 24067 solver.cpp:253]     Train net output #0: loss = 4.54203 (* 1 = 4.54203 loss)
I0601 13:04:15.019525 24067 sgd_solver.cpp:106] Iteration 14620, lr = 0.01
I0601 13:04:20.512640 24067 solver.cpp:237] Iteration 14640, loss = 4.42838
I0601 13:04:20.512679 24067 solver.cpp:253]     Train net output #0: loss = 4.56459 (* 1 = 4.56459 loss)
I0601 13:04:20.512693 24067 sgd_solver.cpp:106] Iteration 14640, lr = 0.01
I0601 13:04:25.999421 24067 solver.cpp:237] Iteration 14660, loss = 4.42148
I0601 13:04:25.999477 24067 solver.cpp:253]     Train net output #0: loss = 4.12262 (* 1 = 4.12262 loss)
I0601 13:04:25.999500 24067 sgd_solver.cpp:106] Iteration 14660, lr = 0.01
I0601 13:04:31.489110 24067 solver.cpp:237] Iteration 14680, loss = 4.43424
I0601 13:04:31.489158 24067 solver.cpp:253]     Train net output #0: loss = 4.23579 (* 1 = 4.23579 loss)
I0601 13:04:31.489167 24067 sgd_solver.cpp:106] Iteration 14680, lr = 0.01
I0601 13:04:36.982167 24067 solver.cpp:237] Iteration 14700, loss = 4.45016
I0601 13:04:36.982399 24067 solver.cpp:253]     Train net output #0: loss = 4.4187 (* 1 = 4.4187 loss)
I0601 13:04:36.982420 24067 sgd_solver.cpp:106] Iteration 14700, lr = 0.01
I0601 13:04:42.416210 24067 solver.cpp:237] Iteration 14720, loss = 4.50901
I0601 13:04:42.416257 24067 solver.cpp:253]     Train net output #0: loss = 4.62896 (* 1 = 4.62896 loss)
I0601 13:04:42.416265 24067 sgd_solver.cpp:106] Iteration 14720, lr = 0.01
I0601 13:04:47.853896 24067 solver.cpp:237] Iteration 14740, loss = 4.50056
I0601 13:04:47.853940 24067 solver.cpp:253]     Train net output #0: loss = 4.4246 (* 1 = 4.4246 loss)
I0601 13:04:47.853946 24067 sgd_solver.cpp:106] Iteration 14740, lr = 0.01
I0601 13:04:53.336089 24067 solver.cpp:237] Iteration 14760, loss = 4.47994
I0601 13:04:53.336122 24067 solver.cpp:253]     Train net output #0: loss = 4.7565 (* 1 = 4.7565 loss)
I0601 13:04:53.336127 24067 sgd_solver.cpp:106] Iteration 14760, lr = 0.01
I0601 13:04:58.821640 24067 solver.cpp:237] Iteration 14780, loss = 4.46497
I0601 13:04:58.821681 24067 solver.cpp:253]     Train net output #0: loss = 4.47538 (* 1 = 4.47538 loss)
I0601 13:04:58.821687 24067 sgd_solver.cpp:106] Iteration 14780, lr = 0.01
I0601 13:05:04.267233 24067 solver.cpp:237] Iteration 14800, loss = 4.51975
I0601 13:05:04.267279 24067 solver.cpp:253]     Train net output #0: loss = 4.40404 (* 1 = 4.40404 loss)
I0601 13:05:04.267285 24067 sgd_solver.cpp:106] Iteration 14800, lr = 0.01
I0601 13:05:09.754276 24067 solver.cpp:237] Iteration 14820, loss = 4.44838
I0601 13:05:09.754511 24067 solver.cpp:253]     Train net output #0: loss = 4.39685 (* 1 = 4.39685 loss)
I0601 13:05:09.754542 24067 sgd_solver.cpp:106] Iteration 14820, lr = 0.01
I0601 13:05:15.243871 24067 solver.cpp:237] Iteration 14840, loss = 4.4782
I0601 13:05:15.243918 24067 solver.cpp:253]     Train net output #0: loss = 4.23719 (* 1 = 4.23719 loss)
I0601 13:05:15.243927 24067 sgd_solver.cpp:106] Iteration 14840, lr = 0.01
I0601 13:05:20.733731 24067 solver.cpp:237] Iteration 14860, loss = 4.46196
I0601 13:05:20.733779 24067 solver.cpp:253]     Train net output #0: loss = 4.57156 (* 1 = 4.57156 loss)
I0601 13:05:20.733788 24067 sgd_solver.cpp:106] Iteration 14860, lr = 0.01
I0601 13:05:26.227097 24067 solver.cpp:237] Iteration 14880, loss = 4.46561
I0601 13:05:26.227145 24067 solver.cpp:253]     Train net output #0: loss = 4.38839 (* 1 = 4.38839 loss)
I0601 13:05:26.227154 24067 sgd_solver.cpp:106] Iteration 14880, lr = 0.01
I0601 13:05:31.714788 24067 solver.cpp:237] Iteration 14900, loss = 4.45838
I0601 13:05:31.714844 24067 solver.cpp:253]     Train net output #0: loss = 4.61901 (* 1 = 4.61901 loss)
I0601 13:05:31.714854 24067 sgd_solver.cpp:106] Iteration 14900, lr = 0.01
I0601 13:05:37.201668 24067 solver.cpp:237] Iteration 14920, loss = 4.55822
I0601 13:05:37.201715 24067 solver.cpp:253]     Train net output #0: loss = 4.48075 (* 1 = 4.48075 loss)
I0601 13:05:37.201726 24067 sgd_solver.cpp:106] Iteration 14920, lr = 0.01
I0601 13:05:42.697438 24067 solver.cpp:237] Iteration 14940, loss = 4.44882
I0601 13:05:42.697688 24067 solver.cpp:253]     Train net output #0: loss = 4.35654 (* 1 = 4.35654 loss)
I0601 13:05:42.697712 24067 sgd_solver.cpp:106] Iteration 14940, lr = 0.01
I0601 13:05:48.157351 24067 solver.cpp:237] Iteration 14960, loss = 4.4666
I0601 13:05:48.157397 24067 solver.cpp:253]     Train net output #0: loss = 4.39888 (* 1 = 4.39888 loss)
I0601 13:05:48.157403 24067 sgd_solver.cpp:106] Iteration 14960, lr = 0.01
I0601 13:05:53.594938 24067 solver.cpp:237] Iteration 14980, loss = 4.48432
I0601 13:05:53.594983 24067 solver.cpp:253]     Train net output #0: loss = 4.41512 (* 1 = 4.41512 loss)
I0601 13:05:53.594988 24067 sgd_solver.cpp:106] Iteration 14980, lr = 0.01
I0601 13:05:58.948396 24067 solver.cpp:341] Iteration 15000, Testing net (#0)
I0601 13:06:28.223073 24067 blocking_queue.cpp:50] Data layer prefetch queue empty
I0601 13:06:31.319332 24067 solver.cpp:409]     Test net output #0: accuracy = 0.17922
I0601 13:06:31.319386 24067 solver.cpp:409]     Test net output #1: loss = 4.24326 (* 1 = 4.24326 loss)
I0601 13:06:31.400460 24067 solver.cpp:237] Iteration 15000, loss = 4.4877
I0601 13:06:31.400503 24067 solver.cpp:253]     Train net output #0: loss = 4.38863 (* 1 = 4.38863 loss)
I0601 13:06:31.400514 24067 sgd_solver.cpp:106] Iteration 15000, lr = 0.01
I0601 13:06:36.850708 24067 solver.cpp:237] Iteration 15020, loss = 4.48253
I0601 13:06:36.850757 24067 solver.cpp:253]     Train net output #0: loss = 4.63052 (* 1 = 4.63052 loss)
I0601 13:06:36.850767 24067 sgd_solver.cpp:106] Iteration 15020, lr = 0.01
I0601 13:06:42.305248 24067 solver.cpp:237] Iteration 15040, loss = 4.44729
I0601 13:06:42.305299 24067 solver.cpp:253]     Train net output #0: loss = 4.19077 (* 1 = 4.19077 loss)
I0601 13:06:42.305308 24067 sgd_solver.cpp:106] Iteration 15040, lr = 0.01
I0601 13:06:47.769698 24067 solver.cpp:237] Iteration 15060, loss = 4.51347
I0601 13:06:47.769755 24067 solver.cpp:253]     Train net output #0: loss = 4.41929 (* 1 = 4.41929 loss)
I0601 13:06:47.769765 24067 sgd_solver.cpp:106] Iteration 15060, lr = 0.01
I0601 13:06:53.231317 24067 solver.cpp:237] Iteration 15080, loss = 4.51983
I0601 13:06:53.231379 24067 solver.cpp:253]     Train net output #0: loss = 4.37659 (* 1 = 4.37659 loss)
I0601 13:06:53.231389 24067 sgd_solver.cpp:106] Iteration 15080, lr = 0.01
I0601 13:06:58.696009 24067 solver.cpp:237] Iteration 15100, loss = 4.47052
I0601 13:06:58.696198 24067 solver.cpp:253]     Train net output #0: loss = 4.46426 (* 1 = 4.46426 loss)
I0601 13:06:58.696209 24067 sgd_solver.cpp:106] Iteration 15100, lr = 0.01
I0601 13:07:04.163213 24067 solver.cpp:237] Iteration 15120, loss = 4.48633
I0601 13:07:04.163260 24067 solver.cpp:253]     Train net output #0: loss = 4.5223 (* 1 = 4.5223 loss)
I0601 13:07:04.163269 24067 sgd_solver.cpp:106] Iteration 15120, lr = 0.01
I0601 13:07:09.634300 24067 solver.cpp:237] Iteration 15140, loss = 4.48839
I0601 13:07:09.634344 24067 solver.cpp:253]     Train net output #0: loss = 4.2147 (* 1 = 4.2147 loss)
I0601 13:07:09.634353 24067 sgd_solver.cpp:106] Iteration 15140, lr = 0.01
I0601 13:07:15.106675 24067 solver.cpp:237] Iteration 15160, loss = 4.42984
I0601 13:07:15.106724 24067 solver.cpp:253]     Train net output #0: loss = 4.47962 (* 1 = 4.47962 loss)
I0601 13:07:15.106734 24067 sgd_solver.cpp:106] Iteration 15160, lr = 0.01
I0601 13:07:20.581954 24067 solver.cpp:237] Iteration 15180, loss = 4.47699
I0601 13:07:20.582006 24067 solver.cpp:253]     Train net output #0: loss = 4.36592 (* 1 = 4.36592 loss)
I0601 13:07:20.582016 24067 sgd_solver.cpp:106] Iteration 15180, lr = 0.01
I0601 13:07:26.052870 24067 solver.cpp:237] Iteration 15200, loss = 4.40551
I0601 13:07:26.052933 24067 solver.cpp:253]     Train net output #0: loss = 4.27832 (* 1 = 4.27832 loss)
I0601 13:07:26.052943 24067 sgd_solver.cpp:106] Iteration 15200, lr = 0.01
I0601 13:07:31.529067 24067 solver.cpp:237] Iteration 15220, loss = 4.4767
I0601 13:07:31.529281 24067 solver.cpp:253]     Train net output #0: loss = 4.457 (* 1 = 4.457 loss)
I0601 13:07:31.529309 24067 sgd_solver.cpp:106] Iteration 15220, lr = 0.01
I0601 13:07:37.005378 24067 solver.cpp:237] Iteration 15240, loss = 4.44454
I0601 13:07:37.005427 24067 solver.cpp:253]     Train net output #0: loss = 4.18687 (* 1 = 4.18687 loss)
I0601 13:07:37.005439 24067 sgd_solver.cpp:106] Iteration 15240, lr = 0.01
I0601 13:07:42.482123 24067 solver.cpp:237] Iteration 15260, loss = 4.42713
I0601 13:07:42.482172 24067 solver.cpp:253]     Train net output #0: loss = 4.617 (* 1 = 4.617 loss)
I0601 13:07:42.482177 24067 sgd_solver.cpp:106] Iteration 15260, lr = 0.01
I0601 13:07:47.913533 24067 solver.cpp:237] Iteration 15280, loss = 4.39936
I0601 13:07:47.913583 24067 solver.cpp:253]     Train net output #0: loss = 4.04878 (* 1 = 4.04878 loss)
I0601 13:07:47.913589 24067 sgd_solver.cpp:106] Iteration 15280, lr = 0.01
I0601 13:07:53.339187 24067 solver.cpp:237] Iteration 15300, loss = 4.43603
I0601 13:07:53.339238 24067 solver.cpp:253]     Train net output #0: loss = 4.23557 (* 1 = 4.23557 loss)
I0601 13:07:53.339246 24067 sgd_solver.cpp:106] Iteration 15300, lr = 0.01
I0601 13:07:58.769879 24067 solver.cpp:237] Iteration 15320, loss = 4.42182
I0601 13:07:58.769924 24067 solver.cpp:253]     Train net output #0: loss = 4.69061 (* 1 = 4.69061 loss)
I0601 13:07:58.769932 24067 sgd_solver.cpp:106] Iteration 15320, lr = 0.01
I0601 13:08:04.201983 24067 solver.cpp:237] Iteration 15340, loss = 4.47766
I0601 13:08:04.202229 24067 solver.cpp:253]     Train net output #0: loss = 4.52629 (* 1 = 4.52629 loss)
I0601 13:08:04.202237 24067 sgd_solver.cpp:106] Iteration 15340, lr = 0.01
I0601 13:08:09.643342 24067 solver.cpp:237] Iteration 15360, loss = 4.50855
I0601 13:08:09.643391 24067 solver.cpp:253]     Train net output #0: loss = 4.41667 (* 1 = 4.41667 loss)
I0601 13:08:09.643399 24067 sgd_solver.cpp:106] Iteration 15360, lr = 0.01
I0601 13:08:15.102056 24067 solver.cpp:237] Iteration 15380, loss = 4.41826
I0601 13:08:15.102102 24067 solver.cpp:253]     Train net output #0: loss = 4.45329 (* 1 = 4.45329 loss)
I0601 13:08:15.102109 24067 sgd_solver.cpp:106] Iteration 15380, lr = 0.01
I0601 13:08:20.564673 24067 solver.cpp:237] Iteration 15400, loss = 4.50181
I0601 13:08:20.564734 24067 solver.cpp:253]     Train net output #0: loss = 4.57483 (* 1 = 4.57483 loss)
I0601 13:08:20.564743 24067 sgd_solver.cpp:106] Iteration 15400, lr = 0.01
I0601 13:08:26.000885 24067 solver.cpp:237] Iteration 15420, loss = 4.41411
I0601 13:08:26.000926 24067 solver.cpp:253]     Train net output #0: loss = 4.54891 (* 1 = 4.54891 loss)
I0601 13:08:26.000932 24067 sgd_solver.cpp:106] Iteration 15420, lr = 0.01
I0601 13:08:31.433070 24067 solver.cpp:237] Iteration 15440, loss = 4.41741
I0601 13:08:31.433111 24067 solver.cpp:253]     Train net output #0: loss = 4.5183 (* 1 = 4.5183 loss)
I0601 13:08:31.433117 24067 sgd_solver.cpp:106] Iteration 15440, lr = 0.01
I0601 13:08:36.869182 24067 solver.cpp:237] Iteration 15460, loss = 4.431
I0601 13:08:36.869401 24067 solver.cpp:253]     Train net output #0: loss = 4.41003 (* 1 = 4.41003 loss)
I0601 13:08:36.869432 24067 sgd_solver.cpp:106] Iteration 15460, lr = 0.01
I0601 13:08:42.304425 24067 solver.cpp:237] Iteration 15480, loss = 4.43214
I0601 13:08:42.304476 24067 solver.cpp:253]     Train net output #0: loss = 4.54472 (* 1 = 4.54472 loss)
I0601 13:08:42.304484 24067 sgd_solver.cpp:106] Iteration 15480, lr = 0.01
I0601 13:08:47.741323 24067 solver.cpp:237] Iteration 15500, loss = 4.52399
I0601 13:08:47.741374 24067 solver.cpp:253]     Train net output #0: loss = 4.56719 (* 1 = 4.56719 loss)
I0601 13:08:47.741384 24067 sgd_solver.cpp:106] Iteration 15500, lr = 0.01
I0601 13:08:53.178007 24067 solver.cpp:237] Iteration 15520, loss = 4.41919
I0601 13:08:53.178068 24067 solver.cpp:253]     Train net output #0: loss = 4.40251 (* 1 = 4.40251 loss)
I0601 13:08:53.178076 24067 sgd_solver.cpp:106] Iteration 15520, lr = 0.01
I0601 13:08:58.612496 24067 solver.cpp:237] Iteration 15540, loss = 4.45127
I0601 13:08:58.612545 24067 solver.cpp:253]     Train net output #0: loss = 4.44941 (* 1 = 4.44941 loss)
I0601 13:08:58.612553 24067 sgd_solver.cpp:106] Iteration 15540, lr = 0.01
I0601 13:09:04.052012 24067 solver.cpp:237] Iteration 15560, loss = 4.45898
I0601 13:09:04.052060 24067 solver.cpp:253]     Train net output #0: loss = 4.40133 (* 1 = 4.40133 loss)
I0601 13:09:04.052069 24067 sgd_solver.cpp:106] Iteration 15560, lr = 0.01
I0601 13:09:09.491952 24067 solver.cpp:237] Iteration 15580, loss = 4.4538
I0601 13:09:09.492180 24067 solver.cpp:253]     Train net output #0: loss = 4.17428 (* 1 = 4.17428 loss)
I0601 13:09:09.492202 24067 sgd_solver.cpp:106] Iteration 15580, lr = 0.01
I0601 13:09:14.922734 24067 solver.cpp:237] Iteration 15600, loss = 4.45209
I0601 13:09:14.922778 24067 solver.cpp:253]     Train net output #0: loss = 4.28474 (* 1 = 4.28474 loss)
I0601 13:09:14.922783 24067 sgd_solver.cpp:106] Iteration 15600, lr = 0.01
I0601 13:09:20.384029 24067 solver.cpp:237] Iteration 15620, loss = 4.42021
I0601 13:09:20.384065 24067 solver.cpp:253]     Train net output #0: loss = 4.31132 (* 1 = 4.31132 loss)
I0601 13:09:20.384070 24067 sgd_solver.cpp:106] Iteration 15620, lr = 0.01
I0601 13:09:25.867913 24067 solver.cpp:237] Iteration 15640, loss = 4.42105
I0601 13:09:25.867960 24067 solver.cpp:253]     Train net output #0: loss = 4.19841 (* 1 = 4.19841 loss)
I0601 13:09:25.867967 24067 sgd_solver.cpp:106] Iteration 15640, lr = 0.01
I0601 13:09:31.299708 24067 solver.cpp:237] Iteration 15660, loss = 4.40112
I0601 13:09:31.299756 24067 solver.cpp:253]     Train net output #0: loss = 3.9208 (* 1 = 3.9208 loss)
I0601 13:09:31.299762 24067 sgd_solver.cpp:106] Iteration 15660, lr = 0.01
I0601 13:09:36.738080 24067 solver.cpp:237] Iteration 15680, loss = 4.42729
I0601 13:09:36.738126 24067 solver.cpp:253]     Train net output #0: loss = 4.5359 (* 1 = 4.5359 loss)
I0601 13:09:36.738132 24067 sgd_solver.cpp:106] Iteration 15680, lr = 0.01
I0601 13:09:42.190477 24067 solver.cpp:237] Iteration 15700, loss = 4.38744
I0601 13:09:42.190649 24067 solver.cpp:253]     Train net output #0: loss = 4.62886 (* 1 = 4.62886 loss)
I0601 13:09:42.190656 24067 sgd_solver.cpp:106] Iteration 15700, lr = 0.01
I0601 13:09:47.676749 24067 solver.cpp:237] Iteration 15720, loss = 4.39078
I0601 13:09:47.676795 24067 solver.cpp:253]     Train net output #0: loss = 4.29301 (* 1 = 4.29301 loss)
I0601 13:09:47.676802 24067 sgd_solver.cpp:106] Iteration 15720, lr = 0.01
I0601 13:09:53.154474 24067 solver.cpp:237] Iteration 15740, loss = 4.43355
I0601 13:09:53.154520 24067 solver.cpp:253]     Train net output #0: loss = 4.27509 (* 1 = 4.27509 loss)
I0601 13:09:53.154526 24067 sgd_solver.cpp:106] Iteration 15740, lr = 0.01
I0601 13:09:58.637293 24067 solver.cpp:237] Iteration 15760, loss = 4.36151
I0601 13:09:58.637346 24067 solver.cpp:253]     Train net output #0: loss = 4.65943 (* 1 = 4.65943 loss)
I0601 13:09:58.637354 24067 sgd_solver.cpp:106] Iteration 15760, lr = 0.01
I0601 13:10:04.129323 24067 solver.cpp:237] Iteration 15780, loss = 4.42495
I0601 13:10:04.129364 24067 solver.cpp:253]     Train net output #0: loss = 4.46898 (* 1 = 4.46898 loss)
I0601 13:10:04.129382 24067 sgd_solver.cpp:106] Iteration 15780, lr = 0.01
I0601 13:10:09.588418 24067 solver.cpp:237] Iteration 15800, loss = 4.43679
I0601 13:10:09.588464 24067 solver.cpp:253]     Train net output #0: loss = 4.35244 (* 1 = 4.35244 loss)
I0601 13:10:09.588471 24067 sgd_solver.cpp:106] Iteration 15800, lr = 0.01
I0601 13:10:15.043004 24067 solver.cpp:237] Iteration 15820, loss = 4.44175
I0601 13:10:15.043256 24067 solver.cpp:253]     Train net output #0: loss = 4.17878 (* 1 = 4.17878 loss)
I0601 13:10:15.043277 24067 sgd_solver.cpp:106] Iteration 15820, lr = 0.01
I0601 13:10:20.535421 24067 solver.cpp:237] Iteration 15840, loss = 4.41773
I0601 13:10:20.535468 24067 solver.cpp:253]     Train net output #0: loss = 4.38708 (* 1 = 4.38708 loss)
I0601 13:10:20.535477 24067 sgd_solver.cpp:106] Iteration 15840, lr = 0.01
I0601 13:10:26.030709 24067 solver.cpp:237] Iteration 15860, loss = 4.38397
I0601 13:10:26.030760 24067 solver.cpp:253]     Train net output #0: loss = 4.62214 (* 1 = 4.62214 loss)
I0601 13:10:26.030768 24067 sgd_solver.cpp:106] Iteration 15860, lr = 0.01
I0601 13:10:31.527045 24067 solver.cpp:237] Iteration 15880, loss = 4.46337
I0601 13:10:31.527094 24067 solver.cpp:253]     Train net output #0: loss = 4.40408 (* 1 = 4.40408 loss)
I0601 13:10:31.527104 24067 sgd_solver.cpp:106] Iteration 15880, lr = 0.01
I0601 13:10:37.023771 24067 solver.cpp:237] Iteration 15900, loss = 4.44908
I0601 13:10:37.023818 24067 solver.cpp:253]     Train net output #0: loss = 4.36301 (* 1 = 4.36301 loss)
I0601 13:10:37.023828 24067 sgd_solver.cpp:106] Iteration 15900, lr = 0.01
I0601 13:10:42.517660 24067 solver.cpp:237] Iteration 15920, loss = 4.44064
I0601 13:10:42.517724 24067 solver.cpp:253]     Train net output #0: loss = 4.38384 (* 1 = 4.38384 loss)
I0601 13:10:42.517740 24067 sgd_solver.cpp:106] Iteration 15920, lr = 0.01
I0601 13:10:48.011098 24067 solver.cpp:237] Iteration 15940, loss = 4.40534
I0601 13:10:48.011332 24067 solver.cpp:253]     Train net output #0: loss = 4.20807 (* 1 = 4.20807 loss)
I0601 13:10:48.011355 24067 sgd_solver.cpp:106] Iteration 15940, lr = 0.01
I0601 13:10:53.449057 24067 solver.cpp:237] Iteration 15960, loss = 4.46129
I0601 13:10:53.449101 24067 solver.cpp:253]     Train net output #0: loss = 4.71057 (* 1 = 4.71057 loss)
I0601 13:10:53.449120 24067 sgd_solver.cpp:106] Iteration 15960, lr = 0.01
I0601 13:10:58.925231 24067 solver.cpp:237] Iteration 15980, loss = 4.43867
I0601 13:10:58.925279 24067 solver.cpp:253]     Train net output #0: loss = 4.04818 (* 1 = 4.04818 loss)
I0601 13:10:58.925287 24067 sgd_solver.cpp:106] Iteration 15980, lr = 0.01
I0601 13:11:04.330204 24067 solver.cpp:341] Iteration 16000, Testing net (#0)
I0601 13:11:32.976747 24067 blocking_queue.cpp:50] Data layer prefetch queue empty
I0601 13:11:35.783108 24067 solver.cpp:409]     Test net output #0: accuracy = 0.18284
I0601 13:11:35.783164 24067 solver.cpp:409]     Test net output #1: loss = 4.2246 (* 1 = 4.2246 loss)
I0601 13:11:35.862368 24067 solver.cpp:237] Iteration 16000, loss = 4.38147
I0601 13:11:35.862409 24067 solver.cpp:253]     Train net output #0: loss = 4.2395 (* 1 = 4.2395 loss)
I0601 13:11:35.862421 24067 sgd_solver.cpp:106] Iteration 16000, lr = 0.01
I0601 13:11:41.318892 24067 solver.cpp:237] Iteration 16020, loss = 4.39227
I0601 13:11:41.318940 24067 solver.cpp:253]     Train net output #0: loss = 4.16783 (* 1 = 4.16783 loss)
I0601 13:11:41.318950 24067 sgd_solver.cpp:106] Iteration 16020, lr = 0.01
I0601 13:11:46.778103 24067 solver.cpp:237] Iteration 16040, loss = 4.36105
I0601 13:11:46.778156 24067 solver.cpp:253]     Train net output #0: loss = 4.41305 (* 1 = 4.41305 loss)
I0601 13:11:46.778163 24067 sgd_solver.cpp:106] Iteration 16040, lr = 0.01
I0601 13:11:52.236644 24067 solver.cpp:237] Iteration 16060, loss = 4.41909
I0601 13:11:52.236693 24067 solver.cpp:253]     Train net output #0: loss = 4.1925 (* 1 = 4.1925 loss)
I0601 13:11:52.236716 24067 sgd_solver.cpp:106] Iteration 16060, lr = 0.01
I0601 13:11:57.697783 24067 solver.cpp:237] Iteration 16080, loss = 4.36091
I0601 13:11:57.697840 24067 solver.cpp:253]     Train net output #0: loss = 4.61345 (* 1 = 4.61345 loss)
I0601 13:11:57.697849 24067 sgd_solver.cpp:106] Iteration 16080, lr = 0.01
I0601 13:12:03.162322 24067 solver.cpp:237] Iteration 16100, loss = 4.3855
I0601 13:12:03.162533 24067 solver.cpp:253]     Train net output #0: loss = 4.23357 (* 1 = 4.23357 loss)
I0601 13:12:03.162551 24067 sgd_solver.cpp:106] Iteration 16100, lr = 0.01
I0601 13:12:08.629465 24067 solver.cpp:237] Iteration 16120, loss = 4.38945
I0601 13:12:08.629516 24067 solver.cpp:253]     Train net output #0: loss = 4.33507 (* 1 = 4.33507 loss)
I0601 13:12:08.629524 24067 sgd_solver.cpp:106] Iteration 16120, lr = 0.01
I0601 13:12:14.097512 24067 solver.cpp:237] Iteration 16140, loss = 4.43453
I0601 13:12:14.097558 24067 solver.cpp:253]     Train net output #0: loss = 4.30592 (* 1 = 4.30592 loss)
I0601 13:12:14.097566 24067 sgd_solver.cpp:106] Iteration 16140, lr = 0.01
I0601 13:12:19.567749 24067 solver.cpp:237] Iteration 16160, loss = 4.38771
I0601 13:12:19.567795 24067 solver.cpp:253]     Train net output #0: loss = 4.46392 (* 1 = 4.46392 loss)
I0601 13:12:19.567802 24067 sgd_solver.cpp:106] Iteration 16160, lr = 0.01
I0601 13:12:25.037264 24067 solver.cpp:237] Iteration 16180, loss = 4.44493
I0601 13:12:25.037312 24067 solver.cpp:253]     Train net output #0: loss = 4.42575 (* 1 = 4.42575 loss)
I0601 13:12:25.037320 24067 sgd_solver.cpp:106] Iteration 16180, lr = 0.01
I0601 13:12:30.508819 24067 solver.cpp:237] Iteration 16200, loss = 4.38359
I0601 13:12:30.508852 24067 solver.cpp:253]     Train net output #0: loss = 4.03824 (* 1 = 4.03824 loss)
I0601 13:12:30.508859 24067 sgd_solver.cpp:106] Iteration 16200, lr = 0.01
I0601 13:12:35.981720 24067 solver.cpp:237] Iteration 16220, loss = 4.40439
I0601 13:12:35.981937 24067 solver.cpp:253]     Train net output #0: loss = 4.33099 (* 1 = 4.33099 loss)
I0601 13:12:35.981959 24067 sgd_solver.cpp:106] Iteration 16220, lr = 0.01
I0601 13:12:41.464330 24067 solver.cpp:237] Iteration 16240, loss = 4.39319
I0601 13:12:41.464401 24067 solver.cpp:253]     Train net output #0: loss = 4.29378 (* 1 = 4.29378 loss)
I0601 13:12:41.464411 24067 sgd_solver.cpp:106] Iteration 16240, lr = 0.01
I0601 13:12:46.944180 24067 solver.cpp:237] Iteration 16260, loss = 4.49085
I0601 13:12:46.944231 24067 solver.cpp:253]     Train net output #0: loss = 4.46517 (* 1 = 4.46517 loss)
I0601 13:12:46.944239 24067 sgd_solver.cpp:106] Iteration 16260, lr = 0.01
I0601 13:12:52.423259 24067 solver.cpp:237] Iteration 16280, loss = 4.43219
I0601 13:12:52.423321 24067 solver.cpp:253]     Train net output #0: loss = 4.42267 (* 1 = 4.42267 loss)
I0601 13:12:52.423331 24067 sgd_solver.cpp:106] Iteration 16280, lr = 0.01
I0601 13:12:57.903553 24067 solver.cpp:237] Iteration 16300, loss = 4.3776
I0601 13:12:57.903597 24067 solver.cpp:253]     Train net output #0: loss = 4.18008 (* 1 = 4.18008 loss)
I0601 13:12:57.903605 24067 sgd_solver.cpp:106] Iteration 16300, lr = 0.01
I0601 13:13:03.330838 24067 solver.cpp:237] Iteration 16320, loss = 4.46538
I0601 13:13:03.330873 24067 solver.cpp:253]     Train net output #0: loss = 4.24818 (* 1 = 4.24818 loss)
I0601 13:13:03.330879 24067 sgd_solver.cpp:106] Iteration 16320, lr = 0.01
I0601 13:13:08.763723 24067 solver.cpp:237] Iteration 16340, loss = 4.41718
I0601 13:13:08.763909 24067 solver.cpp:253]     Train net output #0: loss = 4.25973 (* 1 = 4.25973 loss)
I0601 13:13:08.763921 24067 sgd_solver.cpp:106] Iteration 16340, lr = 0.01
I0601 13:13:14.213201 24067 solver.cpp:237] Iteration 16360, loss = 4.4022
I0601 13:13:14.213244 24067 solver.cpp:253]     Train net output #0: loss = 4.61221 (* 1 = 4.61221 loss)
I0601 13:13:14.213253 24067 sgd_solver.cpp:106] Iteration 16360, lr = 0.01
I0601 13:13:19.661645 24067 solver.cpp:237] Iteration 16380, loss = 4.40684
I0601 13:13:19.661694 24067 solver.cpp:253]     Train net output #0: loss = 4.36077 (* 1 = 4.36077 loss)
I0601 13:13:19.661701 24067 sgd_solver.cpp:106] Iteration 16380, lr = 0.01
I0601 13:13:25.122584 24067 solver.cpp:237] Iteration 16400, loss = 4.35908
I0601 13:13:25.122633 24067 solver.cpp:253]     Train net output #0: loss = 4.2706 (* 1 = 4.2706 loss)
I0601 13:13:25.122642 24067 sgd_solver.cpp:106] Iteration 16400, lr = 0.01
I0601 13:13:30.605756 24067 solver.cpp:237] Iteration 16420, loss = 4.38432
I0601 13:13:30.605808 24067 solver.cpp:253]     Train net output #0: loss = 4.63303 (* 1 = 4.63303 loss)
I0601 13:13:30.605818 24067 sgd_solver.cpp:106] Iteration 16420, lr = 0.01
I0601 13:13:36.090890 24067 solver.cpp:237] Iteration 16440, loss = 4.443
I0601 13:13:36.090934 24067 solver.cpp:253]     Train net output #0: loss = 4.32611 (* 1 = 4.32611 loss)
I0601 13:13:36.090944 24067 sgd_solver.cpp:106] Iteration 16440, lr = 0.01
I0601 13:13:41.575351 24067 solver.cpp:237] Iteration 16460, loss = 4.43565
I0601 13:13:41.575584 24067 solver.cpp:253]     Train net output #0: loss = 4.54299 (* 1 = 4.54299 loss)
I0601 13:13:41.575609 24067 sgd_solver.cpp:106] Iteration 16460, lr = 0.01
I0601 13:13:47.059967 24067 solver.cpp:237] Iteration 16480, loss = 4.33969
I0601 13:13:47.060019 24067 solver.cpp:253]     Train net output #0: loss = 4.41158 (* 1 = 4.41158 loss)
I0601 13:13:47.060026 24067 sgd_solver.cpp:106] Iteration 16480, lr = 0.01
I0601 13:13:52.536875 24067 solver.cpp:237] Iteration 16500, loss = 4.50463
I0601 13:13:52.536923 24067 solver.cpp:253]     Train net output #0: loss = 4.61376 (* 1 = 4.61376 loss)
I0601 13:13:52.536931 24067 sgd_solver.cpp:106] Iteration 16500, lr = 0.01
I0601 13:13:58.020853 24067 solver.cpp:237] Iteration 16520, loss = 4.46402
I0601 13:13:58.020902 24067 solver.cpp:253]     Train net output #0: loss = 4.4152 (* 1 = 4.4152 loss)
I0601 13:13:58.020910 24067 sgd_solver.cpp:106] Iteration 16520, lr = 0.01
I0601 13:14:03.508267 24067 solver.cpp:237] Iteration 16540, loss = 4.39944
I0601 13:14:03.508311 24067 solver.cpp:253]     Train net output #0: loss = 4.40067 (* 1 = 4.40067 loss)
I0601 13:14:03.508317 24067 sgd_solver.cpp:106] Iteration 16540, lr = 0.01
I0601 13:14:08.997154 24067 solver.cpp:237] Iteration 16560, loss = 4.45991
I0601 13:14:08.997202 24067 solver.cpp:253]     Train net output #0: loss = 4.34763 (* 1 = 4.34763 loss)
I0601 13:14:08.997210 24067 sgd_solver.cpp:106] Iteration 16560, lr = 0.01
I0601 13:14:14.477365 24067 solver.cpp:237] Iteration 16580, loss = 4.42328
I0601 13:14:14.477579 24067 solver.cpp:253]     Train net output #0: loss = 4.63529 (* 1 = 4.63529 loss)
I0601 13:14:14.477596 24067 sgd_solver.cpp:106] Iteration 16580, lr = 0.01
I0601 13:14:19.963850 24067 solver.cpp:237] Iteration 16600, loss = 4.40576
I0601 13:14:19.963894 24067 solver.cpp:253]     Train net output #0: loss = 4.48885 (* 1 = 4.48885 loss)
I0601 13:14:19.963902 24067 sgd_solver.cpp:106] Iteration 16600, lr = 0.01
I0601 13:14:25.417738 24067 solver.cpp:237] Iteration 16620, loss = 4.37999
I0601 13:14:25.417771 24067 solver.cpp:253]     Train net output #0: loss = 4.30153 (* 1 = 4.30153 loss)
I0601 13:14:25.417778 24067 sgd_solver.cpp:106] Iteration 16620, lr = 0.01
I0601 13:14:30.861865 24067 solver.cpp:237] Iteration 16640, loss = 4.40823
I0601 13:14:30.861913 24067 solver.cpp:253]     Train net output #0: loss = 4.36931 (* 1 = 4.36931 loss)
I0601 13:14:30.861920 24067 sgd_solver.cpp:106] Iteration 16640, lr = 0.01
I0601 13:14:36.302276 24067 solver.cpp:237] Iteration 16660, loss = 4.37776
I0601 13:14:36.302321 24067 solver.cpp:253]     Train net output #0: loss = 4.31429 (* 1 = 4.31429 loss)
I0601 13:14:36.302328 24067 sgd_solver.cpp:106] Iteration 16660, lr = 0.01
I0601 13:14:41.741813 24067 solver.cpp:237] Iteration 16680, loss = 4.39967
I0601 13:14:41.741858 24067 solver.cpp:253]     Train net output #0: loss = 4.41072 (* 1 = 4.41072 loss)
I0601 13:14:41.741866 24067 sgd_solver.cpp:106] Iteration 16680, lr = 0.01
I0601 13:14:47.181452 24067 solver.cpp:237] Iteration 16700, loss = 4.39566
I0601 13:14:47.181603 24067 solver.cpp:253]     Train net output #0: loss = 4.15818 (* 1 = 4.15818 loss)
I0601 13:14:47.181613 24067 sgd_solver.cpp:106] Iteration 16700, lr = 0.01
I0601 13:14:52.623685 24067 solver.cpp:237] Iteration 16720, loss = 4.31969
I0601 13:14:52.623731 24067 solver.cpp:253]     Train net output #0: loss = 4.2663 (* 1 = 4.2663 loss)
I0601 13:14:52.623739 24067 sgd_solver.cpp:106] Iteration 16720, lr = 0.01
I0601 13:14:58.063874 24067 solver.cpp:237] Iteration 16740, loss = 4.46501
I0601 13:14:58.063933 24067 solver.cpp:253]     Train net output #0: loss = 4.3271 (* 1 = 4.3271 loss)
I0601 13:14:58.063941 24067 sgd_solver.cpp:106] Iteration 16740, lr = 0.01
I0601 13:15:03.501325 24067 solver.cpp:237] Iteration 16760, loss = 4.37631
I0601 13:15:03.501374 24067 solver.cpp:253]     Train net output #0: loss = 4.39113 (* 1 = 4.39113 loss)
I0601 13:15:03.501381 24067 sgd_solver.cpp:106] Iteration 16760, lr = 0.01
I0601 13:15:08.985344 24067 solver.cpp:237] Iteration 16780, loss = 4.37166
I0601 13:15:08.985378 24067 solver.cpp:253]     Train net output #0: loss = 4.60808 (* 1 = 4.60808 loss)
I0601 13:15:08.985386 24067 sgd_solver.cpp:106] Iteration 16780, lr = 0.01
I0601 13:15:14.469269 24067 solver.cpp:237] Iteration 16800, loss = 4.3734
I0601 13:15:14.469316 24067 solver.cpp:253]     Train net output #0: loss = 4.5426 (* 1 = 4.5426 loss)
I0601 13:15:14.469322 24067 sgd_solver.cpp:106] Iteration 16800, lr = 0.01
I0601 13:15:19.946405 24067 solver.cpp:237] Iteration 16820, loss = 4.35433
I0601 13:15:19.946627 24067 solver.cpp:253]     Train net output #0: loss = 4.33197 (* 1 = 4.33197 loss)
I0601 13:15:19.946646 24067 sgd_solver.cpp:106] Iteration 16820, lr = 0.01
I0601 13:15:25.384366 24067 solver.cpp:237] Iteration 16840, loss = 4.41232
I0601 13:15:25.384438 24067 solver.cpp:253]     Train net output #0: loss = 4.58734 (* 1 = 4.58734 loss)
I0601 13:15:25.384445 24067 sgd_solver.cpp:106] Iteration 16840, lr = 0.01
I0601 13:15:30.819370 24067 solver.cpp:237] Iteration 16860, loss = 4.36952
I0601 13:15:30.819427 24067 solver.cpp:253]     Train net output #0: loss = 4.14906 (* 1 = 4.14906 loss)
I0601 13:15:30.819435 24067 sgd_solver.cpp:106] Iteration 16860, lr = 0.01
I0601 13:15:36.261801 24067 solver.cpp:237] Iteration 16880, loss = 4.35022
I0601 13:15:36.261847 24067 solver.cpp:253]     Train net output #0: loss = 4.45639 (* 1 = 4.45639 loss)
I0601 13:15:36.261854 24067 sgd_solver.cpp:106] Iteration 16880, lr = 0.01
I0601 13:15:41.698616 24067 solver.cpp:237] Iteration 16900, loss = 4.3747
I0601 13:15:41.698662 24067 solver.cpp:253]     Train net output #0: loss = 4.31938 (* 1 = 4.31938 loss)
I0601 13:15:41.698668 24067 sgd_solver.cpp:106] Iteration 16900, lr = 0.01
I0601 13:15:47.166296 24067 solver.cpp:237] Iteration 16920, loss = 4.41057
I0601 13:15:47.166343 24067 solver.cpp:253]     Train net output #0: loss = 4.41086 (* 1 = 4.41086 loss)
I0601 13:15:47.166350 24067 sgd_solver.cpp:106] Iteration 16920, lr = 0.01
I0601 13:15:52.654127 24067 solver.cpp:237] Iteration 16940, loss = 4.36046
I0601 13:15:52.654393 24067 solver.cpp:253]     Train net output #0: loss = 4.39676 (* 1 = 4.39676 loss)
I0601 13:15:52.654415 24067 sgd_solver.cpp:106] Iteration 16940, lr = 0.01
I0601 13:15:58.143344 24067 solver.cpp:237] Iteration 16960, loss = 4.38866
I0601 13:15:58.143399 24067 solver.cpp:253]     Train net output #0: loss = 4.5106 (* 1 = 4.5106 loss)
I0601 13:15:58.143410 24067 sgd_solver.cpp:106] Iteration 16960, lr = 0.01
I0601 13:16:03.606443 24067 solver.cpp:237] Iteration 16980, loss = 4.43355
I0601 13:16:03.606485 24067 solver.cpp:253]     Train net output #0: loss = 4.22347 (* 1 = 4.22347 loss)
I0601 13:16:03.606495 24067 sgd_solver.cpp:106] Iteration 16980, lr = 0.01
I0601 13:16:08.955698 24067 solver.cpp:341] Iteration 17000, Testing net (#0)
I0601 13:16:37.349056 24067 blocking_queue.cpp:50] Data layer prefetch queue empty
I0601 13:16:40.292016 24067 solver.cpp:409]     Test net output #0: accuracy = 0.1793
I0601 13:16:40.292063 24067 solver.cpp:409]     Test net output #1: loss = 4.24249 (* 1 = 4.24249 loss)
I0601 13:16:40.372926 24067 solver.cpp:237] Iteration 17000, loss = 4.35465
I0601 13:16:40.372973 24067 solver.cpp:253]     Train net output #0: loss = 4.39929 (* 1 = 4.39929 loss)
I0601 13:16:40.372985 24067 sgd_solver.cpp:106] Iteration 17000, lr = 0.01
I0601 13:16:45.809553 24067 solver.cpp:237] Iteration 17020, loss = 4.3374
I0601 13:16:45.809613 24067 solver.cpp:253]     Train net output #0: loss = 4.26504 (* 1 = 4.26504 loss)
I0601 13:16:45.809620 24067 sgd_solver.cpp:106] Iteration 17020, lr = 0.01
I0601 13:16:51.234604 24067 solver.cpp:237] Iteration 17040, loss = 4.35864
I0601 13:16:51.234657 24067 solver.cpp:253]     Train net output #0: loss = 4.18626 (* 1 = 4.18626 loss)
I0601 13:16:51.234665 24067 sgd_solver.cpp:106] Iteration 17040, lr = 0.01
I0601 13:16:56.660583 24067 solver.cpp:237] Iteration 17060, loss = 4.42307
I0601 13:16:56.660619 24067 solver.cpp:253]     Train net output #0: loss = 4.60823 (* 1 = 4.60823 loss)
I0601 13:16:56.660626 24067 sgd_solver.cpp:106] Iteration 17060, lr = 0.01
I0601 13:17:02.088654 24067 solver.cpp:237] Iteration 17080, loss = 4.41184
I0601 13:17:02.088703 24067 solver.cpp:253]     Train net output #0: loss = 4.32583 (* 1 = 4.32583 loss)
I0601 13:17:02.088711 24067 sgd_solver.cpp:106] Iteration 17080, lr = 0.01
I0601 13:17:07.524293 24067 solver.cpp:237] Iteration 17100, loss = 4.35345
I0601 13:17:07.524473 24067 solver.cpp:253]     Train net output #0: loss = 4.44142 (* 1 = 4.44142 loss)
I0601 13:17:07.524482 24067 sgd_solver.cpp:106] Iteration 17100, lr = 0.01
I0601 13:17:12.979308 24067 solver.cpp:237] Iteration 17120, loss = 4.42772
I0601 13:17:12.979362 24067 solver.cpp:253]     Train net output #0: loss = 4.3436 (* 1 = 4.3436 loss)
I0601 13:17:12.979370 24067 sgd_solver.cpp:106] Iteration 17120, lr = 0.01
I0601 13:17:18.442891 24067 solver.cpp:237] Iteration 17140, loss = 4.35144
I0601 13:17:18.442945 24067 solver.cpp:253]     Train net output #0: loss = 4.42878 (* 1 = 4.42878 loss)
I0601 13:17:18.442955 24067 sgd_solver.cpp:106] Iteration 17140, lr = 0.01
I0601 13:17:23.912864 24067 solver.cpp:237] Iteration 17160, loss = 4.3229
I0601 13:17:23.912904 24067 solver.cpp:253]     Train net output #0: loss = 4.46342 (* 1 = 4.46342 loss)
I0601 13:17:23.912914 24067 sgd_solver.cpp:106] Iteration 17160, lr = 0.01
I0601 13:17:29.388543 24067 solver.cpp:237] Iteration 17180, loss = 4.35371
I0601 13:17:29.388593 24067 solver.cpp:253]     Train net output #0: loss = 4.38071 (* 1 = 4.38071 loss)
I0601 13:17:29.388602 24067 sgd_solver.cpp:106] Iteration 17180, lr = 0.01
I0601 13:17:34.862975 24067 solver.cpp:237] Iteration 17200, loss = 4.29954
I0601 13:17:34.863015 24067 solver.cpp:253]     Train net output #0: loss = 4.22515 (* 1 = 4.22515 loss)
I0601 13:17:34.863025 24067 sgd_solver.cpp:106] Iteration 17200, lr = 0.01
I0601 13:17:40.335624 24067 solver.cpp:237] Iteration 17220, loss = 4.35293
I0601 13:17:40.335842 24067 solver.cpp:253]     Train net output #0: loss = 4.41772 (* 1 = 4.41772 loss)
I0601 13:17:40.335867 24067 sgd_solver.cpp:106] Iteration 17220, lr = 0.01
I0601 13:17:45.813185 24067 solver.cpp:237] Iteration 17240, loss = 4.40078
I0601 13:17:45.813241 24067 solver.cpp:253]     Train net output #0: loss = 4.40786 (* 1 = 4.40786 loss)
I0601 13:17:45.813253 24067 sgd_solver.cpp:106] Iteration 17240, lr = 0.01
I0601 13:17:51.295475 24067 solver.cpp:237] Iteration 17260, loss = 4.45129
I0601 13:17:51.295524 24067 solver.cpp:253]     Train net output #0: loss = 4.53295 (* 1 = 4.53295 loss)
I0601 13:17:51.295533 24067 sgd_solver.cpp:106] Iteration 17260, lr = 0.01
I0601 13:17:56.781468 24067 solver.cpp:237] Iteration 17280, loss = 4.41978
I0601 13:17:56.781518 24067 solver.cpp:253]     Train net output #0: loss = 4.47941 (* 1 = 4.47941 loss)
I0601 13:17:56.781538 24067 sgd_solver.cpp:106] Iteration 17280, lr = 0.01
I0601 13:18:02.267122 24067 solver.cpp:237] Iteration 17300, loss = 4.3667
I0601 13:18:02.267173 24067 solver.cpp:253]     Train net output #0: loss = 4.34384 (* 1 = 4.34384 loss)
I0601 13:18:02.267181 24067 sgd_solver.cpp:106] Iteration 17300, lr = 0.01
I0601 13:18:07.754528 24067 solver.cpp:237] Iteration 17320, loss = 4.41147
I0601 13:18:07.754575 24067 solver.cpp:253]     Train net output #0: loss = 4.40322 (* 1 = 4.40322 loss)
I0601 13:18:07.754583 24067 sgd_solver.cpp:106] Iteration 17320, lr = 0.01
I0601 13:18:13.241029 24067 solver.cpp:237] Iteration 17340, loss = 4.328
I0601 13:18:13.241278 24067 solver.cpp:253]     Train net output #0: loss = 4.24496 (* 1 = 4.24496 loss)
I0601 13:18:13.241302 24067 sgd_solver.cpp:106] Iteration 17340, lr = 0.01
I0601 13:18:18.717568 24067 solver.cpp:237] Iteration 17360, loss = 4.35611
I0601 13:18:18.717610 24067 solver.cpp:253]     Train net output #0: loss = 4.27496 (* 1 = 4.27496 loss)
I0601 13:18:18.717615 24067 sgd_solver.cpp:106] Iteration 17360, lr = 0.01
I0601 13:18:24.191540 24067 solver.cpp:237] Iteration 17380, loss = 4.45832
I0601 13:18:24.191589 24067 solver.cpp:253]     Train net output #0: loss = 4.29416 (* 1 = 4.29416 loss)
I0601 13:18:24.191597 24067 sgd_solver.cpp:106] Iteration 17380, lr = 0.01
I0601 13:18:29.624203 24067 solver.cpp:237] Iteration 17400, loss = 4.40326
I0601 13:18:29.624248 24067 solver.cpp:253]     Train net output #0: loss = 4.28839 (* 1 = 4.28839 loss)
I0601 13:18:29.624253 24067 sgd_solver.cpp:106] Iteration 17400, lr = 0.01
I0601 13:18:35.058058 24067 solver.cpp:237] Iteration 17420, loss = 4.39555
I0601 13:18:35.058111 24067 solver.cpp:253]     Train net output #0: loss = 4.33702 (* 1 = 4.33702 loss)
I0601 13:18:35.058116 24067 sgd_solver.cpp:106] Iteration 17420, lr = 0.01
I0601 13:18:40.494197 24067 solver.cpp:237] Iteration 17440, loss = 4.32651
I0601 13:18:40.494240 24067 solver.cpp:253]     Train net output #0: loss = 4.29717 (* 1 = 4.29717 loss)
I0601 13:18:40.494246 24067 sgd_solver.cpp:106] Iteration 17440, lr = 0.01
I0601 13:18:45.927810 24067 solver.cpp:237] Iteration 17460, loss = 4.36469
I0601 13:18:45.927980 24067 solver.cpp:253]     Train net output #0: loss = 4.22148 (* 1 = 4.22148 loss)
I0601 13:18:45.928000 24067 sgd_solver.cpp:106] Iteration 17460, lr = 0.01
I0601 13:18:51.367055 24067 solver.cpp:237] Iteration 17480, loss = 4.37885
I0601 13:18:51.367106 24067 solver.cpp:253]     Train net output #0: loss = 4.39025 (* 1 = 4.39025 loss)
I0601 13:18:51.367117 24067 sgd_solver.cpp:106] Iteration 17480, lr = 0.01
I0601 13:18:56.806349 24067 solver.cpp:237] Iteration 17500, loss = 4.38611
I0601 13:18:56.806397 24067 solver.cpp:253]     Train net output #0: loss = 4.2164 (* 1 = 4.2164 loss)
I0601 13:18:56.806407 24067 sgd_solver.cpp:106] Iteration 17500, lr = 0.01
I0601 13:19:02.240150 24067 solver.cpp:237] Iteration 17520, loss = 4.37172
I0601 13:19:02.240195 24067 solver.cpp:253]     Train net output #0: loss = 4.63933 (* 1 = 4.63933 loss)
I0601 13:19:02.240206 24067 sgd_solver.cpp:106] Iteration 17520, lr = 0.01
I0601 13:19:07.672819 24067 solver.cpp:237] Iteration 17540, loss = 4.39312
I0601 13:19:07.672866 24067 solver.cpp:253]     Train net output #0: loss = 4.3711 (* 1 = 4.3711 loss)
I0601 13:19:07.672875 24067 sgd_solver.cpp:106] Iteration 17540, lr = 0.01
I0601 13:19:13.111461 24067 solver.cpp:237] Iteration 17560, loss = 4.37354
I0601 13:19:13.111503 24067 solver.cpp:253]     Train net output #0: loss = 4.55032 (* 1 = 4.55032 loss)
I0601 13:19:13.111511 24067 sgd_solver.cpp:106] Iteration 17560, lr = 0.01
I0601 13:19:18.592399 24067 solver.cpp:237] Iteration 17580, loss = 4.34045
I0601 13:19:18.592639 24067 solver.cpp:253]     Train net output #0: loss = 4.213 (* 1 = 4.213 loss)
I0601 13:19:18.592664 24067 sgd_solver.cpp:106] Iteration 17580, lr = 0.01
I0601 13:19:24.083102 24067 solver.cpp:237] Iteration 17600, loss = 4.35565
I0601 13:19:24.083148 24067 solver.cpp:253]     Train net output #0: loss = 4.3747 (* 1 = 4.3747 loss)
I0601 13:19:24.083156 24067 sgd_solver.cpp:106] Iteration 17600, lr = 0.01
I0601 13:19:29.570889 24067 solver.cpp:237] Iteration 17620, loss = 4.3579
I0601 13:19:29.570940 24067 solver.cpp:253]     Train net output #0: loss = 4.44177 (* 1 = 4.44177 loss)
I0601 13:19:29.570948 24067 sgd_solver.cpp:106] Iteration 17620, lr = 0.01
I0601 13:19:35.054217 24067 solver.cpp:237] Iteration 17640, loss = 4.372
I0601 13:19:35.054267 24067 solver.cpp:253]     Train net output #0: loss = 4.39416 (* 1 = 4.39416 loss)
I0601 13:19:35.054275 24067 sgd_solver.cpp:106] Iteration 17640, lr = 0.01
I0601 13:19:40.538823 24067 solver.cpp:237] Iteration 17660, loss = 4.38131
I0601 13:19:40.538869 24067 solver.cpp:253]     Train net output #0: loss = 4.3528 (* 1 = 4.3528 loss)
I0601 13:19:40.538877 24067 sgd_solver.cpp:106] Iteration 17660, lr = 0.01
I0601 13:19:46.031258 24067 solver.cpp:237] Iteration 17680, loss = 4.4238
I0601 13:19:46.031306 24067 solver.cpp:253]     Train net output #0: loss = 4.4019 (* 1 = 4.4019 loss)
I0601 13:19:46.031312 24067 sgd_solver.cpp:106] Iteration 17680, lr = 0.01
I0601 13:19:51.523409 24067 solver.cpp:237] Iteration 17700, loss = 4.33523
I0601 13:19:51.523766 24067 solver.cpp:253]     Train net output #0: loss = 4.28737 (* 1 = 4.28737 loss)
I0601 13:19:51.523802 24067 sgd_solver.cpp:106] Iteration 17700, lr = 0.01
I0601 13:19:57.008990 24067 solver.cpp:237] Iteration 17720, loss = 4.35522
I0601 13:19:57.009042 24067 solver.cpp:253]     Train net output #0: loss = 4.25335 (* 1 = 4.25335 loss)
I0601 13:19:57.009063 24067 sgd_solver.cpp:106] Iteration 17720, lr = 0.01
I0601 13:20:02.496037 24067 solver.cpp:237] Iteration 17740, loss = 4.33142
I0601 13:20:02.496088 24067 solver.cpp:253]     Train net output #0: loss = 4.07913 (* 1 = 4.07913 loss)
I0601 13:20:02.496098 24067 sgd_solver.cpp:106] Iteration 17740, lr = 0.01
I0601 13:20:07.983582 24067 solver.cpp:237] Iteration 17760, loss = 4.3587
I0601 13:20:07.983634 24067 solver.cpp:253]     Train net output #0: loss = 4.38246 (* 1 = 4.38246 loss)
I0601 13:20:07.983644 24067 sgd_solver.cpp:106] Iteration 17760, lr = 0.01
I0601 13:20:13.472230 24067 solver.cpp:237] Iteration 17780, loss = 4.44229
I0601 13:20:13.472267 24067 solver.cpp:253]     Train net output #0: loss = 4.4705 (* 1 = 4.4705 loss)
I0601 13:20:13.472276 24067 sgd_solver.cpp:106] Iteration 17780, lr = 0.01
I0601 13:20:18.955976 24067 solver.cpp:237] Iteration 17800, loss = 4.44194
I0601 13:20:18.956027 24067 solver.cpp:253]     Train net output #0: loss = 4.46551 (* 1 = 4.46551 loss)
I0601 13:20:18.956037 24067 sgd_solver.cpp:106] Iteration 17800, lr = 0.01
I0601 13:20:24.444982 24067 solver.cpp:237] Iteration 17820, loss = 4.36496
I0601 13:20:24.445222 24067 solver.cpp:253]     Train net output #0: loss = 4.48626 (* 1 = 4.48626 loss)
I0601 13:20:24.445245 24067 sgd_solver.cpp:106] Iteration 17820, lr = 0.01
I0601 13:20:29.935185 24067 solver.cpp:237] Iteration 17840, loss = 4.37541
I0601 13:20:29.935221 24067 solver.cpp:253]     Train net output #0: loss = 4.23724 (* 1 = 4.23724 loss)
I0601 13:20:29.935228 24067 sgd_solver.cpp:106] Iteration 17840, lr = 0.01
I0601 13:20:35.425499 24067 solver.cpp:237] Iteration 17860, loss = 4.35718
I0601 13:20:35.425554 24067 solver.cpp:253]     Train net output #0: loss = 4.53759 (* 1 = 4.53759 loss)
I0601 13:20:35.425562 24067 sgd_solver.cpp:106] Iteration 17860, lr = 0.01
I0601 13:20:40.916482 24067 solver.cpp:237] Iteration 17880, loss = 4.36726
I0601 13:20:40.916537 24067 solver.cpp:253]     Train net output #0: loss = 4.12671 (* 1 = 4.12671 loss)
I0601 13:20:40.916544 24067 sgd_solver.cpp:106] Iteration 17880, lr = 0.01
I0601 13:20:46.404054 24067 solver.cpp:237] Iteration 17900, loss = 4.40311
I0601 13:20:46.404100 24067 solver.cpp:253]     Train net output #0: loss = 4.62174 (* 1 = 4.62174 loss)
I0601 13:20:46.404109 24067 sgd_solver.cpp:106] Iteration 17900, lr = 0.01
I0601 13:20:51.891826 24067 solver.cpp:237] Iteration 17920, loss = 4.41891
I0601 13:20:51.891878 24067 solver.cpp:253]     Train net output #0: loss = 4.50369 (* 1 = 4.50369 loss)
I0601 13:20:51.891887 24067 sgd_solver.cpp:106] Iteration 17920, lr = 0.01
I0601 13:20:57.385260 24067 solver.cpp:237] Iteration 17940, loss = 4.39838
I0601 13:20:57.385478 24067 solver.cpp:253]     Train net output #0: loss = 4.15172 (* 1 = 4.15172 loss)
I0601 13:20:57.385501 24067 sgd_solver.cpp:106] Iteration 17940, lr = 0.01
I0601 13:21:02.872920 24067 solver.cpp:237] Iteration 17960, loss = 4.41798
I0601 13:21:02.872970 24067 solver.cpp:253]     Train net output #0: loss = 4.44267 (* 1 = 4.44267 loss)
I0601 13:21:02.872979 24067 sgd_solver.cpp:106] Iteration 17960, lr = 0.01
I0601 13:21:08.359690 24067 solver.cpp:237] Iteration 17980, loss = 4.44063
I0601 13:21:08.359735 24067 solver.cpp:253]     Train net output #0: loss = 4.3707 (* 1 = 4.3707 loss)
I0601 13:21:08.359745 24067 sgd_solver.cpp:106] Iteration 17980, lr = 0.01
I0601 13:21:13.765432 24067 solver.cpp:341] Iteration 18000, Testing net (#0)
I0601 13:21:44.889073 24067 blocking_queue.cpp:50] Data layer prefetch queue empty
I0601 13:21:47.645392 24067 solver.cpp:409]     Test net output #0: accuracy = 0.19192
I0601 13:21:47.645436 24067 solver.cpp:409]     Test net output #1: loss = 4.16541 (* 1 = 4.16541 loss)
I0601 13:21:47.724499 24067 solver.cpp:237] Iteration 18000, loss = 4.34547
I0601 13:21:47.724546 24067 solver.cpp:253]     Train net output #0: loss = 4.30668 (* 1 = 4.30668 loss)
I0601 13:21:47.724556 24067 sgd_solver.cpp:106] Iteration 18000, lr = 0.01
I0601 13:21:53.172775 24067 solver.cpp:237] Iteration 18020, loss = 4.3416
I0601 13:21:53.172827 24067 solver.cpp:253]     Train net output #0: loss = 4.43909 (* 1 = 4.43909 loss)
I0601 13:21:53.172835 24067 sgd_solver.cpp:106] Iteration 18020, lr = 0.01
I0601 13:21:58.620736 24067 solver.cpp:237] Iteration 18040, loss = 4.32067
I0601 13:21:58.620786 24067 solver.cpp:253]     Train net output #0: loss = 4.41015 (* 1 = 4.41015 loss)
I0601 13:21:58.620795 24067 sgd_solver.cpp:106] Iteration 18040, lr = 0.01
I0601 13:22:04.063841 24067 solver.cpp:237] Iteration 18060, loss = 4.37304
I0601 13:22:04.063889 24067 solver.cpp:253]     Train net output #0: loss = 4.3139 (* 1 = 4.3139 loss)
I0601 13:22:04.063896 24067 sgd_solver.cpp:106] Iteration 18060, lr = 0.01
I0601 13:22:09.517026 24067 solver.cpp:237] Iteration 18080, loss = 4.36735
I0601 13:22:09.517068 24067 solver.cpp:253]     Train net output #0: loss = 4.60763 (* 1 = 4.60763 loss)
I0601 13:22:09.517076 24067 sgd_solver.cpp:106] Iteration 18080, lr = 0.01
I0601 13:22:14.924360 24067 solver.cpp:237] Iteration 18100, loss = 4.3504
I0601 13:22:14.924587 24067 solver.cpp:253]     Train net output #0: loss = 4.44782 (* 1 = 4.44782 loss)
I0601 13:22:14.924608 24067 sgd_solver.cpp:106] Iteration 18100, lr = 0.01
I0601 13:22:20.374305 24067 solver.cpp:237] Iteration 18120, loss = 4.38529
I0601 13:22:20.374364 24067 solver.cpp:253]     Train net output #0: loss = 4.33353 (* 1 = 4.33353 loss)
I0601 13:22:20.374372 24067 sgd_solver.cpp:106] Iteration 18120, lr = 0.01
I0601 13:22:25.821060 24067 solver.cpp:237] Iteration 18140, loss = 4.40378
I0601 13:22:25.821108 24067 solver.cpp:253]     Train net output #0: loss = 4.5962 (* 1 = 4.5962 loss)
I0601 13:22:25.821115 24067 sgd_solver.cpp:106] Iteration 18140, lr = 0.01
I0601 13:22:31.248607 24067 solver.cpp:237] Iteration 18160, loss = 4.39958
I0601 13:22:31.248661 24067 solver.cpp:253]     Train net output #0: loss = 4.48689 (* 1 = 4.48689 loss)
I0601 13:22:31.248668 24067 sgd_solver.cpp:106] Iteration 18160, lr = 0.01
I0601 13:22:36.702687 24067 solver.cpp:237] Iteration 18180, loss = 4.33589
I0601 13:22:36.702740 24067 solver.cpp:253]     Train net output #0: loss = 4.46272 (* 1 = 4.46272 loss)
I0601 13:22:36.702746 24067 sgd_solver.cpp:106] Iteration 18180, lr = 0.01
I0601 13:22:42.157785 24067 solver.cpp:237] Iteration 18200, loss = 4.34009
I0601 13:22:42.157819 24067 solver.cpp:253]     Train net output #0: loss = 4.17825 (* 1 = 4.17825 loss)
I0601 13:22:42.157840 24067 sgd_solver.cpp:106] Iteration 18200, lr = 0.01
I0601 13:22:47.621618 24067 solver.cpp:237] Iteration 18220, loss = 4.31642
I0601 13:22:47.621865 24067 solver.cpp:253]     Train net output #0: loss = 4.58712 (* 1 = 4.58712 loss)
I0601 13:22:47.621888 24067 sgd_solver.cpp:106] Iteration 18220, lr = 0.01
I0601 13:22:53.091675 24067 solver.cpp:237] Iteration 18240, loss = 4.37031
I0601 13:22:53.091711 24067 solver.cpp:253]     Train net output #0: loss = 4.26551 (* 1 = 4.26551 loss)
I0601 13:22:53.091719 24067 sgd_solver.cpp:106] Iteration 18240, lr = 0.01
I0601 13:22:58.571605 24067 solver.cpp:237] Iteration 18260, loss = 4.37601
I0601 13:22:58.571640 24067 solver.cpp:253]     Train net output #0: loss = 4.36474 (* 1 = 4.36474 loss)
I0601 13:22:58.571648 24067 sgd_solver.cpp:106] Iteration 18260, lr = 0.01
I0601 13:23:04.047938 24067 solver.cpp:237] Iteration 18280, loss = 4.34038
I0601 13:23:04.047979 24067 solver.cpp:253]     Train net output #0: loss = 4.45319 (* 1 = 4.45319 loss)
I0601 13:23:04.047986 24067 sgd_solver.cpp:106] Iteration 18280, lr = 0.01
I0601 13:23:09.517065 24067 solver.cpp:237] Iteration 18300, loss = 4.35236
I0601 13:23:09.517118 24067 solver.cpp:253]     Train net output #0: loss = 4.53592 (* 1 = 4.53592 loss)
I0601 13:23:09.517124 24067 sgd_solver.cpp:106] Iteration 18300, lr = 0.01
I0601 13:23:14.979516 24067 solver.cpp:237] Iteration 18320, loss = 4.33814
I0601 13:23:14.979558 24067 solver.cpp:253]     Train net output #0: loss = 4.17293 (* 1 = 4.17293 loss)
I0601 13:23:14.979564 24067 sgd_solver.cpp:106] Iteration 18320, lr = 0.01
I0601 13:23:20.445209 24067 solver.cpp:237] Iteration 18340, loss = 4.35418
I0601 13:23:20.445369 24067 solver.cpp:253]     Train net output #0: loss = 4.33631 (* 1 = 4.33631 loss)
I0601 13:23:20.445376 24067 sgd_solver.cpp:106] Iteration 18340, lr = 0.01
I0601 13:23:25.925874 24067 solver.cpp:237] Iteration 18360, loss = 4.34664
I0601 13:23:25.925915 24067 solver.cpp:253]     Train net output #0: loss = 4.35898 (* 1 = 4.35898 loss)
I0601 13:23:25.925925 24067 sgd_solver.cpp:106] Iteration 18360, lr = 0.01
I0601 13:23:31.406366 24067 solver.cpp:237] Iteration 18380, loss = 4.38559
I0601 13:23:31.406416 24067 solver.cpp:253]     Train net output #0: loss = 4.44824 (* 1 = 4.44824 loss)
I0601 13:23:31.406435 24067 sgd_solver.cpp:106] Iteration 18380, lr = 0.01
I0601 13:23:36.888878 24067 solver.cpp:237] Iteration 18400, loss = 4.36016
I0601 13:23:36.888926 24067 solver.cpp:253]     Train net output #0: loss = 4.31837 (* 1 = 4.31837 loss)
I0601 13:23:36.888937 24067 sgd_solver.cpp:106] Iteration 18400, lr = 0.01
I0601 13:23:42.354779 24067 solver.cpp:237] Iteration 18420, loss = 4.32456
I0601 13:23:42.354817 24067 solver.cpp:253]     Train net output #0: loss = 4.26699 (* 1 = 4.26699 loss)
I0601 13:23:42.354826 24067 sgd_solver.cpp:106] Iteration 18420, lr = 0.01
I0601 13:23:47.839043 24067 solver.cpp:237] Iteration 18440, loss = 4.32291
I0601 13:23:47.839079 24067 solver.cpp:253]     Train net output #0: loss = 4.23104 (* 1 = 4.23104 loss)
I0601 13:23:47.839089 24067 sgd_solver.cpp:106] Iteration 18440, lr = 0.01
I0601 13:23:53.306148 24067 solver.cpp:237] Iteration 18460, loss = 4.35891
I0601 13:23:53.306365 24067 solver.cpp:253]     Train net output #0: loss = 4.19764 (* 1 = 4.19764 loss)
I0601 13:23:53.306390 24067 sgd_solver.cpp:106] Iteration 18460, lr = 0.01
I0601 13:23:58.738229 24067 solver.cpp:237] Iteration 18480, loss = 4.38365
I0601 13:23:58.738279 24067 solver.cpp:253]     Train net output #0: loss = 4.28206 (* 1 = 4.28206 loss)
I0601 13:23:58.738288 24067 sgd_solver.cpp:106] Iteration 18480, lr = 0.01
I0601 13:24:04.172195 24067 solver.cpp:237] Iteration 18500, loss = 4.33074
I0601 13:24:04.172247 24067 solver.cpp:253]     Train net output #0: loss = 4.39125 (* 1 = 4.39125 loss)
I0601 13:24:04.172256 24067 sgd_solver.cpp:106] Iteration 18500, lr = 0.01
I0601 13:24:09.610769 24067 solver.cpp:237] Iteration 18520, loss = 4.32214
I0601 13:24:09.610826 24067 solver.cpp:253]     Train net output #0: loss = 4.38053 (* 1 = 4.38053 loss)
I0601 13:24:09.610834 24067 sgd_solver.cpp:106] Iteration 18520, lr = 0.01
I0601 13:24:15.070761 24067 solver.cpp:237] Iteration 18540, loss = 4.33079
I0601 13:24:15.070814 24067 solver.cpp:253]     Train net output #0: loss = 4.21566 (* 1 = 4.21566 loss)
I0601 13:24:15.070823 24067 sgd_solver.cpp:106] Iteration 18540, lr = 0.01
I0601 13:24:20.558665 24067 solver.cpp:237] Iteration 18560, loss = 4.46024
I0601 13:24:20.558722 24067 solver.cpp:253]     Train net output #0: loss = 4.36428 (* 1 = 4.36428 loss)
I0601 13:24:20.558732 24067 sgd_solver.cpp:106] Iteration 18560, lr = 0.01
I0601 13:24:26.046664 24067 solver.cpp:237] Iteration 18580, loss = 4.36463
I0601 13:24:26.046895 24067 solver.cpp:253]     Train net output #0: loss = 4.40226 (* 1 = 4.40226 loss)
I0601 13:24:26.046919 24067 sgd_solver.cpp:106] Iteration 18580, lr = 0.01
I0601 13:24:31.538146 24067 solver.cpp:237] Iteration 18600, loss = 4.2939
I0601 13:24:31.538197 24067 solver.cpp:253]     Train net output #0: loss = 4.26936 (* 1 = 4.26936 loss)
I0601 13:24:31.538215 24067 sgd_solver.cpp:106] Iteration 18600, lr = 0.01
I0601 13:24:37.032351 24067 solver.cpp:237] Iteration 18620, loss = 4.32829
I0601 13:24:37.032410 24067 solver.cpp:253]     Train net output #0: loss = 4.29246 (* 1 = 4.29246 loss)
I0601 13:24:37.032420 24067 sgd_solver.cpp:106] Iteration 18620, lr = 0.01
I0601 13:24:42.530097 24067 solver.cpp:237] Iteration 18640, loss = 4.3442
I0601 13:24:42.530155 24067 solver.cpp:253]     Train net output #0: loss = 4.4324 (* 1 = 4.4324 loss)
I0601 13:24:42.530164 24067 sgd_solver.cpp:106] Iteration 18640, lr = 0.01
I0601 13:24:48.029193 24067 solver.cpp:237] Iteration 18660, loss = 4.30534
I0601 13:24:48.029232 24067 solver.cpp:253]     Train net output #0: loss = 4.18541 (* 1 = 4.18541 loss)
I0601 13:24:48.029242 24067 sgd_solver.cpp:106] Iteration 18660, lr = 0.01
I0601 13:24:53.522899 24067 solver.cpp:237] Iteration 18680, loss = 4.31712
I0601 13:24:53.522943 24067 solver.cpp:253]     Train net output #0: loss = 4.16161 (* 1 = 4.16161 loss)
I0601 13:24:53.522951 24067 sgd_solver.cpp:106] Iteration 18680, lr = 0.01
I0601 13:24:59.020196 24067 solver.cpp:237] Iteration 18700, loss = 4.29086
I0601 13:24:59.020460 24067 solver.cpp:253]     Train net output #0: loss = 4.16709 (* 1 = 4.16709 loss)
I0601 13:24:59.020488 24067 sgd_solver.cpp:106] Iteration 18700, lr = 0.01
I0601 13:25:04.509377 24067 solver.cpp:237] Iteration 18720, loss = 4.3391
I0601 13:25:04.509424 24067 solver.cpp:253]     Train net output #0: loss = 4.01913 (* 1 = 4.01913 loss)
I0601 13:25:04.509431 24067 sgd_solver.cpp:106] Iteration 18720, lr = 0.01
I0601 13:25:10.003970 24067 solver.cpp:237] Iteration 18740, loss = 4.31192
I0601 13:25:10.004022 24067 solver.cpp:253]     Train net output #0: loss = 4.27545 (* 1 = 4.27545 loss)
I0601 13:25:10.004030 24067 sgd_solver.cpp:106] Iteration 18740, lr = 0.01
I0601 13:25:15.495453 24067 solver.cpp:237] Iteration 18760, loss = 4.35519
I0601 13:25:15.495504 24067 solver.cpp:253]     Train net output #0: loss = 4.42284 (* 1 = 4.42284 loss)
I0601 13:25:15.495514 24067 sgd_solver.cpp:106] Iteration 18760, lr = 0.01
I0601 13:25:20.982020 24067 solver.cpp:237] Iteration 18780, loss = 4.3114
I0601 13:25:20.982071 24067 solver.cpp:253]     Train net output #0: loss = 4.39802 (* 1 = 4.39802 loss)
I0601 13:25:20.982080 24067 sgd_solver.cpp:106] Iteration 18780, lr = 0.01
I0601 13:25:26.476356 24067 solver.cpp:237] Iteration 18800, loss = 4.3442
I0601 13:25:26.476423 24067 solver.cpp:253]     Train net output #0: loss = 4.37131 (* 1 = 4.37131 loss)
I0601 13:25:26.476434 24067 sgd_solver.cpp:106] Iteration 18800, lr = 0.01
I0601 13:25:31.964202 24067 solver.cpp:237] Iteration 18820, loss = 4.30836
I0601 13:25:31.964426 24067 solver.cpp:253]     Train net output #0: loss = 4.17141 (* 1 = 4.17141 loss)
I0601 13:25:31.964434 24067 sgd_solver.cpp:106] Iteration 18820, lr = 0.01
I0601 13:25:37.451649 24067 solver.cpp:237] Iteration 18840, loss = 4.28719
I0601 13:25:37.451701 24067 solver.cpp:253]     Train net output #0: loss = 4.31298 (* 1 = 4.31298 loss)
I0601 13:25:37.451711 24067 sgd_solver.cpp:106] Iteration 18840, lr = 0.01
I0601 13:25:42.937630 24067 solver.cpp:237] Iteration 18860, loss = 4.26647
I0601 13:25:42.937682 24067 solver.cpp:253]     Train net output #0: loss = 4.34948 (* 1 = 4.34948 loss)
I0601 13:25:42.937691 24067 sgd_solver.cpp:106] Iteration 18860, lr = 0.01
I0601 13:25:48.428146 24067 solver.cpp:237] Iteration 18880, loss = 4.31467
I0601 13:25:48.428194 24067 solver.cpp:253]     Train net output #0: loss = 4.3339 (* 1 = 4.3339 loss)
I0601 13:25:48.428203 24067 sgd_solver.cpp:106] Iteration 18880, lr = 0.01
I0601 13:25:53.915745 24067 solver.cpp:237] Iteration 18900, loss = 4.30471
I0601 13:25:53.915794 24067 solver.cpp:253]     Train net output #0: loss = 4.14954 (* 1 = 4.14954 loss)
I0601 13:25:53.915803 24067 sgd_solver.cpp:106] Iteration 18900, lr = 0.01
I0601 13:25:59.408093 24067 solver.cpp:237] Iteration 18920, loss = 4.35739
I0601 13:25:59.408150 24067 solver.cpp:253]     Train net output #0: loss = 4.39872 (* 1 = 4.39872 loss)
I0601 13:25:59.408162 24067 sgd_solver.cpp:106] Iteration 18920, lr = 0.01
I0601 13:26:04.904280 24067 solver.cpp:237] Iteration 18940, loss = 4.30063
I0601 13:26:04.904491 24067 solver.cpp:253]     Train net output #0: loss = 4.5744 (* 1 = 4.5744 loss)
I0601 13:26:04.904507 24067 sgd_solver.cpp:106] Iteration 18940, lr = 0.01
I0601 13:26:10.401207 24067 solver.cpp:237] Iteration 18960, loss = 4.32451
I0601 13:26:10.401257 24067 solver.cpp:253]     Train net output #0: loss = 4.22858 (* 1 = 4.22858 loss)
I0601 13:26:10.401265 24067 sgd_solver.cpp:106] Iteration 18960, lr = 0.01
I0601 13:26:15.896703 24067 solver.cpp:237] Iteration 18980, loss = 4.27096
I0601 13:26:15.896767 24067 solver.cpp:253]     Train net output #0: loss = 4.34912 (* 1 = 4.34912 loss)
I0601 13:26:15.896777 24067 sgd_solver.cpp:106] Iteration 18980, lr = 0.01
I0601 13:26:21.303503 24067 solver.cpp:341] Iteration 19000, Testing net (#0)
I0601 13:26:50.496958 24067 blocking_queue.cpp:50] Data layer prefetch queue empty
I0601 13:26:53.121978 24067 solver.cpp:409]     Test net output #0: accuracy = 0.19678
I0601 13:26:53.122027 24067 solver.cpp:409]     Test net output #1: loss = 4.11772 (* 1 = 4.11772 loss)
I0601 13:26:53.207285 24067 solver.cpp:237] Iteration 19000, loss = 4.32199
I0601 13:26:53.207340 24067 solver.cpp:253]     Train net output #0: loss = 4.29318 (* 1 = 4.29318 loss)
I0601 13:26:53.207352 24067 sgd_solver.cpp:106] Iteration 19000, lr = 0.01
I0601 13:26:58.657830 24067 solver.cpp:237] Iteration 19020, loss = 4.31054
I0601 13:26:58.657881 24067 solver.cpp:253]     Train net output #0: loss = 4.15785 (* 1 = 4.15785 loss)
I0601 13:26:58.657891 24067 sgd_solver.cpp:106] Iteration 19020, lr = 0.01
I0601 13:27:04.108080 24067 solver.cpp:237] Iteration 19040, loss = 4.32784
I0601 13:27:04.108129 24067 solver.cpp:253]     Train net output #0: loss = 4.17864 (* 1 = 4.17864 loss)
I0601 13:27:04.108149 24067 sgd_solver.cpp:106] Iteration 19040, lr = 0.01
I0601 13:27:09.567390 24067 solver.cpp:237] Iteration 19060, loss = 4.32939
I0601 13:27:09.567437 24067 solver.cpp:253]     Train net output #0: loss = 4.25127 (* 1 = 4.25127 loss)
I0601 13:27:09.567446 24067 sgd_solver.cpp:106] Iteration 19060, lr = 0.01
I0601 13:27:15.025919 24067 solver.cpp:237] Iteration 19080, loss = 4.31407
I0601 13:27:15.025969 24067 solver.cpp:253]     Train net output #0: loss = 4.11121 (* 1 = 4.11121 loss)
I0601 13:27:15.025976 24067 sgd_solver.cpp:106] Iteration 19080, lr = 0.01
I0601 13:27:20.485657 24067 solver.cpp:237] Iteration 19100, loss = 4.30308
I0601 13:27:20.485713 24067 solver.cpp:253]     Train net output #0: loss = 4.30883 (* 1 = 4.30883 loss)
I0601 13:27:20.485721 24067 sgd_solver.cpp:106] Iteration 19100, lr = 0.01
I0601 13:27:25.950918 24067 solver.cpp:237] Iteration 19120, loss = 4.33162
I0601 13:27:25.951153 24067 solver.cpp:253]     Train net output #0: loss = 4.30641 (* 1 = 4.30641 loss)
I0601 13:27:25.951180 24067 sgd_solver.cpp:106] Iteration 19120, lr = 0.01
I0601 13:27:31.421350 24067 solver.cpp:237] Iteration 19140, loss = 4.36111
I0601 13:27:31.421401 24067 solver.cpp:253]     Train net output #0: loss = 4.31449 (* 1 = 4.31449 loss)
I0601 13:27:31.421411 24067 sgd_solver.cpp:106] Iteration 19140, lr = 0.01
I0601 13:27:36.891444 24067 solver.cpp:237] Iteration 19160, loss = 4.25335
I0601 13:27:36.891490 24067 solver.cpp:253]     Train net output #0: loss = 4.16186 (* 1 = 4.16186 loss)
I0601 13:27:36.891499 24067 sgd_solver.cpp:106] Iteration 19160, lr = 0.01
I0601 13:27:42.362138 24067 solver.cpp:237] Iteration 19180, loss = 4.36551
I0601 13:27:42.362185 24067 solver.cpp:253]     Train net output #0: loss = 4.28298 (* 1 = 4.28298 loss)
I0601 13:27:42.362195 24067 sgd_solver.cpp:106] Iteration 19180, lr = 0.01
I0601 13:27:47.835644 24067 solver.cpp:237] Iteration 19200, loss = 4.31354
I0601 13:27:47.835691 24067 solver.cpp:253]     Train net output #0: loss = 4.30373 (* 1 = 4.30373 loss)
I0601 13:27:47.835700 24067 sgd_solver.cpp:106] Iteration 19200, lr = 0.01
I0601 13:27:53.315827 24067 solver.cpp:237] Iteration 19220, loss = 4.32515
I0601 13:27:53.315873 24067 solver.cpp:253]     Train net output #0: loss = 4.25451 (* 1 = 4.25451 loss)
I0601 13:27:53.315882 24067 sgd_solver.cpp:106] Iteration 19220, lr = 0.01
I0601 13:27:58.797305 24067 solver.cpp:237] Iteration 19240, loss = 4.28488
I0601 13:27:58.797503 24067 solver.cpp:253]     Train net output #0: loss = 4.51251 (* 1 = 4.51251 loss)
I0601 13:27:58.797525 24067 sgd_solver.cpp:106] Iteration 19240, lr = 0.01
I0601 13:28:04.226908 24067 solver.cpp:237] Iteration 19260, loss = 4.3664
I0601 13:28:04.226958 24067 solver.cpp:253]     Train net output #0: loss = 4.3421 (* 1 = 4.3421 loss)
I0601 13:28:04.226964 24067 sgd_solver.cpp:106] Iteration 19260, lr = 0.01
I0601 13:28:09.653663 24067 solver.cpp:237] Iteration 19280, loss = 4.27554
I0601 13:28:09.653715 24067 solver.cpp:253]     Train net output #0: loss = 4.22448 (* 1 = 4.22448 loss)
I0601 13:28:09.653723 24067 sgd_solver.cpp:106] Iteration 19280, lr = 0.01
I0601 13:28:15.087862 24067 solver.cpp:237] Iteration 19300, loss = 4.32674
I0601 13:28:15.087913 24067 solver.cpp:253]     Train net output #0: loss = 4.27316 (* 1 = 4.27316 loss)
I0601 13:28:15.087921 24067 sgd_solver.cpp:106] Iteration 19300, lr = 0.01
I0601 13:28:20.523820 24067 solver.cpp:237] Iteration 19320, loss = 4.38095
I0601 13:28:20.523869 24067 solver.cpp:253]     Train net output #0: loss = 4.16687 (* 1 = 4.16687 loss)
I0601 13:28:20.523877 24067 sgd_solver.cpp:106] Iteration 19320, lr = 0.01
I0601 13:28:25.978320 24067 solver.cpp:237] Iteration 19340, loss = 4.34566
I0601 13:28:25.978374 24067 solver.cpp:253]     Train net output #0: loss = 4.0607 (* 1 = 4.0607 loss)
I0601 13:28:25.978381 24067 sgd_solver.cpp:106] Iteration 19340, lr = 0.01
I0601 13:28:31.469821 24067 solver.cpp:237] Iteration 19360, loss = 4.3422
I0601 13:28:31.470085 24067 solver.cpp:253]     Train net output #0: loss = 4.33907 (* 1 = 4.33907 loss)
I0601 13:28:31.470110 24067 sgd_solver.cpp:106] Iteration 19360, lr = 0.01
I0601 13:28:36.952152 24067 solver.cpp:237] Iteration 19380, loss = 4.25982
I0601 13:28:36.952203 24067 solver.cpp:253]     Train net output #0: loss = 4.47732 (* 1 = 4.47732 loss)
I0601 13:28:36.952214 24067 sgd_solver.cpp:106] Iteration 19380, lr = 0.01
I0601 13:28:42.432262 24067 solver.cpp:237] Iteration 19400, loss = 4.28766
I0601 13:28:42.432306 24067 solver.cpp:253]     Train net output #0: loss = 4.16301 (* 1 = 4.16301 loss)
I0601 13:28:42.432313 24067 sgd_solver.cpp:106] Iteration 19400, lr = 0.01
I0601 13:28:47.919708 24067 solver.cpp:237] Iteration 19420, loss = 4.26947
I0601 13:28:47.919769 24067 solver.cpp:253]     Train net output #0: loss = 4.07249 (* 1 = 4.07249 loss)
I0601 13:28:47.919777 24067 sgd_solver.cpp:106] Iteration 19420, lr = 0.01
I0601 13:28:53.386207 24067 solver.cpp:237] Iteration 19440, loss = 4.30214
I0601 13:28:53.386263 24067 solver.cpp:253]     Train net output #0: loss = 4.2405 (* 1 = 4.2405 loss)
I0601 13:28:53.386273 24067 sgd_solver.cpp:106] Iteration 19440, lr = 0.01
I0601 13:28:58.858103 24067 solver.cpp:237] Iteration 19460, loss = 4.2758
I0601 13:28:58.858155 24067 solver.cpp:253]     Train net output #0: loss = 4.39145 (* 1 = 4.39145 loss)
I0601 13:28:58.858165 24067 sgd_solver.cpp:106] Iteration 19460, lr = 0.01
I0601 13:29:04.346490 24067 solver.cpp:237] Iteration 19480, loss = 4.28976
I0601 13:29:04.346670 24067 solver.cpp:253]     Train net output #0: loss = 4.2899 (* 1 = 4.2899 loss)
I0601 13:29:04.346683 24067 sgd_solver.cpp:106] Iteration 19480, lr = 0.01
I0601 13:29:09.842967 24067 solver.cpp:237] Iteration 19500, loss = 4.40266
I0601 13:29:09.843016 24067 solver.cpp:253]     Train net output #0: loss = 4.33381 (* 1 = 4.33381 loss)
I0601 13:29:09.843024 24067 sgd_solver.cpp:106] Iteration 19500, lr = 0.01
I0601 13:29:15.332000 24067 solver.cpp:237] Iteration 19520, loss = 4.3442
I0601 13:29:15.332051 24067 solver.cpp:253]     Train net output #0: loss = 4.31354 (* 1 = 4.31354 loss)
I0601 13:29:15.332070 24067 sgd_solver.cpp:106] Iteration 19520, lr = 0.01
I0601 13:29:20.820238 24067 solver.cpp:237] Iteration 19540, loss = 4.31416
I0601 13:29:20.820286 24067 solver.cpp:253]     Train net output #0: loss = 4.36642 (* 1 = 4.36642 loss)
I0601 13:29:20.820294 24067 sgd_solver.cpp:106] Iteration 19540, lr = 0.01
I0601 13:29:26.316123 24067 solver.cpp:237] Iteration 19560, loss = 4.26966
I0601 13:29:26.316160 24067 solver.cpp:253]     Train net output #0: loss = 4.21005 (* 1 = 4.21005 loss)
I0601 13:29:26.316169 24067 sgd_solver.cpp:106] Iteration 19560, lr = 0.01
I0601 13:29:31.810163 24067 solver.cpp:237] Iteration 19580, loss = 4.3379
I0601 13:29:31.810214 24067 solver.cpp:253]     Train net output #0: loss = 4.31725 (* 1 = 4.31725 loss)
I0601 13:29:31.810222 24067 sgd_solver.cpp:106] Iteration 19580, lr = 0.01
I0601 13:29:37.308866 24067 solver.cpp:237] Iteration 19600, loss = 4.30359
I0601 13:29:37.309089 24067 solver.cpp:253]     Train net output #0: loss = 4.14729 (* 1 = 4.14729 loss)
I0601 13:29:37.309106 24067 sgd_solver.cpp:106] Iteration 19600, lr = 0.01
I0601 13:29:42.763530 24067 solver.cpp:237] Iteration 19620, loss = 4.33172
I0601 13:29:42.763571 24067 solver.cpp:253]     Train net output #0: loss = 4.31399 (* 1 = 4.31399 loss)
I0601 13:29:42.763576 24067 sgd_solver.cpp:106] Iteration 19620, lr = 0.01
I0601 13:29:48.208374 24067 solver.cpp:237] Iteration 19640, loss = 4.2681
I0601 13:29:48.208415 24067 solver.cpp:253]     Train net output #0: loss = 4.23593 (* 1 = 4.23593 loss)
I0601 13:29:48.208420 24067 sgd_solver.cpp:106] Iteration 19640, lr = 0.01
I0601 13:29:53.690269 24067 solver.cpp:237] Iteration 19660, loss = 4.28262
I0601 13:29:53.690310 24067 solver.cpp:253]     Train net output #0: loss = 4.53816 (* 1 = 4.53816 loss)
I0601 13:29:53.690316 24067 sgd_solver.cpp:106] Iteration 19660, lr = 0.01
I0601 13:29:59.176733 24067 solver.cpp:237] Iteration 19680, loss = 4.28785
I0601 13:29:59.176779 24067 solver.cpp:253]     Train net output #0: loss = 4.1197 (* 1 = 4.1197 loss)
I0601 13:29:59.176785 24067 sgd_solver.cpp:106] Iteration 19680, lr = 0.01
I0601 13:30:04.662922 24067 solver.cpp:237] Iteration 19700, loss = 4.275
I0601 13:30:04.662962 24067 solver.cpp:253]     Train net output #0: loss = 4.18213 (* 1 = 4.18213 loss)
I0601 13:30:04.662968 24067 sgd_solver.cpp:106] Iteration 19700, lr = 0.01
I0601 13:30:10.145087 24067 solver.cpp:237] Iteration 19720, loss = 4.34218
I0601 13:30:10.145339 24067 solver.cpp:253]     Train net output #0: loss = 4.39078 (* 1 = 4.39078 loss)
I0601 13:30:10.145369 24067 sgd_solver.cpp:106] Iteration 19720, lr = 0.01
I0601 13:30:15.638214 24067 solver.cpp:237] Iteration 19740, loss = 4.28425
I0601 13:30:15.638264 24067 solver.cpp:253]     Train net output #0: loss = 4.25763 (* 1 = 4.25763 loss)
I0601 13:30:15.638273 24067 sgd_solver.cpp:106] Iteration 19740, lr = 0.01
I0601 13:30:21.130509 24067 solver.cpp:237] Iteration 19760, loss = 4.32342
I0601 13:30:21.130558 24067 solver.cpp:253]     Train net output #0: loss = 4.29683 (* 1 = 4.29683 loss)
I0601 13:30:21.130565 24067 sgd_solver.cpp:106] Iteration 19760, lr = 0.01
I0601 13:30:26.623359 24067 solver.cpp:237] Iteration 19780, loss = 4.28712
I0601 13:30:26.623409 24067 solver.cpp:253]     Train net output #0: loss = 4.33209 (* 1 = 4.33209 loss)
I0601 13:30:26.623419 24067 sgd_solver.cpp:106] Iteration 19780, lr = 0.01
I0601 13:30:32.114048 24067 solver.cpp:237] Iteration 19800, loss = 4.34175
I0601 13:30:32.114109 24067 solver.cpp:253]     Train net output #0: loss = 4.37412 (* 1 = 4.37412 loss)
I0601 13:30:32.114119 24067 sgd_solver.cpp:106] Iteration 19800, lr = 0.01
I0601 13:30:37.607789 24067 solver.cpp:237] Iteration 19820, loss = 4.29514
I0601 13:30:37.607843 24067 solver.cpp:253]     Train net output #0: loss = 4.47847 (* 1 = 4.47847 loss)
I0601 13:30:37.607856 24067 sgd_solver.cpp:106] Iteration 19820, lr = 0.01
I0601 13:30:43.100168 24067 solver.cpp:237] Iteration 19840, loss = 4.29048
I0601 13:30:43.100414 24067 solver.cpp:253]     Train net output #0: loss = 4.06381 (* 1 = 4.06381 loss)
I0601 13:30:43.100436 24067 sgd_solver.cpp:106] Iteration 19840, lr = 0.01
I0601 13:30:48.583297 24067 solver.cpp:237] Iteration 19860, loss = 4.29932
I0601 13:30:48.583338 24067 solver.cpp:253]     Train net output #0: loss = 4.44203 (* 1 = 4.44203 loss)
I0601 13:30:48.583348 24067 sgd_solver.cpp:106] Iteration 19860, lr = 0.01
I0601 13:30:54.042198 24067 solver.cpp:237] Iteration 19880, loss = 4.34098
I0601 13:30:54.042233 24067 solver.cpp:253]     Train net output #0: loss = 4.3188 (* 1 = 4.3188 loss)
I0601 13:30:54.042240 24067 sgd_solver.cpp:106] Iteration 19880, lr = 0.01
I0601 13:30:59.473098 24067 solver.cpp:237] Iteration 19900, loss = 4.30091
I0601 13:30:59.473143 24067 solver.cpp:253]     Train net output #0: loss = 4.01138 (* 1 = 4.01138 loss)
I0601 13:30:59.473151 24067 sgd_solver.cpp:106] Iteration 19900, lr = 0.01
I0601 13:31:04.907281 24067 solver.cpp:237] Iteration 19920, loss = 4.38657
I0601 13:31:04.907320 24067 solver.cpp:253]     Train net output #0: loss = 4.22756 (* 1 = 4.22756 loss)
I0601 13:31:04.907330 24067 sgd_solver.cpp:106] Iteration 19920, lr = 0.01
I0601 13:31:10.351887 24067 solver.cpp:237] Iteration 19940, loss = 4.30401
I0601 13:31:10.351928 24067 solver.cpp:253]     Train net output #0: loss = 4.24697 (* 1 = 4.24697 loss)
I0601 13:31:10.351934 24067 sgd_solver.cpp:106] Iteration 19940, lr = 0.01
I0601 13:31:15.806222 24067 solver.cpp:237] Iteration 19960, loss = 4.2604
I0601 13:31:15.806485 24067 solver.cpp:253]     Train net output #0: loss = 4.12637 (* 1 = 4.12637 loss)
I0601 13:31:15.806516 24067 sgd_solver.cpp:106] Iteration 19960, lr = 0.01
I0601 13:31:21.301867 24067 solver.cpp:237] Iteration 19980, loss = 4.31229
I0601 13:31:21.301915 24067 solver.cpp:253]     Train net output #0: loss = 4.57116 (* 1 = 4.57116 loss)
I0601 13:31:21.301923 24067 sgd_solver.cpp:106] Iteration 19980, lr = 0.01
I0601 13:31:26.713394 24067 solver.cpp:459] Snapshotting to binary proto file snapshots/caffenet128_no_lrn_lsuv_bn_after_TanH_iter_20000.caffemodel
I0601 13:31:27.862074 24067 sgd_solver.cpp:269] Snapshotting solver state to binary proto file snapshots/caffenet128_no_lrn_lsuv_bn_after_TanH_iter_20000.solverstate
I0601 13:31:28.820019 24067 solver.cpp:341] Iteration 20000, Testing net (#0)
I0601 13:32:00.294806 24067 blocking_queue.cpp:50] Data layer prefetch queue empty
I0601 13:32:02.897578 24067 solver.cpp:409]     Test net output #0: accuracy = 0.19054
I0601 13:32:02.897629 24067 solver.cpp:409]     Test net output #1: loss = 4.17795 (* 1 = 4.17795 loss)
I0601 13:32:02.981578 24067 solver.cpp:237] Iteration 20000, loss = 4.39167
I0601 13:32:02.981629 24067 solver.cpp:253]     Train net output #0: loss = 4.45741 (* 1 = 4.45741 loss)
I0601 13:32:02.981642 24067 sgd_solver.cpp:106] Iteration 20000, lr = 0.01
I0601 13:32:08.441033 24067 solver.cpp:237] Iteration 20020, loss = 4.3607
I0601 13:32:08.441082 24067 solver.cpp:253]     Train net output #0: loss = 4.25095 (* 1 = 4.25095 loss)
I0601 13:32:08.441089 24067 sgd_solver.cpp:106] Iteration 20020, lr = 0.01
I0601 13:32:13.912637 24067 solver.cpp:237] Iteration 20040, loss = 4.29789
I0601 13:32:13.912686 24067 solver.cpp:253]     Train net output #0: loss = 4.19427 (* 1 = 4.19427 loss)
I0601 13:32:13.912695 24067 sgd_solver.cpp:106] Iteration 20040, lr = 0.01
I0601 13:32:19.383172 24067 solver.cpp:237] Iteration 20060, loss = 4.27992
I0601 13:32:19.383211 24067 solver.cpp:253]     Train net output #0: loss = 4.3578 (* 1 = 4.3578 loss)
I0601 13:32:19.383221 24067 sgd_solver.cpp:106] Iteration 20060, lr = 0.01
I0601 13:32:24.844866 24067 solver.cpp:237] Iteration 20080, loss = 4.33347
I0601 13:32:24.844915 24067 solver.cpp:253]     Train net output #0: loss = 4.26406 (* 1 = 4.26406 loss)
I0601 13:32:24.844921 24067 sgd_solver.cpp:106] Iteration 20080, lr = 0.01
I0601 13:32:30.256614 24067 solver.cpp:237] Iteration 20100, loss = 4.39305
I0601 13:32:30.256660 24067 solver.cpp:253]     Train net output #0: loss = 4.29889 (* 1 = 4.29889 loss)
I0601 13:32:30.256666 24067 sgd_solver.cpp:106] Iteration 20100, lr = 0.01
I0601 13:32:35.659575 24067 solver.cpp:237] Iteration 20120, loss = 4.27904
I0601 13:32:35.659818 24067 solver.cpp:253]     Train net output #0: loss = 4.37785 (* 1 = 4.37785 loss)
I0601 13:32:35.659844 24067 sgd_solver.cpp:106] Iteration 20120, lr = 0.01
I0601 13:32:41.070754 24067 solver.cpp:237] Iteration 20140, loss = 4.34674
I0601 13:32:41.070796 24067 solver.cpp:253]     Train net output #0: loss = 4.1328 (* 1 = 4.1328 loss)
I0601 13:32:41.070806 24067 sgd_solver.cpp:106] Iteration 20140, lr = 0.01
I0601 13:32:46.477648 24067 solver.cpp:237] Iteration 20160, loss = 4.23573
I0601 13:32:46.477696 24067 solver.cpp:253]     Train net output #0: loss = 4.49888 (* 1 = 4.49888 loss)
I0601 13:32:46.477705 24067 sgd_solver.cpp:106] Iteration 20160, lr = 0.01
I0601 13:32:51.887491 24067 solver.cpp:237] Iteration 20180, loss = 4.34734
I0601 13:32:51.887540 24067 solver.cpp:253]     Train net output #0: loss = 4.29905 (* 1 = 4.29905 loss)
I0601 13:32:51.887549 24067 sgd_solver.cpp:106] Iteration 20180, lr = 0.01
I0601 13:32:57.309788 24067 solver.cpp:237] Iteration 20200, loss = 4.24388
I0601 13:32:57.309826 24067 solver.cpp:253]     Train net output #0: loss = 3.95984 (* 1 = 3.95984 loss)
I0601 13:32:57.309836 24067 sgd_solver.cpp:106] Iteration 20200, lr = 0.01
I0601 13:33:02.736863 24067 solver.cpp:237] Iteration 20220, loss = 4.34347
I0601 13:33:02.736912 24067 solver.cpp:253]     Train net output #0: loss = 4.389 (* 1 = 4.389 loss)
I0601 13:33:02.736919 24067 sgd_solver.cpp:106] Iteration 20220, lr = 0.01
I0601 13:33:08.160272 24067 solver.cpp:237] Iteration 20240, loss = 4.28362
I0601 13:33:08.160503 24067 solver.cpp:253]     Train net output #0: loss = 4.17344 (* 1 = 4.17344 loss)
I0601 13:33:08.160539 24067 sgd_solver.cpp:106] Iteration 20240, lr = 0.01
I0601 13:33:13.593392 24067 solver.cpp:237] Iteration 20260, loss = 4.26005
I0601 13:33:13.593436 24067 solver.cpp:253]     Train net output #0: loss = 4.21938 (* 1 = 4.21938 loss)
I0601 13:33:13.593449 24067 sgd_solver.cpp:106] Iteration 20260, lr = 0.01
I0601 13:33:19.063769 24067 solver.cpp:237] Iteration 20280, loss = 4.31233
I0601 13:33:19.063813 24067 solver.cpp:253]     Train net output #0: loss = 4.64696 (* 1 = 4.64696 loss)
I0601 13:33:19.063820 24067 sgd_solver.cpp:106] Iteration 20280, lr = 0.01
I0601 13:33:24.532582 24067 solver.cpp:237] Iteration 20300, loss = 4.29783
I0601 13:33:24.532631 24067 solver.cpp:253]     Train net output #0: loss = 4.33916 (* 1 = 4.33916 loss)
I0601 13:33:24.532636 24067 sgd_solver.cpp:106] Iteration 20300, lr = 0.01
I0601 13:33:30.003509 24067 solver.cpp:237] Iteration 20320, loss = 4.24856
I0601 13:33:30.003558 24067 solver.cpp:253]     Train net output #0: loss = 4.45371 (* 1 = 4.45371 loss)
I0601 13:33:30.003566 24067 sgd_solver.cpp:106] Iteration 20320, lr = 0.01
I0601 13:33:35.489977 24067 solver.cpp:237] Iteration 20340, loss = 4.351
I0601 13:33:35.490021 24067 solver.cpp:253]     Train net output #0: loss = 4.05281 (* 1 = 4.05281 loss)
I0601 13:33:35.490028 24067 sgd_solver.cpp:106] Iteration 20340, lr = 0.01
I0601 13:33:40.973778 24067 solver.cpp:237] Iteration 20360, loss = 4.29843
I0601 13:33:40.974028 24067 solver.cpp:253]     Train net output #0: loss = 4.37786 (* 1 = 4.37786 loss)
I0601 13:33:40.974056 24067 sgd_solver.cpp:106] Iteration 20360, lr = 0.01
I0601 13:33:46.453934 24067 solver.cpp:237] Iteration 20380, loss = 4.31518
I0601 13:33:46.453989 24067 solver.cpp:253]     Train net output #0: loss = 4.32 (* 1 = 4.32 loss)
I0601 13:33:46.453999 24067 sgd_solver.cpp:106] Iteration 20380, lr = 0.01
I0601 13:33:51.921684 24067 solver.cpp:237] Iteration 20400, loss = 4.31194
I0601 13:33:51.921733 24067 solver.cpp:253]     Train net output #0: loss = 4.56925 (* 1 = 4.56925 loss)
I0601 13:33:51.921766 24067 sgd_solver.cpp:106] Iteration 20400, lr = 0.01
I0601 13:33:57.402884 24067 solver.cpp:237] Iteration 20420, loss = 4.24546
I0601 13:33:57.402938 24067 solver.cpp:253]     Train net output #0: loss = 4.44946 (* 1 = 4.44946 loss)
I0601 13:33:57.402947 24067 sgd_solver.cpp:106] Iteration 20420, lr = 0.01
I0601 13:34:02.886266 24067 solver.cpp:237] Iteration 20440, loss = 4.25153
I0601 13:34:02.886318 24067 solver.cpp:253]     Train net output #0: loss = 4.11234 (* 1 = 4.11234 loss)
I0601 13:34:02.886327 24067 sgd_solver.cpp:106] Iteration 20440, lr = 0.01
I0601 13:34:08.326267 24067 solver.cpp:237] Iteration 20460, loss = 4.2859
I0601 13:34:08.326323 24067 solver.cpp:253]     Train net output #0: loss = 4.46028 (* 1 = 4.46028 loss)
I0601 13:34:08.326333 24067 sgd_solver.cpp:106] Iteration 20460, lr = 0.01
I0601 13:34:13.759579 24067 solver.cpp:237] Iteration 20480, loss = 4.27207
I0601 13:34:13.759784 24067 solver.cpp:253]     Train net output #0: loss = 4.09509 (* 1 = 4.09509 loss)
I0601 13:34:13.759802 24067 sgd_solver.cpp:106] Iteration 20480, lr = 0.01
I0601 13:34:19.244577 24067 solver.cpp:237] Iteration 20500, loss = 4.33994
I0601 13:34:19.244626 24067 solver.cpp:253]     Train net output #0: loss = 4.63249 (* 1 = 4.63249 loss)
I0601 13:34:19.244634 24067 sgd_solver.cpp:106] Iteration 20500, lr = 0.01
I0601 13:34:24.734460 24067 solver.cpp:237] Iteration 20520, loss = 4.26709
I0601 13:34:24.734508 24067 solver.cpp:253]     Train net output #0: loss = 4.18426 (* 1 = 4.18426 loss)
I0601 13:34:24.734514 24067 sgd_solver.cpp:106] Iteration 20520, lr = 0.01
I0601 13:34:30.226801 24067 solver.cpp:237] Iteration 20540, loss = 4.28536
I0601 13:34:30.226855 24067 solver.cpp:253]     Train net output #0: loss = 4.43927 (* 1 = 4.43927 loss)
I0601 13:34:30.226863 24067 sgd_solver.cpp:106] Iteration 20540, lr = 0.01
I0601 13:34:35.726332 24067 solver.cpp:237] Iteration 20560, loss = 4.37555
I0601 13:34:35.726385 24067 solver.cpp:253]     Train net output #0: loss = 4.54702 (* 1 = 4.54702 loss)
I0601 13:34:35.726393 24067 sgd_solver.cpp:106] Iteration 20560, lr = 0.01
I0601 13:34:41.215894 24067 solver.cpp:237] Iteration 20580, loss = 4.32801
I0601 13:34:41.215944 24067 solver.cpp:253]     Train net output #0: loss = 4.48786 (* 1 = 4.48786 loss)
I0601 13:34:41.215962 24067 sgd_solver.cpp:106] Iteration 20580, lr = 0.01
I0601 13:34:46.709282 24067 solver.cpp:237] Iteration 20600, loss = 4.30265
I0601 13:34:46.709458 24067 solver.cpp:253]     Train net output #0: loss = 4.41448 (* 1 = 4.41448 loss)
I0601 13:34:46.709467 24067 sgd_solver.cpp:106] Iteration 20600, lr = 0.01
I0601 13:34:52.196528 24067 solver.cpp:237] Iteration 20620, loss = 4.32122
I0601 13:34:52.196576 24067 solver.cpp:253]     Train net output #0: loss = 4.55379 (* 1 = 4.55379 loss)
I0601 13:34:52.196584 24067 sgd_solver.cpp:106] Iteration 20620, lr = 0.01
I0601 13:34:57.675429 24067 solver.cpp:237] Iteration 20640, loss = 4.31543
I0601 13:34:57.675479 24067 solver.cpp:253]     Train net output #0: loss = 4.17327 (* 1 = 4.17327 loss)
I0601 13:34:57.675487 24067 sgd_solver.cpp:106] Iteration 20640, lr = 0.01
I0601 13:35:03.163689 24067 solver.cpp:237] Iteration 20660, loss = 4.25147
I0601 13:35:03.163738 24067 solver.cpp:253]     Train net output #0: loss = 4.04859 (* 1 = 4.04859 loss)
I0601 13:35:03.163746 24067 sgd_solver.cpp:106] Iteration 20660, lr = 0.01
I0601 13:35:08.652609 24067 solver.cpp:237] Iteration 20680, loss = 4.3128
I0601 13:35:08.652657 24067 solver.cpp:253]     Train net output #0: loss = 4.24902 (* 1 = 4.24902 loss)
I0601 13:35:08.652665 24067 sgd_solver.cpp:106] Iteration 20680, lr = 0.01
I0601 13:35:14.145104 24067 solver.cpp:237] Iteration 20700, loss = 4.31675
I0601 13:35:14.145158 24067 solver.cpp:253]     Train net output #0: loss = 4.1804 (* 1 = 4.1804 loss)
I0601 13:35:14.145166 24067 sgd_solver.cpp:106] Iteration 20700, lr = 0.01
I0601 13:35:19.631606 24067 solver.cpp:237] Iteration 20720, loss = 4.31946
I0601 13:35:19.631844 24067 solver.cpp:253]     Train net output #0: loss = 4.27072 (* 1 = 4.27072 loss)
I0601 13:35:19.631893 24067 sgd_solver.cpp:106] Iteration 20720, lr = 0.01
I0601 13:35:25.116751 24067 solver.cpp:237] Iteration 20740, loss = 4.26432
I0601 13:35:25.116801 24067 solver.cpp:253]     Train net output #0: loss = 4.45905 (* 1 = 4.45905 loss)
I0601 13:35:25.116807 24067 sgd_solver.cpp:106] Iteration 20740, lr = 0.01
I0601 13:35:30.607504 24067 solver.cpp:237] Iteration 20760, loss = 4.25354
I0601 13:35:30.607548 24067 solver.cpp:253]     Train net output #0: loss = 4.22163 (* 1 = 4.22163 loss)
I0601 13:35:30.607555 24067 sgd_solver.cpp:106] Iteration 20760, lr = 0.01
I0601 13:35:36.104349 24067 solver.cpp:237] Iteration 20780, loss = 4.27332
I0601 13:35:36.104406 24067 solver.cpp:253]     Train net output #0: loss = 4.00646 (* 1 = 4.00646 loss)
I0601 13:35:36.104414 24067 sgd_solver.cpp:106] Iteration 20780, lr = 0.01
I0601 13:35:41.595463 24067 solver.cpp:237] Iteration 20800, loss = 4.24449
I0601 13:35:41.595510 24067 solver.cpp:253]     Train net output #0: loss = 4.36511 (* 1 = 4.36511 loss)
I0601 13:35:41.595517 24067 sgd_solver.cpp:106] Iteration 20800, lr = 0.01
I0601 13:35:47.090019 24067 solver.cpp:237] Iteration 20820, loss = 4.31477
I0601 13:35:47.090068 24067 solver.cpp:253]     Train net output #0: loss = 4.38333 (* 1 = 4.38333 loss)
I0601 13:35:47.090075 24067 sgd_solver.cpp:106] Iteration 20820, lr = 0.01
I0601 13:35:52.640760 24067 solver.cpp:237] Iteration 20840, loss = 4.28418
I0601 13:35:52.640985 24067 solver.cpp:253]     Train net output #0: loss = 4.1922 (* 1 = 4.1922 loss)
I0601 13:35:52.641005 24067 sgd_solver.cpp:106] Iteration 20840, lr = 0.01
I0601 13:35:58.137595 24067 solver.cpp:237] Iteration 20860, loss = 4.25276
I0601 13:35:58.137650 24067 solver.cpp:253]     Train net output #0: loss = 4.53495 (* 1 = 4.53495 loss)
I0601 13:35:58.137658 24067 sgd_solver.cpp:106] Iteration 20860, lr = 0.01
I0601 13:36:03.631966 24067 solver.cpp:237] Iteration 20880, loss = 4.31752
I0601 13:36:03.632024 24067 solver.cpp:253]     Train net output #0: loss = 4.2326 (* 1 = 4.2326 loss)
I0601 13:36:03.632035 24067 sgd_solver.cpp:106] Iteration 20880, lr = 0.01
I0601 13:36:09.123678 24067 solver.cpp:237] Iteration 20900, loss = 4.33155
I0601 13:36:09.123718 24067 solver.cpp:253]     Train net output #0: loss = 4.42079 (* 1 = 4.42079 loss)
I0601 13:36:09.123739 24067 sgd_solver.cpp:106] Iteration 20900, lr = 0.01
I0601 13:36:14.618944 24067 solver.cpp:237] Iteration 20920, loss = 4.31225
I0601 13:36:14.618985 24067 solver.cpp:253]     Train net output #0: loss = 4.15664 (* 1 = 4.15664 loss)
I0601 13:36:14.618995 24067 sgd_solver.cpp:106] Iteration 20920, lr = 0.01
I0601 13:36:20.115401 24067 solver.cpp:237] Iteration 20940, loss = 4.28428
I0601 13:36:20.115445 24067 solver.cpp:253]     Train net output #0: loss = 4.27179 (* 1 = 4.27179 loss)
I0601 13:36:20.115454 24067 sgd_solver.cpp:106] Iteration 20940, lr = 0.01
I0601 13:36:25.602231 24067 solver.cpp:237] Iteration 20960, loss = 4.33623
I0601 13:36:25.602486 24067 solver.cpp:253]     Train net output #0: loss = 4.42194 (* 1 = 4.42194 loss)
I0601 13:36:25.602509 24067 sgd_solver.cpp:106] Iteration 20960, lr = 0.01
I0601 13:36:31.103833 24067 solver.cpp:237] Iteration 20980, loss = 4.3236
I0601 13:36:31.103885 24067 solver.cpp:253]     Train net output #0: loss = 4.40397 (* 1 = 4.40397 loss)
I0601 13:36:31.103895 24067 sgd_solver.cpp:106] Iteration 20980, lr = 0.01
I0601 13:36:36.507382 24067 solver.cpp:341] Iteration 21000, Testing net (#0)
I0601 13:37:04.959517 24067 blocking_queue.cpp:50] Data layer prefetch queue empty
I0601 13:37:08.163928 24067 solver.cpp:409]     Test net output #0: accuracy = 0.19974
I0601 13:37:08.163970 24067 solver.cpp:409]     Test net output #1: loss = 4.10114 (* 1 = 4.10114 loss)
I0601 13:37:08.245061 24067 solver.cpp:237] Iteration 21000, loss = 4.25954
I0601 13:37:08.245110 24067 solver.cpp:253]     Train net output #0: loss = 4.34352 (* 1 = 4.34352 loss)
I0601 13:37:08.245122 24067 sgd_solver.cpp:106] Iteration 21000, lr = 0.01
I0601 13:37:13.690620 24067 solver.cpp:237] Iteration 21020, loss = 4.29544
I0601 13:37:13.690671 24067 solver.cpp:253]     Train net output #0: loss = 3.91474 (* 1 = 3.91474 loss)
I0601 13:37:13.690681 24067 sgd_solver.cpp:106] Iteration 21020, lr = 0.01
I0601 13:37:19.145783 24067 solver.cpp:237] Iteration 21040, loss = 4.21785
I0601 13:37:19.145831 24067 solver.cpp:253]     Train net output #0: loss = 4.18782 (* 1 = 4.18782 loss)
I0601 13:37:19.145840 24067 sgd_solver.cpp:106] Iteration 21040, lr = 0.01
I0601 13:37:24.601683 24067 solver.cpp:237] Iteration 21060, loss = 4.2771
I0601 13:37:24.601738 24067 solver.cpp:253]     Train net output #0: loss = 4.03737 (* 1 = 4.03737 loss)
I0601 13:37:24.601749 24067 sgd_solver.cpp:106] Iteration 21060, lr = 0.01
I0601 13:37:30.060510 24067 solver.cpp:237] Iteration 21080, loss = 4.26299
I0601 13:37:30.060559 24067 solver.cpp:253]     Train net output #0: loss = 4.13443 (* 1 = 4.13443 loss)
I0601 13:37:30.060570 24067 sgd_solver.cpp:106] Iteration 21080, lr = 0.01
I0601 13:37:35.526401 24067 solver.cpp:237] Iteration 21100, loss = 4.22648
I0601 13:37:35.526629 24067 solver.cpp:253]     Train net output #0: loss = 4.22695 (* 1 = 4.22695 loss)
I0601 13:37:35.526649 24067 sgd_solver.cpp:106] Iteration 21100, lr = 0.01
I0601 13:37:40.986416 24067 solver.cpp:237] Iteration 21120, loss = 4.25484
I0601 13:37:40.986460 24067 solver.cpp:253]     Train net output #0: loss = 4.47221 (* 1 = 4.47221 loss)
I0601 13:37:40.986466 24067 sgd_solver.cpp:106] Iteration 21120, lr = 0.01
I0601 13:37:46.445514 24067 solver.cpp:237] Iteration 21140, loss = 4.24919
I0601 13:37:46.445560 24067 solver.cpp:253]     Train net output #0: loss = 4.06489 (* 1 = 4.06489 loss)
I0601 13:37:46.445566 24067 sgd_solver.cpp:106] Iteration 21140, lr = 0.01
I0601 13:37:51.892886 24067 solver.cpp:237] Iteration 21160, loss = 4.26417
I0601 13:37:51.892928 24067 solver.cpp:253]     Train net output #0: loss = 4.12402 (* 1 = 4.12402 loss)
I0601 13:37:51.892935 24067 sgd_solver.cpp:106] Iteration 21160, lr = 0.01
I0601 13:37:57.353387 24067 solver.cpp:237] Iteration 21180, loss = 4.32369
I0601 13:37:57.353437 24067 solver.cpp:253]     Train net output #0: loss = 4.17638 (* 1 = 4.17638 loss)
I0601 13:37:57.353443 24067 sgd_solver.cpp:106] Iteration 21180, lr = 0.01
I0601 13:38:02.792028 24067 solver.cpp:237] Iteration 21200, loss = 4.26357
I0601 13:38:02.792068 24067 solver.cpp:253]     Train net output #0: loss = 4.36455 (* 1 = 4.36455 loss)
I0601 13:38:02.792074 24067 sgd_solver.cpp:106] Iteration 21200, lr = 0.01
I0601 13:38:08.234933 24067 solver.cpp:237] Iteration 21220, loss = 4.23151
I0601 13:38:08.235143 24067 solver.cpp:253]     Train net output #0: loss = 4.34921 (* 1 = 4.34921 loss)
I0601 13:38:08.235169 24067 sgd_solver.cpp:106] Iteration 21220, lr = 0.01
I0601 13:38:13.711642 24067 solver.cpp:237] Iteration 21240, loss = 4.29366
I0601 13:38:13.711702 24067 solver.cpp:253]     Train net output #0: loss = 4.18549 (* 1 = 4.18549 loss)
I0601 13:38:13.711724 24067 sgd_solver.cpp:106] Iteration 21240, lr = 0.01
I0601 13:38:19.198392 24067 solver.cpp:237] Iteration 21260, loss = 4.33737
I0601 13:38:19.198446 24067 solver.cpp:253]     Train net output #0: loss = 4.54377 (* 1 = 4.54377 loss)
I0601 13:38:19.198453 24067 sgd_solver.cpp:106] Iteration 21260, lr = 0.01
I0601 13:38:24.680076 24067 solver.cpp:237] Iteration 21280, loss = 4.30539
I0601 13:38:24.680129 24067 solver.cpp:253]     Train net output #0: loss = 4.06684 (* 1 = 4.06684 loss)
I0601 13:38:24.680140 24067 sgd_solver.cpp:106] Iteration 21280, lr = 0.01
I0601 13:38:30.159668 24067 solver.cpp:237] Iteration 21300, loss = 4.24394
I0601 13:38:30.159720 24067 solver.cpp:253]     Train net output #0: loss = 4.25727 (* 1 = 4.25727 loss)
I0601 13:38:30.159736 24067 sgd_solver.cpp:106] Iteration 21300, lr = 0.01
I0601 13:38:35.638526 24067 solver.cpp:237] Iteration 21320, loss = 4.36162
I0601 13:38:35.638577 24067 solver.cpp:253]     Train net output #0: loss = 4.45955 (* 1 = 4.45955 loss)
I0601 13:38:35.638588 24067 sgd_solver.cpp:106] Iteration 21320, lr = 0.01
I0601 13:38:41.124770 24067 solver.cpp:237] Iteration 21340, loss = 4.31198
I0601 13:38:41.124979 24067 solver.cpp:253]     Train net output #0: loss = 4.55322 (* 1 = 4.55322 loss)
I0601 13:38:41.125011 24067 sgd_solver.cpp:106] Iteration 21340, lr = 0.01
I0601 13:38:46.605310 24067 solver.cpp:237] Iteration 21360, loss = 4.26557
I0601 13:38:46.605352 24067 solver.cpp:253]     Train net output #0: loss = 4.2295 (* 1 = 4.2295 loss)
I0601 13:38:46.605360 24067 sgd_solver.cpp:106] Iteration 21360, lr = 0.01
I0601 13:38:52.086719 24067 solver.cpp:237] Iteration 21380, loss = 4.21109
I0601 13:38:52.086761 24067 solver.cpp:253]     Train net output #0: loss = 4.29973 (* 1 = 4.29973 loss)
I0601 13:38:52.086768 24067 sgd_solver.cpp:106] Iteration 21380, lr = 0.01
I0601 13:38:57.569416 24067 solver.cpp:237] Iteration 21400, loss = 4.22946
I0601 13:38:57.569455 24067 solver.cpp:253]     Train net output #0: loss = 4.30186 (* 1 = 4.30186 loss)
I0601 13:38:57.569463 24067 sgd_solver.cpp:106] Iteration 21400, lr = 0.01
I0601 13:39:03.050623 24067 solver.cpp:237] Iteration 21420, loss = 4.24454
I0601 13:39:03.050654 24067 solver.cpp:253]     Train net output #0: loss = 4.16783 (* 1 = 4.16783 loss)
I0601 13:39:03.050662 24067 sgd_solver.cpp:106] Iteration 21420, lr = 0.01
I0601 13:39:08.537477 24067 solver.cpp:237] Iteration 21440, loss = 4.27107
I0601 13:39:08.537518 24067 solver.cpp:253]     Train net output #0: loss = 4.43931 (* 1 = 4.43931 loss)
I0601 13:39:08.537524 24067 sgd_solver.cpp:106] Iteration 21440, lr = 0.01
I0601 13:39:13.983286 24067 solver.cpp:237] Iteration 21460, loss = 4.2758
I0601 13:39:13.983451 24067 solver.cpp:253]     Train net output #0: loss = 4.12026 (* 1 = 4.12026 loss)
I0601 13:39:13.983460 24067 sgd_solver.cpp:106] Iteration 21460, lr = 0.01
I0601 13:39:19.461488 24067 solver.cpp:237] Iteration 21480, loss = 4.24424
I0601 13:39:19.461537 24067 solver.cpp:253]     Train net output #0: loss = 4.36808 (* 1 = 4.36808 loss)
I0601 13:39:19.461557 24067 sgd_solver.cpp:106] Iteration 21480, lr = 0.01
I0601 13:39:24.952388 24067 solver.cpp:237] Iteration 21500, loss = 4.29995
I0601 13:39:24.952438 24067 solver.cpp:253]     Train net output #0: loss = 4.40565 (* 1 = 4.40565 loss)
I0601 13:39:24.952446 24067 sgd_solver.cpp:106] Iteration 21500, lr = 0.01
I0601 13:39:30.419384 24067 solver.cpp:237] Iteration 21520, loss = 4.32639
I0601 13:39:30.419428 24067 solver.cpp:253]     Train net output #0: loss = 4.02633 (* 1 = 4.02633 loss)
I0601 13:39:30.419435 24067 sgd_solver.cpp:106] Iteration 21520, lr = 0.01
I0601 13:39:35.856861 24067 solver.cpp:237] Iteration 21540, loss = 4.20796
I0601 13:39:35.856910 24067 solver.cpp:253]     Train net output #0: loss = 4.1199 (* 1 = 4.1199 loss)
I0601 13:39:35.856917 24067 sgd_solver.cpp:106] Iteration 21540, lr = 0.01
I0601 13:39:41.294610 24067 solver.cpp:237] Iteration 21560, loss = 4.33598
I0601 13:39:41.294661 24067 solver.cpp:253]     Train net output #0: loss = 4.35113 (* 1 = 4.35113 loss)
I0601 13:39:41.294670 24067 sgd_solver.cpp:106] Iteration 21560, lr = 0.01
I0601 13:39:46.734251 24067 solver.cpp:237] Iteration 21580, loss = 4.24775
I0601 13:39:46.734490 24067 solver.cpp:253]     Train net output #0: loss = 4.27661 (* 1 = 4.27661 loss)
I0601 13:39:46.734511 24067 sgd_solver.cpp:106] Iteration 21580, lr = 0.01
I0601 13:39:52.216688 24067 solver.cpp:237] Iteration 21600, loss = 4.29149
I0601 13:39:52.216737 24067 solver.cpp:253]     Train net output #0: loss = 4.41766 (* 1 = 4.41766 loss)
I0601 13:39:52.216743 24067 sgd_solver.cpp:106] Iteration 21600, lr = 0.01
I0601 13:39:57.683356 24067 solver.cpp:237] Iteration 21620, loss = 4.28589
I0601 13:39:57.683399 24067 solver.cpp:253]     Train net output #0: loss = 4.18367 (* 1 = 4.18367 loss)
I0601 13:39:57.683405 24067 sgd_solver.cpp:106] Iteration 21620, lr = 0.01
I0601 13:40:03.171124 24067 solver.cpp:237] Iteration 21640, loss = 4.23644
I0601 13:40:03.171169 24067 solver.cpp:253]     Train net output #0: loss = 4.31808 (* 1 = 4.31808 loss)
I0601 13:40:03.171186 24067 sgd_solver.cpp:106] Iteration 21640, lr = 0.01
I0601 13:40:08.661864 24067 solver.cpp:237] Iteration 21660, loss = 4.24118
I0601 13:40:08.661906 24067 solver.cpp:253]     Train net output #0: loss = 4.1775 (* 1 = 4.1775 loss)
I0601 13:40:08.661911 24067 sgd_solver.cpp:106] Iteration 21660, lr = 0.01
I0601 13:40:14.114169 24067 solver.cpp:237] Iteration 21680, loss = 4.19505
I0601 13:40:14.114214 24067 solver.cpp:253]     Train net output #0: loss = 4.44712 (* 1 = 4.44712 loss)
I0601 13:40:14.114220 24067 sgd_solver.cpp:106] Iteration 21680, lr = 0.01
I0601 13:40:19.604152 24067 solver.cpp:237] Iteration 21700, loss = 4.35506
I0601 13:40:19.604441 24067 solver.cpp:253]     Train net output #0: loss = 4.27685 (* 1 = 4.27685 loss)
I0601 13:40:19.604463 24067 sgd_solver.cpp:106] Iteration 21700, lr = 0.01
I0601 13:40:25.096199 24067 solver.cpp:237] Iteration 21720, loss = 4.19032
I0601 13:40:25.096246 24067 solver.cpp:253]     Train net output #0: loss = 4.27988 (* 1 = 4.27988 loss)
I0601 13:40:25.096256 24067 sgd_solver.cpp:106] Iteration 21720, lr = 0.01
I0601 13:40:30.590503 24067 solver.cpp:237] Iteration 21740, loss = 4.27734
I0601 13:40:30.590551 24067 solver.cpp:253]     Train net output #0: loss = 4.26183 (* 1 = 4.26183 loss)
I0601 13:40:30.590561 24067 sgd_solver.cpp:106] Iteration 21740, lr = 0.01
I0601 13:40:36.083706 24067 solver.cpp:237] Iteration 21760, loss = 4.24914
I0601 13:40:36.083755 24067 solver.cpp:253]     Train net output #0: loss = 4.24104 (* 1 = 4.24104 loss)
I0601 13:40:36.083765 24067 sgd_solver.cpp:106] Iteration 21760, lr = 0.01
I0601 13:40:41.577368 24067 solver.cpp:237] Iteration 21780, loss = 4.26704
I0601 13:40:41.577422 24067 solver.cpp:253]     Train net output #0: loss = 4.13085 (* 1 = 4.13085 loss)
I0601 13:40:41.577433 24067 sgd_solver.cpp:106] Iteration 21780, lr = 0.01
I0601 13:40:47.065760 24067 solver.cpp:237] Iteration 21800, loss = 4.24084
I0601 13:40:47.065809 24067 solver.cpp:253]     Train net output #0: loss = 4.25803 (* 1 = 4.25803 loss)
I0601 13:40:47.065819 24067 sgd_solver.cpp:106] Iteration 21800, lr = 0.01
I0601 13:40:52.553804 24067 solver.cpp:237] Iteration 21820, loss = 4.27557
I0601 13:40:52.553997 24067 solver.cpp:253]     Train net output #0: loss = 4.1535 (* 1 = 4.1535 loss)
I0601 13:40:52.554008 24067 sgd_solver.cpp:106] Iteration 21820, lr = 0.01
I0601 13:40:58.044234 24067 solver.cpp:237] Iteration 21840, loss = 4.22483
I0601 13:40:58.044283 24067 solver.cpp:253]     Train net output #0: loss = 4.30728 (* 1 = 4.30728 loss)
I0601 13:40:58.044292 24067 sgd_solver.cpp:106] Iteration 21840, lr = 0.01
I0601 13:41:03.538729 24067 solver.cpp:237] Iteration 21860, loss = 4.30803
I0601 13:41:03.538775 24067 solver.cpp:253]     Train net output #0: loss = 4.15888 (* 1 = 4.15888 loss)
I0601 13:41:03.538782 24067 sgd_solver.cpp:106] Iteration 21860, lr = 0.01
I0601 13:41:09.026484 24067 solver.cpp:237] Iteration 21880, loss = 4.2517
I0601 13:41:09.026540 24067 solver.cpp:253]     Train net output #0: loss = 4.16343 (* 1 = 4.16343 loss)
I0601 13:41:09.026547 24067 sgd_solver.cpp:106] Iteration 21880, lr = 0.01
I0601 13:41:14.523080 24067 solver.cpp:237] Iteration 21900, loss = 4.23505
I0601 13:41:14.523126 24067 solver.cpp:253]     Train net output #0: loss = 4.07879 (* 1 = 4.07879 loss)
I0601 13:41:14.523134 24067 sgd_solver.cpp:106] Iteration 21900, lr = 0.01
I0601 13:41:20.016322 24067 solver.cpp:237] Iteration 21920, loss = 4.2333
I0601 13:41:20.016383 24067 solver.cpp:253]     Train net output #0: loss = 4.15343 (* 1 = 4.15343 loss)
I0601 13:41:20.016391 24067 sgd_solver.cpp:106] Iteration 21920, lr = 0.01
I0601 13:41:25.509788 24067 solver.cpp:237] Iteration 21940, loss = 4.19427
I0601 13:41:25.509960 24067 solver.cpp:253]     Train net output #0: loss = 4.3288 (* 1 = 4.3288 loss)
I0601 13:41:25.509971 24067 sgd_solver.cpp:106] Iteration 21940, lr = 0.01
I0601 13:41:31.003367 24067 solver.cpp:237] Iteration 21960, loss = 4.21086
I0601 13:41:31.003423 24067 solver.cpp:253]     Train net output #0: loss = 4.01894 (* 1 = 4.01894 loss)
I0601 13:41:31.003435 24067 sgd_solver.cpp:106] Iteration 21960, lr = 0.01
I0601 13:41:36.491554 24067 solver.cpp:237] Iteration 21980, loss = 4.27808
I0601 13:41:36.491603 24067 solver.cpp:253]     Train net output #0: loss = 4.14354 (* 1 = 4.14354 loss)
I0601 13:41:36.491611 24067 sgd_solver.cpp:106] Iteration 21980, lr = 0.01
I0601 13:41:41.901408 24067 solver.cpp:341] Iteration 22000, Testing net (#0)
I0601 13:42:10.066735 24067 blocking_queue.cpp:50] Data layer prefetch queue empty
I0601 13:42:13.274314 24067 solver.cpp:409]     Test net output #0: accuracy = 0.19672
I0601 13:42:13.274361 24067 solver.cpp:409]     Test net output #1: loss = 4.09716 (* 1 = 4.09716 loss)
I0601 13:42:13.355345 24067 solver.cpp:237] Iteration 22000, loss = 4.24635
I0601 13:42:13.355381 24067 solver.cpp:253]     Train net output #0: loss = 4.23956 (* 1 = 4.23956 loss)
I0601 13:42:13.355392 24067 sgd_solver.cpp:106] Iteration 22000, lr = 0.01
I0601 13:42:18.813496 24067 solver.cpp:237] Iteration 22020, loss = 4.21911
I0601 13:42:18.813571 24067 solver.cpp:253]     Train net output #0: loss = 4.1011 (* 1 = 4.1011 loss)
I0601 13:42:18.813585 24067 sgd_solver.cpp:106] Iteration 22020, lr = 0.01
I0601 13:42:24.230141 24067 solver.cpp:237] Iteration 22040, loss = 4.18221
I0601 13:42:24.230192 24067 solver.cpp:253]     Train net output #0: loss = 4.46351 (* 1 = 4.46351 loss)
I0601 13:42:24.230201 24067 sgd_solver.cpp:106] Iteration 22040, lr = 0.01
I0601 13:42:29.682927 24067 solver.cpp:237] Iteration 22060, loss = 4.25233
I0601 13:42:29.682978 24067 solver.cpp:253]     Train net output #0: loss = 4.39143 (* 1 = 4.39143 loss)
I0601 13:42:29.682987 24067 sgd_solver.cpp:106] Iteration 22060, lr = 0.01
I0601 13:42:35.143417 24067 solver.cpp:237] Iteration 22080, loss = 4.28771
I0601 13:42:35.143466 24067 solver.cpp:253]     Train net output #0: loss = 4.35227 (* 1 = 4.35227 loss)
I0601 13:42:35.143473 24067 sgd_solver.cpp:106] Iteration 22080, lr = 0.01
I0601 13:42:40.602325 24067 solver.cpp:237] Iteration 22100, loss = 4.22464
I0601 13:42:40.602480 24067 solver.cpp:253]     Train net output #0: loss = 4.05512 (* 1 = 4.05512 loss)
I0601 13:42:40.602490 24067 sgd_solver.cpp:106] Iteration 22100, lr = 0.01
I0601 13:42:46.066211 24067 solver.cpp:237] Iteration 22120, loss = 4.30654
I0601 13:42:46.066260 24067 solver.cpp:253]     Train net output #0: loss = 4.21343 (* 1 = 4.21343 loss)
I0601 13:42:46.066267 24067 sgd_solver.cpp:106] Iteration 22120, lr = 0.01
I0601 13:42:51.529949 24067 solver.cpp:237] Iteration 22140, loss = 4.29365
I0601 13:42:51.529997 24067 solver.cpp:253]     Train net output #0: loss = 4.18801 (* 1 = 4.18801 loss)
I0601 13:42:51.530006 24067 sgd_solver.cpp:106] Iteration 22140, lr = 0.01
I0601 13:42:56.998026 24067 solver.cpp:237] Iteration 22160, loss = 4.26075
I0601 13:42:56.998075 24067 solver.cpp:253]     Train net output #0: loss = 4.24263 (* 1 = 4.24263 loss)
I0601 13:42:56.998082 24067 sgd_solver.cpp:106] Iteration 22160, lr = 0.01
I0601 13:43:02.464031 24067 solver.cpp:237] Iteration 22180, loss = 4.27847
I0601 13:43:02.464081 24067 solver.cpp:253]     Train net output #0: loss = 4.20566 (* 1 = 4.20566 loss)
I0601 13:43:02.464088 24067 sgd_solver.cpp:106] Iteration 22180, lr = 0.01
I0601 13:43:07.938462 24067 solver.cpp:237] Iteration 22200, loss = 4.18776
I0601 13:43:07.938504 24067 solver.cpp:253]     Train net output #0: loss = 4.21391 (* 1 = 4.21391 loss)
I0601 13:43:07.938524 24067 sgd_solver.cpp:106] Iteration 22200, lr = 0.01
I0601 13:43:13.415472 24067 solver.cpp:237] Iteration 22220, loss = 4.19389
I0601 13:43:13.415711 24067 solver.cpp:253]     Train net output #0: loss = 4.372 (* 1 = 4.372 loss)
I0601 13:43:13.415735 24067 sgd_solver.cpp:106] Iteration 22220, lr = 0.01
I0601 13:43:18.947212 24067 solver.cpp:237] Iteration 22240, loss = 4.33883
I0601 13:43:18.947273 24067 solver.cpp:253]     Train net output #0: loss = 4.3184 (* 1 = 4.3184 loss)
I0601 13:43:18.947283 24067 sgd_solver.cpp:106] Iteration 22240, lr = 0.01
I0601 13:43:24.427335 24067 solver.cpp:237] Iteration 22260, loss = 4.33486
I0601 13:43:24.427386 24067 solver.cpp:253]     Train net output #0: loss = 4.32303 (* 1 = 4.32303 loss)
I0601 13:43:24.427394 24067 sgd_solver.cpp:106] Iteration 22260, lr = 0.01
I0601 13:43:29.909235 24067 solver.cpp:237] Iteration 22280, loss = 4.29813
I0601 13:43:29.909276 24067 solver.cpp:253]     Train net output #0: loss = 4.25839 (* 1 = 4.25839 loss)
I0601 13:43:29.909282 24067 sgd_solver.cpp:106] Iteration 22280, lr = 0.01
I0601 13:43:35.387436 24067 solver.cpp:237] Iteration 22300, loss = 4.26707
I0601 13:43:35.387477 24067 solver.cpp:253]     Train net output #0: loss = 4.45937 (* 1 = 4.45937 loss)
I0601 13:43:35.387482 24067 sgd_solver.cpp:106] Iteration 22300, lr = 0.01
I0601 13:43:40.863961 24067 solver.cpp:237] Iteration 22320, loss = 4.29186
I0601 13:43:40.864008 24067 solver.cpp:253]     Train net output #0: loss = 4.22231 (* 1 = 4.22231 loss)
I0601 13:43:40.864013 24067 sgd_solver.cpp:106] Iteration 22320, lr = 0.01
I0601 13:43:46.345036 24067 solver.cpp:237] Iteration 22340, loss = 4.24615
I0601 13:43:46.345249 24067 solver.cpp:253]     Train net output #0: loss = 4.2803 (* 1 = 4.2803 loss)
I0601 13:43:46.345278 24067 sgd_solver.cpp:106] Iteration 22340, lr = 0.01
I0601 13:43:51.833950 24067 solver.cpp:237] Iteration 22360, loss = 4.24171
I0601 13:43:51.833997 24067 solver.cpp:253]     Train net output #0: loss = 4.23813 (* 1 = 4.23813 loss)
I0601 13:43:51.834004 24067 sgd_solver.cpp:106] Iteration 22360, lr = 0.01
I0601 13:43:57.317867 24067 solver.cpp:237] Iteration 22380, loss = 4.28735
I0601 13:43:57.317912 24067 solver.cpp:253]     Train net output #0: loss = 4.31627 (* 1 = 4.31627 loss)
I0601 13:43:57.317919 24067 sgd_solver.cpp:106] Iteration 22380, lr = 0.01
I0601 13:44:02.795114 24067 solver.cpp:237] Iteration 22400, loss = 4.31516
I0601 13:44:02.795167 24067 solver.cpp:253]     Train net output #0: loss = 4.18741 (* 1 = 4.18741 loss)
I0601 13:44:02.795174 24067 sgd_solver.cpp:106] Iteration 22400, lr = 0.01
I0601 13:44:08.286584 24067 solver.cpp:237] Iteration 22420, loss = 4.26784
I0601 13:44:08.286617 24067 solver.cpp:253]     Train net output #0: loss = 4.21861 (* 1 = 4.21861 loss)
I0601 13:44:08.286623 24067 sgd_solver.cpp:106] Iteration 22420, lr = 0.01
I0601 13:44:13.766435 24067 solver.cpp:237] Iteration 22440, loss = 4.1855
I0601 13:44:13.766479 24067 solver.cpp:253]     Train net output #0: loss = 4.35851 (* 1 = 4.35851 loss)
I0601 13:44:13.766486 24067 sgd_solver.cpp:106] Iteration 22440, lr = 0.01
I0601 13:44:19.249598 24067 solver.cpp:237] Iteration 22460, loss = 4.24696
I0601 13:44:19.249799 24067 solver.cpp:253]     Train net output #0: loss = 4.33356 (* 1 = 4.33356 loss)
I0601 13:44:19.249825 24067 sgd_solver.cpp:106] Iteration 22460, lr = 0.01
I0601 13:44:24.734493 24067 solver.cpp:237] Iteration 22480, loss = 4.27331
I0601 13:44:24.734544 24067 solver.cpp:253]     Train net output #0: loss = 4.50992 (* 1 = 4.50992 loss)
I0601 13:44:24.734550 24067 sgd_solver.cpp:106] Iteration 22480, lr = 0.01
I0601 13:44:30.223608 24067 solver.cpp:237] Iteration 22500, loss = 4.25586
I0601 13:44:30.223649 24067 solver.cpp:253]     Train net output #0: loss = 4.18104 (* 1 = 4.18104 loss)
I0601 13:44:30.223654 24067 sgd_solver.cpp:106] Iteration 22500, lr = 0.01
I0601 13:44:35.707139 24067 solver.cpp:237] Iteration 22520, loss = 4.22939
I0601 13:44:35.707195 24067 solver.cpp:253]     Train net output #0: loss = 4.45817 (* 1 = 4.45817 loss)
I0601 13:44:35.707202 24067 sgd_solver.cpp:106] Iteration 22520, lr = 0.01
I0601 13:44:41.194561 24067 solver.cpp:237] Iteration 22540, loss = 4.21518
I0601 13:44:41.194600 24067 solver.cpp:253]     Train net output #0: loss = 4.12983 (* 1 = 4.12983 loss)
I0601 13:44:41.194607 24067 sgd_solver.cpp:106] Iteration 22540, lr = 0.01
I0601 13:44:46.680546 24067 solver.cpp:237] Iteration 22560, loss = 4.20777
I0601 13:44:46.680585 24067 solver.cpp:253]     Train net output #0: loss = 4.35033 (* 1 = 4.35033 loss)
I0601 13:44:46.680593 24067 sgd_solver.cpp:106] Iteration 22560, lr = 0.01
I0601 13:44:52.169934 24067 solver.cpp:237] Iteration 22580, loss = 4.24107
I0601 13:44:52.170146 24067 solver.cpp:253]     Train net output #0: loss = 3.99497 (* 1 = 3.99497 loss)
I0601 13:44:52.170176 24067 sgd_solver.cpp:106] Iteration 22580, lr = 0.01
I0601 13:44:57.660158 24067 solver.cpp:237] Iteration 22600, loss = 4.19258
I0601 13:44:57.660209 24067 solver.cpp:253]     Train net output #0: loss = 4.33207 (* 1 = 4.33207 loss)
I0601 13:44:57.660219 24067 sgd_solver.cpp:106] Iteration 22600, lr = 0.01
I0601 13:45:03.153921 24067 solver.cpp:237] Iteration 22620, loss = 4.22857
I0601 13:45:03.153971 24067 solver.cpp:253]     Train net output #0: loss = 4.3912 (* 1 = 4.3912 loss)
I0601 13:45:03.153980 24067 sgd_solver.cpp:106] Iteration 22620, lr = 0.01
I0601 13:45:08.649782 24067 solver.cpp:237] Iteration 22640, loss = 4.25743
I0601 13:45:08.649821 24067 solver.cpp:253]     Train net output #0: loss = 4.51464 (* 1 = 4.51464 loss)
I0601 13:45:08.649832 24067 sgd_solver.cpp:106] Iteration 22640, lr = 0.01
I0601 13:45:14.140576 24067 solver.cpp:237] Iteration 22660, loss = 4.28421
I0601 13:45:14.140612 24067 solver.cpp:253]     Train net output #0: loss = 4.61137 (* 1 = 4.61137 loss)
I0601 13:45:14.140621 24067 sgd_solver.cpp:106] Iteration 22660, lr = 0.01
I0601 13:45:19.638219 24067 solver.cpp:237] Iteration 22680, loss = 4.28506
I0601 13:45:19.638269 24067 solver.cpp:253]     Train net output #0: loss = 4.05611 (* 1 = 4.05611 loss)
I0601 13:45:19.638285 24067 sgd_solver.cpp:106] Iteration 22680, lr = 0.01
I0601 13:45:25.129993 24067 solver.cpp:237] Iteration 22700, loss = 4.27512
I0601 13:45:25.130136 24067 solver.cpp:253]     Train net output #0: loss = 4.33818 (* 1 = 4.33818 loss)
I0601 13:45:25.130146 24067 sgd_solver.cpp:106] Iteration 22700, lr = 0.01
I0601 13:45:30.614950 24067 solver.cpp:237] Iteration 22720, loss = 4.2562
I0601 13:45:30.615000 24067 solver.cpp:253]     Train net output #0: loss = 4.18198 (* 1 = 4.18198 loss)
I0601 13:45:30.615010 24067 sgd_solver.cpp:106] Iteration 22720, lr = 0.01
I0601 13:45:36.106395 24067 solver.cpp:237] Iteration 22740, loss = 4.24771
I0601 13:45:36.106443 24067 solver.cpp:253]     Train net output #0: loss = 4.34487 (* 1 = 4.34487 loss)
I0601 13:45:36.106452 24067 sgd_solver.cpp:106] Iteration 22740, lr = 0.01
I0601 13:45:41.595705 24067 solver.cpp:237] Iteration 22760, loss = 4.22484
I0601 13:45:41.595753 24067 solver.cpp:253]     Train net output #0: loss = 4.31331 (* 1 = 4.31331 loss)
I0601 13:45:41.595762 24067 sgd_solver.cpp:106] Iteration 22760, lr = 0.01
I0601 13:45:47.085896 24067 solver.cpp:237] Iteration 22780, loss = 4.27225
I0601 13:45:47.085945 24067 solver.cpp:253]     Train net output #0: loss = 4.35845 (* 1 = 4.35845 loss)
I0601 13:45:47.085954 24067 sgd_solver.cpp:106] Iteration 22780, lr = 0.01
I0601 13:45:52.573420 24067 solver.cpp:237] Iteration 22800, loss = 4.28736
I0601 13:45:52.573465 24067 solver.cpp:253]     Train net output #0: loss = 4.44215 (* 1 = 4.44215 loss)
I0601 13:45:52.573474 24067 sgd_solver.cpp:106] Iteration 22800, lr = 0.01
I0601 13:45:58.065507 24067 solver.cpp:237] Iteration 22820, loss = 4.28732
I0601 13:45:58.065600 24067 solver.cpp:253]     Train net output #0: loss = 4.21606 (* 1 = 4.21606 loss)
I0601 13:45:58.065610 24067 sgd_solver.cpp:106] Iteration 22820, lr = 0.01
I0601 13:46:03.554337 24067 solver.cpp:237] Iteration 22840, loss = 4.19839
I0601 13:46:03.554383 24067 solver.cpp:253]     Train net output #0: loss = 4.56574 (* 1 = 4.56574 loss)
I0601 13:46:03.554390 24067 sgd_solver.cpp:106] Iteration 22840, lr = 0.01
I0601 13:46:09.046511 24067 solver.cpp:237] Iteration 22860, loss = 4.2849
I0601 13:46:09.046545 24067 solver.cpp:253]     Train net output #0: loss = 4.48018 (* 1 = 4.48018 loss)
I0601 13:46:09.046555 24067 sgd_solver.cpp:106] Iteration 22860, lr = 0.01
I0601 13:46:14.538841 24067 solver.cpp:237] Iteration 22880, loss = 4.27966
I0601 13:46:14.538887 24067 solver.cpp:253]     Train net output #0: loss = 4.41264 (* 1 = 4.41264 loss)
I0601 13:46:14.538895 24067 sgd_solver.cpp:106] Iteration 22880, lr = 0.01
I0601 13:46:20.034109 24067 solver.cpp:237] Iteration 22900, loss = 4.20908
I0601 13:46:20.034157 24067 solver.cpp:253]     Train net output #0: loss = 4.22691 (* 1 = 4.22691 loss)
I0601 13:46:20.034167 24067 sgd_solver.cpp:106] Iteration 22900, lr = 0.01
I0601 13:46:25.523382 24067 solver.cpp:237] Iteration 22920, loss = 4.25783
I0601 13:46:25.523434 24067 solver.cpp:253]     Train net output #0: loss = 4.2493 (* 1 = 4.2493 loss)
I0601 13:46:25.523443 24067 sgd_solver.cpp:106] Iteration 22920, lr = 0.01
I0601 13:46:31.037816 24067 solver.cpp:237] Iteration 22940, loss = 4.30976
I0601 13:46:31.038009 24067 solver.cpp:253]     Train net output #0: loss = 4.17383 (* 1 = 4.17383 loss)
I0601 13:46:31.038025 24067 sgd_solver.cpp:106] Iteration 22940, lr = 0.01
I0601 13:46:36.529598 24067 solver.cpp:237] Iteration 22960, loss = 4.2645
I0601 13:46:36.529645 24067 solver.cpp:253]     Train net output #0: loss = 4.47436 (* 1 = 4.47436 loss)
I0601 13:46:36.529651 24067 sgd_solver.cpp:106] Iteration 22960, lr = 0.01
I0601 13:46:42.018563 24067 solver.cpp:237] Iteration 22980, loss = 4.2679
I0601 13:46:42.018612 24067 solver.cpp:253]     Train net output #0: loss = 4.15841 (* 1 = 4.15841 loss)
I0601 13:46:42.018630 24067 sgd_solver.cpp:106] Iteration 22980, lr = 0.01
I0601 13:46:47.426822 24067 solver.cpp:341] Iteration 23000, Testing net (#0)
I0601 13:47:12.996031 24067 blocking_queue.cpp:50] Data layer prefetch queue empty
I0601 13:47:20.882709 24067 solver.cpp:409]     Test net output #0: accuracy = 0.1961
I0601 13:47:20.882752 24067 solver.cpp:409]     Test net output #1: loss = 4.12274 (* 1 = 4.12274 loss)
I0601 13:47:20.963424 24067 solver.cpp:237] Iteration 23000, loss = 4.24542
I0601 13:47:20.963466 24067 solver.cpp:253]     Train net output #0: loss = 4.17859 (* 1 = 4.17859 loss)
I0601 13:47:20.963475 24067 sgd_solver.cpp:106] Iteration 23000, lr = 0.01
I0601 13:47:26.399988 24067 solver.cpp:237] Iteration 23020, loss = 4.22327
I0601 13:47:26.400035 24067 solver.cpp:253]     Train net output #0: loss = 3.91073 (* 1 = 3.91073 loss)
I0601 13:47:26.400043 24067 sgd_solver.cpp:106] Iteration 23020, lr = 0.01
I0601 13:47:31.843807 24067 solver.cpp:237] Iteration 23040, loss = 4.2565
I0601 13:47:31.843857 24067 solver.cpp:253]     Train net output #0: loss = 4.43093 (* 1 = 4.43093 loss)
I0601 13:47:31.843866 24067 sgd_solver.cpp:106] Iteration 23040, lr = 0.01
I0601 13:47:37.296800 24067 solver.cpp:237] Iteration 23060, loss = 4.21228
I0601 13:47:37.296846 24067 solver.cpp:253]     Train net output #0: loss = 4.35395 (* 1 = 4.35395 loss)
I0601 13:47:37.296854 24067 sgd_solver.cpp:106] Iteration 23060, lr = 0.01
I0601 13:47:42.755771 24067 solver.cpp:237] Iteration 23080, loss = 4.24517
I0601 13:47:42.755827 24067 solver.cpp:253]     Train net output #0: loss = 4.34601 (* 1 = 4.34601 loss)
I0601 13:47:42.755841 24067 sgd_solver.cpp:106] Iteration 23080, lr = 0.01
I0601 13:47:48.212152 24067 solver.cpp:237] Iteration 23100, loss = 4.29235
I0601 13:47:48.212348 24067 solver.cpp:253]     Train net output #0: loss = 4.23147 (* 1 = 4.23147 loss)
I0601 13:47:48.212362 24067 sgd_solver.cpp:106] Iteration 23100, lr = 0.01
I0601 13:47:53.634956 24067 solver.cpp:237] Iteration 23120, loss = 4.29104
I0601 13:47:53.635011 24067 solver.cpp:253]     Train net output #0: loss = 4.48075 (* 1 = 4.48075 loss)
I0601 13:47:53.635022 24067 sgd_solver.cpp:106] Iteration 23120, lr = 0.01
I0601 13:47:59.051615 24067 solver.cpp:237] Iteration 23140, loss = 4.30741
I0601 13:47:59.051676 24067 solver.cpp:253]     Train net output #0: loss = 4.09665 (* 1 = 4.09665 loss)
I0601 13:47:59.051687 24067 sgd_solver.cpp:106] Iteration 23140, lr = 0.01
I0601 13:48:04.471755 24067 solver.cpp:237] Iteration 23160, loss = 4.27114
I0601 13:48:04.471803 24067 solver.cpp:253]     Train net output #0: loss = 4.07057 (* 1 = 4.07057 loss)
I0601 13:48:04.471812 24067 sgd_solver.cpp:106] Iteration 23160, lr = 0.01
I0601 13:48:09.893110 24067 solver.cpp:237] Iteration 23180, loss = 4.2206
I0601 13:48:09.893159 24067 solver.cpp:253]     Train net output #0: loss = 4.14955 (* 1 = 4.14955 loss)
I0601 13:48:09.893167 24067 sgd_solver.cpp:106] Iteration 23180, lr = 0.01
I0601 13:48:15.330502 24067 solver.cpp:237] Iteration 23200, loss = 4.21612
I0601 13:48:15.330556 24067 solver.cpp:253]     Train net output #0: loss = 4.42135 (* 1 = 4.42135 loss)
I0601 13:48:15.330567 24067 sgd_solver.cpp:106] Iteration 23200, lr = 0.01
I0601 13:48:20.800846 24067 solver.cpp:237] Iteration 23220, loss = 4.25815
I0601 13:48:20.801031 24067 solver.cpp:253]     Train net output #0: loss = 4.08236 (* 1 = 4.08236 loss)
I0601 13:48:20.801043 24067 sgd_solver.cpp:106] Iteration 23220, lr = 0.01
I0601 13:48:26.273517 24067 solver.cpp:237] Iteration 23240, loss = 4.27894
I0601 13:48:26.273566 24067 solver.cpp:253]     Train net output #0: loss = 4.25755 (* 1 = 4.25755 loss)
I0601 13:48:26.273576 24067 sgd_solver.cpp:106] Iteration 23240, lr = 0.01
I0601 13:48:31.754230 24067 solver.cpp:237] Iteration 23260, loss = 4.24391
I0601 13:48:31.754290 24067 solver.cpp:253]     Train net output #0: loss = 4.30257 (* 1 = 4.30257 loss)
I0601 13:48:31.754302 24067 sgd_solver.cpp:106] Iteration 23260, lr = 0.01
I0601 13:48:37.232385 24067 solver.cpp:237] Iteration 23280, loss = 4.22372
I0601 13:48:37.232460 24067 solver.cpp:253]     Train net output #0: loss = 4.16316 (* 1 = 4.16316 loss)
I0601 13:48:37.232471 24067 sgd_solver.cpp:106] Iteration 23280, lr = 0.01
I0601 13:48:42.704306 24067 solver.cpp:237] Iteration 23300, loss = 4.29033
I0601 13:48:42.704356 24067 solver.cpp:253]     Train net output #0: loss = 4.23838 (* 1 = 4.23838 loss)
I0601 13:48:42.704365 24067 sgd_solver.cpp:106] Iteration 23300, lr = 0.01
I0601 13:48:48.190268 24067 solver.cpp:237] Iteration 23320, loss = 4.26226
I0601 13:48:48.190317 24067 solver.cpp:253]     Train net output #0: loss = 4.5644 (* 1 = 4.5644 loss)
I0601 13:48:48.190326 24067 sgd_solver.cpp:106] Iteration 23320, lr = 0.01
I0601 13:48:53.673338 24067 solver.cpp:237] Iteration 23340, loss = 4.16755
I0601 13:48:53.673509 24067 solver.cpp:253]     Train net output #0: loss = 4.35436 (* 1 = 4.35436 loss)
I0601 13:48:53.673521 24067 sgd_solver.cpp:106] Iteration 23340, lr = 0.01
I0601 13:48:59.159688 24067 solver.cpp:237] Iteration 23360, loss = 4.24478
I0601 13:48:59.159742 24067 solver.cpp:253]     Train net output #0: loss = 4.16637 (* 1 = 4.16637 loss)
I0601 13:48:59.159754 24067 sgd_solver.cpp:106] Iteration 23360, lr = 0.01
I0601 13:49:04.643169 24067 solver.cpp:237] Iteration 23380, loss = 4.28434
I0601 13:49:04.643218 24067 solver.cpp:253]     Train net output #0: loss = 4.46368 (* 1 = 4.46368 loss)
I0601 13:49:04.643229 24067 sgd_solver.cpp:106] Iteration 23380, lr = 0.01
I0601 13:49:10.125180 24067 solver.cpp:237] Iteration 23400, loss = 4.22627
I0601 13:49:10.125239 24067 solver.cpp:253]     Train net output #0: loss = 4.09008 (* 1 = 4.09008 loss)
I0601 13:49:10.125249 24067 sgd_solver.cpp:106] Iteration 23400, lr = 0.01
I0601 13:49:15.611470 24067 solver.cpp:237] Iteration 23420, loss = 4.23518
I0601 13:49:15.611522 24067 solver.cpp:253]     Train net output #0: loss = 4.507 (* 1 = 4.507 loss)
I0601 13:49:15.611532 24067 sgd_solver.cpp:106] Iteration 23420, lr = 0.01
I0601 13:49:21.103368 24067 solver.cpp:237] Iteration 23440, loss = 4.20742
I0601 13:49:21.103420 24067 solver.cpp:253]     Train net output #0: loss = 4.3935 (* 1 = 4.3935 loss)
I0601 13:49:21.103428 24067 sgd_solver.cpp:106] Iteration 23440, lr = 0.01
I0601 13:49:26.590778 24067 solver.cpp:237] Iteration 23460, loss = 4.18148
I0601 13:49:26.591025 24067 solver.cpp:253]     Train net output #0: loss = 4.00789 (* 1 = 4.00789 loss)
I0601 13:49:26.591044 24067 sgd_solver.cpp:106] Iteration 23460, lr = 0.01
I0601 13:49:32.043346 24067 solver.cpp:237] Iteration 23480, loss = 4.24424
I0601 13:49:32.043393 24067 solver.cpp:253]     Train net output #0: loss = 4.38379 (* 1 = 4.38379 loss)
I0601 13:49:32.043401 24067 sgd_solver.cpp:106] Iteration 23480, lr = 0.01
I0601 13:49:37.526423 24067 solver.cpp:237] Iteration 23500, loss = 4.18868
I0601 13:49:37.526469 24067 solver.cpp:253]     Train net output #0: loss = 4.11067 (* 1 = 4.11067 loss)
I0601 13:49:37.526475 24067 sgd_solver.cpp:106] Iteration 23500, lr = 0.01
I0601 13:49:43.010943 24067 solver.cpp:237] Iteration 23520, loss = 4.17809
I0601 13:49:43.011000 24067 solver.cpp:253]     Train net output #0: loss = 4.08282 (* 1 = 4.08282 loss)
I0601 13:49:43.011009 24067 sgd_solver.cpp:106] Iteration 23520, lr = 0.01
I0601 13:49:48.463366 24067 solver.cpp:237] Iteration 23540, loss = 4.23025
I0601 13:49:48.463409 24067 solver.cpp:253]     Train net output #0: loss = 4.0176 (* 1 = 4.0176 loss)
I0601 13:49:48.463416 24067 sgd_solver.cpp:106] Iteration 23540, lr = 0.01
I0601 13:49:53.898591 24067 solver.cpp:237] Iteration 23560, loss = 4.25114
I0601 13:49:53.898643 24067 solver.cpp:253]     Train net output #0: loss = 4.47861 (* 1 = 4.47861 loss)
I0601 13:49:53.898649 24067 sgd_solver.cpp:106] Iteration 23560, lr = 0.01
I0601 13:49:59.336247 24067 solver.cpp:237] Iteration 23580, loss = 4.27366
I0601 13:49:59.336468 24067 solver.cpp:253]     Train net output #0: loss = 4.52519 (* 1 = 4.52519 loss)
I0601 13:49:59.336486 24067 sgd_solver.cpp:106] Iteration 23580, lr = 0.01
I0601 13:50:04.799055 24067 solver.cpp:237] Iteration 23600, loss = 4.14806
I0601 13:50:04.799098 24067 solver.cpp:253]     Train net output #0: loss = 4.13356 (* 1 = 4.13356 loss)
I0601 13:50:04.799104 24067 sgd_solver.cpp:106] Iteration 23600, lr = 0.01
I0601 13:50:10.281381 24067 solver.cpp:237] Iteration 23620, loss = 4.17978
I0601 13:50:10.281447 24067 solver.cpp:253]     Train net output #0: loss = 4.05888 (* 1 = 4.05888 loss)
I0601 13:50:10.281453 24067 sgd_solver.cpp:106] Iteration 23620, lr = 0.01
I0601 13:50:15.770313 24067 solver.cpp:237] Iteration 23640, loss = 4.24165
I0601 13:50:15.770364 24067 solver.cpp:253]     Train net output #0: loss = 4.27707 (* 1 = 4.27707 loss)
I0601 13:50:15.770370 24067 sgd_solver.cpp:106] Iteration 23640, lr = 0.01
I0601 13:50:21.248320 24067 solver.cpp:237] Iteration 23660, loss = 4.20274
I0601 13:50:21.248374 24067 solver.cpp:253]     Train net output #0: loss = 4.33552 (* 1 = 4.33552 loss)
I0601 13:50:21.248381 24067 sgd_solver.cpp:106] Iteration 23660, lr = 0.01
I0601 13:50:26.731175 24067 solver.cpp:237] Iteration 23680, loss = 4.18916
I0601 13:50:26.731215 24067 solver.cpp:253]     Train net output #0: loss = 4.23525 (* 1 = 4.23525 loss)
I0601 13:50:26.731222 24067 sgd_solver.cpp:106] Iteration 23680, lr = 0.01
I0601 13:50:32.221736 24067 solver.cpp:237] Iteration 23700, loss = 4.21723
I0601 13:50:32.221973 24067 solver.cpp:253]     Train net output #0: loss = 4.10892 (* 1 = 4.10892 loss)
I0601 13:50:32.221999 24067 sgd_solver.cpp:106] Iteration 23700, lr = 0.01
I0601 13:50:37.709004 24067 solver.cpp:237] Iteration 23720, loss = 4.21946
I0601 13:50:37.709051 24067 solver.cpp:253]     Train net output #0: loss = 4.24426 (* 1 = 4.24426 loss)
I0601 13:50:37.709060 24067 sgd_solver.cpp:106] Iteration 23720, lr = 0.01
I0601 13:50:43.192600 24067 solver.cpp:237] Iteration 23740, loss = 4.18753
I0601 13:50:43.192649 24067 solver.cpp:253]     Train net output #0: loss = 3.95794 (* 1 = 3.95794 loss)
I0601 13:50:43.192659 24067 sgd_solver.cpp:106] Iteration 23740, lr = 0.01
I0601 13:50:48.681560 24067 solver.cpp:237] Iteration 23760, loss = 4.23942
I0601 13:50:48.681608 24067 solver.cpp:253]     Train net output #0: loss = 4.17851 (* 1 = 4.17851 loss)
I0601 13:50:48.681617 24067 sgd_solver.cpp:106] Iteration 23760, lr = 0.01
I0601 13:50:54.171998 24067 solver.cpp:237] Iteration 23780, loss = 4.19696
I0601 13:50:54.172045 24067 solver.cpp:253]     Train net output #0: loss = 4.27871 (* 1 = 4.27871 loss)
I0601 13:50:54.172054 24067 sgd_solver.cpp:106] Iteration 23780, lr = 0.01
I0601 13:50:59.662152 24067 solver.cpp:237] Iteration 23800, loss = 4.25629
I0601 13:50:59.662201 24067 solver.cpp:253]     Train net output #0: loss = 4.11087 (* 1 = 4.11087 loss)
I0601 13:50:59.662211 24067 sgd_solver.cpp:106] Iteration 23800, lr = 0.01
I0601 13:51:05.148792 24067 solver.cpp:237] Iteration 23820, loss = 4.23783
I0601 13:51:05.149006 24067 solver.cpp:253]     Train net output #0: loss = 4.3298 (* 1 = 4.3298 loss)
I0601 13:51:05.149036 24067 sgd_solver.cpp:106] Iteration 23820, lr = 0.01
I0601 13:51:10.605042 24067 solver.cpp:237] Iteration 23840, loss = 4.19225
I0601 13:51:10.605084 24067 solver.cpp:253]     Train net output #0: loss = 4.50818 (* 1 = 4.50818 loss)
I0601 13:51:10.605090 24067 sgd_solver.cpp:106] Iteration 23840, lr = 0.01
I0601 13:51:16.040659 24067 solver.cpp:237] Iteration 23860, loss = 4.26087
I0601 13:51:16.040707 24067 solver.cpp:253]     Train net output #0: loss = 4.24693 (* 1 = 4.24693 loss)
I0601 13:51:16.040714 24067 sgd_solver.cpp:106] Iteration 23860, lr = 0.01
I0601 13:51:21.488746 24067 solver.cpp:237] Iteration 23880, loss = 4.19436
I0601 13:51:21.488783 24067 solver.cpp:253]     Train net output #0: loss = 4.6194 (* 1 = 4.6194 loss)
I0601 13:51:21.488788 24067 sgd_solver.cpp:106] Iteration 23880, lr = 0.01
I0601 13:51:26.926460 24067 solver.cpp:237] Iteration 23900, loss = 4.24767
I0601 13:51:26.926498 24067 solver.cpp:253]     Train net output #0: loss = 4.2259 (* 1 = 4.2259 loss)
I0601 13:51:26.926504 24067 sgd_solver.cpp:106] Iteration 23900, lr = 0.01
I0601 13:51:32.363960 24067 solver.cpp:237] Iteration 23920, loss = 4.28203
I0601 13:51:32.363998 24067 solver.cpp:253]     Train net output #0: loss = 4.46823 (* 1 = 4.46823 loss)
I0601 13:51:32.364003 24067 sgd_solver.cpp:106] Iteration 23920, lr = 0.01
I0601 13:51:37.805356 24067 solver.cpp:237] Iteration 23940, loss = 4.20008
I0601 13:51:37.805560 24067 solver.cpp:253]     Train net output #0: loss = 4.10947 (* 1 = 4.10947 loss)
I0601 13:51:37.805586 24067 sgd_solver.cpp:106] Iteration 23940, lr = 0.01
I0601 13:51:43.276043 24067 solver.cpp:237] Iteration 23960, loss = 4.20973
I0601 13:51:43.276094 24067 solver.cpp:253]     Train net output #0: loss = 4.23888 (* 1 = 4.23888 loss)
I0601 13:51:43.276104 24067 sgd_solver.cpp:106] Iteration 23960, lr = 0.01
I0601 13:51:48.760758 24067 solver.cpp:237] Iteration 23980, loss = 4.14801
I0601 13:51:48.760803 24067 solver.cpp:253]     Train net output #0: loss = 4.41618 (* 1 = 4.41618 loss)
I0601 13:51:48.760812 24067 sgd_solver.cpp:106] Iteration 23980, lr = 0.01
I0601 13:51:54.133532 24067 solver.cpp:341] Iteration 24000, Testing net (#0)
I0601 13:52:18.854076 24067 blocking_queue.cpp:50] Data layer prefetch queue empty
I0601 13:52:26.499886 24067 solver.cpp:409]     Test net output #0: accuracy = 0.20726
I0601 13:52:26.499945 24067 solver.cpp:409]     Test net output #1: loss = 4.04741 (* 1 = 4.04741 loss)
I0601 13:52:26.583362 24067 solver.cpp:237] Iteration 24000, loss = 4.26928
I0601 13:52:26.583413 24067 solver.cpp:253]     Train net output #0: loss = 4.3883 (* 1 = 4.3883 loss)
I0601 13:52:26.583425 24067 sgd_solver.cpp:106] Iteration 24000, lr = 0.01
I0601 13:52:32.006620 24067 solver.cpp:237] Iteration 24020, loss = 4.23874
I0601 13:52:32.006669 24067 solver.cpp:253]     Train net output #0: loss = 4.57942 (* 1 = 4.57942 loss)
I0601 13:52:32.006677 24067 sgd_solver.cpp:106] Iteration 24020, lr = 0.01
I0601 13:52:37.423207 24067 solver.cpp:237] Iteration 24040, loss = 4.21119
I0601 13:52:37.423266 24067 solver.cpp:253]     Train net output #0: loss = 4.26418 (* 1 = 4.26418 loss)
I0601 13:52:37.423274 24067 sgd_solver.cpp:106] Iteration 24040, lr = 0.01
I0601 13:52:42.837613 24067 solver.cpp:237] Iteration 24060, loss = 4.22858
I0601 13:52:42.837663 24067 solver.cpp:253]     Train net output #0: loss = 4.24044 (* 1 = 4.24044 loss)
I0601 13:52:42.837671 24067 sgd_solver.cpp:106] Iteration 24060, lr = 0.01
I0601 13:52:48.270347 24067 solver.cpp:237] Iteration 24080, loss = 4.20266
I0601 13:52:48.270392 24067 solver.cpp:253]     Train net output #0: loss = 4.27293 (* 1 = 4.27293 loss)
I0601 13:52:48.270400 24067 sgd_solver.cpp:106] Iteration 24080, lr = 0.01
I0601 13:52:53.680050 24067 solver.cpp:237] Iteration 24100, loss = 4.16219
I0601 13:52:53.680279 24067 solver.cpp:253]     Train net output #0: loss = 4.2684 (* 1 = 4.2684 loss)
I0601 13:52:53.680312 24067 sgd_solver.cpp:106] Iteration 24100, lr = 0.01
I0601 13:52:59.090585 24067 solver.cpp:237] Iteration 24120, loss = 4.20347
I0601 13:52:59.090638 24067 solver.cpp:253]     Train net output #0: loss = 4.44432 (* 1 = 4.44432 loss)
I0601 13:52:59.090646 24067 sgd_solver.cpp:106] Iteration 24120, lr = 0.01
I0601 13:53:04.552938 24067 solver.cpp:237] Iteration 24140, loss = 4.23866
I0601 13:53:04.552983 24067 solver.cpp:253]     Train net output #0: loss = 4.21036 (* 1 = 4.21036 loss)
I0601 13:53:04.552995 24067 sgd_solver.cpp:106] Iteration 24140, lr = 0.01
I0601 13:53:10.015342 24067 solver.cpp:237] Iteration 24160, loss = 4.13472
I0601 13:53:10.015386 24067 solver.cpp:253]     Train net output #0: loss = 4.17071 (* 1 = 4.17071 loss)
I0601 13:53:10.015398 24067 sgd_solver.cpp:106] Iteration 24160, lr = 0.01
I0601 13:53:15.480573 24067 solver.cpp:237] Iteration 24180, loss = 4.22588
I0601 13:53:15.480648 24067 solver.cpp:253]     Train net output #0: loss = 4.1563 (* 1 = 4.1563 loss)
I0601 13:53:15.480656 24067 sgd_solver.cpp:106] Iteration 24180, lr = 0.01
I0601 13:53:20.944962 24067 solver.cpp:237] Iteration 24200, loss = 4.18801
I0601 13:53:20.945015 24067 solver.cpp:253]     Train net output #0: loss = 4.12102 (* 1 = 4.12102 loss)
I0601 13:53:20.945024 24067 sgd_solver.cpp:106] Iteration 24200, lr = 0.01
I0601 13:53:26.400208 24067 solver.cpp:237] Iteration 24220, loss = 4.21237
I0601 13:53:26.400400 24067 solver.cpp:253]     Train net output #0: loss = 4.45489 (* 1 = 4.45489 loss)
I0601 13:53:26.400411 24067 sgd_solver.cpp:106] Iteration 24220, lr = 0.01
I0601 13:53:31.867265 24067 solver.cpp:237] Iteration 24240, loss = 4.17672
I0601 13:53:31.867310 24067 solver.cpp:253]     Train net output #0: loss = 4.21013 (* 1 = 4.21013 loss)
I0601 13:53:31.867317 24067 sgd_solver.cpp:106] Iteration 24240, lr = 0.01
I0601 13:53:37.334590 24067 solver.cpp:237] Iteration 24260, loss = 4.2779
I0601 13:53:37.334630 24067 solver.cpp:253]     Train net output #0: loss = 4.31797 (* 1 = 4.31797 loss)
I0601 13:53:37.334640 24067 sgd_solver.cpp:106] Iteration 24260, lr = 0.01
I0601 13:53:42.804570 24067 solver.cpp:237] Iteration 24280, loss = 4.13386
I0601 13:53:42.804620 24067 solver.cpp:253]     Train net output #0: loss = 4.10608 (* 1 = 4.10608 loss)
I0601 13:53:42.804628 24067 sgd_solver.cpp:106] Iteration 24280, lr = 0.01
I0601 13:53:48.275007 24067 solver.cpp:237] Iteration 24300, loss = 4.1944
I0601 13:53:48.275053 24067 solver.cpp:253]     Train net output #0: loss = 4.14434 (* 1 = 4.14434 loss)
I0601 13:53:48.275061 24067 sgd_solver.cpp:106] Iteration 24300, lr = 0.01
I0601 13:53:53.741974 24067 solver.cpp:237] Iteration 24320, loss = 4.27662
I0601 13:53:53.742022 24067 solver.cpp:253]     Train net output #0: loss = 4.47484 (* 1 = 4.47484 loss)
I0601 13:53:53.742030 24067 sgd_solver.cpp:106] Iteration 24320, lr = 0.01
I0601 13:53:59.180169 24067 solver.cpp:237] Iteration 24340, loss = 4.28626
I0601 13:53:59.180326 24067 solver.cpp:253]     Train net output #0: loss = 4.10802 (* 1 = 4.10802 loss)
I0601 13:53:59.180336 24067 sgd_solver.cpp:106] Iteration 24340, lr = 0.01
I0601 13:54:04.645604 24067 solver.cpp:237] Iteration 24360, loss = 4.24439
I0601 13:54:04.645651 24067 solver.cpp:253]     Train net output #0: loss = 4.21801 (* 1 = 4.21801 loss)
I0601 13:54:04.645658 24067 sgd_solver.cpp:106] Iteration 24360, lr = 0.01
I0601 13:54:10.116093 24067 solver.cpp:237] Iteration 24380, loss = 4.20287
I0601 13:54:10.116143 24067 solver.cpp:253]     Train net output #0: loss = 3.90679 (* 1 = 3.90679 loss)
I0601 13:54:10.116152 24067 sgd_solver.cpp:106] Iteration 24380, lr = 0.01
I0601 13:54:15.591549 24067 solver.cpp:237] Iteration 24400, loss = 4.18303
I0601 13:54:15.591598 24067 solver.cpp:253]     Train net output #0: loss = 4.41159 (* 1 = 4.41159 loss)
I0601 13:54:15.591619 24067 sgd_solver.cpp:106] Iteration 24400, lr = 0.01
I0601 13:54:21.053678 24067 solver.cpp:237] Iteration 24420, loss = 4.19398
I0601 13:54:21.053731 24067 solver.cpp:253]     Train net output #0: loss = 4.12667 (* 1 = 4.12667 loss)
I0601 13:54:21.053741 24067 sgd_solver.cpp:106] Iteration 24420, lr = 0.01
I0601 13:54:26.540395 24067 solver.cpp:237] Iteration 24440, loss = 4.19272
I0601 13:54:26.540446 24067 solver.cpp:253]     Train net output #0: loss = 4.35723 (* 1 = 4.35723 loss)
I0601 13:54:26.540457 24067 sgd_solver.cpp:106] Iteration 24440, lr = 0.01
I0601 13:54:32.008633 24067 solver.cpp:237] Iteration 24460, loss = 4.23062
I0601 13:54:32.008885 24067 solver.cpp:253]     Train net output #0: loss = 4.27146 (* 1 = 4.27146 loss)
I0601 13:54:32.008921 24067 sgd_solver.cpp:106] Iteration 24460, lr = 0.01
I0601 13:54:37.489277 24067 solver.cpp:237] Iteration 24480, loss = 4.27948
I0601 13:54:37.489328 24067 solver.cpp:253]     Train net output #0: loss = 4.05725 (* 1 = 4.05725 loss)
I0601 13:54:37.489336 24067 sgd_solver.cpp:106] Iteration 24480, lr = 0.01
I0601 13:54:42.975831 24067 solver.cpp:237] Iteration 24500, loss = 4.28946
I0601 13:54:42.975884 24067 solver.cpp:253]     Train net output #0: loss = 4.22767 (* 1 = 4.22767 loss)
I0601 13:54:42.975893 24067 sgd_solver.cpp:106] Iteration 24500, lr = 0.01
I0601 13:54:48.459435 24067 solver.cpp:237] Iteration 24520, loss = 4.21532
I0601 13:54:48.459484 24067 solver.cpp:253]     Train net output #0: loss = 4.27343 (* 1 = 4.27343 loss)
I0601 13:54:48.459492 24067 sgd_solver.cpp:106] Iteration 24520, lr = 0.01
I0601 13:54:53.950642 24067 solver.cpp:237] Iteration 24540, loss = 4.19672
I0601 13:54:53.950683 24067 solver.cpp:253]     Train net output #0: loss = 4.06272 (* 1 = 4.06272 loss)
I0601 13:54:53.950690 24067 sgd_solver.cpp:106] Iteration 24540, lr = 0.01
I0601 13:54:59.419373 24067 solver.cpp:237] Iteration 24560, loss = 4.20337
I0601 13:54:59.419415 24067 solver.cpp:253]     Train net output #0: loss = 4.0845 (* 1 = 4.0845 loss)
I0601 13:54:59.419420 24067 sgd_solver.cpp:106] Iteration 24560, lr = 0.01
I0601 13:55:04.858022 24067 solver.cpp:237] Iteration 24580, loss = 4.20087
I0601 13:55:04.858244 24067 solver.cpp:253]     Train net output #0: loss = 4.33268 (* 1 = 4.33268 loss)
I0601 13:55:04.858270 24067 sgd_solver.cpp:106] Iteration 24580, lr = 0.01
I0601 13:55:10.342017 24067 solver.cpp:237] Iteration 24600, loss = 4.21468
I0601 13:55:10.342069 24067 solver.cpp:253]     Train net output #0: loss = 4.4909 (* 1 = 4.4909 loss)
I0601 13:55:10.342082 24067 sgd_solver.cpp:106] Iteration 24600, lr = 0.01
I0601 13:55:15.831018 24067 solver.cpp:237] Iteration 24620, loss = 4.1537
I0601 13:55:15.831068 24067 solver.cpp:253]     Train net output #0: loss = 4.08535 (* 1 = 4.08535 loss)
I0601 13:55:15.831079 24067 sgd_solver.cpp:106] Iteration 24620, lr = 0.01
I0601 13:55:21.314409 24067 solver.cpp:237] Iteration 24640, loss = 4.09161
I0601 13:55:21.314471 24067 solver.cpp:253]     Train net output #0: loss = 4.07227 (* 1 = 4.07227 loss)
I0601 13:55:21.314479 24067 sgd_solver.cpp:106] Iteration 24640, lr = 0.01
I0601 13:55:26.801717 24067 solver.cpp:237] Iteration 24660, loss = 4.16836
I0601 13:55:26.801753 24067 solver.cpp:253]     Train net output #0: loss = 4.07557 (* 1 = 4.07557 loss)
I0601 13:55:26.801761 24067 sgd_solver.cpp:106] Iteration 24660, lr = 0.01
I0601 13:55:32.286516 24067 solver.cpp:237] Iteration 24680, loss = 4.20224
I0601 13:55:32.286567 24067 solver.cpp:253]     Train net output #0: loss = 4.0573 (* 1 = 4.0573 loss)
I0601 13:55:32.286576 24067 sgd_solver.cpp:106] Iteration 24680, lr = 0.01
I0601 13:55:37.774355 24067 solver.cpp:237] Iteration 24700, loss = 4.20325
I0601 13:55:37.774603 24067 solver.cpp:253]     Train net output #0: loss = 4.33926 (* 1 = 4.33926 loss)
I0601 13:55:37.774633 24067 sgd_solver.cpp:106] Iteration 24700, lr = 0.01
I0601 13:55:43.263515 24067 solver.cpp:237] Iteration 24720, loss = 4.24526
I0601 13:55:43.263561 24067 solver.cpp:253]     Train net output #0: loss = 4.16818 (* 1 = 4.16818 loss)
I0601 13:55:43.263569 24067 sgd_solver.cpp:106] Iteration 24720, lr = 0.01
I0601 13:55:48.753381 24067 solver.cpp:237] Iteration 24740, loss = 4.22363
I0601 13:55:48.753434 24067 solver.cpp:253]     Train net output #0: loss = 4.14351 (* 1 = 4.14351 loss)
I0601 13:55:48.753444 24067 sgd_solver.cpp:106] Iteration 24740, lr = 0.01
I0601 13:55:54.243057 24067 solver.cpp:237] Iteration 24760, loss = 4.20939
I0601 13:55:54.243108 24067 solver.cpp:253]     Train net output #0: loss = 4.42985 (* 1 = 4.42985 loss)
I0601 13:55:54.243118 24067 sgd_solver.cpp:106] Iteration 24760, lr = 0.01
I0601 13:55:59.729547 24067 solver.cpp:237] Iteration 24780, loss = 4.21043
I0601 13:55:59.729596 24067 solver.cpp:253]     Train net output #0: loss = 4.41775 (* 1 = 4.41775 loss)
I0601 13:55:59.729606 24067 sgd_solver.cpp:106] Iteration 24780, lr = 0.01
I0601 13:56:05.219943 24067 solver.cpp:237] Iteration 24800, loss = 4.19243
I0601 13:56:05.219990 24067 solver.cpp:253]     Train net output #0: loss = 4.39375 (* 1 = 4.39375 loss)
I0601 13:56:05.220000 24067 sgd_solver.cpp:106] Iteration 24800, lr = 0.01
I0601 13:56:10.711961 24067 solver.cpp:237] Iteration 24820, loss = 4.22202
I0601 13:56:10.712163 24067 solver.cpp:253]     Train net output #0: loss = 4.33347 (* 1 = 4.33347 loss)
I0601 13:56:10.712177 24067 sgd_solver.cpp:106] Iteration 24820, lr = 0.01
I0601 13:56:16.204190 24067 solver.cpp:237] Iteration 24840, loss = 4.20232
I0601 13:56:16.204239 24067 solver.cpp:253]     Train net output #0: loss = 4.18307 (* 1 = 4.18307 loss)
I0601 13:56:16.204249 24067 sgd_solver.cpp:106] Iteration 24840, lr = 0.01
I0601 13:56:21.693228 24067 solver.cpp:237] Iteration 24860, loss = 4.18968
I0601 13:56:21.693279 24067 solver.cpp:253]     Train net output #0: loss = 4.25583 (* 1 = 4.25583 loss)
I0601 13:56:21.693287 24067 sgd_solver.cpp:106] Iteration 24860, lr = 0.01
I0601 13:56:27.179635 24067 solver.cpp:237] Iteration 24880, loss = 4.18961
I0601 13:56:27.179680 24067 solver.cpp:253]     Train net output #0: loss = 4.40689 (* 1 = 4.40689 loss)
I0601 13:56:27.179689 24067 sgd_solver.cpp:106] Iteration 24880, lr = 0.01
I0601 13:56:32.668313 24067 solver.cpp:237] Iteration 24900, loss = 4.23971
I0601 13:56:32.668351 24067 solver.cpp:253]     Train net output #0: loss = 4.21402 (* 1 = 4.21402 loss)
I0601 13:56:32.668361 24067 sgd_solver.cpp:106] Iteration 24900, lr = 0.01
I0601 13:56:38.154289 24067 solver.cpp:237] Iteration 24920, loss = 4.2726
I0601 13:56:38.154343 24067 solver.cpp:253]     Train net output #0: loss = 4.35701 (* 1 = 4.35701 loss)
I0601 13:56:38.154359 24067 sgd_solver.cpp:106] Iteration 24920, lr = 0.01
I0601 13:56:43.637240 24067 solver.cpp:237] Iteration 24940, loss = 4.18882
I0601 13:56:43.637475 24067 solver.cpp:253]     Train net output #0: loss = 4.31305 (* 1 = 4.31305 loss)
I0601 13:56:43.637497 24067 sgd_solver.cpp:106] Iteration 24940, lr = 0.01
I0601 13:56:49.119809 24067 solver.cpp:237] Iteration 24960, loss = 4.16993
I0601 13:56:49.119849 24067 solver.cpp:253]     Train net output #0: loss = 4.19166 (* 1 = 4.19166 loss)
I0601 13:56:49.119856 24067 sgd_solver.cpp:106] Iteration 24960, lr = 0.01
I0601 13:56:54.608858 24067 solver.cpp:237] Iteration 24980, loss = 4.19
I0601 13:56:54.608907 24067 solver.cpp:253]     Train net output #0: loss = 4.03277 (* 1 = 4.03277 loss)
I0601 13:56:54.608916 24067 sgd_solver.cpp:106] Iteration 24980, lr = 0.01
I0601 13:57:00.018463 24067 solver.cpp:341] Iteration 25000, Testing net (#0)
I0601 13:57:24.756757 24067 blocking_queue.cpp:50] Data layer prefetch queue empty
I0601 13:57:32.537686 24067 solver.cpp:409]     Test net output #0: accuracy = 0.19428
I0601 13:57:32.537739 24067 solver.cpp:409]     Test net output #1: loss = 4.15393 (* 1 = 4.15393 loss)
I0601 13:57:32.619446 24067 solver.cpp:237] Iteration 25000, loss = 4.30363
I0601 13:57:32.619495 24067 solver.cpp:253]     Train net output #0: loss = 4.21844 (* 1 = 4.21844 loss)
I0601 13:57:32.619505 24067 sgd_solver.cpp:106] Iteration 25000, lr = 0.01
I0601 13:57:38.069198 24067 solver.cpp:237] Iteration 25020, loss = 4.24221
I0601 13:57:38.069253 24067 solver.cpp:253]     Train net output #0: loss = 4.16332 (* 1 = 4.16332 loss)
I0601 13:57:38.069263 24067 sgd_solver.cpp:106] Iteration 25020, lr = 0.01
I0601 13:57:43.522263 24067 solver.cpp:237] Iteration 25040, loss = 4.23807
I0601 13:57:43.522315 24067 solver.cpp:253]     Train net output #0: loss = 4.27493 (* 1 = 4.27493 loss)
I0601 13:57:43.522323 24067 sgd_solver.cpp:106] Iteration 25040, lr = 0.01
I0601 13:57:48.973781 24067 solver.cpp:237] Iteration 25060, loss = 4.20103
I0601 13:57:48.973844 24067 solver.cpp:253]     Train net output #0: loss = 4.38084 (* 1 = 4.38084 loss)
I0601 13:57:48.973852 24067 sgd_solver.cpp:106] Iteration 25060, lr = 0.01
I0601 13:57:54.438863 24067 solver.cpp:237] Iteration 25080, loss = 4.21709
I0601 13:57:54.438916 24067 solver.cpp:253]     Train net output #0: loss = 4.11614 (* 1 = 4.11614 loss)
I0601 13:57:54.438926 24067 sgd_solver.cpp:106] Iteration 25080, lr = 0.01
I0601 13:57:59.893301 24067 solver.cpp:237] Iteration 25100, loss = 4.29578
I0601 13:57:59.893519 24067 solver.cpp:253]     Train net output #0: loss = 4.11035 (* 1 = 4.11035 loss)
I0601 13:57:59.893544 24067 sgd_solver.cpp:106] Iteration 25100, lr = 0.01
I0601 13:58:05.326591 24067 solver.cpp:237] Iteration 25120, loss = 4.16151
I0601 13:58:05.326642 24067 solver.cpp:253]     Train net output #0: loss = 4.06521 (* 1 = 4.06521 loss)
I0601 13:58:05.326656 24067 sgd_solver.cpp:106] Iteration 25120, lr = 0.01
I0601 13:58:10.787179 24067 solver.cpp:237] Iteration 25140, loss = 4.24513
I0601 13:58:10.787230 24067 solver.cpp:253]     Train net output #0: loss = 4.36628 (* 1 = 4.36628 loss)
I0601 13:58:10.787237 24067 sgd_solver.cpp:106] Iteration 25140, lr = 0.01
I0601 13:58:16.245342 24067 solver.cpp:237] Iteration 25160, loss = 4.1219
I0601 13:58:16.245394 24067 solver.cpp:253]     Train net output #0: loss = 4.09264 (* 1 = 4.09264 loss)
I0601 13:58:16.245415 24067 sgd_solver.cpp:106] Iteration 25160, lr = 0.01
I0601 13:58:21.708690 24067 solver.cpp:237] Iteration 25180, loss = 4.24418
I0601 13:58:21.708740 24067 solver.cpp:253]     Train net output #0: loss = 4.02326 (* 1 = 4.02326 loss)
I0601 13:58:21.708760 24067 sgd_solver.cpp:106] Iteration 25180, lr = 0.01
I0601 13:58:27.177239 24067 solver.cpp:237] Iteration 25200, loss = 4.17846
I0601 13:58:27.177279 24067 solver.cpp:253]     Train net output #0: loss = 4.07858 (* 1 = 4.07858 loss)
I0601 13:58:27.177287 24067 sgd_solver.cpp:106] Iteration 25200, lr = 0.01
I0601 13:58:32.648607 24067 solver.cpp:237] Iteration 25220, loss = 4.19726
I0601 13:58:32.648841 24067 solver.cpp:253]     Train net output #0: loss = 4.20221 (* 1 = 4.20221 loss)
I0601 13:58:32.648864 24067 sgd_solver.cpp:106] Iteration 25220, lr = 0.01
I0601 13:58:38.126268 24067 solver.cpp:237] Iteration 25240, loss = 4.19466
I0601 13:58:38.126308 24067 solver.cpp:253]     Train net output #0: loss = 4.2341 (* 1 = 4.2341 loss)
I0601 13:58:38.126314 24067 sgd_solver.cpp:106] Iteration 25240, lr = 0.01
I0601 13:58:43.602012 24067 solver.cpp:237] Iteration 25260, loss = 4.15123
I0601 13:58:43.602057 24067 solver.cpp:253]     Train net output #0: loss = 3.88188 (* 1 = 3.88188 loss)
I0601 13:58:43.602064 24067 sgd_solver.cpp:106] Iteration 25260, lr = 0.01
I0601 13:58:49.075466 24067 solver.cpp:237] Iteration 25280, loss = 4.21093
I0601 13:58:49.075508 24067 solver.cpp:253]     Train net output #0: loss = 4.28862 (* 1 = 4.28862 loss)
I0601 13:58:49.075515 24067 sgd_solver.cpp:106] Iteration 25280, lr = 0.01
I0601 13:58:54.551286 24067 solver.cpp:237] Iteration 25300, loss = 4.18422
I0601 13:58:54.551327 24067 solver.cpp:253]     Train net output #0: loss = 4.26431 (* 1 = 4.26431 loss)
I0601 13:58:54.551332 24067 sgd_solver.cpp:106] Iteration 25300, lr = 0.01
I0601 13:59:00.014678 24067 solver.cpp:237] Iteration 25320, loss = 4.17687
I0601 13:59:00.014719 24067 solver.cpp:253]     Train net output #0: loss = 4.29697 (* 1 = 4.29697 loss)
I0601 13:59:00.014725 24067 sgd_solver.cpp:106] Iteration 25320, lr = 0.01
I0601 13:59:05.444320 24067 solver.cpp:237] Iteration 25340, loss = 4.19724
I0601 13:59:05.444427 24067 solver.cpp:253]     Train net output #0: loss = 4.12823 (* 1 = 4.12823 loss)
I0601 13:59:05.444434 24067 sgd_solver.cpp:106] Iteration 25340, lr = 0.01
I0601 13:59:10.908622 24067 solver.cpp:237] Iteration 25360, loss = 4.16374
I0601 13:59:10.908674 24067 solver.cpp:253]     Train net output #0: loss = 4.09188 (* 1 = 4.09188 loss)
I0601 13:59:10.908680 24067 sgd_solver.cpp:106] Iteration 25360, lr = 0.01
I0601 13:59:16.388484 24067 solver.cpp:237] Iteration 25380, loss = 4.18738
I0601 13:59:16.388528 24067 solver.cpp:253]     Train net output #0: loss = 4.03604 (* 1 = 4.03604 loss)
I0601 13:59:16.388533 24067 sgd_solver.cpp:106] Iteration 25380, lr = 0.01
I0601 13:59:21.866030 24067 solver.cpp:237] Iteration 25400, loss = 4.1736
I0601 13:59:21.866071 24067 solver.cpp:253]     Train net output #0: loss = 4.13743 (* 1 = 4.13743 loss)
I0601 13:59:21.866076 24067 sgd_solver.cpp:106] Iteration 25400, lr = 0.01
I0601 13:59:27.339203 24067 solver.cpp:237] Iteration 25420, loss = 4.17027
I0601 13:59:27.339251 24067 solver.cpp:253]     Train net output #0: loss = 4.16112 (* 1 = 4.16112 loss)
I0601 13:59:27.339259 24067 sgd_solver.cpp:106] Iteration 25420, lr = 0.01
I0601 13:59:32.778515 24067 solver.cpp:237] Iteration 25440, loss = 4.21414
I0601 13:59:32.778548 24067 solver.cpp:253]     Train net output #0: loss = 4.15243 (* 1 = 4.15243 loss)
I0601 13:59:32.778553 24067 sgd_solver.cpp:106] Iteration 25440, lr = 0.01
I0601 13:59:38.216764 24067 solver.cpp:237] Iteration 25460, loss = 4.13453
I0601 13:59:38.216969 24067 solver.cpp:253]     Train net output #0: loss = 4.23932 (* 1 = 4.23932 loss)
I0601 13:59:38.216995 24067 sgd_solver.cpp:106] Iteration 25460, lr = 0.01
I0601 13:59:43.648499 24067 solver.cpp:237] Iteration 25480, loss = 4.21345
I0601 13:59:43.648547 24067 solver.cpp:253]     Train net output #0: loss = 4.30391 (* 1 = 4.30391 loss)
I0601 13:59:43.648569 24067 sgd_solver.cpp:106] Iteration 25480, lr = 0.01
I0601 13:59:49.096786 24067 solver.cpp:237] Iteration 25500, loss = 4.16481
I0601 13:59:49.096818 24067 solver.cpp:253]     Train net output #0: loss = 4.24316 (* 1 = 4.24316 loss)
I0601 13:59:49.096825 24067 sgd_solver.cpp:106] Iteration 25500, lr = 0.01
I0601 13:59:54.532831 24067 solver.cpp:237] Iteration 25520, loss = 4.19571
I0601 13:59:54.532871 24067 solver.cpp:253]     Train net output #0: loss = 4.10922 (* 1 = 4.10922 loss)
I0601 13:59:54.532878 24067 sgd_solver.cpp:106] Iteration 25520, lr = 0.01
I0601 13:59:59.991266 24067 solver.cpp:237] Iteration 25540, loss = 4.16796
I0601 13:59:59.991299 24067 solver.cpp:253]     Train net output #0: loss = 4.15753 (* 1 = 4.15753 loss)
I0601 13:59:59.991304 24067 sgd_solver.cpp:106] Iteration 25540, lr = 0.01
I0601 14:00:05.478560 24067 solver.cpp:237] Iteration 25560, loss = 4.24547
I0601 14:00:05.478606 24067 solver.cpp:253]     Train net output #0: loss = 4.18118 (* 1 = 4.18118 loss)
I0601 14:00:05.478615 24067 sgd_solver.cpp:106] Iteration 25560, lr = 0.01
I0601 14:00:10.966506 24067 solver.cpp:237] Iteration 25580, loss = 4.24608
I0601 14:00:10.966738 24067 solver.cpp:253]     Train net output #0: loss = 4.49369 (* 1 = 4.49369 loss)
I0601 14:00:10.966763 24067 sgd_solver.cpp:106] Iteration 25580, lr = 0.01
I0601 14:00:16.453783 24067 solver.cpp:237] Iteration 25600, loss = 4.23576
I0601 14:00:16.453830 24067 solver.cpp:253]     Train net output #0: loss = 4.15073 (* 1 = 4.15073 loss)
I0601 14:00:16.453840 24067 sgd_solver.cpp:106] Iteration 25600, lr = 0.01
I0601 14:00:21.940207 24067 solver.cpp:237] Iteration 25620, loss = 4.24138
I0601 14:00:21.940256 24067 solver.cpp:253]     Train net output #0: loss = 4.23624 (* 1 = 4.23624 loss)
I0601 14:00:21.940268 24067 sgd_solver.cpp:106] Iteration 25620, lr = 0.01
I0601 14:00:27.431956 24067 solver.cpp:237] Iteration 25640, loss = 4.17118
I0601 14:00:27.432001 24067 solver.cpp:253]     Train net output #0: loss = 4.19896 (* 1 = 4.19896 loss)
I0601 14:00:27.432010 24067 sgd_solver.cpp:106] Iteration 25640, lr = 0.01
I0601 14:00:32.905148 24067 solver.cpp:237] Iteration 25660, loss = 4.22786
I0601 14:00:32.905190 24067 solver.cpp:253]     Train net output #0: loss = 4.18878 (* 1 = 4.18878 loss)
I0601 14:00:32.905199 24067 sgd_solver.cpp:106] Iteration 25660, lr = 0.01
I0601 14:00:38.337769 24067 solver.cpp:237] Iteration 25680, loss = 4.11905
I0601 14:00:38.337808 24067 solver.cpp:253]     Train net output #0: loss = 4.06626 (* 1 = 4.06626 loss)
I0601 14:00:38.337815 24067 sgd_solver.cpp:106] Iteration 25680, lr = 0.01
I0601 14:00:43.817538 24067 solver.cpp:237] Iteration 25700, loss = 4.21229
I0601 14:00:43.817775 24067 solver.cpp:253]     Train net output #0: loss = 4.38879 (* 1 = 4.38879 loss)
I0601 14:00:43.817809 24067 sgd_solver.cpp:106] Iteration 25700, lr = 0.01
I0601 14:00:49.312126 24067 solver.cpp:237] Iteration 25720, loss = 4.18159
I0601 14:00:49.312173 24067 solver.cpp:253]     Train net output #0: loss = 3.81429 (* 1 = 3.81429 loss)
I0601 14:00:49.312181 24067 sgd_solver.cpp:106] Iteration 25720, lr = 0.01
I0601 14:00:54.802456 24067 solver.cpp:237] Iteration 25740, loss = 4.09544
I0601 14:00:54.802513 24067 solver.cpp:253]     Train net output #0: loss = 4.15541 (* 1 = 4.15541 loss)
I0601 14:00:54.802522 24067 sgd_solver.cpp:106] Iteration 25740, lr = 0.01
I0601 14:01:00.290946 24067 solver.cpp:237] Iteration 25760, loss = 4.17324
I0601 14:01:00.290985 24067 solver.cpp:253]     Train net output #0: loss = 4.30091 (* 1 = 4.30091 loss)
I0601 14:01:00.290992 24067 sgd_solver.cpp:106] Iteration 25760, lr = 0.01
I0601 14:01:05.739534 24067 solver.cpp:237] Iteration 25780, loss = 4.17804
I0601 14:01:05.739583 24067 solver.cpp:253]     Train net output #0: loss = 4.29079 (* 1 = 4.29079 loss)
I0601 14:01:05.739589 24067 sgd_solver.cpp:106] Iteration 25780, lr = 0.01
I0601 14:01:11.205584 24067 solver.cpp:237] Iteration 25800, loss = 4.14225
I0601 14:01:11.205613 24067 solver.cpp:253]     Train net output #0: loss = 3.93586 (* 1 = 3.93586 loss)
I0601 14:01:11.205621 24067 sgd_solver.cpp:106] Iteration 25800, lr = 0.01
I0601 14:01:16.676223 24067 solver.cpp:237] Iteration 25820, loss = 4.1849
I0601 14:01:16.676430 24067 solver.cpp:253]     Train net output #0: loss = 4.14771 (* 1 = 4.14771 loss)
I0601 14:01:16.676451 24067 sgd_solver.cpp:106] Iteration 25820, lr = 0.01
I0601 14:01:22.165732 24067 solver.cpp:237] Iteration 25840, loss = 4.17383
I0601 14:01:22.165779 24067 solver.cpp:253]     Train net output #0: loss = 4.24127 (* 1 = 4.24127 loss)
I0601 14:01:22.165787 24067 sgd_solver.cpp:106] Iteration 25840, lr = 0.01
I0601 14:01:27.652146 24067 solver.cpp:237] Iteration 25860, loss = 4.12983
I0601 14:01:27.652195 24067 solver.cpp:253]     Train net output #0: loss = 4.12852 (* 1 = 4.12852 loss)
I0601 14:01:27.652201 24067 sgd_solver.cpp:106] Iteration 25860, lr = 0.01
I0601 14:01:33.141315 24067 solver.cpp:237] Iteration 25880, loss = 4.19321
I0601 14:01:33.141347 24067 solver.cpp:253]     Train net output #0: loss = 4.27947 (* 1 = 4.27947 loss)
I0601 14:01:33.141355 24067 sgd_solver.cpp:106] Iteration 25880, lr = 0.01
I0601 14:01:38.624867 24067 solver.cpp:237] Iteration 25900, loss = 4.2356
I0601 14:01:38.624905 24067 solver.cpp:253]     Train net output #0: loss = 4.13999 (* 1 = 4.13999 loss)
I0601 14:01:38.624912 24067 sgd_solver.cpp:106] Iteration 25900, lr = 0.01
I0601 14:01:44.118381 24067 solver.cpp:237] Iteration 25920, loss = 4.23699
I0601 14:01:44.118432 24067 solver.cpp:253]     Train net output #0: loss = 4.45009 (* 1 = 4.45009 loss)
I0601 14:01:44.118438 24067 sgd_solver.cpp:106] Iteration 25920, lr = 0.01
I0601 14:01:49.606734 24067 solver.cpp:237] Iteration 25940, loss = 4.17624
I0601 14:01:49.606945 24067 solver.cpp:253]     Train net output #0: loss = 4.08351 (* 1 = 4.08351 loss)
I0601 14:01:49.606966 24067 sgd_solver.cpp:106] Iteration 25940, lr = 0.01
I0601 14:01:55.095302 24067 solver.cpp:237] Iteration 25960, loss = 4.17424
I0601 14:01:55.095353 24067 solver.cpp:253]     Train net output #0: loss = 4.43366 (* 1 = 4.43366 loss)
I0601 14:01:55.095362 24067 sgd_solver.cpp:106] Iteration 25960, lr = 0.01
I0601 14:02:00.580314 24067 solver.cpp:237] Iteration 25980, loss = 4.23678
I0601 14:02:00.580364 24067 solver.cpp:253]     Train net output #0: loss = 4.24837 (* 1 = 4.24837 loss)
I0601 14:02:00.580377 24067 sgd_solver.cpp:106] Iteration 25980, lr = 0.01
I0601 14:02:05.981627 24067 solver.cpp:341] Iteration 26000, Testing net (#0)
I0601 14:02:30.764243 24067 blocking_queue.cpp:50] Data layer prefetch queue empty
I0601 14:02:38.324031 24067 solver.cpp:409]     Test net output #0: accuracy = 0.21316
I0601 14:02:38.324079 24067 solver.cpp:409]     Test net output #1: loss = 3.9648 (* 1 = 3.9648 loss)
I0601 14:02:38.404733 24067 solver.cpp:237] Iteration 26000, loss = 4.22616
I0601 14:02:38.404762 24067 solver.cpp:253]     Train net output #0: loss = 4.17224 (* 1 = 4.17224 loss)
I0601 14:02:38.404770 24067 sgd_solver.cpp:106] Iteration 26000, lr = 0.01
I0601 14:02:43.847026 24067 solver.cpp:237] Iteration 26020, loss = 4.18837
I0601 14:02:43.847056 24067 solver.cpp:253]     Train net output #0: loss = 4.26136 (* 1 = 4.26136 loss)
I0601 14:02:43.847064 24067 sgd_solver.cpp:106] Iteration 26020, lr = 0.01
I0601 14:02:49.303428 24067 solver.cpp:237] Iteration 26040, loss = 4.18967
I0601 14:02:49.303467 24067 solver.cpp:253]     Train net output #0: loss = 4.16566 (* 1 = 4.16566 loss)
I0601 14:02:49.303474 24067 sgd_solver.cpp:106] Iteration 26040, lr = 0.01
I0601 14:02:54.761543 24067 solver.cpp:237] Iteration 26060, loss = 4.10572
I0601 14:02:54.761579 24067 solver.cpp:253]     Train net output #0: loss = 4.18395 (* 1 = 4.18395 loss)
I0601 14:02:54.761584 24067 sgd_solver.cpp:106] Iteration 26060, lr = 0.01
I0601 14:03:00.219717 24067 solver.cpp:237] Iteration 26080, loss = 4.09172
I0601 14:03:00.219749 24067 solver.cpp:253]     Train net output #0: loss = 3.97613 (* 1 = 3.97613 loss)
I0601 14:03:00.219758 24067 sgd_solver.cpp:106] Iteration 26080, lr = 0.01
I0601 14:03:05.683624 24067 solver.cpp:237] Iteration 26100, loss = 4.14039
I0601 14:03:05.683858 24067 solver.cpp:253]     Train net output #0: loss = 4.03437 (* 1 = 4.03437 loss)
I0601 14:03:05.683890 24067 sgd_solver.cpp:106] Iteration 26100, lr = 0.01
I0601 14:03:11.173193 24067 solver.cpp:237] Iteration 26120, loss = 4.12574
I0601 14:03:11.173239 24067 solver.cpp:253]     Train net output #0: loss = 4.21136 (* 1 = 4.21136 loss)
I0601 14:03:11.173246 24067 sgd_solver.cpp:106] Iteration 26120, lr = 0.01
I0601 14:03:16.637884 24067 solver.cpp:237] Iteration 26140, loss = 4.16379
I0601 14:03:16.637924 24067 solver.cpp:253]     Train net output #0: loss = 4.25645 (* 1 = 4.25645 loss)
I0601 14:03:16.637933 24067 sgd_solver.cpp:106] Iteration 26140, lr = 0.01
I0601 14:03:22.103144 24067 solver.cpp:237] Iteration 26160, loss = 4.20399
I0601 14:03:22.103183 24067 solver.cpp:253]     Train net output #0: loss = 4.06559 (* 1 = 4.06559 loss)
I0601 14:03:22.103190 24067 sgd_solver.cpp:106] Iteration 26160, lr = 0.01
I0601 14:03:27.574646 24067 solver.cpp:237] Iteration 26180, loss = 4.21136
I0601 14:03:27.574710 24067 solver.cpp:253]     Train net output #0: loss = 4.0933 (* 1 = 4.0933 loss)
I0601 14:03:27.574722 24067 sgd_solver.cpp:106] Iteration 26180, lr = 0.01
I0601 14:03:33.050389 24067 solver.cpp:237] Iteration 26200, loss = 4.17165
I0601 14:03:33.050441 24067 solver.cpp:253]     Train net output #0: loss = 3.92142 (* 1 = 3.92142 loss)
I0601 14:03:33.050449 24067 sgd_solver.cpp:106] Iteration 26200, lr = 0.01
I0601 14:03:38.525547 24067 solver.cpp:237] Iteration 26220, loss = 4.13438
I0601 14:03:38.525782 24067 solver.cpp:253]     Train net output #0: loss = 4.11519 (* 1 = 4.11519 loss)
I0601 14:03:38.525809 24067 sgd_solver.cpp:106] Iteration 26220, lr = 0.01
I0601 14:03:44.010314 24067 solver.cpp:237] Iteration 26240, loss = 4.2162
I0601 14:03:44.010365 24067 solver.cpp:253]     Train net output #0: loss = 4.05032 (* 1 = 4.05032 loss)
I0601 14:03:44.010373 24067 sgd_solver.cpp:106] Iteration 26240, lr = 0.01
I0601 14:03:49.494256 24067 solver.cpp:237] Iteration 26260, loss = 4.16518
I0601 14:03:49.494304 24067 solver.cpp:253]     Train net output #0: loss = 4.18666 (* 1 = 4.18666 loss)
I0601 14:03:49.494312 24067 sgd_solver.cpp:106] Iteration 26260, lr = 0.01
I0601 14:03:54.975952 24067 solver.cpp:237] Iteration 26280, loss = 4.2218
I0601 14:03:54.976001 24067 solver.cpp:253]     Train net output #0: loss = 4.23795 (* 1 = 4.23795 loss)
I0601 14:03:54.976008 24067 sgd_solver.cpp:106] Iteration 26280, lr = 0.01
I0601 14:04:00.457685 24067 solver.cpp:237] Iteration 26300, loss = 4.19023
I0601 14:04:00.457741 24067 solver.cpp:253]     Train net output #0: loss = 4.52147 (* 1 = 4.52147 loss)
I0601 14:04:00.457749 24067 sgd_solver.cpp:106] Iteration 26300, lr = 0.01
I0601 14:04:05.939368 24067 solver.cpp:237] Iteration 26320, loss = 4.2445
I0601 14:04:05.939410 24067 solver.cpp:253]     Train net output #0: loss = 4.25924 (* 1 = 4.25924 loss)
I0601 14:04:05.939429 24067 sgd_solver.cpp:106] Iteration 26320, lr = 0.01
I0601 14:04:11.421056 24067 solver.cpp:237] Iteration 26340, loss = 4.21506
I0601 14:04:11.421291 24067 solver.cpp:253]     Train net output #0: loss = 4.2503 (* 1 = 4.2503 loss)
I0601 14:04:11.421310 24067 sgd_solver.cpp:106] Iteration 26340, lr = 0.01
I0601 14:04:16.898932 24067 solver.cpp:237] Iteration 26360, loss = 4.23495
I0601 14:04:16.898983 24067 solver.cpp:253]     Train net output #0: loss = 4.37969 (* 1 = 4.37969 loss)
I0601 14:04:16.898991 24067 sgd_solver.cpp:106] Iteration 26360, lr = 0.01
I0601 14:04:22.382980 24067 solver.cpp:237] Iteration 26380, loss = 4.1434
I0601 14:04:22.383024 24067 solver.cpp:253]     Train net output #0: loss = 4.20383 (* 1 = 4.20383 loss)
I0601 14:04:22.383030 24067 sgd_solver.cpp:106] Iteration 26380, lr = 0.01
I0601 14:04:27.870604 24067 solver.cpp:237] Iteration 26400, loss = 4.13856
I0601 14:04:27.870652 24067 solver.cpp:253]     Train net output #0: loss = 4.07767 (* 1 = 4.07767 loss)
I0601 14:04:27.870661 24067 sgd_solver.cpp:106] Iteration 26400, lr = 0.01
I0601 14:04:33.353538 24067 solver.cpp:237] Iteration 26420, loss = 4.10702
I0601 14:04:33.353587 24067 solver.cpp:253]     Train net output #0: loss = 4.38066 (* 1 = 4.38066 loss)
I0601 14:04:33.353595 24067 sgd_solver.cpp:106] Iteration 26420, lr = 0.01
I0601 14:04:38.840769 24067 solver.cpp:237] Iteration 26440, loss = 4.24296
I0601 14:04:38.840813 24067 solver.cpp:253]     Train net output #0: loss = 4.47983 (* 1 = 4.47983 loss)
I0601 14:04:38.840821 24067 sgd_solver.cpp:106] Iteration 26440, lr = 0.01
I0601 14:04:44.334134 24067 solver.cpp:237] Iteration 26460, loss = 4.17902
I0601 14:04:44.334345 24067 solver.cpp:253]     Train net output #0: loss = 4.27401 (* 1 = 4.27401 loss)
I0601 14:04:44.334372 24067 sgd_solver.cpp:106] Iteration 26460, lr = 0.01
I0601 14:04:49.825141 24067 solver.cpp:237] Iteration 26480, loss = 4.1388
I0601 14:04:49.825186 24067 solver.cpp:253]     Train net output #0: loss = 4.04537 (* 1 = 4.04537 loss)
I0601 14:04:49.825193 24067 sgd_solver.cpp:106] Iteration 26480, lr = 0.01
I0601 14:04:55.306915 24067 solver.cpp:237] Iteration 26500, loss = 4.2044
I0601 14:04:55.306958 24067 solver.cpp:253]     Train net output #0: loss = 4.25788 (* 1 = 4.25788 loss)
I0601 14:04:55.306967 24067 sgd_solver.cpp:106] Iteration 26500, lr = 0.01
I0601 14:05:00.794337 24067 solver.cpp:237] Iteration 26520, loss = 4.24518
I0601 14:05:00.794389 24067 solver.cpp:253]     Train net output #0: loss = 4.23331 (* 1 = 4.23331 loss)
I0601 14:05:00.794397 24067 sgd_solver.cpp:106] Iteration 26520, lr = 0.01
I0601 14:05:06.284574 24067 solver.cpp:237] Iteration 26540, loss = 4.18982
I0601 14:05:06.284627 24067 solver.cpp:253]     Train net output #0: loss = 4.21398 (* 1 = 4.21398 loss)
I0601 14:05:06.284634 24067 sgd_solver.cpp:106] Iteration 26540, lr = 0.01
I0601 14:05:11.769004 24067 solver.cpp:237] Iteration 26560, loss = 4.19959
I0601 14:05:11.769052 24067 solver.cpp:253]     Train net output #0: loss = 4.13728 (* 1 = 4.13728 loss)
I0601 14:05:11.769058 24067 sgd_solver.cpp:106] Iteration 26560, lr = 0.01
I0601 14:05:17.259549 24067 solver.cpp:237] Iteration 26580, loss = 4.17124
I0601 14:05:17.259722 24067 solver.cpp:253]     Train net output #0: loss = 4.14353 (* 1 = 4.14353 loss)
I0601 14:05:17.259730 24067 sgd_solver.cpp:106] Iteration 26580, lr = 0.01
I0601 14:05:22.752979 24067 solver.cpp:237] Iteration 26600, loss = 4.20701
I0601 14:05:22.753027 24067 solver.cpp:253]     Train net output #0: loss = 4.42051 (* 1 = 4.42051 loss)
I0601 14:05:22.753036 24067 sgd_solver.cpp:106] Iteration 26600, lr = 0.01
I0601 14:05:28.247582 24067 solver.cpp:237] Iteration 26620, loss = 4.15272
I0601 14:05:28.247630 24067 solver.cpp:253]     Train net output #0: loss = 4.1122 (* 1 = 4.1122 loss)
I0601 14:05:28.247638 24067 sgd_solver.cpp:106] Iteration 26620, lr = 0.01
I0601 14:05:33.735842 24067 solver.cpp:237] Iteration 26640, loss = 4.14141
I0601 14:05:33.735891 24067 solver.cpp:253]     Train net output #0: loss = 3.98049 (* 1 = 3.98049 loss)
I0601 14:05:33.735900 24067 sgd_solver.cpp:106] Iteration 26640, lr = 0.01
I0601 14:05:39.234179 24067 solver.cpp:237] Iteration 26660, loss = 4.13425
I0601 14:05:39.234213 24067 solver.cpp:253]     Train net output #0: loss = 4.23005 (* 1 = 4.23005 loss)
I0601 14:05:39.234221 24067 sgd_solver.cpp:106] Iteration 26660, lr = 0.01
I0601 14:05:44.722620 24067 solver.cpp:237] Iteration 26680, loss = 4.09688
I0601 14:05:44.722676 24067 solver.cpp:253]     Train net output #0: loss = 4.06572 (* 1 = 4.06572 loss)
I0601 14:05:44.722686 24067 sgd_solver.cpp:106] Iteration 26680, lr = 0.01
I0601 14:05:50.216565 24067 solver.cpp:237] Iteration 26700, loss = 4.25594
I0601 14:05:50.216790 24067 solver.cpp:253]     Train net output #0: loss = 4.29513 (* 1 = 4.29513 loss)
I0601 14:05:50.216815 24067 sgd_solver.cpp:106] Iteration 26700, lr = 0.01
I0601 14:05:55.710753 24067 solver.cpp:237] Iteration 26720, loss = 4.10859
I0601 14:05:55.710805 24067 solver.cpp:253]     Train net output #0: loss = 4.02736 (* 1 = 4.02736 loss)
I0601 14:05:55.710814 24067 sgd_solver.cpp:106] Iteration 26720, lr = 0.01
I0601 14:06:01.201189 24067 solver.cpp:237] Iteration 26740, loss = 4.1604
I0601 14:06:01.201246 24067 solver.cpp:253]     Train net output #0: loss = 3.99538 (* 1 = 3.99538 loss)
I0601 14:06:01.201256 24067 sgd_solver.cpp:106] Iteration 26740, lr = 0.01
I0601 14:06:06.697824 24067 solver.cpp:237] Iteration 26760, loss = 4.16596
I0601 14:06:06.697877 24067 solver.cpp:253]     Train net output #0: loss = 4.20581 (* 1 = 4.20581 loss)
I0601 14:06:06.697888 24067 sgd_solver.cpp:106] Iteration 26760, lr = 0.01
I0601 14:06:12.183080 24067 solver.cpp:237] Iteration 26780, loss = 4.1091
I0601 14:06:12.183130 24067 solver.cpp:253]     Train net output #0: loss = 3.84663 (* 1 = 3.84663 loss)
I0601 14:06:12.183140 24067 sgd_solver.cpp:106] Iteration 26780, lr = 0.01
I0601 14:06:17.669039 24067 solver.cpp:237] Iteration 26800, loss = 4.18764
I0601 14:06:17.669091 24067 solver.cpp:253]     Train net output #0: loss = 4.18079 (* 1 = 4.18079 loss)
I0601 14:06:17.669100 24067 sgd_solver.cpp:106] Iteration 26800, lr = 0.01
I0601 14:06:23.158625 24067 solver.cpp:237] Iteration 26820, loss = 4.15189
I0601 14:06:23.158881 24067 solver.cpp:253]     Train net output #0: loss = 3.82651 (* 1 = 3.82651 loss)
I0601 14:06:23.158910 24067 sgd_solver.cpp:106] Iteration 26820, lr = 0.01
I0601 14:06:28.647409 24067 solver.cpp:237] Iteration 26840, loss = 4.15221
I0601 14:06:28.647460 24067 solver.cpp:253]     Train net output #0: loss = 3.9502 (* 1 = 3.9502 loss)
I0601 14:06:28.647467 24067 sgd_solver.cpp:106] Iteration 26840, lr = 0.01
I0601 14:06:34.137132 24067 solver.cpp:237] Iteration 26860, loss = 4.16674
I0601 14:06:34.137176 24067 solver.cpp:253]     Train net output #0: loss = 4.07313 (* 1 = 4.07313 loss)
I0601 14:06:34.137182 24067 sgd_solver.cpp:106] Iteration 26860, lr = 0.01
I0601 14:06:39.623189 24067 solver.cpp:237] Iteration 26880, loss = 4.14709
I0601 14:06:39.623245 24067 solver.cpp:253]     Train net output #0: loss = 4.1395 (* 1 = 4.1395 loss)
I0601 14:06:39.623251 24067 sgd_solver.cpp:106] Iteration 26880, lr = 0.01
I0601 14:06:45.110432 24067 solver.cpp:237] Iteration 26900, loss = 4.16193
I0601 14:06:45.110481 24067 solver.cpp:253]     Train net output #0: loss = 4.03813 (* 1 = 4.03813 loss)
I0601 14:06:45.110487 24067 sgd_solver.cpp:106] Iteration 26900, lr = 0.01
I0601 14:06:50.595830 24067 solver.cpp:237] Iteration 26920, loss = 4.20327
I0601 14:06:50.595873 24067 solver.cpp:253]     Train net output #0: loss = 4.41213 (* 1 = 4.41213 loss)
I0601 14:06:50.595880 24067 sgd_solver.cpp:106] Iteration 26920, lr = 0.01
I0601 14:06:56.081081 24067 solver.cpp:237] Iteration 26940, loss = 4.12629
I0601 14:06:56.081259 24067 solver.cpp:253]     Train net output #0: loss = 4.05044 (* 1 = 4.05044 loss)
I0601 14:06:56.081269 24067 sgd_solver.cpp:106] Iteration 26940, lr = 0.01
I0601 14:07:01.579710 24067 solver.cpp:237] Iteration 26960, loss = 4.18238
I0601 14:07:01.579758 24067 solver.cpp:253]     Train net output #0: loss = 4.37805 (* 1 = 4.37805 loss)
I0601 14:07:01.579766 24067 sgd_solver.cpp:106] Iteration 26960, lr = 0.01
I0601 14:07:07.069183 24067 solver.cpp:237] Iteration 26980, loss = 4.16531
I0601 14:07:07.069248 24067 solver.cpp:253]     Train net output #0: loss = 4.05005 (* 1 = 4.05005 loss)
I0601 14:07:07.069257 24067 sgd_solver.cpp:106] Iteration 26980, lr = 0.01
I0601 14:07:12.473253 24067 solver.cpp:341] Iteration 27000, Testing net (#0)
I0601 14:07:31.043022 24067 blocking_queue.cpp:50] Data layer prefetch queue empty
I0601 14:07:44.174039 24067 solver.cpp:409]     Test net output #0: accuracy = 0.20776
I0601 14:07:44.174089 24067 solver.cpp:409]     Test net output #1: loss = 4.03979 (* 1 = 4.03979 loss)
I0601 14:07:44.259802 24067 solver.cpp:237] Iteration 27000, loss = 4.12454
I0601 14:07:44.259842 24067 solver.cpp:253]     Train net output #0: loss = 4.13679 (* 1 = 4.13679 loss)
I0601 14:07:44.259852 24067 sgd_solver.cpp:106] Iteration 27000, lr = 0.01
I0601 14:07:49.712965 24067 solver.cpp:237] Iteration 27020, loss = 4.11817
I0601 14:07:49.713016 24067 solver.cpp:253]     Train net output #0: loss = 3.94109 (* 1 = 3.94109 loss)
I0601 14:07:49.713026 24067 sgd_solver.cpp:106] Iteration 27020, lr = 0.01
I0601 14:07:55.161592 24067 solver.cpp:237] Iteration 27040, loss = 4.09937
I0601 14:07:55.161640 24067 solver.cpp:253]     Train net output #0: loss = 4.06722 (* 1 = 4.06722 loss)
I0601 14:07:55.161650 24067 sgd_solver.cpp:106] Iteration 27040, lr = 0.01
I0601 14:08:00.617116 24067 solver.cpp:237] Iteration 27060, loss = 4.13151
I0601 14:08:00.617166 24067 solver.cpp:253]     Train net output #0: loss = 4.14894 (* 1 = 4.14894 loss)
I0601 14:08:00.617175 24067 sgd_solver.cpp:106] Iteration 27060, lr = 0.01
I0601 14:08:06.074096 24067 solver.cpp:237] Iteration 27080, loss = 4.16469
I0601 14:08:06.074314 24067 solver.cpp:253]     Train net output #0: loss = 4.17673 (* 1 = 4.17673 loss)
I0601 14:08:06.074337 24067 sgd_solver.cpp:106] Iteration 27080, lr = 0.01
I0601 14:08:11.536098 24067 solver.cpp:237] Iteration 27100, loss = 4.15579
I0601 14:08:11.536134 24067 solver.cpp:253]     Train net output #0: loss = 3.92273 (* 1 = 3.92273 loss)
I0601 14:08:11.536141 24067 sgd_solver.cpp:106] Iteration 27100, lr = 0.01
I0601 14:08:16.997457 24067 solver.cpp:237] Iteration 27120, loss = 4.17644
I0601 14:08:16.997506 24067 solver.cpp:253]     Train net output #0: loss = 4.47828 (* 1 = 4.47828 loss)
I0601 14:08:16.997514 24067 sgd_solver.cpp:106] Iteration 27120, lr = 0.01
I0601 14:08:22.428027 24067 solver.cpp:237] Iteration 27140, loss = 4.16343
I0601 14:08:22.428067 24067 solver.cpp:253]     Train net output #0: loss = 4.3313 (* 1 = 4.3313 loss)
I0601 14:08:22.428073 24067 sgd_solver.cpp:106] Iteration 27140, lr = 0.01
I0601 14:08:27.851935 24067 solver.cpp:237] Iteration 27160, loss = 4.1693
I0601 14:08:27.851971 24067 solver.cpp:253]     Train net output #0: loss = 3.83137 (* 1 = 3.83137 loss)
I0601 14:08:27.851976 24067 sgd_solver.cpp:106] Iteration 27160, lr = 0.01
I0601 14:08:33.273366 24067 solver.cpp:237] Iteration 27180, loss = 4.15722
I0601 14:08:33.273411 24067 solver.cpp:253]     Train net output #0: loss = 4.13108 (* 1 = 4.13108 loss)
I0601 14:08:33.273416 24067 sgd_solver.cpp:106] Iteration 27180, lr = 0.01
I0601 14:08:38.695359 24067 solver.cpp:237] Iteration 27200, loss = 4.10823
I0601 14:08:38.695586 24067 solver.cpp:253]     Train net output #0: loss = 4.10898 (* 1 = 4.10898 loss)
I0601 14:08:38.695612 24067 sgd_solver.cpp:106] Iteration 27200, lr = 0.01
I0601 14:08:44.123441 24067 solver.cpp:237] Iteration 27220, loss = 4.11983
I0601 14:08:44.123493 24067 solver.cpp:253]     Train net output #0: loss = 4.04498 (* 1 = 4.04498 loss)
I0601 14:08:44.123504 24067 sgd_solver.cpp:106] Iteration 27220, lr = 0.01
I0601 14:08:49.589689 24067 solver.cpp:237] Iteration 27240, loss = 4.19498
I0601 14:08:49.589740 24067 solver.cpp:253]     Train net output #0: loss = 4.1103 (* 1 = 4.1103 loss)
I0601 14:08:49.589751 24067 sgd_solver.cpp:106] Iteration 27240, lr = 0.01
I0601 14:08:55.068585 24067 solver.cpp:237] Iteration 27260, loss = 4.24829
I0601 14:08:55.068634 24067 solver.cpp:253]     Train net output #0: loss = 4.40531 (* 1 = 4.40531 loss)
I0601 14:08:55.068645 24067 sgd_solver.cpp:106] Iteration 27260, lr = 0.01
I0601 14:09:00.549360 24067 solver.cpp:237] Iteration 27280, loss = 4.25567
I0601 14:09:00.549407 24067 solver.cpp:253]     Train net output #0: loss = 4.24639 (* 1 = 4.24639 loss)
I0601 14:09:00.549428 24067 sgd_solver.cpp:106] Iteration 27280, lr = 0.01
I0601 14:09:06.026684 24067 solver.cpp:237] Iteration 27300, loss = 4.18864
I0601 14:09:06.026731 24067 solver.cpp:253]     Train net output #0: loss = 4.49045 (* 1 = 4.49045 loss)
I0601 14:09:06.026742 24067 sgd_solver.cpp:106] Iteration 27300, lr = 0.01
I0601 14:09:11.504168 24067 solver.cpp:237] Iteration 27320, loss = 4.17278
I0601 14:09:11.504439 24067 solver.cpp:253]     Train net output #0: loss = 4.01506 (* 1 = 4.01506 loss)
I0601 14:09:11.504465 24067 sgd_solver.cpp:106] Iteration 27320, lr = 0.01
I0601 14:09:16.988483 24067 solver.cpp:237] Iteration 27340, loss = 4.19588
I0601 14:09:16.988528 24067 solver.cpp:253]     Train net output #0: loss = 4.17067 (* 1 = 4.17067 loss)
I0601 14:09:16.988534 24067 sgd_solver.cpp:106] Iteration 27340, lr = 0.01
I0601 14:09:22.439721 24067 solver.cpp:237] Iteration 27360, loss = 4.15447
I0601 14:09:22.439774 24067 solver.cpp:253]     Train net output #0: loss = 3.9808 (* 1 = 3.9808 loss)
I0601 14:09:22.439784 24067 sgd_solver.cpp:106] Iteration 27360, lr = 0.01
I0601 14:09:27.869601 24067 solver.cpp:237] Iteration 27380, loss = 4.16124
I0601 14:09:27.869649 24067 solver.cpp:253]     Train net output #0: loss = 4.34249 (* 1 = 4.34249 loss)
I0601 14:09:27.869658 24067 sgd_solver.cpp:106] Iteration 27380, lr = 0.01
I0601 14:09:33.347656 24067 solver.cpp:237] Iteration 27400, loss = 4.2154
I0601 14:09:33.347704 24067 solver.cpp:253]     Train net output #0: loss = 4.15599 (* 1 = 4.15599 loss)
I0601 14:09:33.347712 24067 sgd_solver.cpp:106] Iteration 27400, lr = 0.01
I0601 14:09:38.835626 24067 solver.cpp:237] Iteration 27420, loss = 4.20151
I0601 14:09:38.835669 24067 solver.cpp:253]     Train net output #0: loss = 4.21702 (* 1 = 4.21702 loss)
I0601 14:09:38.835675 24067 sgd_solver.cpp:106] Iteration 27420, lr = 0.01
I0601 14:09:44.267477 24067 solver.cpp:237] Iteration 27440, loss = 4.1533
I0601 14:09:44.267686 24067 solver.cpp:253]     Train net output #0: loss = 4.1441 (* 1 = 4.1441 loss)
I0601 14:09:44.267711 24067 sgd_solver.cpp:106] Iteration 27440, lr = 0.01
I0601 14:09:49.730872 24067 solver.cpp:237] Iteration 27460, loss = 4.11734
I0601 14:09:49.730923 24067 solver.cpp:253]     Train net output #0: loss = 4.23805 (* 1 = 4.23805 loss)
I0601 14:09:49.730943 24067 sgd_solver.cpp:106] Iteration 27460, lr = 0.01
I0601 14:09:55.217614 24067 solver.cpp:237] Iteration 27480, loss = 4.14944
I0601 14:09:55.217665 24067 solver.cpp:253]     Train net output #0: loss = 4.31541 (* 1 = 4.31541 loss)
I0601 14:09:55.217675 24067 sgd_solver.cpp:106] Iteration 27480, lr = 0.01
I0601 14:10:00.709597 24067 solver.cpp:237] Iteration 27500, loss = 4.15141
I0601 14:10:00.709653 24067 solver.cpp:253]     Train net output #0: loss = 4.16788 (* 1 = 4.16788 loss)
I0601 14:10:00.709664 24067 sgd_solver.cpp:106] Iteration 27500, lr = 0.01
I0601 14:10:06.193264 24067 solver.cpp:237] Iteration 27520, loss = 4.12412
I0601 14:10:06.193312 24067 solver.cpp:253]     Train net output #0: loss = 4.00943 (* 1 = 4.00943 loss)
I0601 14:10:06.193322 24067 sgd_solver.cpp:106] Iteration 27520, lr = 0.01
I0601 14:10:11.680933 24067 solver.cpp:237] Iteration 27540, loss = 4.13388
I0601 14:10:11.680977 24067 solver.cpp:253]     Train net output #0: loss = 3.90164 (* 1 = 3.90164 loss)
I0601 14:10:11.680985 24067 sgd_solver.cpp:106] Iteration 27540, lr = 0.01
I0601 14:10:17.164433 24067 solver.cpp:237] Iteration 27560, loss = 4.13479
I0601 14:10:17.164686 24067 solver.cpp:253]     Train net output #0: loss = 4.09173 (* 1 = 4.09173 loss)
I0601 14:10:17.164711 24067 sgd_solver.cpp:106] Iteration 27560, lr = 0.01
I0601 14:10:22.649440 24067 solver.cpp:237] Iteration 27580, loss = 4.14864
I0601 14:10:22.649490 24067 solver.cpp:253]     Train net output #0: loss = 3.9891 (* 1 = 3.9891 loss)
I0601 14:10:22.649498 24067 sgd_solver.cpp:106] Iteration 27580, lr = 0.01
I0601 14:10:28.137097 24067 solver.cpp:237] Iteration 27600, loss = 4.11592
I0601 14:10:28.137146 24067 solver.cpp:253]     Train net output #0: loss = 4.06304 (* 1 = 4.06304 loss)
I0601 14:10:28.137154 24067 sgd_solver.cpp:106] Iteration 27600, lr = 0.01
I0601 14:10:33.618795 24067 solver.cpp:237] Iteration 27620, loss = 4.148
I0601 14:10:33.618839 24067 solver.cpp:253]     Train net output #0: loss = 4.26978 (* 1 = 4.26978 loss)
I0601 14:10:33.618847 24067 sgd_solver.cpp:106] Iteration 27620, lr = 0.01
I0601 14:10:39.109796 24067 solver.cpp:237] Iteration 27640, loss = 4.19351
I0601 14:10:39.109841 24067 solver.cpp:253]     Train net output #0: loss = 4.42062 (* 1 = 4.42062 loss)
I0601 14:10:39.109848 24067 sgd_solver.cpp:106] Iteration 27640, lr = 0.01
I0601 14:10:44.593996 24067 solver.cpp:237] Iteration 27660, loss = 4.18581
I0601 14:10:44.594043 24067 solver.cpp:253]     Train net output #0: loss = 4.17336 (* 1 = 4.17336 loss)
I0601 14:10:44.594050 24067 sgd_solver.cpp:106] Iteration 27660, lr = 0.01
I0601 14:10:50.085575 24067 solver.cpp:237] Iteration 27680, loss = 4.17559
I0601 14:10:50.085808 24067 solver.cpp:253]     Train net output #0: loss = 4.10633 (* 1 = 4.10633 loss)
I0601 14:10:50.085831 24067 sgd_solver.cpp:106] Iteration 27680, lr = 0.01
I0601 14:10:55.576092 24067 solver.cpp:237] Iteration 27700, loss = 4.19896
I0601 14:10:55.576153 24067 solver.cpp:253]     Train net output #0: loss = 3.86765 (* 1 = 3.86765 loss)
I0601 14:10:55.576161 24067 sgd_solver.cpp:106] Iteration 27700, lr = 0.01
I0601 14:11:01.065739 24067 solver.cpp:237] Iteration 27720, loss = 4.13953
I0601 14:11:01.065803 24067 solver.cpp:253]     Train net output #0: loss = 3.88133 (* 1 = 3.88133 loss)
I0601 14:11:01.065811 24067 sgd_solver.cpp:106] Iteration 27720, lr = 0.01
I0601 14:11:06.554679 24067 solver.cpp:237] Iteration 27740, loss = 4.1611
I0601 14:11:06.554725 24067 solver.cpp:253]     Train net output #0: loss = 4.11621 (* 1 = 4.11621 loss)
I0601 14:11:06.554733 24067 sgd_solver.cpp:106] Iteration 27740, lr = 0.01
I0601 14:11:12.041800 24067 solver.cpp:237] Iteration 27760, loss = 4.17273
I0601 14:11:12.041846 24067 solver.cpp:253]     Train net output #0: loss = 4.05047 (* 1 = 4.05047 loss)
I0601 14:11:12.041854 24067 sgd_solver.cpp:106] Iteration 27760, lr = 0.01
I0601 14:11:17.534854 24067 solver.cpp:237] Iteration 27780, loss = 4.11633
I0601 14:11:17.534904 24067 solver.cpp:253]     Train net output #0: loss = 4.14191 (* 1 = 4.14191 loss)
I0601 14:11:17.534924 24067 sgd_solver.cpp:106] Iteration 27780, lr = 0.01
I0601 14:11:23.018507 24067 solver.cpp:237] Iteration 27800, loss = 4.19728
I0601 14:11:23.018765 24067 solver.cpp:253]     Train net output #0: loss = 4.17002 (* 1 = 4.17002 loss)
I0601 14:11:23.018790 24067 sgd_solver.cpp:106] Iteration 27800, lr = 0.01
I0601 14:11:28.503525 24067 solver.cpp:237] Iteration 27820, loss = 4.23046
I0601 14:11:28.503571 24067 solver.cpp:253]     Train net output #0: loss = 4.31571 (* 1 = 4.31571 loss)
I0601 14:11:28.503589 24067 sgd_solver.cpp:106] Iteration 27820, lr = 0.01
I0601 14:11:33.996474 24067 solver.cpp:237] Iteration 27840, loss = 4.11768
I0601 14:11:33.996523 24067 solver.cpp:253]     Train net output #0: loss = 4.12036 (* 1 = 4.12036 loss)
I0601 14:11:33.996533 24067 sgd_solver.cpp:106] Iteration 27840, lr = 0.01
I0601 14:11:39.487795 24067 solver.cpp:237] Iteration 27860, loss = 4.18324
I0601 14:11:39.487845 24067 solver.cpp:253]     Train net output #0: loss = 4.21423 (* 1 = 4.21423 loss)
I0601 14:11:39.487855 24067 sgd_solver.cpp:106] Iteration 27860, lr = 0.01
I0601 14:11:44.974094 24067 solver.cpp:237] Iteration 27880, loss = 4.22626
I0601 14:11:44.974143 24067 solver.cpp:253]     Train net output #0: loss = 4.14759 (* 1 = 4.14759 loss)
I0601 14:11:44.974150 24067 sgd_solver.cpp:106] Iteration 27880, lr = 0.01
I0601 14:11:50.465983 24067 solver.cpp:237] Iteration 27900, loss = 4.12426
I0601 14:11:50.466033 24067 solver.cpp:253]     Train net output #0: loss = 4.12432 (* 1 = 4.12432 loss)
I0601 14:11:50.466042 24067 sgd_solver.cpp:106] Iteration 27900, lr = 0.01
I0601 14:11:55.956478 24067 solver.cpp:237] Iteration 27920, loss = 4.15234
I0601 14:11:55.956660 24067 solver.cpp:253]     Train net output #0: loss = 4.27921 (* 1 = 4.27921 loss)
I0601 14:11:55.956671 24067 sgd_solver.cpp:106] Iteration 27920, lr = 0.01
I0601 14:12:01.450088 24067 solver.cpp:237] Iteration 27940, loss = 4.22378
I0601 14:12:01.450139 24067 solver.cpp:253]     Train net output #0: loss = 4.16995 (* 1 = 4.16995 loss)
I0601 14:12:01.450147 24067 sgd_solver.cpp:106] Iteration 27940, lr = 0.01
I0601 14:12:06.944392 24067 solver.cpp:237] Iteration 27960, loss = 4.1602
I0601 14:12:06.944453 24067 solver.cpp:253]     Train net output #0: loss = 4.16021 (* 1 = 4.16021 loss)
I0601 14:12:06.944463 24067 sgd_solver.cpp:106] Iteration 27960, lr = 0.01
I0601 14:12:12.438052 24067 solver.cpp:237] Iteration 27980, loss = 4.20181
I0601 14:12:12.438104 24067 solver.cpp:253]     Train net output #0: loss = 4.27631 (* 1 = 4.27631 loss)
I0601 14:12:12.438112 24067 sgd_solver.cpp:106] Iteration 27980, lr = 0.01
I0601 14:12:17.840518 24067 solver.cpp:341] Iteration 28000, Testing net (#0)
I0601 14:12:35.568285 24067 blocking_queue.cpp:50] Data layer prefetch queue empty
I0601 14:12:48.594360 24067 solver.cpp:409]     Test net output #0: accuracy = 0.21122
I0601 14:12:48.594422 24067 solver.cpp:409]     Test net output #1: loss = 3.9979 (* 1 = 3.9979 loss)
I0601 14:12:48.678702 24067 solver.cpp:237] Iteration 28000, loss = 4.11413
I0601 14:12:48.678740 24067 solver.cpp:253]     Train net output #0: loss = 4.02834 (* 1 = 4.02834 loss)
I0601 14:12:48.678750 24067 sgd_solver.cpp:106] Iteration 28000, lr = 0.01
I0601 14:12:54.138712 24067 solver.cpp:237] Iteration 28020, loss = 4.17047
I0601 14:12:54.138761 24067 solver.cpp:253]     Train net output #0: loss = 4.16434 (* 1 = 4.16434 loss)
I0601 14:12:54.138782 24067 sgd_solver.cpp:106] Iteration 28020, lr = 0.01
I0601 14:12:59.605183 24067 solver.cpp:237] Iteration 28040, loss = 4.11056
I0601 14:12:59.605235 24067 solver.cpp:253]     Train net output #0: loss = 4.18525 (* 1 = 4.18525 loss)
I0601 14:12:59.605245 24067 sgd_solver.cpp:106] Iteration 28040, lr = 0.01
I0601 14:13:05.076356 24067 solver.cpp:237] Iteration 28060, loss = 4.14903
I0601 14:13:05.076419 24067 solver.cpp:253]     Train net output #0: loss = 4.20011 (* 1 = 4.20011 loss)
I0601 14:13:05.076428 24067 sgd_solver.cpp:106] Iteration 28060, lr = 0.01
I0601 14:13:10.540133 24067 solver.cpp:237] Iteration 28080, loss = 4.16098
I0601 14:13:10.540315 24067 solver.cpp:253]     Train net output #0: loss = 3.93539 (* 1 = 3.93539 loss)
I0601 14:13:10.540325 24067 sgd_solver.cpp:106] Iteration 28080, lr = 0.01
I0601 14:13:16.004928 24067 solver.cpp:237] Iteration 28100, loss = 4.16841
I0601 14:13:16.004976 24067 solver.cpp:253]     Train net output #0: loss = 4.14373 (* 1 = 4.14373 loss)
I0601 14:13:16.004984 24067 sgd_solver.cpp:106] Iteration 28100, lr = 0.01
I0601 14:13:21.473175 24067 solver.cpp:237] Iteration 28120, loss = 4.19115
I0601 14:13:21.473222 24067 solver.cpp:253]     Train net output #0: loss = 4.17266 (* 1 = 4.17266 loss)
I0601 14:13:21.473230 24067 sgd_solver.cpp:106] Iteration 28120, lr = 0.01
I0601 14:13:26.941555 24067 solver.cpp:237] Iteration 28140, loss = 4.2186
I0601 14:13:26.941604 24067 solver.cpp:253]     Train net output #0: loss = 3.88748 (* 1 = 3.88748 loss)
I0601 14:13:26.941613 24067 sgd_solver.cpp:106] Iteration 28140, lr = 0.01
I0601 14:13:32.417124 24067 solver.cpp:237] Iteration 28160, loss = 4.16852
I0601 14:13:32.417173 24067 solver.cpp:253]     Train net output #0: loss = 4.21173 (* 1 = 4.21173 loss)
I0601 14:13:32.417181 24067 sgd_solver.cpp:106] Iteration 28160, lr = 0.01
I0601 14:13:37.893975 24067 solver.cpp:237] Iteration 28180, loss = 4.10618
I0601 14:13:37.894021 24067 solver.cpp:253]     Train net output #0: loss = 4.13838 (* 1 = 4.13838 loss)
I0601 14:13:37.894028 24067 sgd_solver.cpp:106] Iteration 28180, lr = 0.01
I0601 14:13:43.364884 24067 solver.cpp:237] Iteration 28200, loss = 4.08612
I0601 14:13:43.365057 24067 solver.cpp:253]     Train net output #0: loss = 4.31639 (* 1 = 4.31639 loss)
I0601 14:13:43.365067 24067 sgd_solver.cpp:106] Iteration 28200, lr = 0.01
I0601 14:13:48.846436 24067 solver.cpp:237] Iteration 28220, loss = 4.10836
I0601 14:13:48.846483 24067 solver.cpp:253]     Train net output #0: loss = 4.03864 (* 1 = 4.03864 loss)
I0601 14:13:48.846492 24067 sgd_solver.cpp:106] Iteration 28220, lr = 0.01
I0601 14:13:54.331598 24067 solver.cpp:237] Iteration 28240, loss = 4.17509
I0601 14:13:54.331646 24067 solver.cpp:253]     Train net output #0: loss = 4.06311 (* 1 = 4.06311 loss)
I0601 14:13:54.331655 24067 sgd_solver.cpp:106] Iteration 28240, lr = 0.01
I0601 14:13:59.811743 24067 solver.cpp:237] Iteration 28260, loss = 4.17148
I0601 14:13:59.811789 24067 solver.cpp:253]     Train net output #0: loss = 4.11018 (* 1 = 4.11018 loss)
I0601 14:13:59.811797 24067 sgd_solver.cpp:106] Iteration 28260, lr = 0.01
I0601 14:14:05.297359 24067 solver.cpp:237] Iteration 28280, loss = 4.10878
I0601 14:14:05.297407 24067 solver.cpp:253]     Train net output #0: loss = 4.14889 (* 1 = 4.14889 loss)
I0601 14:14:05.297416 24067 sgd_solver.cpp:106] Iteration 28280, lr = 0.01
I0601 14:14:10.779316 24067 solver.cpp:237] Iteration 28300, loss = 4.1549
I0601 14:14:10.779355 24067 solver.cpp:253]     Train net output #0: loss = 4.22875 (* 1 = 4.22875 loss)
I0601 14:14:10.779364 24067 sgd_solver.cpp:106] Iteration 28300, lr = 0.01
I0601 14:14:16.263710 24067 solver.cpp:237] Iteration 28320, loss = 4.14762
I0601 14:14:16.263980 24067 solver.cpp:253]     Train net output #0: loss = 4.25051 (* 1 = 4.25051 loss)
I0601 14:14:16.264005 24067 sgd_solver.cpp:106] Iteration 28320, lr = 0.01
I0601 14:14:21.737905 24067 solver.cpp:237] Iteration 28340, loss = 4.08987
I0601 14:14:21.737948 24067 solver.cpp:253]     Train net output #0: loss = 4.15301 (* 1 = 4.15301 loss)
I0601 14:14:21.737956 24067 sgd_solver.cpp:106] Iteration 28340, lr = 0.01
I0601 14:14:27.196640 24067 solver.cpp:237] Iteration 28360, loss = 4.21832
I0601 14:14:27.196683 24067 solver.cpp:253]     Train net output #0: loss = 4.26346 (* 1 = 4.26346 loss)
I0601 14:14:27.196691 24067 sgd_solver.cpp:106] Iteration 28360, lr = 0.01
I0601 14:14:32.674223 24067 solver.cpp:237] Iteration 28380, loss = 4.16876
I0601 14:14:32.674273 24067 solver.cpp:253]     Train net output #0: loss = 4.01047 (* 1 = 4.01047 loss)
I0601 14:14:32.674283 24067 sgd_solver.cpp:106] Iteration 28380, lr = 0.01
I0601 14:14:38.150043 24067 solver.cpp:237] Iteration 28400, loss = 4.15269
I0601 14:14:38.150094 24067 solver.cpp:253]     Train net output #0: loss = 4.3352 (* 1 = 4.3352 loss)
I0601 14:14:38.150099 24067 sgd_solver.cpp:106] Iteration 28400, lr = 0.01
I0601 14:14:43.634757 24067 solver.cpp:237] Iteration 28420, loss = 4.12223
I0601 14:14:43.634799 24067 solver.cpp:253]     Train net output #0: loss = 4.07858 (* 1 = 4.07858 loss)
I0601 14:14:43.634804 24067 sgd_solver.cpp:106] Iteration 28420, lr = 0.01
I0601 14:14:49.116524 24067 solver.cpp:237] Iteration 28440, loss = 4.10136
I0601 14:14:49.116715 24067 solver.cpp:253]     Train net output #0: loss = 4.05258 (* 1 = 4.05258 loss)
I0601 14:14:49.116741 24067 sgd_solver.cpp:106] Iteration 28440, lr = 0.01
I0601 14:14:54.601825 24067 solver.cpp:237] Iteration 28460, loss = 4.08889
I0601 14:14:54.601863 24067 solver.cpp:253]     Train net output #0: loss = 4.04638 (* 1 = 4.04638 loss)
I0601 14:14:54.601872 24067 sgd_solver.cpp:106] Iteration 28460, lr = 0.01
I0601 14:15:00.045825 24067 solver.cpp:237] Iteration 28480, loss = 4.13197
I0601 14:15:00.045871 24067 solver.cpp:253]     Train net output #0: loss = 4.20164 (* 1 = 4.20164 loss)
I0601 14:15:00.045881 24067 sgd_solver.cpp:106] Iteration 28480, lr = 0.01
I0601 14:15:05.479192 24067 solver.cpp:237] Iteration 28500, loss = 4.1548
I0601 14:15:05.479238 24067 solver.cpp:253]     Train net output #0: loss = 4.22717 (* 1 = 4.22717 loss)
I0601 14:15:05.479248 24067 sgd_solver.cpp:106] Iteration 28500, lr = 0.01
I0601 14:15:10.916731 24067 solver.cpp:237] Iteration 28520, loss = 4.11673
I0601 14:15:10.916765 24067 solver.cpp:253]     Train net output #0: loss = 4.08175 (* 1 = 4.08175 loss)
I0601 14:15:10.916774 24067 sgd_solver.cpp:106] Iteration 28520, lr = 0.01
I0601 14:15:16.376770 24067 solver.cpp:237] Iteration 28540, loss = 4.16561
I0601 14:15:16.376812 24067 solver.cpp:253]     Train net output #0: loss = 3.99391 (* 1 = 3.99391 loss)
I0601 14:15:16.376821 24067 sgd_solver.cpp:106] Iteration 28540, lr = 0.01
I0601 14:15:21.819257 24067 solver.cpp:237] Iteration 28560, loss = 4.14076
I0601 14:15:21.819483 24067 solver.cpp:253]     Train net output #0: loss = 3.99054 (* 1 = 3.99054 loss)
I0601 14:15:21.819506 24067 sgd_solver.cpp:106] Iteration 28560, lr = 0.01
I0601 14:15:27.257377 24067 solver.cpp:237] Iteration 28580, loss = 4.19883
I0601 14:15:27.257427 24067 solver.cpp:253]     Train net output #0: loss = 3.9331 (* 1 = 3.9331 loss)
I0601 14:15:27.257437 24067 sgd_solver.cpp:106] Iteration 28580, lr = 0.01
I0601 14:15:32.701014 24067 solver.cpp:237] Iteration 28600, loss = 4.13839
I0601 14:15:32.701063 24067 solver.cpp:253]     Train net output #0: loss = 4.22982 (* 1 = 4.22982 loss)
I0601 14:15:32.701073 24067 sgd_solver.cpp:106] Iteration 28600, lr = 0.01
I0601 14:15:38.137178 24067 solver.cpp:237] Iteration 28620, loss = 4.14464
I0601 14:15:38.137228 24067 solver.cpp:253]     Train net output #0: loss = 4.13028 (* 1 = 4.13028 loss)
I0601 14:15:38.137238 24067 sgd_solver.cpp:106] Iteration 28620, lr = 0.01
I0601 14:15:43.577585 24067 solver.cpp:237] Iteration 28640, loss = 4.16393
I0601 14:15:43.577635 24067 solver.cpp:253]     Train net output #0: loss = 4.41595 (* 1 = 4.41595 loss)
I0601 14:15:43.577643 24067 sgd_solver.cpp:106] Iteration 28640, lr = 0.01
I0601 14:15:49.012712 24067 solver.cpp:237] Iteration 28660, loss = 4.09934
I0601 14:15:49.012759 24067 solver.cpp:253]     Train net output #0: loss = 3.99021 (* 1 = 3.99021 loss)
I0601 14:15:49.012769 24067 sgd_solver.cpp:106] Iteration 28660, lr = 0.01
I0601 14:15:54.453546 24067 solver.cpp:237] Iteration 28680, loss = 4.1154
I0601 14:15:54.453760 24067 solver.cpp:253]     Train net output #0: loss = 4.05488 (* 1 = 4.05488 loss)
I0601 14:15:54.453781 24067 sgd_solver.cpp:106] Iteration 28680, lr = 0.01
I0601 14:15:59.888540 24067 solver.cpp:237] Iteration 28700, loss = 4.17372
I0601 14:15:59.888578 24067 solver.cpp:253]     Train net output #0: loss = 4.34048 (* 1 = 4.34048 loss)
I0601 14:15:59.888584 24067 sgd_solver.cpp:106] Iteration 28700, lr = 0.01
I0601 14:16:05.320631 24067 solver.cpp:237] Iteration 28720, loss = 4.1725
I0601 14:16:05.320674 24067 solver.cpp:253]     Train net output #0: loss = 4.16005 (* 1 = 4.16005 loss)
I0601 14:16:05.320680 24067 sgd_solver.cpp:106] Iteration 28720, lr = 0.01
I0601 14:16:10.755221 24067 solver.cpp:237] Iteration 28740, loss = 4.15874
I0601 14:16:10.755256 24067 solver.cpp:253]     Train net output #0: loss = 4.12534 (* 1 = 4.12534 loss)
I0601 14:16:10.755275 24067 sgd_solver.cpp:106] Iteration 28740, lr = 0.01
I0601 14:16:16.191541 24067 solver.cpp:237] Iteration 28760, loss = 4.15714
I0601 14:16:16.191584 24067 solver.cpp:253]     Train net output #0: loss = 3.9001 (* 1 = 3.9001 loss)
I0601 14:16:16.191591 24067 sgd_solver.cpp:106] Iteration 28760, lr = 0.01
I0601 14:16:21.664927 24067 solver.cpp:237] Iteration 28780, loss = 4.11949
I0601 14:16:21.664968 24067 solver.cpp:253]     Train net output #0: loss = 4.34434 (* 1 = 4.34434 loss)
I0601 14:16:21.664973 24067 sgd_solver.cpp:106] Iteration 28780, lr = 0.01
I0601 14:16:27.138036 24067 solver.cpp:237] Iteration 28800, loss = 4.18225
I0601 14:16:27.138236 24067 solver.cpp:253]     Train net output #0: loss = 4.49561 (* 1 = 4.49561 loss)
I0601 14:16:27.138248 24067 sgd_solver.cpp:106] Iteration 28800, lr = 0.01
I0601 14:16:32.576120 24067 solver.cpp:237] Iteration 28820, loss = 4.14265
I0601 14:16:32.576165 24067 solver.cpp:253]     Train net output #0: loss = 4.3491 (* 1 = 4.3491 loss)
I0601 14:16:32.576171 24067 sgd_solver.cpp:106] Iteration 28820, lr = 0.01
I0601 14:16:38.012357 24067 solver.cpp:237] Iteration 28840, loss = 4.11726
I0601 14:16:38.012415 24067 solver.cpp:253]     Train net output #0: loss = 3.88948 (* 1 = 3.88948 loss)
I0601 14:16:38.012423 24067 sgd_solver.cpp:106] Iteration 28840, lr = 0.01
I0601 14:16:43.477573 24067 solver.cpp:237] Iteration 28860, loss = 4.12833
I0601 14:16:43.477619 24067 solver.cpp:253]     Train net output #0: loss = 4.03806 (* 1 = 4.03806 loss)
I0601 14:16:43.477625 24067 sgd_solver.cpp:106] Iteration 28860, lr = 0.01
I0601 14:16:48.960815 24067 solver.cpp:237] Iteration 28880, loss = 4.10824
I0601 14:16:48.960861 24067 solver.cpp:253]     Train net output #0: loss = 4.10088 (* 1 = 4.10088 loss)
I0601 14:16:48.960866 24067 sgd_solver.cpp:106] Iteration 28880, lr = 0.01
I0601 14:16:54.446851 24067 solver.cpp:237] Iteration 28900, loss = 4.16582
I0601 14:16:54.446903 24067 solver.cpp:253]     Train net output #0: loss = 4.21118 (* 1 = 4.21118 loss)
I0601 14:16:54.446913 24067 sgd_solver.cpp:106] Iteration 28900, lr = 0.01
I0601 14:16:59.933794 24067 solver.cpp:237] Iteration 28920, loss = 4.14505
I0601 14:16:59.934077 24067 solver.cpp:253]     Train net output #0: loss = 4.11599 (* 1 = 4.11599 loss)
I0601 14:16:59.934100 24067 sgd_solver.cpp:106] Iteration 28920, lr = 0.01
I0601 14:17:05.423889 24067 solver.cpp:237] Iteration 28940, loss = 4.19173
I0601 14:17:05.423938 24067 solver.cpp:253]     Train net output #0: loss = 4.04087 (* 1 = 4.04087 loss)
I0601 14:17:05.423944 24067 sgd_solver.cpp:106] Iteration 28940, lr = 0.01
I0601 14:17:10.907667 24067 solver.cpp:237] Iteration 28960, loss = 4.12153
I0601 14:17:10.907707 24067 solver.cpp:253]     Train net output #0: loss = 4.29277 (* 1 = 4.29277 loss)
I0601 14:17:10.907713 24067 sgd_solver.cpp:106] Iteration 28960, lr = 0.01
I0601 14:17:16.393329 24067 solver.cpp:237] Iteration 28980, loss = 4.1267
I0601 14:17:16.393370 24067 solver.cpp:253]     Train net output #0: loss = 4.07295 (* 1 = 4.07295 loss)
I0601 14:17:16.393375 24067 sgd_solver.cpp:106] Iteration 28980, lr = 0.01
I0601 14:17:21.788565 24067 solver.cpp:341] Iteration 29000, Testing net (#0)
I0601 14:17:41.037245 24067 blocking_queue.cpp:50] Data layer prefetch queue empty
I0601 14:17:53.524555 24067 solver.cpp:409]     Test net output #0: accuracy = 0.21724
I0601 14:17:53.524605 24067 solver.cpp:409]     Test net output #1: loss = 3.95408 (* 1 = 3.95408 loss)
I0601 14:17:53.604902 24067 solver.cpp:237] Iteration 29000, loss = 4.12332
I0601 14:17:53.604948 24067 solver.cpp:253]     Train net output #0: loss = 4.21295 (* 1 = 4.21295 loss)
I0601 14:17:53.604959 24067 sgd_solver.cpp:106] Iteration 29000, lr = 0.01
I0601 14:17:59.053341 24067 solver.cpp:237] Iteration 29020, loss = 4.13341
I0601 14:17:59.053390 24067 solver.cpp:253]     Train net output #0: loss = 4.34148 (* 1 = 4.34148 loss)
I0601 14:17:59.053401 24067 sgd_solver.cpp:106] Iteration 29020, lr = 0.01
I0601 14:18:04.510699 24067 solver.cpp:237] Iteration 29040, loss = 4.14311
I0601 14:18:04.510742 24067 solver.cpp:253]     Train net output #0: loss = 4.48689 (* 1 = 4.48689 loss)
I0601 14:18:04.510754 24067 sgd_solver.cpp:106] Iteration 29040, lr = 0.01
I0601 14:18:09.966217 24067 solver.cpp:237] Iteration 29060, loss = 4.16101
I0601 14:18:09.966267 24067 solver.cpp:253]     Train net output #0: loss = 4.14244 (* 1 = 4.14244 loss)
I0601 14:18:09.966276 24067 sgd_solver.cpp:106] Iteration 29060, lr = 0.01
I0601 14:18:15.428503 24067 solver.cpp:237] Iteration 29080, loss = 4.14151
I0601 14:18:15.428730 24067 solver.cpp:253]     Train net output #0: loss = 4.29599 (* 1 = 4.29599 loss)
I0601 14:18:15.428758 24067 sgd_solver.cpp:106] Iteration 29080, lr = 0.01
I0601 14:18:20.890493 24067 solver.cpp:237] Iteration 29100, loss = 4.03006
I0601 14:18:20.890533 24067 solver.cpp:253]     Train net output #0: loss = 4.01676 (* 1 = 4.01676 loss)
I0601 14:18:20.890543 24067 sgd_solver.cpp:106] Iteration 29100, lr = 0.01
I0601 14:18:26.356809 24067 solver.cpp:237] Iteration 29120, loss = 4.11768
I0601 14:18:26.356866 24067 solver.cpp:253]     Train net output #0: loss = 4.08183 (* 1 = 4.08183 loss)
I0601 14:18:26.356875 24067 sgd_solver.cpp:106] Iteration 29120, lr = 0.01
I0601 14:18:31.823931 24067 solver.cpp:237] Iteration 29140, loss = 4.15222
I0601 14:18:31.823982 24067 solver.cpp:253]     Train net output #0: loss = 4.29519 (* 1 = 4.29519 loss)
I0601 14:18:31.823993 24067 sgd_solver.cpp:106] Iteration 29140, lr = 0.01
I0601 14:18:37.290343 24067 solver.cpp:237] Iteration 29160, loss = 4.1025
I0601 14:18:37.290390 24067 solver.cpp:253]     Train net output #0: loss = 4.0926 (* 1 = 4.0926 loss)
I0601 14:18:37.290397 24067 sgd_solver.cpp:106] Iteration 29160, lr = 0.01
I0601 14:18:42.753301 24067 solver.cpp:237] Iteration 29180, loss = 4.11039
I0601 14:18:42.753345 24067 solver.cpp:253]     Train net output #0: loss = 3.94907 (* 1 = 3.94907 loss)
I0601 14:18:42.753365 24067 sgd_solver.cpp:106] Iteration 29180, lr = 0.01
