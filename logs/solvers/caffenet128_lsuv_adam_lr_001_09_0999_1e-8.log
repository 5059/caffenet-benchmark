I0124 14:08:16.343152 26758 caffe.cpp:184] Using GPUs 0
I0124 14:08:16.905256 26758 solver.cpp:47] Initializing solver from parameters: 
test_iter: 1000
test_interval: 1000
base_lr: 0.01
display: 20
max_iter: 320000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0005
snapshot: 10000
snapshot_prefix: "snapshots/caffenet128_lsuv_adam"
solver_mode: GPU
device_id: 0
net_param {
  name: "CaffeNet"
  layer {
    name: "data"
    type: "Data"
    top: "data"
    top: "label"
    include {
      phase: TRAIN
    }
    transform_param {
      scale: 0.04
      mirror: true
      crop_size: 128
      mean_value: 104
      mean_value: 117
      mean_value: 124
      force_color: true
      resize_param {
        prob: 1
        resize_mode: FIT_SMALL_SIZE
        height: 144
        width: 144
        pad_mode: MIRRORED
        pad_value: 104
        pad_value: 117
        pad_value: 124
        interp_mode: LINEAR
        center_object: false
        max_angle: 0
      }
    }
    data_param {
      source: "/local/temporary/imagenet_clc_orig/ilsvrc12_train_shuffle_lmdb"
      batch_size: 128
      backend: LMDB
    }
  }
  layer {
    name: "data"
    type: "Data"
    top: "data"
    top: "label"
    include {
      phase: TEST
    }
    transform_param {
      scale: 0.04
      mirror: false
      crop_size: 128
      mean_value: 104
      mean_value: 117
      mean_value: 123
      force_color: true
      resize_param {
        prob: 1
        resize_mode: FIT_SMALL_SIZE
        height: 144
        width: 144
        pad_mode: MIRRORED
        pad_value: 104
        pad_value: 117
        pad_value: 124
        interp_mode: LINEAR
        center_object: false
        max_angle: 0
      }
    }
    data_param {
      source: "/local/temporary/imagenet_clc_orig/ilsvrc12_val_lmdb"
      batch_size: 50
      backend: LMDB
    }
  }
  layer {
    name: "conv1"
    type: "Convolution"
    bottom: "data"
    top: "conv1"
    param {
      lr_mult: 1
      decay_mult: 1
    }
    param {
      lr_mult: 2
      decay_mult: 0
    }
    convolution_param {
      num_output: 96
      kernel_size: 11
      stride: 4
      weight_filler {
        type: "gaussian"
        std: 0.01
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layer {
    name: "relu1"
    type: "ReLU"
    bottom: "conv1"
    top: "relu1"
  }
  layer {
    name: "pool1"
    type: "Pooling"
    bottom: "relu1"
    top: "pool1"
    pooling_param {
      pool: MAX
      kernel_size: 3
      stride: 2
    }
  }
  layer {
    name: "conv2"
    type: "Convolution"
    bottom: "pool1"
    top: "conv2"
    param {
      lr_mult: 1
      decay_mult: 1
    }
    param {
      lr_mult: 2
      decay_mult: 0
    }
    convolution_param {
      num_output: 256
      pad: 2
      kernel_size: 5
      group: 2
      weight_filler {
        type: "gaussian"
        std: 0.01
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layer {
    name: "relu2"
    type: "ReLU"
    bottom: "conv2"
    top: "relu2"
  }
  layer {
    name: "pool2"
    type: "Pooling"
    bottom: "relu2"
    top: "pool2"
    pooling_param {
      pool: MAX
      kernel_size: 3
      stride: 2
    }
  }
  layer {
    name: "conv3"
    type: "Convolution"
    bottom: "pool2"
    top: "conv3"
    param {
      lr_mult: 1
      decay_mult: 1
    }
    param {
      lr_mult: 2
      decay_mult: 0
    }
    convolution_param {
      num_output: 384
      pad: 1
      kernel_size: 3
      weight_filler {
        type: "gaussian"
        std: 0.01
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layer {
    name: "relu3"
    type: "ReLU"
    bottom: "conv3"
    top: "relu3"
  }
  layer {
    name: "conv4"
    type: "Convolution"
    bottom: "relu3"
    top: "conv4"
    param {
      lr_mult: 1
      decay_mult: 1
    }
    param {
      lr_mult: 2
      decay_mult: 0
    }
    convolution_param {
      num_output: 384
      pad: 1
      kernel_size: 3
      group: 2
      weight_filler {
        type: "gaussian"
        std: 0.01
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layer {
    name: "relu4"
    type: "ReLU"
    bottom: "conv4"
    top: "relu4"
  }
  layer {
    name: "conv5"
    type: "Convolution"
    bottom: "relu4"
    top: "conv5"
    param {
      lr_mult: 1
      decay_mult: 1
    }
    param {
      lr_mult: 2
      decay_mult: 0
    }
    convolution_param {
      num_output: 256
      pad: 1
      kernel_size: 3
      group: 2
      weight_filler {
        type: "gaussian"
        std: 0.01
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layer {
    name: "relu5"
    type: "ReLU"
    bottom: "conv5"
    top: "relu5"
  }
  layer {
    name: "pool5"
    type: "Pooling"
    bottom: "relu5"
    top: "pool5"
    pooling_param {
      pool: MAX
      kernel_size: 3
      stride: 2
    }
  }
  layer {
    name: "fc6"
    type: "InnerProduct"
    bottom: "pool5"
    top: "fc6"
    param {
      lr_mult: 1
      decay_mult: 1
    }
    param {
      lr_mult: 2
      decay_mult: 0
    }
    inner_product_param {
      num_output: 2048
      weight_filler {
        type: "gaussian"
        std: 0.005
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layer {
    name: "relu6"
    type: "ReLU"
    bottom: "fc6"
    top: "relu6"
  }
  layer {
    name: "drop6"
    type: "Dropout"
    bottom: "relu6"
    top: "drop6"
    dropout_param {
      dropout_ratio: 0.5
    }
  }
  layer {
    name: "fc7"
    type: "InnerProduct"
    bottom: "drop6"
    top: "fc7"
    param {
      lr_mult: 1
      decay_mult: 1
    }
    param {
      lr_mult: 2
      decay_mult: 0
    }
    inner_product_param {
      num_output: 2048
      weight_filler {
        type: "gaussian"
        std: 0.005
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layer {
    name: "relu7"
    type: "ReLU"
    bottom: "fc7"
    top: "relu7"
  }
  layer {
    name: "drop7"
    type: "Dropout"
    bottom: "relu7"
    top: "drop7"
    dropout_param {
      dropout_ratio: 0.5
    }
  }
  layer {
    name: "fc8"
    type: "InnerProduct"
    bottom: "drop7"
    top: "fc8"
    param {
      lr_mult: 1
      decay_mult: 1
    }
    param {
      lr_mult: 2
      decay_mult: 0
    }
    inner_product_param {
      num_output: 1000
      weight_filler {
        type: "gaussian"
        std: 0.01
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layer {
    name: "accuracy"
    type: "Accuracy"
    bottom: "fc8"
    bottom: "label"
    top: "accuracy"
    include {
      phase: TEST
    }
  }
  layer {
    name: "loss"
    type: "SoftmaxWithLoss"
    bottom: "fc8"
    bottom: "label"
    top: "loss"
  }
}
delta: 1e-08
test_initialization: false
iter_size: 1
momentum2: 0.999
type: "Adam"
I0124 14:08:16.906352 26758 solver.cpp:85] Creating training net specified in net_param.
I0124 14:08:16.906494 26758 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0124 14:08:16.906525 26758 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0124 14:08:16.906805 26758 net.cpp:49] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.04
    mirror: true
    crop_size: 128
    mean_value: 104
    mean_value: 117
    mean_value: 124
    force_color: true
    resize_param {
      prob: 1
      resize_mode: FIT_SMALL_SIZE
      height: 144
      width: 144
      pad_mode: MIRRORED
      pad_value: 104
      pad_value: 117
      pad_value: 124
      interp_mode: LINEAR
      center_object: false
      max_angle: 0
    }
  }
  data_param {
    source: "/local/temporary/imagenet_clc_orig/ilsvrc12_train_shuffle_lmdb"
    batch_size: 128
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "relu1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "relu1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "relu2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "relu2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "relu3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "relu3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "relu4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "relu4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "relu5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "relu5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "relu6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "relu6"
  top: "drop6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "drop6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "relu7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "relu7"
  top: "drop7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "drop7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0124 14:08:16.907428 26758 layer_factory.hpp:76] Creating layer data
I0124 14:08:16.908058 26758 net.cpp:106] Creating Layer data
I0124 14:08:16.908097 26758 net.cpp:411] data -> data
I0124 14:08:16.908129 26758 net.cpp:411] data -> label
I0124 14:08:16.909478 26864 db_lmdb.cpp:38] Opened lmdb /local/temporary/imagenet_clc_orig/ilsvrc12_train_shuffle_lmdb
I0124 14:08:16.933411 26758 data_layer.cpp:41] output data size: 128,3,128,128
I0124 14:08:16.995802 26758 net.cpp:150] Setting up data
I0124 14:08:16.995851 26758 net.cpp:157] Top shape: 128 3 128 128 (6291456)
I0124 14:08:16.995859 26758 net.cpp:157] Top shape: 128 (128)
I0124 14:08:16.995864 26758 net.cpp:165] Memory required for data: 25166336
I0124 14:08:16.995878 26758 layer_factory.hpp:76] Creating layer conv1
I0124 14:08:16.995899 26758 net.cpp:106] Creating Layer conv1
I0124 14:08:16.995908 26758 net.cpp:454] conv1 <- data
I0124 14:08:16.995939 26758 net.cpp:411] conv1 -> conv1
I0124 14:08:17.166707 26758 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 4356
I0124 14:08:17.166864 26758 net.cpp:150] Setting up conv1
I0124 14:08:17.166880 26758 net.cpp:157] Top shape: 128 96 30 30 (11059200)
I0124 14:08:17.166887 26758 net.cpp:165] Memory required for data: 69403136
I0124 14:08:17.166916 26758 layer_factory.hpp:76] Creating layer relu1
I0124 14:08:17.166929 26758 net.cpp:106] Creating Layer relu1
I0124 14:08:17.166934 26758 net.cpp:454] relu1 <- conv1
I0124 14:08:17.166941 26758 net.cpp:411] relu1 -> relu1
I0124 14:08:17.167151 26758 net.cpp:150] Setting up relu1
I0124 14:08:17.167161 26758 net.cpp:157] Top shape: 128 96 30 30 (11059200)
I0124 14:08:17.167165 26758 net.cpp:165] Memory required for data: 113639936
I0124 14:08:17.167170 26758 layer_factory.hpp:76] Creating layer pool1
I0124 14:08:17.167179 26758 net.cpp:106] Creating Layer pool1
I0124 14:08:17.167184 26758 net.cpp:454] pool1 <- relu1
I0124 14:08:17.167196 26758 net.cpp:411] pool1 -> pool1
I0124 14:08:17.167538 26758 net.cpp:150] Setting up pool1
I0124 14:08:17.167562 26758 net.cpp:157] Top shape: 128 96 15 15 (2764800)
I0124 14:08:17.167564 26758 net.cpp:165] Memory required for data: 124699136
I0124 14:08:17.167577 26758 layer_factory.hpp:76] Creating layer conv2
I0124 14:08:17.167589 26758 net.cpp:106] Creating Layer conv2
I0124 14:08:17.167593 26758 net.cpp:454] conv2 <- pool1
I0124 14:08:17.167599 26758 net.cpp:411] conv2 -> conv2
I0124 14:08:17.179823 26758 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 28800
I0124 14:08:17.179847 26758 net.cpp:150] Setting up conv2
I0124 14:08:17.179854 26758 net.cpp:157] Top shape: 128 256 15 15 (7372800)
I0124 14:08:17.179858 26758 net.cpp:165] Memory required for data: 154190336
I0124 14:08:17.179868 26758 layer_factory.hpp:76] Creating layer relu2
I0124 14:08:17.179877 26758 net.cpp:106] Creating Layer relu2
I0124 14:08:17.179882 26758 net.cpp:454] relu2 <- conv2
I0124 14:08:17.179886 26758 net.cpp:411] relu2 -> relu2
I0124 14:08:17.180102 26758 net.cpp:150] Setting up relu2
I0124 14:08:17.180112 26758 net.cpp:157] Top shape: 128 256 15 15 (7372800)
I0124 14:08:17.180116 26758 net.cpp:165] Memory required for data: 183681536
I0124 14:08:17.180120 26758 layer_factory.hpp:76] Creating layer pool2
I0124 14:08:17.180126 26758 net.cpp:106] Creating Layer pool2
I0124 14:08:17.180133 26758 net.cpp:454] pool2 <- relu2
I0124 14:08:17.180138 26758 net.cpp:411] pool2 -> pool2
I0124 14:08:17.180467 26758 net.cpp:150] Setting up pool2
I0124 14:08:17.180480 26758 net.cpp:157] Top shape: 128 256 7 7 (1605632)
I0124 14:08:17.180485 26758 net.cpp:165] Memory required for data: 190104064
I0124 14:08:17.180488 26758 layer_factory.hpp:76] Creating layer conv3
I0124 14:08:17.180508 26758 net.cpp:106] Creating Layer conv3
I0124 14:08:17.180511 26758 net.cpp:454] conv3 <- pool2
I0124 14:08:17.180519 26758 net.cpp:411] conv3 -> conv3
I0124 14:08:17.210356 26758 net.cpp:150] Setting up conv3
I0124 14:08:17.210384 26758 net.cpp:157] Top shape: 128 384 7 7 (2408448)
I0124 14:08:17.210389 26758 net.cpp:165] Memory required for data: 199737856
I0124 14:08:17.210404 26758 layer_factory.hpp:76] Creating layer relu3
I0124 14:08:17.210417 26758 net.cpp:106] Creating Layer relu3
I0124 14:08:17.210420 26758 net.cpp:454] relu3 <- conv3
I0124 14:08:17.210427 26758 net.cpp:411] relu3 -> relu3
I0124 14:08:17.210803 26758 net.cpp:150] Setting up relu3
I0124 14:08:17.210814 26758 net.cpp:157] Top shape: 128 384 7 7 (2408448)
I0124 14:08:17.210819 26758 net.cpp:165] Memory required for data: 209371648
I0124 14:08:17.210822 26758 layer_factory.hpp:76] Creating layer conv4
I0124 14:08:17.210835 26758 net.cpp:106] Creating Layer conv4
I0124 14:08:17.210845 26758 net.cpp:454] conv4 <- relu3
I0124 14:08:17.210852 26758 net.cpp:411] conv4 -> conv4
I0124 14:08:17.234330 26758 net.cpp:150] Setting up conv4
I0124 14:08:17.234356 26758 net.cpp:157] Top shape: 128 384 7 7 (2408448)
I0124 14:08:17.234360 26758 net.cpp:165] Memory required for data: 219005440
I0124 14:08:17.234369 26758 layer_factory.hpp:76] Creating layer relu4
I0124 14:08:17.234379 26758 net.cpp:106] Creating Layer relu4
I0124 14:08:17.234382 26758 net.cpp:454] relu4 <- conv4
I0124 14:08:17.234388 26758 net.cpp:411] relu4 -> relu4
I0124 14:08:17.234601 26758 net.cpp:150] Setting up relu4
I0124 14:08:17.234611 26758 net.cpp:157] Top shape: 128 384 7 7 (2408448)
I0124 14:08:17.234616 26758 net.cpp:165] Memory required for data: 228639232
I0124 14:08:17.234618 26758 layer_factory.hpp:76] Creating layer conv5
I0124 14:08:17.234630 26758 net.cpp:106] Creating Layer conv5
I0124 14:08:17.234637 26758 net.cpp:454] conv5 <- relu4
I0124 14:08:17.234642 26758 net.cpp:411] conv5 -> conv5
I0124 14:08:17.251116 26758 net.cpp:150] Setting up conv5
I0124 14:08:17.251132 26758 net.cpp:157] Top shape: 128 256 7 7 (1605632)
I0124 14:08:17.251142 26758 net.cpp:165] Memory required for data: 235061760
I0124 14:08:17.251153 26758 layer_factory.hpp:76] Creating layer relu5
I0124 14:08:17.251160 26758 net.cpp:106] Creating Layer relu5
I0124 14:08:17.251171 26758 net.cpp:454] relu5 <- conv5
I0124 14:08:17.251178 26758 net.cpp:411] relu5 -> relu5
I0124 14:08:17.251394 26758 net.cpp:150] Setting up relu5
I0124 14:08:17.251405 26758 net.cpp:157] Top shape: 128 256 7 7 (1605632)
I0124 14:08:17.251410 26758 net.cpp:165] Memory required for data: 241484288
I0124 14:08:17.251413 26758 layer_factory.hpp:76] Creating layer pool5
I0124 14:08:17.251425 26758 net.cpp:106] Creating Layer pool5
I0124 14:08:17.251428 26758 net.cpp:454] pool5 <- relu5
I0124 14:08:17.251435 26758 net.cpp:411] pool5 -> pool5
I0124 14:08:17.251801 26758 net.cpp:150] Setting up pool5
I0124 14:08:17.251813 26758 net.cpp:157] Top shape: 128 256 3 3 (294912)
I0124 14:08:17.251816 26758 net.cpp:165] Memory required for data: 242663936
I0124 14:08:17.251823 26758 layer_factory.hpp:76] Creating layer fc6
I0124 14:08:17.251833 26758 net.cpp:106] Creating Layer fc6
I0124 14:08:17.251837 26758 net.cpp:454] fc6 <- pool5
I0124 14:08:17.251843 26758 net.cpp:411] fc6 -> fc6
I0124 14:08:17.403998 26758 net.cpp:150] Setting up fc6
I0124 14:08:17.404032 26758 net.cpp:157] Top shape: 128 2048 (262144)
I0124 14:08:17.404036 26758 net.cpp:165] Memory required for data: 243712512
I0124 14:08:17.404047 26758 layer_factory.hpp:76] Creating layer relu6
I0124 14:08:17.404058 26758 net.cpp:106] Creating Layer relu6
I0124 14:08:17.404062 26758 net.cpp:454] relu6 <- fc6
I0124 14:08:17.404069 26758 net.cpp:411] relu6 -> relu6
I0124 14:08:17.404352 26758 net.cpp:150] Setting up relu6
I0124 14:08:17.404367 26758 net.cpp:157] Top shape: 128 2048 (262144)
I0124 14:08:17.404373 26758 net.cpp:165] Memory required for data: 244761088
I0124 14:08:17.404376 26758 layer_factory.hpp:76] Creating layer drop6
I0124 14:08:17.404393 26758 net.cpp:106] Creating Layer drop6
I0124 14:08:17.404397 26758 net.cpp:454] drop6 <- relu6
I0124 14:08:17.404402 26758 net.cpp:411] drop6 -> drop6
I0124 14:08:17.404448 26758 net.cpp:150] Setting up drop6
I0124 14:08:17.404456 26758 net.cpp:157] Top shape: 128 2048 (262144)
I0124 14:08:17.404461 26758 net.cpp:165] Memory required for data: 245809664
I0124 14:08:17.404464 26758 layer_factory.hpp:76] Creating layer fc7
I0124 14:08:17.404474 26758 net.cpp:106] Creating Layer fc7
I0124 14:08:17.404477 26758 net.cpp:454] fc7 <- drop6
I0124 14:08:17.404491 26758 net.cpp:411] fc7 -> fc7
I0124 14:08:17.538965 26758 net.cpp:150] Setting up fc7
I0124 14:08:17.539021 26758 net.cpp:157] Top shape: 128 2048 (262144)
I0124 14:08:17.539024 26758 net.cpp:165] Memory required for data: 246858240
I0124 14:08:17.539036 26758 layer_factory.hpp:76] Creating layer relu7
I0124 14:08:17.539046 26758 net.cpp:106] Creating Layer relu7
I0124 14:08:17.539049 26758 net.cpp:454] relu7 <- fc7
I0124 14:08:17.539057 26758 net.cpp:411] relu7 -> relu7
I0124 14:08:17.539530 26758 net.cpp:150] Setting up relu7
I0124 14:08:17.539542 26758 net.cpp:157] Top shape: 128 2048 (262144)
I0124 14:08:17.539546 26758 net.cpp:165] Memory required for data: 247906816
I0124 14:08:17.539549 26758 layer_factory.hpp:76] Creating layer drop7
I0124 14:08:17.539558 26758 net.cpp:106] Creating Layer drop7
I0124 14:08:17.539566 26758 net.cpp:454] drop7 <- relu7
I0124 14:08:17.539577 26758 net.cpp:411] drop7 -> drop7
I0124 14:08:17.539630 26758 net.cpp:150] Setting up drop7
I0124 14:08:17.539640 26758 net.cpp:157] Top shape: 128 2048 (262144)
I0124 14:08:17.539645 26758 net.cpp:165] Memory required for data: 248955392
I0124 14:08:17.539669 26758 layer_factory.hpp:76] Creating layer fc8
I0124 14:08:17.539686 26758 net.cpp:106] Creating Layer fc8
I0124 14:08:17.539695 26758 net.cpp:454] fc8 <- drop7
I0124 14:08:17.539707 26758 net.cpp:411] fc8 -> fc8
I0124 14:08:17.605226 26758 net.cpp:150] Setting up fc8
I0124 14:08:17.605254 26758 net.cpp:157] Top shape: 128 1000 (128000)
I0124 14:08:17.605260 26758 net.cpp:165] Memory required for data: 249467392
I0124 14:08:17.605273 26758 layer_factory.hpp:76] Creating layer loss
I0124 14:08:17.605296 26758 net.cpp:106] Creating Layer loss
I0124 14:08:17.605312 26758 net.cpp:454] loss <- fc8
I0124 14:08:17.605327 26758 net.cpp:454] loss <- label
I0124 14:08:17.605335 26758 net.cpp:411] loss -> loss
I0124 14:08:17.605350 26758 layer_factory.hpp:76] Creating layer loss
I0124 14:08:17.606484 26758 net.cpp:150] Setting up loss
I0124 14:08:17.606498 26758 net.cpp:157] Top shape: (1)
I0124 14:08:17.606500 26758 net.cpp:160]     with loss weight 1
I0124 14:08:17.606529 26758 net.cpp:165] Memory required for data: 249467396
I0124 14:08:17.606533 26758 net.cpp:226] loss needs backward computation.
I0124 14:08:17.606537 26758 net.cpp:226] fc8 needs backward computation.
I0124 14:08:17.606540 26758 net.cpp:226] drop7 needs backward computation.
I0124 14:08:17.606544 26758 net.cpp:226] relu7 needs backward computation.
I0124 14:08:17.606547 26758 net.cpp:226] fc7 needs backward computation.
I0124 14:08:17.606551 26758 net.cpp:226] drop6 needs backward computation.
I0124 14:08:17.606555 26758 net.cpp:226] relu6 needs backward computation.
I0124 14:08:17.606559 26758 net.cpp:226] fc6 needs backward computation.
I0124 14:08:17.606562 26758 net.cpp:226] pool5 needs backward computation.
I0124 14:08:17.606565 26758 net.cpp:226] relu5 needs backward computation.
I0124 14:08:17.606569 26758 net.cpp:226] conv5 needs backward computation.
I0124 14:08:17.606572 26758 net.cpp:226] relu4 needs backward computation.
I0124 14:08:17.606576 26758 net.cpp:226] conv4 needs backward computation.
I0124 14:08:17.606580 26758 net.cpp:226] relu3 needs backward computation.
I0124 14:08:17.606583 26758 net.cpp:226] conv3 needs backward computation.
I0124 14:08:17.606586 26758 net.cpp:226] pool2 needs backward computation.
I0124 14:08:17.606590 26758 net.cpp:226] relu2 needs backward computation.
I0124 14:08:17.606595 26758 net.cpp:226] conv2 needs backward computation.
I0124 14:08:17.606601 26758 net.cpp:226] pool1 needs backward computation.
I0124 14:08:17.606606 26758 net.cpp:226] relu1 needs backward computation.
I0124 14:08:17.606616 26758 net.cpp:226] conv1 needs backward computation.
I0124 14:08:17.606619 26758 net.cpp:228] data does not need backward computation.
I0124 14:08:17.606622 26758 net.cpp:270] This network produces output loss
I0124 14:08:17.606645 26758 net.cpp:283] Network initialization done.
I0124 14:08:17.606792 26758 solver.cpp:180] Creating test net (#0) specified by net_param
I0124 14:08:17.606837 26758 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0124 14:08:17.607200 26758 net.cpp:49] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.04
    mirror: false
    crop_size: 128
    mean_value: 104
    mean_value: 117
    mean_value: 123
    force_color: true
    resize_param {
      prob: 1
      resize_mode: FIT_SMALL_SIZE
      height: 144
      width: 144
      pad_mode: MIRRORED
      pad_value: 104
      pad_value: 117
      pad_value: 124
      interp_mode: LINEAR
      center_object: false
      max_angle: 0
    }
  }
  data_param {
    source: "/local/temporary/imagenet_clc_orig/ilsvrc12_val_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "relu1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "relu1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "relu2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "relu2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "relu3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "relu3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "relu4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "relu4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "relu5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "relu5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "relu6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "relu6"
  top: "drop6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "drop6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "relu7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "relu7"
  top: "drop7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "drop7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0124 14:08:17.607348 26758 layer_factory.hpp:76] Creating layer data
I0124 14:08:17.607463 26758 net.cpp:106] Creating Layer data
I0124 14:08:17.607481 26758 net.cpp:411] data -> data
I0124 14:08:17.607492 26758 net.cpp:411] data -> label
I0124 14:08:17.608808 26934 db_lmdb.cpp:38] Opened lmdb /local/temporary/imagenet_clc_orig/ilsvrc12_val_lmdb
I0124 14:08:17.611599 26758 data_layer.cpp:41] output data size: 50,3,128,128
I0124 14:08:17.629719 26758 net.cpp:150] Setting up data
I0124 14:08:17.629745 26758 net.cpp:157] Top shape: 50 3 128 128 (2457600)
I0124 14:08:17.629751 26758 net.cpp:157] Top shape: 50 (50)
I0124 14:08:17.629755 26758 net.cpp:165] Memory required for data: 9830600
I0124 14:08:17.629760 26758 layer_factory.hpp:76] Creating layer label_data_1_split
I0124 14:08:17.629772 26758 net.cpp:106] Creating Layer label_data_1_split
I0124 14:08:17.629776 26758 net.cpp:454] label_data_1_split <- label
I0124 14:08:17.629784 26758 net.cpp:411] label_data_1_split -> label_data_1_split_0
I0124 14:08:17.629796 26758 net.cpp:411] label_data_1_split -> label_data_1_split_1
I0124 14:08:17.629866 26758 net.cpp:150] Setting up label_data_1_split
I0124 14:08:17.629873 26758 net.cpp:157] Top shape: 50 (50)
I0124 14:08:17.629878 26758 net.cpp:157] Top shape: 50 (50)
I0124 14:08:17.629881 26758 net.cpp:165] Memory required for data: 9831000
I0124 14:08:17.629885 26758 layer_factory.hpp:76] Creating layer conv1
I0124 14:08:17.629899 26758 net.cpp:106] Creating Layer conv1
I0124 14:08:17.629911 26758 net.cpp:454] conv1 <- data
I0124 14:08:17.629917 26758 net.cpp:411] conv1 -> conv1
I0124 14:08:17.632369 26758 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 4356
I0124 14:08:17.632416 26758 net.cpp:150] Setting up conv1
I0124 14:08:17.632423 26758 net.cpp:157] Top shape: 50 96 30 30 (4320000)
I0124 14:08:17.632429 26758 net.cpp:165] Memory required for data: 27111000
I0124 14:08:17.632449 26758 layer_factory.hpp:76] Creating layer relu1
I0124 14:08:17.632457 26758 net.cpp:106] Creating Layer relu1
I0124 14:08:17.632462 26758 net.cpp:454] relu1 <- conv1
I0124 14:08:17.632467 26758 net.cpp:411] relu1 -> relu1
I0124 14:08:17.632802 26758 net.cpp:150] Setting up relu1
I0124 14:08:17.632814 26758 net.cpp:157] Top shape: 50 96 30 30 (4320000)
I0124 14:08:17.632818 26758 net.cpp:165] Memory required for data: 44391000
I0124 14:08:17.632822 26758 layer_factory.hpp:76] Creating layer pool1
I0124 14:08:17.632832 26758 net.cpp:106] Creating Layer pool1
I0124 14:08:17.632834 26758 net.cpp:454] pool1 <- relu1
I0124 14:08:17.632839 26758 net.cpp:411] pool1 -> pool1
I0124 14:08:17.633054 26758 net.cpp:150] Setting up pool1
I0124 14:08:17.633064 26758 net.cpp:157] Top shape: 50 96 15 15 (1080000)
I0124 14:08:17.633067 26758 net.cpp:165] Memory required for data: 48711000
I0124 14:08:17.633074 26758 layer_factory.hpp:76] Creating layer conv2
I0124 14:08:17.633082 26758 net.cpp:106] Creating Layer conv2
I0124 14:08:17.633085 26758 net.cpp:454] conv2 <- pool1
I0124 14:08:17.633091 26758 net.cpp:411] conv2 -> conv2
I0124 14:08:17.645534 26758 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 28800
I0124 14:08:17.645591 26758 net.cpp:150] Setting up conv2
I0124 14:08:17.645598 26758 net.cpp:157] Top shape: 50 256 15 15 (2880000)
I0124 14:08:17.645602 26758 net.cpp:165] Memory required for data: 60231000
I0124 14:08:17.645614 26758 layer_factory.hpp:76] Creating layer relu2
I0124 14:08:17.645622 26758 net.cpp:106] Creating Layer relu2
I0124 14:08:17.645625 26758 net.cpp:454] relu2 <- conv2
I0124 14:08:17.645630 26758 net.cpp:411] relu2 -> relu2
I0124 14:08:17.645853 26758 net.cpp:150] Setting up relu2
I0124 14:08:17.645864 26758 net.cpp:157] Top shape: 50 256 15 15 (2880000)
I0124 14:08:17.645869 26758 net.cpp:165] Memory required for data: 71751000
I0124 14:08:17.645872 26758 layer_factory.hpp:76] Creating layer pool2
I0124 14:08:17.645879 26758 net.cpp:106] Creating Layer pool2
I0124 14:08:17.645882 26758 net.cpp:454] pool2 <- relu2
I0124 14:08:17.645889 26758 net.cpp:411] pool2 -> pool2
I0124 14:08:17.646252 26758 net.cpp:150] Setting up pool2
I0124 14:08:17.646263 26758 net.cpp:157] Top shape: 50 256 7 7 (627200)
I0124 14:08:17.646275 26758 net.cpp:165] Memory required for data: 74259800
I0124 14:08:17.646278 26758 layer_factory.hpp:76] Creating layer conv3
I0124 14:08:17.646301 26758 net.cpp:106] Creating Layer conv3
I0124 14:08:17.646306 26758 net.cpp:454] conv3 <- pool2
I0124 14:08:17.646311 26758 net.cpp:411] conv3 -> conv3
I0124 14:08:17.677494 26758 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 27648
I0124 14:08:17.677541 26758 net.cpp:150] Setting up conv3
I0124 14:08:17.677548 26758 net.cpp:157] Top shape: 50 384 7 7 (940800)
I0124 14:08:17.677554 26758 net.cpp:165] Memory required for data: 78023000
I0124 14:08:17.677567 26758 layer_factory.hpp:76] Creating layer relu3
I0124 14:08:17.677578 26758 net.cpp:106] Creating Layer relu3
I0124 14:08:17.677582 26758 net.cpp:454] relu3 <- conv3
I0124 14:08:17.677589 26758 net.cpp:411] relu3 -> relu3
I0124 14:08:17.677811 26758 net.cpp:150] Setting up relu3
I0124 14:08:17.677822 26758 net.cpp:157] Top shape: 50 384 7 7 (940800)
I0124 14:08:17.677826 26758 net.cpp:165] Memory required for data: 81786200
I0124 14:08:17.677829 26758 layer_factory.hpp:76] Creating layer conv4
I0124 14:08:17.677841 26758 net.cpp:106] Creating Layer conv4
I0124 14:08:17.677846 26758 net.cpp:454] conv4 <- relu3
I0124 14:08:17.677855 26758 net.cpp:411] conv4 -> conv4
I0124 14:08:17.702435 26758 net.cpp:150] Setting up conv4
I0124 14:08:17.702457 26758 net.cpp:157] Top shape: 50 384 7 7 (940800)
I0124 14:08:17.702461 26758 net.cpp:165] Memory required for data: 85549400
I0124 14:08:17.702471 26758 layer_factory.hpp:76] Creating layer relu4
I0124 14:08:17.702479 26758 net.cpp:106] Creating Layer relu4
I0124 14:08:17.702482 26758 net.cpp:454] relu4 <- conv4
I0124 14:08:17.702488 26758 net.cpp:411] relu4 -> relu4
I0124 14:08:17.702710 26758 net.cpp:150] Setting up relu4
I0124 14:08:17.702721 26758 net.cpp:157] Top shape: 50 384 7 7 (940800)
I0124 14:08:17.702724 26758 net.cpp:165] Memory required for data: 89312600
I0124 14:08:17.702728 26758 layer_factory.hpp:76] Creating layer conv5
I0124 14:08:17.702739 26758 net.cpp:106] Creating Layer conv5
I0124 14:08:17.702744 26758 net.cpp:454] conv5 <- relu4
I0124 14:08:17.702751 26758 net.cpp:411] conv5 -> conv5
I0124 14:08:17.719689 26758 net.cpp:150] Setting up conv5
I0124 14:08:17.719707 26758 net.cpp:157] Top shape: 50 256 7 7 (627200)
I0124 14:08:17.719713 26758 net.cpp:165] Memory required for data: 91821400
I0124 14:08:17.719741 26758 layer_factory.hpp:76] Creating layer relu5
I0124 14:08:17.719753 26758 net.cpp:106] Creating Layer relu5
I0124 14:08:17.719763 26758 net.cpp:454] relu5 <- conv5
I0124 14:08:17.719779 26758 net.cpp:411] relu5 -> relu5
I0124 14:08:17.720137 26758 net.cpp:150] Setting up relu5
I0124 14:08:17.720161 26758 net.cpp:157] Top shape: 50 256 7 7 (627200)
I0124 14:08:17.720165 26758 net.cpp:165] Memory required for data: 94330200
I0124 14:08:17.720170 26758 layer_factory.hpp:76] Creating layer pool5
I0124 14:08:17.720177 26758 net.cpp:106] Creating Layer pool5
I0124 14:08:17.720180 26758 net.cpp:454] pool5 <- relu5
I0124 14:08:17.720230 26758 net.cpp:411] pool5 -> pool5
I0124 14:08:17.720469 26758 net.cpp:150] Setting up pool5
I0124 14:08:17.720482 26758 net.cpp:157] Top shape: 50 256 3 3 (115200)
I0124 14:08:17.720485 26758 net.cpp:165] Memory required for data: 94791000
I0124 14:08:17.720494 26758 layer_factory.hpp:76] Creating layer fc6
I0124 14:08:17.720511 26758 net.cpp:106] Creating Layer fc6
I0124 14:08:17.720515 26758 net.cpp:454] fc6 <- pool5
I0124 14:08:17.720530 26758 net.cpp:411] fc6 -> fc6
I0124 14:08:17.867715 26758 net.cpp:150] Setting up fc6
I0124 14:08:17.867753 26758 net.cpp:157] Top shape: 50 2048 (102400)
I0124 14:08:17.867756 26758 net.cpp:165] Memory required for data: 95200600
I0124 14:08:17.867768 26758 layer_factory.hpp:76] Creating layer relu6
I0124 14:08:17.867790 26758 net.cpp:106] Creating Layer relu6
I0124 14:08:17.867794 26758 net.cpp:454] relu6 <- fc6
I0124 14:08:17.867802 26758 net.cpp:411] relu6 -> relu6
I0124 14:08:17.868342 26758 net.cpp:150] Setting up relu6
I0124 14:08:17.868355 26758 net.cpp:157] Top shape: 50 2048 (102400)
I0124 14:08:17.868358 26758 net.cpp:165] Memory required for data: 95610200
I0124 14:08:17.868361 26758 layer_factory.hpp:76] Creating layer drop6
I0124 14:08:17.868368 26758 net.cpp:106] Creating Layer drop6
I0124 14:08:17.868371 26758 net.cpp:454] drop6 <- relu6
I0124 14:08:17.868378 26758 net.cpp:411] drop6 -> drop6
I0124 14:08:17.868432 26758 net.cpp:150] Setting up drop6
I0124 14:08:17.868438 26758 net.cpp:157] Top shape: 50 2048 (102400)
I0124 14:08:17.868440 26758 net.cpp:165] Memory required for data: 96019800
I0124 14:08:17.868444 26758 layer_factory.hpp:76] Creating layer fc7
I0124 14:08:17.868453 26758 net.cpp:106] Creating Layer fc7
I0124 14:08:17.868458 26758 net.cpp:454] fc7 <- drop6
I0124 14:08:17.868477 26758 net.cpp:411] fc7 -> fc7
I0124 14:08:17.987227 26758 net.cpp:150] Setting up fc7
I0124 14:08:17.987265 26758 net.cpp:157] Top shape: 50 2048 (102400)
I0124 14:08:17.987269 26758 net.cpp:165] Memory required for data: 96429400
I0124 14:08:17.987278 26758 layer_factory.hpp:76] Creating layer relu7
I0124 14:08:17.987289 26758 net.cpp:106] Creating Layer relu7
I0124 14:08:17.987293 26758 net.cpp:454] relu7 <- fc7
I0124 14:08:17.987299 26758 net.cpp:411] relu7 -> relu7
I0124 14:08:17.987570 26758 net.cpp:150] Setting up relu7
I0124 14:08:17.987578 26758 net.cpp:157] Top shape: 50 2048 (102400)
I0124 14:08:17.987581 26758 net.cpp:165] Memory required for data: 96839000
I0124 14:08:17.987584 26758 layer_factory.hpp:76] Creating layer drop7
I0124 14:08:17.987593 26758 net.cpp:106] Creating Layer drop7
I0124 14:08:17.987608 26758 net.cpp:454] drop7 <- relu7
I0124 14:08:17.987614 26758 net.cpp:411] drop7 -> drop7
I0124 14:08:17.987654 26758 net.cpp:150] Setting up drop7
I0124 14:08:17.987663 26758 net.cpp:157] Top shape: 50 2048 (102400)
I0124 14:08:17.987665 26758 net.cpp:165] Memory required for data: 97248600
I0124 14:08:17.987668 26758 layer_factory.hpp:76] Creating layer fc8
I0124 14:08:17.987678 26758 net.cpp:106] Creating Layer fc8
I0124 14:08:17.987682 26758 net.cpp:454] fc8 <- drop7
I0124 14:08:17.987689 26758 net.cpp:411] fc8 -> fc8
I0124 14:08:18.045146 26758 net.cpp:150] Setting up fc8
I0124 14:08:18.045183 26758 net.cpp:157] Top shape: 50 1000 (50000)
I0124 14:08:18.045187 26758 net.cpp:165] Memory required for data: 97448600
I0124 14:08:18.045197 26758 layer_factory.hpp:76] Creating layer fc8_fc8_0_split
I0124 14:08:18.045207 26758 net.cpp:106] Creating Layer fc8_fc8_0_split
I0124 14:08:18.045210 26758 net.cpp:454] fc8_fc8_0_split <- fc8
I0124 14:08:18.045233 26758 net.cpp:411] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0124 14:08:18.045243 26758 net.cpp:411] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0124 14:08:18.045302 26758 net.cpp:150] Setting up fc8_fc8_0_split
I0124 14:08:18.045310 26758 net.cpp:157] Top shape: 50 1000 (50000)
I0124 14:08:18.045315 26758 net.cpp:157] Top shape: 50 1000 (50000)
I0124 14:08:18.045317 26758 net.cpp:165] Memory required for data: 97848600
I0124 14:08:18.045321 26758 layer_factory.hpp:76] Creating layer accuracy
I0124 14:08:18.045356 26758 net.cpp:106] Creating Layer accuracy
I0124 14:08:18.045361 26758 net.cpp:454] accuracy <- fc8_fc8_0_split_0
I0124 14:08:18.045364 26758 net.cpp:454] accuracy <- label_data_1_split_0
I0124 14:08:18.045374 26758 net.cpp:411] accuracy -> accuracy
I0124 14:08:18.045382 26758 net.cpp:150] Setting up accuracy
I0124 14:08:18.045388 26758 net.cpp:157] Top shape: (1)
I0124 14:08:18.045392 26758 net.cpp:165] Memory required for data: 97848604
I0124 14:08:18.045397 26758 layer_factory.hpp:76] Creating layer loss
I0124 14:08:18.045403 26758 net.cpp:106] Creating Layer loss
I0124 14:08:18.045405 26758 net.cpp:454] loss <- fc8_fc8_0_split_1
I0124 14:08:18.045409 26758 net.cpp:454] loss <- label_data_1_split_1
I0124 14:08:18.045414 26758 net.cpp:411] loss -> loss
I0124 14:08:18.045423 26758 layer_factory.hpp:76] Creating layer loss
I0124 14:08:18.046051 26758 net.cpp:150] Setting up loss
I0124 14:08:18.046062 26758 net.cpp:157] Top shape: (1)
I0124 14:08:18.046066 26758 net.cpp:160]     with loss weight 1
I0124 14:08:18.046075 26758 net.cpp:165] Memory required for data: 97848608
I0124 14:08:18.046079 26758 net.cpp:226] loss needs backward computation.
I0124 14:08:18.046085 26758 net.cpp:228] accuracy does not need backward computation.
I0124 14:08:18.046090 26758 net.cpp:226] fc8_fc8_0_split needs backward computation.
I0124 14:08:18.046093 26758 net.cpp:226] fc8 needs backward computation.
I0124 14:08:18.046108 26758 net.cpp:226] drop7 needs backward computation.
I0124 14:08:18.046111 26758 net.cpp:226] relu7 needs backward computation.
I0124 14:08:18.046114 26758 net.cpp:226] fc7 needs backward computation.
I0124 14:08:18.046118 26758 net.cpp:226] drop6 needs backward computation.
I0124 14:08:18.046121 26758 net.cpp:226] relu6 needs backward computation.
I0124 14:08:18.046124 26758 net.cpp:226] fc6 needs backward computation.
I0124 14:08:18.046128 26758 net.cpp:226] pool5 needs backward computation.
I0124 14:08:18.046130 26758 net.cpp:226] relu5 needs backward computation.
I0124 14:08:18.046133 26758 net.cpp:226] conv5 needs backward computation.
I0124 14:08:18.046136 26758 net.cpp:226] relu4 needs backward computation.
I0124 14:08:18.046139 26758 net.cpp:226] conv4 needs backward computation.
I0124 14:08:18.046142 26758 net.cpp:226] relu3 needs backward computation.
I0124 14:08:18.046145 26758 net.cpp:226] conv3 needs backward computation.
I0124 14:08:18.046149 26758 net.cpp:226] pool2 needs backward computation.
I0124 14:08:18.046151 26758 net.cpp:226] relu2 needs backward computation.
I0124 14:08:18.046154 26758 net.cpp:226] conv2 needs backward computation.
I0124 14:08:18.046157 26758 net.cpp:226] pool1 needs backward computation.
I0124 14:08:18.046160 26758 net.cpp:226] relu1 needs backward computation.
I0124 14:08:18.046164 26758 net.cpp:226] conv1 needs backward computation.
I0124 14:08:18.046167 26758 net.cpp:228] label_data_1_split does not need backward computation.
I0124 14:08:18.046171 26758 net.cpp:228] data does not need backward computation.
I0124 14:08:18.046174 26758 net.cpp:270] This network produces output accuracy
I0124 14:08:18.046177 26758 net.cpp:270] This network produces output loss
I0124 14:08:18.046197 26758 net.cpp:283] Network initialization done.
I0124 14:08:18.046329 26758 solver.cpp:59] Solver scaffolding done.
I0124 14:08:18.047124 26758 caffe.cpp:128] Finetuning from caffenet128_lsuv_adagrad.prototxt.caffemodel
I0124 14:08:18.190850 26758 caffe.cpp:212] Starting Optimization
I0124 14:08:18.190879 26758 solver.cpp:287] Solving CaffeNet
I0124 14:08:18.190891 26758 solver.cpp:288] Learning Rate Policy: fixed
I0124 14:08:18.255192 26758 solver.cpp:236] Iteration 0, loss = 7.40782
I0124 14:08:18.255237 26758 solver.cpp:252]     Train net output #0: loss = 7.40782 (* 1 = 7.40782 loss)
I0124 14:08:18.255245 26758 sgd_solver.cpp:106] Iteration 0, lr = 0.01
I0124 14:08:18.645426 26758 blocking_queue.cpp:50] Data layer prefetch queue empty
I0124 14:08:22.558044 26758 solver.cpp:236] Iteration 20, loss = 6.89614
I0124 14:08:22.558101 26758 solver.cpp:252]     Train net output #0: loss = 6.89614 (* 1 = 6.89614 loss)
I0124 14:08:22.558152 26758 sgd_solver.cpp:106] Iteration 20, lr = 0.01
I0124 14:08:27.241935 26758 solver.cpp:236] Iteration 40, loss = 6.9266
I0124 14:08:27.241997 26758 solver.cpp:252]     Train net output #0: loss = 6.9266 (* 1 = 6.9266 loss)
I0124 14:08:27.242009 26758 sgd_solver.cpp:106] Iteration 40, lr = 0.01
I0124 14:08:31.955194 26758 solver.cpp:236] Iteration 60, loss = 6.91012
I0124 14:08:31.955277 26758 solver.cpp:252]     Train net output #0: loss = 6.91012 (* 1 = 6.91012 loss)
I0124 14:08:31.955291 26758 sgd_solver.cpp:106] Iteration 60, lr = 0.01
I0124 14:08:36.639271 26758 solver.cpp:236] Iteration 80, loss = 6.90047
I0124 14:08:36.639335 26758 solver.cpp:252]     Train net output #0: loss = 6.90047 (* 1 = 6.90047 loss)
I0124 14:08:36.639351 26758 sgd_solver.cpp:106] Iteration 80, lr = 0.01
I0124 14:08:41.322908 26758 solver.cpp:236] Iteration 100, loss = 6.9331
I0124 14:08:41.322980 26758 solver.cpp:252]     Train net output #0: loss = 6.9331 (* 1 = 6.9331 loss)
I0124 14:08:41.322996 26758 sgd_solver.cpp:106] Iteration 100, lr = 0.01
I0124 14:08:46.076984 26758 solver.cpp:236] Iteration 120, loss = 6.92387
I0124 14:08:46.077054 26758 solver.cpp:252]     Train net output #0: loss = 6.92387 (* 1 = 6.92387 loss)
I0124 14:08:46.077071 26758 sgd_solver.cpp:106] Iteration 120, lr = 0.01
I0124 14:08:51.126935 26758 solver.cpp:236] Iteration 140, loss = 6.95576
I0124 14:08:51.127081 26758 solver.cpp:252]     Train net output #0: loss = 6.95576 (* 1 = 6.95576 loss)
I0124 14:08:51.127094 26758 sgd_solver.cpp:106] Iteration 140, lr = 0.01
I0124 14:08:57.004395 26758 solver.cpp:236] Iteration 160, loss = 6.95354
I0124 14:08:57.004454 26758 solver.cpp:252]     Train net output #0: loss = 6.95354 (* 1 = 6.95354 loss)
I0124 14:08:57.004467 26758 sgd_solver.cpp:106] Iteration 160, lr = 0.01
I0124 14:09:01.874550 26758 solver.cpp:236] Iteration 180, loss = 6.93925
I0124 14:09:01.874610 26758 solver.cpp:252]     Train net output #0: loss = 6.93925 (* 1 = 6.93925 loss)
I0124 14:09:01.874620 26758 sgd_solver.cpp:106] Iteration 180, lr = 0.01
I0124 14:09:06.528338 26758 solver.cpp:236] Iteration 200, loss = 6.91104
I0124 14:09:06.528394 26758 solver.cpp:252]     Train net output #0: loss = 6.91104 (* 1 = 6.91104 loss)
I0124 14:09:06.528404 26758 sgd_solver.cpp:106] Iteration 200, lr = 0.01
I0124 14:09:11.197337 26758 solver.cpp:236] Iteration 220, loss = 6.94169
I0124 14:09:11.197397 26758 solver.cpp:252]     Train net output #0: loss = 6.94169 (* 1 = 6.94169 loss)
I0124 14:09:11.197407 26758 sgd_solver.cpp:106] Iteration 220, lr = 0.01
I0124 14:09:15.842536 26758 solver.cpp:236] Iteration 240, loss = 6.93556
I0124 14:09:15.842588 26758 solver.cpp:252]     Train net output #0: loss = 6.93556 (* 1 = 6.93556 loss)
I0124 14:09:15.842595 26758 sgd_solver.cpp:106] Iteration 240, lr = 0.01
I0124 14:09:20.562168 26758 solver.cpp:236] Iteration 260, loss = 6.90839
I0124 14:09:20.562230 26758 solver.cpp:252]     Train net output #0: loss = 6.90839 (* 1 = 6.90839 loss)
I0124 14:09:20.562242 26758 sgd_solver.cpp:106] Iteration 260, lr = 0.01
I0124 14:09:25.155654 26758 solver.cpp:236] Iteration 280, loss = 6.91346
I0124 14:09:25.155845 26758 solver.cpp:252]     Train net output #0: loss = 6.91346 (* 1 = 6.91346 loss)
I0124 14:09:25.155861 26758 sgd_solver.cpp:106] Iteration 280, lr = 0.01
I0124 14:09:29.931717 26758 solver.cpp:236] Iteration 300, loss = 6.92343
I0124 14:09:29.931771 26758 solver.cpp:252]     Train net output #0: loss = 6.92343 (* 1 = 6.92343 loss)
I0124 14:09:29.931787 26758 sgd_solver.cpp:106] Iteration 300, lr = 0.01
I0124 14:09:34.678597 26758 solver.cpp:236] Iteration 320, loss = 6.93571
I0124 14:09:34.678659 26758 solver.cpp:252]     Train net output #0: loss = 6.93571 (* 1 = 6.93571 loss)
I0124 14:09:34.678671 26758 sgd_solver.cpp:106] Iteration 320, lr = 0.01
I0124 14:09:39.388717 26758 solver.cpp:236] Iteration 340, loss = 6.90315
I0124 14:09:39.388778 26758 solver.cpp:252]     Train net output #0: loss = 6.90315 (* 1 = 6.90315 loss)
I0124 14:09:39.388787 26758 sgd_solver.cpp:106] Iteration 340, lr = 0.01
I0124 14:09:44.796820 26758 solver.cpp:236] Iteration 360, loss = 6.9325
I0124 14:09:44.796883 26758 solver.cpp:252]     Train net output #0: loss = 6.9325 (* 1 = 6.9325 loss)
I0124 14:09:44.796900 26758 sgd_solver.cpp:106] Iteration 360, lr = 0.01
I0124 14:09:49.695994 26758 solver.cpp:236] Iteration 380, loss = 6.91224
I0124 14:09:49.696080 26758 solver.cpp:252]     Train net output #0: loss = 6.91224 (* 1 = 6.91224 loss)
I0124 14:09:49.696094 26758 sgd_solver.cpp:106] Iteration 380, lr = 0.01
I0124 14:09:54.256897 26758 solver.cpp:236] Iteration 400, loss = 6.9022
I0124 14:09:54.256958 26758 solver.cpp:252]     Train net output #0: loss = 6.9022 (* 1 = 6.9022 loss)
I0124 14:09:54.256968 26758 sgd_solver.cpp:106] Iteration 400, lr = 0.01
I0124 14:09:58.831943 26758 solver.cpp:236] Iteration 420, loss = 6.92528
I0124 14:09:58.832245 26758 solver.cpp:252]     Train net output #0: loss = 6.92528 (* 1 = 6.92528 loss)
I0124 14:09:58.832260 26758 sgd_solver.cpp:106] Iteration 420, lr = 0.01
I0124 14:10:03.426185 26758 solver.cpp:236] Iteration 440, loss = 6.90692
I0124 14:10:03.426245 26758 solver.cpp:252]     Train net output #0: loss = 6.90692 (* 1 = 6.90692 loss)
I0124 14:10:03.426257 26758 sgd_solver.cpp:106] Iteration 440, lr = 0.01
I0124 14:10:08.002900 26758 solver.cpp:236] Iteration 460, loss = 6.93352
I0124 14:10:08.002955 26758 solver.cpp:252]     Train net output #0: loss = 6.93352 (* 1 = 6.93352 loss)
I0124 14:10:08.002966 26758 sgd_solver.cpp:106] Iteration 460, lr = 0.01
I0124 14:10:12.675858 26758 solver.cpp:236] Iteration 480, loss = 6.92437
I0124 14:10:12.675904 26758 solver.cpp:252]     Train net output #0: loss = 6.92437 (* 1 = 6.92437 loss)
I0124 14:10:12.675915 26758 sgd_solver.cpp:106] Iteration 480, lr = 0.01
I0124 14:10:17.380156 26758 solver.cpp:236] Iteration 500, loss = 6.91799
I0124 14:10:17.380211 26758 solver.cpp:252]     Train net output #0: loss = 6.91799 (* 1 = 6.91799 loss)
I0124 14:10:17.380223 26758 sgd_solver.cpp:106] Iteration 500, lr = 0.01
I0124 14:10:22.059970 26758 solver.cpp:236] Iteration 520, loss = 6.90175
I0124 14:10:22.060025 26758 solver.cpp:252]     Train net output #0: loss = 6.90175 (* 1 = 6.90175 loss)
I0124 14:10:22.060035 26758 sgd_solver.cpp:106] Iteration 520, lr = 0.01
I0124 14:10:26.946665 26758 solver.cpp:236] Iteration 540, loss = 6.90444
I0124 14:10:26.946710 26758 solver.cpp:252]     Train net output #0: loss = 6.90444 (* 1 = 6.90444 loss)
I0124 14:10:26.946717 26758 sgd_solver.cpp:106] Iteration 540, lr = 0.01
I0124 14:10:31.953413 26758 solver.cpp:236] Iteration 560, loss = 6.93592
I0124 14:10:31.953524 26758 solver.cpp:252]     Train net output #0: loss = 6.93592 (* 1 = 6.93592 loss)
I0124 14:10:31.953533 26758 sgd_solver.cpp:106] Iteration 560, lr = 0.01
