I0124 12:24:04.620131 19781 caffe.cpp:184] Using GPUs 1
I0124 12:24:05.224884 19781 solver.cpp:47] Initializing solver from parameters: 
test_iter: 1000
test_interval: 1000
base_lr: 1
display: 20
max_iter: 320000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.0005
snapshot: 10000
snapshot_prefix: "snapshots/caffenet128_lsuv_adadelta1e-7"
solver_mode: GPU
device_id: 1
net_param {
  name: "CaffeNet"
  layer {
    name: "data"
    type: "Data"
    top: "data"
    top: "label"
    include {
      phase: TRAIN
    }
    transform_param {
      scale: 0.04
      mirror: true
      crop_size: 128
      mean_value: 104
      mean_value: 117
      mean_value: 124
      force_color: true
      resize_param {
        prob: 1
        resize_mode: FIT_SMALL_SIZE
        height: 144
        width: 144
        pad_mode: MIRRORED
        pad_value: 104
        pad_value: 117
        pad_value: 124
        interp_mode: LINEAR
        center_object: false
        max_angle: 0
      }
    }
    data_param {
      source: "/local/temporary/imagenet_clc_orig/ilsvrc12_train_shuffle_lmdb"
      batch_size: 128
      backend: LMDB
    }
  }
  layer {
    name: "data"
    type: "Data"
    top: "data"
    top: "label"
    include {
      phase: TEST
    }
    transform_param {
      scale: 0.04
      mirror: false
      crop_size: 128
      mean_value: 104
      mean_value: 117
      mean_value: 123
      force_color: true
      resize_param {
        prob: 1
        resize_mode: FIT_SMALL_SIZE
        height: 144
        width: 144
        pad_mode: MIRRORED
        pad_value: 104
        pad_value: 117
        pad_value: 124
        interp_mode: LINEAR
        center_object: false
        max_angle: 0
      }
    }
    data_param {
      source: "/local/temporary/imagenet_clc_orig/ilsvrc12_val_lmdb"
      batch_size: 50
      backend: LMDB
    }
  }
  layer {
    name: "conv1"
    type: "Convolution"
    bottom: "data"
    top: "conv1"
    param {
      lr_mult: 1
      decay_mult: 1
    }
    param {
      lr_mult: 2
      decay_mult: 0
    }
    convolution_param {
      num_output: 96
      kernel_size: 11
      stride: 4
      weight_filler {
        type: "gaussian"
        std: 0.01
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layer {
    name: "relu1"
    type: "ReLU"
    bottom: "conv1"
    top: "relu1"
  }
  layer {
    name: "pool1"
    type: "Pooling"
    bottom: "relu1"
    top: "pool1"
    pooling_param {
      pool: MAX
      kernel_size: 3
      stride: 2
    }
  }
  layer {
    name: "conv2"
    type: "Convolution"
    bottom: "pool1"
    top: "conv2"
    param {
      lr_mult: 1
      decay_mult: 1
    }
    param {
      lr_mult: 2
      decay_mult: 0
    }
    convolution_param {
      num_output: 256
      pad: 2
      kernel_size: 5
      group: 2
      weight_filler {
        type: "gaussian"
        std: 0.01
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layer {
    name: "relu2"
    type: "ReLU"
    bottom: "conv2"
    top: "relu2"
  }
  layer {
    name: "pool2"
    type: "Pooling"
    bottom: "relu2"
    top: "pool2"
    pooling_param {
      pool: MAX
      kernel_size: 3
      stride: 2
    }
  }
  layer {
    name: "conv3"
    type: "Convolution"
    bottom: "pool2"
    top: "conv3"
    param {
      lr_mult: 1
      decay_mult: 1
    }
    param {
      lr_mult: 2
      decay_mult: 0
    }
    convolution_param {
      num_output: 384
      pad: 1
      kernel_size: 3
      weight_filler {
        type: "gaussian"
        std: 0.01
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layer {
    name: "relu3"
    type: "ReLU"
    bottom: "conv3"
    top: "relu3"
  }
  layer {
    name: "conv4"
    type: "Convolution"
    bottom: "relu3"
    top: "conv4"
    param {
      lr_mult: 1
      decay_mult: 1
    }
    param {
      lr_mult: 2
      decay_mult: 0
    }
    convolution_param {
      num_output: 384
      pad: 1
      kernel_size: 3
      group: 2
      weight_filler {
        type: "gaussian"
        std: 0.01
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layer {
    name: "relu4"
    type: "ReLU"
    bottom: "conv4"
    top: "relu4"
  }
  layer {
    name: "conv5"
    type: "Convolution"
    bottom: "relu4"
    top: "conv5"
    param {
      lr_mult: 1
      decay_mult: 1
    }
    param {
      lr_mult: 2
      decay_mult: 0
    }
    convolution_param {
      num_output: 256
      pad: 1
      kernel_size: 3
      group: 2
      weight_filler {
        type: "gaussian"
        std: 0.01
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layer {
    name: "relu5"
    type: "ReLU"
    bottom: "conv5"
    top: "relu5"
  }
  layer {
    name: "pool5"
    type: "Pooling"
    bottom: "relu5"
    top: "pool5"
    pooling_param {
      pool: MAX
      kernel_size: 3
      stride: 2
    }
  }
  layer {
    name: "fc6"
    type: "InnerProduct"
    bottom: "pool5"
    top: "fc6"
    param {
      lr_mult: 1
      decay_mult: 1
    }
    param {
      lr_mult: 2
      decay_mult: 0
    }
    inner_product_param {
      num_output: 2048
      weight_filler {
        type: "gaussian"
        std: 0.005
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layer {
    name: "relu6"
    type: "ReLU"
    bottom: "fc6"
    top: "relu6"
  }
  layer {
    name: "drop6"
    type: "Dropout"
    bottom: "relu6"
    top: "drop6"
    dropout_param {
      dropout_ratio: 0.5
    }
  }
  layer {
    name: "fc7"
    type: "InnerProduct"
    bottom: "drop6"
    top: "fc7"
    param {
      lr_mult: 1
      decay_mult: 1
    }
    param {
      lr_mult: 2
      decay_mult: 0
    }
    inner_product_param {
      num_output: 2048
      weight_filler {
        type: "gaussian"
        std: 0.005
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layer {
    name: "relu7"
    type: "ReLU"
    bottom: "fc7"
    top: "relu7"
  }
  layer {
    name: "drop7"
    type: "Dropout"
    bottom: "relu7"
    top: "drop7"
    dropout_param {
      dropout_ratio: 0.5
    }
  }
  layer {
    name: "fc8"
    type: "InnerProduct"
    bottom: "drop7"
    top: "fc8"
    param {
      lr_mult: 1
      decay_mult: 1
    }
    param {
      lr_mult: 2
      decay_mult: 0
    }
    inner_product_param {
      num_output: 1000
      weight_filler {
        type: "gaussian"
        std: 0.01
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layer {
    name: "accuracy"
    type: "Accuracy"
    bottom: "fc8"
    bottom: "label"
    top: "accuracy"
    include {
      phase: TEST
    }
  }
  layer {
    name: "loss"
    type: "SoftmaxWithLoss"
    bottom: "fc8"
    bottom: "label"
    top: "loss"
  }
}
delta: 1e-07
test_initialization: false
iter_size: 1
type: "AdaDelta"
I0124 12:24:05.225868 19781 solver.cpp:85] Creating training net specified in net_param.
I0124 12:24:05.225972 19781 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0124 12:24:05.225997 19781 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0124 12:24:05.226272 19781 net.cpp:49] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.04
    mirror: true
    crop_size: 128
    mean_value: 104
    mean_value: 117
    mean_value: 124
    force_color: true
    resize_param {
      prob: 1
      resize_mode: FIT_SMALL_SIZE
      height: 144
      width: 144
      pad_mode: MIRRORED
      pad_value: 104
      pad_value: 117
      pad_value: 124
      interp_mode: LINEAR
      center_object: false
      max_angle: 0
    }
  }
  data_param {
    source: "/local/temporary/imagenet_clc_orig/ilsvrc12_train_shuffle_lmdb"
    batch_size: 128
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "relu1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "relu1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "relu2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "relu2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "relu3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "relu3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "relu4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "relu4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "relu5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "relu5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "relu6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "relu6"
  top: "drop6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "drop6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "relu7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "relu7"
  top: "drop7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "drop7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0124 12:24:05.226409 19781 layer_factory.hpp:76] Creating layer data
I0124 12:24:05.226974 19781 net.cpp:106] Creating Layer data
I0124 12:24:05.226987 19781 net.cpp:411] data -> data
I0124 12:24:05.227017 19781 net.cpp:411] data -> label
I0124 12:24:05.228067 19850 db_lmdb.cpp:38] Opened lmdb /local/temporary/imagenet_clc_orig/ilsvrc12_train_shuffle_lmdb
I0124 12:24:05.248050 19781 data_layer.cpp:41] output data size: 128,3,128,128
I0124 12:24:05.309478 19781 net.cpp:150] Setting up data
I0124 12:24:05.309522 19781 net.cpp:157] Top shape: 128 3 128 128 (6291456)
I0124 12:24:05.309530 19781 net.cpp:157] Top shape: 128 (128)
I0124 12:24:05.309535 19781 net.cpp:165] Memory required for data: 25166336
I0124 12:24:05.309547 19781 layer_factory.hpp:76] Creating layer conv1
I0124 12:24:05.309571 19781 net.cpp:106] Creating Layer conv1
I0124 12:24:05.309579 19781 net.cpp:454] conv1 <- data
I0124 12:24:05.309608 19781 net.cpp:411] conv1 -> conv1
I0124 12:24:05.444057 19781 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 4356
I0124 12:24:05.444233 19781 net.cpp:150] Setting up conv1
I0124 12:24:05.444248 19781 net.cpp:157] Top shape: 128 96 30 30 (11059200)
I0124 12:24:05.444254 19781 net.cpp:165] Memory required for data: 69403136
I0124 12:24:05.444273 19781 layer_factory.hpp:76] Creating layer relu1
I0124 12:24:05.444285 19781 net.cpp:106] Creating Layer relu1
I0124 12:24:05.444290 19781 net.cpp:454] relu1 <- conv1
I0124 12:24:05.444296 19781 net.cpp:411] relu1 -> relu1
I0124 12:24:05.444489 19781 net.cpp:150] Setting up relu1
I0124 12:24:05.444499 19781 net.cpp:157] Top shape: 128 96 30 30 (11059200)
I0124 12:24:05.444501 19781 net.cpp:165] Memory required for data: 113639936
I0124 12:24:05.444505 19781 layer_factory.hpp:76] Creating layer pool1
I0124 12:24:05.444512 19781 net.cpp:106] Creating Layer pool1
I0124 12:24:05.444517 19781 net.cpp:454] pool1 <- relu1
I0124 12:24:05.444521 19781 net.cpp:411] pool1 -> pool1
I0124 12:24:05.444841 19781 net.cpp:150] Setting up pool1
I0124 12:24:05.444852 19781 net.cpp:157] Top shape: 128 96 15 15 (2764800)
I0124 12:24:05.444856 19781 net.cpp:165] Memory required for data: 124699136
I0124 12:24:05.444860 19781 layer_factory.hpp:76] Creating layer conv2
I0124 12:24:05.444871 19781 net.cpp:106] Creating Layer conv2
I0124 12:24:05.444887 19781 net.cpp:454] conv2 <- pool1
I0124 12:24:05.444893 19781 net.cpp:411] conv2 -> conv2
I0124 12:24:05.455262 19781 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 28800
I0124 12:24:05.455294 19781 net.cpp:150] Setting up conv2
I0124 12:24:05.455301 19781 net.cpp:157] Top shape: 128 256 15 15 (7372800)
I0124 12:24:05.455303 19781 net.cpp:165] Memory required for data: 154190336
I0124 12:24:05.455313 19781 layer_factory.hpp:76] Creating layer relu2
I0124 12:24:05.455319 19781 net.cpp:106] Creating Layer relu2
I0124 12:24:05.455322 19781 net.cpp:454] relu2 <- conv2
I0124 12:24:05.455329 19781 net.cpp:411] relu2 -> relu2
I0124 12:24:05.455536 19781 net.cpp:150] Setting up relu2
I0124 12:24:05.455544 19781 net.cpp:157] Top shape: 128 256 15 15 (7372800)
I0124 12:24:05.455548 19781 net.cpp:165] Memory required for data: 183681536
I0124 12:24:05.455550 19781 layer_factory.hpp:76] Creating layer pool2
I0124 12:24:05.455557 19781 net.cpp:106] Creating Layer pool2
I0124 12:24:05.455562 19781 net.cpp:454] pool2 <- relu2
I0124 12:24:05.455569 19781 net.cpp:411] pool2 -> pool2
I0124 12:24:05.455894 19781 net.cpp:150] Setting up pool2
I0124 12:24:05.455905 19781 net.cpp:157] Top shape: 128 256 7 7 (1605632)
I0124 12:24:05.455909 19781 net.cpp:165] Memory required for data: 190104064
I0124 12:24:05.455912 19781 layer_factory.hpp:76] Creating layer conv3
I0124 12:24:05.455922 19781 net.cpp:106] Creating Layer conv3
I0124 12:24:05.455927 19781 net.cpp:454] conv3 <- pool2
I0124 12:24:05.455946 19781 net.cpp:411] conv3 -> conv3
I0124 12:24:05.481855 19781 net.cpp:150] Setting up conv3
I0124 12:24:05.481891 19781 net.cpp:157] Top shape: 128 384 7 7 (2408448)
I0124 12:24:05.481895 19781 net.cpp:165] Memory required for data: 199737856
I0124 12:24:05.481907 19781 layer_factory.hpp:76] Creating layer relu3
I0124 12:24:05.481919 19781 net.cpp:106] Creating Layer relu3
I0124 12:24:05.481922 19781 net.cpp:454] relu3 <- conv3
I0124 12:24:05.481928 19781 net.cpp:411] relu3 -> relu3
I0124 12:24:05.482295 19781 net.cpp:150] Setting up relu3
I0124 12:24:05.482307 19781 net.cpp:157] Top shape: 128 384 7 7 (2408448)
I0124 12:24:05.482311 19781 net.cpp:165] Memory required for data: 209371648
I0124 12:24:05.482313 19781 layer_factory.hpp:76] Creating layer conv4
I0124 12:24:05.482326 19781 net.cpp:106] Creating Layer conv4
I0124 12:24:05.482331 19781 net.cpp:454] conv4 <- relu3
I0124 12:24:05.482338 19781 net.cpp:411] conv4 -> conv4
I0124 12:24:05.503511 19781 net.cpp:150] Setting up conv4
I0124 12:24:05.503546 19781 net.cpp:157] Top shape: 128 384 7 7 (2408448)
I0124 12:24:05.503551 19781 net.cpp:165] Memory required for data: 219005440
I0124 12:24:05.503559 19781 layer_factory.hpp:76] Creating layer relu4
I0124 12:24:05.503569 19781 net.cpp:106] Creating Layer relu4
I0124 12:24:05.503573 19781 net.cpp:454] relu4 <- conv4
I0124 12:24:05.503584 19781 net.cpp:411] relu4 -> relu4
I0124 12:24:05.503779 19781 net.cpp:150] Setting up relu4
I0124 12:24:05.503787 19781 net.cpp:157] Top shape: 128 384 7 7 (2408448)
I0124 12:24:05.503790 19781 net.cpp:165] Memory required for data: 228639232
I0124 12:24:05.503794 19781 layer_factory.hpp:76] Creating layer conv5
I0124 12:24:05.503808 19781 net.cpp:106] Creating Layer conv5
I0124 12:24:05.503811 19781 net.cpp:454] conv5 <- relu4
I0124 12:24:05.503816 19781 net.cpp:411] conv5 -> conv5
I0124 12:24:05.518295 19781 net.cpp:150] Setting up conv5
I0124 12:24:05.518308 19781 net.cpp:157] Top shape: 128 256 7 7 (1605632)
I0124 12:24:05.518312 19781 net.cpp:165] Memory required for data: 235061760
I0124 12:24:05.518322 19781 layer_factory.hpp:76] Creating layer relu5
I0124 12:24:05.518328 19781 net.cpp:106] Creating Layer relu5
I0124 12:24:05.518332 19781 net.cpp:454] relu5 <- conv5
I0124 12:24:05.518338 19781 net.cpp:411] relu5 -> relu5
I0124 12:24:05.518525 19781 net.cpp:150] Setting up relu5
I0124 12:24:05.518534 19781 net.cpp:157] Top shape: 128 256 7 7 (1605632)
I0124 12:24:05.518537 19781 net.cpp:165] Memory required for data: 241484288
I0124 12:24:05.518540 19781 layer_factory.hpp:76] Creating layer pool5
I0124 12:24:05.518549 19781 net.cpp:106] Creating Layer pool5
I0124 12:24:05.518553 19781 net.cpp:454] pool5 <- relu5
I0124 12:24:05.518558 19781 net.cpp:411] pool5 -> pool5
I0124 12:24:05.518900 19781 net.cpp:150] Setting up pool5
I0124 12:24:05.518914 19781 net.cpp:157] Top shape: 128 256 3 3 (294912)
I0124 12:24:05.518919 19781 net.cpp:165] Memory required for data: 242663936
I0124 12:24:05.518924 19781 layer_factory.hpp:76] Creating layer fc6
I0124 12:24:05.518939 19781 net.cpp:106] Creating Layer fc6
I0124 12:24:05.518946 19781 net.cpp:454] fc6 <- pool5
I0124 12:24:05.518952 19781 net.cpp:411] fc6 -> fc6
I0124 12:24:05.651365 19781 net.cpp:150] Setting up fc6
I0124 12:24:05.651407 19781 net.cpp:157] Top shape: 128 2048 (262144)
I0124 12:24:05.651409 19781 net.cpp:165] Memory required for data: 243712512
I0124 12:24:05.651419 19781 layer_factory.hpp:76] Creating layer relu6
I0124 12:24:05.651428 19781 net.cpp:106] Creating Layer relu6
I0124 12:24:05.651432 19781 net.cpp:454] relu6 <- fc6
I0124 12:24:05.651440 19781 net.cpp:411] relu6 -> relu6
I0124 12:24:05.651691 19781 net.cpp:150] Setting up relu6
I0124 12:24:05.651702 19781 net.cpp:157] Top shape: 128 2048 (262144)
I0124 12:24:05.651705 19781 net.cpp:165] Memory required for data: 244761088
I0124 12:24:05.651708 19781 layer_factory.hpp:76] Creating layer drop6
I0124 12:24:05.651717 19781 net.cpp:106] Creating Layer drop6
I0124 12:24:05.651722 19781 net.cpp:454] drop6 <- relu6
I0124 12:24:05.651738 19781 net.cpp:411] drop6 -> drop6
I0124 12:24:05.651784 19781 net.cpp:150] Setting up drop6
I0124 12:24:05.651792 19781 net.cpp:157] Top shape: 128 2048 (262144)
I0124 12:24:05.651794 19781 net.cpp:165] Memory required for data: 245809664
I0124 12:24:05.651798 19781 layer_factory.hpp:76] Creating layer fc7
I0124 12:24:05.651806 19781 net.cpp:106] Creating Layer fc7
I0124 12:24:05.651810 19781 net.cpp:454] fc7 <- drop6
I0124 12:24:05.651815 19781 net.cpp:411] fc7 -> fc7
I0124 12:24:05.769816 19781 net.cpp:150] Setting up fc7
I0124 12:24:05.769896 19781 net.cpp:157] Top shape: 128 2048 (262144)
I0124 12:24:05.769901 19781 net.cpp:165] Memory required for data: 246858240
I0124 12:24:05.769911 19781 layer_factory.hpp:76] Creating layer relu7
I0124 12:24:05.769919 19781 net.cpp:106] Creating Layer relu7
I0124 12:24:05.769924 19781 net.cpp:454] relu7 <- fc7
I0124 12:24:05.769930 19781 net.cpp:411] relu7 -> relu7
I0124 12:24:05.770411 19781 net.cpp:150] Setting up relu7
I0124 12:24:05.770421 19781 net.cpp:157] Top shape: 128 2048 (262144)
I0124 12:24:05.770437 19781 net.cpp:165] Memory required for data: 247906816
I0124 12:24:05.770439 19781 layer_factory.hpp:76] Creating layer drop7
I0124 12:24:05.770448 19781 net.cpp:106] Creating Layer drop7
I0124 12:24:05.770452 19781 net.cpp:454] drop7 <- relu7
I0124 12:24:05.770457 19781 net.cpp:411] drop7 -> drop7
I0124 12:24:05.770498 19781 net.cpp:150] Setting up drop7
I0124 12:24:05.770503 19781 net.cpp:157] Top shape: 128 2048 (262144)
I0124 12:24:05.770506 19781 net.cpp:165] Memory required for data: 248955392
I0124 12:24:05.770509 19781 layer_factory.hpp:76] Creating layer fc8
I0124 12:24:05.770519 19781 net.cpp:106] Creating Layer fc8
I0124 12:24:05.770524 19781 net.cpp:454] fc8 <- drop7
I0124 12:24:05.770527 19781 net.cpp:411] fc8 -> fc8
I0124 12:24:05.828310 19781 net.cpp:150] Setting up fc8
I0124 12:24:05.828344 19781 net.cpp:157] Top shape: 128 1000 (128000)
I0124 12:24:05.828348 19781 net.cpp:165] Memory required for data: 249467392
I0124 12:24:05.828357 19781 layer_factory.hpp:76] Creating layer loss
I0124 12:24:05.828369 19781 net.cpp:106] Creating Layer loss
I0124 12:24:05.828373 19781 net.cpp:454] loss <- fc8
I0124 12:24:05.828379 19781 net.cpp:454] loss <- label
I0124 12:24:05.828385 19781 net.cpp:411] loss -> loss
I0124 12:24:05.828402 19781 layer_factory.hpp:76] Creating layer loss
I0124 12:24:05.829479 19781 net.cpp:150] Setting up loss
I0124 12:24:05.829490 19781 net.cpp:157] Top shape: (1)
I0124 12:24:05.829505 19781 net.cpp:160]     with loss weight 1
I0124 12:24:05.829531 19781 net.cpp:165] Memory required for data: 249467396
I0124 12:24:05.829535 19781 net.cpp:226] loss needs backward computation.
I0124 12:24:05.829540 19781 net.cpp:226] fc8 needs backward computation.
I0124 12:24:05.829542 19781 net.cpp:226] drop7 needs backward computation.
I0124 12:24:05.829545 19781 net.cpp:226] relu7 needs backward computation.
I0124 12:24:05.829548 19781 net.cpp:226] fc7 needs backward computation.
I0124 12:24:05.829551 19781 net.cpp:226] drop6 needs backward computation.
I0124 12:24:05.829555 19781 net.cpp:226] relu6 needs backward computation.
I0124 12:24:05.829557 19781 net.cpp:226] fc6 needs backward computation.
I0124 12:24:05.829560 19781 net.cpp:226] pool5 needs backward computation.
I0124 12:24:05.829563 19781 net.cpp:226] relu5 needs backward computation.
I0124 12:24:05.829566 19781 net.cpp:226] conv5 needs backward computation.
I0124 12:24:05.829569 19781 net.cpp:226] relu4 needs backward computation.
I0124 12:24:05.829573 19781 net.cpp:226] conv4 needs backward computation.
I0124 12:24:05.829576 19781 net.cpp:226] relu3 needs backward computation.
I0124 12:24:05.829579 19781 net.cpp:226] conv3 needs backward computation.
I0124 12:24:05.829581 19781 net.cpp:226] pool2 needs backward computation.
I0124 12:24:05.829584 19781 net.cpp:226] relu2 needs backward computation.
I0124 12:24:05.829587 19781 net.cpp:226] conv2 needs backward computation.
I0124 12:24:05.829591 19781 net.cpp:226] pool1 needs backward computation.
I0124 12:24:05.829593 19781 net.cpp:226] relu1 needs backward computation.
I0124 12:24:05.829596 19781 net.cpp:226] conv1 needs backward computation.
I0124 12:24:05.829601 19781 net.cpp:228] data does not need backward computation.
I0124 12:24:05.829603 19781 net.cpp:270] This network produces output loss
I0124 12:24:05.829623 19781 net.cpp:283] Network initialization done.
I0124 12:24:05.829759 19781 solver.cpp:180] Creating test net (#0) specified by net_param
I0124 12:24:05.829802 19781 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0124 12:24:05.830148 19781 net.cpp:49] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.04
    mirror: false
    crop_size: 128
    mean_value: 104
    mean_value: 117
    mean_value: 123
    force_color: true
    resize_param {
      prob: 1
      resize_mode: FIT_SMALL_SIZE
      height: 144
      width: 144
      pad_mode: MIRRORED
      pad_value: 104
      pad_value: 117
      pad_value: 124
      interp_mode: LINEAR
      center_object: false
      max_angle: 0
    }
  }
  data_param {
    source: "/local/temporary/imagenet_clc_orig/ilsvrc12_val_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "relu1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "relu1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "relu2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "relu2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "relu3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "relu3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "relu4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "relu4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "relu5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "relu5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "relu6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "relu6"
  top: "drop6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "drop6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "relu7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "relu7"
  top: "drop7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "drop7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0124 12:24:05.830302 19781 layer_factory.hpp:76] Creating layer data
I0124 12:24:05.830395 19781 net.cpp:106] Creating Layer data
I0124 12:24:05.830425 19781 net.cpp:411] data -> data
I0124 12:24:05.830435 19781 net.cpp:411] data -> label
I0124 12:24:05.831421 19926 db_lmdb.cpp:38] Opened lmdb /local/temporary/imagenet_clc_orig/ilsvrc12_val_lmdb
I0124 12:24:05.835305 19781 data_layer.cpp:41] output data size: 50,3,128,128
I0124 12:24:05.856380 19781 net.cpp:150] Setting up data
I0124 12:24:05.856451 19781 net.cpp:157] Top shape: 50 3 128 128 (2457600)
I0124 12:24:05.856468 19781 net.cpp:157] Top shape: 50 (50)
I0124 12:24:05.856482 19781 net.cpp:165] Memory required for data: 9830600
I0124 12:24:05.856498 19781 layer_factory.hpp:76] Creating layer label_data_1_split
I0124 12:24:05.856531 19781 net.cpp:106] Creating Layer label_data_1_split
I0124 12:24:05.856544 19781 net.cpp:454] label_data_1_split <- label
I0124 12:24:05.856564 19781 net.cpp:411] label_data_1_split -> label_data_1_split_0
I0124 12:24:05.856590 19781 net.cpp:411] label_data_1_split -> label_data_1_split_1
I0124 12:24:05.856696 19781 net.cpp:150] Setting up label_data_1_split
I0124 12:24:05.856719 19781 net.cpp:157] Top shape: 50 (50)
I0124 12:24:05.856732 19781 net.cpp:157] Top shape: 50 (50)
I0124 12:24:05.856745 19781 net.cpp:165] Memory required for data: 9831000
I0124 12:24:05.856757 19781 layer_factory.hpp:76] Creating layer conv1
I0124 12:24:05.856782 19781 net.cpp:106] Creating Layer conv1
I0124 12:24:05.856796 19781 net.cpp:454] conv1 <- data
I0124 12:24:05.856813 19781 net.cpp:411] conv1 -> conv1
I0124 12:24:05.859447 19781 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 4356
I0124 12:24:05.859486 19781 net.cpp:150] Setting up conv1
I0124 12:24:05.859494 19781 net.cpp:157] Top shape: 50 96 30 30 (4320000)
I0124 12:24:05.859498 19781 net.cpp:165] Memory required for data: 27111000
I0124 12:24:05.859509 19781 layer_factory.hpp:76] Creating layer relu1
I0124 12:24:05.859521 19781 net.cpp:106] Creating Layer relu1
I0124 12:24:05.859527 19781 net.cpp:454] relu1 <- conv1
I0124 12:24:05.859534 19781 net.cpp:411] relu1 -> relu1
I0124 12:24:05.859849 19781 net.cpp:150] Setting up relu1
I0124 12:24:05.859861 19781 net.cpp:157] Top shape: 50 96 30 30 (4320000)
I0124 12:24:05.859864 19781 net.cpp:165] Memory required for data: 44391000
I0124 12:24:05.859869 19781 layer_factory.hpp:76] Creating layer pool1
I0124 12:24:05.859876 19781 net.cpp:106] Creating Layer pool1
I0124 12:24:05.859880 19781 net.cpp:454] pool1 <- relu1
I0124 12:24:05.859885 19781 net.cpp:411] pool1 -> pool1
I0124 12:24:05.860090 19781 net.cpp:150] Setting up pool1
I0124 12:24:05.860097 19781 net.cpp:157] Top shape: 50 96 15 15 (1080000)
I0124 12:24:05.860101 19781 net.cpp:165] Memory required for data: 48711000
I0124 12:24:05.860105 19781 layer_factory.hpp:76] Creating layer conv2
I0124 12:24:05.860113 19781 net.cpp:106] Creating Layer conv2
I0124 12:24:05.860118 19781 net.cpp:454] conv2 <- pool1
I0124 12:24:05.860127 19781 net.cpp:411] conv2 -> conv2
I0124 12:24:05.871104 19781 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 28800
I0124 12:24:05.871167 19781 net.cpp:150] Setting up conv2
I0124 12:24:05.871181 19781 net.cpp:157] Top shape: 50 256 15 15 (2880000)
I0124 12:24:05.871188 19781 net.cpp:165] Memory required for data: 60231000
I0124 12:24:05.871201 19781 layer_factory.hpp:76] Creating layer relu2
I0124 12:24:05.871207 19781 net.cpp:106] Creating Layer relu2
I0124 12:24:05.871211 19781 net.cpp:454] relu2 <- conv2
I0124 12:24:05.871215 19781 net.cpp:411] relu2 -> relu2
I0124 12:24:05.871423 19781 net.cpp:150] Setting up relu2
I0124 12:24:05.871431 19781 net.cpp:157] Top shape: 50 256 15 15 (2880000)
I0124 12:24:05.871434 19781 net.cpp:165] Memory required for data: 71751000
I0124 12:24:05.871438 19781 layer_factory.hpp:76] Creating layer pool2
I0124 12:24:05.871444 19781 net.cpp:106] Creating Layer pool2
I0124 12:24:05.871448 19781 net.cpp:454] pool2 <- relu2
I0124 12:24:05.871455 19781 net.cpp:411] pool2 -> pool2
I0124 12:24:05.871778 19781 net.cpp:150] Setting up pool2
I0124 12:24:05.871789 19781 net.cpp:157] Top shape: 50 256 7 7 (627200)
I0124 12:24:05.871793 19781 net.cpp:165] Memory required for data: 74259800
I0124 12:24:05.871795 19781 layer_factory.hpp:76] Creating layer conv3
I0124 12:24:05.871809 19781 net.cpp:106] Creating Layer conv3
I0124 12:24:05.871812 19781 net.cpp:454] conv3 <- pool2
I0124 12:24:05.871819 19781 net.cpp:411] conv3 -> conv3
I0124 12:24:05.897982 19781 cudnn_conv_layer.cpp:194] Reallocating workspace storage: 27648
I0124 12:24:05.898021 19781 net.cpp:150] Setting up conv3
I0124 12:24:05.898030 19781 net.cpp:157] Top shape: 50 384 7 7 (940800)
I0124 12:24:05.898032 19781 net.cpp:165] Memory required for data: 78023000
I0124 12:24:05.898044 19781 layer_factory.hpp:76] Creating layer relu3
I0124 12:24:05.898056 19781 net.cpp:106] Creating Layer relu3
I0124 12:24:05.898059 19781 net.cpp:454] relu3 <- conv3
I0124 12:24:05.898066 19781 net.cpp:411] relu3 -> relu3
I0124 12:24:05.898290 19781 net.cpp:150] Setting up relu3
I0124 12:24:05.898299 19781 net.cpp:157] Top shape: 50 384 7 7 (940800)
I0124 12:24:05.898303 19781 net.cpp:165] Memory required for data: 81786200
I0124 12:24:05.898306 19781 layer_factory.hpp:76] Creating layer conv4
I0124 12:24:05.898319 19781 net.cpp:106] Creating Layer conv4
I0124 12:24:05.898324 19781 net.cpp:454] conv4 <- relu3
I0124 12:24:05.898329 19781 net.cpp:411] conv4 -> conv4
I0124 12:24:05.919023 19781 net.cpp:150] Setting up conv4
I0124 12:24:05.919054 19781 net.cpp:157] Top shape: 50 384 7 7 (940800)
I0124 12:24:05.919057 19781 net.cpp:165] Memory required for data: 85549400
I0124 12:24:05.919065 19781 layer_factory.hpp:76] Creating layer relu4
I0124 12:24:05.919073 19781 net.cpp:106] Creating Layer relu4
I0124 12:24:05.919077 19781 net.cpp:454] relu4 <- conv4
I0124 12:24:05.919082 19781 net.cpp:411] relu4 -> relu4
I0124 12:24:05.919293 19781 net.cpp:150] Setting up relu4
I0124 12:24:05.919301 19781 net.cpp:157] Top shape: 50 384 7 7 (940800)
I0124 12:24:05.919304 19781 net.cpp:165] Memory required for data: 89312600
I0124 12:24:05.919307 19781 layer_factory.hpp:76] Creating layer conv5
I0124 12:24:05.919318 19781 net.cpp:106] Creating Layer conv5
I0124 12:24:05.919323 19781 net.cpp:454] conv5 <- relu4
I0124 12:24:05.919330 19781 net.cpp:411] conv5 -> conv5
I0124 12:24:05.933887 19781 net.cpp:150] Setting up conv5
I0124 12:24:05.933902 19781 net.cpp:157] Top shape: 50 256 7 7 (627200)
I0124 12:24:05.933907 19781 net.cpp:165] Memory required for data: 91821400
I0124 12:24:05.933918 19781 layer_factory.hpp:76] Creating layer relu5
I0124 12:24:05.933928 19781 net.cpp:106] Creating Layer relu5
I0124 12:24:05.933930 19781 net.cpp:454] relu5 <- conv5
I0124 12:24:05.933936 19781 net.cpp:411] relu5 -> relu5
I0124 12:24:05.934248 19781 net.cpp:150] Setting up relu5
I0124 12:24:05.934259 19781 net.cpp:157] Top shape: 50 256 7 7 (627200)
I0124 12:24:05.934262 19781 net.cpp:165] Memory required for data: 94330200
I0124 12:24:05.934267 19781 layer_factory.hpp:76] Creating layer pool5
I0124 12:24:05.934273 19781 net.cpp:106] Creating Layer pool5
I0124 12:24:05.934276 19781 net.cpp:454] pool5 <- relu5
I0124 12:24:05.934314 19781 net.cpp:411] pool5 -> pool5
I0124 12:24:05.934546 19781 net.cpp:150] Setting up pool5
I0124 12:24:05.934561 19781 net.cpp:157] Top shape: 50 256 3 3 (115200)
I0124 12:24:05.934583 19781 net.cpp:165] Memory required for data: 94791000
I0124 12:24:05.934592 19781 layer_factory.hpp:76] Creating layer fc6
I0124 12:24:05.934602 19781 net.cpp:106] Creating Layer fc6
I0124 12:24:05.934620 19781 net.cpp:454] fc6 <- pool5
I0124 12:24:05.934644 19781 net.cpp:411] fc6 -> fc6
I0124 12:24:06.069007 19781 net.cpp:150] Setting up fc6
I0124 12:24:06.069032 19781 net.cpp:157] Top shape: 50 2048 (102400)
I0124 12:24:06.069036 19781 net.cpp:165] Memory required for data: 95200600
I0124 12:24:06.069047 19781 layer_factory.hpp:76] Creating layer relu6
I0124 12:24:06.069061 19781 net.cpp:106] Creating Layer relu6
I0124 12:24:06.069067 19781 net.cpp:454] relu6 <- fc6
I0124 12:24:06.069079 19781 net.cpp:411] relu6 -> relu6
I0124 12:24:06.069568 19781 net.cpp:150] Setting up relu6
I0124 12:24:06.069581 19781 net.cpp:157] Top shape: 50 2048 (102400)
I0124 12:24:06.069584 19781 net.cpp:165] Memory required for data: 95610200
I0124 12:24:06.069587 19781 layer_factory.hpp:76] Creating layer drop6
I0124 12:24:06.069609 19781 net.cpp:106] Creating Layer drop6
I0124 12:24:06.069625 19781 net.cpp:454] drop6 <- relu6
I0124 12:24:06.069636 19781 net.cpp:411] drop6 -> drop6
I0124 12:24:06.069700 19781 net.cpp:150] Setting up drop6
I0124 12:24:06.069708 19781 net.cpp:157] Top shape: 50 2048 (102400)
I0124 12:24:06.069715 19781 net.cpp:165] Memory required for data: 96019800
I0124 12:24:06.069720 19781 layer_factory.hpp:76] Creating layer fc7
I0124 12:24:06.069736 19781 net.cpp:106] Creating Layer fc7
I0124 12:24:06.069746 19781 net.cpp:454] fc7 <- drop6
I0124 12:24:06.069768 19781 net.cpp:411] fc7 -> fc7
I0124 12:24:06.189749 19781 net.cpp:150] Setting up fc7
I0124 12:24:06.189793 19781 net.cpp:157] Top shape: 50 2048 (102400)
I0124 12:24:06.189797 19781 net.cpp:165] Memory required for data: 96429400
I0124 12:24:06.189806 19781 layer_factory.hpp:76] Creating layer relu7
I0124 12:24:06.189816 19781 net.cpp:106] Creating Layer relu7
I0124 12:24:06.189821 19781 net.cpp:454] relu7 <- fc7
I0124 12:24:06.189827 19781 net.cpp:411] relu7 -> relu7
I0124 12:24:06.190115 19781 net.cpp:150] Setting up relu7
I0124 12:24:06.190125 19781 net.cpp:157] Top shape: 50 2048 (102400)
I0124 12:24:06.190129 19781 net.cpp:165] Memory required for data: 96839000
I0124 12:24:06.190131 19781 layer_factory.hpp:76] Creating layer drop7
I0124 12:24:06.190140 19781 net.cpp:106] Creating Layer drop7
I0124 12:24:06.190142 19781 net.cpp:454] drop7 <- relu7
I0124 12:24:06.190148 19781 net.cpp:411] drop7 -> drop7
I0124 12:24:06.190232 19781 net.cpp:150] Setting up drop7
I0124 12:24:06.190242 19781 net.cpp:157] Top shape: 50 2048 (102400)
I0124 12:24:06.190246 19781 net.cpp:165] Memory required for data: 97248600
I0124 12:24:06.190263 19781 layer_factory.hpp:76] Creating layer fc8
I0124 12:24:06.190279 19781 net.cpp:106] Creating Layer fc8
I0124 12:24:06.190284 19781 net.cpp:454] fc8 <- drop7
I0124 12:24:06.190304 19781 net.cpp:411] fc8 -> fc8
I0124 12:24:06.248193 19781 net.cpp:150] Setting up fc8
I0124 12:24:06.248226 19781 net.cpp:157] Top shape: 50 1000 (50000)
I0124 12:24:06.248230 19781 net.cpp:165] Memory required for data: 97448600
I0124 12:24:06.248245 19781 layer_factory.hpp:76] Creating layer fc8_fc8_0_split
I0124 12:24:06.248253 19781 net.cpp:106] Creating Layer fc8_fc8_0_split
I0124 12:24:06.248257 19781 net.cpp:454] fc8_fc8_0_split <- fc8
I0124 12:24:06.248265 19781 net.cpp:411] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0124 12:24:06.248288 19781 net.cpp:411] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0124 12:24:06.248353 19781 net.cpp:150] Setting up fc8_fc8_0_split
I0124 12:24:06.248364 19781 net.cpp:157] Top shape: 50 1000 (50000)
I0124 12:24:06.248373 19781 net.cpp:157] Top shape: 50 1000 (50000)
I0124 12:24:06.248378 19781 net.cpp:165] Memory required for data: 97848600
I0124 12:24:06.248383 19781 layer_factory.hpp:76] Creating layer accuracy
I0124 12:24:06.248427 19781 net.cpp:106] Creating Layer accuracy
I0124 12:24:06.248432 19781 net.cpp:454] accuracy <- fc8_fc8_0_split_0
I0124 12:24:06.248436 19781 net.cpp:454] accuracy <- label_data_1_split_0
I0124 12:24:06.248443 19781 net.cpp:411] accuracy -> accuracy
I0124 12:24:06.248455 19781 net.cpp:150] Setting up accuracy
I0124 12:24:06.248463 19781 net.cpp:157] Top shape: (1)
I0124 12:24:06.248468 19781 net.cpp:165] Memory required for data: 97848604
I0124 12:24:06.248473 19781 layer_factory.hpp:76] Creating layer loss
I0124 12:24:06.248481 19781 net.cpp:106] Creating Layer loss
I0124 12:24:06.248486 19781 net.cpp:454] loss <- fc8_fc8_0_split_1
I0124 12:24:06.248489 19781 net.cpp:454] loss <- label_data_1_split_1
I0124 12:24:06.248497 19781 net.cpp:411] loss -> loss
I0124 12:24:06.248507 19781 layer_factory.hpp:76] Creating layer loss
I0124 12:24:06.249130 19781 net.cpp:150] Setting up loss
I0124 12:24:06.249142 19781 net.cpp:157] Top shape: (1)
I0124 12:24:06.249146 19781 net.cpp:160]     with loss weight 1
I0124 12:24:06.249157 19781 net.cpp:165] Memory required for data: 97848608
I0124 12:24:06.249161 19781 net.cpp:226] loss needs backward computation.
I0124 12:24:06.249167 19781 net.cpp:228] accuracy does not need backward computation.
I0124 12:24:06.249171 19781 net.cpp:226] fc8_fc8_0_split needs backward computation.
I0124 12:24:06.249174 19781 net.cpp:226] fc8 needs backward computation.
I0124 12:24:06.249177 19781 net.cpp:226] drop7 needs backward computation.
I0124 12:24:06.249192 19781 net.cpp:226] relu7 needs backward computation.
I0124 12:24:06.249197 19781 net.cpp:226] fc7 needs backward computation.
I0124 12:24:06.249199 19781 net.cpp:226] drop6 needs backward computation.
I0124 12:24:06.249202 19781 net.cpp:226] relu6 needs backward computation.
I0124 12:24:06.249205 19781 net.cpp:226] fc6 needs backward computation.
I0124 12:24:06.249208 19781 net.cpp:226] pool5 needs backward computation.
I0124 12:24:06.249212 19781 net.cpp:226] relu5 needs backward computation.
I0124 12:24:06.249214 19781 net.cpp:226] conv5 needs backward computation.
I0124 12:24:06.249217 19781 net.cpp:226] relu4 needs backward computation.
I0124 12:24:06.249220 19781 net.cpp:226] conv4 needs backward computation.
I0124 12:24:06.249224 19781 net.cpp:226] relu3 needs backward computation.
I0124 12:24:06.249228 19781 net.cpp:226] conv3 needs backward computation.
I0124 12:24:06.249230 19781 net.cpp:226] pool2 needs backward computation.
I0124 12:24:06.249233 19781 net.cpp:226] relu2 needs backward computation.
I0124 12:24:06.249236 19781 net.cpp:226] conv2 needs backward computation.
I0124 12:24:06.249239 19781 net.cpp:226] pool1 needs backward computation.
I0124 12:24:06.249243 19781 net.cpp:226] relu1 needs backward computation.
I0124 12:24:06.249245 19781 net.cpp:226] conv1 needs backward computation.
I0124 12:24:06.249249 19781 net.cpp:228] label_data_1_split does not need backward computation.
I0124 12:24:06.249253 19781 net.cpp:228] data does not need backward computation.
I0124 12:24:06.249256 19781 net.cpp:270] This network produces output accuracy
I0124 12:24:06.249259 19781 net.cpp:270] This network produces output loss
I0124 12:24:06.249281 19781 net.cpp:283] Network initialization done.
I0124 12:24:06.249413 19781 solver.cpp:59] Solver scaffolding done.
I0124 12:24:06.250250 19781 caffe.cpp:128] Finetuning from caffenet128_lsuv_adagrad.prototxt.caffemodel
I0124 12:24:06.355550 19781 caffe.cpp:212] Starting Optimization
I0124 12:24:06.355583 19781 solver.cpp:287] Solving CaffeNet
I0124 12:24:06.355587 19781 solver.cpp:288] Learning Rate Policy: fixed
I0124 12:24:06.418298 19781 solver.cpp:236] Iteration 0, loss = 7.32732
I0124 12:24:06.418331 19781 solver.cpp:252]     Train net output #0: loss = 7.32732 (* 1 = 7.32732 loss)
I0124 12:24:06.418337 19781 sgd_solver.cpp:106] Iteration 0, lr = 1
I0124 12:24:06.818565 19781 blocking_queue.cpp:50] Data layer prefetch queue empty
I0124 12:24:11.039185 19781 solver.cpp:236] Iteration 20, loss = 6.90589
I0124 12:24:11.039224 19781 solver.cpp:252]     Train net output #0: loss = 6.90589 (* 1 = 6.90589 loss)
I0124 12:24:11.039278 19781 sgd_solver.cpp:106] Iteration 20, lr = 1
I0124 12:24:15.982131 19781 solver.cpp:236] Iteration 40, loss = 6.92714
I0124 12:24:15.982185 19781 solver.cpp:252]     Train net output #0: loss = 6.92714 (* 1 = 6.92714 loss)
I0124 12:24:15.982200 19781 sgd_solver.cpp:106] Iteration 40, lr = 1
I0124 12:24:21.384799 19781 solver.cpp:236] Iteration 60, loss = 6.91135
I0124 12:24:21.384847 19781 solver.cpp:252]     Train net output #0: loss = 6.91135 (* 1 = 6.91135 loss)
I0124 12:24:21.384857 19781 sgd_solver.cpp:106] Iteration 60, lr = 1
I0124 12:24:26.219058 19781 solver.cpp:236] Iteration 80, loss = 6.90604
I0124 12:24:26.219104 19781 solver.cpp:252]     Train net output #0: loss = 6.90604 (* 1 = 6.90604 loss)
I0124 12:24:26.219113 19781 sgd_solver.cpp:106] Iteration 80, lr = 1
I0124 12:24:30.891053 19781 solver.cpp:236] Iteration 100, loss = 6.91024
I0124 12:24:30.891103 19781 solver.cpp:252]     Train net output #0: loss = 6.91024 (* 1 = 6.91024 loss)
I0124 12:24:30.891113 19781 sgd_solver.cpp:106] Iteration 100, lr = 1
I0124 12:24:35.597040 19781 solver.cpp:236] Iteration 120, loss = 6.91141
I0124 12:24:35.597378 19781 solver.cpp:252]     Train net output #0: loss = 6.91141 (* 1 = 6.91141 loss)
I0124 12:24:35.597394 19781 sgd_solver.cpp:106] Iteration 120, lr = 1
I0124 12:24:40.321003 19781 solver.cpp:236] Iteration 140, loss = 6.92236
I0124 12:24:40.321066 19781 solver.cpp:252]     Train net output #0: loss = 6.92236 (* 1 = 6.92236 loss)
I0124 12:24:40.321080 19781 sgd_solver.cpp:106] Iteration 140, lr = 1
I0124 12:24:44.975981 19781 solver.cpp:236] Iteration 160, loss = 6.91126
I0124 12:24:44.976028 19781 solver.cpp:252]     Train net output #0: loss = 6.91126 (* 1 = 6.91126 loss)
I0124 12:24:44.976037 19781 sgd_solver.cpp:106] Iteration 160, lr = 1
I0124 12:24:49.690385 19781 solver.cpp:236] Iteration 180, loss = 6.91855
I0124 12:24:49.690440 19781 solver.cpp:252]     Train net output #0: loss = 6.91855 (* 1 = 6.91855 loss)
I0124 12:24:49.690451 19781 sgd_solver.cpp:106] Iteration 180, lr = 1
I0124 12:24:54.556421 19781 solver.cpp:236] Iteration 200, loss = 6.91064
I0124 12:24:54.556479 19781 solver.cpp:252]     Train net output #0: loss = 6.91064 (* 1 = 6.91064 loss)
I0124 12:24:54.556489 19781 sgd_solver.cpp:106] Iteration 200, lr = 1
I0124 12:25:00.957391 19781 solver.cpp:236] Iteration 220, loss = 6.91019
I0124 12:25:00.957439 19781 solver.cpp:252]     Train net output #0: loss = 6.91019 (* 1 = 6.91019 loss)
I0124 12:25:00.957450 19781 sgd_solver.cpp:106] Iteration 220, lr = 1
I0124 12:25:09.218659 19781 solver.cpp:236] Iteration 240, loss = 6.91306
I0124 12:25:09.218771 19781 solver.cpp:252]     Train net output #0: loss = 6.91306 (* 1 = 6.91306 loss)
I0124 12:25:09.218782 19781 sgd_solver.cpp:106] Iteration 240, lr = 1
I0124 12:25:16.912094 19781 solver.cpp:236] Iteration 260, loss = 6.90757
I0124 12:25:16.912154 19781 solver.cpp:252]     Train net output #0: loss = 6.90757 (* 1 = 6.90757 loss)
I0124 12:25:16.912165 19781 sgd_solver.cpp:106] Iteration 260, lr = 1
I0124 12:25:21.556831 19781 solver.cpp:236] Iteration 280, loss = 6.91224
I0124 12:25:21.556879 19781 solver.cpp:252]     Train net output #0: loss = 6.91224 (* 1 = 6.91224 loss)
I0124 12:25:21.556890 19781 sgd_solver.cpp:106] Iteration 280, lr = 1
I0124 12:25:26.283581 19781 solver.cpp:236] Iteration 300, loss = 6.90744
I0124 12:25:26.283627 19781 solver.cpp:252]     Train net output #0: loss = 6.90744 (* 1 = 6.90744 loss)
I0124 12:25:26.283635 19781 sgd_solver.cpp:106] Iteration 300, lr = 1
I0124 12:25:31.099128 19781 solver.cpp:236] Iteration 320, loss = 6.91209
I0124 12:25:31.099177 19781 solver.cpp:252]     Train net output #0: loss = 6.91209 (* 1 = 6.91209 loss)
I0124 12:25:31.099189 19781 sgd_solver.cpp:106] Iteration 320, lr = 1
I0124 12:25:35.881062 19781 solver.cpp:236] Iteration 340, loss = 6.90515
I0124 12:25:35.881110 19781 solver.cpp:252]     Train net output #0: loss = 6.90515 (* 1 = 6.90515 loss)
I0124 12:25:35.881120 19781 sgd_solver.cpp:106] Iteration 340, lr = 1
I0124 12:25:40.785070 19781 solver.cpp:236] Iteration 360, loss = 6.91439
I0124 12:25:40.785384 19781 solver.cpp:252]     Train net output #0: loss = 6.91439 (* 1 = 6.91439 loss)
I0124 12:25:40.785398 19781 sgd_solver.cpp:106] Iteration 360, lr = 1
I0124 12:25:46.119664 19781 solver.cpp:236] Iteration 380, loss = 6.88478
I0124 12:25:46.119746 19781 solver.cpp:252]     Train net output #0: loss = 6.88478 (* 1 = 6.88478 loss)
I0124 12:25:46.119757 19781 sgd_solver.cpp:106] Iteration 380, lr = 1
I0124 12:25:51.178758 19781 solver.cpp:236] Iteration 400, loss = 6.89469
I0124 12:25:51.178799 19781 solver.cpp:252]     Train net output #0: loss = 6.89469 (* 1 = 6.89469 loss)
I0124 12:25:51.178805 19781 sgd_solver.cpp:106] Iteration 400, lr = 1
I0124 12:25:55.485167 19781 solver.cpp:236] Iteration 420, loss = 6.87921
I0124 12:25:55.485222 19781 solver.cpp:252]     Train net output #0: loss = 6.87921 (* 1 = 6.87921 loss)
I0124 12:25:55.485234 19781 sgd_solver.cpp:106] Iteration 420, lr = 1
I0124 12:25:59.868156 19781 solver.cpp:236] Iteration 440, loss = 6.92454
I0124 12:25:59.868207 19781 solver.cpp:252]     Train net output #0: loss = 6.92454 (* 1 = 6.92454 loss)
I0124 12:25:59.868216 19781 sgd_solver.cpp:106] Iteration 440, lr = 1
I0124 12:26:04.291556 19781 solver.cpp:236] Iteration 460, loss = 6.85478
I0124 12:26:04.291592 19781 solver.cpp:252]     Train net output #0: loss = 6.85478 (* 1 = 6.85478 loss)
I0124 12:26:04.291600 19781 sgd_solver.cpp:106] Iteration 460, lr = 1
I0124 12:26:08.756688 19781 solver.cpp:236] Iteration 480, loss = 6.86258
I0124 12:26:08.756738 19781 solver.cpp:252]     Train net output #0: loss = 6.86258 (* 1 = 6.86258 loss)
I0124 12:26:08.756752 19781 sgd_solver.cpp:106] Iteration 480, lr = 1
I0124 12:26:13.304998 19781 solver.cpp:236] Iteration 500, loss = 6.84576
I0124 12:26:13.305205 19781 solver.cpp:252]     Train net output #0: loss = 6.84576 (* 1 = 6.84576 loss)
I0124 12:26:13.305217 19781 sgd_solver.cpp:106] Iteration 500, lr = 1
I0124 12:26:18.068516 19781 solver.cpp:236] Iteration 520, loss = 6.85926
I0124 12:26:18.068569 19781 solver.cpp:252]     Train net output #0: loss = 6.85926 (* 1 = 6.85926 loss)
I0124 12:26:18.068579 19781 sgd_solver.cpp:106] Iteration 520, lr = 1
I0124 12:26:22.831308 19781 solver.cpp:236] Iteration 540, loss = 6.86539
I0124 12:26:22.831342 19781 solver.cpp:252]     Train net output #0: loss = 6.86539 (* 1 = 6.86539 loss)
I0124 12:26:22.831348 19781 sgd_solver.cpp:106] Iteration 540, lr = 1
I0124 12:26:27.768533 19781 solver.cpp:236] Iteration 560, loss = 6.88682
I0124 12:26:27.768745 19781 solver.cpp:252]     Train net output #0: loss = 6.88682 (* 1 = 6.88682 loss)
I0124 12:26:27.768774 19781 sgd_solver.cpp:106] Iteration 560, lr = 1
I0124 12:26:33.000113 19781 solver.cpp:236] Iteration 580, loss = 6.82199
I0124 12:26:33.000191 19781 solver.cpp:252]     Train net output #0: loss = 6.82199 (* 1 = 6.82199 loss)
I0124 12:26:33.000202 19781 sgd_solver.cpp:106] Iteration 580, lr = 1
I0124 12:26:37.963615 19781 solver.cpp:236] Iteration 600, loss = 6.75877
I0124 12:26:37.963672 19781 solver.cpp:252]     Train net output #0: loss = 6.75877 (* 1 = 6.75877 loss)
I0124 12:26:37.963686 19781 sgd_solver.cpp:106] Iteration 600, lr = 1
I0124 12:26:42.932359 19781 solver.cpp:236] Iteration 620, loss = 6.79904
I0124 12:26:42.932405 19781 solver.cpp:252]     Train net output #0: loss = 6.79904 (* 1 = 6.79904 loss)
I0124 12:26:42.932415 19781 sgd_solver.cpp:106] Iteration 620, lr = 1
I0124 12:26:47.974882 19781 solver.cpp:236] Iteration 640, loss = 6.82888
I0124 12:26:47.975103 19781 solver.cpp:252]     Train net output #0: loss = 6.82888 (* 1 = 6.82888 loss)
I0124 12:26:47.975124 19781 sgd_solver.cpp:106] Iteration 640, lr = 1
I0124 12:26:53.090970 19781 solver.cpp:236] Iteration 660, loss = 6.82422
I0124 12:26:53.091029 19781 solver.cpp:252]     Train net output #0: loss = 6.82422 (* 1 = 6.82422 loss)
I0124 12:26:53.091040 19781 sgd_solver.cpp:106] Iteration 660, lr = 1
I0124 12:26:58.216287 19781 solver.cpp:236] Iteration 680, loss = 6.80006
I0124 12:26:58.216346 19781 solver.cpp:252]     Train net output #0: loss = 6.80006 (* 1 = 6.80006 loss)
I0124 12:26:58.216356 19781 sgd_solver.cpp:106] Iteration 680, lr = 1
I0124 12:27:03.268291 19781 solver.cpp:236] Iteration 700, loss = 6.85661
I0124 12:27:03.268347 19781 solver.cpp:252]     Train net output #0: loss = 6.85661 (* 1 = 6.85661 loss)
I0124 12:27:03.268355 19781 sgd_solver.cpp:106] Iteration 700, lr = 1
I0124 12:27:08.912451 19781 solver.cpp:236] Iteration 720, loss = 6.79087
I0124 12:27:08.912511 19781 solver.cpp:252]     Train net output #0: loss = 6.79087 (* 1 = 6.79087 loss)
I0124 12:27:08.912521 19781 sgd_solver.cpp:106] Iteration 720, lr = 1
I0124 12:27:14.016294 19781 solver.cpp:236] Iteration 740, loss = 6.78635
I0124 12:27:14.016341 19781 solver.cpp:252]     Train net output #0: loss = 6.78635 (* 1 = 6.78635 loss)
I0124 12:27:14.016355 19781 sgd_solver.cpp:106] Iteration 740, lr = 1
I0124 12:27:19.015337 19781 solver.cpp:236] Iteration 760, loss = 6.76717
I0124 12:27:19.015625 19781 solver.cpp:252]     Train net output #0: loss = 6.76717 (* 1 = 6.76717 loss)
I0124 12:27:19.015663 19781 sgd_solver.cpp:106] Iteration 760, lr = 1
I0124 12:27:23.572868 19781 solver.cpp:236] Iteration 780, loss = 6.85519
I0124 12:27:23.572937 19781 solver.cpp:252]     Train net output #0: loss = 6.85519 (* 1 = 6.85519 loss)
I0124 12:27:23.572947 19781 sgd_solver.cpp:106] Iteration 780, lr = 1
I0124 12:27:28.092383 19781 solver.cpp:236] Iteration 800, loss = 6.75946
I0124 12:27:28.092447 19781 solver.cpp:252]     Train net output #0: loss = 6.75946 (* 1 = 6.75946 loss)
I0124 12:27:28.092458 19781 sgd_solver.cpp:106] Iteration 800, lr = 1
I0124 12:27:32.673666 19781 solver.cpp:236] Iteration 820, loss = 6.81659
I0124 12:27:32.673720 19781 solver.cpp:252]     Train net output #0: loss = 6.81659 (* 1 = 6.81659 loss)
I0124 12:27:32.673730 19781 sgd_solver.cpp:106] Iteration 820, lr = 1
I0124 12:27:37.256307 19781 solver.cpp:236] Iteration 840, loss = 6.8065
I0124 12:27:37.256367 19781 solver.cpp:252]     Train net output #0: loss = 6.8065 (* 1 = 6.8065 loss)
I0124 12:27:37.256377 19781 sgd_solver.cpp:106] Iteration 840, lr = 1
I0124 12:27:42.006744 19781 solver.cpp:236] Iteration 860, loss = 6.7908
I0124 12:27:42.006808 19781 solver.cpp:252]     Train net output #0: loss = 6.7908 (* 1 = 6.7908 loss)
I0124 12:27:42.006819 19781 sgd_solver.cpp:106] Iteration 860, lr = 1
I0124 12:27:46.796248 19781 solver.cpp:236] Iteration 880, loss = 6.80599
I0124 12:27:46.796305 19781 solver.cpp:252]     Train net output #0: loss = 6.80599 (* 1 = 6.80599 loss)
I0124 12:27:46.796316 19781 sgd_solver.cpp:106] Iteration 880, lr = 1
I0124 12:27:51.677662 19781 solver.cpp:236] Iteration 900, loss = 6.74546
I0124 12:27:51.678135 19781 solver.cpp:252]     Train net output #0: loss = 6.74546 (* 1 = 6.74546 loss)
I0124 12:27:51.678151 19781 sgd_solver.cpp:106] Iteration 900, lr = 1
I0124 12:27:57.231910 19781 solver.cpp:236] Iteration 920, loss = 6.73959
I0124 12:27:57.231948 19781 solver.cpp:252]     Train net output #0: loss = 6.73959 (* 1 = 6.73959 loss)
I0124 12:27:57.231957 19781 sgd_solver.cpp:106] Iteration 920, lr = 1
I0124 12:28:02.292099 19781 solver.cpp:236] Iteration 940, loss = 6.81367
I0124 12:28:02.292155 19781 solver.cpp:252]     Train net output #0: loss = 6.81367 (* 1 = 6.81367 loss)
I0124 12:28:02.292171 19781 sgd_solver.cpp:106] Iteration 940, lr = 1
I0124 12:28:06.900655 19781 solver.cpp:236] Iteration 960, loss = 6.77902
I0124 12:28:06.900710 19781 solver.cpp:252]     Train net output #0: loss = 6.77902 (* 1 = 6.77902 loss)
I0124 12:28:06.900720 19781 sgd_solver.cpp:106] Iteration 960, lr = 1
I0124 12:28:11.514083 19781 solver.cpp:236] Iteration 980, loss = 6.83923
I0124 12:28:11.514159 19781 solver.cpp:252]     Train net output #0: loss = 6.83923 (* 1 = 6.83923 loss)
I0124 12:28:11.514173 19781 sgd_solver.cpp:106] Iteration 980, lr = 1
I0124 12:28:15.850039 19781 solver.cpp:340] Iteration 1000, Testing net (#0)
I0124 12:28:16.467739 19781 blocking_queue.cpp:50] Data layer prefetch queue empty
I0124 12:29:56.507969 19781 solver.cpp:408]     Test net output #0: accuracy = 0.00366
I0124 12:29:56.508301 19781 solver.cpp:408]     Test net output #1: loss = 6.74261 (* 1 = 6.74261 loss)
I0124 12:29:56.545976 19781 solver.cpp:236] Iteration 1000, loss = 6.75711
I0124 12:29:56.546025 19781 solver.cpp:252]     Train net output #0: loss = 6.75711 (* 1 = 6.75711 loss)
I0124 12:29:56.546036 19781 sgd_solver.cpp:106] Iteration 1000, lr = 1
I0124 12:29:58.550042 19781 blocking_queue.cpp:50] Data layer prefetch queue empty
I0124 12:30:00.924721 19781 solver.cpp:236] Iteration 1020, loss = 6.78632
I0124 12:30:00.924769 19781 solver.cpp:252]     Train net output #0: loss = 6.78632 (* 1 = 6.78632 loss)
I0124 12:30:00.924777 19781 sgd_solver.cpp:106] Iteration 1020, lr = 1
I0124 12:30:05.563807 19781 solver.cpp:236] Iteration 1040, loss = 6.7691
I0124 12:30:05.563865 19781 solver.cpp:252]     Train net output #0: loss = 6.7691 (* 1 = 6.7691 loss)
I0124 12:30:05.563876 19781 sgd_solver.cpp:106] Iteration 1040, lr = 1
I0124 12:30:10.758694 19781 solver.cpp:236] Iteration 1060, loss = 6.80908
I0124 12:30:10.758738 19781 solver.cpp:252]     Train net output #0: loss = 6.80908 (* 1 = 6.80908 loss)
I0124 12:30:10.758746 19781 sgd_solver.cpp:106] Iteration 1060, lr = 1
I0124 12:30:15.912422 19781 solver.cpp:236] Iteration 1080, loss = 6.73608
I0124 12:30:15.912483 19781 solver.cpp:252]     Train net output #0: loss = 6.73608 (* 1 = 6.73608 loss)
I0124 12:30:15.912493 19781 sgd_solver.cpp:106] Iteration 1080, lr = 1
I0124 12:30:20.525020 19781 solver.cpp:236] Iteration 1100, loss = 6.74905
I0124 12:30:20.525074 19781 solver.cpp:252]     Train net output #0: loss = 6.74905 (* 1 = 6.74905 loss)
I0124 12:30:20.525084 19781 sgd_solver.cpp:106] Iteration 1100, lr = 1
I0124 12:30:25.010628 19781 solver.cpp:236] Iteration 1120, loss = 6.68985
I0124 12:30:25.010673 19781 solver.cpp:252]     Train net output #0: loss = 6.68985 (* 1 = 6.68985 loss)
I0124 12:30:25.010680 19781 sgd_solver.cpp:106] Iteration 1120, lr = 1
I0124 12:30:29.500126 19781 solver.cpp:236] Iteration 1140, loss = 6.68755
I0124 12:30:29.500360 19781 solver.cpp:252]     Train net output #0: loss = 6.68755 (* 1 = 6.68755 loss)
I0124 12:30:29.500393 19781 sgd_solver.cpp:106] Iteration 1140, lr = 1
I0124 12:30:34.031934 19781 solver.cpp:236] Iteration 1160, loss = 6.75057
I0124 12:30:34.032006 19781 solver.cpp:252]     Train net output #0: loss = 6.75057 (* 1 = 6.75057 loss)
I0124 12:30:34.032016 19781 sgd_solver.cpp:106] Iteration 1160, lr = 1
I0124 12:30:38.589396 19781 solver.cpp:236] Iteration 1180, loss = 6.60869
I0124 12:30:38.589462 19781 solver.cpp:252]     Train net output #0: loss = 6.60869 (* 1 = 6.60869 loss)
I0124 12:30:38.589473 19781 sgd_solver.cpp:106] Iteration 1180, lr = 1
I0124 12:30:43.250382 19781 solver.cpp:236] Iteration 1200, loss = 6.80112
I0124 12:30:43.250453 19781 solver.cpp:252]     Train net output #0: loss = 6.80112 (* 1 = 6.80112 loss)
I0124 12:30:43.250464 19781 sgd_solver.cpp:106] Iteration 1200, lr = 1
I0124 12:30:47.847623 19781 solver.cpp:236] Iteration 1220, loss = 6.766
I0124 12:30:47.847690 19781 solver.cpp:252]     Train net output #0: loss = 6.766 (* 1 = 6.766 loss)
I0124 12:30:47.847702 19781 sgd_solver.cpp:106] Iteration 1220, lr = 1
I0124 12:30:52.526396 19781 solver.cpp:236] Iteration 1240, loss = 6.71383
I0124 12:30:52.526456 19781 solver.cpp:252]     Train net output #0: loss = 6.71383 (* 1 = 6.71383 loss)
I0124 12:30:52.526468 19781 sgd_solver.cpp:106] Iteration 1240, lr = 1
I0124 12:30:57.510982 19781 solver.cpp:236] Iteration 1260, loss = 6.76927
I0124 12:30:57.511026 19781 solver.cpp:252]     Train net output #0: loss = 6.76927 (* 1 = 6.76927 loss)
I0124 12:30:57.511040 19781 sgd_solver.cpp:106] Iteration 1260, lr = 1
I0124 12:31:02.779284 19781 solver.cpp:236] Iteration 1280, loss = 6.70293
I0124 12:31:02.779490 19781 solver.cpp:252]     Train net output #0: loss = 6.70293 (* 1 = 6.70293 loss)
I0124 12:31:02.779521 19781 sgd_solver.cpp:106] Iteration 1280, lr = 1
I0124 12:31:07.427165 19781 solver.cpp:236] Iteration 1300, loss = 6.65379
I0124 12:31:07.427217 19781 solver.cpp:252]     Train net output #0: loss = 6.65379 (* 1 = 6.65379 loss)
I0124 12:31:07.427227 19781 sgd_solver.cpp:106] Iteration 1300, lr = 1
I0124 12:31:12.003312 19781 solver.cpp:236] Iteration 1320, loss = 6.67954
I0124 12:31:12.003362 19781 solver.cpp:252]     Train net output #0: loss = 6.67954 (* 1 = 6.67954 loss)
I0124 12:31:12.003373 19781 sgd_solver.cpp:106] Iteration 1320, lr = 1
I0124 12:31:16.603559 19781 solver.cpp:236] Iteration 1340, loss = 6.61281
I0124 12:31:16.603620 19781 solver.cpp:252]     Train net output #0: loss = 6.61281 (* 1 = 6.61281 loss)
I0124 12:31:16.603631 19781 sgd_solver.cpp:106] Iteration 1340, lr = 1
I0124 12:31:21.216881 19781 solver.cpp:236] Iteration 1360, loss = 6.72819
I0124 12:31:21.216943 19781 solver.cpp:252]     Train net output #0: loss = 6.72819 (* 1 = 6.72819 loss)
I0124 12:31:21.216954 19781 sgd_solver.cpp:106] Iteration 1360, lr = 1
I0124 12:31:25.889233 19781 solver.cpp:236] Iteration 1380, loss = 6.69415
I0124 12:31:25.889307 19781 solver.cpp:252]     Train net output #0: loss = 6.69415 (* 1 = 6.69415 loss)
I0124 12:31:25.889322 19781 sgd_solver.cpp:106] Iteration 1380, lr = 1
I0124 12:31:30.551169 19781 solver.cpp:236] Iteration 1400, loss = 6.60828
I0124 12:31:30.551233 19781 solver.cpp:252]     Train net output #0: loss = 6.60828 (* 1 = 6.60828 loss)
I0124 12:31:30.551247 19781 sgd_solver.cpp:106] Iteration 1400, lr = 1
I0124 12:31:35.250634 19781 solver.cpp:236] Iteration 1420, loss = 6.54882
I0124 12:31:35.250964 19781 solver.cpp:252]     Train net output #0: loss = 6.54882 (* 1 = 6.54882 loss)
I0124 12:31:35.250987 19781 sgd_solver.cpp:106] Iteration 1420, lr = 1
I0124 12:31:40.025974 19781 solver.cpp:236] Iteration 1440, loss = 6.52243
I0124 12:31:40.026021 19781 solver.cpp:252]     Train net output #0: loss = 6.52243 (* 1 = 6.52243 loss)
I0124 12:31:40.026028 19781 sgd_solver.cpp:106] Iteration 1440, lr = 1
I0124 12:31:45.267065 19781 solver.cpp:236] Iteration 1460, loss = 6.56225
I0124 12:31:45.267124 19781 solver.cpp:252]     Train net output #0: loss = 6.56225 (* 1 = 6.56225 loss)
I0124 12:31:45.267134 19781 sgd_solver.cpp:106] Iteration 1460, lr = 1
I0124 12:31:50.291280 19781 solver.cpp:236] Iteration 1480, loss = 6.60991
I0124 12:31:50.291321 19781 solver.cpp:252]     Train net output #0: loss = 6.60991 (* 1 = 6.60991 loss)
I0124 12:31:50.291329 19781 sgd_solver.cpp:106] Iteration 1480, lr = 1
I0124 12:31:55.012276 19781 solver.cpp:236] Iteration 1500, loss = 6.63365
I0124 12:31:55.012323 19781 solver.cpp:252]     Train net output #0: loss = 6.63365 (* 1 = 6.63365 loss)
I0124 12:31:55.012331 19781 sgd_solver.cpp:106] Iteration 1500, lr = 1
I0124 12:31:59.721940 19781 solver.cpp:236] Iteration 1520, loss = 6.59081
I0124 12:31:59.722002 19781 solver.cpp:252]     Train net output #0: loss = 6.59081 (* 1 = 6.59081 loss)
I0124 12:31:59.722012 19781 sgd_solver.cpp:106] Iteration 1520, lr = 1
I0124 12:32:04.474205 19781 solver.cpp:236] Iteration 1540, loss = 6.59164
I0124 12:32:04.474251 19781 solver.cpp:252]     Train net output #0: loss = 6.59164 (* 1 = 6.59164 loss)
I0124 12:32:04.474261 19781 sgd_solver.cpp:106] Iteration 1540, lr = 1
I0124 12:32:09.245295 19781 solver.cpp:236] Iteration 1560, loss = 6.61088
I0124 12:32:09.245578 19781 solver.cpp:252]     Train net output #0: loss = 6.61088 (* 1 = 6.61088 loss)
I0124 12:32:09.245601 19781 sgd_solver.cpp:106] Iteration 1560, lr = 1
I0124 12:32:14.083024 19781 solver.cpp:236] Iteration 1580, loss = 6.42056
I0124 12:32:14.083078 19781 solver.cpp:252]     Train net output #0: loss = 6.42056 (* 1 = 6.42056 loss)
I0124 12:32:14.083091 19781 sgd_solver.cpp:106] Iteration 1580, lr = 1
I0124 12:32:18.869861 19781 solver.cpp:236] Iteration 1600, loss = 6.64749
I0124 12:32:18.869922 19781 solver.cpp:252]     Train net output #0: loss = 6.64749 (* 1 = 6.64749 loss)
I0124 12:32:18.869932 19781 sgd_solver.cpp:106] Iteration 1600, lr = 1
I0124 12:32:23.731791 19781 solver.cpp:236] Iteration 1620, loss = 6.5782
I0124 12:32:23.731986 19781 solver.cpp:252]     Train net output #0: loss = 6.5782 (* 1 = 6.5782 loss)
I0124 12:32:23.732007 19781 sgd_solver.cpp:106] Iteration 1620, lr = 1
I0124 12:32:28.747963 19781 solver.cpp:236] Iteration 1640, loss = 6.63286
I0124 12:32:28.748029 19781 solver.cpp:252]     Train net output #0: loss = 6.63286 (* 1 = 6.63286 loss)
I0124 12:32:28.748047 19781 sgd_solver.cpp:106] Iteration 1640, lr = 1
I0124 12:32:33.746568 19781 solver.cpp:236] Iteration 1660, loss = 6.36958
I0124 12:32:33.746625 19781 solver.cpp:252]     Train net output #0: loss = 6.36958 (* 1 = 6.36958 loss)
I0124 12:32:33.746634 19781 sgd_solver.cpp:106] Iteration 1660, lr = 1
I0124 12:32:38.319092 19781 solver.cpp:236] Iteration 1680, loss = 6.50252
I0124 12:32:38.319161 19781 solver.cpp:252]     Train net output #0: loss = 6.50252 (* 1 = 6.50252 loss)
I0124 12:32:38.319174 19781 sgd_solver.cpp:106] Iteration 1680, lr = 1
I0124 12:32:42.869130 19781 solver.cpp:236] Iteration 1700, loss = 6.67859
I0124 12:32:42.869385 19781 solver.cpp:252]     Train net output #0: loss = 6.67859 (* 1 = 6.67859 loss)
I0124 12:32:42.869398 19781 sgd_solver.cpp:106] Iteration 1700, lr = 1
I0124 12:32:47.424710 19781 solver.cpp:236] Iteration 1720, loss = 6.76775
I0124 12:32:47.424784 19781 solver.cpp:252]     Train net output #0: loss = 6.76775 (* 1 = 6.76775 loss)
I0124 12:32:47.424796 19781 sgd_solver.cpp:106] Iteration 1720, lr = 1
I0124 12:32:51.953192 19781 solver.cpp:236] Iteration 1740, loss = 6.58116
I0124 12:32:51.953258 19781 solver.cpp:252]     Train net output #0: loss = 6.58116 (* 1 = 6.58116 loss)
I0124 12:32:51.953269 19781 sgd_solver.cpp:106] Iteration 1740, lr = 1
I0124 12:32:56.503693 19781 solver.cpp:236] Iteration 1760, loss = 6.64714
I0124 12:32:56.503773 19781 solver.cpp:252]     Train net output #0: loss = 6.64714 (* 1 = 6.64714 loss)
I0124 12:32:56.503784 19781 sgd_solver.cpp:106] Iteration 1760, lr = 1
I0124 12:33:01.235043 19781 solver.cpp:236] Iteration 1780, loss = 6.54798
I0124 12:33:01.235102 19781 solver.cpp:252]     Train net output #0: loss = 6.54798 (* 1 = 6.54798 loss)
I0124 12:33:01.235112 19781 sgd_solver.cpp:106] Iteration 1780, lr = 1
I0124 12:33:06.043615 19781 solver.cpp:236] Iteration 1800, loss = 6.5313
I0124 12:33:06.043946 19781 solver.cpp:252]     Train net output #0: loss = 6.5313 (* 1 = 6.5313 loss)
I0124 12:33:06.043995 19781 sgd_solver.cpp:106] Iteration 1800, lr = 1
I0124 12:33:11.235666 19781 solver.cpp:236] Iteration 1820, loss = 6.60081
I0124 12:33:11.235726 19781 solver.cpp:252]     Train net output #0: loss = 6.60081 (* 1 = 6.60081 loss)
I0124 12:33:11.235738 19781 sgd_solver.cpp:106] Iteration 1820, lr = 1
I0124 12:33:16.189643 19781 solver.cpp:236] Iteration 1840, loss = 6.66942
I0124 12:33:16.189813 19781 solver.cpp:252]     Train net output #0: loss = 6.66942 (* 1 = 6.66942 loss)
I0124 12:33:16.189826 19781 sgd_solver.cpp:106] Iteration 1840, lr = 1
I0124 12:33:20.767146 19781 solver.cpp:236] Iteration 1860, loss = 6.55863
I0124 12:33:20.767195 19781 solver.cpp:252]     Train net output #0: loss = 6.55863 (* 1 = 6.55863 loss)
I0124 12:33:20.767204 19781 sgd_solver.cpp:106] Iteration 1860, lr = 1
I0124 12:33:25.362934 19781 solver.cpp:236] Iteration 1880, loss = 6.58735
I0124 12:33:25.363008 19781 solver.cpp:252]     Train net output #0: loss = 6.58735 (* 1 = 6.58735 loss)
I0124 12:33:25.363015 19781 sgd_solver.cpp:106] Iteration 1880, lr = 1
I0124 12:33:29.925529 19781 solver.cpp:236] Iteration 1900, loss = 6.57292
I0124 12:33:29.925602 19781 solver.cpp:252]     Train net output #0: loss = 6.57292 (* 1 = 6.57292 loss)
I0124 12:33:29.925612 19781 sgd_solver.cpp:106] Iteration 1900, lr = 1
I0124 12:33:34.494673 19781 solver.cpp:236] Iteration 1920, loss = 6.47679
I0124 12:33:34.494730 19781 solver.cpp:252]     Train net output #0: loss = 6.47679 (* 1 = 6.47679 loss)
I0124 12:33:34.494740 19781 sgd_solver.cpp:106] Iteration 1920, lr = 1
I0124 12:33:39.199100 19781 solver.cpp:236] Iteration 1940, loss = 6.48446
I0124 12:33:39.199152 19781 solver.cpp:252]     Train net output #0: loss = 6.48446 (* 1 = 6.48446 loss)
I0124 12:33:39.199162 19781 sgd_solver.cpp:106] Iteration 1940, lr = 1
I0124 12:33:43.903703 19781 solver.cpp:236] Iteration 1960, loss = 6.47073
I0124 12:33:43.903765 19781 solver.cpp:252]     Train net output #0: loss = 6.47073 (* 1 = 6.47073 loss)
I0124 12:33:43.903775 19781 sgd_solver.cpp:106] Iteration 1960, lr = 1
I0124 12:33:48.783198 19781 solver.cpp:236] Iteration 1980, loss = 6.44423
I0124 12:33:48.783788 19781 solver.cpp:252]     Train net output #0: loss = 6.44423 (* 1 = 6.44423 loss)
I0124 12:33:48.783809 19781 sgd_solver.cpp:106] Iteration 1980, lr = 1
I0124 12:33:54.290534 19781 solver.cpp:340] Iteration 2000, Testing net (#0)
I0124 12:33:55.474558 19781 blocking_queue.cpp:50] Data layer prefetch queue empty
I0124 12:35:33.802191 19781 solver.cpp:408]     Test net output #0: accuracy = 0.00914001
I0124 12:35:33.802430 19781 solver.cpp:408]     Test net output #1: loss = 6.42962 (* 1 = 6.42962 loss)
I0124 12:35:33.840348 19781 solver.cpp:236] Iteration 2000, loss = 6.64474
I0124 12:35:33.840405 19781 solver.cpp:252]     Train net output #0: loss = 6.64474 (* 1 = 6.64474 loss)
I0124 12:35:33.840423 19781 sgd_solver.cpp:106] Iteration 2000, lr = 1
I0124 12:35:37.446621 19781 blocking_queue.cpp:50] Data layer prefetch queue empty
I0124 12:35:38.417557 19781 solver.cpp:236] Iteration 2020, loss = 6.4105
I0124 12:35:38.417618 19781 solver.cpp:252]     Train net output #0: loss = 6.4105 (* 1 = 6.4105 loss)
I0124 12:35:38.417629 19781 sgd_solver.cpp:106] Iteration 2020, lr = 1
I0124 12:35:43.346668 19781 solver.cpp:236] Iteration 2040, loss = 6.49787
I0124 12:35:43.346726 19781 solver.cpp:252]     Train net output #0: loss = 6.49787 (* 1 = 6.49787 loss)
I0124 12:35:43.346736 19781 sgd_solver.cpp:106] Iteration 2040, lr = 1
I0124 12:35:48.295603 19781 solver.cpp:236] Iteration 2060, loss = 6.42113
I0124 12:35:48.295661 19781 solver.cpp:252]     Train net output #0: loss = 6.42113 (* 1 = 6.42113 loss)
I0124 12:35:48.295673 19781 sgd_solver.cpp:106] Iteration 2060, lr = 1
I0124 12:35:53.210060 19781 solver.cpp:236] Iteration 2080, loss = 6.55001
I0124 12:35:53.210124 19781 solver.cpp:252]     Train net output #0: loss = 6.55001 (* 1 = 6.55001 loss)
I0124 12:35:53.210134 19781 sgd_solver.cpp:106] Iteration 2080, lr = 1
I0124 12:35:58.165383 19781 solver.cpp:236] Iteration 2100, loss = 6.4761
I0124 12:35:58.165447 19781 solver.cpp:252]     Train net output #0: loss = 6.4761 (* 1 = 6.4761 loss)
I0124 12:35:58.165458 19781 sgd_solver.cpp:106] Iteration 2100, lr = 1
I0124 12:36:04.091111 19781 solver.cpp:236] Iteration 2120, loss = 6.45704
I0124 12:36:04.091275 19781 solver.cpp:252]     Train net output #0: loss = 6.45704 (* 1 = 6.45704 loss)
I0124 12:36:04.091289 19781 sgd_solver.cpp:106] Iteration 2120, lr = 1
I0124 12:36:08.614630 19781 solver.cpp:236] Iteration 2140, loss = 6.35829
I0124 12:36:08.614714 19781 solver.cpp:252]     Train net output #0: loss = 6.35829 (* 1 = 6.35829 loss)
I0124 12:36:08.614732 19781 sgd_solver.cpp:106] Iteration 2140, lr = 1
I0124 12:36:13.266855 19781 solver.cpp:236] Iteration 2160, loss = 6.36463
I0124 12:36:13.266901 19781 solver.cpp:252]     Train net output #0: loss = 6.36463 (* 1 = 6.36463 loss)
I0124 12:36:13.266908 19781 sgd_solver.cpp:106] Iteration 2160, lr = 1
I0124 12:36:17.963722 19781 solver.cpp:236] Iteration 2180, loss = 6.51608
I0124 12:36:17.963760 19781 solver.cpp:252]     Train net output #0: loss = 6.51608 (* 1 = 6.51608 loss)
I0124 12:36:17.963767 19781 sgd_solver.cpp:106] Iteration 2180, lr = 1
I0124 12:36:22.692266 19781 solver.cpp:236] Iteration 2200, loss = 6.56752
I0124 12:36:22.692317 19781 solver.cpp:252]     Train net output #0: loss = 6.56752 (* 1 = 6.56752 loss)
I0124 12:36:22.692332 19781 sgd_solver.cpp:106] Iteration 2200, lr = 1
I0124 12:36:27.413420 19781 solver.cpp:236] Iteration 2220, loss = 6.38955
I0124 12:36:27.413467 19781 solver.cpp:252]     Train net output #0: loss = 6.38955 (* 1 = 6.38955 loss)
I0124 12:36:27.413477 19781 sgd_solver.cpp:106] Iteration 2220, lr = 1
I0124 12:36:32.120865 19781 solver.cpp:236] Iteration 2240, loss = 6.48215
I0124 12:36:32.120915 19781 solver.cpp:252]     Train net output #0: loss = 6.48215 (* 1 = 6.48215 loss)
I0124 12:36:32.120926 19781 sgd_solver.cpp:106] Iteration 2240, lr = 1
I0124 12:36:36.911569 19781 solver.cpp:236] Iteration 2260, loss = 6.51397
I0124 12:36:36.911792 19781 solver.cpp:252]     Train net output #0: loss = 6.51397 (* 1 = 6.51397 loss)
I0124 12:36:36.911813 19781 sgd_solver.cpp:106] Iteration 2260, lr = 1
I0124 12:36:41.645450 19781 solver.cpp:236] Iteration 2280, loss = 6.52139
I0124 12:36:41.645489 19781 solver.cpp:252]     Train net output #0: loss = 6.52139 (* 1 = 6.52139 loss)
I0124 12:36:41.645501 19781 sgd_solver.cpp:106] Iteration 2280, lr = 1
I0124 12:36:47.069056 19781 solver.cpp:236] Iteration 2300, loss = 6.25492
I0124 12:36:47.069106 19781 solver.cpp:252]     Train net output #0: loss = 6.25492 (* 1 = 6.25492 loss)
I0124 12:36:47.069113 19781 sgd_solver.cpp:106] Iteration 2300, lr = 1
I0124 12:36:51.838017 19781 solver.cpp:236] Iteration 2320, loss = 6.23632
I0124 12:36:51.838063 19781 solver.cpp:252]     Train net output #0: loss = 6.23632 (* 1 = 6.23632 loss)
I0124 12:36:51.838073 19781 sgd_solver.cpp:106] Iteration 2320, lr = 1
I0124 12:36:56.706410 19781 solver.cpp:236] Iteration 2340, loss = 6.55881
I0124 12:36:56.706462 19781 solver.cpp:252]     Train net output #0: loss = 6.55881 (* 1 = 6.55881 loss)
I0124 12:36:56.706475 19781 sgd_solver.cpp:106] Iteration 2340, lr = 1
I0124 12:37:01.756649 19781 solver.cpp:236] Iteration 2360, loss = 6.45989
I0124 12:37:01.756698 19781 solver.cpp:252]     Train net output #0: loss = 6.45989 (* 1 = 6.45989 loss)
I0124 12:37:01.756707 19781 sgd_solver.cpp:106] Iteration 2360, lr = 1
I0124 12:37:06.892268 19781 solver.cpp:236] Iteration 2380, loss = 6.42661
I0124 12:37:06.892307 19781 solver.cpp:252]     Train net output #0: loss = 6.42661 (* 1 = 6.42661 loss)
I0124 12:37:06.892314 19781 sgd_solver.cpp:106] Iteration 2380, lr = 1
I0124 12:37:11.998359 19781 solver.cpp:236] Iteration 2400, loss = 6.24443
I0124 12:37:11.998602 19781 solver.cpp:252]     Train net output #0: loss = 6.24443 (* 1 = 6.24443 loss)
I0124 12:37:11.998630 19781 sgd_solver.cpp:106] Iteration 2400, lr = 1
I0124 12:37:17.133729 19781 solver.cpp:236] Iteration 2420, loss = 6.39496
I0124 12:37:17.133795 19781 solver.cpp:252]     Train net output #0: loss = 6.39496 (* 1 = 6.39496 loss)
I0124 12:37:17.133806 19781 sgd_solver.cpp:106] Iteration 2420, lr = 1
I0124 12:37:22.271996 19781 solver.cpp:236] Iteration 2440, loss = 6.39529
I0124 12:37:22.272058 19781 solver.cpp:252]     Train net output #0: loss = 6.39529 (* 1 = 6.39529 loss)
I0124 12:37:22.272068 19781 sgd_solver.cpp:106] Iteration 2440, lr = 1
I0124 12:37:27.716002 19781 solver.cpp:236] Iteration 2460, loss = 6.45728
I0124 12:37:27.716070 19781 solver.cpp:252]     Train net output #0: loss = 6.45728 (* 1 = 6.45728 loss)
I0124 12:37:27.716085 19781 sgd_solver.cpp:106] Iteration 2460, lr = 1
I0124 12:37:33.161164 19781 solver.cpp:236] Iteration 2480, loss = 6.16323
I0124 12:37:33.161239 19781 solver.cpp:252]     Train net output #0: loss = 6.16323 (* 1 = 6.16323 loss)
I0124 12:37:33.161252 19781 sgd_solver.cpp:106] Iteration 2480, lr = 1
I0124 12:37:38.181751 19781 solver.cpp:236] Iteration 2500, loss = 6.2787
I0124 12:37:38.181814 19781 solver.cpp:252]     Train net output #0: loss = 6.2787 (* 1 = 6.2787 loss)
I0124 12:37:38.181826 19781 sgd_solver.cpp:106] Iteration 2500, lr = 1
I0124 12:37:43.150800 19781 solver.cpp:236] Iteration 2520, loss = 6.39389
I0124 12:37:43.150955 19781 solver.cpp:252]     Train net output #0: loss = 6.39389 (* 1 = 6.39389 loss)
I0124 12:37:43.150970 19781 sgd_solver.cpp:106] Iteration 2520, lr = 1
I0124 12:37:48.120421 19781 solver.cpp:236] Iteration 2540, loss = 6.38867
I0124 12:37:48.120515 19781 solver.cpp:252]     Train net output #0: loss = 6.38867 (* 1 = 6.38867 loss)
I0124 12:37:48.120527 19781 sgd_solver.cpp:106] Iteration 2540, lr = 1
I0124 12:37:53.063273 19781 solver.cpp:236] Iteration 2560, loss = 6.35511
I0124 12:37:53.063351 19781 solver.cpp:252]     Train net output #0: loss = 6.35511 (* 1 = 6.35511 loss)
I0124 12:37:53.063366 19781 sgd_solver.cpp:106] Iteration 2560, lr = 1
I0124 12:37:58.103181 19781 solver.cpp:236] Iteration 2580, loss = 6.35326
I0124 12:37:58.103238 19781 solver.cpp:252]     Train net output #0: loss = 6.35326 (* 1 = 6.35326 loss)
I0124 12:37:58.103250 19781 sgd_solver.cpp:106] Iteration 2580, lr = 1
I0124 12:38:03.185719 19781 solver.cpp:236] Iteration 2600, loss = 6.35931
I0124 12:38:03.185802 19781 solver.cpp:252]     Train net output #0: loss = 6.35931 (* 1 = 6.35931 loss)
I0124 12:38:03.185814 19781 sgd_solver.cpp:106] Iteration 2600, lr = 1
I0124 12:38:08.243734 19781 solver.cpp:236] Iteration 2620, loss = 6.332
I0124 12:38:08.243795 19781 solver.cpp:252]     Train net output #0: loss = 6.332 (* 1 = 6.332 loss)
I0124 12:38:08.243805 19781 sgd_solver.cpp:106] Iteration 2620, lr = 1
I0124 12:38:14.105764 19781 solver.cpp:236] Iteration 2640, loss = 6.34818
I0124 12:38:14.106029 19781 solver.cpp:252]     Train net output #0: loss = 6.34818 (* 1 = 6.34818 loss)
I0124 12:38:14.106051 19781 sgd_solver.cpp:106] Iteration 2640, lr = 1
I0124 12:38:19.210954 19781 solver.cpp:236] Iteration 2660, loss = 6.31889
I0124 12:38:19.211000 19781 solver.cpp:252]     Train net output #0: loss = 6.31889 (* 1 = 6.31889 loss)
I0124 12:38:19.211010 19781 sgd_solver.cpp:106] Iteration 2660, lr = 1
I0124 12:38:24.283160 19781 solver.cpp:236] Iteration 2680, loss = 6.37733
I0124 12:38:24.283211 19781 solver.cpp:252]     Train net output #0: loss = 6.37733 (* 1 = 6.37733 loss)
I0124 12:38:24.283221 19781 sgd_solver.cpp:106] Iteration 2680, lr = 1
I0124 12:38:29.342181 19781 solver.cpp:236] Iteration 2700, loss = 6.31433
I0124 12:38:29.342236 19781 solver.cpp:252]     Train net output #0: loss = 6.31433 (* 1 = 6.31433 loss)
I0124 12:38:29.342247 19781 sgd_solver.cpp:106] Iteration 2700, lr = 1
I0124 12:38:34.371024 19781 solver.cpp:236] Iteration 2720, loss = 6.44976
I0124 12:38:34.371068 19781 solver.cpp:252]     Train net output #0: loss = 6.44976 (* 1 = 6.44976 loss)
I0124 12:38:34.371079 19781 sgd_solver.cpp:106] Iteration 2720, lr = 1
I0124 12:38:39.430707 19781 solver.cpp:236] Iteration 2740, loss = 6.38259
I0124 12:38:39.430759 19781 solver.cpp:252]     Train net output #0: loss = 6.38259 (* 1 = 6.38259 loss)
I0124 12:38:39.430769 19781 sgd_solver.cpp:106] Iteration 2740, lr = 1
I0124 12:38:44.445477 19781 solver.cpp:236] Iteration 2760, loss = 6.41646
I0124 12:38:44.445631 19781 solver.cpp:252]     Train net output #0: loss = 6.41646 (* 1 = 6.41646 loss)
I0124 12:38:44.445643 19781 sgd_solver.cpp:106] Iteration 2760, lr = 1
I0124 12:38:49.505286 19781 solver.cpp:236] Iteration 2780, loss = 6.22921
I0124 12:38:49.505342 19781 solver.cpp:252]     Train net output #0: loss = 6.22921 (* 1 = 6.22921 loss)
I0124 12:38:49.505352 19781 sgd_solver.cpp:106] Iteration 2780, lr = 1
I0124 12:38:55.410436 19781 solver.cpp:236] Iteration 2800, loss = 6.29393
I0124 12:38:55.410487 19781 solver.cpp:252]     Train net output #0: loss = 6.29393 (* 1 = 6.29393 loss)
I0124 12:38:55.410501 19781 sgd_solver.cpp:106] Iteration 2800, lr = 1
I0124 12:39:03.776367 19781 solver.cpp:236] Iteration 2820, loss = 6.29186
I0124 12:39:03.776420 19781 solver.cpp:252]     Train net output #0: loss = 6.29186 (* 1 = 6.29186 loss)
I0124 12:39:03.776432 19781 sgd_solver.cpp:106] Iteration 2820, lr = 1
I0124 12:39:11.266121 19781 solver.cpp:236] Iteration 2840, loss = 6.2141
I0124 12:39:11.266171 19781 solver.cpp:252]     Train net output #0: loss = 6.2141 (* 1 = 6.2141 loss)
I0124 12:39:11.266186 19781 sgd_solver.cpp:106] Iteration 2840, lr = 1
I0124 12:39:18.633579 19781 solver.cpp:236] Iteration 2860, loss = 6.07909
I0124 12:39:18.633796 19781 solver.cpp:252]     Train net output #0: loss = 6.07909 (* 1 = 6.07909 loss)
I0124 12:39:18.633812 19781 sgd_solver.cpp:106] Iteration 2860, lr = 1
I0124 12:39:26.070457 19781 solver.cpp:236] Iteration 2880, loss = 6.19554
I0124 12:39:26.070529 19781 solver.cpp:252]     Train net output #0: loss = 6.19554 (* 1 = 6.19554 loss)
I0124 12:39:26.070539 19781 sgd_solver.cpp:106] Iteration 2880, lr = 1
I0124 12:39:33.753830 19781 solver.cpp:236] Iteration 2900, loss = 6.2182
I0124 12:39:33.753900 19781 solver.cpp:252]     Train net output #0: loss = 6.2182 (* 1 = 6.2182 loss)
I0124 12:39:33.753911 19781 sgd_solver.cpp:106] Iteration 2900, lr = 1
I0124 12:39:39.449398 19781 solver.cpp:236] Iteration 2920, loss = 6.39005
I0124 12:39:39.449440 19781 solver.cpp:252]     Train net output #0: loss = 6.39005 (* 1 = 6.39005 loss)
I0124 12:39:39.449448 19781 sgd_solver.cpp:106] Iteration 2920, lr = 1
I0124 12:39:46.891116 19781 solver.cpp:236] Iteration 2940, loss = 6.22132
I0124 12:39:46.891168 19781 solver.cpp:252]     Train net output #0: loss = 6.22132 (* 1 = 6.22132 loss)
I0124 12:39:46.891183 19781 sgd_solver.cpp:106] Iteration 2940, lr = 1
I0124 12:39:54.445696 19781 solver.cpp:236] Iteration 2960, loss = 6.28629
I0124 12:39:54.445910 19781 solver.cpp:252]     Train net output #0: loss = 6.28629 (* 1 = 6.28629 loss)
I0124 12:39:54.445922 19781 sgd_solver.cpp:106] Iteration 2960, lr = 1
I0124 12:40:02.178694 19781 solver.cpp:236] Iteration 2980, loss = 6.37703
I0124 12:40:02.178740 19781 solver.cpp:252]     Train net output #0: loss = 6.37703 (* 1 = 6.37703 loss)
I0124 12:40:02.178750 19781 sgd_solver.cpp:106] Iteration 2980, lr = 1
I0124 12:40:09.450502 19781 solver.cpp:340] Iteration 3000, Testing net (#0)
I0124 12:40:11.306802 19781 blocking_queue.cpp:50] Data layer prefetch queue empty
I0124 12:41:46.365062 19781 solver.cpp:408]     Test net output #0: accuracy = 0.0206601
I0124 12:41:46.365275 19781 solver.cpp:408]     Test net output #1: loss = 6.07701 (* 1 = 6.07701 loss)
I0124 12:41:46.403090 19781 solver.cpp:236] Iteration 3000, loss = 6.09025
I0124 12:41:46.403133 19781 solver.cpp:252]     Train net output #0: loss = 6.09025 (* 1 = 6.09025 loss)
I0124 12:41:46.403143 19781 sgd_solver.cpp:106] Iteration 3000, lr = 1
I0124 12:41:51.003346 19781 solver.cpp:236] Iteration 3020, loss = 6.35054
I0124 12:41:51.003381 19781 solver.cpp:252]     Train net output #0: loss = 6.35054 (* 1 = 6.35054 loss)
I0124 12:41:51.003387 19781 sgd_solver.cpp:106] Iteration 3020, lr = 1
I0124 12:41:51.726711 19781 blocking_queue.cpp:50] Data layer prefetch queue empty
I0124 12:41:55.918495 19781 solver.cpp:236] Iteration 3040, loss = 6.30779
I0124 12:41:55.918543 19781 solver.cpp:252]     Train net output #0: loss = 6.30779 (* 1 = 6.30779 loss)
I0124 12:41:55.918555 19781 sgd_solver.cpp:106] Iteration 3040, lr = 1
I0124 12:42:01.111353 19781 solver.cpp:236] Iteration 3060, loss = 6.32335
I0124 12:42:01.111407 19781 solver.cpp:252]     Train net output #0: loss = 6.32335 (* 1 = 6.32335 loss)
I0124 12:42:01.111414 19781 sgd_solver.cpp:106] Iteration 3060, lr = 1
I0124 12:42:06.277693 19781 solver.cpp:236] Iteration 3080, loss = 6.43137
I0124 12:42:06.277736 19781 solver.cpp:252]     Train net output #0: loss = 6.43137 (* 1 = 6.43137 loss)
I0124 12:42:06.277745 19781 sgd_solver.cpp:106] Iteration 3080, lr = 1
I0124 12:42:11.261322 19781 solver.cpp:236] Iteration 3100, loss = 6.20491
I0124 12:42:11.261375 19781 solver.cpp:252]     Train net output #0: loss = 6.20491 (* 1 = 6.20491 loss)
I0124 12:42:11.261384 19781 sgd_solver.cpp:106] Iteration 3100, lr = 1
I0124 12:42:16.322059 19781 solver.cpp:236] Iteration 3120, loss = 6.31622
I0124 12:42:16.322110 19781 solver.cpp:252]     Train net output #0: loss = 6.31622 (* 1 = 6.31622 loss)
I0124 12:42:16.322118 19781 sgd_solver.cpp:106] Iteration 3120, lr = 1
I0124 12:42:21.428408 19781 solver.cpp:236] Iteration 3140, loss = 6.38402
I0124 12:42:21.428649 19781 solver.cpp:252]     Train net output #0: loss = 6.38402 (* 1 = 6.38402 loss)
I0124 12:42:21.428673 19781 sgd_solver.cpp:106] Iteration 3140, lr = 1
I0124 12:42:26.490932 19781 solver.cpp:236] Iteration 3160, loss = 6.24497
I0124 12:42:26.490993 19781 solver.cpp:252]     Train net output #0: loss = 6.24497 (* 1 = 6.24497 loss)
I0124 12:42:26.491003 19781 sgd_solver.cpp:106] Iteration 3160, lr = 1
I0124 12:42:31.624641 19781 solver.cpp:236] Iteration 3180, loss = 6.45545
I0124 12:42:31.624701 19781 solver.cpp:252]     Train net output #0: loss = 6.45545 (* 1 = 6.45545 loss)
I0124 12:42:31.624707 19781 sgd_solver.cpp:106] Iteration 3180, lr = 1
I0124 12:42:36.766085 19781 solver.cpp:236] Iteration 3200, loss = 6.37056
I0124 12:42:36.766152 19781 solver.cpp:252]     Train net output #0: loss = 6.37056 (* 1 = 6.37056 loss)
I0124 12:42:36.766165 19781 sgd_solver.cpp:106] Iteration 3200, lr = 1
I0124 12:42:41.862210 19781 solver.cpp:236] Iteration 3220, loss = 6.1488
I0124 12:42:41.862268 19781 solver.cpp:252]     Train net output #0: loss = 6.1488 (* 1 = 6.1488 loss)
I0124 12:42:41.862280 19781 sgd_solver.cpp:106] Iteration 3220, lr = 1
I0124 12:42:47.673254 19781 solver.cpp:236] Iteration 3240, loss = 6.02317
I0124 12:42:47.673317 19781 solver.cpp:252]     Train net output #0: loss = 6.02317 (* 1 = 6.02317 loss)
I0124 12:42:47.673331 19781 sgd_solver.cpp:106] Iteration 3240, lr = 1
I0124 12:42:52.720906 19781 solver.cpp:236] Iteration 3260, loss = 6.30142
I0124 12:42:52.721243 19781 solver.cpp:252]     Train net output #0: loss = 6.30142 (* 1 = 6.30142 loss)
I0124 12:42:52.721261 19781 sgd_solver.cpp:106] Iteration 3260, lr = 1
I0124 12:42:57.712558 19781 solver.cpp:236] Iteration 3280, loss = 6.19239
I0124 12:42:57.712610 19781 solver.cpp:252]     Train net output #0: loss = 6.19239 (* 1 = 6.19239 loss)
I0124 12:42:57.712620 19781 sgd_solver.cpp:106] Iteration 3280, lr = 1
I0124 12:43:02.717111 19781 solver.cpp:236] Iteration 3300, loss = 6.05711
I0124 12:43:02.717166 19781 solver.cpp:252]     Train net output #0: loss = 6.05711 (* 1 = 6.05711 loss)
I0124 12:43:02.717176 19781 sgd_solver.cpp:106] Iteration 3300, lr = 1
I0124 12:43:07.754247 19781 solver.cpp:236] Iteration 3320, loss = 6.18243
I0124 12:43:07.754302 19781 solver.cpp:252]     Train net output #0: loss = 6.18243 (* 1 = 6.18243 loss)
I0124 12:43:07.754312 19781 sgd_solver.cpp:106] Iteration 3320, lr = 1
I0124 12:43:12.845762 19781 solver.cpp:236] Iteration 3340, loss = 6.03774
I0124 12:43:12.845814 19781 solver.cpp:252]     Train net output #0: loss = 6.03774 (* 1 = 6.03774 loss)
I0124 12:43:12.845824 19781 sgd_solver.cpp:106] Iteration 3340, lr = 1
I0124 12:43:18.043318 19781 solver.cpp:236] Iteration 3360, loss = 6.24359
I0124 12:43:18.043375 19781 solver.cpp:252]     Train net output #0: loss = 6.24359 (* 1 = 6.24359 loss)
I0124 12:43:18.043386 19781 sgd_solver.cpp:106] Iteration 3360, lr = 1
I0124 12:43:23.221184 19781 solver.cpp:236] Iteration 3380, loss = 6.34743
I0124 12:43:23.221452 19781 solver.cpp:252]     Train net output #0: loss = 6.34743 (* 1 = 6.34743 loss)
I0124 12:43:23.221472 19781 sgd_solver.cpp:106] Iteration 3380, lr = 1
I0124 12:43:28.558080 19781 solver.cpp:236] Iteration 3400, loss = 6.28212
I0124 12:43:28.558146 19781 solver.cpp:252]     Train net output #0: loss = 6.28212 (* 1 = 6.28212 loss)
I0124 12:43:28.558157 19781 sgd_solver.cpp:106] Iteration 3400, lr = 1
I0124 12:43:35.187834 19781 solver.cpp:236] Iteration 3420, loss = 6.01729
I0124 12:43:35.187892 19781 solver.cpp:252]     Train net output #0: loss = 6.01729 (* 1 = 6.01729 loss)
I0124 12:43:35.187904 19781 sgd_solver.cpp:106] Iteration 3420, lr = 1
I0124 12:43:42.508754 19781 solver.cpp:236] Iteration 3440, loss = 6.0281
I0124 12:43:42.508812 19781 solver.cpp:252]     Train net output #0: loss = 6.0281 (* 1 = 6.0281 loss)
I0124 12:43:42.508821 19781 sgd_solver.cpp:106] Iteration 3440, lr = 1
I0124 12:43:49.865314 19781 solver.cpp:236] Iteration 3460, loss = 5.9485
I0124 12:43:49.865391 19781 solver.cpp:252]     Train net output #0: loss = 5.9485 (* 1 = 5.9485 loss)
I0124 12:43:49.865406 19781 sgd_solver.cpp:106] Iteration 3460, lr = 1
I0124 12:43:57.327966 19781 solver.cpp:236] Iteration 3480, loss = 6.2822
I0124 12:43:57.328119 19781 solver.cpp:252]     Train net output #0: loss = 6.2822 (* 1 = 6.2822 loss)
I0124 12:43:57.328135 19781 sgd_solver.cpp:106] Iteration 3480, lr = 1
I0124 12:44:04.735129 19781 solver.cpp:236] Iteration 3500, loss = 6.26675
I0124 12:44:04.735190 19781 solver.cpp:252]     Train net output #0: loss = 6.26675 (* 1 = 6.26675 loss)
I0124 12:44:04.735204 19781 sgd_solver.cpp:106] Iteration 3500, lr = 1
I0124 12:44:11.997885 19781 solver.cpp:236] Iteration 3520, loss = 6.22066
I0124 12:44:11.997951 19781 solver.cpp:252]     Train net output #0: loss = 6.22066 (* 1 = 6.22066 loss)
I0124 12:44:11.997964 19781 sgd_solver.cpp:106] Iteration 3520, lr = 1
I0124 12:44:18.823213 19781 solver.cpp:236] Iteration 3540, loss = 6.15842
I0124 12:44:18.823264 19781 solver.cpp:252]     Train net output #0: loss = 6.15842 (* 1 = 6.15842 loss)
I0124 12:44:18.823276 19781 sgd_solver.cpp:106] Iteration 3540, lr = 1
I0124 12:44:23.958142 19781 solver.cpp:236] Iteration 3560, loss = 6.20363
I0124 12:44:23.958196 19781 solver.cpp:252]     Train net output #0: loss = 6.20363 (* 1 = 6.20363 loss)
I0124 12:44:23.958206 19781 sgd_solver.cpp:106] Iteration 3560, lr = 1
I0124 12:44:28.736960 19781 solver.cpp:236] Iteration 3580, loss = 6.20624
I0124 12:44:28.737192 19781 solver.cpp:252]     Train net output #0: loss = 6.20624 (* 1 = 6.20624 loss)
I0124 12:44:28.737205 19781 sgd_solver.cpp:106] Iteration 3580, lr = 1
I0124 12:44:33.453637 19781 solver.cpp:236] Iteration 3600, loss = 6.12308
I0124 12:44:33.453694 19781 solver.cpp:252]     Train net output #0: loss = 6.12308 (* 1 = 6.12308 loss)
I0124 12:44:33.453704 19781 sgd_solver.cpp:106] Iteration 3600, lr = 1
I0124 12:44:38.144341 19781 solver.cpp:236] Iteration 3620, loss = 6.16308
I0124 12:44:38.144384 19781 solver.cpp:252]     Train net output #0: loss = 6.16308 (* 1 = 6.16308 loss)
I0124 12:44:38.144392 19781 sgd_solver.cpp:106] Iteration 3620, lr = 1
I0124 12:44:42.842811 19781 solver.cpp:236] Iteration 3640, loss = 6.12651
I0124 12:44:42.842862 19781 solver.cpp:252]     Train net output #0: loss = 6.12651 (* 1 = 6.12651 loss)
I0124 12:44:42.842872 19781 sgd_solver.cpp:106] Iteration 3640, lr = 1
I0124 12:44:47.631439 19781 solver.cpp:236] Iteration 3660, loss = 6.13019
I0124 12:44:47.631487 19781 solver.cpp:252]     Train net output #0: loss = 6.13019 (* 1 = 6.13019 loss)
I0124 12:44:47.631497 19781 sgd_solver.cpp:106] Iteration 3660, lr = 1
I0124 12:44:52.522804 19781 solver.cpp:236] Iteration 3680, loss = 6.17984
I0124 12:44:52.522845 19781 solver.cpp:252]     Train net output #0: loss = 6.17984 (* 1 = 6.17984 loss)
I0124 12:44:52.522853 19781 sgd_solver.cpp:106] Iteration 3680, lr = 1
I0124 12:44:57.251637 19781 solver.cpp:236] Iteration 3700, loss = 5.9244
I0124 12:44:57.251688 19781 solver.cpp:252]     Train net output #0: loss = 5.9244 (* 1 = 5.9244 loss)
I0124 12:44:57.251698 19781 sgd_solver.cpp:106] Iteration 3700, lr = 1
I0124 12:45:02.178869 19781 solver.cpp:236] Iteration 3720, loss = 6.13564
I0124 12:45:02.179137 19781 solver.cpp:252]     Train net output #0: loss = 6.13564 (* 1 = 6.13564 loss)
I0124 12:45:02.179159 19781 sgd_solver.cpp:106] Iteration 3720, lr = 1
I0124 12:45:07.543332 19781 solver.cpp:236] Iteration 3740, loss = 6.41194
I0124 12:45:07.543403 19781 solver.cpp:252]     Train net output #0: loss = 6.41194 (* 1 = 6.41194 loss)
I0124 12:45:07.543417 19781 sgd_solver.cpp:106] Iteration 3740, lr = 1
I0124 12:45:12.795900 19781 solver.cpp:236] Iteration 3760, loss = 6.11891
I0124 12:45:12.795960 19781 solver.cpp:252]     Train net output #0: loss = 6.11891 (* 1 = 6.11891 loss)
I0124 12:45:12.795970 19781 sgd_solver.cpp:106] Iteration 3760, lr = 1
I0124 12:45:17.874135 19781 solver.cpp:236] Iteration 3780, loss = 6.33897
I0124 12:45:17.874191 19781 solver.cpp:252]     Train net output #0: loss = 6.33897 (* 1 = 6.33897 loss)
I0124 12:45:17.874200 19781 sgd_solver.cpp:106] Iteration 3780, lr = 1
I0124 12:45:22.890220 19781 solver.cpp:236] Iteration 3800, loss = 5.98159
I0124 12:45:22.890271 19781 solver.cpp:252]     Train net output #0: loss = 5.98159 (* 1 = 5.98159 loss)
I0124 12:45:22.890281 19781 sgd_solver.cpp:106] Iteration 3800, lr = 1
I0124 12:45:27.941653 19781 solver.cpp:236] Iteration 3820, loss = 6.14156
I0124 12:45:27.941709 19781 solver.cpp:252]     Train net output #0: loss = 6.14156 (* 1 = 6.14156 loss)
I0124 12:45:27.941718 19781 sgd_solver.cpp:106] Iteration 3820, lr = 1
I0124 12:45:32.962772 19781 solver.cpp:236] Iteration 3840, loss = 6.24175
I0124 12:45:32.962999 19781 solver.cpp:252]     Train net output #0: loss = 6.24175 (* 1 = 6.24175 loss)
I0124 12:45:32.963011 19781 sgd_solver.cpp:106] Iteration 3840, lr = 1
I0124 12:45:37.967578 19781 solver.cpp:236] Iteration 3860, loss = 6.14033
I0124 12:45:37.967622 19781 solver.cpp:252]     Train net output #0: loss = 6.14033 (* 1 = 6.14033 loss)
I0124 12:45:37.967633 19781 sgd_solver.cpp:106] Iteration 3860, lr = 1
I0124 12:45:42.769891 19781 solver.cpp:236] Iteration 3880, loss = 5.9963
I0124 12:45:42.769933 19781 solver.cpp:252]     Train net output #0: loss = 5.9963 (* 1 = 5.9963 loss)
I0124 12:45:42.769942 19781 sgd_solver.cpp:106] Iteration 3880, lr = 1
I0124 12:45:47.900667 19781 solver.cpp:236] Iteration 3900, loss = 6.25507
I0124 12:45:47.900725 19781 solver.cpp:252]     Train net output #0: loss = 6.25507 (* 1 = 6.25507 loss)
I0124 12:45:47.900741 19781 sgd_solver.cpp:106] Iteration 3900, lr = 1
I0124 12:45:53.162695 19781 solver.cpp:236] Iteration 3920, loss = 6.05817
I0124 12:45:53.162739 19781 solver.cpp:252]     Train net output #0: loss = 6.05817 (* 1 = 6.05817 loss)
I0124 12:45:53.162746 19781 sgd_solver.cpp:106] Iteration 3920, lr = 1
I0124 12:45:57.849848 19781 solver.cpp:236] Iteration 3940, loss = 6.31456
I0124 12:45:57.849906 19781 solver.cpp:252]     Train net output #0: loss = 6.31456 (* 1 = 6.31456 loss)
I0124 12:45:57.849918 19781 sgd_solver.cpp:106] Iteration 3940, lr = 1
I0124 12:46:02.805140 19781 solver.cpp:236] Iteration 3960, loss = 6.20271
I0124 12:46:02.805186 19781 solver.cpp:252]     Train net output #0: loss = 6.20271 (* 1 = 6.20271 loss)
I0124 12:46:02.805194 19781 sgd_solver.cpp:106] Iteration 3960, lr = 1
I0124 12:46:07.753759 19781 solver.cpp:236] Iteration 3980, loss = 6.22304
I0124 12:46:07.753962 19781 solver.cpp:252]     Train net output #0: loss = 6.22304 (* 1 = 6.22304 loss)
I0124 12:46:07.753988 19781 sgd_solver.cpp:106] Iteration 3980, lr = 1
I0124 12:46:12.481353 19781 solver.cpp:340] Iteration 4000, Testing net (#0)
I0124 12:46:14.998410 19781 blocking_queue.cpp:50] Data layer prefetch queue empty
I0124 12:47:57.348460 19781 solver.cpp:408]     Test net output #0: accuracy = 0.0274202
I0124 12:47:57.348695 19781 solver.cpp:408]     Test net output #1: loss = 5.95512 (* 1 = 5.95512 loss)
I0124 12:47:57.386466 19781 solver.cpp:236] Iteration 4000, loss = 6.18116
I0124 12:47:57.386503 19781 solver.cpp:252]     Train net output #0: loss = 6.18116 (* 1 = 6.18116 loss)
I0124 12:47:57.386534 19781 sgd_solver.cpp:106] Iteration 4000, lr = 1
I0124 12:48:01.805739 19781 solver.cpp:236] Iteration 4020, loss = 6.04035
I0124 12:48:01.805786 19781 solver.cpp:252]     Train net output #0: loss = 6.04035 (* 1 = 6.04035 loss)
I0124 12:48:01.805796 19781 sgd_solver.cpp:106] Iteration 4020, lr = 1
I0124 12:48:04.207844 19781 blocking_queue.cpp:50] Data layer prefetch queue empty
I0124 12:48:06.601197 19781 solver.cpp:236] Iteration 4040, loss = 6.26516
I0124 12:48:06.601259 19781 solver.cpp:252]     Train net output #0: loss = 6.26516 (* 1 = 6.26516 loss)
I0124 12:48:06.601269 19781 sgd_solver.cpp:106] Iteration 4040, lr = 1
I0124 12:48:11.478821 19781 solver.cpp:236] Iteration 4060, loss = 6.24422
I0124 12:48:11.478883 19781 solver.cpp:252]     Train net output #0: loss = 6.24422 (* 1 = 6.24422 loss)
I0124 12:48:11.478894 19781 sgd_solver.cpp:106] Iteration 4060, lr = 1
I0124 12:48:16.303992 19781 solver.cpp:236] Iteration 4080, loss = 6.03158
I0124 12:48:16.304046 19781 solver.cpp:252]     Train net output #0: loss = 6.03158 (* 1 = 6.03158 loss)
I0124 12:48:16.304056 19781 sgd_solver.cpp:106] Iteration 4080, lr = 1
I0124 12:48:21.529832 19781 solver.cpp:236] Iteration 4100, loss = 6.15819
I0124 12:48:21.529881 19781 solver.cpp:252]     Train net output #0: loss = 6.15819 (* 1 = 6.15819 loss)
I0124 12:48:21.529892 19781 sgd_solver.cpp:106] Iteration 4100, lr = 1
I0124 12:48:26.706707 19781 solver.cpp:236] Iteration 4120, loss = 6.18743
I0124 12:48:26.706760 19781 solver.cpp:252]     Train net output #0: loss = 6.18743 (* 1 = 6.18743 loss)
I0124 12:48:26.706776 19781 sgd_solver.cpp:106] Iteration 4120, lr = 1
I0124 12:48:31.370928 19781 solver.cpp:236] Iteration 4140, loss = 6.04821
I0124 12:48:31.371098 19781 solver.cpp:252]     Train net output #0: loss = 6.04821 (* 1 = 6.04821 loss)
I0124 12:48:31.371105 19781 sgd_solver.cpp:106] Iteration 4140, lr = 1
I0124 12:48:36.030832 19781 solver.cpp:236] Iteration 4160, loss = 6.04542
I0124 12:48:36.030881 19781 solver.cpp:252]     Train net output #0: loss = 6.04542 (* 1 = 6.04542 loss)
I0124 12:48:36.030891 19781 sgd_solver.cpp:106] Iteration 4160, lr = 1
I0124 12:48:40.706929 19781 solver.cpp:236] Iteration 4180, loss = 6.45198
I0124 12:48:40.706985 19781 solver.cpp:252]     Train net output #0: loss = 6.45198 (* 1 = 6.45198 loss)
I0124 12:48:40.706995 19781 sgd_solver.cpp:106] Iteration 4180, lr = 1
I0124 12:48:45.394608 19781 solver.cpp:236] Iteration 4200, loss = 6.31967
I0124 12:48:45.394659 19781 solver.cpp:252]     Train net output #0: loss = 6.31967 (* 1 = 6.31967 loss)
I0124 12:48:45.394667 19781 sgd_solver.cpp:106] Iteration 4200, lr = 1
I0124 12:48:50.207031 19781 solver.cpp:236] Iteration 4220, loss = 5.78316
I0124 12:48:50.207087 19781 solver.cpp:252]     Train net output #0: loss = 5.78316 (* 1 = 5.78316 loss)
I0124 12:48:50.207096 19781 sgd_solver.cpp:106] Iteration 4220, lr = 1
I0124 12:48:55.103533 19781 solver.cpp:236] Iteration 4240, loss = 6.20053
I0124 12:48:55.103590 19781 solver.cpp:252]     Train net output #0: loss = 6.20053 (* 1 = 6.20053 loss)
I0124 12:48:55.103601 19781 sgd_solver.cpp:106] Iteration 4240, lr = 1
I0124 12:49:00.037451 19781 solver.cpp:236] Iteration 4260, loss = 6.16755
I0124 12:49:00.037506 19781 solver.cpp:252]     Train net output #0: loss = 6.16755 (* 1 = 6.16755 loss)
I0124 12:49:00.037518 19781 sgd_solver.cpp:106] Iteration 4260, lr = 1
I0124 12:49:04.963865 19781 solver.cpp:236] Iteration 4280, loss = 5.95684
I0124 12:49:04.964036 19781 solver.cpp:252]     Train net output #0: loss = 5.95684 (* 1 = 5.95684 loss)
I0124 12:49:04.964051 19781 sgd_solver.cpp:106] Iteration 4280, lr = 1
I0124 12:49:09.714354 19781 solver.cpp:236] Iteration 4300, loss = 6.03687
I0124 12:49:09.714418 19781 solver.cpp:252]     Train net output #0: loss = 6.03687 (* 1 = 6.03687 loss)
I0124 12:49:09.714431 19781 sgd_solver.cpp:106] Iteration 4300, lr = 1
I0124 12:49:15.080382 19781 solver.cpp:236] Iteration 4320, loss = 5.9161
I0124 12:49:15.080452 19781 solver.cpp:252]     Train net output #0: loss = 5.9161 (* 1 = 5.9161 loss)
I0124 12:49:15.080464 19781 sgd_solver.cpp:106] Iteration 4320, lr = 1
I0124 12:49:20.098186 19781 solver.cpp:236] Iteration 4340, loss = 6.06249
I0124 12:49:20.098240 19781 solver.cpp:252]     Train net output #0: loss = 6.06249 (* 1 = 6.06249 loss)
I0124 12:49:20.098248 19781 sgd_solver.cpp:106] Iteration 4340, lr = 1
I0124 12:49:24.736595 19781 solver.cpp:236] Iteration 4360, loss = 6.0587
I0124 12:49:24.736665 19781 solver.cpp:252]     Train net output #0: loss = 6.0587 (* 1 = 6.0587 loss)
I0124 12:49:24.736675 19781 sgd_solver.cpp:106] Iteration 4360, lr = 1
I0124 12:49:29.761330 19781 solver.cpp:236] Iteration 4380, loss = 6.08993
I0124 12:49:29.761399 19781 solver.cpp:252]     Train net output #0: loss = 6.08993 (* 1 = 6.08993 loss)
I0124 12:49:29.761415 19781 sgd_solver.cpp:106] Iteration 4380, lr = 1
I0124 12:49:34.440258 19781 solver.cpp:236] Iteration 4400, loss = 6.10785
I0124 12:49:34.440335 19781 solver.cpp:252]     Train net output #0: loss = 6.10785 (* 1 = 6.10785 loss)
I0124 12:49:34.440346 19781 sgd_solver.cpp:106] Iteration 4400, lr = 1
I0124 12:49:39.096772 19781 solver.cpp:236] Iteration 4420, loss = 6.01003
I0124 12:49:39.096920 19781 solver.cpp:252]     Train net output #0: loss = 6.01003 (* 1 = 6.01003 loss)
I0124 12:49:39.096932 19781 sgd_solver.cpp:106] Iteration 4420, lr = 1
I0124 12:49:43.854508 19781 solver.cpp:236] Iteration 4440, loss = 6.11892
I0124 12:49:43.854549 19781 solver.cpp:252]     Train net output #0: loss = 6.11892 (* 1 = 6.11892 loss)
I0124 12:49:43.854559 19781 sgd_solver.cpp:106] Iteration 4440, lr = 1
I0124 12:49:48.692975 19781 solver.cpp:236] Iteration 4460, loss = 6.20206
I0124 12:49:48.693027 19781 solver.cpp:252]     Train net output #0: loss = 6.20206 (* 1 = 6.20206 loss)
I0124 12:49:48.693037 19781 sgd_solver.cpp:106] Iteration 4460, lr = 1
I0124 12:49:53.687660 19781 solver.cpp:236] Iteration 4480, loss = 6.2443
I0124 12:49:53.687700 19781 solver.cpp:252]     Train net output #0: loss = 6.2443 (* 1 = 6.2443 loss)
I0124 12:49:53.687717 19781 sgd_solver.cpp:106] Iteration 4480, lr = 1
I0124 12:49:58.556128 19781 solver.cpp:236] Iteration 4500, loss = 6.10279
I0124 12:49:58.556190 19781 solver.cpp:252]     Train net output #0: loss = 6.10279 (* 1 = 6.10279 loss)
I0124 12:49:58.556200 19781 sgd_solver.cpp:106] Iteration 4500, lr = 1
I0124 12:50:03.344091 19781 solver.cpp:236] Iteration 4520, loss = 6.04737
I0124 12:50:03.344144 19781 solver.cpp:252]     Train net output #0: loss = 6.04737 (* 1 = 6.04737 loss)
I0124 12:50:03.344172 19781 sgd_solver.cpp:106] Iteration 4520, lr = 1
I0124 12:50:08.127249 19781 solver.cpp:236] Iteration 4540, loss = 5.9553
I0124 12:50:08.127326 19781 solver.cpp:252]     Train net output #0: loss = 5.9553 (* 1 = 5.9553 loss)
I0124 12:50:08.127336 19781 sgd_solver.cpp:106] Iteration 4540, lr = 1
I0124 12:50:13.574026 19781 solver.cpp:236] Iteration 4560, loss = 6.09893
I0124 12:50:13.574226 19781 solver.cpp:252]     Train net output #0: loss = 6.09893 (* 1 = 6.09893 loss)
I0124 12:50:13.574242 19781 sgd_solver.cpp:106] Iteration 4560, lr = 1
I0124 12:50:18.379607 19781 solver.cpp:236] Iteration 4580, loss = 5.87526
I0124 12:50:18.379648 19781 solver.cpp:252]     Train net output #0: loss = 5.87526 (* 1 = 5.87526 loss)
I0124 12:50:18.379655 19781 sgd_solver.cpp:106] Iteration 4580, lr = 1
I0124 12:50:23.266804 19781 solver.cpp:236] Iteration 4600, loss = 5.91963
I0124 12:50:23.266855 19781 solver.cpp:252]     Train net output #0: loss = 5.91963 (* 1 = 5.91963 loss)
I0124 12:50:23.266865 19781 sgd_solver.cpp:106] Iteration 4600, lr = 1
I0124 12:50:28.050597 19781 solver.cpp:236] Iteration 4620, loss = 5.98106
I0124 12:50:28.050652 19781 solver.cpp:252]     Train net output #0: loss = 5.98106 (* 1 = 5.98106 loss)
I0124 12:50:28.050662 19781 sgd_solver.cpp:106] Iteration 4620, lr = 1
I0124 12:50:32.783501 19781 solver.cpp:236] Iteration 4640, loss = 6.08043
I0124 12:50:32.783556 19781 solver.cpp:252]     Train net output #0: loss = 6.08043 (* 1 = 6.08043 loss)
I0124 12:50:32.783566 19781 sgd_solver.cpp:106] Iteration 4640, lr = 1
I0124 12:50:37.601637 19781 solver.cpp:236] Iteration 4660, loss = 6.16638
I0124 12:50:37.601677 19781 solver.cpp:252]     Train net output #0: loss = 6.16638 (* 1 = 6.16638 loss)
I0124 12:50:37.601683 19781 sgd_solver.cpp:106] Iteration 4660, lr = 1
I0124 12:50:42.597046 19781 solver.cpp:236] Iteration 4680, loss = 5.84205
I0124 12:50:42.597095 19781 solver.cpp:252]     Train net output #0: loss = 5.84205 (* 1 = 5.84205 loss)
I0124 12:50:42.597105 19781 sgd_solver.cpp:106] Iteration 4680, lr = 1
I0124 12:50:47.884943 19781 solver.cpp:236] Iteration 4700, loss = 5.99085
I0124 12:50:47.885098 19781 solver.cpp:252]     Train net output #0: loss = 5.99085 (* 1 = 5.99085 loss)
I0124 12:50:47.885110 19781 sgd_solver.cpp:106] Iteration 4700, lr = 1
I0124 12:50:52.784494 19781 solver.cpp:236] Iteration 4720, loss = 5.98038
I0124 12:50:52.784564 19781 solver.cpp:252]     Train net output #0: loss = 5.98038 (* 1 = 5.98038 loss)
I0124 12:50:52.784575 19781 sgd_solver.cpp:106] Iteration 4720, lr = 1
I0124 12:50:57.480561 19781 solver.cpp:236] Iteration 4740, loss = 6.17672
I0124 12:50:57.480612 19781 solver.cpp:252]     Train net output #0: loss = 6.17672 (* 1 = 6.17672 loss)
I0124 12:50:57.480626 19781 sgd_solver.cpp:106] Iteration 4740, lr = 1
I0124 12:51:02.747742 19781 solver.cpp:236] Iteration 4760, loss = 6.01751
I0124 12:51:02.747788 19781 solver.cpp:252]     Train net output #0: loss = 6.01751 (* 1 = 6.01751 loss)
I0124 12:51:02.747798 19781 sgd_solver.cpp:106] Iteration 4760, lr = 1
I0124 12:51:07.660689 19781 solver.cpp:236] Iteration 4780, loss = 6.2461
I0124 12:51:07.660735 19781 solver.cpp:252]     Train net output #0: loss = 6.2461 (* 1 = 6.2461 loss)
I0124 12:51:07.660745 19781 sgd_solver.cpp:106] Iteration 4780, lr = 1
I0124 12:51:12.228232 19781 solver.cpp:236] Iteration 4800, loss = 5.87154
I0124 12:51:12.228281 19781 solver.cpp:252]     Train net output #0: loss = 5.87154 (* 1 = 5.87154 loss)
I0124 12:51:12.228292 19781 sgd_solver.cpp:106] Iteration 4800, lr = 1
I0124 12:51:16.854439 19781 solver.cpp:236] Iteration 4820, loss = 6.10761
I0124 12:51:16.854476 19781 solver.cpp:252]     Train net output #0: loss = 6.10761 (* 1 = 6.10761 loss)
I0124 12:51:16.854482 19781 sgd_solver.cpp:106] Iteration 4820, lr = 1
I0124 12:51:21.534961 19781 solver.cpp:236] Iteration 4840, loss = 5.91382
I0124 12:51:21.535254 19781 solver.cpp:252]     Train net output #0: loss = 5.91382 (* 1 = 5.91382 loss)
I0124 12:51:21.535279 19781 sgd_solver.cpp:106] Iteration 4840, lr = 1
I0124 12:51:26.117518 19781 solver.cpp:236] Iteration 4860, loss = 5.92516
I0124 12:51:26.117570 19781 solver.cpp:252]     Train net output #0: loss = 5.92516 (* 1 = 5.92516 loss)
I0124 12:51:26.117580 19781 sgd_solver.cpp:106] Iteration 4860, lr = 1
I0124 12:51:30.888322 19781 solver.cpp:236] Iteration 4880, loss = 6.22992
I0124 12:51:30.888375 19781 solver.cpp:252]     Train net output #0: loss = 6.22992 (* 1 = 6.22992 loss)
I0124 12:51:30.888384 19781 sgd_solver.cpp:106] Iteration 4880, lr = 1
I0124 12:51:35.716799 19781 solver.cpp:236] Iteration 4900, loss = 6.14201
I0124 12:51:35.716836 19781 solver.cpp:252]     Train net output #0: loss = 6.14201 (* 1 = 6.14201 loss)
I0124 12:51:35.716845 19781 sgd_solver.cpp:106] Iteration 4900, lr = 1
I0124 12:51:40.648339 19781 solver.cpp:236] Iteration 4920, loss = 6.18259
I0124 12:51:40.648404 19781 solver.cpp:252]     Train net output #0: loss = 6.18259 (* 1 = 6.18259 loss)
I0124 12:51:40.648416 19781 sgd_solver.cpp:106] Iteration 4920, lr = 1
I0124 12:51:45.180589 19781 solver.cpp:236] Iteration 4940, loss = 5.8972
I0124 12:51:45.180631 19781 solver.cpp:252]     Train net output #0: loss = 5.8972 (* 1 = 5.8972 loss)
I0124 12:51:45.180639 19781 sgd_solver.cpp:106] Iteration 4940, lr = 1
I0124 12:51:49.894604 19781 solver.cpp:236] Iteration 4960, loss = 6.1409
I0124 12:51:49.894655 19781 solver.cpp:252]     Train net output #0: loss = 6.1409 (* 1 = 6.1409 loss)
I0124 12:51:49.894666 19781 sgd_solver.cpp:106] Iteration 4960, lr = 1
I0124 12:51:54.630134 19781 solver.cpp:236] Iteration 4980, loss = 5.92662
I0124 12:51:54.630342 19781 solver.cpp:252]     Train net output #0: loss = 5.92662 (* 1 = 5.92662 loss)
I0124 12:51:54.630367 19781 sgd_solver.cpp:106] Iteration 4980, lr = 1
I0124 12:51:59.385960 19781 solver.cpp:340] Iteration 5000, Testing net (#0)
I0124 12:52:02.774859 19781 blocking_queue.cpp:50] Data layer prefetch queue empty
I0124 12:53:39.785857 19781 solver.cpp:408]     Test net output #0: accuracy = 0.0365002
I0124 12:53:39.786021 19781 solver.cpp:408]     Test net output #1: loss = 5.83066 (* 1 = 5.83066 loss)
I0124 12:53:39.823776 19781 solver.cpp:236] Iteration 5000, loss = 5.96174
I0124 12:53:39.823830 19781 solver.cpp:252]     Train net output #0: loss = 5.96174 (* 1 = 5.96174 loss)
I0124 12:53:39.823840 19781 sgd_solver.cpp:106] Iteration 5000, lr = 1
I0124 12:53:44.595461 19781 solver.cpp:236] Iteration 5020, loss = 6.04331
I0124 12:53:44.595522 19781 solver.cpp:252]     Train net output #0: loss = 6.04331 (* 1 = 6.04331 loss)
I0124 12:53:44.595535 19781 sgd_solver.cpp:106] Iteration 5020, lr = 1
I0124 12:53:48.673460 19781 blocking_queue.cpp:50] Data layer prefetch queue empty
I0124 12:53:49.702798 19781 solver.cpp:236] Iteration 5040, loss = 6.09182
I0124 12:53:49.702860 19781 solver.cpp:252]     Train net output #0: loss = 6.09182 (* 1 = 6.09182 loss)
I0124 12:53:49.702870 19781 sgd_solver.cpp:106] Iteration 5040, lr = 1
I0124 12:53:54.845993 19781 solver.cpp:236] Iteration 5060, loss = 6.13573
I0124 12:53:54.846053 19781 solver.cpp:252]     Train net output #0: loss = 6.13573 (* 1 = 6.13573 loss)
I0124 12:53:54.846062 19781 sgd_solver.cpp:106] Iteration 5060, lr = 1
I0124 12:54:00.904376 19781 solver.cpp:236] Iteration 5080, loss = 6.13694
I0124 12:54:00.904438 19781 solver.cpp:252]     Train net output #0: loss = 6.13694 (* 1 = 6.13694 loss)
I0124 12:54:00.904448 19781 sgd_solver.cpp:106] Iteration 5080, lr = 1
I0124 12:54:05.851943 19781 solver.cpp:236] Iteration 5100, loss = 6.07048
I0124 12:54:05.852010 19781 solver.cpp:252]     Train net output #0: loss = 6.07048 (* 1 = 6.07048 loss)
I0124 12:54:05.852021 19781 sgd_solver.cpp:106] Iteration 5100, lr = 1
I0124 12:54:10.837689 19781 solver.cpp:236] Iteration 5120, loss = 5.92602
I0124 12:54:10.838011 19781 solver.cpp:252]     Train net output #0: loss = 5.92602 (* 1 = 5.92602 loss)
I0124 12:54:10.838030 19781 sgd_solver.cpp:106] Iteration 5120, lr = 1
I0124 12:54:15.773244 19781 solver.cpp:236] Iteration 5140, loss = 6.08524
I0124 12:54:15.773294 19781 solver.cpp:252]     Train net output #0: loss = 6.08524 (* 1 = 6.08524 loss)
I0124 12:54:15.773304 19781 sgd_solver.cpp:106] Iteration 5140, lr = 1
I0124 12:54:20.707022 19781 solver.cpp:236] Iteration 5160, loss = 6.09342
I0124 12:54:20.707077 19781 solver.cpp:252]     Train net output #0: loss = 6.09342 (* 1 = 6.09342 loss)
I0124 12:54:20.707087 19781 sgd_solver.cpp:106] Iteration 5160, lr = 1
I0124 12:54:25.642482 19781 solver.cpp:236] Iteration 5180, loss = 6.02797
I0124 12:54:25.642535 19781 solver.cpp:252]     Train net output #0: loss = 6.02797 (* 1 = 6.02797 loss)
I0124 12:54:25.642542 19781 sgd_solver.cpp:106] Iteration 5180, lr = 1
I0124 12:54:30.600046 19781 solver.cpp:236] Iteration 5200, loss = 5.55151
I0124 12:54:30.600085 19781 solver.cpp:252]     Train net output #0: loss = 5.55151 (* 1 = 5.55151 loss)
I0124 12:54:30.600093 19781 sgd_solver.cpp:106] Iteration 5200, lr = 1
I0124 12:54:35.546315 19781 solver.cpp:236] Iteration 5220, loss = 6.17997
I0124 12:54:35.546363 19781 solver.cpp:252]     Train net output #0: loss = 6.17997 (* 1 = 6.17997 loss)
I0124 12:54:35.546372 19781 sgd_solver.cpp:106] Iteration 5220, lr = 1
I0124 12:54:40.455394 19781 solver.cpp:236] Iteration 5240, loss = 6.20865
I0124 12:54:40.455453 19781 solver.cpp:252]     Train net output #0: loss = 6.20865 (* 1 = 6.20865 loss)
I0124 12:54:40.455464 19781 sgd_solver.cpp:106] Iteration 5240, lr = 1
I0124 12:54:46.051290 19781 solver.cpp:236] Iteration 5260, loss = 6.1615
I0124 12:54:46.051523 19781 solver.cpp:252]     Train net output #0: loss = 6.1615 (* 1 = 6.1615 loss)
I0124 12:54:46.051550 19781 sgd_solver.cpp:106] Iteration 5260, lr = 1
I0124 12:54:51.474767 19781 solver.cpp:236] Iteration 5280, loss = 6.09767
I0124 12:54:51.474843 19781 solver.cpp:252]     Train net output #0: loss = 6.09767 (* 1 = 6.09767 loss)
I0124 12:54:51.474853 19781 sgd_solver.cpp:106] Iteration 5280, lr = 1
I0124 12:54:56.225422 19781 solver.cpp:236] Iteration 5300, loss = 6.1255
I0124 12:54:56.225482 19781 solver.cpp:252]     Train net output #0: loss = 6.1255 (* 1 = 6.1255 loss)
I0124 12:54:56.225495 19781 sgd_solver.cpp:106] Iteration 5300, lr = 1
I0124 12:55:00.946631 19781 solver.cpp:236] Iteration 5320, loss = 6.07923
I0124 12:55:00.946699 19781 solver.cpp:252]     Train net output #0: loss = 6.07923 (* 1 = 6.07923 loss)
I0124 12:55:00.946710 19781 sgd_solver.cpp:106] Iteration 5320, lr = 1
I0124 12:55:05.669714 19781 solver.cpp:236] Iteration 5340, loss = 5.89049
I0124 12:55:05.669778 19781 solver.cpp:252]     Train net output #0: loss = 5.89049 (* 1 = 5.89049 loss)
I0124 12:55:05.669791 19781 sgd_solver.cpp:106] Iteration 5340, lr = 1
I0124 12:55:10.374742 19781 solver.cpp:236] Iteration 5360, loss = 6.01065
I0124 12:55:10.374814 19781 solver.cpp:252]     Train net output #0: loss = 6.01065 (* 1 = 6.01065 loss)
I0124 12:55:10.374825 19781 sgd_solver.cpp:106] Iteration 5360, lr = 1
I0124 12:55:15.121004 19781 solver.cpp:236] Iteration 5380, loss = 6.25345
I0124 12:55:15.121071 19781 solver.cpp:252]     Train net output #0: loss = 6.25345 (* 1 = 6.25345 loss)
I0124 12:55:15.121084 19781 sgd_solver.cpp:106] Iteration 5380, lr = 1
I0124 12:55:20.001610 19781 solver.cpp:236] Iteration 5400, loss = 5.82265
I0124 12:55:20.001906 19781 solver.cpp:252]     Train net output #0: loss = 5.82265 (* 1 = 5.82265 loss)
I0124 12:55:20.001924 19781 sgd_solver.cpp:106] Iteration 5400, lr = 1
I0124 12:55:24.914263 19781 solver.cpp:236] Iteration 5420, loss = 6.15734
I0124 12:55:24.914316 19781 solver.cpp:252]     Train net output #0: loss = 6.15734 (* 1 = 6.15734 loss)
I0124 12:55:24.914326 19781 sgd_solver.cpp:106] Iteration 5420, lr = 1
I0124 12:55:30.800379 19781 solver.cpp:236] Iteration 5440, loss = 6.17623
I0124 12:55:30.800436 19781 solver.cpp:252]     Train net output #0: loss = 6.17623 (* 1 = 6.17623 loss)
I0124 12:55:30.800447 19781 sgd_solver.cpp:106] Iteration 5440, lr = 1
I0124 12:55:35.858458 19781 solver.cpp:236] Iteration 5460, loss = 5.92913
I0124 12:55:35.858505 19781 solver.cpp:252]     Train net output #0: loss = 5.92913 (* 1 = 5.92913 loss)
I0124 12:55:35.858520 19781 sgd_solver.cpp:106] Iteration 5460, lr = 1
I0124 12:55:40.493393 19781 solver.cpp:236] Iteration 5480, loss = 5.84396
I0124 12:55:40.493443 19781 solver.cpp:252]     Train net output #0: loss = 5.84396 (* 1 = 5.84396 loss)
I0124 12:55:40.493453 19781 sgd_solver.cpp:106] Iteration 5480, lr = 1
I0124 12:55:45.140506 19781 solver.cpp:236] Iteration 5500, loss = 5.97556
I0124 12:55:45.140558 19781 solver.cpp:252]     Train net output #0: loss = 5.97556 (* 1 = 5.97556 loss)
I0124 12:55:45.140570 19781 sgd_solver.cpp:106] Iteration 5500, lr = 1
I0124 12:55:49.770851 19781 solver.cpp:236] Iteration 5520, loss = 5.8911
I0124 12:55:49.770905 19781 solver.cpp:252]     Train net output #0: loss = 5.8911 (* 1 = 5.8911 loss)
I0124 12:55:49.770915 19781 sgd_solver.cpp:106] Iteration 5520, lr = 1
I0124 12:55:54.381014 19781 solver.cpp:236] Iteration 5540, loss = 5.781
I0124 12:55:54.381227 19781 solver.cpp:252]     Train net output #0: loss = 5.781 (* 1 = 5.781 loss)
I0124 12:55:54.381248 19781 sgd_solver.cpp:106] Iteration 5540, lr = 1
I0124 12:55:59.105763 19781 solver.cpp:236] Iteration 5560, loss = 5.72937
I0124 12:55:59.105828 19781 solver.cpp:252]     Train net output #0: loss = 5.72937 (* 1 = 5.72937 loss)
I0124 12:55:59.105836 19781 sgd_solver.cpp:106] Iteration 5560, lr = 1
I0124 12:56:03.812957 19781 solver.cpp:236] Iteration 5580, loss = 6.19387
I0124 12:56:03.813029 19781 solver.cpp:252]     Train net output #0: loss = 6.19387 (* 1 = 6.19387 loss)
I0124 12:56:03.813042 19781 sgd_solver.cpp:106] Iteration 5580, lr = 1
I0124 12:56:08.603194 19781 solver.cpp:236] Iteration 5600, loss = 5.85777
I0124 12:56:08.603247 19781 solver.cpp:252]     Train net output #0: loss = 5.85777 (* 1 = 5.85777 loss)
I0124 12:56:08.603255 19781 sgd_solver.cpp:106] Iteration 5600, lr = 1
I0124 12:56:13.318819 19781 solver.cpp:236] Iteration 5620, loss = 5.93703
I0124 12:56:13.319079 19781 solver.cpp:252]     Train net output #0: loss = 5.93703 (* 1 = 5.93703 loss)
I0124 12:56:13.319103 19781 sgd_solver.cpp:106] Iteration 5620, lr = 1
I0124 12:56:18.294817 19781 solver.cpp:236] Iteration 5640, loss = 6.12296
I0124 12:56:18.294873 19781 solver.cpp:252]     Train net output #0: loss = 6.12296 (* 1 = 6.12296 loss)
I0124 12:56:18.294884 19781 sgd_solver.cpp:106] Iteration 5640, lr = 1
I0124 12:56:23.061612 19781 solver.cpp:236] Iteration 5660, loss = 5.77029
I0124 12:56:23.061663 19781 solver.cpp:252]     Train net output #0: loss = 5.77029 (* 1 = 5.77029 loss)
I0124 12:56:23.061673 19781 sgd_solver.cpp:106] Iteration 5660, lr = 1
I0124 12:56:27.845991 19781 solver.cpp:236] Iteration 5680, loss = 6.18578
I0124 12:56:27.846207 19781 solver.cpp:252]     Train net output #0: loss = 6.18578 (* 1 = 6.18578 loss)
I0124 12:56:27.846233 19781 sgd_solver.cpp:106] Iteration 5680, lr = 1
I0124 12:56:32.703100 19781 solver.cpp:236] Iteration 5700, loss = 5.95032
I0124 12:56:32.703172 19781 solver.cpp:252]     Train net output #0: loss = 5.95032 (* 1 = 5.95032 loss)
I0124 12:56:32.703183 19781 sgd_solver.cpp:106] Iteration 5700, lr = 1
I0124 12:56:37.641860 19781 solver.cpp:236] Iteration 5720, loss = 6.21669
I0124 12:56:37.641926 19781 solver.cpp:252]     Train net output #0: loss = 6.21669 (* 1 = 6.21669 loss)
I0124 12:56:37.641937 19781 sgd_solver.cpp:106] Iteration 5720, lr = 1
I0124 12:56:42.574693 19781 solver.cpp:236] Iteration 5740, loss = 5.82479
I0124 12:56:42.574753 19781 solver.cpp:252]     Train net output #0: loss = 5.82479 (* 1 = 5.82479 loss)
I0124 12:56:42.574764 19781 sgd_solver.cpp:106] Iteration 5740, lr = 1
I0124 12:56:47.474012 19781 solver.cpp:236] Iteration 5760, loss = 5.81073
I0124 12:56:47.474073 19781 solver.cpp:252]     Train net output #0: loss = 5.81073 (* 1 = 5.81073 loss)
I0124 12:56:47.474086 19781 sgd_solver.cpp:106] Iteration 5760, lr = 1
I0124 12:56:52.294030 19781 solver.cpp:236] Iteration 5780, loss = 5.86093
I0124 12:56:52.294090 19781 solver.cpp:252]     Train net output #0: loss = 5.86093 (* 1 = 5.86093 loss)
I0124 12:56:52.294100 19781 sgd_solver.cpp:106] Iteration 5780, lr = 1
I0124 12:56:57.546206 19781 solver.cpp:236] Iteration 5800, loss = 6.02345
I0124 12:56:57.546252 19781 solver.cpp:252]     Train net output #0: loss = 6.02345 (* 1 = 6.02345 loss)
I0124 12:56:57.546262 19781 sgd_solver.cpp:106] Iteration 5800, lr = 1
I0124 12:57:02.495074 19781 solver.cpp:236] Iteration 5820, loss = 6.22874
I0124 12:57:02.495369 19781 solver.cpp:252]     Train net output #0: loss = 6.22874 (* 1 = 6.22874 loss)
I0124 12:57:02.495389 19781 sgd_solver.cpp:106] Iteration 5820, lr = 1
I0124 12:57:07.269873 19781 solver.cpp:236] Iteration 5840, loss = 5.8437
I0124 12:57:07.269942 19781 solver.cpp:252]     Train net output #0: loss = 5.8437 (* 1 = 5.8437 loss)
I0124 12:57:07.269953 19781 sgd_solver.cpp:106] Iteration 5840, lr = 1
I0124 12:57:11.679697 19781 solver.cpp:236] Iteration 5860, loss = 6.22374
I0124 12:57:11.679769 19781 solver.cpp:252]     Train net output #0: loss = 6.22374 (* 1 = 6.22374 loss)
I0124 12:57:11.679781 19781 sgd_solver.cpp:106] Iteration 5860, lr = 1
I0124 12:57:16.052253 19781 solver.cpp:236] Iteration 5880, loss = 5.89287
I0124 12:57:16.052317 19781 solver.cpp:252]     Train net output #0: loss = 5.89287 (* 1 = 5.89287 loss)
I0124 12:57:16.052328 19781 sgd_solver.cpp:106] Iteration 5880, lr = 1
I0124 12:57:20.405946 19781 solver.cpp:236] Iteration 5900, loss = 6.2112
I0124 12:57:20.406023 19781 solver.cpp:252]     Train net output #0: loss = 6.2112 (* 1 = 6.2112 loss)
I0124 12:57:20.406033 19781 sgd_solver.cpp:106] Iteration 5900, lr = 1
I0124 12:57:24.821887 19781 solver.cpp:236] Iteration 5920, loss = 5.99994
I0124 12:57:24.821956 19781 solver.cpp:252]     Train net output #0: loss = 5.99994 (* 1 = 5.99994 loss)
I0124 12:57:24.821969 19781 sgd_solver.cpp:106] Iteration 5920, lr = 1
I0124 12:57:29.475100 19781 solver.cpp:236] Iteration 5940, loss = 6.02457
I0124 12:57:29.475149 19781 solver.cpp:252]     Train net output #0: loss = 6.02457 (* 1 = 6.02457 loss)
I0124 12:57:29.475160 19781 sgd_solver.cpp:106] Iteration 5940, lr = 1
I0124 12:57:34.121781 19781 solver.cpp:236] Iteration 5960, loss = 6.01027
I0124 12:57:34.122046 19781 solver.cpp:252]     Train net output #0: loss = 6.01027 (* 1 = 6.01027 loss)
I0124 12:57:34.122061 19781 sgd_solver.cpp:106] Iteration 5960, lr = 1
I0124 12:57:38.767015 19781 solver.cpp:236] Iteration 5980, loss = 6.01405
I0124 12:57:38.767065 19781 solver.cpp:252]     Train net output #0: loss = 6.01405 (* 1 = 6.01405 loss)
I0124 12:57:38.767074 19781 sgd_solver.cpp:106] Iteration 5980, lr = 1
I0124 12:57:44.139055 19781 solver.cpp:340] Iteration 6000, Testing net (#0)
I0124 12:57:47.836814 19781 blocking_queue.cpp:50] Data layer prefetch queue empty
I0124 12:59:20.479136 19781 solver.cpp:408]     Test net output #0: accuracy = 0.0411603
I0124 12:59:20.479316 19781 solver.cpp:408]     Test net output #1: loss = 5.72957 (* 1 = 5.72957 loss)
I0124 12:59:20.517267 19781 solver.cpp:236] Iteration 6000, loss = 5.82333
I0124 12:59:20.517303 19781 solver.cpp:252]     Train net output #0: loss = 5.82333 (* 1 = 5.82333 loss)
I0124 12:59:20.517316 19781 sgd_solver.cpp:106] Iteration 6000, lr = 1
I0124 12:59:24.933228 19781 solver.cpp:236] Iteration 6020, loss = 5.96963
I0124 12:59:24.933277 19781 solver.cpp:252]     Train net output #0: loss = 5.96963 (* 1 = 5.96963 loss)
I0124 12:59:24.933287 19781 sgd_solver.cpp:106] Iteration 6020, lr = 1
I0124 12:59:29.745393 19781 solver.cpp:236] Iteration 6040, loss = 5.93455
I0124 12:59:29.745435 19781 solver.cpp:252]     Train net output #0: loss = 5.93455 (* 1 = 5.93455 loss)
I0124 12:59:29.745443 19781 sgd_solver.cpp:106] Iteration 6040, lr = 1
I0124 12:59:30.217867 19781 blocking_queue.cpp:50] Data layer prefetch queue empty
I0124 12:59:34.407831 19781 solver.cpp:236] Iteration 6060, loss = 5.87222
I0124 12:59:34.407878 19781 solver.cpp:252]     Train net output #0: loss = 5.87222 (* 1 = 5.87222 loss)
I0124 12:59:34.407887 19781 sgd_solver.cpp:106] Iteration 6060, lr = 1
I0124 12:59:39.042471 19781 solver.cpp:236] Iteration 6080, loss = 5.78315
I0124 12:59:39.042511 19781 solver.cpp:252]     Train net output #0: loss = 5.78315 (* 1 = 5.78315 loss)
I0124 12:59:39.042520 19781 sgd_solver.cpp:106] Iteration 6080, lr = 1
I0124 12:59:43.828531 19781 solver.cpp:236] Iteration 6100, loss = 5.90856
I0124 12:59:43.828572 19781 solver.cpp:252]     Train net output #0: loss = 5.90856 (* 1 = 5.90856 loss)
I0124 12:59:43.828579 19781 sgd_solver.cpp:106] Iteration 6100, lr = 1
I0124 12:59:48.624209 19781 solver.cpp:236] Iteration 6120, loss = 6.10632
I0124 12:59:48.624253 19781 solver.cpp:252]     Train net output #0: loss = 6.10632 (* 1 = 6.10632 loss)
I0124 12:59:48.624263 19781 sgd_solver.cpp:106] Iteration 6120, lr = 1
I0124 12:59:53.543668 19781 solver.cpp:236] Iteration 6140, loss = 5.93048
I0124 12:59:53.544189 19781 solver.cpp:252]     Train net output #0: loss = 5.93048 (* 1 = 5.93048 loss)
I0124 12:59:53.544241 19781 sgd_solver.cpp:106] Iteration 6140, lr = 1
I0124 12:59:58.557068 19781 solver.cpp:236] Iteration 6160, loss = 5.72459
I0124 12:59:58.557137 19781 solver.cpp:252]     Train net output #0: loss = 5.72459 (* 1 = 5.72459 loss)
I0124 12:59:58.557147 19781 sgd_solver.cpp:106] Iteration 6160, lr = 1
I0124 13:00:03.602376 19781 solver.cpp:236] Iteration 6180, loss = 5.93995
I0124 13:00:03.602447 19781 solver.cpp:252]     Train net output #0: loss = 5.93995 (* 1 = 5.93995 loss)
I0124 13:00:03.602465 19781 sgd_solver.cpp:106] Iteration 6180, lr = 1
I0124 13:00:08.232069 19781 solver.cpp:236] Iteration 6200, loss = 5.90914
I0124 13:00:08.232141 19781 solver.cpp:252]     Train net output #0: loss = 5.90914 (* 1 = 5.90914 loss)
I0124 13:00:08.232172 19781 sgd_solver.cpp:106] Iteration 6200, lr = 1
I0124 13:00:12.863376 19781 solver.cpp:236] Iteration 6220, loss = 5.70989
I0124 13:00:12.863453 19781 solver.cpp:252]     Train net output #0: loss = 5.70989 (* 1 = 5.70989 loss)
I0124 13:00:12.863471 19781 sgd_solver.cpp:106] Iteration 6220, lr = 1
I0124 13:00:17.549010 19781 solver.cpp:236] Iteration 6240, loss = 5.89498
I0124 13:00:17.549068 19781 solver.cpp:252]     Train net output #0: loss = 5.89498 (* 1 = 5.89498 loss)
I0124 13:00:17.549079 19781 sgd_solver.cpp:106] Iteration 6240, lr = 1
I0124 13:00:22.198611 19781 solver.cpp:236] Iteration 6260, loss = 5.96063
I0124 13:00:22.198669 19781 solver.cpp:252]     Train net output #0: loss = 5.96063 (* 1 = 5.96063 loss)
I0124 13:00:22.198681 19781 sgd_solver.cpp:106] Iteration 6260, lr = 1
I0124 13:00:26.791950 19781 solver.cpp:236] Iteration 6280, loss = 5.82865
I0124 13:00:26.792125 19781 solver.cpp:252]     Train net output #0: loss = 5.82865 (* 1 = 5.82865 loss)
I0124 13:00:26.792136 19781 sgd_solver.cpp:106] Iteration 6280, lr = 1
I0124 13:00:31.499526 19781 solver.cpp:236] Iteration 6300, loss = 6.03728
I0124 13:00:31.499593 19781 solver.cpp:252]     Train net output #0: loss = 6.03728 (* 1 = 6.03728 loss)
I0124 13:00:31.499608 19781 sgd_solver.cpp:106] Iteration 6300, lr = 1
I0124 13:00:36.103621 19781 solver.cpp:236] Iteration 6320, loss = 5.98025
I0124 13:00:36.103682 19781 solver.cpp:252]     Train net output #0: loss = 5.98025 (* 1 = 5.98025 loss)
I0124 13:00:36.103695 19781 sgd_solver.cpp:106] Iteration 6320, lr = 1
I0124 13:00:41.035224 19781 solver.cpp:236] Iteration 6340, loss = 5.86841
I0124 13:00:41.035300 19781 solver.cpp:252]     Train net output #0: loss = 5.86841 (* 1 = 5.86841 loss)
I0124 13:00:41.035310 19781 sgd_solver.cpp:106] Iteration 6340, lr = 1
I0124 13:00:46.248600 19781 solver.cpp:236] Iteration 6360, loss = 5.83795
I0124 13:00:46.248664 19781 solver.cpp:252]     Train net output #0: loss = 5.83795 (* 1 = 5.83795 loss)
I0124 13:00:46.248674 19781 sgd_solver.cpp:106] Iteration 6360, lr = 1
I0124 13:00:50.977321 19781 solver.cpp:236] Iteration 6380, loss = 6.00172
I0124 13:00:50.977393 19781 solver.cpp:252]     Train net output #0: loss = 6.00172 (* 1 = 6.00172 loss)
I0124 13:00:50.977404 19781 sgd_solver.cpp:106] Iteration 6380, lr = 1
I0124 13:00:55.773409 19781 solver.cpp:236] Iteration 6400, loss = 5.75303
I0124 13:00:55.773474 19781 solver.cpp:252]     Train net output #0: loss = 5.75303 (* 1 = 5.75303 loss)
I0124 13:00:55.773485 19781 sgd_solver.cpp:106] Iteration 6400, lr = 1
I0124 13:01:00.625139 19781 solver.cpp:236] Iteration 6420, loss = 5.89931
I0124 13:01:00.625427 19781 solver.cpp:252]     Train net output #0: loss = 5.89931 (* 1 = 5.89931 loss)
I0124 13:01:00.625445 19781 sgd_solver.cpp:106] Iteration 6420, lr = 1
I0124 13:01:06.675165 19781 solver.cpp:236] Iteration 6440, loss = 6.0959
I0124 13:01:06.675215 19781 solver.cpp:252]     Train net output #0: loss = 6.0959 (* 1 = 6.0959 loss)
I0124 13:01:06.675225 19781 sgd_solver.cpp:106] Iteration 6440, lr = 1
I0124 13:01:13.361665 19781 solver.cpp:236] Iteration 6460, loss = 5.76357
I0124 13:01:13.361711 19781 solver.cpp:252]     Train net output #0: loss = 5.76357 (* 1 = 5.76357 loss)
I0124 13:01:13.361721 19781 sgd_solver.cpp:106] Iteration 6460, lr = 1
I0124 13:01:19.642300 19781 solver.cpp:236] Iteration 6480, loss = 6.03861
I0124 13:01:19.642350 19781 solver.cpp:252]     Train net output #0: loss = 6.03861 (* 1 = 6.03861 loss)
I0124 13:01:19.642370 19781 sgd_solver.cpp:106] Iteration 6480, lr = 1
I0124 13:01:25.395792 19781 solver.cpp:236] Iteration 6500, loss = 5.96892
I0124 13:01:25.395834 19781 solver.cpp:252]     Train net output #0: loss = 5.96892 (* 1 = 5.96892 loss)
I0124 13:01:25.395845 19781 sgd_solver.cpp:106] Iteration 6500, lr = 1
I0124 13:01:30.441519 19781 solver.cpp:236] Iteration 6520, loss = 5.83511
I0124 13:01:30.441571 19781 solver.cpp:252]     Train net output #0: loss = 5.83511 (* 1 = 5.83511 loss)
I0124 13:01:30.441588 19781 sgd_solver.cpp:106] Iteration 6520, lr = 1
I0124 13:01:35.262876 19781 solver.cpp:236] Iteration 6540, loss = 5.9162
I0124 13:01:35.263095 19781 solver.cpp:252]     Train net output #0: loss = 5.9162 (* 1 = 5.9162 loss)
I0124 13:01:35.263104 19781 sgd_solver.cpp:106] Iteration 6540, lr = 1
I0124 13:01:40.166754 19781 solver.cpp:236] Iteration 6560, loss = 5.95105
I0124 13:01:40.166802 19781 solver.cpp:252]     Train net output #0: loss = 5.95105 (* 1 = 5.95105 loss)
I0124 13:01:40.166813 19781 sgd_solver.cpp:106] Iteration 6560, lr = 1
I0124 13:01:45.096730 19781 solver.cpp:236] Iteration 6580, loss = 5.84279
I0124 13:01:45.096786 19781 solver.cpp:252]     Train net output #0: loss = 5.84279 (* 1 = 5.84279 loss)
I0124 13:01:45.096801 19781 sgd_solver.cpp:106] Iteration 6580, lr = 1
I0124 13:01:50.025867 19781 solver.cpp:236] Iteration 6600, loss = 5.87848
I0124 13:01:50.025919 19781 solver.cpp:252]     Train net output #0: loss = 5.87848 (* 1 = 5.87848 loss)
I0124 13:01:50.025929 19781 sgd_solver.cpp:106] Iteration 6600, lr = 1
I0124 13:01:54.944277 19781 solver.cpp:236] Iteration 6620, loss = 5.67053
I0124 13:01:54.944322 19781 solver.cpp:252]     Train net output #0: loss = 5.67053 (* 1 = 5.67053 loss)
I0124 13:01:54.944337 19781 sgd_solver.cpp:106] Iteration 6620, lr = 1
I0124 13:01:59.911515 19781 solver.cpp:236] Iteration 6640, loss = 5.87325
I0124 13:01:59.911552 19781 solver.cpp:252]     Train net output #0: loss = 5.87325 (* 1 = 5.87325 loss)
I0124 13:01:59.911558 19781 sgd_solver.cpp:106] Iteration 6640, lr = 1
I0124 13:02:04.840399 19781 solver.cpp:236] Iteration 6660, loss = 5.9858
I0124 13:02:04.840450 19781 solver.cpp:252]     Train net output #0: loss = 5.9858 (* 1 = 5.9858 loss)
I0124 13:02:04.840473 19781 sgd_solver.cpp:106] Iteration 6660, lr = 1
I0124 13:02:10.060490 19781 solver.cpp:236] Iteration 6680, loss = 5.80029
I0124 13:02:10.060905 19781 solver.cpp:252]     Train net output #0: loss = 5.80029 (* 1 = 5.80029 loss)
I0124 13:02:10.060966 19781 sgd_solver.cpp:106] Iteration 6680, lr = 1
I0124 13:02:15.477941 19781 solver.cpp:236] Iteration 6700, loss = 6.03709
I0124 13:02:15.478021 19781 solver.cpp:252]     Train net output #0: loss = 6.03709 (* 1 = 6.03709 loss)
I0124 13:02:15.478037 19781 sgd_solver.cpp:106] Iteration 6700, lr = 1
I0124 13:02:20.122717 19781 solver.cpp:236] Iteration 6720, loss = 6.03966
I0124 13:02:20.122768 19781 solver.cpp:252]     Train net output #0: loss = 6.03966 (* 1 = 6.03966 loss)
I0124 13:02:20.122776 19781 sgd_solver.cpp:106] Iteration 6720, lr = 1
I0124 13:02:25.214112 19781 solver.cpp:236] Iteration 6740, loss = 5.93576
I0124 13:02:25.214179 19781 solver.cpp:252]     Train net output #0: loss = 5.93576 (* 1 = 5.93576 loss)
I0124 13:02:25.214187 19781 sgd_solver.cpp:106] Iteration 6740, lr = 1
I0124 13:02:29.784795 19781 solver.cpp:236] Iteration 6760, loss = 5.87747
I0124 13:02:29.784870 19781 solver.cpp:252]     Train net output #0: loss = 5.87747 (* 1 = 5.87747 loss)
I0124 13:02:29.784891 19781 sgd_solver.cpp:106] Iteration 6760, lr = 1
I0124 13:02:34.489457 19781 solver.cpp:236] Iteration 6780, loss = 5.91733
I0124 13:02:34.489524 19781 solver.cpp:252]     Train net output #0: loss = 5.91733 (* 1 = 5.91733 loss)
I0124 13:02:34.489536 19781 sgd_solver.cpp:106] Iteration 6780, lr = 1
I0124 13:02:39.091445 19781 solver.cpp:236] Iteration 6800, loss = 5.60281
I0124 13:02:39.091507 19781 solver.cpp:252]     Train net output #0: loss = 5.60281 (* 1 = 5.60281 loss)
I0124 13:02:39.091518 19781 sgd_solver.cpp:106] Iteration 6800, lr = 1
I0124 13:02:43.771972 19781 solver.cpp:236] Iteration 6820, loss = 6.03027
I0124 13:02:43.772238 19781 solver.cpp:252]     Train net output #0: loss = 6.03027 (* 1 = 6.03027 loss)
I0124 13:02:43.772264 19781 sgd_solver.cpp:106] Iteration 6820, lr = 1
I0124 13:02:48.762606 19781 solver.cpp:236] Iteration 6840, loss = 5.91254
I0124 13:02:48.762689 19781 solver.cpp:252]     Train net output #0: loss = 5.91254 (* 1 = 5.91254 loss)
I0124 13:02:48.762698 19781 sgd_solver.cpp:106] Iteration 6840, lr = 1
I0124 13:02:53.690546 19781 solver.cpp:236] Iteration 6860, loss = 5.68574
I0124 13:02:53.690611 19781 solver.cpp:252]     Train net output #0: loss = 5.68574 (* 1 = 5.68574 loss)
I0124 13:02:53.690623 19781 sgd_solver.cpp:106] Iteration 6860, lr = 1
I0124 13:02:58.839306 19781 solver.cpp:236] Iteration 6880, loss = 5.82759
I0124 13:02:58.839540 19781 solver.cpp:252]     Train net output #0: loss = 5.82759 (* 1 = 5.82759 loss)
I0124 13:02:58.839563 19781 sgd_solver.cpp:106] Iteration 6880, lr = 1
I0124 13:03:04.134943 19781 solver.cpp:236] Iteration 6900, loss = 5.85205
I0124 13:03:04.135005 19781 solver.cpp:252]     Train net output #0: loss = 5.85205 (* 1 = 5.85205 loss)
I0124 13:03:04.135013 19781 sgd_solver.cpp:106] Iteration 6900, lr = 1
I0124 13:03:09.202842 19781 solver.cpp:236] Iteration 6920, loss = 6.08292
I0124 13:03:09.202899 19781 solver.cpp:252]     Train net output #0: loss = 6.08292 (* 1 = 6.08292 loss)
I0124 13:03:09.202908 19781 sgd_solver.cpp:106] Iteration 6920, lr = 1
I0124 13:03:14.100064 19781 solver.cpp:236] Iteration 6940, loss = 5.64838
I0124 13:03:14.100204 19781 solver.cpp:252]     Train net output #0: loss = 5.64838 (* 1 = 5.64838 loss)
I0124 13:03:14.100214 19781 sgd_solver.cpp:106] Iteration 6940, lr = 1
I0124 13:03:19.059875 19781 solver.cpp:236] Iteration 6960, loss = 5.77916
I0124 13:03:19.059938 19781 solver.cpp:252]     Train net output #0: loss = 5.77916 (* 1 = 5.77916 loss)
I0124 13:03:19.059947 19781 sgd_solver.cpp:106] Iteration 6960, lr = 1
I0124 13:03:24.011641 19781 solver.cpp:236] Iteration 6980, loss = 5.78499
I0124 13:03:24.011710 19781 solver.cpp:252]     Train net output #0: loss = 5.78499 (* 1 = 5.78499 loss)
I0124 13:03:24.011723 19781 sgd_solver.cpp:106] Iteration 6980, lr = 1
I0124 13:03:28.967010 19781 solver.cpp:340] Iteration 7000, Testing net (#0)
I0124 13:03:33.226784 19781 blocking_queue.cpp:50] Data layer prefetch queue empty
I0124 13:05:07.215468 19781 solver.cpp:408]     Test net output #0: accuracy = 0.0471403
I0124 13:05:07.215772 19781 solver.cpp:408]     Test net output #1: loss = 5.69027 (* 1 = 5.69027 loss)
I0124 13:05:07.253846 19781 solver.cpp:236] Iteration 7000, loss = 5.91458
I0124 13:05:07.253901 19781 solver.cpp:252]     Train net output #0: loss = 5.91458 (* 1 = 5.91458 loss)
I0124 13:05:07.253912 19781 sgd_solver.cpp:106] Iteration 7000, lr = 1
I0124 13:05:12.188827 19781 solver.cpp:236] Iteration 7020, loss = 6.07999
I0124 13:05:12.188894 19781 solver.cpp:252]     Train net output #0: loss = 6.07999 (* 1 = 6.07999 loss)
I0124 13:05:12.188910 19781 sgd_solver.cpp:106] Iteration 7020, lr = 1
I0124 13:05:20.598510 19781 solver.cpp:236] Iteration 7040, loss = 5.7307
I0124 13:05:20.598556 19781 solver.cpp:252]     Train net output #0: loss = 5.7307 (* 1 = 5.7307 loss)
I0124 13:05:20.598562 19781 sgd_solver.cpp:106] Iteration 7040, lr = 1
I0124 13:05:24.052608 19781 blocking_queue.cpp:50] Data layer prefetch queue empty
I0124 13:05:28.386011 19781 solver.cpp:236] Iteration 7060, loss = 5.80902
I0124 13:05:28.386050 19781 solver.cpp:252]     Train net output #0: loss = 5.80902 (* 1 = 5.80902 loss)
I0124 13:05:28.386056 19781 sgd_solver.cpp:106] Iteration 7060, lr = 1
I0124 13:05:36.153291 19781 solver.cpp:236] Iteration 7080, loss = 5.75891
I0124 13:05:36.153343 19781 solver.cpp:252]     Train net output #0: loss = 5.75891 (* 1 = 5.75891 loss)
I0124 13:05:36.153348 19781 sgd_solver.cpp:106] Iteration 7080, lr = 1
I0124 13:05:43.966516 19781 solver.cpp:236] Iteration 7100, loss = 5.92868
I0124 13:05:43.966727 19781 solver.cpp:252]     Train net output #0: loss = 5.92868 (* 1 = 5.92868 loss)
I0124 13:05:43.966747 19781 sgd_solver.cpp:106] Iteration 7100, lr = 1
I0124 13:05:52.006288 19781 solver.cpp:236] Iteration 7120, loss = 5.95874
I0124 13:05:52.006341 19781 solver.cpp:252]     Train net output #0: loss = 5.95874 (* 1 = 5.95874 loss)
I0124 13:05:52.006351 19781 sgd_solver.cpp:106] Iteration 7120, lr = 1
I0124 13:05:58.358340 19781 solver.cpp:236] Iteration 7140, loss = 5.89913
I0124 13:05:58.358386 19781 solver.cpp:252]     Train net output #0: loss = 5.89913 (* 1 = 5.89913 loss)
I0124 13:05:58.358396 19781 sgd_solver.cpp:106] Iteration 7140, lr = 1
I0124 13:06:03.602923 19781 solver.cpp:236] Iteration 7160, loss = 6.12078
I0124 13:06:03.602964 19781 solver.cpp:252]     Train net output #0: loss = 6.12078 (* 1 = 6.12078 loss)
I0124 13:06:03.602973 19781 sgd_solver.cpp:106] Iteration 7160, lr = 1
I0124 13:06:08.210399 19781 solver.cpp:236] Iteration 7180, loss = 5.84602
I0124 13:06:08.210463 19781 solver.cpp:252]     Train net output #0: loss = 5.84602 (* 1 = 5.84602 loss)
I0124 13:06:08.210477 19781 sgd_solver.cpp:106] Iteration 7180, lr = 1
I0124 13:06:12.614549 19781 solver.cpp:236] Iteration 7200, loss = 6.1361
I0124 13:06:12.614593 19781 solver.cpp:252]     Train net output #0: loss = 6.1361 (* 1 = 6.1361 loss)
I0124 13:06:12.614603 19781 sgd_solver.cpp:106] Iteration 7200, lr = 1
I0124 13:06:17.185065 19781 solver.cpp:236] Iteration 7220, loss = 5.9233
I0124 13:06:17.185181 19781 solver.cpp:252]     Train net output #0: loss = 5.9233 (* 1 = 5.9233 loss)
I0124 13:06:17.185189 19781 sgd_solver.cpp:106] Iteration 7220, lr = 1
I0124 13:06:21.715663 19781 solver.cpp:236] Iteration 7240, loss = 5.85126
I0124 13:06:21.715718 19781 solver.cpp:252]     Train net output #0: loss = 5.85126 (* 1 = 5.85126 loss)
I0124 13:06:21.715728 19781 sgd_solver.cpp:106] Iteration 7240, lr = 1
I0124 13:06:26.270987 19781 solver.cpp:236] Iteration 7260, loss = 5.86842
I0124 13:06:26.271039 19781 solver.cpp:252]     Train net output #0: loss = 5.86842 (* 1 = 5.86842 loss)
I0124 13:06:26.271049 19781 sgd_solver.cpp:106] Iteration 7260, lr = 1
I0124 13:06:30.918629 19781 solver.cpp:236] Iteration 7280, loss = 5.82874
I0124 13:06:30.918699 19781 solver.cpp:252]     Train net output #0: loss = 5.82874 (* 1 = 5.82874 loss)
I0124 13:06:30.918710 19781 sgd_solver.cpp:106] Iteration 7280, lr = 1
I0124 13:06:35.540945 19781 solver.cpp:236] Iteration 7300, loss = 6.28785
I0124 13:06:35.541009 19781 solver.cpp:252]     Train net output #0: loss = 6.28785 (* 1 = 6.28785 loss)
I0124 13:06:35.541020 19781 sgd_solver.cpp:106] Iteration 7300, lr = 1
I0124 13:06:40.328500 19781 solver.cpp:236] Iteration 7320, loss = 5.9475
I0124 13:06:40.328562 19781 solver.cpp:252]     Train net output #0: loss = 5.9475 (* 1 = 5.9475 loss)
I0124 13:06:40.328573 19781 sgd_solver.cpp:106] Iteration 7320, lr = 1
I0124 13:06:46.157316 19781 solver.cpp:236] Iteration 7340, loss = 5.78478
I0124 13:06:46.157378 19781 solver.cpp:252]     Train net output #0: loss = 5.78478 (* 1 = 5.78478 loss)
I0124 13:06:46.157388 19781 sgd_solver.cpp:106] Iteration 7340, lr = 1
I0124 13:06:50.447546 19781 solver.cpp:236] Iteration 7360, loss = 5.99275
I0124 13:06:50.447795 19781 solver.cpp:252]     Train net output #0: loss = 5.99275 (* 1 = 5.99275 loss)
I0124 13:06:50.447818 19781 sgd_solver.cpp:106] Iteration 7360, lr = 1
I0124 13:06:55.113883 19781 solver.cpp:236] Iteration 7380, loss = 5.8242
I0124 13:06:55.113936 19781 solver.cpp:252]     Train net output #0: loss = 5.8242 (* 1 = 5.8242 loss)
I0124 13:06:55.113946 19781 sgd_solver.cpp:106] Iteration 7380, lr = 1
I0124 13:06:59.724889 19781 solver.cpp:236] Iteration 7400, loss = 5.80187
I0124 13:06:59.724942 19781 solver.cpp:252]     Train net output #0: loss = 5.80187 (* 1 = 5.80187 loss)
I0124 13:06:59.724951 19781 sgd_solver.cpp:106] Iteration 7400, lr = 1
I0124 13:07:04.317330 19781 solver.cpp:236] Iteration 7420, loss = 5.89777
I0124 13:07:04.317384 19781 solver.cpp:252]     Train net output #0: loss = 5.89777 (* 1 = 5.89777 loss)
I0124 13:07:04.317394 19781 sgd_solver.cpp:106] Iteration 7420, lr = 1
I0124 13:07:08.945885 19781 solver.cpp:236] Iteration 7440, loss = 5.82906
I0124 13:07:08.945927 19781 solver.cpp:252]     Train net output #0: loss = 5.82906 (* 1 = 5.82906 loss)
I0124 13:07:08.945936 19781 sgd_solver.cpp:106] Iteration 7440, lr = 1
I0124 13:07:13.660305 19781 solver.cpp:236] Iteration 7460, loss = 6.0778
I0124 13:07:13.660356 19781 solver.cpp:252]     Train net output #0: loss = 6.0778 (* 1 = 6.0778 loss)
I0124 13:07:13.660364 19781 sgd_solver.cpp:106] Iteration 7460, lr = 1
I0124 13:07:18.386323 19781 solver.cpp:236] Iteration 7480, loss = 5.86508
I0124 13:07:18.386379 19781 solver.cpp:252]     Train net output #0: loss = 5.86508 (* 1 = 5.86508 loss)
I0124 13:07:18.386389 19781 sgd_solver.cpp:106] Iteration 7480, lr = 1
I0124 13:07:23.096724 19781 solver.cpp:236] Iteration 7500, loss = 5.88216
I0124 13:07:23.096995 19781 solver.cpp:252]     Train net output #0: loss = 5.88216 (* 1 = 5.88216 loss)
I0124 13:07:23.097008 19781 sgd_solver.cpp:106] Iteration 7500, lr = 1
I0124 13:07:28.553082 19781 solver.cpp:236] Iteration 7520, loss = 5.84387
I0124 13:07:28.553118 19781 solver.cpp:252]     Train net output #0: loss = 5.84387 (* 1 = 5.84387 loss)
I0124 13:07:28.553133 19781 sgd_solver.cpp:106] Iteration 7520, lr = 1
I0124 13:07:34.293684 19781 solver.cpp:236] Iteration 7540, loss = 5.99348
I0124 13:07:34.293747 19781 solver.cpp:252]     Train net output #0: loss = 5.99348 (* 1 = 5.99348 loss)
I0124 13:07:34.293758 19781 sgd_solver.cpp:106] Iteration 7540, lr = 1
I0124 13:07:39.516954 19781 solver.cpp:236] Iteration 7560, loss = 5.89648
I0124 13:07:39.517025 19781 solver.cpp:252]     Train net output #0: loss = 5.89648 (* 1 = 5.89648 loss)
I0124 13:07:39.517036 19781 sgd_solver.cpp:106] Iteration 7560, lr = 1
I0124 13:07:44.724961 19781 solver.cpp:236] Iteration 7580, loss = 5.8599
I0124 13:07:44.725036 19781 solver.cpp:252]     Train net output #0: loss = 5.8599 (* 1 = 5.8599 loss)
I0124 13:07:44.725046 19781 sgd_solver.cpp:106] Iteration 7580, lr = 1
I0124 13:07:49.947018 19781 solver.cpp:236] Iteration 7600, loss = 5.82895
I0124 13:07:49.947085 19781 solver.cpp:252]     Train net output #0: loss = 5.82895 (* 1 = 5.82895 loss)
I0124 13:07:49.947098 19781 sgd_solver.cpp:106] Iteration 7600, lr = 1
I0124 13:07:55.194470 19781 solver.cpp:236] Iteration 7620, loss = 5.97425
I0124 13:07:55.194792 19781 solver.cpp:252]     Train net output #0: loss = 5.97425 (* 1 = 5.97425 loss)
I0124 13:07:55.194809 19781 sgd_solver.cpp:106] Iteration 7620, lr = 1
I0124 13:08:00.412987 19781 solver.cpp:236] Iteration 7640, loss = 5.80291
I0124 13:08:00.413041 19781 solver.cpp:252]     Train net output #0: loss = 5.80291 (* 1 = 5.80291 loss)
I0124 13:08:00.413051 19781 sgd_solver.cpp:106] Iteration 7640, lr = 1
I0124 13:08:05.580163 19781 solver.cpp:236] Iteration 7660, loss = 5.99653
I0124 13:08:05.580207 19781 solver.cpp:252]     Train net output #0: loss = 5.99653 (* 1 = 5.99653 loss)
I0124 13:08:05.580216 19781 sgd_solver.cpp:106] Iteration 7660, lr = 1
I0124 13:08:10.814926 19781 solver.cpp:236] Iteration 7680, loss = 5.51366
I0124 13:08:10.814978 19781 solver.cpp:252]     Train net output #0: loss = 5.51366 (* 1 = 5.51366 loss)
I0124 13:08:10.814987 19781 sgd_solver.cpp:106] Iteration 7680, lr = 1
I0124 13:08:16.906360 19781 solver.cpp:236] Iteration 7700, loss = 5.83737
I0124 13:08:16.906430 19781 solver.cpp:252]     Train net output #0: loss = 5.83737 (* 1 = 5.83737 loss)
I0124 13:08:16.906441 19781 sgd_solver.cpp:106] Iteration 7700, lr = 1
I0124 13:08:22.043156 19781 solver.cpp:236] Iteration 7720, loss = 5.95062
I0124 13:08:22.043215 19781 solver.cpp:252]     Train net output #0: loss = 5.95062 (* 1 = 5.95062 loss)
I0124 13:08:22.043226 19781 sgd_solver.cpp:106] Iteration 7720, lr = 1
I0124 13:08:27.201741 19781 solver.cpp:236] Iteration 7740, loss = 5.66006
I0124 13:08:27.201970 19781 solver.cpp:252]     Train net output #0: loss = 5.66006 (* 1 = 5.66006 loss)
I0124 13:08:27.201997 19781 sgd_solver.cpp:106] Iteration 7740, lr = 1
I0124 13:08:32.367591 19781 solver.cpp:236] Iteration 7760, loss = 5.63886
I0124 13:08:32.367635 19781 solver.cpp:252]     Train net output #0: loss = 5.63886 (* 1 = 5.63886 loss)
I0124 13:08:32.367641 19781 sgd_solver.cpp:106] Iteration 7760, lr = 1
I0124 13:08:37.489101 19781 solver.cpp:236] Iteration 7780, loss = 5.87809
I0124 13:08:37.489154 19781 solver.cpp:252]     Train net output #0: loss = 5.87809 (* 1 = 5.87809 loss)
I0124 13:08:37.489163 19781 sgd_solver.cpp:106] Iteration 7780, lr = 1
I0124 13:08:42.558809 19781 solver.cpp:236] Iteration 7800, loss = 5.79687
I0124 13:08:42.558861 19781 solver.cpp:252]     Train net output #0: loss = 5.79687 (* 1 = 5.79687 loss)
I0124 13:08:42.558871 19781 sgd_solver.cpp:106] Iteration 7800, lr = 1
I0124 13:08:47.679658 19781 solver.cpp:236] Iteration 7820, loss = 5.8899
I0124 13:08:47.679711 19781 solver.cpp:252]     Train net output #0: loss = 5.8899 (* 1 = 5.8899 loss)
I0124 13:08:47.679725 19781 sgd_solver.cpp:106] Iteration 7820, lr = 1
I0124 13:08:52.786063 19781 solver.cpp:236] Iteration 7840, loss = 5.94973
I0124 13:08:52.786109 19781 solver.cpp:252]     Train net output #0: loss = 5.94973 (* 1 = 5.94973 loss)
I0124 13:08:52.786121 19781 sgd_solver.cpp:106] Iteration 7840, lr = 1
I0124 13:08:58.405148 19781 solver.cpp:236] Iteration 7860, loss = 5.82591
I0124 13:08:58.405297 19781 solver.cpp:252]     Train net output #0: loss = 5.82591 (* 1 = 5.82591 loss)
I0124 13:08:58.405308 19781 sgd_solver.cpp:106] Iteration 7860, lr = 1
I0124 13:09:03.551240 19781 solver.cpp:236] Iteration 7880, loss = 5.5954
I0124 13:09:03.551296 19781 solver.cpp:252]     Train net output #0: loss = 5.5954 (* 1 = 5.5954 loss)
I0124 13:09:03.551307 19781 sgd_solver.cpp:106] Iteration 7880, lr = 1
I0124 13:09:08.550463 19781 solver.cpp:236] Iteration 7900, loss = 5.74659
I0124 13:09:08.550532 19781 solver.cpp:252]     Train net output #0: loss = 5.74659 (* 1 = 5.74659 loss)
I0124 13:09:08.550544 19781 sgd_solver.cpp:106] Iteration 7900, lr = 1
I0124 13:09:13.400326 19781 solver.cpp:236] Iteration 7920, loss = 5.87596
I0124 13:09:13.400398 19781 solver.cpp:252]     Train net output #0: loss = 5.87596 (* 1 = 5.87596 loss)
I0124 13:09:13.400413 19781 sgd_solver.cpp:106] Iteration 7920, lr = 1
I0124 13:09:18.165128 19781 solver.cpp:236] Iteration 7940, loss = 5.85806
I0124 13:09:18.165205 19781 solver.cpp:252]     Train net output #0: loss = 5.85806 (* 1 = 5.85806 loss)
I0124 13:09:18.165215 19781 sgd_solver.cpp:106] Iteration 7940, lr = 1
I0124 13:09:22.852080 19781 solver.cpp:236] Iteration 7960, loss = 5.80223
I0124 13:09:22.852144 19781 solver.cpp:252]     Train net output #0: loss = 5.80223 (* 1 = 5.80223 loss)
I0124 13:09:22.852161 19781 sgd_solver.cpp:106] Iteration 7960, lr = 1
I0124 13:09:27.614933 19781 solver.cpp:236] Iteration 7980, loss = 5.52089
I0124 13:09:27.615017 19781 solver.cpp:252]     Train net output #0: loss = 5.52089 (* 1 = 5.52089 loss)
I0124 13:09:27.615031 19781 sgd_solver.cpp:106] Iteration 7980, lr = 1
I0124 13:09:32.107233 19781 solver.cpp:340] Iteration 8000, Testing net (#0)
I0124 13:09:37.231281 19781 blocking_queue.cpp:50] Data layer prefetch queue empty
I0124 13:11:14.175231 19781 solver.cpp:408]     Test net output #0: accuracy = 0.0542604
I0124 13:11:14.175375 19781 solver.cpp:408]     Test net output #1: loss = 5.4951 (* 1 = 5.4951 loss)
I0124 13:11:14.213003 19781 solver.cpp:236] Iteration 8000, loss = 5.83006
I0124 13:11:14.213037 19781 solver.cpp:252]     Train net output #0: loss = 5.83006 (* 1 = 5.83006 loss)
I0124 13:11:14.213045 19781 sgd_solver.cpp:106] Iteration 8000, lr = 1
I0124 13:11:18.922581 19781 solver.cpp:236] Iteration 8020, loss = 5.8131
I0124 13:11:18.922627 19781 solver.cpp:252]     Train net output #0: loss = 5.8131 (* 1 = 5.8131 loss)
I0124 13:11:18.922637 19781 sgd_solver.cpp:106] Iteration 8020, lr = 1
I0124 13:11:23.938735 19781 solver.cpp:236] Iteration 8040, loss = 5.89234
I0124 13:11:23.938787 19781 solver.cpp:252]     Train net output #0: loss = 5.89234 (* 1 = 5.89234 loss)
I0124 13:11:23.938797 19781 sgd_solver.cpp:106] Iteration 8040, lr = 1
I0124 13:11:27.952728 19781 blocking_queue.cpp:50] Data layer prefetch queue empty
I0124 13:11:28.937151 19781 solver.cpp:236] Iteration 8060, loss = 5.61637
I0124 13:11:28.937217 19781 solver.cpp:252]     Train net output #0: loss = 5.61637 (* 1 = 5.61637 loss)
I0124 13:11:28.937249 19781 sgd_solver.cpp:106] Iteration 8060, lr = 1
I0124 13:11:34.037072 19781 solver.cpp:236] Iteration 8080, loss = 5.69365
I0124 13:11:34.037138 19781 solver.cpp:252]     Train net output #0: loss = 5.69365 (* 1 = 5.69365 loss)
I0124 13:11:34.037148 19781 sgd_solver.cpp:106] Iteration 8080, lr = 1
I0124 13:11:39.119983 19781 solver.cpp:236] Iteration 8100, loss = 5.90495
I0124 13:11:39.120039 19781 solver.cpp:252]     Train net output #0: loss = 5.90495 (* 1 = 5.90495 loss)
I0124 13:11:39.120050 19781 sgd_solver.cpp:106] Iteration 8100, lr = 1
I0124 13:11:44.207209 19781 solver.cpp:236] Iteration 8120, loss = 5.75571
I0124 13:11:44.207433 19781 solver.cpp:252]     Train net output #0: loss = 5.75571 (* 1 = 5.75571 loss)
I0124 13:11:44.207455 19781 sgd_solver.cpp:106] Iteration 8120, lr = 1
I0124 13:11:49.260383 19781 solver.cpp:236] Iteration 8140, loss = 5.86616
I0124 13:11:49.260437 19781 solver.cpp:252]     Train net output #0: loss = 5.86616 (* 1 = 5.86616 loss)
I0124 13:11:49.260447 19781 sgd_solver.cpp:106] Iteration 8140, lr = 1
I0124 13:11:54.723949 19781 solver.cpp:236] Iteration 8160, loss = 6.04864
I0124 13:11:54.723994 19781 solver.cpp:252]     Train net output #0: loss = 6.04864 (* 1 = 6.04864 loss)
I0124 13:11:54.724002 19781 sgd_solver.cpp:106] Iteration 8160, lr = 1
I0124 13:11:59.488637 19781 solver.cpp:236] Iteration 8180, loss = 6.11658
I0124 13:11:59.488683 19781 solver.cpp:252]     Train net output #0: loss = 6.11658 (* 1 = 6.11658 loss)
I0124 13:11:59.488692 19781 sgd_solver.cpp:106] Iteration 8180, lr = 1
I0124 13:12:04.260645 19781 solver.cpp:236] Iteration 8200, loss = 5.86046
I0124 13:12:04.260679 19781 solver.cpp:252]     Train net output #0: loss = 5.86046 (* 1 = 5.86046 loss)
I0124 13:12:04.260691 19781 sgd_solver.cpp:106] Iteration 8200, lr = 1
I0124 13:12:11.784461 19781 solver.cpp:236] Iteration 8220, loss = 5.97079
I0124 13:12:11.784519 19781 solver.cpp:252]     Train net output #0: loss = 5.97079 (* 1 = 5.97079 loss)
I0124 13:12:11.784534 19781 sgd_solver.cpp:106] Iteration 8220, lr = 1
I0124 13:12:16.397722 19781 solver.cpp:236] Iteration 8240, loss = 5.88393
I0124 13:12:16.398069 19781 solver.cpp:252]     Train net output #0: loss = 5.88393 (* 1 = 5.88393 loss)
I0124 13:12:16.398092 19781 sgd_solver.cpp:106] Iteration 8240, lr = 1
I0124 13:12:20.984971 19781 solver.cpp:236] Iteration 8260, loss = 5.99553
I0124 13:12:20.985038 19781 solver.cpp:252]     Train net output #0: loss = 5.99553 (* 1 = 5.99553 loss)
I0124 13:12:20.985049 19781 sgd_solver.cpp:106] Iteration 8260, lr = 1
I0124 13:12:25.733820 19781 solver.cpp:236] Iteration 8280, loss = 5.95113
I0124 13:12:25.733888 19781 solver.cpp:252]     Train net output #0: loss = 5.95113 (* 1 = 5.95113 loss)
I0124 13:12:25.733899 19781 sgd_solver.cpp:106] Iteration 8280, lr = 1
I0124 13:12:31.038771 19781 solver.cpp:236] Iteration 8300, loss = 5.64245
I0124 13:12:31.038833 19781 solver.cpp:252]     Train net output #0: loss = 5.64245 (* 1 = 5.64245 loss)
I0124 13:12:31.038844 19781 sgd_solver.cpp:106] Iteration 8300, lr = 1
I0124 13:12:35.840688 19781 solver.cpp:236] Iteration 8320, loss = 5.96624
I0124 13:12:35.840757 19781 solver.cpp:252]     Train net output #0: loss = 5.96624 (* 1 = 5.96624 loss)
I0124 13:12:35.840771 19781 sgd_solver.cpp:106] Iteration 8320, lr = 1
I0124 13:12:40.690588 19781 solver.cpp:236] Iteration 8340, loss = 5.95798
I0124 13:12:40.690654 19781 solver.cpp:252]     Train net output #0: loss = 5.95798 (* 1 = 5.95798 loss)
I0124 13:12:40.690666 19781 sgd_solver.cpp:106] Iteration 8340, lr = 1
I0124 13:12:45.868758 19781 solver.cpp:236] Iteration 8360, loss = 5.70887
I0124 13:12:45.868856 19781 solver.cpp:252]     Train net output #0: loss = 5.70887 (* 1 = 5.70887 loss)
I0124 13:12:45.868867 19781 sgd_solver.cpp:106] Iteration 8360, lr = 1
I0124 13:12:51.111471 19781 solver.cpp:236] Iteration 8380, loss = 5.52573
I0124 13:12:51.111718 19781 solver.cpp:252]     Train net output #0: loss = 5.52573 (* 1 = 5.52573 loss)
I0124 13:12:51.111733 19781 sgd_solver.cpp:106] Iteration 8380, lr = 1
I0124 13:12:56.634379 19781 solver.cpp:236] Iteration 8400, loss = 5.70769
I0124 13:12:56.634418 19781 solver.cpp:252]     Train net output #0: loss = 5.70769 (* 1 = 5.70769 loss)
I0124 13:12:56.634426 19781 sgd_solver.cpp:106] Iteration 8400, lr = 1
I0124 13:13:01.612165 19781 solver.cpp:236] Iteration 8420, loss = 5.76497
I0124 13:13:01.612210 19781 solver.cpp:252]     Train net output #0: loss = 5.76497 (* 1 = 5.76497 loss)
I0124 13:13:01.612221 19781 sgd_solver.cpp:106] Iteration 8420, lr = 1
I0124 13:13:06.240190 19781 solver.cpp:236] Iteration 8440, loss = 5.76488
I0124 13:13:06.240234 19781 solver.cpp:252]     Train net output #0: loss = 5.76488 (* 1 = 5.76488 loss)
I0124 13:13:06.240242 19781 sgd_solver.cpp:106] Iteration 8440, lr = 1
I0124 13:13:10.876974 19781 solver.cpp:236] Iteration 8460, loss = 5.63363
I0124 13:13:10.877020 19781 solver.cpp:252]     Train net output #0: loss = 5.63363 (* 1 = 5.63363 loss)
I0124 13:13:10.877027 19781 sgd_solver.cpp:106] Iteration 8460, lr = 1
I0124 13:13:15.490084 19781 solver.cpp:236] Iteration 8480, loss = 5.86425
I0124 13:13:15.490126 19781 solver.cpp:252]     Train net output #0: loss = 5.86425 (* 1 = 5.86425 loss)
I0124 13:13:15.490134 19781 sgd_solver.cpp:106] Iteration 8480, lr = 1
I0124 13:13:20.122352 19781 solver.cpp:236] Iteration 8500, loss = 5.76311
I0124 13:13:20.122407 19781 solver.cpp:252]     Train net output #0: loss = 5.76311 (* 1 = 5.76311 loss)
I0124 13:13:20.122417 19781 sgd_solver.cpp:106] Iteration 8500, lr = 1
I0124 13:13:24.915585 19781 solver.cpp:236] Iteration 8520, loss = 6.02746
I0124 13:13:24.915745 19781 solver.cpp:252]     Train net output #0: loss = 6.02746 (* 1 = 6.02746 loss)
I0124 13:13:24.915756 19781 sgd_solver.cpp:106] Iteration 8520, lr = 1
I0124 13:13:29.772106 19781 solver.cpp:236] Iteration 8540, loss = 5.79107
I0124 13:13:29.772146 19781 solver.cpp:252]     Train net output #0: loss = 5.79107 (* 1 = 5.79107 loss)
I0124 13:13:29.772166 19781 sgd_solver.cpp:106] Iteration 8540, lr = 1
I0124 13:13:34.657526 19781 solver.cpp:236] Iteration 8560, loss = 5.59118
I0124 13:13:34.657593 19781 solver.cpp:252]     Train net output #0: loss = 5.59118 (* 1 = 5.59118 loss)
I0124 13:13:34.657618 19781 sgd_solver.cpp:106] Iteration 8560, lr = 1
I0124 13:13:41.427362 19781 solver.cpp:236] Iteration 8580, loss = 5.52129
I0124 13:13:41.427418 19781 solver.cpp:252]     Train net output #0: loss = 5.52129 (* 1 = 5.52129 loss)
I0124 13:13:41.427428 19781 sgd_solver.cpp:106] Iteration 8580, lr = 1
I0124 13:13:46.812283 19781 solver.cpp:236] Iteration 8600, loss = 5.91404
I0124 13:13:46.812331 19781 solver.cpp:252]     Train net output #0: loss = 5.91404 (* 1 = 5.91404 loss)
I0124 13:13:46.812341 19781 sgd_solver.cpp:106] Iteration 8600, lr = 1
I0124 13:13:51.627818 19781 solver.cpp:236] Iteration 8620, loss = 5.4595
I0124 13:13:51.627868 19781 solver.cpp:252]     Train net output #0: loss = 5.4595 (* 1 = 5.4595 loss)
I0124 13:13:51.627878 19781 sgd_solver.cpp:106] Iteration 8620, lr = 1
I0124 13:13:56.241679 19781 solver.cpp:236] Iteration 8640, loss = 5.92149
I0124 13:13:56.241935 19781 solver.cpp:252]     Train net output #0: loss = 5.92149 (* 1 = 5.92149 loss)
I0124 13:13:56.241952 19781 sgd_solver.cpp:106] Iteration 8640, lr = 1
I0124 13:14:00.928913 19781 solver.cpp:236] Iteration 8660, loss = 5.84273
I0124 13:14:00.928980 19781 solver.cpp:252]     Train net output #0: loss = 5.84273 (* 1 = 5.84273 loss)
I0124 13:14:00.928992 19781 sgd_solver.cpp:106] Iteration 8660, lr = 1
I0124 13:14:05.553495 19781 solver.cpp:236] Iteration 8680, loss = 5.79519
I0124 13:14:05.553560 19781 solver.cpp:252]     Train net output #0: loss = 5.79519 (* 1 = 5.79519 loss)
I0124 13:14:05.553570 19781 sgd_solver.cpp:106] Iteration 8680, lr = 1
I0124 13:14:10.234900 19781 solver.cpp:236] Iteration 8700, loss = 5.86479
I0124 13:14:10.234976 19781 solver.cpp:252]     Train net output #0: loss = 5.86479 (* 1 = 5.86479 loss)
I0124 13:14:10.234990 19781 sgd_solver.cpp:106] Iteration 8700, lr = 1
I0124 13:14:15.008996 19781 solver.cpp:236] Iteration 8720, loss = 5.84433
I0124 13:14:15.009068 19781 solver.cpp:252]     Train net output #0: loss = 5.84433 (* 1 = 5.84433 loss)
I0124 13:14:15.009079 19781 sgd_solver.cpp:106] Iteration 8720, lr = 1
I0124 13:14:19.783753 19781 solver.cpp:236] Iteration 8740, loss = 5.5782
I0124 13:14:19.783825 19781 solver.cpp:252]     Train net output #0: loss = 5.5782 (* 1 = 5.5782 loss)
I0124 13:14:19.783838 19781 sgd_solver.cpp:106] Iteration 8740, lr = 1
I0124 13:14:24.731411 19781 solver.cpp:236] Iteration 8760, loss = 5.67297
I0124 13:14:24.731484 19781 solver.cpp:252]     Train net output #0: loss = 5.67297 (* 1 = 5.67297 loss)
I0124 13:14:24.731495 19781 sgd_solver.cpp:106] Iteration 8760, lr = 1
I0124 13:14:30.323331 19781 solver.cpp:236] Iteration 8780, loss = 5.94715
I0124 13:14:30.323504 19781 solver.cpp:252]     Train net output #0: loss = 5.94715 (* 1 = 5.94715 loss)
I0124 13:14:30.323518 19781 sgd_solver.cpp:106] Iteration 8780, lr = 1
I0124 13:14:35.593122 19781 solver.cpp:236] Iteration 8800, loss = 5.78823
I0124 13:14:35.593195 19781 solver.cpp:252]     Train net output #0: loss = 5.78823 (* 1 = 5.78823 loss)
I0124 13:14:35.593204 19781 sgd_solver.cpp:106] Iteration 8800, lr = 1
I0124 13:14:40.344045 19781 solver.cpp:236] Iteration 8820, loss = 5.74199
I0124 13:14:40.344105 19781 solver.cpp:252]     Train net output #0: loss = 5.74199 (* 1 = 5.74199 loss)
I0124 13:14:40.344115 19781 sgd_solver.cpp:106] Iteration 8820, lr = 1
I0124 13:14:45.147951 19781 solver.cpp:236] Iteration 8840, loss = 5.5261
I0124 13:14:45.148013 19781 solver.cpp:252]     Train net output #0: loss = 5.5261 (* 1 = 5.5261 loss)
I0124 13:14:45.148025 19781 sgd_solver.cpp:106] Iteration 8840, lr = 1
I0124 13:14:49.958158 19781 solver.cpp:236] Iteration 8860, loss = 5.82658
I0124 13:14:49.958212 19781 solver.cpp:252]     Train net output #0: loss = 5.82658 (* 1 = 5.82658 loss)
I0124 13:14:49.958223 19781 sgd_solver.cpp:106] Iteration 8860, lr = 1
I0124 13:14:54.817246 19781 solver.cpp:236] Iteration 8880, loss = 5.84476
I0124 13:14:54.817315 19781 solver.cpp:252]     Train net output #0: loss = 5.84476 (* 1 = 5.84476 loss)
I0124 13:14:54.817327 19781 sgd_solver.cpp:106] Iteration 8880, lr = 1
I0124 13:14:59.831717 19781 solver.cpp:236] Iteration 8900, loss = 5.88745
I0124 13:14:59.831796 19781 solver.cpp:252]     Train net output #0: loss = 5.88745 (* 1 = 5.88745 loss)
I0124 13:14:59.831807 19781 sgd_solver.cpp:106] Iteration 8900, lr = 1
I0124 13:15:04.931184 19781 solver.cpp:236] Iteration 8920, loss = 5.73275
I0124 13:15:04.931463 19781 solver.cpp:252]     Train net output #0: loss = 5.73275 (* 1 = 5.73275 loss)
I0124 13:15:04.931498 19781 sgd_solver.cpp:106] Iteration 8920, lr = 1
I0124 13:15:10.224134 19781 solver.cpp:236] Iteration 8940, loss = 5.76478
I0124 13:15:10.224206 19781 solver.cpp:252]     Train net output #0: loss = 5.76478 (* 1 = 5.76478 loss)
I0124 13:15:10.224215 19781 sgd_solver.cpp:106] Iteration 8940, lr = 1
I0124 13:15:15.399276 19781 solver.cpp:236] Iteration 8960, loss = 5.63088
I0124 13:15:15.399322 19781 solver.cpp:252]     Train net output #0: loss = 5.63088 (* 1 = 5.63088 loss)
I0124 13:15:15.399330 19781 sgd_solver.cpp:106] Iteration 8960, lr = 1
I0124 13:15:20.416335 19781 solver.cpp:236] Iteration 8980, loss = 5.59011
I0124 13:15:20.416378 19781 solver.cpp:252]     Train net output #0: loss = 5.59011 (* 1 = 5.59011 loss)
I0124 13:15:20.416385 19781 sgd_solver.cpp:106] Iteration 8980, lr = 1
I0124 13:15:24.888101 19781 solver.cpp:340] Iteration 9000, Testing net (#0)
I0124 13:15:30.644213 19781 blocking_queue.cpp:50] Data layer prefetch queue empty
I0124 13:17:03.584939 19781 solver.cpp:408]     Test net output #0: accuracy = 0.0563204
I0124 13:17:03.585181 19781 solver.cpp:408]     Test net output #1: loss = 5.42161 (* 1 = 5.42161 loss)
I0124 13:17:03.623002 19781 solver.cpp:236] Iteration 9000, loss = 5.6855
I0124 13:17:03.623031 19781 solver.cpp:252]     Train net output #0: loss = 5.6855 (* 1 = 5.6855 loss)
I0124 13:17:03.623039 19781 sgd_solver.cpp:106] Iteration 9000, lr = 1
I0124 13:17:07.879565 19781 solver.cpp:236] Iteration 9020, loss = 5.8158
I0124 13:17:07.879611 19781 solver.cpp:252]     Train net output #0: loss = 5.8158 (* 1 = 5.8158 loss)
I0124 13:17:07.879623 19781 sgd_solver.cpp:106] Iteration 9020, lr = 1
I0124 13:17:12.427158 19781 solver.cpp:236] Iteration 9040, loss = 5.83908
I0124 13:17:12.427198 19781 solver.cpp:252]     Train net output #0: loss = 5.83908 (* 1 = 5.83908 loss)
I0124 13:17:12.427206 19781 sgd_solver.cpp:106] Iteration 9040, lr = 1
I0124 13:17:17.030567 19781 solver.cpp:236] Iteration 9060, loss = 5.66958
I0124 13:17:17.030618 19781 solver.cpp:252]     Train net output #0: loss = 5.66958 (* 1 = 5.66958 loss)
I0124 13:17:17.030632 19781 sgd_solver.cpp:106] Iteration 9060, lr = 1
I0124 13:17:17.499379 19781 blocking_queue.cpp:50] Data layer prefetch queue empty
I0124 13:17:21.704602 19781 solver.cpp:236] Iteration 9080, loss = 5.83089
I0124 13:17:21.704661 19781 solver.cpp:252]     Train net output #0: loss = 5.83089 (* 1 = 5.83089 loss)
I0124 13:17:21.704670 19781 sgd_solver.cpp:106] Iteration 9080, lr = 1
I0124 13:17:26.886066 19781 solver.cpp:236] Iteration 9100, loss = 5.63094
I0124 13:17:26.886126 19781 solver.cpp:252]     Train net output #0: loss = 5.63094 (* 1 = 5.63094 loss)
I0124 13:17:26.886138 19781 sgd_solver.cpp:106] Iteration 9100, lr = 1
I0124 13:17:33.323791 19781 solver.cpp:236] Iteration 9120, loss = 5.82561
I0124 13:17:33.323859 19781 solver.cpp:252]     Train net output #0: loss = 5.82561 (* 1 = 5.82561 loss)
I0124 13:17:33.323871 19781 sgd_solver.cpp:106] Iteration 9120, lr = 1
I0124 13:17:40.796455 19781 solver.cpp:236] Iteration 9140, loss = 5.79489
I0124 13:17:40.796687 19781 solver.cpp:252]     Train net output #0: loss = 5.79489 (* 1 = 5.79489 loss)
I0124 13:17:40.796700 19781 sgd_solver.cpp:106] Iteration 9140, lr = 1
I0124 13:17:48.479799 19781 solver.cpp:236] Iteration 9160, loss = 5.86472
I0124 13:17:48.479841 19781 solver.cpp:252]     Train net output #0: loss = 5.86472 (* 1 = 5.86472 loss)
I0124 13:17:48.479848 19781 sgd_solver.cpp:106] Iteration 9160, lr = 1
I0124 13:17:56.644081 19781 solver.cpp:236] Iteration 9180, loss = 5.72744
I0124 13:17:56.644130 19781 solver.cpp:252]     Train net output #0: loss = 5.72744 (* 1 = 5.72744 loss)
I0124 13:17:56.644140 19781 sgd_solver.cpp:106] Iteration 9180, lr = 1
I0124 13:18:04.733225 19781 solver.cpp:236] Iteration 9200, loss = 5.84663
I0124 13:18:04.733284 19781 solver.cpp:252]     Train net output #0: loss = 5.84663 (* 1 = 5.84663 loss)
I0124 13:18:04.733294 19781 sgd_solver.cpp:106] Iteration 9200, lr = 1
I0124 13:18:11.620296 19781 solver.cpp:236] Iteration 9220, loss = 5.60752
I0124 13:18:11.620518 19781 solver.cpp:252]     Train net output #0: loss = 5.60752 (* 1 = 5.60752 loss)
I0124 13:18:11.620532 19781 sgd_solver.cpp:106] Iteration 9220, lr = 1
I0124 13:18:16.854256 19781 solver.cpp:236] Iteration 9240, loss = 6.20626
I0124 13:18:16.854303 19781 solver.cpp:252]     Train net output #0: loss = 6.20626 (* 1 = 6.20626 loss)
I0124 13:18:16.854315 19781 sgd_solver.cpp:106] Iteration 9240, lr = 1
I0124 13:18:21.696192 19781 solver.cpp:236] Iteration 9260, loss = 5.65085
I0124 13:18:21.696245 19781 solver.cpp:252]     Train net output #0: loss = 5.65085 (* 1 = 5.65085 loss)
I0124 13:18:21.696255 19781 sgd_solver.cpp:106] Iteration 9260, lr = 1
I0124 13:18:26.330505 19781 solver.cpp:236] Iteration 9280, loss = 5.72813
I0124 13:18:26.330559 19781 solver.cpp:252]     Train net output #0: loss = 5.72813 (* 1 = 5.72813 loss)
I0124 13:18:26.330569 19781 sgd_solver.cpp:106] Iteration 9280, lr = 1
I0124 13:18:30.908888 19781 solver.cpp:236] Iteration 9300, loss = 5.66822
I0124 13:18:30.908942 19781 solver.cpp:252]     Train net output #0: loss = 5.66822 (* 1 = 5.66822 loss)
I0124 13:18:30.908953 19781 sgd_solver.cpp:106] Iteration 9300, lr = 1
I0124 13:18:35.563992 19781 solver.cpp:236] Iteration 9320, loss = 5.87314
I0124 13:18:35.564034 19781 solver.cpp:252]     Train net output #0: loss = 5.87314 (* 1 = 5.87314 loss)
I0124 13:18:35.564041 19781 sgd_solver.cpp:106] Iteration 9320, lr = 1
I0124 13:18:40.187834 19781 solver.cpp:236] Iteration 9340, loss = 5.79242
I0124 13:18:40.187887 19781 solver.cpp:252]     Train net output #0: loss = 5.79242 (* 1 = 5.79242 loss)
I0124 13:18:40.187898 19781 sgd_solver.cpp:106] Iteration 9340, lr = 1
I0124 13:18:44.847141 19781 solver.cpp:236] Iteration 9360, loss = 5.46014
I0124 13:18:44.847316 19781 solver.cpp:252]     Train net output #0: loss = 5.46014 (* 1 = 5.46014 loss)
I0124 13:18:44.847331 19781 sgd_solver.cpp:106] Iteration 9360, lr = 1
I0124 13:18:49.670608 19781 solver.cpp:236] Iteration 9380, loss = 5.78442
I0124 13:18:49.670670 19781 solver.cpp:252]     Train net output #0: loss = 5.78442 (* 1 = 5.78442 loss)
I0124 13:18:49.670680 19781 sgd_solver.cpp:106] Iteration 9380, lr = 1
I0124 13:18:54.553406 19781 solver.cpp:236] Iteration 9400, loss = 5.48732
I0124 13:18:54.553463 19781 solver.cpp:252]     Train net output #0: loss = 5.48732 (* 1 = 5.48732 loss)
I0124 13:18:54.553473 19781 sgd_solver.cpp:106] Iteration 9400, lr = 1
I0124 13:18:59.512631 19781 solver.cpp:236] Iteration 9420, loss = 5.61241
I0124 13:18:59.512666 19781 solver.cpp:252]     Train net output #0: loss = 5.61241 (* 1 = 5.61241 loss)
I0124 13:18:59.512672 19781 sgd_solver.cpp:106] Iteration 9420, lr = 1
I0124 13:19:05.630187 19781 solver.cpp:236] Iteration 9440, loss = 5.65572
I0124 13:19:05.630241 19781 solver.cpp:252]     Train net output #0: loss = 5.65572 (* 1 = 5.65572 loss)
I0124 13:19:05.630256 19781 sgd_solver.cpp:106] Iteration 9440, lr = 1
I0124 13:19:10.555958 19781 solver.cpp:236] Iteration 9460, loss = 5.71137
I0124 13:19:10.556010 19781 solver.cpp:252]     Train net output #0: loss = 5.71137 (* 1 = 5.71137 loss)
I0124 13:19:10.556023 19781 sgd_solver.cpp:106] Iteration 9460, lr = 1
I0124 13:19:15.574601 19781 solver.cpp:236] Iteration 9480, loss = 5.65301
I0124 13:19:15.574762 19781 solver.cpp:252]     Train net output #0: loss = 5.65301 (* 1 = 5.65301 loss)
I0124 13:19:15.574774 19781 sgd_solver.cpp:106] Iteration 9480, lr = 1
I0124 13:19:20.532764 19781 solver.cpp:236] Iteration 9500, loss = 5.66982
I0124 13:19:20.532809 19781 solver.cpp:252]     Train net output #0: loss = 5.66982 (* 1 = 5.66982 loss)
I0124 13:19:20.532815 19781 sgd_solver.cpp:106] Iteration 9500, lr = 1
I0124 13:19:25.476027 19781 solver.cpp:236] Iteration 9520, loss = 5.91599
I0124 13:19:25.476080 19781 solver.cpp:252]     Train net output #0: loss = 5.91599 (* 1 = 5.91599 loss)
I0124 13:19:25.476104 19781 sgd_solver.cpp:106] Iteration 9520, lr = 1
I0124 13:19:30.410334 19781 solver.cpp:236] Iteration 9540, loss = 5.61996
I0124 13:19:30.410374 19781 solver.cpp:252]     Train net output #0: loss = 5.61996 (* 1 = 5.61996 loss)
I0124 13:19:30.410380 19781 sgd_solver.cpp:106] Iteration 9540, lr = 1
I0124 13:19:35.492580 19781 solver.cpp:236] Iteration 9560, loss = 5.6406
I0124 13:19:35.492624 19781 solver.cpp:252]     Train net output #0: loss = 5.6406 (* 1 = 5.6406 loss)
I0124 13:19:35.492631 19781 sgd_solver.cpp:106] Iteration 9560, lr = 1
I0124 13:19:40.573371 19781 solver.cpp:236] Iteration 9580, loss = 5.71067
I0124 13:19:40.573421 19781 solver.cpp:252]     Train net output #0: loss = 5.71067 (* 1 = 5.71067 loss)
I0124 13:19:40.573431 19781 sgd_solver.cpp:106] Iteration 9580, lr = 1
I0124 13:19:46.361625 19781 solver.cpp:236] Iteration 9600, loss = 5.6263
I0124 13:19:46.361927 19781 solver.cpp:252]     Train net output #0: loss = 5.6263 (* 1 = 5.6263 loss)
I0124 13:19:46.361949 19781 sgd_solver.cpp:106] Iteration 9600, lr = 1
I0124 13:19:51.415951 19781 solver.cpp:236] Iteration 9620, loss = 5.72288
I0124 13:19:51.416024 19781 solver.cpp:252]     Train net output #0: loss = 5.72288 (* 1 = 5.72288 loss)
I0124 13:19:51.416033 19781 sgd_solver.cpp:106] Iteration 9620, lr = 1
I0124 13:19:56.083183 19781 solver.cpp:236] Iteration 9640, loss = 5.74665
I0124 13:19:56.083243 19781 solver.cpp:252]     Train net output #0: loss = 5.74665 (* 1 = 5.74665 loss)
I0124 13:19:56.083256 19781 sgd_solver.cpp:106] Iteration 9640, lr = 1
I0124 13:20:00.755261 19781 solver.cpp:236] Iteration 9660, loss = 5.76895
I0124 13:20:00.755327 19781 solver.cpp:252]     Train net output #0: loss = 5.76895 (* 1 = 5.76895 loss)
I0124 13:20:00.755341 19781 sgd_solver.cpp:106] Iteration 9660, lr = 1
I0124 13:20:05.453312 19781 solver.cpp:236] Iteration 9680, loss = 5.83847
I0124 13:20:05.453377 19781 solver.cpp:252]     Train net output #0: loss = 5.83847 (* 1 = 5.83847 loss)
I0124 13:20:05.453387 19781 sgd_solver.cpp:106] Iteration 9680, lr = 1
I0124 13:20:10.202963 19781 solver.cpp:236] Iteration 9700, loss = 5.72335
I0124 13:20:10.203027 19781 solver.cpp:252]     Train net output #0: loss = 5.72335 (* 1 = 5.72335 loss)
I0124 13:20:10.203039 19781 sgd_solver.cpp:106] Iteration 9700, lr = 1
I0124 13:20:14.941403 19781 solver.cpp:236] Iteration 9720, loss = 5.61598
I0124 13:20:14.941462 19781 solver.cpp:252]     Train net output #0: loss = 5.61598 (* 1 = 5.61598 loss)
I0124 13:20:14.941473 19781 sgd_solver.cpp:106] Iteration 9720, lr = 1
I0124 13:20:19.719477 19781 solver.cpp:236] Iteration 9740, loss = 6.06813
I0124 13:20:19.719739 19781 solver.cpp:252]     Train net output #0: loss = 6.06813 (* 1 = 6.06813 loss)
I0124 13:20:19.719759 19781 sgd_solver.cpp:106] Iteration 9740, lr = 1
I0124 13:20:24.420614 19781 solver.cpp:236] Iteration 9760, loss = 5.74569
I0124 13:20:24.420703 19781 solver.cpp:252]     Train net output #0: loss = 5.74569 (* 1 = 5.74569 loss)
I0124 13:20:24.420729 19781 sgd_solver.cpp:106] Iteration 9760, lr = 1
I0124 13:20:29.361240 19781 solver.cpp:236] Iteration 9780, loss = 5.76233
I0124 13:20:29.361304 19781 solver.cpp:252]     Train net output #0: loss = 5.76233 (* 1 = 5.76233 loss)
I0124 13:20:29.361316 19781 sgd_solver.cpp:106] Iteration 9780, lr = 1
I0124 13:20:34.270623 19781 solver.cpp:236] Iteration 9800, loss = 5.95441
I0124 13:20:34.270676 19781 solver.cpp:252]     Train net output #0: loss = 5.95441 (* 1 = 5.95441 loss)
I0124 13:20:34.270684 19781 sgd_solver.cpp:106] Iteration 9800, lr = 1
I0124 13:20:39.447345 19781 solver.cpp:236] Iteration 9820, loss = 5.85968
I0124 13:20:39.447407 19781 solver.cpp:252]     Train net output #0: loss = 5.85968 (* 1 = 5.85968 loss)
I0124 13:20:39.447417 19781 sgd_solver.cpp:106] Iteration 9820, lr = 1
I0124 13:20:44.535199 19781 solver.cpp:236] Iteration 9840, loss = 5.59794
I0124 13:20:44.535284 19781 solver.cpp:252]     Train net output #0: loss = 5.59794 (* 1 = 5.59794 loss)
I0124 13:20:44.535293 19781 sgd_solver.cpp:106] Iteration 9840, lr = 1
I0124 13:20:49.703680 19781 solver.cpp:236] Iteration 9860, loss = 5.9007
I0124 13:20:49.703742 19781 solver.cpp:252]     Train net output #0: loss = 5.9007 (* 1 = 5.9007 loss)
I0124 13:20:49.703761 19781 sgd_solver.cpp:106] Iteration 9860, lr = 1
I0124 13:20:54.939628 19781 solver.cpp:236] Iteration 9880, loss = 5.41128
I0124 13:20:54.939931 19781 solver.cpp:252]     Train net output #0: loss = 5.41128 (* 1 = 5.41128 loss)
I0124 13:20:54.939952 19781 sgd_solver.cpp:106] Iteration 9880, lr = 1
I0124 13:21:00.166102 19781 solver.cpp:236] Iteration 9900, loss = 5.67723
I0124 13:21:00.166154 19781 solver.cpp:252]     Train net output #0: loss = 5.67723 (* 1 = 5.67723 loss)
I0124 13:21:00.166164 19781 sgd_solver.cpp:106] Iteration 9900, lr = 1
I0124 13:21:05.349030 19781 solver.cpp:236] Iteration 9920, loss = 5.83133
I0124 13:21:05.349079 19781 solver.cpp:252]     Train net output #0: loss = 5.83133 (* 1 = 5.83133 loss)
I0124 13:21:05.349088 19781 sgd_solver.cpp:106] Iteration 9920, lr = 1
I0124 13:21:10.544836 19781 solver.cpp:236] Iteration 9940, loss = 5.9077
I0124 13:21:10.544874 19781 solver.cpp:252]     Train net output #0: loss = 5.9077 (* 1 = 5.9077 loss)
I0124 13:21:10.544880 19781 sgd_solver.cpp:106] Iteration 9940, lr = 1
I0124 13:21:15.854878 19781 solver.cpp:236] Iteration 9960, loss = 5.66722
I0124 13:21:15.854944 19781 solver.cpp:252]     Train net output #0: loss = 5.66722 (* 1 = 5.66722 loss)
I0124 13:21:15.854955 19781 sgd_solver.cpp:106] Iteration 9960, lr = 1
I0124 13:21:21.188391 19781 solver.cpp:236] Iteration 9980, loss = 5.75613
I0124 13:21:21.188458 19781 solver.cpp:252]     Train net output #0: loss = 5.75613 (* 1 = 5.75613 loss)
I0124 13:21:21.188469 19781 sgd_solver.cpp:106] Iteration 9980, lr = 1
I0124 13:21:26.035145 19781 solver.cpp:461] Snapshotting to binary proto file snapshots/caffenet128_lsuv_adadelta1e-7_iter_10000.caffemodel
I0124 13:21:27.560834 19781 sgd_solver.cpp:269] Snapshotting solver state to binary proto file snapshots/caffenet128_lsuv_adadelta1e-7_iter_10000.solverstate
I0124 13:21:30.209652 19781 solver.cpp:340] Iteration 10000, Testing net (#0)
I0124 13:21:36.612853 19781 blocking_queue.cpp:50] Data layer prefetch queue empty
I0124 13:23:06.795397 19781 solver.cpp:408]     Test net output #0: accuracy = 0.0609204
I0124 13:23:06.795601 19781 solver.cpp:408]     Test net output #1: loss = 5.41858 (* 1 = 5.41858 loss)
I0124 13:23:06.833289 19781 solver.cpp:236] Iteration 10000, loss = 5.68739
I0124 13:23:06.833326 19781 solver.cpp:252]     Train net output #0: loss = 5.68739 (* 1 = 5.68739 loss)
I0124 13:23:06.833361 19781 sgd_solver.cpp:106] Iteration 10000, lr = 1
I0124 13:23:11.354969 19781 solver.cpp:236] Iteration 10020, loss = 5.39574
I0124 13:23:11.355017 19781 solver.cpp:252]     Train net output #0: loss = 5.39574 (* 1 = 5.39574 loss)
I0124 13:23:11.355031 19781 sgd_solver.cpp:106] Iteration 10020, lr = 1
I0124 13:23:16.138566 19781 solver.cpp:236] Iteration 10040, loss = 5.65931
I0124 13:23:16.138618 19781 solver.cpp:252]     Train net output #0: loss = 5.65931 (* 1 = 5.65931 loss)
I0124 13:23:16.138633 19781 sgd_solver.cpp:106] Iteration 10040, lr = 1
I0124 13:23:20.994534 19781 solver.cpp:236] Iteration 10060, loss = 5.88061
I0124 13:23:20.994592 19781 solver.cpp:252]     Train net output #0: loss = 5.88061 (* 1 = 5.88061 loss)
I0124 13:23:20.994606 19781 sgd_solver.cpp:106] Iteration 10060, lr = 1
I0124 13:23:22.894577 19781 blocking_queue.cpp:50] Data layer prefetch queue empty
I0124 13:23:25.752730 19781 solver.cpp:236] Iteration 10080, loss = 5.86561
I0124 13:23:25.752768 19781 solver.cpp:252]     Train net output #0: loss = 5.86561 (* 1 = 5.86561 loss)
I0124 13:23:25.752775 19781 sgd_solver.cpp:106] Iteration 10080, lr = 1
I0124 13:23:30.529217 19781 solver.cpp:236] Iteration 10100, loss = 5.76264
I0124 13:23:30.529263 19781 solver.cpp:252]     Train net output #0: loss = 5.76264 (* 1 = 5.76264 loss)
I0124 13:23:30.529273 19781 sgd_solver.cpp:106] Iteration 10100, lr = 1
I0124 13:23:35.487109 19781 solver.cpp:236] Iteration 10120, loss = 5.79086
I0124 13:23:35.487165 19781 solver.cpp:252]     Train net output #0: loss = 5.79086 (* 1 = 5.79086 loss)
I0124 13:23:35.487175 19781 sgd_solver.cpp:106] Iteration 10120, lr = 1
I0124 13:23:41.138739 19781 solver.cpp:236] Iteration 10140, loss = 5.9144
I0124 13:23:41.138960 19781 solver.cpp:252]     Train net output #0: loss = 5.9144 (* 1 = 5.9144 loss)
I0124 13:23:41.138979 19781 sgd_solver.cpp:106] Iteration 10140, lr = 1
I0124 13:23:46.372287 19781 solver.cpp:236] Iteration 10160, loss = 5.85908
I0124 13:23:46.372341 19781 solver.cpp:252]     Train net output #0: loss = 5.85908 (* 1 = 5.85908 loss)
I0124 13:23:46.372351 19781 sgd_solver.cpp:106] Iteration 10160, lr = 1
I0124 13:23:51.364688 19781 solver.cpp:236] Iteration 10180, loss = 5.66847
I0124 13:23:51.364743 19781 solver.cpp:252]     Train net output #0: loss = 5.66847 (* 1 = 5.66847 loss)
I0124 13:23:51.364753 19781 sgd_solver.cpp:106] Iteration 10180, lr = 1
I0124 13:23:56.387313 19781 solver.cpp:236] Iteration 10200, loss = 5.4526
I0124 13:23:56.387387 19781 solver.cpp:252]     Train net output #0: loss = 5.4526 (* 1 = 5.4526 loss)
I0124 13:23:56.387398 19781 sgd_solver.cpp:106] Iteration 10200, lr = 1
I0124 13:24:01.471187 19781 solver.cpp:236] Iteration 10220, loss = 5.87217
I0124 13:24:01.471252 19781 solver.cpp:252]     Train net output #0: loss = 5.87217 (* 1 = 5.87217 loss)
I0124 13:24:01.471264 19781 sgd_solver.cpp:106] Iteration 10220, lr = 1
I0124 13:24:06.616143 19781 solver.cpp:236] Iteration 10240, loss = 5.79527
I0124 13:24:06.616228 19781 solver.cpp:252]     Train net output #0: loss = 5.79527 (* 1 = 5.79527 loss)
I0124 13:24:06.616237 19781 sgd_solver.cpp:106] Iteration 10240, lr = 1
I0124 13:24:11.800284 19781 solver.cpp:236] Iteration 10260, loss = 5.84581
I0124 13:24:11.800444 19781 solver.cpp:252]     Train net output #0: loss = 5.84581 (* 1 = 5.84581 loss)
I0124 13:24:11.800457 19781 sgd_solver.cpp:106] Iteration 10260, lr = 1
I0124 13:24:16.939836 19781 solver.cpp:236] Iteration 10280, loss = 5.68947
I0124 13:24:16.939895 19781 solver.cpp:252]     Train net output #0: loss = 5.68947 (* 1 = 5.68947 loss)
I0124 13:24:16.939908 19781 sgd_solver.cpp:106] Iteration 10280, lr = 1
I0124 13:24:23.144736 19781 solver.cpp:236] Iteration 10300, loss = 5.80703
I0124 13:24:23.144796 19781 solver.cpp:252]     Train net output #0: loss = 5.80703 (* 1 = 5.80703 loss)
I0124 13:24:23.144804 19781 sgd_solver.cpp:106] Iteration 10300, lr = 1
I0124 13:24:28.084434 19781 solver.cpp:236] Iteration 10320, loss = 5.3795
I0124 13:24:28.084497 19781 solver.cpp:252]     Train net output #0: loss = 5.3795 (* 1 = 5.3795 loss)
I0124 13:24:28.084516 19781 sgd_solver.cpp:106] Iteration 10320, lr = 1
I0124 13:24:33.018815 19781 solver.cpp:236] Iteration 10340, loss = 5.90302
I0124 13:24:33.018890 19781 solver.cpp:252]     Train net output #0: loss = 5.90302 (* 1 = 5.90302 loss)
I0124 13:24:33.018903 19781 sgd_solver.cpp:106] Iteration 10340, lr = 1
I0124 13:24:38.020639 19781 solver.cpp:236] Iteration 10360, loss = 5.55296
I0124 13:24:38.020710 19781 solver.cpp:252]     Train net output #0: loss = 5.55296 (* 1 = 5.55296 loss)
I0124 13:24:38.020722 19781 sgd_solver.cpp:106] Iteration 10360, lr = 1
I0124 13:24:43.006098 19781 solver.cpp:236] Iteration 10380, loss = 5.46776
I0124 13:24:43.006356 19781 solver.cpp:252]     Train net output #0: loss = 5.46776 (* 1 = 5.46776 loss)
I0124 13:24:43.006373 19781 sgd_solver.cpp:106] Iteration 10380, lr = 1
I0124 13:24:47.912240 19781 solver.cpp:236] Iteration 10400, loss = 5.66667
I0124 13:24:47.912295 19781 solver.cpp:252]     Train net output #0: loss = 5.66667 (* 1 = 5.66667 loss)
I0124 13:24:47.912307 19781 sgd_solver.cpp:106] Iteration 10400, lr = 1
I0124 13:24:52.838496 19781 solver.cpp:236] Iteration 10420, loss = 5.47706
I0124 13:24:52.838544 19781 solver.cpp:252]     Train net output #0: loss = 5.47706 (* 1 = 5.47706 loss)
I0124 13:24:52.838556 19781 sgd_solver.cpp:106] Iteration 10420, lr = 1
I0124 13:24:57.795889 19781 solver.cpp:236] Iteration 10440, loss = 5.90078
I0124 13:24:57.795930 19781 solver.cpp:252]     Train net output #0: loss = 5.90078 (* 1 = 5.90078 loss)
I0124 13:24:57.795938 19781 sgd_solver.cpp:106] Iteration 10440, lr = 1
I0124 13:25:03.180155 19781 solver.cpp:236] Iteration 10460, loss = 5.83157
I0124 13:25:03.180202 19781 solver.cpp:252]     Train net output #0: loss = 5.83157 (* 1 = 5.83157 loss)
I0124 13:25:03.180210 19781 sgd_solver.cpp:106] Iteration 10460, lr = 1
I0124 13:25:08.265761 19781 solver.cpp:236] Iteration 10480, loss = 5.59187
I0124 13:25:08.265817 19781 solver.cpp:252]     Train net output #0: loss = 5.59187 (* 1 = 5.59187 loss)
I0124 13:25:08.265828 19781 sgd_solver.cpp:106] Iteration 10480, lr = 1
I0124 13:25:13.783916 19781 solver.cpp:236] Iteration 10500, loss = 5.85858
I0124 13:25:13.784126 19781 solver.cpp:252]     Train net output #0: loss = 5.85858 (* 1 = 5.85858 loss)
I0124 13:25:13.784137 19781 sgd_solver.cpp:106] Iteration 10500, lr = 1
I0124 13:25:18.634254 19781 solver.cpp:236] Iteration 10520, loss = 5.51629
I0124 13:25:18.634310 19781 solver.cpp:252]     Train net output #0: loss = 5.51629 (* 1 = 5.51629 loss)
I0124 13:25:18.634320 19781 sgd_solver.cpp:106] Iteration 10520, lr = 1
I0124 13:25:23.381888 19781 solver.cpp:236] Iteration 10540, loss = 5.48499
I0124 13:25:23.381942 19781 solver.cpp:252]     Train net output #0: loss = 5.48499 (* 1 = 5.48499 loss)
I0124 13:25:23.381950 19781 sgd_solver.cpp:106] Iteration 10540, lr = 1
I0124 13:25:28.132948 19781 solver.cpp:236] Iteration 10560, loss = 5.43767
I0124 13:25:28.133002 19781 solver.cpp:252]     Train net output #0: loss = 5.43767 (* 1 = 5.43767 loss)
I0124 13:25:28.133013 19781 sgd_solver.cpp:106] Iteration 10560, lr = 1
I0124 13:25:32.859279 19781 solver.cpp:236] Iteration 10580, loss = 5.64127
I0124 13:25:32.859333 19781 solver.cpp:252]     Train net output #0: loss = 5.64127 (* 1 = 5.64127 loss)
I0124 13:25:32.859343 19781 sgd_solver.cpp:106] Iteration 10580, lr = 1
I0124 13:25:37.557874 19781 solver.cpp:236] Iteration 10600, loss = 5.46847
I0124 13:25:37.557925 19781 solver.cpp:252]     Train net output #0: loss = 5.46847 (* 1 = 5.46847 loss)
I0124 13:25:37.557934 19781 sgd_solver.cpp:106] Iteration 10600, lr = 1
I0124 13:25:42.451210 19781 solver.cpp:236] Iteration 10620, loss = 5.67896
I0124 13:25:42.451266 19781 solver.cpp:252]     Train net output #0: loss = 5.67896 (* 1 = 5.67896 loss)
I0124 13:25:42.451279 19781 sgd_solver.cpp:106] Iteration 10620, lr = 1
I0124 13:25:47.316999 19781 solver.cpp:236] Iteration 10640, loss = 5.47033
I0124 13:25:47.317148 19781 solver.cpp:252]     Train net output #0: loss = 5.47033 (* 1 = 5.47033 loss)
I0124 13:25:47.317157 19781 sgd_solver.cpp:106] Iteration 10640, lr = 1
I0124 13:25:52.904839 19781 solver.cpp:236] Iteration 10660, loss = 5.79934
I0124 13:25:52.904894 19781 solver.cpp:252]     Train net output #0: loss = 5.79934 (* 1 = 5.79934 loss)
I0124 13:25:52.904908 19781 sgd_solver.cpp:106] Iteration 10660, lr = 1
I0124 13:25:58.361135 19781 solver.cpp:236] Iteration 10680, loss = 5.77607
I0124 13:25:58.361174 19781 solver.cpp:252]     Train net output #0: loss = 5.77607 (* 1 = 5.77607 loss)
I0124 13:25:58.361186 19781 sgd_solver.cpp:106] Iteration 10680, lr = 1
I0124 13:26:03.411351 19781 solver.cpp:236] Iteration 10700, loss = 5.90068
I0124 13:26:03.411422 19781 solver.cpp:252]     Train net output #0: loss = 5.90068 (* 1 = 5.90068 loss)
I0124 13:26:03.411432 19781 sgd_solver.cpp:106] Iteration 10700, lr = 1
I0124 13:26:08.455893 19781 solver.cpp:236] Iteration 10720, loss = 5.62103
I0124 13:26:08.455960 19781 solver.cpp:252]     Train net output #0: loss = 5.62103 (* 1 = 5.62103 loss)
I0124 13:26:08.455971 19781 sgd_solver.cpp:106] Iteration 10720, lr = 1
I0124 13:26:14.567456 19781 solver.cpp:236] Iteration 10740, loss = 5.5902
I0124 13:26:14.567517 19781 solver.cpp:252]     Train net output #0: loss = 5.5902 (* 1 = 5.5902 loss)
I0124 13:26:14.567528 19781 sgd_solver.cpp:106] Iteration 10740, lr = 1
I0124 13:26:21.064081 19781 solver.cpp:236] Iteration 10760, loss = 5.81317
I0124 13:26:21.064334 19781 solver.cpp:252]     Train net output #0: loss = 5.81317 (* 1 = 5.81317 loss)
I0124 13:26:21.064348 19781 sgd_solver.cpp:106] Iteration 10760, lr = 1
I0124 13:26:26.460484 19781 solver.cpp:236] Iteration 10780, loss = 5.69396
I0124 13:26:26.460542 19781 solver.cpp:252]     Train net output #0: loss = 5.69396 (* 1 = 5.69396 loss)
I0124 13:26:26.460553 19781 sgd_solver.cpp:106] Iteration 10780, lr = 1
I0124 13:26:31.150568 19781 solver.cpp:236] Iteration 10800, loss = 5.85074
I0124 13:26:31.150635 19781 solver.cpp:252]     Train net output #0: loss = 5.85074 (* 1 = 5.85074 loss)
I0124 13:26:31.150646 19781 sgd_solver.cpp:106] Iteration 10800, lr = 1
I0124 13:26:36.242396 19781 solver.cpp:236] Iteration 10820, loss = 5.76956
I0124 13:26:36.242447 19781 solver.cpp:252]     Train net output #0: loss = 5.76956 (* 1 = 5.76956 loss)
I0124 13:26:36.242457 19781 sgd_solver.cpp:106] Iteration 10820, lr = 1
I0124 13:26:41.567864 19781 solver.cpp:236] Iteration 10840, loss = 5.74561
I0124 13:26:41.567914 19781 solver.cpp:252]     Train net output #0: loss = 5.74561 (* 1 = 5.74561 loss)
I0124 13:26:41.567921 19781 sgd_solver.cpp:106] Iteration 10840, lr = 1
I0124 13:26:46.671507 19781 solver.cpp:236] Iteration 10860, loss = 5.81098
I0124 13:26:46.671562 19781 solver.cpp:252]     Train net output #0: loss = 5.81098 (* 1 = 5.81098 loss)
I0124 13:26:46.671571 19781 sgd_solver.cpp:106] Iteration 10860, lr = 1
I0124 13:26:50.988312 19781 solver.cpp:236] Iteration 10880, loss = 5.59375
I0124 13:26:50.988375 19781 solver.cpp:252]     Train net output #0: loss = 5.59375 (* 1 = 5.59375 loss)
I0124 13:26:50.988387 19781 sgd_solver.cpp:106] Iteration 10880, lr = 1
I0124 13:26:55.321035 19781 solver.cpp:236] Iteration 10900, loss = 5.71711
I0124 13:26:55.321264 19781 solver.cpp:252]     Train net output #0: loss = 5.71711 (* 1 = 5.71711 loss)
I0124 13:26:55.321285 19781 sgd_solver.cpp:106] Iteration 10900, lr = 1
I0124 13:26:59.607138 19781 solver.cpp:236] Iteration 10920, loss = 5.51481
I0124 13:26:59.607180 19781 solver.cpp:252]     Train net output #0: loss = 5.51481 (* 1 = 5.51481 loss)
I0124 13:26:59.607187 19781 sgd_solver.cpp:106] Iteration 10920, lr = 1
I0124 13:27:04.066740 19781 solver.cpp:236] Iteration 10940, loss = 5.729
I0124 13:27:04.066790 19781 solver.cpp:252]     Train net output #0: loss = 5.729 (* 1 = 5.729 loss)
I0124 13:27:04.066800 19781 sgd_solver.cpp:106] Iteration 10940, lr = 1
I0124 13:27:08.810447 19781 solver.cpp:236] Iteration 10960, loss = 5.96428
I0124 13:27:08.810504 19781 solver.cpp:252]     Train net output #0: loss = 5.96428 (* 1 = 5.96428 loss)
I0124 13:27:08.810514 19781 sgd_solver.cpp:106] Iteration 10960, lr = 1
I0124 13:27:13.690933 19781 solver.cpp:236] Iteration 10980, loss = 6.04021
I0124 13:27:13.690994 19781 solver.cpp:252]     Train net output #0: loss = 6.04021 (* 1 = 6.04021 loss)
I0124 13:27:13.691004 19781 sgd_solver.cpp:106] Iteration 10980, lr = 1
I0124 13:27:18.231186 19781 solver.cpp:340] Iteration 11000, Testing net (#0)
I0124 13:27:25.650583 19781 blocking_queue.cpp:50] Data layer prefetch queue empty
I0124 13:29:11.734238 19781 solver.cpp:408]     Test net output #0: accuracy = 0.0631603
I0124 13:29:11.734376 19781 solver.cpp:408]     Test net output #1: loss = 5.37271 (* 1 = 5.37271 loss)
I0124 13:29:11.771980 19781 solver.cpp:236] Iteration 11000, loss = 5.62768
I0124 13:29:11.772008 19781 solver.cpp:252]     Train net output #0: loss = 5.62768 (* 1 = 5.62768 loss)
I0124 13:29:11.772022 19781 sgd_solver.cpp:106] Iteration 11000, lr = 1
I0124 13:29:16.198714 19781 solver.cpp:236] Iteration 11020, loss = 5.73725
I0124 13:29:16.198770 19781 solver.cpp:252]     Train net output #0: loss = 5.73725 (* 1 = 5.73725 loss)
I0124 13:29:16.198781 19781 sgd_solver.cpp:106] Iteration 11020, lr = 1
I0124 13:29:20.880550 19781 solver.cpp:236] Iteration 11040, loss = 5.65054
I0124 13:29:20.880604 19781 solver.cpp:252]     Train net output #0: loss = 5.65054 (* 1 = 5.65054 loss)
I0124 13:29:20.880614 19781 sgd_solver.cpp:106] Iteration 11040, lr = 1
I0124 13:29:25.601261 19781 solver.cpp:236] Iteration 11060, loss = 5.92089
I0124 13:29:25.601305 19781 solver.cpp:252]     Train net output #0: loss = 5.92089 (* 1 = 5.92089 loss)
I0124 13:29:25.601315 19781 sgd_solver.cpp:106] Iteration 11060, lr = 1
I0124 13:29:29.194193 19781 blocking_queue.cpp:50] Data layer prefetch queue empty
I0124 13:29:30.378815 19781 solver.cpp:236] Iteration 11080, loss = 5.77979
I0124 13:29:30.378854 19781 solver.cpp:252]     Train net output #0: loss = 5.77979 (* 1 = 5.77979 loss)
I0124 13:29:30.378862 19781 sgd_solver.cpp:106] Iteration 11080, lr = 1
I0124 13:29:35.224536 19781 solver.cpp:236] Iteration 11100, loss = 5.61264
I0124 13:29:35.224584 19781 solver.cpp:252]     Train net output #0: loss = 5.61264 (* 1 = 5.61264 loss)
I0124 13:29:35.224592 19781 sgd_solver.cpp:106] Iteration 11100, lr = 1
I0124 13:29:40.546411 19781 solver.cpp:236] Iteration 11120, loss = 5.68432
I0124 13:29:40.546460 19781 solver.cpp:252]     Train net output #0: loss = 5.68432 (* 1 = 5.68432 loss)
I0124 13:29:40.546469 19781 sgd_solver.cpp:106] Iteration 11120, lr = 1
I0124 13:29:46.281620 19781 solver.cpp:236] Iteration 11140, loss = 5.93725
I0124 13:29:46.281929 19781 solver.cpp:252]     Train net output #0: loss = 5.93725 (* 1 = 5.93725 loss)
I0124 13:29:46.281951 19781 sgd_solver.cpp:106] Iteration 11140, lr = 1
I0124 13:29:51.251271 19781 solver.cpp:236] Iteration 11160, loss = 5.60011
I0124 13:29:51.251332 19781 solver.cpp:252]     Train net output #0: loss = 5.60011 (* 1 = 5.60011 loss)
I0124 13:29:51.251343 19781 sgd_solver.cpp:106] Iteration 11160, lr = 1
I0124 13:29:55.957996 19781 solver.cpp:236] Iteration 11180, loss = 5.5075
I0124 13:29:55.958056 19781 solver.cpp:252]     Train net output #0: loss = 5.5075 (* 1 = 5.5075 loss)
I0124 13:29:55.958070 19781 sgd_solver.cpp:106] Iteration 11180, lr = 1
I0124 13:30:00.652807 19781 solver.cpp:236] Iteration 11200, loss = 5.85094
I0124 13:30:00.652884 19781 solver.cpp:252]     Train net output #0: loss = 5.85094 (* 1 = 5.85094 loss)
I0124 13:30:00.652896 19781 sgd_solver.cpp:106] Iteration 11200, lr = 1
I0124 13:30:05.285866 19781 solver.cpp:236] Iteration 11220, loss = 5.69123
I0124 13:30:05.285934 19781 solver.cpp:252]     Train net output #0: loss = 5.69123 (* 1 = 5.69123 loss)
I0124 13:30:05.285945 19781 sgd_solver.cpp:106] Iteration 11220, lr = 1
I0124 13:30:09.979533 19781 solver.cpp:236] Iteration 11240, loss = 5.68247
I0124 13:30:09.979606 19781 solver.cpp:252]     Train net output #0: loss = 5.68247 (* 1 = 5.68247 loss)
I0124 13:30:09.979617 19781 sgd_solver.cpp:106] Iteration 11240, lr = 1
I0124 13:30:14.736562 19781 solver.cpp:236] Iteration 11260, loss = 5.72503
I0124 13:30:14.736611 19781 solver.cpp:252]     Train net output #0: loss = 5.72503 (* 1 = 5.72503 loss)
I0124 13:30:14.736623 19781 sgd_solver.cpp:106] Iteration 11260, lr = 1
I0124 13:30:19.513656 19781 solver.cpp:236] Iteration 11280, loss = 5.83673
I0124 13:30:19.513861 19781 solver.cpp:252]     Train net output #0: loss = 5.83673 (* 1 = 5.83673 loss)
I0124 13:30:19.513885 19781 sgd_solver.cpp:106] Iteration 11280, lr = 1
I0124 13:30:24.419097 19781 solver.cpp:236] Iteration 11300, loss = 5.6927
I0124 13:30:24.419425 19781 solver.cpp:252]     Train net output #0: loss = 5.6927 (* 1 = 5.6927 loss)
I0124 13:30:24.419440 19781 sgd_solver.cpp:106] Iteration 11300, lr = 1
I0124 13:30:29.442152 19781 solver.cpp:236] Iteration 11320, loss = 5.56471
I0124 13:30:29.442209 19781 solver.cpp:252]     Train net output #0: loss = 5.56471 (* 1 = 5.56471 loss)
I0124 13:30:29.442220 19781 sgd_solver.cpp:106] Iteration 11320, lr = 1
I0124 13:30:34.590756 19781 solver.cpp:236] Iteration 11340, loss = 5.66005
I0124 13:30:34.590824 19781 solver.cpp:252]     Train net output #0: loss = 5.66005 (* 1 = 5.66005 loss)
I0124 13:30:34.590837 19781 sgd_solver.cpp:106] Iteration 11340, lr = 1
I0124 13:30:39.717450 19781 solver.cpp:236] Iteration 11360, loss = 5.69445
I0124 13:30:39.717519 19781 solver.cpp:252]     Train net output #0: loss = 5.69445 (* 1 = 5.69445 loss)
I0124 13:30:39.717528 19781 sgd_solver.cpp:106] Iteration 11360, lr = 1
I0124 13:30:44.877975 19781 solver.cpp:236] Iteration 11380, loss = 5.77691
I0124 13:30:44.878036 19781 solver.cpp:252]     Train net output #0: loss = 5.77691 (* 1 = 5.77691 loss)
I0124 13:30:44.878046 19781 sgd_solver.cpp:106] Iteration 11380, lr = 1
I0124 13:30:50.006789 19781 solver.cpp:236] Iteration 11400, loss = 5.59985
I0124 13:30:50.006994 19781 solver.cpp:252]     Train net output #0: loss = 5.59985 (* 1 = 5.59985 loss)
I0124 13:30:50.007004 19781 sgd_solver.cpp:106] Iteration 11400, lr = 1
I0124 13:30:55.141141 19781 solver.cpp:236] Iteration 11420, loss = 5.47613
I0124 13:30:55.141201 19781 solver.cpp:252]     Train net output #0: loss = 5.47613 (* 1 = 5.47613 loss)
I0124 13:30:55.141212 19781 sgd_solver.cpp:106] Iteration 11420, lr = 1
I0124 13:31:00.224515 19781 solver.cpp:236] Iteration 11440, loss = 5.46488
I0124 13:31:00.224570 19781 solver.cpp:252]     Train net output #0: loss = 5.46488 (* 1 = 5.46488 loss)
I0124 13:31:00.224577 19781 sgd_solver.cpp:106] Iteration 11440, lr = 1
I0124 13:31:05.571295 19781 solver.cpp:236] Iteration 11460, loss = 5.4636
I0124 13:31:05.571629 19781 solver.cpp:252]     Train net output #0: loss = 5.4636 (* 1 = 5.4636 loss)
I0124 13:31:05.571650 19781 sgd_solver.cpp:106] Iteration 11460, lr = 1
I0124 13:31:11.409919 19781 solver.cpp:236] Iteration 11480, loss = 5.86696
I0124 13:31:11.409982 19781 solver.cpp:252]     Train net output #0: loss = 5.86696 (* 1 = 5.86696 loss)
I0124 13:31:11.409996 19781 sgd_solver.cpp:106] Iteration 11480, lr = 1
I0124 13:31:16.348325 19781 solver.cpp:236] Iteration 11500, loss = 5.65574
I0124 13:31:16.348393 19781 solver.cpp:252]     Train net output #0: loss = 5.65574 (* 1 = 5.65574 loss)
I0124 13:31:16.348412 19781 sgd_solver.cpp:106] Iteration 11500, lr = 1
I0124 13:31:21.284170 19781 solver.cpp:236] Iteration 11520, loss = 5.75942
I0124 13:31:21.296231 19781 solver.cpp:252]     Train net output #0: loss = 5.75942 (* 1 = 5.75942 loss)
I0124 13:31:21.296249 19781 sgd_solver.cpp:106] Iteration 11520, lr = 1
I0124 13:31:26.216439 19781 solver.cpp:236] Iteration 11540, loss = 5.79982
I0124 13:31:26.216508 19781 solver.cpp:252]     Train net output #0: loss = 5.79982 (* 1 = 5.79982 loss)
I0124 13:31:26.216521 19781 sgd_solver.cpp:106] Iteration 11540, lr = 1
I0124 13:31:31.164587 19781 solver.cpp:236] Iteration 11560, loss = 6.02814
I0124 13:31:31.164654 19781 solver.cpp:252]     Train net output #0: loss = 6.02814 (* 1 = 6.02814 loss)
I0124 13:31:31.164665 19781 sgd_solver.cpp:106] Iteration 11560, lr = 1
I0124 13:31:36.124924 19781 solver.cpp:236] Iteration 11580, loss = 5.41693
I0124 13:31:36.124989 19781 solver.cpp:252]     Train net output #0: loss = 5.41693 (* 1 = 5.41693 loss)
I0124 13:31:36.125007 19781 sgd_solver.cpp:106] Iteration 11580, lr = 1
I0124 13:31:41.102226 19781 solver.cpp:236] Iteration 11600, loss = 5.67387
I0124 13:31:41.102289 19781 solver.cpp:252]     Train net output #0: loss = 5.67387 (* 1 = 5.67387 loss)
I0124 13:31:41.102301 19781 sgd_solver.cpp:106] Iteration 11600, lr = 1
I0124 13:31:46.051496 19781 solver.cpp:236] Iteration 11620, loss = 5.808
I0124 13:31:46.051568 19781 solver.cpp:252]     Train net output #0: loss = 5.808 (* 1 = 5.808 loss)
I0124 13:31:46.051579 19781 sgd_solver.cpp:106] Iteration 11620, lr = 1
I0124 13:31:52.465337 19781 solver.cpp:236] Iteration 11640, loss = 5.71811
I0124 13:31:52.465566 19781 solver.cpp:252]     Train net output #0: loss = 5.71811 (* 1 = 5.71811 loss)
I0124 13:31:52.465602 19781 sgd_solver.cpp:106] Iteration 11640, lr = 1
I0124 13:31:56.868515 19781 solver.cpp:236] Iteration 11660, loss = 5.63017
I0124 13:31:56.868562 19781 solver.cpp:252]     Train net output #0: loss = 5.63017 (* 1 = 5.63017 loss)
I0124 13:31:56.868572 19781 sgd_solver.cpp:106] Iteration 11660, lr = 1
I0124 13:32:01.649360 19781 solver.cpp:236] Iteration 11680, loss = 5.54825
I0124 13:32:01.649405 19781 solver.cpp:252]     Train net output #0: loss = 5.54825 (* 1 = 5.54825 loss)
I0124 13:32:01.649416 19781 sgd_solver.cpp:106] Iteration 11680, lr = 1
I0124 13:32:06.542171 19781 solver.cpp:236] Iteration 11700, loss = 5.78546
I0124 13:32:06.542207 19781 solver.cpp:252]     Train net output #0: loss = 5.78546 (* 1 = 5.78546 loss)
I0124 13:32:06.542213 19781 sgd_solver.cpp:106] Iteration 11700, lr = 1
I0124 13:32:11.493701 19781 solver.cpp:236] Iteration 11720, loss = 5.90696
I0124 13:32:11.493751 19781 solver.cpp:252]     Train net output #0: loss = 5.90696 (* 1 = 5.90696 loss)
I0124 13:32:11.493760 19781 sgd_solver.cpp:106] Iteration 11720, lr = 1
I0124 13:32:16.431727 19781 solver.cpp:236] Iteration 11740, loss = 5.47289
I0124 13:32:16.431784 19781 solver.cpp:252]     Train net output #0: loss = 5.47289 (* 1 = 5.47289 loss)
I0124 13:32:16.431794 19781 sgd_solver.cpp:106] Iteration 11740, lr = 1
I0124 13:32:21.398424 19781 solver.cpp:236] Iteration 11760, loss = 5.48482
I0124 13:32:21.398488 19781 solver.cpp:252]     Train net output #0: loss = 5.48482 (* 1 = 5.48482 loss)
I0124 13:32:21.398499 19781 sgd_solver.cpp:106] Iteration 11760, lr = 1
I0124 13:32:26.342017 19781 solver.cpp:236] Iteration 11780, loss = 5.60753
I0124 13:32:26.342313 19781 solver.cpp:252]     Train net output #0: loss = 5.60753 (* 1 = 5.60753 loss)
I0124 13:32:26.342335 19781 sgd_solver.cpp:106] Iteration 11780, lr = 1
I0124 13:32:31.215991 19781 solver.cpp:236] Iteration 11800, loss = 5.41363
I0124 13:32:31.216032 19781 solver.cpp:252]     Train net output #0: loss = 5.41363 (* 1 = 5.41363 loss)
I0124 13:32:31.216042 19781 sgd_solver.cpp:106] Iteration 11800, lr = 1
I0124 13:32:36.958181 19781 solver.cpp:236] Iteration 11820, loss = 5.70986
I0124 13:32:36.958223 19781 solver.cpp:252]     Train net output #0: loss = 5.70986 (* 1 = 5.70986 loss)
I0124 13:32:36.958232 19781 sgd_solver.cpp:106] Iteration 11820, lr = 1
I0124 13:32:41.996083 19781 solver.cpp:236] Iteration 11840, loss = 5.55217
I0124 13:32:41.996124 19781 solver.cpp:252]     Train net output #0: loss = 5.55217 (* 1 = 5.55217 loss)
I0124 13:32:41.996132 19781 sgd_solver.cpp:106] Iteration 11840, lr = 1
I0124 13:32:47.076751 19781 solver.cpp:236] Iteration 11860, loss = 5.79294
I0124 13:32:47.076810 19781 solver.cpp:252]     Train net output #0: loss = 5.79294 (* 1 = 5.79294 loss)
I0124 13:32:47.076820 19781 sgd_solver.cpp:106] Iteration 11860, lr = 1
I0124 13:32:52.160240 19781 solver.cpp:236] Iteration 11880, loss = 5.61455
I0124 13:32:52.160301 19781 solver.cpp:252]     Train net output #0: loss = 5.61455 (* 1 = 5.61455 loss)
I0124 13:32:52.160311 19781 sgd_solver.cpp:106] Iteration 11880, lr = 1
I0124 13:32:57.235034 19781 solver.cpp:236] Iteration 11900, loss = 5.80728
I0124 13:32:57.235173 19781 solver.cpp:252]     Train net output #0: loss = 5.80728 (* 1 = 5.80728 loss)
I0124 13:32:57.235186 19781 sgd_solver.cpp:106] Iteration 11900, lr = 1
I0124 13:33:02.341370 19781 solver.cpp:236] Iteration 11920, loss = 5.5797
I0124 13:33:02.341426 19781 solver.cpp:252]     Train net output #0: loss = 5.5797 (* 1 = 5.5797 loss)
I0124 13:33:02.341436 19781 sgd_solver.cpp:106] Iteration 11920, lr = 1
I0124 13:33:07.455037 19781 solver.cpp:236] Iteration 11940, loss = 5.74715
I0124 13:33:07.455090 19781 solver.cpp:252]     Train net output #0: loss = 5.74715 (* 1 = 5.74715 loss)
I0124 13:33:07.455102 19781 sgd_solver.cpp:106] Iteration 11940, lr = 1
I0124 13:33:12.499621 19781 solver.cpp:236] Iteration 11960, loss = 5.36618
I0124 13:33:12.499678 19781 solver.cpp:252]     Train net output #0: loss = 5.36618 (* 1 = 5.36618 loss)
I0124 13:33:12.499688 19781 sgd_solver.cpp:106] Iteration 11960, lr = 1
I0124 13:33:18.097677 19781 solver.cpp:236] Iteration 11980, loss = 5.39776
I0124 13:33:18.097730 19781 solver.cpp:252]     Train net output #0: loss = 5.39776 (* 1 = 5.39776 loss)
I0124 13:33:18.097739 19781 sgd_solver.cpp:106] Iteration 11980, lr = 1
I0124 13:33:23.351034 19781 solver.cpp:340] Iteration 12000, Testing net (#0)
I0124 13:33:31.050117 19781 blocking_queue.cpp:50] Data layer prefetch queue empty
I0124 13:35:10.037591 19781 solver.cpp:408]     Test net output #0: accuracy = 0.0682004
I0124 13:35:10.037873 19781 solver.cpp:408]     Test net output #1: loss = 5.24531 (* 1 = 5.24531 loss)
I0124 13:35:10.075557 19781 solver.cpp:236] Iteration 12000, loss = 5.37304
I0124 13:35:10.075601 19781 solver.cpp:252]     Train net output #0: loss = 5.37304 (* 1 = 5.37304 loss)
I0124 13:35:10.075611 19781 sgd_solver.cpp:106] Iteration 12000, lr = 1
I0124 13:35:14.859927 19781 solver.cpp:236] Iteration 12020, loss = 5.63169
I0124 13:35:14.859990 19781 solver.cpp:252]     Train net output #0: loss = 5.63169 (* 1 = 5.63169 loss)
I0124 13:35:14.860002 19781 sgd_solver.cpp:106] Iteration 12020, lr = 1
I0124 13:35:19.924929 19781 solver.cpp:236] Iteration 12040, loss = 5.87599
I0124 13:35:19.925000 19781 solver.cpp:252]     Train net output #0: loss = 5.87599 (* 1 = 5.87599 loss)
I0124 13:35:19.925011 19781 sgd_solver.cpp:106] Iteration 12040, lr = 1
I0124 13:35:25.007892 19781 solver.cpp:236] Iteration 12060, loss = 5.56658
I0124 13:35:25.007956 19781 solver.cpp:252]     Train net output #0: loss = 5.56658 (* 1 = 5.56658 loss)
I0124 13:35:25.007966 19781 sgd_solver.cpp:106] Iteration 12060, lr = 1
I0124 13:35:30.477320 19781 solver.cpp:236] Iteration 12080, loss = 5.75768
I0124 13:35:30.477373 19781 solver.cpp:252]     Train net output #0: loss = 5.75768 (* 1 = 5.75768 loss)
I0124 13:35:30.477381 19781 sgd_solver.cpp:106] Iteration 12080, lr = 1
I0124 13:35:30.722661 19781 blocking_queue.cpp:50] Data layer prefetch queue empty
I0124 13:35:36.135661 19781 solver.cpp:236] Iteration 12100, loss = 5.65386
I0124 13:35:36.135735 19781 solver.cpp:252]     Train net output #0: loss = 5.65386 (* 1 = 5.65386 loss)
I0124 13:35:36.135745 19781 sgd_solver.cpp:106] Iteration 12100, lr = 1
I0124 13:35:41.811192 19781 solver.cpp:236] Iteration 12120, loss = 5.74275
I0124 13:35:41.811414 19781 solver.cpp:252]     Train net output #0: loss = 5.74275 (* 1 = 5.74275 loss)
I0124 13:35:41.811441 19781 sgd_solver.cpp:106] Iteration 12120, lr = 1
I0124 13:35:47.211918 19781 solver.cpp:236] Iteration 12140, loss = 5.69294
I0124 13:35:47.211972 19781 solver.cpp:252]     Train net output #0: loss = 5.69294 (* 1 = 5.69294 loss)
I0124 13:35:47.211982 19781 sgd_solver.cpp:106] Iteration 12140, lr = 1
I0124 13:35:51.897300 19781 solver.cpp:236] Iteration 12160, loss = 5.52173
I0124 13:35:51.897348 19781 solver.cpp:252]     Train net output #0: loss = 5.52173 (* 1 = 5.52173 loss)
I0124 13:35:51.897358 19781 sgd_solver.cpp:106] Iteration 12160, lr = 1
I0124 13:35:56.467552 19781 solver.cpp:236] Iteration 12180, loss = 5.57811
I0124 13:35:56.467624 19781 solver.cpp:252]     Train net output #0: loss = 5.57811 (* 1 = 5.57811 loss)
I0124 13:35:56.467634 19781 sgd_solver.cpp:106] Iteration 12180, lr = 1
I0124 13:36:01.068511 19781 solver.cpp:236] Iteration 12200, loss = 5.87099
I0124 13:36:01.068591 19781 solver.cpp:252]     Train net output #0: loss = 5.87099 (* 1 = 5.87099 loss)
I0124 13:36:01.068601 19781 sgd_solver.cpp:106] Iteration 12200, lr = 1
I0124 13:36:07.350505 19781 solver.cpp:236] Iteration 12220, loss = 5.61508
I0124 13:36:07.350564 19781 solver.cpp:252]     Train net output #0: loss = 5.61508 (* 1 = 5.61508 loss)
I0124 13:36:07.350576 19781 sgd_solver.cpp:106] Iteration 12220, lr = 1
I0124 13:36:14.127856 19781 solver.cpp:236] Iteration 12240, loss = 5.66148
I0124 13:36:14.128093 19781 solver.cpp:252]     Train net output #0: loss = 5.66148 (* 1 = 5.66148 loss)
I0124 13:36:14.128110 19781 sgd_solver.cpp:106] Iteration 12240, lr = 1
I0124 13:36:18.781143 19781 solver.cpp:236] Iteration 12260, loss = 5.65192
I0124 13:36:18.781210 19781 solver.cpp:252]     Train net output #0: loss = 5.65192 (* 1 = 5.65192 loss)
I0124 13:36:18.781222 19781 sgd_solver.cpp:106] Iteration 12260, lr = 1
I0124 13:36:23.782941 19781 solver.cpp:236] Iteration 12280, loss = 5.7343
I0124 13:36:23.782997 19781 solver.cpp:252]     Train net output #0: loss = 5.7343 (* 1 = 5.7343 loss)
I0124 13:36:23.783009 19781 sgd_solver.cpp:106] Iteration 12280, lr = 1
I0124 13:36:28.531749 19781 solver.cpp:236] Iteration 12300, loss = 5.46144
I0124 13:36:28.531811 19781 solver.cpp:252]     Train net output #0: loss = 5.46144 (* 1 = 5.46144 loss)
I0124 13:36:28.531823 19781 sgd_solver.cpp:106] Iteration 12300, lr = 1
I0124 13:36:33.383862 19781 solver.cpp:236] Iteration 12320, loss = 5.62853
I0124 13:36:33.383929 19781 solver.cpp:252]     Train net output #0: loss = 5.62853 (* 1 = 5.62853 loss)
I0124 13:36:33.383939 19781 sgd_solver.cpp:106] Iteration 12320, lr = 1
I0124 13:36:38.201391 19781 solver.cpp:236] Iteration 12340, loss = 5.79373
I0124 13:36:38.201457 19781 solver.cpp:252]     Train net output #0: loss = 5.79373 (* 1 = 5.79373 loss)
I0124 13:36:38.201468 19781 sgd_solver.cpp:106] Iteration 12340, lr = 1
I0124 13:36:42.944113 19781 solver.cpp:236] Iteration 12360, loss = 5.89371
I0124 13:36:42.944183 19781 solver.cpp:252]     Train net output #0: loss = 5.89371 (* 1 = 5.89371 loss)
I0124 13:36:42.944195 19781 sgd_solver.cpp:106] Iteration 12360, lr = 1
I0124 13:36:47.698555 19781 solver.cpp:236] Iteration 12380, loss = 5.5356
I0124 13:36:47.698755 19781 solver.cpp:252]     Train net output #0: loss = 5.5356 (* 1 = 5.5356 loss)
I0124 13:36:47.698768 19781 sgd_solver.cpp:106] Iteration 12380, lr = 1
I0124 13:36:52.578935 19781 solver.cpp:236] Iteration 12400, loss = 5.62151
I0124 13:36:52.578991 19781 solver.cpp:252]     Train net output #0: loss = 5.62151 (* 1 = 5.62151 loss)
I0124 13:36:52.579001 19781 sgd_solver.cpp:106] Iteration 12400, lr = 1
I0124 13:36:58.767359 19781 solver.cpp:236] Iteration 12420, loss = 5.57349
I0124 13:36:58.767423 19781 solver.cpp:252]     Train net output #0: loss = 5.57349 (* 1 = 5.57349 loss)
I0124 13:36:58.767434 19781 sgd_solver.cpp:106] Iteration 12420, lr = 1
I0124 13:37:04.659827 19781 solver.cpp:236] Iteration 12440, loss = 5.78845
I0124 13:37:04.659881 19781 solver.cpp:252]     Train net output #0: loss = 5.78845 (* 1 = 5.78845 loss)
I0124 13:37:04.659889 19781 sgd_solver.cpp:106] Iteration 12440, lr = 1
I0124 13:37:09.577262 19781 solver.cpp:236] Iteration 12460, loss = 5.57616
I0124 13:37:09.577330 19781 solver.cpp:252]     Train net output #0: loss = 5.57616 (* 1 = 5.57616 loss)
I0124 13:37:09.577342 19781 sgd_solver.cpp:106] Iteration 12460, lr = 1
I0124 13:37:14.010869 19781 solver.cpp:236] Iteration 12480, loss = 5.34668
I0124 13:37:14.010936 19781 solver.cpp:252]     Train net output #0: loss = 5.34668 (* 1 = 5.34668 loss)
I0124 13:37:14.010946 19781 sgd_solver.cpp:106] Iteration 12480, lr = 1
I0124 13:37:18.471766 19781 solver.cpp:236] Iteration 12500, loss = 5.47796
I0124 13:37:18.472028 19781 solver.cpp:252]     Train net output #0: loss = 5.47796 (* 1 = 5.47796 loss)
I0124 13:37:18.472049 19781 sgd_solver.cpp:106] Iteration 12500, lr = 1
I0124 13:37:22.961033 19781 solver.cpp:236] Iteration 12520, loss = 5.683
I0124 13:37:22.961097 19781 solver.cpp:252]     Train net output #0: loss = 5.683 (* 1 = 5.683 loss)
I0124 13:37:22.961109 19781 sgd_solver.cpp:106] Iteration 12520, lr = 1
I0124 13:37:27.384923 19781 solver.cpp:236] Iteration 12540, loss = 5.82246
I0124 13:37:27.384986 19781 solver.cpp:252]     Train net output #0: loss = 5.82246 (* 1 = 5.82246 loss)
I0124 13:37:27.384997 19781 sgd_solver.cpp:106] Iteration 12540, lr = 1
I0124 13:37:31.901809 19781 solver.cpp:236] Iteration 12560, loss = 5.63586
I0124 13:37:31.901871 19781 solver.cpp:252]     Train net output #0: loss = 5.63586 (* 1 = 5.63586 loss)
I0124 13:37:31.901883 19781 sgd_solver.cpp:106] Iteration 12560, lr = 1
I0124 13:37:36.568310 19781 solver.cpp:236] Iteration 12580, loss = 5.44097
I0124 13:37:36.568372 19781 solver.cpp:252]     Train net output #0: loss = 5.44097 (* 1 = 5.44097 loss)
I0124 13:37:36.568383 19781 sgd_solver.cpp:106] Iteration 12580, lr = 1
I0124 13:37:41.362010 19781 solver.cpp:236] Iteration 12600, loss = 5.72407
I0124 13:37:41.362079 19781 solver.cpp:252]     Train net output #0: loss = 5.72407 (* 1 = 5.72407 loss)
I0124 13:37:41.362093 19781 sgd_solver.cpp:106] Iteration 12600, lr = 1
I0124 13:37:46.391505 19781 solver.cpp:236] Iteration 12620, loss = 5.651
I0124 13:37:46.391573 19781 solver.cpp:252]     Train net output #0: loss = 5.651 (* 1 = 5.651 loss)
I0124 13:37:46.391582 19781 sgd_solver.cpp:106] Iteration 12620, lr = 1
I0124 13:37:51.238191 19781 solver.cpp:236] Iteration 12640, loss = 5.60975
I0124 13:37:51.238397 19781 solver.cpp:252]     Train net output #0: loss = 5.60975 (* 1 = 5.60975 loss)
I0124 13:37:51.238412 19781 sgd_solver.cpp:106] Iteration 12640, lr = 1
I0124 13:37:55.972391 19781 solver.cpp:236] Iteration 12660, loss = 5.43136
I0124 13:37:55.972461 19781 solver.cpp:252]     Train net output #0: loss = 5.43136 (* 1 = 5.43136 loss)
I0124 13:37:55.972472 19781 sgd_solver.cpp:106] Iteration 12660, lr = 1
I0124 13:38:00.763195 19781 solver.cpp:236] Iteration 12680, loss = 5.8681
I0124 13:38:00.763257 19781 solver.cpp:252]     Train net output #0: loss = 5.8681 (* 1 = 5.8681 loss)
I0124 13:38:00.763268 19781 sgd_solver.cpp:106] Iteration 12680, lr = 1
I0124 13:38:05.536716 19781 solver.cpp:236] Iteration 12700, loss = 5.68063
I0124 13:38:05.536803 19781 solver.cpp:252]     Train net output #0: loss = 5.68063 (* 1 = 5.68063 loss)
I0124 13:38:05.536813 19781 sgd_solver.cpp:106] Iteration 12700, lr = 1
I0124 13:38:10.350097 19781 solver.cpp:236] Iteration 12720, loss = 6.00961
I0124 13:38:10.350152 19781 solver.cpp:252]     Train net output #0: loss = 6.00961 (* 1 = 6.00961 loss)
I0124 13:38:10.350160 19781 sgd_solver.cpp:106] Iteration 12720, lr = 1
I0124 13:38:15.241581 19781 solver.cpp:236] Iteration 12740, loss = 5.65156
I0124 13:38:15.241660 19781 solver.cpp:252]     Train net output #0: loss = 5.65156 (* 1 = 5.65156 loss)
I0124 13:38:15.241670 19781 sgd_solver.cpp:106] Iteration 12740, lr = 1
I0124 13:38:20.085767 19781 solver.cpp:236] Iteration 12760, loss = 5.77887
I0124 13:38:20.085834 19781 solver.cpp:252]     Train net output #0: loss = 5.77887 (* 1 = 5.77887 loss)
I0124 13:38:20.085845 19781 sgd_solver.cpp:106] Iteration 12760, lr = 1
I0124 13:38:24.847462 19781 solver.cpp:236] Iteration 12780, loss = 5.70624
I0124 13:38:24.847636 19781 solver.cpp:252]     Train net output #0: loss = 5.70624 (* 1 = 5.70624 loss)
I0124 13:38:24.847651 19781 sgd_solver.cpp:106] Iteration 12780, lr = 1
I0124 13:38:29.634699 19781 solver.cpp:236] Iteration 12800, loss = 5.59434
I0124 13:38:29.634788 19781 solver.cpp:252]     Train net output #0: loss = 5.59434 (* 1 = 5.59434 loss)
I0124 13:38:29.634799 19781 sgd_solver.cpp:106] Iteration 12800, lr = 1
I0124 13:38:34.414083 19781 solver.cpp:236] Iteration 12820, loss = 5.87316
I0124 13:38:34.414160 19781 solver.cpp:252]     Train net output #0: loss = 5.87316 (* 1 = 5.87316 loss)
I0124 13:38:34.414171 19781 sgd_solver.cpp:106] Iteration 12820, lr = 1
I0124 13:38:39.243772 19781 solver.cpp:236] Iteration 12840, loss = 5.66151
I0124 13:38:39.243826 19781 solver.cpp:252]     Train net output #0: loss = 5.66151 (* 1 = 5.66151 loss)
I0124 13:38:39.243834 19781 sgd_solver.cpp:106] Iteration 12840, lr = 1
I0124 13:38:43.965256 19781 solver.cpp:236] Iteration 12860, loss = 5.31808
I0124 13:38:43.965322 19781 solver.cpp:252]     Train net output #0: loss = 5.31808 (* 1 = 5.31808 loss)
I0124 13:38:43.965333 19781 sgd_solver.cpp:106] Iteration 12860, lr = 1
I0124 13:38:48.726275 19781 solver.cpp:236] Iteration 12880, loss = 5.65586
I0124 13:38:48.726351 19781 solver.cpp:252]     Train net output #0: loss = 5.65586 (* 1 = 5.65586 loss)
I0124 13:38:48.726361 19781 sgd_solver.cpp:106] Iteration 12880, lr = 1
I0124 13:38:53.555145 19781 solver.cpp:236] Iteration 12900, loss = 5.62122
I0124 13:38:53.555224 19781 solver.cpp:252]     Train net output #0: loss = 5.62122 (* 1 = 5.62122 loss)
I0124 13:38:53.555235 19781 sgd_solver.cpp:106] Iteration 12900, lr = 1
I0124 13:38:58.390482 19781 solver.cpp:236] Iteration 12920, loss = 5.83032
I0124 13:38:58.390655 19781 solver.cpp:252]     Train net output #0: loss = 5.83032 (* 1 = 5.83032 loss)
I0124 13:38:58.390666 19781 sgd_solver.cpp:106] Iteration 12920, lr = 1
I0124 13:39:03.086031 19781 solver.cpp:236] Iteration 12940, loss = 5.33976
I0124 13:39:03.086094 19781 solver.cpp:252]     Train net output #0: loss = 5.33976 (* 1 = 5.33976 loss)
I0124 13:39:03.086105 19781 sgd_solver.cpp:106] Iteration 12940, lr = 1
I0124 13:39:07.766279 19781 solver.cpp:236] Iteration 12960, loss = 5.79659
I0124 13:39:07.766338 19781 solver.cpp:252]     Train net output #0: loss = 5.79659 (* 1 = 5.79659 loss)
I0124 13:39:07.766350 19781 sgd_solver.cpp:106] Iteration 12960, lr = 1
I0124 13:39:13.227172 19781 solver.cpp:236] Iteration 12980, loss = 5.76926
I0124 13:39:13.227238 19781 solver.cpp:252]     Train net output #0: loss = 5.76926 (* 1 = 5.76926 loss)
I0124 13:39:13.227251 19781 sgd_solver.cpp:106] Iteration 12980, lr = 1
I0124 13:39:18.291496 19781 solver.cpp:340] Iteration 13000, Testing net (#0)
I0124 13:39:26.659421 19781 blocking_queue.cpp:50] Data layer prefetch queue empty
I0124 13:40:55.839081 19781 solver.cpp:408]     Test net output #0: accuracy = 0.0645403
I0124 13:40:55.839390 19781 solver.cpp:408]     Test net output #1: loss = 5.35785 (* 1 = 5.35785 loss)
I0124 13:40:55.877245 19781 solver.cpp:236] Iteration 13000, loss = 5.70436
I0124 13:40:55.877280 19781 solver.cpp:252]     Train net output #0: loss = 5.70436 (* 1 = 5.70436 loss)
I0124 13:40:55.877295 19781 sgd_solver.cpp:106] Iteration 13000, lr = 1
I0124 13:41:00.688930 19781 solver.cpp:236] Iteration 13020, loss = 6.02267
I0124 13:41:00.688988 19781 solver.cpp:252]     Train net output #0: loss = 6.02267 (* 1 = 6.02267 loss)
I0124 13:41:00.689003 19781 sgd_solver.cpp:106] Iteration 13020, lr = 1
I0124 13:41:05.706074 19781 solver.cpp:236] Iteration 13040, loss = 5.32185
I0124 13:41:05.706120 19781 solver.cpp:252]     Train net output #0: loss = 5.32185 (* 1 = 5.32185 loss)
I0124 13:41:05.706130 19781 sgd_solver.cpp:106] Iteration 13040, lr = 1
I0124 13:41:10.514891 19781 solver.cpp:236] Iteration 13060, loss = 5.46193
I0124 13:41:10.514943 19781 solver.cpp:252]     Train net output #0: loss = 5.46193 (* 1 = 5.46193 loss)
I0124 13:41:10.514953 19781 sgd_solver.cpp:106] Iteration 13060, lr = 1
I0124 13:41:15.359484 19781 solver.cpp:236] Iteration 13080, loss = 5.56026
I0124 13:41:15.359536 19781 solver.cpp:252]     Train net output #0: loss = 5.56026 (* 1 = 5.56026 loss)
I0124 13:41:15.359547 19781 sgd_solver.cpp:106] Iteration 13080, lr = 1
I0124 13:41:17.073879 19781 blocking_queue.cpp:50] Data layer prefetch queue empty
I0124 13:41:20.233965 19781 solver.cpp:236] Iteration 13100, loss = 5.46761
I0124 13:41:20.234026 19781 solver.cpp:252]     Train net output #0: loss = 5.46761 (* 1 = 5.46761 loss)
I0124 13:41:20.234041 19781 sgd_solver.cpp:106] Iteration 13100, lr = 1
I0124 13:41:25.056051 19781 solver.cpp:236] Iteration 13120, loss = 5.66161
I0124 13:41:25.056107 19781 solver.cpp:252]     Train net output #0: loss = 5.66161 (* 1 = 5.66161 loss)
I0124 13:41:25.056118 19781 sgd_solver.cpp:106] Iteration 13120, lr = 1
I0124 13:41:29.766522 19781 solver.cpp:236] Iteration 13140, loss = 5.8497
I0124 13:41:29.766695 19781 solver.cpp:252]     Train net output #0: loss = 5.8497 (* 1 = 5.8497 loss)
I0124 13:41:29.766707 19781 sgd_solver.cpp:106] Iteration 13140, lr = 1
I0124 13:41:34.512444 19781 solver.cpp:236] Iteration 13160, loss = 5.81325
I0124 13:41:34.512498 19781 solver.cpp:252]     Train net output #0: loss = 5.81325 (* 1 = 5.81325 loss)
I0124 13:41:34.512509 19781 sgd_solver.cpp:106] Iteration 13160, lr = 1
I0124 13:41:39.351014 19781 solver.cpp:236] Iteration 13180, loss = 5.8342
I0124 13:41:39.351059 19781 solver.cpp:252]     Train net output #0: loss = 5.8342 (* 1 = 5.8342 loss)
I0124 13:41:39.351068 19781 sgd_solver.cpp:106] Iteration 13180, lr = 1
I0124 13:41:44.181385 19781 solver.cpp:236] Iteration 13200, loss = 5.55777
I0124 13:41:44.181433 19781 solver.cpp:252]     Train net output #0: loss = 5.55777 (* 1 = 5.55777 loss)
I0124 13:41:44.181445 19781 sgd_solver.cpp:106] Iteration 13200, lr = 1
I0124 13:41:49.038358 19781 solver.cpp:236] Iteration 13220, loss = 5.48075
I0124 13:41:49.038409 19781 solver.cpp:252]     Train net output #0: loss = 5.48075 (* 1 = 5.48075 loss)
I0124 13:41:49.038425 19781 sgd_solver.cpp:106] Iteration 13220, lr = 1
I0124 13:41:53.891253 19781 solver.cpp:236] Iteration 13240, loss = 5.61729
I0124 13:41:53.891304 19781 solver.cpp:252]     Train net output #0: loss = 5.61729 (* 1 = 5.61729 loss)
I0124 13:41:53.891314 19781 sgd_solver.cpp:106] Iteration 13240, lr = 1
I0124 13:41:58.751041 19781 solver.cpp:236] Iteration 13260, loss = 5.8383
I0124 13:41:58.751096 19781 solver.cpp:252]     Train net output #0: loss = 5.8383 (* 1 = 5.8383 loss)
I0124 13:41:58.751108 19781 sgd_solver.cpp:106] Iteration 13260, lr = 1
I0124 13:42:03.762187 19781 solver.cpp:236] Iteration 13280, loss = 5.61306
I0124 13:42:03.762467 19781 solver.cpp:252]     Train net output #0: loss = 5.61306 (* 1 = 5.61306 loss)
I0124 13:42:03.762485 19781 sgd_solver.cpp:106] Iteration 13280, lr = 1
I0124 13:42:08.669895 19781 solver.cpp:236] Iteration 13300, loss = 5.60075
I0124 13:42:08.669934 19781 solver.cpp:252]     Train net output #0: loss = 5.60075 (* 1 = 5.60075 loss)
I0124 13:42:08.669939 19781 sgd_solver.cpp:106] Iteration 13300, lr = 1
I0124 13:42:12.976704 19781 solver.cpp:236] Iteration 13320, loss = 5.47564
I0124 13:42:12.976754 19781 solver.cpp:252]     Train net output #0: loss = 5.47564 (* 1 = 5.47564 loss)
I0124 13:42:12.976765 19781 sgd_solver.cpp:106] Iteration 13320, lr = 1
I0124 13:42:17.290343 19781 solver.cpp:236] Iteration 13340, loss = 5.68441
I0124 13:42:17.290385 19781 solver.cpp:252]     Train net output #0: loss = 5.68441 (* 1 = 5.68441 loss)
I0124 13:42:17.290395 19781 sgd_solver.cpp:106] Iteration 13340, lr = 1
I0124 13:42:21.635637 19781 solver.cpp:236] Iteration 13360, loss = 5.71755
I0124 13:42:21.635682 19781 solver.cpp:252]     Train net output #0: loss = 5.71755 (* 1 = 5.71755 loss)
I0124 13:42:21.635690 19781 sgd_solver.cpp:106] Iteration 13360, lr = 1
I0124 13:42:25.976943 19781 solver.cpp:236] Iteration 13380, loss = 5.73882
I0124 13:42:25.976981 19781 solver.cpp:252]     Train net output #0: loss = 5.73882 (* 1 = 5.73882 loss)
I0124 13:42:25.976989 19781 sgd_solver.cpp:106] Iteration 13380, lr = 1
I0124 13:42:30.401051 19781 solver.cpp:236] Iteration 13400, loss = 5.60178
I0124 13:42:30.401114 19781 solver.cpp:252]     Train net output #0: loss = 5.60178 (* 1 = 5.60178 loss)
I0124 13:42:30.401126 19781 sgd_solver.cpp:106] Iteration 13400, lr = 1
I0124 13:42:35.090235 19781 solver.cpp:236] Iteration 13420, loss = 5.63825
I0124 13:42:35.090410 19781 solver.cpp:252]     Train net output #0: loss = 5.63825 (* 1 = 5.63825 loss)
I0124 13:42:35.090427 19781 sgd_solver.cpp:106] Iteration 13420, lr = 1
I0124 13:42:39.879588 19781 solver.cpp:236] Iteration 13440, loss = 5.62219
I0124 13:42:39.879647 19781 solver.cpp:252]     Train net output #0: loss = 5.62219 (* 1 = 5.62219 loss)
I0124 13:42:39.879662 19781 sgd_solver.cpp:106] Iteration 13440, lr = 1
I0124 13:42:45.130703 19781 solver.cpp:236] Iteration 13460, loss = 5.40742
I0124 13:42:45.130772 19781 solver.cpp:252]     Train net output #0: loss = 5.40742 (* 1 = 5.40742 loss)
I0124 13:42:45.130782 19781 sgd_solver.cpp:106] Iteration 13460, lr = 1
I0124 13:42:50.537478 19781 solver.cpp:236] Iteration 13480, loss = 5.56181
I0124 13:42:50.537555 19781 solver.cpp:252]     Train net output #0: loss = 5.56181 (* 1 = 5.56181 loss)
I0124 13:42:50.537567 19781 sgd_solver.cpp:106] Iteration 13480, lr = 1
I0124 13:42:55.259136 19781 solver.cpp:236] Iteration 13500, loss = 5.8449
I0124 13:42:55.259212 19781 solver.cpp:252]     Train net output #0: loss = 5.8449 (* 1 = 5.8449 loss)
I0124 13:42:55.259223 19781 sgd_solver.cpp:106] Iteration 13500, lr = 1
I0124 13:42:59.981286 19781 solver.cpp:236] Iteration 13520, loss = 5.80452
I0124 13:42:59.981353 19781 solver.cpp:252]     Train net output #0: loss = 5.80452 (* 1 = 5.80452 loss)
I0124 13:42:59.981366 19781 sgd_solver.cpp:106] Iteration 13520, lr = 1
I0124 13:43:04.687091 19781 solver.cpp:236] Iteration 13540, loss = 5.71268
I0124 13:43:04.687160 19781 solver.cpp:252]     Train net output #0: loss = 5.71268 (* 1 = 5.71268 loss)
I0124 13:43:04.687175 19781 sgd_solver.cpp:106] Iteration 13540, lr = 1
I0124 13:43:09.297523 19781 solver.cpp:236] Iteration 13560, loss = 5.58994
I0124 13:43:09.297699 19781 solver.cpp:252]     Train net output #0: loss = 5.58994 (* 1 = 5.58994 loss)
I0124 13:43:09.297714 19781 sgd_solver.cpp:106] Iteration 13560, lr = 1
I0124 13:43:14.000746 19781 solver.cpp:236] Iteration 13580, loss = 5.58653
I0124 13:43:14.000811 19781 solver.cpp:252]     Train net output #0: loss = 5.58653 (* 1 = 5.58653 loss)
I0124 13:43:14.000823 19781 sgd_solver.cpp:106] Iteration 13580, lr = 1
I0124 13:43:18.807062 19781 solver.cpp:236] Iteration 13600, loss = 5.4831
I0124 13:43:18.807123 19781 solver.cpp:252]     Train net output #0: loss = 5.4831 (* 1 = 5.4831 loss)
I0124 13:43:18.807133 19781 sgd_solver.cpp:106] Iteration 13600, lr = 1
I0124 13:43:23.459296 19781 solver.cpp:236] Iteration 13620, loss = 5.7201
I0124 13:43:23.459370 19781 solver.cpp:252]     Train net output #0: loss = 5.7201 (* 1 = 5.7201 loss)
I0124 13:43:23.459380 19781 sgd_solver.cpp:106] Iteration 13620, lr = 1
I0124 13:43:28.341651 19781 solver.cpp:236] Iteration 13640, loss = 5.88951
I0124 13:43:28.342002 19781 solver.cpp:252]     Train net output #0: loss = 5.88951 (* 1 = 5.88951 loss)
I0124 13:43:28.342030 19781 sgd_solver.cpp:106] Iteration 13640, lr = 1
I0124 13:43:33.547085 19781 solver.cpp:236] Iteration 13660, loss = 5.58642
I0124 13:43:33.547142 19781 solver.cpp:252]     Train net output #0: loss = 5.58642 (* 1 = 5.58642 loss)
I0124 13:43:33.547153 19781 sgd_solver.cpp:106] Iteration 13660, lr = 1
I0124 13:43:38.273309 19781 solver.cpp:236] Iteration 13680, loss = 5.72545
I0124 13:43:38.273376 19781 solver.cpp:252]     Train net output #0: loss = 5.72545 (* 1 = 5.72545 loss)
I0124 13:43:38.273387 19781 sgd_solver.cpp:106] Iteration 13680, lr = 1
I0124 13:43:42.793843 19781 solver.cpp:236] Iteration 13700, loss = 5.5012
I0124 13:43:42.794165 19781 solver.cpp:252]     Train net output #0: loss = 5.5012 (* 1 = 5.5012 loss)
I0124 13:43:42.794185 19781 sgd_solver.cpp:106] Iteration 13700, lr = 1
I0124 13:43:47.380180 19781 solver.cpp:236] Iteration 13720, loss = 5.48641
I0124 13:43:47.380244 19781 solver.cpp:252]     Train net output #0: loss = 5.48641 (* 1 = 5.48641 loss)
I0124 13:43:47.380256 19781 sgd_solver.cpp:106] Iteration 13720, lr = 1
I0124 13:43:51.944686 19781 solver.cpp:236] Iteration 13740, loss = 5.76662
I0124 13:43:51.944735 19781 solver.cpp:252]     Train net output #0: loss = 5.76662 (* 1 = 5.76662 loss)
I0124 13:43:51.944742 19781 sgd_solver.cpp:106] Iteration 13740, lr = 1
I0124 13:43:56.555305 19781 solver.cpp:236] Iteration 13760, loss = 5.68718
I0124 13:43:56.555376 19781 solver.cpp:252]     Train net output #0: loss = 5.68718 (* 1 = 5.68718 loss)
I0124 13:43:56.555387 19781 sgd_solver.cpp:106] Iteration 13760, lr = 1
I0124 13:44:01.379945 19781 solver.cpp:236] Iteration 13780, loss = 5.73605
I0124 13:44:01.380026 19781 solver.cpp:252]     Train net output #0: loss = 5.73605 (* 1 = 5.73605 loss)
I0124 13:44:01.380038 19781 sgd_solver.cpp:106] Iteration 13780, lr = 1
I0124 13:44:06.015980 19781 solver.cpp:236] Iteration 13800, loss = 5.35029
I0124 13:44:06.016037 19781 solver.cpp:252]     Train net output #0: loss = 5.35029 (* 1 = 5.35029 loss)
I0124 13:44:06.016048 19781 sgd_solver.cpp:106] Iteration 13800, lr = 1
I0124 13:44:10.900586 19781 solver.cpp:236] Iteration 13820, loss = 5.53495
I0124 13:44:10.900638 19781 solver.cpp:252]     Train net output #0: loss = 5.53495 (* 1 = 5.53495 loss)
I0124 13:44:10.900653 19781 sgd_solver.cpp:106] Iteration 13820, lr = 1
I0124 13:44:16.113771 19781 solver.cpp:236] Iteration 13840, loss = 5.86369
I0124 13:44:16.113940 19781 solver.cpp:252]     Train net output #0: loss = 5.86369 (* 1 = 5.86369 loss)
I0124 13:44:16.113955 19781 sgd_solver.cpp:106] Iteration 13840, lr = 1
I0124 13:44:21.070163 19781 solver.cpp:236] Iteration 13860, loss = 5.58773
I0124 13:44:21.070211 19781 solver.cpp:252]     Train net output #0: loss = 5.58773 (* 1 = 5.58773 loss)
I0124 13:44:21.070221 19781 sgd_solver.cpp:106] Iteration 13860, lr = 1
I0124 13:44:25.695214 19781 solver.cpp:236] Iteration 13880, loss = 5.65054
I0124 13:44:25.695250 19781 solver.cpp:252]     Train net output #0: loss = 5.65054 (* 1 = 5.65054 loss)
I0124 13:44:25.695256 19781 sgd_solver.cpp:106] Iteration 13880, lr = 1
I0124 13:44:30.299347 19781 solver.cpp:236] Iteration 13900, loss = 5.55839
I0124 13:44:30.299396 19781 solver.cpp:252]     Train net output #0: loss = 5.55839 (* 1 = 5.55839 loss)
I0124 13:44:30.299407 19781 sgd_solver.cpp:106] Iteration 13900, lr = 1
I0124 13:44:34.867139 19781 solver.cpp:236] Iteration 13920, loss = 5.56034
I0124 13:44:34.867188 19781 solver.cpp:252]     Train net output #0: loss = 5.56034 (* 1 = 5.56034 loss)
I0124 13:44:34.867198 19781 sgd_solver.cpp:106] Iteration 13920, lr = 1
I0124 13:44:39.500192 19781 solver.cpp:236] Iteration 13940, loss = 5.703
I0124 13:44:39.500226 19781 solver.cpp:252]     Train net output #0: loss = 5.703 (* 1 = 5.703 loss)
I0124 13:44:39.500231 19781 sgd_solver.cpp:106] Iteration 13940, lr = 1
I0124 13:44:44.218976 19781 solver.cpp:236] Iteration 13960, loss = 5.71663
I0124 13:44:44.219023 19781 solver.cpp:252]     Train net output #0: loss = 5.71663 (* 1 = 5.71663 loss)
I0124 13:44:44.219033 19781 sgd_solver.cpp:106] Iteration 13960, lr = 1
I0124 13:44:48.948679 19781 solver.cpp:236] Iteration 13980, loss = 5.55307
I0124 13:44:48.948899 19781 solver.cpp:252]     Train net output #0: loss = 5.55307 (* 1 = 5.55307 loss)
I0124 13:44:48.948911 19781 sgd_solver.cpp:106] Iteration 13980, lr = 1
I0124 13:44:53.617358 19781 solver.cpp:340] Iteration 14000, Testing net (#0)
I0124 13:45:03.225261 19781 blocking_queue.cpp:50] Data layer prefetch queue empty
I0124 13:46:32.243657 19781 solver.cpp:408]     Test net output #0: accuracy = 0.0703002
I0124 13:46:32.243877 19781 solver.cpp:408]     Test net output #1: loss = 5.25493 (* 1 = 5.25493 loss)
I0124 13:46:32.281378 19781 solver.cpp:236] Iteration 14000, loss = 5.62685
I0124 13:46:32.281419 19781 solver.cpp:252]     Train net output #0: loss = 5.62685 (* 1 = 5.62685 loss)
I0124 13:46:32.281427 19781 sgd_solver.cpp:106] Iteration 14000, lr = 1
I0124 13:46:36.511291 19781 solver.cpp:236] Iteration 14020, loss = 5.49055
I0124 13:46:36.511363 19781 solver.cpp:252]     Train net output #0: loss = 5.49055 (* 1 = 5.49055 loss)
I0124 13:46:36.511379 19781 sgd_solver.cpp:106] Iteration 14020, lr = 1
I0124 13:46:41.243147 19781 solver.cpp:236] Iteration 14040, loss = 5.77864
I0124 13:46:41.243212 19781 solver.cpp:252]     Train net output #0: loss = 5.77864 (* 1 = 5.77864 loss)
I0124 13:46:41.243222 19781 sgd_solver.cpp:106] Iteration 14040, lr = 1
I0124 13:46:45.912433 19781 solver.cpp:236] Iteration 14060, loss = 5.75697
I0124 13:46:45.912502 19781 solver.cpp:252]     Train net output #0: loss = 5.75697 (* 1 = 5.75697 loss)
I0124 13:46:45.912513 19781 sgd_solver.cpp:106] Iteration 14060, lr = 1
I0124 13:46:50.565940 19781 solver.cpp:236] Iteration 14080, loss = 5.75575
I0124 13:46:50.565990 19781 solver.cpp:252]     Train net output #0: loss = 5.75575 (* 1 = 5.75575 loss)
I0124 13:46:50.566002 19781 sgd_solver.cpp:106] Iteration 14080, lr = 1
I0124 13:46:53.831408 19781 blocking_queue.cpp:50] Data layer prefetch queue empty
I0124 13:46:55.234159 19781 solver.cpp:236] Iteration 14100, loss = 5.9049
I0124 13:46:55.234223 19781 solver.cpp:252]     Train net output #0: loss = 5.9049 (* 1 = 5.9049 loss)
I0124 13:46:55.234236 19781 sgd_solver.cpp:106] Iteration 14100, lr = 1
I0124 13:47:00.023461 19781 solver.cpp:236] Iteration 14120, loss = 5.7274
I0124 13:47:00.023526 19781 solver.cpp:252]     Train net output #0: loss = 5.7274 (* 1 = 5.7274 loss)
I0124 13:47:00.023537 19781 sgd_solver.cpp:106] Iteration 14120, lr = 1
I0124 13:47:04.805760 19781 solver.cpp:236] Iteration 14140, loss = 5.73879
I0124 13:47:04.805971 19781 solver.cpp:252]     Train net output #0: loss = 5.73879 (* 1 = 5.73879 loss)
I0124 13:47:04.805991 19781 sgd_solver.cpp:106] Iteration 14140, lr = 1
I0124 13:47:09.587383 19781 solver.cpp:236] Iteration 14160, loss = 5.49516
I0124 13:47:09.587452 19781 solver.cpp:252]     Train net output #0: loss = 5.49516 (* 1 = 5.49516 loss)
I0124 13:47:09.587465 19781 sgd_solver.cpp:106] Iteration 14160, lr = 1
I0124 13:47:15.574975 19781 solver.cpp:236] Iteration 14180, loss = 5.84565
I0124 13:47:15.575034 19781 solver.cpp:252]     Train net output #0: loss = 5.84565 (* 1 = 5.84565 loss)
I0124 13:47:15.575045 19781 sgd_solver.cpp:106] Iteration 14180, lr = 1
I0124 13:47:19.985211 19781 solver.cpp:236] Iteration 14200, loss = 5.61325
I0124 13:47:19.985273 19781 solver.cpp:252]     Train net output #0: loss = 5.61325 (* 1 = 5.61325 loss)
I0124 13:47:19.985283 19781 sgd_solver.cpp:106] Iteration 14200, lr = 1
I0124 13:47:24.487059 19781 solver.cpp:236] Iteration 14220, loss = 5.35917
I0124 13:47:24.487124 19781 solver.cpp:252]     Train net output #0: loss = 5.35917 (* 1 = 5.35917 loss)
I0124 13:47:24.487134 19781 sgd_solver.cpp:106] Iteration 14220, lr = 1
I0124 13:47:29.072527 19781 solver.cpp:236] Iteration 14240, loss = 5.76
I0124 13:47:29.072597 19781 solver.cpp:252]     Train net output #0: loss = 5.76 (* 1 = 5.76 loss)
I0124 13:47:29.072608 19781 sgd_solver.cpp:106] Iteration 14240, lr = 1
I0124 13:47:34.002202 19781 solver.cpp:236] Iteration 14260, loss = 5.91782
I0124 13:47:34.002264 19781 solver.cpp:252]     Train net output #0: loss = 5.91782 (* 1 = 5.91782 loss)
I0124 13:47:34.002271 19781 sgd_solver.cpp:106] Iteration 14260, lr = 1
I0124 13:47:39.014595 19781 solver.cpp:236] Iteration 14280, loss = 5.75089
I0124 13:47:39.014839 19781 solver.cpp:252]     Train net output #0: loss = 5.75089 (* 1 = 5.75089 loss)
I0124 13:47:39.014850 19781 sgd_solver.cpp:106] Iteration 14280, lr = 1
I0124 13:47:44.021648 19781 solver.cpp:236] Iteration 14300, loss = 5.75328
I0124 13:47:44.021723 19781 solver.cpp:252]     Train net output #0: loss = 5.75328 (* 1 = 5.75328 loss)
I0124 13:47:44.021730 19781 sgd_solver.cpp:106] Iteration 14300, lr = 1
I0124 13:47:49.011023 19781 solver.cpp:236] Iteration 14320, loss = 5.72348
I0124 13:47:49.011106 19781 solver.cpp:252]     Train net output #0: loss = 5.72348 (* 1 = 5.72348 loss)
I0124 13:47:49.011121 19781 sgd_solver.cpp:106] Iteration 14320, lr = 1
I0124 13:47:54.363230 19781 solver.cpp:236] Iteration 14340, loss = 5.26627
I0124 13:47:54.363410 19781 solver.cpp:252]     Train net output #0: loss = 5.26627 (* 1 = 5.26627 loss)
I0124 13:47:54.363438 19781 sgd_solver.cpp:106] Iteration 14340, lr = 1
I0124 13:48:00.484835 19781 solver.cpp:236] Iteration 14360, loss = 5.81966
I0124 13:48:00.484905 19781 solver.cpp:252]     Train net output #0: loss = 5.81966 (* 1 = 5.81966 loss)
I0124 13:48:00.484920 19781 sgd_solver.cpp:106] Iteration 14360, lr = 1
I0124 13:48:05.640429 19781 solver.cpp:236] Iteration 14380, loss = 5.6708
I0124 13:48:05.640502 19781 solver.cpp:252]     Train net output #0: loss = 5.6708 (* 1 = 5.6708 loss)
I0124 13:48:05.640519 19781 sgd_solver.cpp:106] Iteration 14380, lr = 1
I0124 13:48:10.821092 19781 solver.cpp:236] Iteration 14400, loss = 5.46854
I0124 13:48:10.821244 19781 solver.cpp:252]     Train net output #0: loss = 5.46854 (* 1 = 5.46854 loss)
I0124 13:48:10.821255 19781 sgd_solver.cpp:106] Iteration 14400, lr = 1
I0124 13:48:15.930479 19781 solver.cpp:236] Iteration 14420, loss = 5.697
I0124 13:48:15.930539 19781 solver.cpp:252]     Train net output #0: loss = 5.697 (* 1 = 5.697 loss)
I0124 13:48:15.930548 19781 sgd_solver.cpp:106] Iteration 14420, lr = 1
I0124 13:48:21.060072 19781 solver.cpp:236] Iteration 14440, loss = 5.53263
I0124 13:48:21.060163 19781 solver.cpp:252]     Train net output #0: loss = 5.53263 (* 1 = 5.53263 loss)
I0124 13:48:21.060178 19781 sgd_solver.cpp:106] Iteration 14440, lr = 1
I0124 13:48:26.280629 19781 solver.cpp:236] Iteration 14460, loss = 5.47692
I0124 13:48:26.280712 19781 solver.cpp:252]     Train net output #0: loss = 5.47692 (* 1 = 5.47692 loss)
I0124 13:48:26.280725 19781 sgd_solver.cpp:106] Iteration 14460, lr = 1
I0124 13:48:31.452111 19781 solver.cpp:236] Iteration 14480, loss = 5.76763
I0124 13:48:31.452189 19781 solver.cpp:252]     Train net output #0: loss = 5.76763 (* 1 = 5.76763 loss)
I0124 13:48:31.452201 19781 sgd_solver.cpp:106] Iteration 14480, lr = 1
I0124 13:48:36.662065 19781 solver.cpp:236] Iteration 14500, loss = 5.60284
I0124 13:48:36.662425 19781 solver.cpp:252]     Train net output #0: loss = 5.60284 (* 1 = 5.60284 loss)
I0124 13:48:36.662474 19781 sgd_solver.cpp:106] Iteration 14500, lr = 1
I0124 13:48:42.646651 19781 solver.cpp:236] Iteration 14520, loss = 5.75575
I0124 13:48:42.646893 19781 solver.cpp:252]     Train net output #0: loss = 5.75575 (* 1 = 5.75575 loss)
I0124 13:48:42.646908 19781 sgd_solver.cpp:106] Iteration 14520, lr = 1
I0124 13:48:47.776242 19781 solver.cpp:236] Iteration 14540, loss = 5.65757
I0124 13:48:47.776301 19781 solver.cpp:252]     Train net output #0: loss = 5.65757 (* 1 = 5.65757 loss)
I0124 13:48:47.776314 19781 sgd_solver.cpp:106] Iteration 14540, lr = 1
I0124 13:48:52.887467 19781 solver.cpp:236] Iteration 14560, loss = 5.4597
I0124 13:48:52.887526 19781 solver.cpp:252]     Train net output #0: loss = 5.4597 (* 1 = 5.4597 loss)
I0124 13:48:52.887538 19781 sgd_solver.cpp:106] Iteration 14560, lr = 1
I0124 13:48:58.000768 19781 solver.cpp:236] Iteration 14580, loss = 5.64431
I0124 13:48:58.000833 19781 solver.cpp:252]     Train net output #0: loss = 5.64431 (* 1 = 5.64431 loss)
I0124 13:48:58.000845 19781 sgd_solver.cpp:106] Iteration 14580, lr = 1
I0124 13:49:03.210708 19781 solver.cpp:236] Iteration 14600, loss = 5.63123
I0124 13:49:03.210791 19781 solver.cpp:252]     Train net output #0: loss = 5.63123 (* 1 = 5.63123 loss)
I0124 13:49:03.210806 19781 sgd_solver.cpp:106] Iteration 14600, lr = 1
I0124 13:49:08.258637 19781 solver.cpp:236] Iteration 14620, loss = 5.81258
I0124 13:49:08.258694 19781 solver.cpp:252]     Train net output #0: loss = 5.81258 (* 1 = 5.81258 loss)
I0124 13:49:08.258708 19781 sgd_solver.cpp:106] Iteration 14620, lr = 1
I0124 13:49:13.276160 19781 solver.cpp:236] Iteration 14640, loss = 5.59171
I0124 13:49:13.276418 19781 solver.cpp:252]     Train net output #0: loss = 5.59171 (* 1 = 5.59171 loss)
I0124 13:49:13.276443 19781 sgd_solver.cpp:106] Iteration 14640, lr = 1
I0124 13:49:18.262647 19781 solver.cpp:236] Iteration 14660, loss = 5.54454
I0124 13:49:18.262697 19781 solver.cpp:252]     Train net output #0: loss = 5.54454 (* 1 = 5.54454 loss)
I0124 13:49:18.262706 19781 sgd_solver.cpp:106] Iteration 14660, lr = 1
I0124 13:49:23.776072 19781 solver.cpp:236] Iteration 14680, loss = 5.56044
I0124 13:49:23.776127 19781 solver.cpp:252]     Train net output #0: loss = 5.56044 (* 1 = 5.56044 loss)
I0124 13:49:23.776151 19781 sgd_solver.cpp:106] Iteration 14680, lr = 1
I0124 13:49:29.111320 19781 solver.cpp:236] Iteration 14700, loss = 5.59766
I0124 13:49:29.111367 19781 solver.cpp:252]     Train net output #0: loss = 5.59766 (* 1 = 5.59766 loss)
I0124 13:49:29.111378 19781 sgd_solver.cpp:106] Iteration 14700, lr = 1
I0124 13:49:34.262262 19781 solver.cpp:236] Iteration 14720, loss = 5.74336
I0124 13:49:34.262311 19781 solver.cpp:252]     Train net output #0: loss = 5.74336 (* 1 = 5.74336 loss)
I0124 13:49:34.262320 19781 sgd_solver.cpp:106] Iteration 14720, lr = 1
I0124 13:49:39.189671 19781 solver.cpp:236] Iteration 14740, loss = 5.47648
I0124 13:49:39.189729 19781 solver.cpp:252]     Train net output #0: loss = 5.47648 (* 1 = 5.47648 loss)
I0124 13:49:39.189740 19781 sgd_solver.cpp:106] Iteration 14740, lr = 1
I0124 13:49:44.154117 19781 solver.cpp:236] Iteration 14760, loss = 5.72062
I0124 13:49:44.154302 19781 solver.cpp:252]     Train net output #0: loss = 5.72062 (* 1 = 5.72062 loss)
I0124 13:49:44.154330 19781 sgd_solver.cpp:106] Iteration 14760, lr = 1
I0124 13:49:49.139084 19781 solver.cpp:236] Iteration 14780, loss = 5.62746
I0124 13:49:49.139133 19781 solver.cpp:252]     Train net output #0: loss = 5.62746 (* 1 = 5.62746 loss)
I0124 13:49:49.139144 19781 sgd_solver.cpp:106] Iteration 14780, lr = 1
I0124 13:49:54.086839 19781 solver.cpp:236] Iteration 14800, loss = 5.49099
I0124 13:49:54.086890 19781 solver.cpp:252]     Train net output #0: loss = 5.49099 (* 1 = 5.49099 loss)
I0124 13:49:54.086900 19781 sgd_solver.cpp:106] Iteration 14800, lr = 1
I0124 13:49:59.137189 19781 solver.cpp:236] Iteration 14820, loss = 5.62598
I0124 13:49:59.137244 19781 solver.cpp:252]     Train net output #0: loss = 5.62598 (* 1 = 5.62598 loss)
I0124 13:49:59.137255 19781 sgd_solver.cpp:106] Iteration 14820, lr = 1
I0124 13:50:04.178073 19781 solver.cpp:236] Iteration 14840, loss = 5.44927
I0124 13:50:04.178128 19781 solver.cpp:252]     Train net output #0: loss = 5.44927 (* 1 = 5.44927 loss)
I0124 13:50:04.178139 19781 sgd_solver.cpp:106] Iteration 14840, lr = 1
I0124 13:50:09.721731 19781 solver.cpp:236] Iteration 14860, loss = 5.41429
I0124 13:50:09.721791 19781 solver.cpp:252]     Train net output #0: loss = 5.41429 (* 1 = 5.41429 loss)
I0124 13:50:09.721806 19781 sgd_solver.cpp:106] Iteration 14860, lr = 1
I0124 13:50:14.968333 19781 solver.cpp:236] Iteration 14880, loss = 5.88248
I0124 13:50:14.968619 19781 solver.cpp:252]     Train net output #0: loss = 5.88248 (* 1 = 5.88248 loss)
I0124 13:50:14.968639 19781 sgd_solver.cpp:106] Iteration 14880, lr = 1
I0124 13:50:19.647967 19781 solver.cpp:236] Iteration 14900, loss = 5.7828
I0124 13:50:19.648013 19781 solver.cpp:252]     Train net output #0: loss = 5.7828 (* 1 = 5.7828 loss)
I0124 13:50:19.648022 19781 sgd_solver.cpp:106] Iteration 14900, lr = 1
I0124 13:50:24.264039 19781 solver.cpp:236] Iteration 14920, loss = 6.02071
I0124 13:50:24.264092 19781 solver.cpp:252]     Train net output #0: loss = 6.02071 (* 1 = 6.02071 loss)
I0124 13:50:24.264103 19781 sgd_solver.cpp:106] Iteration 14920, lr = 1
I0124 13:50:28.893784 19781 solver.cpp:236] Iteration 14940, loss = 5.44171
I0124 13:50:28.893846 19781 solver.cpp:252]     Train net output #0: loss = 5.44171 (* 1 = 5.44171 loss)
I0124 13:50:28.893857 19781 sgd_solver.cpp:106] Iteration 14940, lr = 1
I0124 13:50:33.467051 19781 solver.cpp:236] Iteration 14960, loss = 5.43999
I0124 13:50:33.467102 19781 solver.cpp:252]     Train net output #0: loss = 5.43999 (* 1 = 5.43999 loss)
I0124 13:50:33.467111 19781 sgd_solver.cpp:106] Iteration 14960, lr = 1
I0124 13:50:38.154368 19781 solver.cpp:236] Iteration 14980, loss = 5.62173
I0124 13:50:38.154419 19781 solver.cpp:252]     Train net output #0: loss = 5.62173 (* 1 = 5.62173 loss)
I0124 13:50:38.154428 19781 sgd_solver.cpp:106] Iteration 14980, lr = 1
I0124 13:50:42.652324 19781 solver.cpp:340] Iteration 15000, Testing net (#0)
I0124 13:50:53.121817 19781 blocking_queue.cpp:50] Data layer prefetch queue empty
I0124 13:52:18.793016 19781 solver.cpp:408]     Test net output #0: accuracy = 0.0714203
I0124 13:52:18.793583 19781 solver.cpp:408]     Test net output #1: loss = 5.31826 (* 1 = 5.31826 loss)
I0124 13:52:18.831836 19781 solver.cpp:236] Iteration 15000, loss = 5.61181
I0124 13:52:18.831991 19781 solver.cpp:252]     Train net output #0: loss = 5.61181 (* 1 = 5.61181 loss)
I0124 13:52:18.832015 19781 sgd_solver.cpp:106] Iteration 15000, lr = 1
I0124 13:52:24.027444 19781 solver.cpp:236] Iteration 15020, loss = 5.51765
I0124 13:52:24.027495 19781 solver.cpp:252]     Train net output #0: loss = 5.51765 (* 1 = 5.51765 loss)
I0124 13:52:24.027510 19781 sgd_solver.cpp:106] Iteration 15020, lr = 1
I0124 13:52:28.871626 19781 solver.cpp:236] Iteration 15040, loss = 5.69111
I0124 13:52:28.871676 19781 solver.cpp:252]     Train net output #0: loss = 5.69111 (* 1 = 5.69111 loss)
I0124 13:52:28.871687 19781 sgd_solver.cpp:106] Iteration 15040, lr = 1
I0124 13:52:33.636044 19781 solver.cpp:236] Iteration 15060, loss = 5.66199
I0124 13:52:33.636101 19781 solver.cpp:252]     Train net output #0: loss = 5.66199 (* 1 = 5.66199 loss)
I0124 13:52:33.636113 19781 sgd_solver.cpp:106] Iteration 15060, lr = 1
I0124 13:52:38.425048 19781 solver.cpp:236] Iteration 15080, loss = 5.49234
I0124 13:52:38.425098 19781 solver.cpp:252]     Train net output #0: loss = 5.49234 (* 1 = 5.49234 loss)
I0124 13:52:38.425108 19781 sgd_solver.cpp:106] Iteration 15080, lr = 1
I0124 13:52:43.127645 19781 solver.cpp:236] Iteration 15100, loss = 5.68667
I0124 13:52:43.127697 19781 solver.cpp:252]     Train net output #0: loss = 5.68667 (* 1 = 5.68667 loss)
I0124 13:52:43.127708 19781 sgd_solver.cpp:106] Iteration 15100, lr = 1
I0124 13:52:43.129760 19781 blocking_queue.cpp:50] Data layer prefetch queue empty
I0124 13:52:47.856608 19781 solver.cpp:236] Iteration 15120, loss = 5.57487
I0124 13:52:47.856655 19781 solver.cpp:252]     Train net output #0: loss = 5.57487 (* 1 = 5.57487 loss)
I0124 13:52:47.856665 19781 sgd_solver.cpp:106] Iteration 15120, lr = 1
I0124 13:52:52.637527 19781 solver.cpp:236] Iteration 15140, loss = 5.41464
I0124 13:52:52.637848 19781 solver.cpp:252]     Train net output #0: loss = 5.41464 (* 1 = 5.41464 loss)
I0124 13:52:52.637869 19781 sgd_solver.cpp:106] Iteration 15140, lr = 1
I0124 13:52:57.433223 19781 solver.cpp:236] Iteration 15160, loss = 5.6338
I0124 13:52:57.433301 19781 solver.cpp:252]     Train net output #0: loss = 5.6338 (* 1 = 5.6338 loss)
I0124 13:52:57.433312 19781 sgd_solver.cpp:106] Iteration 15160, lr = 1
I0124 13:53:02.380931 19781 solver.cpp:236] Iteration 15180, loss = 5.57717
I0124 13:53:02.380995 19781 solver.cpp:252]     Train net output #0: loss = 5.57717 (* 1 = 5.57717 loss)
I0124 13:53:02.381006 19781 sgd_solver.cpp:106] Iteration 15180, lr = 1
I0124 13:53:07.413858 19781 solver.cpp:236] Iteration 15200, loss = 5.27447
I0124 13:53:07.413915 19781 solver.cpp:252]     Train net output #0: loss = 5.27447 (* 1 = 5.27447 loss)
I0124 13:53:07.413926 19781 sgd_solver.cpp:106] Iteration 15200, lr = 1
I0124 13:53:12.425850 19781 solver.cpp:236] Iteration 15220, loss = 5.5338
I0124 13:53:12.425909 19781 solver.cpp:252]     Train net output #0: loss = 5.5338 (* 1 = 5.5338 loss)
I0124 13:53:12.425920 19781 sgd_solver.cpp:106] Iteration 15220, lr = 1
I0124 13:53:16.786909 19781 solver.cpp:236] Iteration 15240, loss = 5.81474
I0124 13:53:16.786977 19781 solver.cpp:252]     Train net output #0: loss = 5.81474 (* 1 = 5.81474 loss)
I0124 13:53:16.786985 19781 sgd_solver.cpp:106] Iteration 15240, lr = 1
I0124 13:53:21.137660 19781 solver.cpp:236] Iteration 15260, loss = 5.38371
I0124 13:53:21.137719 19781 solver.cpp:252]     Train net output #0: loss = 5.38371 (* 1 = 5.38371 loss)
I0124 13:53:21.137730 19781 sgd_solver.cpp:106] Iteration 15260, lr = 1
I0124 13:53:25.563323 19781 solver.cpp:236] Iteration 15280, loss = 5.71811
I0124 13:53:25.563551 19781 solver.cpp:252]     Train net output #0: loss = 5.71811 (* 1 = 5.71811 loss)
I0124 13:53:25.563570 19781 sgd_solver.cpp:106] Iteration 15280, lr = 1
I0124 13:53:29.986464 19781 solver.cpp:236] Iteration 15300, loss = 5.75125
I0124 13:53:29.986521 19781 solver.cpp:252]     Train net output #0: loss = 5.75125 (* 1 = 5.75125 loss)
I0124 13:53:29.986531 19781 sgd_solver.cpp:106] Iteration 15300, lr = 1
I0124 13:53:34.522411 19781 solver.cpp:236] Iteration 15320, loss = 5.67784
I0124 13:53:34.522460 19781 solver.cpp:252]     Train net output #0: loss = 5.67784 (* 1 = 5.67784 loss)
I0124 13:53:34.522470 19781 sgd_solver.cpp:106] Iteration 15320, lr = 1
I0124 13:53:39.139020 19781 solver.cpp:236] Iteration 15340, loss = 5.30255
I0124 13:53:39.139070 19781 solver.cpp:252]     Train net output #0: loss = 5.30255 (* 1 = 5.30255 loss)
I0124 13:53:39.139080 19781 sgd_solver.cpp:106] Iteration 15340, lr = 1
I0124 13:53:43.763641 19781 solver.cpp:236] Iteration 15360, loss = 5.60384
I0124 13:53:43.763691 19781 solver.cpp:252]     Train net output #0: loss = 5.60384 (* 1 = 5.60384 loss)
I0124 13:53:43.763702 19781 sgd_solver.cpp:106] Iteration 15360, lr = 1
I0124 13:53:48.720926 19781 solver.cpp:236] Iteration 15380, loss = 5.64243
I0124 13:53:48.720978 19781 solver.cpp:252]     Train net output #0: loss = 5.64243 (* 1 = 5.64243 loss)
I0124 13:53:48.720985 19781 sgd_solver.cpp:106] Iteration 15380, lr = 1
I0124 13:53:53.900917 19781 solver.cpp:236] Iteration 15400, loss = 5.45794
I0124 13:53:53.900961 19781 solver.cpp:252]     Train net output #0: loss = 5.45794 (* 1 = 5.45794 loss)
I0124 13:53:53.900971 19781 sgd_solver.cpp:106] Iteration 15400, lr = 1
I0124 13:53:58.686105 19781 solver.cpp:236] Iteration 15420, loss = 5.61543
I0124 13:53:58.686266 19781 solver.cpp:252]     Train net output #0: loss = 5.61543 (* 1 = 5.61543 loss)
I0124 13:53:58.686276 19781 sgd_solver.cpp:106] Iteration 15420, lr = 1
I0124 13:54:03.406851 19781 solver.cpp:236] Iteration 15440, loss = 5.80875
I0124 13:54:03.406905 19781 solver.cpp:252]     Train net output #0: loss = 5.80875 (* 1 = 5.80875 loss)
I0124 13:54:03.406914 19781 sgd_solver.cpp:106] Iteration 15440, lr = 1
I0124 13:54:08.071255 19781 solver.cpp:236] Iteration 15460, loss = 5.5536
I0124 13:54:08.071310 19781 solver.cpp:252]     Train net output #0: loss = 5.5536 (* 1 = 5.5536 loss)
I0124 13:54:08.071322 19781 sgd_solver.cpp:106] Iteration 15460, lr = 1
I0124 13:54:12.712687 19781 solver.cpp:236] Iteration 15480, loss = 5.69199
I0124 13:54:12.712729 19781 solver.cpp:252]     Train net output #0: loss = 5.69199 (* 1 = 5.69199 loss)
I0124 13:54:12.712735 19781 sgd_solver.cpp:106] Iteration 15480, lr = 1
I0124 13:54:17.376441 19781 solver.cpp:236] Iteration 15500, loss = 5.70191
I0124 13:54:17.376482 19781 solver.cpp:252]     Train net output #0: loss = 5.70191 (* 1 = 5.70191 loss)
I0124 13:54:17.376489 19781 sgd_solver.cpp:106] Iteration 15500, lr = 1
I0124 13:54:22.111663 19781 solver.cpp:236] Iteration 15520, loss = 5.36397
I0124 13:54:22.111707 19781 solver.cpp:252]     Train net output #0: loss = 5.36397 (* 1 = 5.36397 loss)
I0124 13:54:22.111718 19781 sgd_solver.cpp:106] Iteration 15520, lr = 1
I0124 13:54:26.831190 19781 solver.cpp:236] Iteration 15540, loss = 5.59171
I0124 13:54:26.831238 19781 solver.cpp:252]     Train net output #0: loss = 5.59171 (* 1 = 5.59171 loss)
I0124 13:54:26.831250 19781 sgd_solver.cpp:106] Iteration 15540, lr = 1
I0124 13:54:31.103071 19781 solver.cpp:461] Snapshotting to binary proto file snapshots/caffenet128_lsuv_adadelta1e-7_iter_15557.caffemodel
I0124 13:54:33.078865 19781 sgd_solver.cpp:269] Snapshotting solver state to binary proto file snapshots/caffenet128_lsuv_adadelta1e-7_iter_15557.solverstate
I0124 13:54:41.598853 19781 solver.cpp:308] Optimization stopped early.
I0124 13:54:41.598899 19781 caffe.cpp:215] Optimization Done.
