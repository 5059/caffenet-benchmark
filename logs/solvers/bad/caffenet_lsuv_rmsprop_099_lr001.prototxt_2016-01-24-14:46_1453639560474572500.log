I0124 14:46:43.651161 32597 caffe.cpp:184] Using GPUs 0
I0124 14:46:43.804031 32597 solver.cpp:48] Initializing solver from parameters: 
test_iter: 200
test_interval: 2000
base_lr: 0.01
display: 20
max_iter: 320000
lr_policy: "step"
weight_decay: 0.0005
stepsize: 100000
snapshot: 10000
snapshot_prefix: "snapshots1/caffenet128_rmsprop"
solver_mode: GPU
device_id: 0
net_param {
  name: "CaffeNet"
  layer {
    name: "data"
    type: "Data"
    top: "data"
    top: "label"
    include {
      phase: TRAIN
    }
    transform_param {
      scale: 0.04
      mirror: true
      crop_size: 128
      mean_value: 104
      mean_value: 117
      mean_value: 124
      force_color: true
      resize_param {
        prob: 1
        resize_mode: FIT_SMALL_SIZE
        height: 144
        width: 144
        pad_mode: MIRRORED
        pad_value: 104
        pad_value: 117
        pad_value: 124
        interp_mode: LINEAR
        center_object: false
        max_angle: 0
      }
    }
    data_param {
      source: "/home/old-ufo/datasets/imagenet/ilsvrc12_train_shuffle_lmdb"
      batch_size: 256
      backend: LMDB
    }
  }
  layer {
    name: "data"
    type: "Data"
    top: "data"
    top: "label"
    include {
      phase: TEST
    }
    transform_param {
      scale: 0.04
      mirror: false
      crop_size: 128
      mean_value: 104
      mean_value: 117
      mean_value: 123
      force_color: true
      resize_param {
        prob: 1
        resize_mode: FIT_SMALL_SIZE
        height: 144
        width: 144
        pad_mode: MIRRORED
        pad_value: 104
        pad_value: 117
        pad_value: 124
        interp_mode: LINEAR
        center_object: false
        max_angle: 0
      }
    }
    data_param {
      source: "/home/old-ufo/datasets/imagenet/ilsvrc12_val_lmdb"
      batch_size: 250
      backend: LMDB
    }
  }
  layer {
    name: "conv1"
    type: "Convolution"
    bottom: "data"
    top: "conv1"
    param {
      lr_mult: 1
      decay_mult: 1
    }
    param {
      lr_mult: 2
      decay_mult: 0
    }
    convolution_param {
      num_output: 96
      kernel_size: 11
      stride: 4
      weight_filler {
        type: "gaussian"
        std: 0.01
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layer {
    name: "relu1"
    type: "ReLU"
    bottom: "conv1"
    top: "relu1"
  }
  layer {
    name: "pool1"
    type: "Pooling"
    bottom: "relu1"
    top: "pool1"
    pooling_param {
      pool: MAX
      kernel_size: 3
      stride: 2
    }
  }
  layer {
    name: "conv2"
    type: "Convolution"
    bottom: "pool1"
    top: "conv2"
    param {
      lr_mult: 1
      decay_mult: 1
    }
    param {
      lr_mult: 2
      decay_mult: 0
    }
    convolution_param {
      num_output: 256
      pad: 2
      kernel_size: 5
      group: 2
      weight_filler {
        type: "gaussian"
        std: 0.01
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layer {
    name: "relu2"
    type: "ReLU"
    bottom: "conv2"
    top: "conv2"
  }
  layer {
    name: "pool2"
    type: "Pooling"
    bottom: "conv2"
    top: "pool2"
    pooling_param {
      pool: MAX
      kernel_size: 3
      stride: 2
    }
  }
  layer {
    name: "conv3"
    type: "Convolution"
    bottom: "pool2"
    top: "conv3"
    param {
      lr_mult: 1
      decay_mult: 1
    }
    param {
      lr_mult: 2
      decay_mult: 0
    }
    convolution_param {
      num_output: 384
      pad: 1
      kernel_size: 3
      weight_filler {
        type: "gaussian"
        std: 0.01
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layer {
    name: "relu3"
    type: "ReLU"
    bottom: "conv3"
    top: "conv3"
  }
  layer {
    name: "conv4"
    type: "Convolution"
    bottom: "conv3"
    top: "conv4"
    param {
      lr_mult: 1
      decay_mult: 1
    }
    param {
      lr_mult: 2
      decay_mult: 0
    }
    convolution_param {
      num_output: 384
      pad: 1
      kernel_size: 3
      group: 2
      weight_filler {
        type: "gaussian"
        std: 0.01
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layer {
    name: "relu4"
    type: "ReLU"
    bottom: "conv4"
    top: "conv4"
  }
  layer {
    name: "conv5"
    type: "Convolution"
    bottom: "conv4"
    top: "conv5"
    param {
      lr_mult: 1
      decay_mult: 1
    }
    param {
      lr_mult: 2
      decay_mult: 0
    }
    convolution_param {
      num_output: 256
      pad: 1
      kernel_size: 3
      group: 2
      weight_filler {
        type: "gaussian"
        std: 0.01
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layer {
    name: "relu5"
    type: "ReLU"
    bottom: "conv5"
    top: "conv5"
  }
  layer {
    name: "pool5"
    type: "Pooling"
    bottom: "conv5"
    top: "pool5"
    pooling_param {
      pool: MAX
      kernel_size: 3
      stride: 2
    }
  }
  layer {
    name: "fc6"
    type: "InnerProduct"
    bottom: "pool5"
    top: "fc6"
    param {
      lr_mult: 1
      decay_mult: 1
    }
    param {
      lr_mult: 2
      decay_mult: 0
    }
    inner_product_param {
      num_output: 2048
      weight_filler {
        type: "gaussian"
        std: 0.005
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layer {
    name: "relu6"
    type: "ReLU"
    bottom: "fc6"
    top: "fc6"
  }
  layer {
    name: "drop6"
    type: "Dropout"
    bottom: "fc6"
    top: "fc6"
    dropout_param {
      dropout_ratio: 0.5
    }
  }
  layer {
    name: "fc7"
    type: "InnerProduct"
    bottom: "fc6"
    top: "fc7"
    param {
      lr_mult: 1
      decay_mult: 1
    }
    param {
      lr_mult: 2
      decay_mult: 0
    }
    inner_product_param {
      num_output: 2048
      weight_filler {
        type: "gaussian"
        std: 0.005
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layer {
    name: "relu7"
    type: "ReLU"
    bottom: "fc7"
    top: "fc7"
  }
  layer {
    name: "drop7"
    type: "Dropout"
    bottom: "fc7"
    top: "fc7"
    dropout_param {
      dropout_ratio: 0.5
    }
  }
  layer {
    name: "fc8"
    type: "InnerProduct"
    bottom: "fc7"
    top: "fc8"
    param {
      lr_mult: 1
      decay_mult: 1
    }
    param {
      lr_mult: 2
      decay_mult: 0
    }
    inner_product_param {
      num_output: 1000
      weight_filler {
        type: "gaussian"
        std: 0.01
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layer {
    name: "accuracy"
    type: "Accuracy"
    bottom: "fc8"
    bottom: "label"
    top: "accuracy"
    include {
      phase: TEST
    }
  }
  layer {
    name: "loss"
    type: "SoftmaxWithLoss"
    bottom: "fc8"
    bottom: "label"
    top: "loss"
  }
}
test_initialization: false
average_loss: 20
iter_size: 1
rms_decay: 0.99
type: "RMSProp"
I0124 14:46:44.235843 32597 solver.cpp:86] Creating training net specified in net_param.
I0124 14:46:44.236011 32597 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0124 14:46:44.236049 32597 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0124 14:46:44.236270 32597 net.cpp:49] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.04
    mirror: true
    crop_size: 128
    mean_value: 104
    mean_value: 117
    mean_value: 124
    force_color: true
    resize_param {
      prob: 1
      resize_mode: FIT_SMALL_SIZE
      height: 144
      width: 144
      pad_mode: MIRRORED
      pad_value: 104
      pad_value: 117
      pad_value: 124
      interp_mode: LINEAR
      center_object: false
      max_angle: 0
    }
  }
  data_param {
    source: "/home/old-ufo/datasets/imagenet/ilsvrc12_train_shuffle_lmdb"
    batch_size: 256
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "relu1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "relu1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0124 14:46:44.236405 32597 layer_factory.hpp:76] Creating layer data
I0124 14:46:44.237310 32597 net.cpp:106] Creating Layer data
I0124 14:46:44.237329 32597 net.cpp:411] data -> data
I0124 14:46:44.237371 32597 net.cpp:411] data -> label
I0124 14:46:44.238008 32605 db_lmdb.cpp:38] Opened lmdb /home/old-ufo/datasets/imagenet/ilsvrc12_train_shuffle_lmdb
I0124 14:46:44.256014 32597 data_layer.cpp:41] output data size: 256,3,128,128
I0124 14:46:44.328255 32597 net.cpp:150] Setting up data
I0124 14:46:44.328289 32597 net.cpp:157] Top shape: 256 3 128 128 (12582912)
I0124 14:46:44.328296 32597 net.cpp:157] Top shape: 256 (256)
I0124 14:46:44.328299 32597 net.cpp:165] Memory required for data: 50332672
I0124 14:46:44.328311 32597 layer_factory.hpp:76] Creating layer conv1
I0124 14:46:44.328330 32597 net.cpp:106] Creating Layer conv1
I0124 14:46:44.328336 32597 net.cpp:454] conv1 <- data
I0124 14:46:44.328349 32597 net.cpp:411] conv1 -> conv1
I0124 14:46:44.487200 32597 net.cpp:150] Setting up conv1
I0124 14:46:44.487226 32597 net.cpp:157] Top shape: 256 96 30 30 (22118400)
I0124 14:46:44.487229 32597 net.cpp:165] Memory required for data: 138806272
I0124 14:46:44.487247 32597 layer_factory.hpp:76] Creating layer relu1
I0124 14:46:44.487262 32597 net.cpp:106] Creating Layer relu1
I0124 14:46:44.487269 32597 net.cpp:454] relu1 <- conv1
I0124 14:46:44.487277 32597 net.cpp:411] relu1 -> relu1
I0124 14:46:44.487821 32597 net.cpp:150] Setting up relu1
I0124 14:46:44.487831 32597 net.cpp:157] Top shape: 256 96 30 30 (22118400)
I0124 14:46:44.487834 32597 net.cpp:165] Memory required for data: 227279872
I0124 14:46:44.487838 32597 layer_factory.hpp:76] Creating layer pool1
I0124 14:46:44.487844 32597 net.cpp:106] Creating Layer pool1
I0124 14:46:44.487848 32597 net.cpp:454] pool1 <- relu1
I0124 14:46:44.487854 32597 net.cpp:411] pool1 -> pool1
I0124 14:46:44.488380 32597 net.cpp:150] Setting up pool1
I0124 14:46:44.488390 32597 net.cpp:157] Top shape: 256 96 15 15 (5529600)
I0124 14:46:44.488394 32597 net.cpp:165] Memory required for data: 249398272
I0124 14:46:44.488396 32597 layer_factory.hpp:76] Creating layer conv2
I0124 14:46:44.488407 32597 net.cpp:106] Creating Layer conv2
I0124 14:46:44.488412 32597 net.cpp:454] conv2 <- pool1
I0124 14:46:44.488418 32597 net.cpp:411] conv2 -> conv2
I0124 14:46:44.499969 32597 net.cpp:150] Setting up conv2
I0124 14:46:44.499990 32597 net.cpp:157] Top shape: 256 256 15 15 (14745600)
I0124 14:46:44.499994 32597 net.cpp:165] Memory required for data: 308380672
I0124 14:46:44.500005 32597 layer_factory.hpp:76] Creating layer relu2
I0124 14:46:44.500016 32597 net.cpp:106] Creating Layer relu2
I0124 14:46:44.500021 32597 net.cpp:454] relu2 <- conv2
I0124 14:46:44.500030 32597 net.cpp:397] relu2 -> conv2 (in-place)
I0124 14:46:44.500540 32597 net.cpp:150] Setting up relu2
I0124 14:46:44.500548 32597 net.cpp:157] Top shape: 256 256 15 15 (14745600)
I0124 14:46:44.500551 32597 net.cpp:165] Memory required for data: 367363072
I0124 14:46:44.500555 32597 layer_factory.hpp:76] Creating layer pool2
I0124 14:46:44.500562 32597 net.cpp:106] Creating Layer pool2
I0124 14:46:44.500566 32597 net.cpp:454] pool2 <- conv2
I0124 14:46:44.500572 32597 net.cpp:411] pool2 -> pool2
I0124 14:46:44.501248 32597 net.cpp:150] Setting up pool2
I0124 14:46:44.501260 32597 net.cpp:157] Top shape: 256 256 7 7 (3211264)
I0124 14:46:44.501262 32597 net.cpp:165] Memory required for data: 380208128
I0124 14:46:44.501266 32597 layer_factory.hpp:76] Creating layer conv3
I0124 14:46:44.501273 32597 net.cpp:106] Creating Layer conv3
I0124 14:46:44.501276 32597 net.cpp:454] conv3 <- pool2
I0124 14:46:44.501281 32597 net.cpp:411] conv3 -> conv3
I0124 14:46:44.526711 32597 net.cpp:150] Setting up conv3
I0124 14:46:44.526734 32597 net.cpp:157] Top shape: 256 384 7 7 (4816896)
I0124 14:46:44.526738 32597 net.cpp:165] Memory required for data: 399475712
I0124 14:46:44.526749 32597 layer_factory.hpp:76] Creating layer relu3
I0124 14:46:44.526760 32597 net.cpp:106] Creating Layer relu3
I0124 14:46:44.526765 32597 net.cpp:454] relu3 <- conv3
I0124 14:46:44.526772 32597 net.cpp:397] relu3 -> conv3 (in-place)
I0124 14:46:44.527288 32597 net.cpp:150] Setting up relu3
I0124 14:46:44.527298 32597 net.cpp:157] Top shape: 256 384 7 7 (4816896)
I0124 14:46:44.527300 32597 net.cpp:165] Memory required for data: 418743296
I0124 14:46:44.527326 32597 layer_factory.hpp:76] Creating layer conv4
I0124 14:46:44.527338 32597 net.cpp:106] Creating Layer conv4
I0124 14:46:44.527343 32597 net.cpp:454] conv4 <- conv3
I0124 14:46:44.527349 32597 net.cpp:411] conv4 -> conv4
I0124 14:46:44.548388 32597 net.cpp:150] Setting up conv4
I0124 14:46:44.548414 32597 net.cpp:157] Top shape: 256 384 7 7 (4816896)
I0124 14:46:44.548418 32597 net.cpp:165] Memory required for data: 438010880
I0124 14:46:44.548430 32597 layer_factory.hpp:76] Creating layer relu4
I0124 14:46:44.548441 32597 net.cpp:106] Creating Layer relu4
I0124 14:46:44.548446 32597 net.cpp:454] relu4 <- conv4
I0124 14:46:44.548454 32597 net.cpp:397] relu4 -> conv4 (in-place)
I0124 14:46:44.549170 32597 net.cpp:150] Setting up relu4
I0124 14:46:44.549182 32597 net.cpp:157] Top shape: 256 384 7 7 (4816896)
I0124 14:46:44.549186 32597 net.cpp:165] Memory required for data: 457278464
I0124 14:46:44.549190 32597 layer_factory.hpp:76] Creating layer conv5
I0124 14:46:44.549202 32597 net.cpp:106] Creating Layer conv5
I0124 14:46:44.549208 32597 net.cpp:454] conv5 <- conv4
I0124 14:46:44.549216 32597 net.cpp:411] conv5 -> conv5
I0124 14:46:44.566256 32597 net.cpp:150] Setting up conv5
I0124 14:46:44.566277 32597 net.cpp:157] Top shape: 256 256 7 7 (3211264)
I0124 14:46:44.566279 32597 net.cpp:165] Memory required for data: 470123520
I0124 14:46:44.566292 32597 layer_factory.hpp:76] Creating layer relu5
I0124 14:46:44.566303 32597 net.cpp:106] Creating Layer relu5
I0124 14:46:44.566308 32597 net.cpp:454] relu5 <- conv5
I0124 14:46:44.566313 32597 net.cpp:397] relu5 -> conv5 (in-place)
I0124 14:46:44.566860 32597 net.cpp:150] Setting up relu5
I0124 14:46:44.566870 32597 net.cpp:157] Top shape: 256 256 7 7 (3211264)
I0124 14:46:44.566874 32597 net.cpp:165] Memory required for data: 482968576
I0124 14:46:44.566876 32597 layer_factory.hpp:76] Creating layer pool5
I0124 14:46:44.566884 32597 net.cpp:106] Creating Layer pool5
I0124 14:46:44.566887 32597 net.cpp:454] pool5 <- conv5
I0124 14:46:44.566893 32597 net.cpp:411] pool5 -> pool5
I0124 14:46:44.567481 32597 net.cpp:150] Setting up pool5
I0124 14:46:44.567490 32597 net.cpp:157] Top shape: 256 256 3 3 (589824)
I0124 14:46:44.567493 32597 net.cpp:165] Memory required for data: 485327872
I0124 14:46:44.567497 32597 layer_factory.hpp:76] Creating layer fc6
I0124 14:46:44.567504 32597 net.cpp:106] Creating Layer fc6
I0124 14:46:44.567508 32597 net.cpp:454] fc6 <- pool5
I0124 14:46:44.567517 32597 net.cpp:411] fc6 -> fc6
I0124 14:46:44.692493 32597 net.cpp:150] Setting up fc6
I0124 14:46:44.692517 32597 net.cpp:157] Top shape: 256 2048 (524288)
I0124 14:46:44.692519 32597 net.cpp:165] Memory required for data: 487425024
I0124 14:46:44.692528 32597 layer_factory.hpp:76] Creating layer relu6
I0124 14:46:44.692538 32597 net.cpp:106] Creating Layer relu6
I0124 14:46:44.692543 32597 net.cpp:454] relu6 <- fc6
I0124 14:46:44.692550 32597 net.cpp:397] relu6 -> fc6 (in-place)
I0124 14:46:44.693189 32597 net.cpp:150] Setting up relu6
I0124 14:46:44.693198 32597 net.cpp:157] Top shape: 256 2048 (524288)
I0124 14:46:44.693202 32597 net.cpp:165] Memory required for data: 489522176
I0124 14:46:44.693204 32597 layer_factory.hpp:76] Creating layer drop6
I0124 14:46:44.693225 32597 net.cpp:106] Creating Layer drop6
I0124 14:46:44.693230 32597 net.cpp:454] drop6 <- fc6
I0124 14:46:44.693236 32597 net.cpp:397] drop6 -> fc6 (in-place)
I0124 14:46:44.693270 32597 net.cpp:150] Setting up drop6
I0124 14:46:44.693277 32597 net.cpp:157] Top shape: 256 2048 (524288)
I0124 14:46:44.693279 32597 net.cpp:165] Memory required for data: 491619328
I0124 14:46:44.693282 32597 layer_factory.hpp:76] Creating layer fc7
I0124 14:46:44.693290 32597 net.cpp:106] Creating Layer fc7
I0124 14:46:44.693295 32597 net.cpp:454] fc7 <- fc6
I0124 14:46:44.693302 32597 net.cpp:411] fc7 -> fc7
I0124 14:46:44.802498 32597 net.cpp:150] Setting up fc7
I0124 14:46:44.802522 32597 net.cpp:157] Top shape: 256 2048 (524288)
I0124 14:46:44.802525 32597 net.cpp:165] Memory required for data: 493716480
I0124 14:46:44.802557 32597 layer_factory.hpp:76] Creating layer relu7
I0124 14:46:44.802568 32597 net.cpp:106] Creating Layer relu7
I0124 14:46:44.802573 32597 net.cpp:454] relu7 <- fc7
I0124 14:46:44.802579 32597 net.cpp:397] relu7 -> fc7 (in-place)
I0124 14:46:44.803239 32597 net.cpp:150] Setting up relu7
I0124 14:46:44.803251 32597 net.cpp:157] Top shape: 256 2048 (524288)
I0124 14:46:44.803253 32597 net.cpp:165] Memory required for data: 495813632
I0124 14:46:44.803256 32597 layer_factory.hpp:76] Creating layer drop7
I0124 14:46:44.803264 32597 net.cpp:106] Creating Layer drop7
I0124 14:46:44.803267 32597 net.cpp:454] drop7 <- fc7
I0124 14:46:44.803272 32597 net.cpp:397] drop7 -> fc7 (in-place)
I0124 14:46:44.803306 32597 net.cpp:150] Setting up drop7
I0124 14:46:44.803313 32597 net.cpp:157] Top shape: 256 2048 (524288)
I0124 14:46:44.803314 32597 net.cpp:165] Memory required for data: 497910784
I0124 14:46:44.803318 32597 layer_factory.hpp:76] Creating layer fc8
I0124 14:46:44.803328 32597 net.cpp:106] Creating Layer fc8
I0124 14:46:44.803331 32597 net.cpp:454] fc8 <- fc7
I0124 14:46:44.803339 32597 net.cpp:411] fc8 -> fc8
I0124 14:46:44.857367 32597 net.cpp:150] Setting up fc8
I0124 14:46:44.857393 32597 net.cpp:157] Top shape: 256 1000 (256000)
I0124 14:46:44.857395 32597 net.cpp:165] Memory required for data: 498934784
I0124 14:46:44.857404 32597 layer_factory.hpp:76] Creating layer loss
I0124 14:46:44.857412 32597 net.cpp:106] Creating Layer loss
I0124 14:46:44.857416 32597 net.cpp:454] loss <- fc8
I0124 14:46:44.857422 32597 net.cpp:454] loss <- label
I0124 14:46:44.857430 32597 net.cpp:411] loss -> loss
I0124 14:46:44.857440 32597 layer_factory.hpp:76] Creating layer loss
I0124 14:46:44.859020 32597 net.cpp:150] Setting up loss
I0124 14:46:44.859036 32597 net.cpp:157] Top shape: (1)
I0124 14:46:44.859040 32597 net.cpp:160]     with loss weight 1
I0124 14:46:44.859053 32597 net.cpp:165] Memory required for data: 498934788
I0124 14:46:44.859056 32597 net.cpp:226] loss needs backward computation.
I0124 14:46:44.859061 32597 net.cpp:226] fc8 needs backward computation.
I0124 14:46:44.859062 32597 net.cpp:226] drop7 needs backward computation.
I0124 14:46:44.859064 32597 net.cpp:226] relu7 needs backward computation.
I0124 14:46:44.859066 32597 net.cpp:226] fc7 needs backward computation.
I0124 14:46:44.859069 32597 net.cpp:226] drop6 needs backward computation.
I0124 14:46:44.859071 32597 net.cpp:226] relu6 needs backward computation.
I0124 14:46:44.859073 32597 net.cpp:226] fc6 needs backward computation.
I0124 14:46:44.859076 32597 net.cpp:226] pool5 needs backward computation.
I0124 14:46:44.859079 32597 net.cpp:226] relu5 needs backward computation.
I0124 14:46:44.859081 32597 net.cpp:226] conv5 needs backward computation.
I0124 14:46:44.859083 32597 net.cpp:226] relu4 needs backward computation.
I0124 14:46:44.859086 32597 net.cpp:226] conv4 needs backward computation.
I0124 14:46:44.859087 32597 net.cpp:226] relu3 needs backward computation.
I0124 14:46:44.859091 32597 net.cpp:226] conv3 needs backward computation.
I0124 14:46:44.859092 32597 net.cpp:226] pool2 needs backward computation.
I0124 14:46:44.859096 32597 net.cpp:226] relu2 needs backward computation.
I0124 14:46:44.859097 32597 net.cpp:226] conv2 needs backward computation.
I0124 14:46:44.859099 32597 net.cpp:226] pool1 needs backward computation.
I0124 14:46:44.859102 32597 net.cpp:226] relu1 needs backward computation.
I0124 14:46:44.859104 32597 net.cpp:226] conv1 needs backward computation.
I0124 14:46:44.859107 32597 net.cpp:228] data does not need backward computation.
I0124 14:46:44.859109 32597 net.cpp:270] This network produces output loss
I0124 14:46:44.859120 32597 net.cpp:283] Network initialization done.
I0124 14:46:44.859200 32597 solver.cpp:181] Creating test net (#0) specified by net_param
I0124 14:46:44.859227 32597 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0124 14:46:44.859362 32597 net.cpp:49] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.04
    mirror: false
    crop_size: 128
    mean_value: 104
    mean_value: 117
    mean_value: 123
    force_color: true
    resize_param {
      prob: 1
      resize_mode: FIT_SMALL_SIZE
      height: 144
      width: 144
      pad_mode: MIRRORED
      pad_value: 104
      pad_value: 117
      pad_value: 124
      interp_mode: LINEAR
      center_object: false
      max_angle: 0
    }
  }
  data_param {
    source: "/home/old-ufo/datasets/imagenet/ilsvrc12_val_lmdb"
    batch_size: 250
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "relu1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "relu1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0124 14:46:44.859467 32597 layer_factory.hpp:76] Creating layer data
I0124 14:46:44.859715 32597 net.cpp:106] Creating Layer data
I0124 14:46:44.859726 32597 net.cpp:411] data -> data
I0124 14:46:44.859736 32597 net.cpp:411] data -> label
I0124 14:46:44.860474 32614 db_lmdb.cpp:38] Opened lmdb /home/old-ufo/datasets/imagenet/ilsvrc12_val_lmdb
I0124 14:46:44.867348 32597 data_layer.cpp:41] output data size: 250,3,128,128
I0124 14:46:44.938760 32597 net.cpp:150] Setting up data
I0124 14:46:44.938796 32597 net.cpp:157] Top shape: 250 3 128 128 (12288000)
I0124 14:46:44.938807 32597 net.cpp:157] Top shape: 250 (250)
I0124 14:46:44.938812 32597 net.cpp:165] Memory required for data: 49153000
I0124 14:46:44.938820 32597 layer_factory.hpp:76] Creating layer label_data_1_split
I0124 14:46:44.938835 32597 net.cpp:106] Creating Layer label_data_1_split
I0124 14:46:44.938841 32597 net.cpp:454] label_data_1_split <- label
I0124 14:46:44.938850 32597 net.cpp:411] label_data_1_split -> label_data_1_split_0
I0124 14:46:44.938863 32597 net.cpp:411] label_data_1_split -> label_data_1_split_1
I0124 14:46:44.939064 32597 net.cpp:150] Setting up label_data_1_split
I0124 14:46:44.939079 32597 net.cpp:157] Top shape: 250 (250)
I0124 14:46:44.939085 32597 net.cpp:157] Top shape: 250 (250)
I0124 14:46:44.939087 32597 net.cpp:165] Memory required for data: 49155000
I0124 14:46:44.939092 32597 layer_factory.hpp:76] Creating layer conv1
I0124 14:46:44.939105 32597 net.cpp:106] Creating Layer conv1
I0124 14:46:44.939110 32597 net.cpp:454] conv1 <- data
I0124 14:46:44.939117 32597 net.cpp:411] conv1 -> conv1
I0124 14:46:44.947844 32597 net.cpp:150] Setting up conv1
I0124 14:46:44.947875 32597 net.cpp:157] Top shape: 250 96 30 30 (21600000)
I0124 14:46:44.947880 32597 net.cpp:165] Memory required for data: 135555000
I0124 14:46:44.947895 32597 layer_factory.hpp:76] Creating layer relu1
I0124 14:46:44.947906 32597 net.cpp:106] Creating Layer relu1
I0124 14:46:44.947911 32597 net.cpp:454] relu1 <- conv1
I0124 14:46:44.947919 32597 net.cpp:411] relu1 -> relu1
I0124 14:46:44.948876 32597 net.cpp:150] Setting up relu1
I0124 14:46:44.948890 32597 net.cpp:157] Top shape: 250 96 30 30 (21600000)
I0124 14:46:44.948896 32597 net.cpp:165] Memory required for data: 221955000
I0124 14:46:44.948901 32597 layer_factory.hpp:76] Creating layer pool1
I0124 14:46:44.948911 32597 net.cpp:106] Creating Layer pool1
I0124 14:46:44.948915 32597 net.cpp:454] pool1 <- relu1
I0124 14:46:44.948921 32597 net.cpp:411] pool1 -> pool1
I0124 14:46:44.949820 32597 net.cpp:150] Setting up pool1
I0124 14:46:44.949836 32597 net.cpp:157] Top shape: 250 96 15 15 (5400000)
I0124 14:46:44.949841 32597 net.cpp:165] Memory required for data: 243555000
I0124 14:46:44.949846 32597 layer_factory.hpp:76] Creating layer conv2
I0124 14:46:44.949859 32597 net.cpp:106] Creating Layer conv2
I0124 14:46:44.949868 32597 net.cpp:454] conv2 <- pool1
I0124 14:46:44.949915 32597 net.cpp:411] conv2 -> conv2
I0124 14:46:44.962967 32597 net.cpp:150] Setting up conv2
I0124 14:46:44.963001 32597 net.cpp:157] Top shape: 250 256 15 15 (14400000)
I0124 14:46:44.963006 32597 net.cpp:165] Memory required for data: 301155000
I0124 14:46:44.963022 32597 layer_factory.hpp:76] Creating layer relu2
I0124 14:46:44.963034 32597 net.cpp:106] Creating Layer relu2
I0124 14:46:44.963063 32597 net.cpp:454] relu2 <- conv2
I0124 14:46:44.963071 32597 net.cpp:397] relu2 -> conv2 (in-place)
I0124 14:46:44.963852 32597 net.cpp:150] Setting up relu2
I0124 14:46:44.963865 32597 net.cpp:157] Top shape: 250 256 15 15 (14400000)
I0124 14:46:44.963868 32597 net.cpp:165] Memory required for data: 358755000
I0124 14:46:44.963872 32597 layer_factory.hpp:76] Creating layer pool2
I0124 14:46:44.963886 32597 net.cpp:106] Creating Layer pool2
I0124 14:46:44.963891 32597 net.cpp:454] pool2 <- conv2
I0124 14:46:44.963897 32597 net.cpp:411] pool2 -> pool2
I0124 14:46:44.965119 32597 net.cpp:150] Setting up pool2
I0124 14:46:44.965139 32597 net.cpp:157] Top shape: 250 256 7 7 (3136000)
I0124 14:46:44.965143 32597 net.cpp:165] Memory required for data: 371299000
I0124 14:46:44.965148 32597 layer_factory.hpp:76] Creating layer conv3
I0124 14:46:44.965164 32597 net.cpp:106] Creating Layer conv3
I0124 14:46:44.965170 32597 net.cpp:454] conv3 <- pool2
I0124 14:46:44.965179 32597 net.cpp:411] conv3 -> conv3
I0124 14:46:44.991111 32597 net.cpp:150] Setting up conv3
I0124 14:46:44.991137 32597 net.cpp:157] Top shape: 250 384 7 7 (4704000)
I0124 14:46:44.991140 32597 net.cpp:165] Memory required for data: 390115000
I0124 14:46:44.991153 32597 layer_factory.hpp:76] Creating layer relu3
I0124 14:46:44.991165 32597 net.cpp:106] Creating Layer relu3
I0124 14:46:44.991170 32597 net.cpp:454] relu3 <- conv3
I0124 14:46:44.991179 32597 net.cpp:397] relu3 -> conv3 (in-place)
I0124 14:46:44.991832 32597 net.cpp:150] Setting up relu3
I0124 14:46:44.991847 32597 net.cpp:157] Top shape: 250 384 7 7 (4704000)
I0124 14:46:44.991852 32597 net.cpp:165] Memory required for data: 408931000
I0124 14:46:44.991858 32597 layer_factory.hpp:76] Creating layer conv4
I0124 14:46:44.991873 32597 net.cpp:106] Creating Layer conv4
I0124 14:46:44.991878 32597 net.cpp:454] conv4 <- conv3
I0124 14:46:44.991886 32597 net.cpp:411] conv4 -> conv4
I0124 14:46:45.014485 32597 net.cpp:150] Setting up conv4
I0124 14:46:45.014509 32597 net.cpp:157] Top shape: 250 384 7 7 (4704000)
I0124 14:46:45.014513 32597 net.cpp:165] Memory required for data: 427747000
I0124 14:46:45.014523 32597 layer_factory.hpp:76] Creating layer relu4
I0124 14:46:45.014535 32597 net.cpp:106] Creating Layer relu4
I0124 14:46:45.014541 32597 net.cpp:454] relu4 <- conv4
I0124 14:46:45.014549 32597 net.cpp:397] relu4 -> conv4 (in-place)
I0124 14:46:45.015157 32597 net.cpp:150] Setting up relu4
I0124 14:46:45.015172 32597 net.cpp:157] Top shape: 250 384 7 7 (4704000)
I0124 14:46:45.015174 32597 net.cpp:165] Memory required for data: 446563000
I0124 14:46:45.015179 32597 layer_factory.hpp:76] Creating layer conv5
I0124 14:46:45.015190 32597 net.cpp:106] Creating Layer conv5
I0124 14:46:45.015195 32597 net.cpp:454] conv5 <- conv4
I0124 14:46:45.015205 32597 net.cpp:411] conv5 -> conv5
I0124 14:46:45.032105 32597 net.cpp:150] Setting up conv5
I0124 14:46:45.032138 32597 net.cpp:157] Top shape: 250 256 7 7 (3136000)
I0124 14:46:45.032142 32597 net.cpp:165] Memory required for data: 459107000
I0124 14:46:45.032156 32597 layer_factory.hpp:76] Creating layer relu5
I0124 14:46:45.032166 32597 net.cpp:106] Creating Layer relu5
I0124 14:46:45.032172 32597 net.cpp:454] relu5 <- conv5
I0124 14:46:45.032179 32597 net.cpp:397] relu5 -> conv5 (in-place)
I0124 14:46:45.032829 32597 net.cpp:150] Setting up relu5
I0124 14:46:45.032840 32597 net.cpp:157] Top shape: 250 256 7 7 (3136000)
I0124 14:46:45.032843 32597 net.cpp:165] Memory required for data: 471651000
I0124 14:46:45.032846 32597 layer_factory.hpp:76] Creating layer pool5
I0124 14:46:45.032855 32597 net.cpp:106] Creating Layer pool5
I0124 14:46:45.032857 32597 net.cpp:454] pool5 <- conv5
I0124 14:46:45.032866 32597 net.cpp:411] pool5 -> pool5
I0124 14:46:45.033514 32597 net.cpp:150] Setting up pool5
I0124 14:46:45.033525 32597 net.cpp:157] Top shape: 250 256 3 3 (576000)
I0124 14:46:45.033527 32597 net.cpp:165] Memory required for data: 473955000
I0124 14:46:45.033530 32597 layer_factory.hpp:76] Creating layer fc6
I0124 14:46:45.033560 32597 net.cpp:106] Creating Layer fc6
I0124 14:46:45.033566 32597 net.cpp:454] fc6 <- pool5
I0124 14:46:45.033574 32597 net.cpp:411] fc6 -> fc6
I0124 14:46:45.159975 32597 net.cpp:150] Setting up fc6
I0124 14:46:45.159998 32597 net.cpp:157] Top shape: 250 2048 (512000)
I0124 14:46:45.160002 32597 net.cpp:165] Memory required for data: 476003000
I0124 14:46:45.160012 32597 layer_factory.hpp:76] Creating layer relu6
I0124 14:46:45.160024 32597 net.cpp:106] Creating Layer relu6
I0124 14:46:45.160032 32597 net.cpp:454] relu6 <- fc6
I0124 14:46:45.160040 32597 net.cpp:397] relu6 -> fc6 (in-place)
I0124 14:46:45.161063 32597 net.cpp:150] Setting up relu6
I0124 14:46:45.161077 32597 net.cpp:157] Top shape: 250 2048 (512000)
I0124 14:46:45.161079 32597 net.cpp:165] Memory required for data: 478051000
I0124 14:46:45.161083 32597 layer_factory.hpp:76] Creating layer drop6
I0124 14:46:45.161092 32597 net.cpp:106] Creating Layer drop6
I0124 14:46:45.161095 32597 net.cpp:454] drop6 <- fc6
I0124 14:46:45.161103 32597 net.cpp:397] drop6 -> fc6 (in-place)
I0124 14:46:45.161149 32597 net.cpp:150] Setting up drop6
I0124 14:46:45.161156 32597 net.cpp:157] Top shape: 250 2048 (512000)
I0124 14:46:45.161159 32597 net.cpp:165] Memory required for data: 480099000
I0124 14:46:45.161162 32597 layer_factory.hpp:76] Creating layer fc7
I0124 14:46:45.161173 32597 net.cpp:106] Creating Layer fc7
I0124 14:46:45.161177 32597 net.cpp:454] fc7 <- fc6
I0124 14:46:45.161185 32597 net.cpp:411] fc7 -> fc7
I0124 14:46:45.308143 32597 net.cpp:150] Setting up fc7
I0124 14:46:45.308173 32597 net.cpp:157] Top shape: 250 2048 (512000)
I0124 14:46:45.308178 32597 net.cpp:165] Memory required for data: 482147000
I0124 14:46:45.308190 32597 layer_factory.hpp:76] Creating layer relu7
I0124 14:46:45.308200 32597 net.cpp:106] Creating Layer relu7
I0124 14:46:45.308207 32597 net.cpp:454] relu7 <- fc7
I0124 14:46:45.308214 32597 net.cpp:397] relu7 -> fc7 (in-place)
I0124 14:46:45.309324 32597 net.cpp:150] Setting up relu7
I0124 14:46:45.309337 32597 net.cpp:157] Top shape: 250 2048 (512000)
I0124 14:46:45.309342 32597 net.cpp:165] Memory required for data: 484195000
I0124 14:46:45.309347 32597 layer_factory.hpp:76] Creating layer drop7
I0124 14:46:45.309355 32597 net.cpp:106] Creating Layer drop7
I0124 14:46:45.309361 32597 net.cpp:454] drop7 <- fc7
I0124 14:46:45.309370 32597 net.cpp:397] drop7 -> fc7 (in-place)
I0124 14:46:45.309415 32597 net.cpp:150] Setting up drop7
I0124 14:46:45.309424 32597 net.cpp:157] Top shape: 250 2048 (512000)
I0124 14:46:45.309428 32597 net.cpp:165] Memory required for data: 486243000
I0124 14:46:45.309433 32597 layer_factory.hpp:76] Creating layer fc8
I0124 14:46:45.309442 32597 net.cpp:106] Creating Layer fc8
I0124 14:46:45.309445 32597 net.cpp:454] fc8 <- fc7
I0124 14:46:45.309453 32597 net.cpp:411] fc8 -> fc8
I0124 14:46:45.391680 32597 net.cpp:150] Setting up fc8
I0124 14:46:45.391707 32597 net.cpp:157] Top shape: 250 1000 (250000)
I0124 14:46:45.391711 32597 net.cpp:165] Memory required for data: 487243000
I0124 14:46:45.391722 32597 layer_factory.hpp:76] Creating layer fc8_fc8_0_split
I0124 14:46:45.391733 32597 net.cpp:106] Creating Layer fc8_fc8_0_split
I0124 14:46:45.391738 32597 net.cpp:454] fc8_fc8_0_split <- fc8
I0124 14:46:45.391747 32597 net.cpp:411] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0124 14:46:45.391758 32597 net.cpp:411] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0124 14:46:45.391830 32597 net.cpp:150] Setting up fc8_fc8_0_split
I0124 14:46:45.391839 32597 net.cpp:157] Top shape: 250 1000 (250000)
I0124 14:46:45.391844 32597 net.cpp:157] Top shape: 250 1000 (250000)
I0124 14:46:45.391846 32597 net.cpp:165] Memory required for data: 489243000
I0124 14:46:45.391850 32597 layer_factory.hpp:76] Creating layer accuracy
I0124 14:46:45.391865 32597 net.cpp:106] Creating Layer accuracy
I0124 14:46:45.391868 32597 net.cpp:454] accuracy <- fc8_fc8_0_split_0
I0124 14:46:45.391873 32597 net.cpp:454] accuracy <- label_data_1_split_0
I0124 14:46:45.391881 32597 net.cpp:411] accuracy -> accuracy
I0124 14:46:45.391916 32597 net.cpp:150] Setting up accuracy
I0124 14:46:45.391921 32597 net.cpp:157] Top shape: (1)
I0124 14:46:45.391924 32597 net.cpp:165] Memory required for data: 489243004
I0124 14:46:45.391928 32597 layer_factory.hpp:76] Creating layer loss
I0124 14:46:45.391935 32597 net.cpp:106] Creating Layer loss
I0124 14:46:45.391939 32597 net.cpp:454] loss <- fc8_fc8_0_split_1
I0124 14:46:45.391943 32597 net.cpp:454] loss <- label_data_1_split_1
I0124 14:46:45.391949 32597 net.cpp:411] loss -> loss
I0124 14:46:45.391957 32597 layer_factory.hpp:76] Creating layer loss
I0124 14:46:45.393939 32597 net.cpp:150] Setting up loss
I0124 14:46:45.393956 32597 net.cpp:157] Top shape: (1)
I0124 14:46:45.393961 32597 net.cpp:160]     with loss weight 1
I0124 14:46:45.393973 32597 net.cpp:165] Memory required for data: 489243008
I0124 14:46:45.393978 32597 net.cpp:226] loss needs backward computation.
I0124 14:46:45.393985 32597 net.cpp:228] accuracy does not need backward computation.
I0124 14:46:45.393990 32597 net.cpp:226] fc8_fc8_0_split needs backward computation.
I0124 14:46:45.393993 32597 net.cpp:226] fc8 needs backward computation.
I0124 14:46:45.393997 32597 net.cpp:226] drop7 needs backward computation.
I0124 14:46:45.394001 32597 net.cpp:226] relu7 needs backward computation.
I0124 14:46:45.394006 32597 net.cpp:226] fc7 needs backward computation.
I0124 14:46:45.394009 32597 net.cpp:226] drop6 needs backward computation.
I0124 14:46:45.394013 32597 net.cpp:226] relu6 needs backward computation.
I0124 14:46:45.394016 32597 net.cpp:226] fc6 needs backward computation.
I0124 14:46:45.394021 32597 net.cpp:226] pool5 needs backward computation.
I0124 14:46:45.394026 32597 net.cpp:226] relu5 needs backward computation.
I0124 14:46:45.394029 32597 net.cpp:226] conv5 needs backward computation.
I0124 14:46:45.394033 32597 net.cpp:226] relu4 needs backward computation.
I0124 14:46:45.394037 32597 net.cpp:226] conv4 needs backward computation.
I0124 14:46:45.394040 32597 net.cpp:226] relu3 needs backward computation.
I0124 14:46:45.394044 32597 net.cpp:226] conv3 needs backward computation.
I0124 14:46:45.394048 32597 net.cpp:226] pool2 needs backward computation.
I0124 14:46:45.394052 32597 net.cpp:226] relu2 needs backward computation.
I0124 14:46:45.394057 32597 net.cpp:226] conv2 needs backward computation.
I0124 14:46:45.394062 32597 net.cpp:226] pool1 needs backward computation.
I0124 14:46:45.394065 32597 net.cpp:226] relu1 needs backward computation.
I0124 14:46:45.394068 32597 net.cpp:226] conv1 needs backward computation.
I0124 14:46:45.394073 32597 net.cpp:228] label_data_1_split does not need backward computation.
I0124 14:46:45.394078 32597 net.cpp:228] data does not need backward computation.
I0124 14:46:45.394081 32597 net.cpp:270] This network produces output accuracy
I0124 14:46:45.394086 32597 net.cpp:270] This network produces output loss
I0124 14:46:45.394105 32597 net.cpp:283] Network initialization done.
I0124 14:46:45.394222 32597 solver.cpp:60] Solver scaffolding done.
I0124 14:46:45.395243 32597 caffe.cpp:128] Finetuning from ./caffenet_lsuv_rmsprop_099_lr001.prototxt.caffemodel
I0124 14:46:45.593202 32597 caffe.cpp:212] Starting Optimization
I0124 14:46:45.593237 32597 solver.cpp:288] Solving CaffeNet
I0124 14:46:45.593245 32597 solver.cpp:289] Learning Rate Policy: step
I0124 14:46:45.644168 32597 solver.cpp:237] Iteration 0, loss = 7.4164
I0124 14:46:45.644343 32597 solver.cpp:253]     Train net output #0: loss = 7.4164 (* 1 = 7.4164 loss)
I0124 14:46:45.644420 32597 sgd_solver.cpp:106] Iteration 0, lr = 0.01
I0124 14:46:45.734779 32597 blocking_queue.cpp:50] Data layer prefetch queue empty
I0124 14:46:52.873492 32597 solver.cpp:237] Iteration 20, loss = 67.2958
I0124 14:46:52.873530 32597 solver.cpp:253]     Train net output #0: loss = 7.25523 (* 1 = 7.25523 loss)
I0124 14:46:52.873538 32597 sgd_solver.cpp:106] Iteration 20, lr = 0.01
I0124 14:47:01.045212 32597 solver.cpp:237] Iteration 40, loss = 7.19459
I0124 14:47:01.045297 32597 solver.cpp:253]     Train net output #0: loss = 6.92027 (* 1 = 6.92027 loss)
I0124 14:47:01.045356 32597 sgd_solver.cpp:106] Iteration 40, lr = 0.01
I0124 14:47:08.928827 32597 solver.cpp:237] Iteration 60, loss = 7.05162
I0124 14:47:08.928928 32597 solver.cpp:253]     Train net output #0: loss = 6.9197 (* 1 = 6.9197 loss)
I0124 14:47:08.928963 32597 sgd_solver.cpp:106] Iteration 60, lr = 0.01
I0124 14:47:16.465566 32597 solver.cpp:237] Iteration 80, loss = 6.99024
I0124 14:47:16.465742 32597 solver.cpp:253]     Train net output #0: loss = 6.94309 (* 1 = 6.94309 loss)
I0124 14:47:16.465765 32597 sgd_solver.cpp:106] Iteration 80, lr = 0.01
I0124 14:47:24.146070 32597 solver.cpp:237] Iteration 100, loss = 6.99681
I0124 14:47:24.146116 32597 solver.cpp:253]     Train net output #0: loss = 6.9233 (* 1 = 6.9233 loss)
I0124 14:47:24.146126 32597 sgd_solver.cpp:106] Iteration 100, lr = 0.01
I0124 14:47:31.691613 32597 solver.cpp:237] Iteration 120, loss = 6.95172
I0124 14:47:31.691648 32597 solver.cpp:253]     Train net output #0: loss = 6.91669 (* 1 = 6.91669 loss)
I0124 14:47:31.691658 32597 sgd_solver.cpp:106] Iteration 120, lr = 0.01
I0124 14:47:39.216423 32597 solver.cpp:237] Iteration 140, loss = 6.96503
I0124 14:47:39.216455 32597 solver.cpp:253]     Train net output #0: loss = 7.2207 (* 1 = 7.2207 loss)
I0124 14:47:39.216464 32597 sgd_solver.cpp:106] Iteration 140, lr = 0.01
I0124 14:47:46.987399 32597 solver.cpp:237] Iteration 160, loss = 7.10894
I0124 14:47:46.987485 32597 solver.cpp:253]     Train net output #0: loss = 7.26427 (* 1 = 7.26427 loss)
I0124 14:47:46.987496 32597 sgd_solver.cpp:106] Iteration 160, lr = 0.01
I0124 14:47:54.725584 32597 solver.cpp:237] Iteration 180, loss = 11.0559
I0124 14:47:54.725625 32597 solver.cpp:253]     Train net output #0: loss = 7.23799 (* 1 = 7.23799 loss)
I0124 14:47:54.725636 32597 sgd_solver.cpp:106] Iteration 180, lr = 0.01
I0124 14:48:02.256561 32597 solver.cpp:237] Iteration 200, loss = 7.07692
I0124 14:48:02.256595 32597 solver.cpp:253]     Train net output #0: loss = 6.90887 (* 1 = 6.90887 loss)
I0124 14:48:02.256604 32597 sgd_solver.cpp:106] Iteration 200, lr = 0.01
I0124 14:48:09.962014 32597 solver.cpp:237] Iteration 220, loss = 6.93262
I0124 14:48:09.962047 32597 solver.cpp:253]     Train net output #0: loss = 6.91524 (* 1 = 6.91524 loss)
I0124 14:48:09.962056 32597 sgd_solver.cpp:106] Iteration 220, lr = 0.01
I0124 14:48:17.587201 32597 solver.cpp:237] Iteration 240, loss = 7.60784
I0124 14:48:17.587529 32597 solver.cpp:253]     Train net output #0: loss = 6.91202 (* 1 = 6.91202 loss)
I0124 14:48:17.587616 32597 sgd_solver.cpp:106] Iteration 240, lr = 0.01
I0124 14:48:25.290200 32597 solver.cpp:237] Iteration 260, loss = 7.0737
I0124 14:48:25.290236 32597 solver.cpp:253]     Train net output #0: loss = 7.53123 (* 1 = 7.53123 loss)
I0124 14:48:25.290247 32597 sgd_solver.cpp:106] Iteration 260, lr = 0.01
I0124 14:48:32.797269 32597 solver.cpp:237] Iteration 280, loss = 6.99431
I0124 14:48:32.797304 32597 solver.cpp:253]     Train net output #0: loss = 6.91856 (* 1 = 6.91856 loss)
I0124 14:48:32.797317 32597 sgd_solver.cpp:106] Iteration 280, lr = 0.01
I0124 14:48:40.192762 32597 solver.cpp:237] Iteration 300, loss = 6.94817
I0124 14:48:40.192800 32597 solver.cpp:253]     Train net output #0: loss = 6.90893 (* 1 = 6.90893 loss)
I0124 14:48:40.192808 32597 sgd_solver.cpp:106] Iteration 300, lr = 0.01
I0124 14:48:47.717147 32597 solver.cpp:237] Iteration 320, loss = 6.94671
I0124 14:48:47.717239 32597 solver.cpp:253]     Train net output #0: loss = 6.9148 (* 1 = 6.9148 loss)
I0124 14:48:47.717252 32597 sgd_solver.cpp:106] Iteration 320, lr = 0.01
I0124 14:48:55.455334 32597 solver.cpp:237] Iteration 340, loss = 6.91677
I0124 14:48:55.455368 32597 solver.cpp:253]     Train net output #0: loss = 6.92239 (* 1 = 6.92239 loss)
I0124 14:48:55.455375 32597 sgd_solver.cpp:106] Iteration 340, lr = 0.01
I0124 14:49:02.918336 32597 solver.cpp:237] Iteration 360, loss = 6.93258
I0124 14:49:02.918375 32597 solver.cpp:253]     Train net output #0: loss = 6.92629 (* 1 = 6.92629 loss)
I0124 14:49:02.918458 32597 sgd_solver.cpp:106] Iteration 360, lr = 0.01
I0124 14:49:10.445252 32597 solver.cpp:237] Iteration 380, loss = 6.91483
I0124 14:49:10.445286 32597 solver.cpp:253]     Train net output #0: loss = 6.92055 (* 1 = 6.92055 loss)
I0124 14:49:10.445293 32597 sgd_solver.cpp:106] Iteration 380, lr = 0.01
I0124 14:49:18.154633 32597 solver.cpp:237] Iteration 400, loss = 6.95221
I0124 14:49:18.154743 32597 solver.cpp:253]     Train net output #0: loss = 6.91946 (* 1 = 6.91946 loss)
I0124 14:49:18.154754 32597 sgd_solver.cpp:106] Iteration 400, lr = 0.01
I0124 14:49:25.844585 32597 solver.cpp:237] Iteration 420, loss = 6.92607
I0124 14:49:25.844621 32597 solver.cpp:253]     Train net output #0: loss = 6.91748 (* 1 = 6.91748 loss)
I0124 14:49:25.844632 32597 sgd_solver.cpp:106] Iteration 420, lr = 0.01
I0124 14:49:33.561609 32597 solver.cpp:237] Iteration 440, loss = 6.93332
I0124 14:49:33.561641 32597 solver.cpp:253]     Train net output #0: loss = 6.9206 (* 1 = 6.9206 loss)
I0124 14:49:33.561650 32597 sgd_solver.cpp:106] Iteration 440, lr = 0.01
I0124 14:49:41.024328 32597 solver.cpp:237] Iteration 460, loss = 6.91255
I0124 14:49:41.024369 32597 solver.cpp:253]     Train net output #0: loss = 6.92537 (* 1 = 6.92537 loss)
I0124 14:49:41.024461 32597 sgd_solver.cpp:106] Iteration 460, lr = 0.01
I0124 14:49:48.610069 32597 solver.cpp:237] Iteration 480, loss = 6.91355
I0124 14:49:48.610152 32597 solver.cpp:253]     Train net output #0: loss = 6.90834 (* 1 = 6.90834 loss)
I0124 14:49:48.610164 32597 sgd_solver.cpp:106] Iteration 480, lr = 0.01
I0124 14:49:56.290511 32597 solver.cpp:237] Iteration 500, loss = 6.93449
I0124 14:49:56.290551 32597 solver.cpp:253]     Train net output #0: loss = 6.91665 (* 1 = 6.91665 loss)
I0124 14:49:56.290562 32597 sgd_solver.cpp:106] Iteration 500, lr = 0.01
I0124 14:50:04.155640 32597 solver.cpp:237] Iteration 520, loss = 6.91717
I0124 14:50:04.155681 32597 solver.cpp:253]     Train net output #0: loss = 6.92342 (* 1 = 6.92342 loss)
I0124 14:50:04.155691 32597 sgd_solver.cpp:106] Iteration 520, lr = 0.01
I0124 14:50:11.849913 32597 solver.cpp:237] Iteration 540, loss = 6.98199
I0124 14:50:11.849951 32597 solver.cpp:253]     Train net output #0: loss = 7.5495 (* 1 = 7.5495 loss)
I0124 14:50:11.849961 32597 sgd_solver.cpp:106] Iteration 540, lr = 0.01
I0124 14:50:19.630172 32597 solver.cpp:237] Iteration 560, loss = 6.95154
I0124 14:50:19.630262 32597 solver.cpp:253]     Train net output #0: loss = 6.90586 (* 1 = 6.90586 loss)
I0124 14:50:19.630275 32597 sgd_solver.cpp:106] Iteration 560, lr = 0.01
I0124 14:50:27.347520 32597 solver.cpp:237] Iteration 580, loss = 6.9457
I0124 14:50:27.347614 32597 solver.cpp:253]     Train net output #0: loss = 6.90147 (* 1 = 6.90147 loss)
I0124 14:50:27.347642 32597 sgd_solver.cpp:106] Iteration 580, lr = 0.01
I0124 14:50:34.960623 32597 solver.cpp:237] Iteration 600, loss = 9.22465
I0124 14:50:34.960662 32597 solver.cpp:253]     Train net output #0: loss = 8.7944 (* 1 = 8.7944 loss)
I0124 14:50:34.960674 32597 sgd_solver.cpp:106] Iteration 600, lr = 0.01
I0124 14:50:42.728219 32597 solver.cpp:237] Iteration 620, loss = 6.96424
I0124 14:50:42.728260 32597 solver.cpp:253]     Train net output #0: loss = 6.92652 (* 1 = 6.92652 loss)
I0124 14:50:42.728271 32597 sgd_solver.cpp:106] Iteration 620, lr = 0.01
I0124 14:50:50.962332 32597 solver.cpp:237] Iteration 640, loss = 6.94777
I0124 14:50:50.962452 32597 solver.cpp:253]     Train net output #0: loss = 6.93097 (* 1 = 6.93097 loss)
I0124 14:50:50.962476 32597 sgd_solver.cpp:106] Iteration 640, lr = 0.01
I0124 14:51:00.050631 32597 solver.cpp:237] Iteration 660, loss = 8.93127
I0124 14:51:00.050668 32597 solver.cpp:253]     Train net output #0: loss = 6.91406 (* 1 = 6.91406 loss)
I0124 14:51:00.050678 32597 sgd_solver.cpp:106] Iteration 660, lr = 0.01
I0124 14:51:08.070528 32597 solver.cpp:237] Iteration 680, loss = 6.91698
I0124 14:51:08.070647 32597 solver.cpp:253]     Train net output #0: loss = 6.90764 (* 1 = 6.90764 loss)
I0124 14:51:08.070688 32597 sgd_solver.cpp:106] Iteration 680, lr = 0.01
I0124 14:51:16.154237 32597 solver.cpp:237] Iteration 700, loss = 6.92194
I0124 14:51:16.154268 32597 solver.cpp:253]     Train net output #0: loss = 6.91662 (* 1 = 6.91662 loss)
I0124 14:51:16.154278 32597 sgd_solver.cpp:106] Iteration 700, lr = 0.01
I0124 14:51:23.776293 32597 solver.cpp:237] Iteration 720, loss = 6.93504
I0124 14:51:23.776381 32597 solver.cpp:253]     Train net output #0: loss = 6.89922 (* 1 = 6.89922 loss)
I0124 14:51:23.776391 32597 sgd_solver.cpp:106] Iteration 720, lr = 0.01
I0124 14:51:31.742269 32597 solver.cpp:237] Iteration 740, loss = 6.91875
I0124 14:51:31.742308 32597 solver.cpp:253]     Train net output #0: loss = 6.92356 (* 1 = 6.92356 loss)
I0124 14:51:31.742339 32597 sgd_solver.cpp:106] Iteration 740, lr = 0.01
I0124 14:51:40.109201 32597 solver.cpp:237] Iteration 760, loss = 23.4143
I0124 14:51:40.109434 32597 solver.cpp:253]     Train net output #0: loss = 7.22309 (* 1 = 7.22309 loss)
I0124 14:51:40.109462 32597 sgd_solver.cpp:106] Iteration 760, lr = 0.01
I0124 14:51:48.069458 32597 solver.cpp:237] Iteration 780, loss = 13.4438
I0124 14:51:48.069552 32597 solver.cpp:253]     Train net output #0: loss = 6.96033 (* 1 = 6.96033 loss)
I0124 14:51:48.069583 32597 sgd_solver.cpp:106] Iteration 780, lr = 0.01
I0124 14:51:56.337273 32597 solver.cpp:237] Iteration 800, loss = 8.79461
I0124 14:51:56.337349 32597 solver.cpp:253]     Train net output #0: loss = 44.5045 (* 1 = 44.5045 loss)
I0124 14:51:56.337426 32597 sgd_solver.cpp:106] Iteration 800, lr = 0.01
I0124 14:52:04.396576 32597 solver.cpp:237] Iteration 820, loss = 6.98891
I0124 14:52:04.396610 32597 solver.cpp:253]     Train net output #0: loss = 6.92613 (* 1 = 6.92613 loss)
I0124 14:52:04.396617 32597 sgd_solver.cpp:106] Iteration 820, lr = 0.01
I0124 14:52:12.508803 32597 solver.cpp:237] Iteration 840, loss = 6.91746
I0124 14:52:12.508836 32597 solver.cpp:253]     Train net output #0: loss = 6.91544 (* 1 = 6.91544 loss)
I0124 14:52:12.508846 32597 sgd_solver.cpp:106] Iteration 840, lr = 0.01
