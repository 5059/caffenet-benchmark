I0414 16:13:19.980437 12023 upgrade_proto.cpp:990] Attempting to upgrade input file specified using deprecated 'solver_type' field (enum)': caffenet128_lsuv_online_lr0000039063.prototxt
I0414 16:13:19.980690 12023 upgrade_proto.cpp:997] Successfully upgraded file specified using deprecated 'solver_type' field (enum) to 'type' field (string).
W0414 16:13:19.980700 12023 upgrade_proto.cpp:999] Note that future Caffe releases will only support 'type' field (string) for a solver's type.
I0414 16:13:19.980821 12023 caffe.cpp:184] Using GPUs 0
I0414 16:13:20.173336 12023 solver.cpp:48] Initializing solver from parameters: 
test_iter: 1000
test_interval: 256000
base_lr: 3.9063e-05
display: 51200
max_iter: 81920000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 25600000
snapshot: 2560000
snapshot_prefix: "snapshots/caffenet128_no_lrn_lsuv_relu_bs1"
solver_mode: GPU
device_id: 0
net_param {
  name: "CaffeNet"
  layer {
    name: "data"
    type: "Data"
    top: "data"
    top: "label"
    include {
      phase: TRAIN
    }
    transform_param {
      scale: 0.04
      mirror: true
      crop_size: 128
      mean_value: 104
      mean_value: 117
      mean_value: 124
      force_color: true
    }
    data_param {
      source: "/home/old-ufo/storage/datasets/imagenet/imgs128/lmdb/ilsvrc12_128_train_lmdb"
      batch_size: 1
      backend: LMDB
    }
  }
  layer {
    name: "data"
    type: "Data"
    top: "data"
    top: "label"
    include {
      phase: TEST
    }
    transform_param {
      scale: 0.04
      mirror: false
      crop_size: 128
      mean_value: 104
      mean_value: 117
      mean_value: 123
      force_color: true
    }
    data_param {
      source: "/home/old-ufo/storage/datasets/imagenet/imgs128/lmdb/ilsvrc12_128_val_lmdb"
      batch_size: 50
      backend: LMDB
    }
  }
  layer {
    name: "conv1"
    type: "Convolution"
    bottom: "data"
    top: "conv1"
    param {
      lr_mult: 1
      decay_mult: 1
    }
    param {
      lr_mult: 2
      decay_mult: 0
    }
    convolution_param {
      num_output: 96
      kernel_size: 11
      stride: 4
      weight_filler {
        type: "gaussian"
        std: 0.01
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layer {
    name: "relu1"
    type: "ReLU"
    bottom: "conv1"
    top: "relu1"
  }
  layer {
    name: "pool1"
    type: "Pooling"
    bottom: "relu1"
    top: "pool1"
    pooling_param {
      pool: MAX
      kernel_size: 3
      stride: 2
    }
  }
  layer {
    name: "conv2"
    type: "Convolution"
    bottom: "pool1"
    top: "conv2"
    param {
      lr_mult: 1
      decay_mult: 1
    }
    param {
      lr_mult: 2
      decay_mult: 0
    }
    convolution_param {
      num_output: 256
      pad: 2
      kernel_size: 5
      group: 2
      weight_filler {
        type: "gaussian"
        std: 0.01
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layer {
    name: "relu2"
    type: "ReLU"
    bottom: "conv2"
    top: "relu2"
  }
  layer {
    name: "pool2"
    type: "Pooling"
    bottom: "relu2"
    top: "pool2"
    pooling_param {
      pool: MAX
      kernel_size: 3
      stride: 2
    }
  }
  layer {
    name: "conv3"
    type: "Convolution"
    bottom: "pool2"
    top: "conv3"
    param {
      lr_mult: 1
      decay_mult: 1
    }
    param {
      lr_mult: 2
      decay_mult: 0
    }
    convolution_param {
      num_output: 384
      pad: 1
      kernel_size: 3
      weight_filler {
        type: "gaussian"
        std: 0.01
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layer {
    name: "relu3"
    type: "ReLU"
    bottom: "conv3"
    top: "relu3"
  }
  layer {
    name: "conv4"
    type: "Convolution"
    bottom: "relu3"
    top: "conv4"
    param {
      lr_mult: 1
      decay_mult: 1
    }
    param {
      lr_mult: 2
      decay_mult: 0
    }
    convolution_param {
      num_output: 384
      pad: 1
      kernel_size: 3
      group: 2
      weight_filler {
        type: "gaussian"
        std: 0.01
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layer {
    name: "relu4"
    type: "ReLU"
    bottom: "conv4"
    top: "relu4"
  }
  layer {
    name: "conv5"
    type: "Convolution"
    bottom: "relu4"
    top: "conv5"
    param {
      lr_mult: 1
      decay_mult: 1
    }
    param {
      lr_mult: 2
      decay_mult: 0
    }
    convolution_param {
      num_output: 256
      pad: 1
      kernel_size: 3
      group: 2
      weight_filler {
        type: "gaussian"
        std: 0.01
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layer {
    name: "relu5"
    type: "ReLU"
    bottom: "conv5"
    top: "relu5"
  }
  layer {
    name: "pool5"
    type: "Pooling"
    bottom: "relu5"
    top: "pool5"
    pooling_param {
      pool: MAX
      kernel_size: 3
      stride: 2
    }
  }
  layer {
    name: "fc6"
    type: "InnerProduct"
    bottom: "pool5"
    top: "fc6"
    param {
      lr_mult: 1
      decay_mult: 1
    }
    param {
      lr_mult: 2
      decay_mult: 0
    }
    inner_product_param {
      num_output: 2048
      weight_filler {
        type: "gaussian"
        std: 0.005
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layer {
    name: "relu6"
    type: "ReLU"
    bottom: "fc6"
    top: "relu6"
  }
  layer {
    name: "drop6"
    type: "Dropout"
    bottom: "relu6"
    top: "drop6"
    dropout_param {
      dropout_ratio: 0.5
    }
  }
  layer {
    name: "fc7"
    type: "InnerProduct"
    bottom: "drop6"
    top: "fc7"
    param {
      lr_mult: 1
      decay_mult: 1
    }
    param {
      lr_mult: 2
      decay_mult: 0
    }
    inner_product_param {
      num_output: 2048
      weight_filler {
        type: "gaussian"
        std: 0.005
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layer {
    name: "relu7"
    type: "ReLU"
    bottom: "fc7"
    top: "relu7"
  }
  layer {
    name: "drop7"
    type: "Dropout"
    bottom: "relu7"
    top: "drop7"
    dropout_param {
      dropout_ratio: 0.5
    }
  }
  layer {
    name: "fc8"
    type: "InnerProduct"
    bottom: "drop7"
    top: "fc8"
    param {
      lr_mult: 1
      decay_mult: 1
    }
    param {
      lr_mult: 2
      decay_mult: 0
    }
    inner_product_param {
      num_output: 1000
      weight_filler {
        type: "gaussian"
        std: 0.01
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layer {
    name: "accuracy"
    type: "Accuracy"
    bottom: "fc8"
    bottom: "label"
    top: "accuracy"
    include {
      phase: TEST
    }
  }
  layer {
    name: "loss"
    type: "SoftmaxWithLoss"
    bottom: "fc8"
    bottom: "label"
    top: "loss"
  }
}
test_initialization: true
average_loss: 51200
iter_size: 1
type: "SGD"
I0414 16:13:20.173499 12023 solver.cpp:86] Creating training net specified in net_param.
I0414 16:13:20.173560 12023 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0414 16:13:20.173576 12023 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0414 16:13:20.173692 12023 net.cpp:49] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.04
    mirror: true
    crop_size: 128
    mean_value: 104
    mean_value: 117
    mean_value: 124
    force_color: true
  }
  data_param {
    source: "/home/old-ufo/storage/datasets/imagenet/imgs128/lmdb/ilsvrc12_128_train_lmdb"
    batch_size: 1
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "relu1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "relu1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "relu2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "relu2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "relu3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "relu3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "relu4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "relu4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "relu5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "relu5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "relu6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "relu6"
  top: "drop6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "drop6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "relu7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "relu7"
  top: "drop7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "drop7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0414 16:13:20.173777 12023 layer_factory.hpp:76] Creating layer data
I0414 16:13:20.174180 12023 net.cpp:106] Creating Layer data
I0414 16:13:20.174188 12023 net.cpp:411] data -> data
I0414 16:13:20.174213 12023 net.cpp:411] data -> label
I0414 16:13:20.174870 12029 db_lmdb.cpp:38] Opened lmdb /home/old-ufo/storage/datasets/imagenet/imgs128/lmdb/ilsvrc12_128_train_lmdb
I0414 16:13:20.183531 12023 data_layer.cpp:41] output data size: 1,3,128,128
I0414 16:13:20.184170 12023 net.cpp:150] Setting up data
I0414 16:13:20.184186 12023 net.cpp:157] Top shape: 1 3 128 128 (49152)
I0414 16:13:20.184195 12023 net.cpp:157] Top shape: 1 (1)
I0414 16:13:20.184213 12023 net.cpp:165] Memory required for data: 196612
I0414 16:13:20.184227 12023 layer_factory.hpp:76] Creating layer conv1
I0414 16:13:20.184248 12023 net.cpp:106] Creating Layer conv1
I0414 16:13:20.184255 12023 net.cpp:454] conv1 <- data
I0414 16:13:20.184273 12023 net.cpp:411] conv1 -> conv1
I0414 16:13:20.290333 12023 net.cpp:150] Setting up conv1
I0414 16:13:20.290360 12023 net.cpp:157] Top shape: 1 96 30 30 (86400)
I0414 16:13:20.290365 12023 net.cpp:165] Memory required for data: 542212
I0414 16:13:20.290388 12023 layer_factory.hpp:76] Creating layer relu1
I0414 16:13:20.290405 12023 net.cpp:106] Creating Layer relu1
I0414 16:13:20.290413 12023 net.cpp:454] relu1 <- conv1
I0414 16:13:20.290422 12023 net.cpp:411] relu1 -> relu1
I0414 16:13:20.290979 12023 net.cpp:150] Setting up relu1
I0414 16:13:20.290990 12023 net.cpp:157] Top shape: 1 96 30 30 (86400)
I0414 16:13:20.290995 12023 net.cpp:165] Memory required for data: 887812
I0414 16:13:20.290999 12023 layer_factory.hpp:76] Creating layer pool1
I0414 16:13:20.291009 12023 net.cpp:106] Creating Layer pool1
I0414 16:13:20.291014 12023 net.cpp:454] pool1 <- relu1
I0414 16:13:20.291023 12023 net.cpp:411] pool1 -> pool1
I0414 16:13:20.291584 12023 net.cpp:150] Setting up pool1
I0414 16:13:20.291595 12023 net.cpp:157] Top shape: 1 96 15 15 (21600)
I0414 16:13:20.291600 12023 net.cpp:165] Memory required for data: 974212
I0414 16:13:20.291604 12023 layer_factory.hpp:76] Creating layer conv2
I0414 16:13:20.291618 12023 net.cpp:106] Creating Layer conv2
I0414 16:13:20.291625 12023 net.cpp:454] conv2 <- pool1
I0414 16:13:20.291633 12023 net.cpp:411] conv2 -> conv2
I0414 16:13:20.302799 12023 net.cpp:150] Setting up conv2
I0414 16:13:20.302819 12023 net.cpp:157] Top shape: 1 256 15 15 (57600)
I0414 16:13:20.302824 12023 net.cpp:165] Memory required for data: 1204612
I0414 16:13:20.302837 12023 layer_factory.hpp:76] Creating layer relu2
I0414 16:13:20.302847 12023 net.cpp:106] Creating Layer relu2
I0414 16:13:20.302852 12023 net.cpp:454] relu2 <- conv2
I0414 16:13:20.302865 12023 net.cpp:411] relu2 -> relu2
I0414 16:13:20.303431 12023 net.cpp:150] Setting up relu2
I0414 16:13:20.303442 12023 net.cpp:157] Top shape: 1 256 15 15 (57600)
I0414 16:13:20.303447 12023 net.cpp:165] Memory required for data: 1435012
I0414 16:13:20.303452 12023 layer_factory.hpp:76] Creating layer pool2
I0414 16:13:20.303462 12023 net.cpp:106] Creating Layer pool2
I0414 16:13:20.303467 12023 net.cpp:454] pool2 <- relu2
I0414 16:13:20.303473 12023 net.cpp:411] pool2 -> pool2
I0414 16:13:20.304105 12023 net.cpp:150] Setting up pool2
I0414 16:13:20.304116 12023 net.cpp:157] Top shape: 1 256 7 7 (12544)
I0414 16:13:20.304121 12023 net.cpp:165] Memory required for data: 1485188
I0414 16:13:20.304126 12023 layer_factory.hpp:76] Creating layer conv3
I0414 16:13:20.304138 12023 net.cpp:106] Creating Layer conv3
I0414 16:13:20.304143 12023 net.cpp:454] conv3 <- pool2
I0414 16:13:20.304152 12023 net.cpp:411] conv3 -> conv3
I0414 16:13:20.328440 12023 net.cpp:150] Setting up conv3
I0414 16:13:20.328469 12023 net.cpp:157] Top shape: 1 384 7 7 (18816)
I0414 16:13:20.328474 12023 net.cpp:165] Memory required for data: 1560452
I0414 16:13:20.328490 12023 layer_factory.hpp:76] Creating layer relu3
I0414 16:13:20.328502 12023 net.cpp:106] Creating Layer relu3
I0414 16:13:20.328510 12023 net.cpp:454] relu3 <- conv3
I0414 16:13:20.328522 12023 net.cpp:411] relu3 -> relu3
I0414 16:13:20.329087 12023 net.cpp:150] Setting up relu3
I0414 16:13:20.329098 12023 net.cpp:157] Top shape: 1 384 7 7 (18816)
I0414 16:13:20.329104 12023 net.cpp:165] Memory required for data: 1635716
I0414 16:13:20.329109 12023 layer_factory.hpp:76] Creating layer conv4
I0414 16:13:20.329120 12023 net.cpp:106] Creating Layer conv4
I0414 16:13:20.329125 12023 net.cpp:454] conv4 <- relu3
I0414 16:13:20.329135 12023 net.cpp:411] conv4 -> conv4
I0414 16:13:20.349424 12023 net.cpp:150] Setting up conv4
I0414 16:13:20.349452 12023 net.cpp:157] Top shape: 1 384 7 7 (18816)
I0414 16:13:20.349455 12023 net.cpp:165] Memory required for data: 1710980
I0414 16:13:20.349496 12023 layer_factory.hpp:76] Creating layer relu4
I0414 16:13:20.349510 12023 net.cpp:106] Creating Layer relu4
I0414 16:13:20.349519 12023 net.cpp:454] relu4 <- conv4
I0414 16:13:20.349530 12023 net.cpp:411] relu4 -> relu4
I0414 16:13:20.350114 12023 net.cpp:150] Setting up relu4
I0414 16:13:20.350126 12023 net.cpp:157] Top shape: 1 384 7 7 (18816)
I0414 16:13:20.350131 12023 net.cpp:165] Memory required for data: 1786244
I0414 16:13:20.350136 12023 layer_factory.hpp:76] Creating layer conv5
I0414 16:13:20.350147 12023 net.cpp:106] Creating Layer conv5
I0414 16:13:20.350153 12023 net.cpp:454] conv5 <- relu4
I0414 16:13:20.350162 12023 net.cpp:411] conv5 -> conv5
I0414 16:13:20.364920 12023 net.cpp:150] Setting up conv5
I0414 16:13:20.364943 12023 net.cpp:157] Top shape: 1 256 7 7 (12544)
I0414 16:13:20.364948 12023 net.cpp:165] Memory required for data: 1836420
I0414 16:13:20.364965 12023 layer_factory.hpp:76] Creating layer relu5
I0414 16:13:20.364976 12023 net.cpp:106] Creating Layer relu5
I0414 16:13:20.364982 12023 net.cpp:454] relu5 <- conv5
I0414 16:13:20.364992 12023 net.cpp:411] relu5 -> relu5
I0414 16:13:20.365579 12023 net.cpp:150] Setting up relu5
I0414 16:13:20.365592 12023 net.cpp:157] Top shape: 1 256 7 7 (12544)
I0414 16:13:20.365597 12023 net.cpp:165] Memory required for data: 1886596
I0414 16:13:20.365600 12023 layer_factory.hpp:76] Creating layer pool5
I0414 16:13:20.365608 12023 net.cpp:106] Creating Layer pool5
I0414 16:13:20.365613 12023 net.cpp:454] pool5 <- relu5
I0414 16:13:20.365622 12023 net.cpp:411] pool5 -> pool5
I0414 16:13:20.366217 12023 net.cpp:150] Setting up pool5
I0414 16:13:20.366228 12023 net.cpp:157] Top shape: 1 256 3 3 (2304)
I0414 16:13:20.366232 12023 net.cpp:165] Memory required for data: 1895812
I0414 16:13:20.366237 12023 layer_factory.hpp:76] Creating layer fc6
I0414 16:13:20.366255 12023 net.cpp:106] Creating Layer fc6
I0414 16:13:20.366262 12023 net.cpp:454] fc6 <- pool5
I0414 16:13:20.366271 12023 net.cpp:411] fc6 -> fc6
I0414 16:13:20.485448 12023 net.cpp:150] Setting up fc6
I0414 16:13:20.485478 12023 net.cpp:157] Top shape: 1 2048 (2048)
I0414 16:13:20.485482 12023 net.cpp:165] Memory required for data: 1904004
I0414 16:13:20.485493 12023 layer_factory.hpp:76] Creating layer relu6
I0414 16:13:20.485505 12023 net.cpp:106] Creating Layer relu6
I0414 16:13:20.485512 12023 net.cpp:454] relu6 <- fc6
I0414 16:13:20.485523 12023 net.cpp:411] relu6 -> relu6
I0414 16:13:20.486166 12023 net.cpp:150] Setting up relu6
I0414 16:13:20.486179 12023 net.cpp:157] Top shape: 1 2048 (2048)
I0414 16:13:20.486183 12023 net.cpp:165] Memory required for data: 1912196
I0414 16:13:20.486188 12023 layer_factory.hpp:76] Creating layer drop6
I0414 16:13:20.486201 12023 net.cpp:106] Creating Layer drop6
I0414 16:13:20.486207 12023 net.cpp:454] drop6 <- relu6
I0414 16:13:20.486213 12023 net.cpp:411] drop6 -> drop6
I0414 16:13:20.486258 12023 net.cpp:150] Setting up drop6
I0414 16:13:20.486265 12023 net.cpp:157] Top shape: 1 2048 (2048)
I0414 16:13:20.486269 12023 net.cpp:165] Memory required for data: 1920388
I0414 16:13:20.486274 12023 layer_factory.hpp:76] Creating layer fc7
I0414 16:13:20.486284 12023 net.cpp:106] Creating Layer fc7
I0414 16:13:20.486289 12023 net.cpp:454] fc7 <- drop6
I0414 16:13:20.486297 12023 net.cpp:411] fc7 -> fc7
I0414 16:13:20.591985 12023 net.cpp:150] Setting up fc7
I0414 16:13:20.592012 12023 net.cpp:157] Top shape: 1 2048 (2048)
I0414 16:13:20.592016 12023 net.cpp:165] Memory required for data: 1928580
I0414 16:13:20.592030 12023 layer_factory.hpp:76] Creating layer relu7
I0414 16:13:20.592042 12023 net.cpp:106] Creating Layer relu7
I0414 16:13:20.592049 12023 net.cpp:454] relu7 <- fc7
I0414 16:13:20.592059 12023 net.cpp:411] relu7 -> relu7
I0414 16:13:20.592756 12023 net.cpp:150] Setting up relu7
I0414 16:13:20.592767 12023 net.cpp:157] Top shape: 1 2048 (2048)
I0414 16:13:20.592772 12023 net.cpp:165] Memory required for data: 1936772
I0414 16:13:20.592775 12023 layer_factory.hpp:76] Creating layer drop7
I0414 16:13:20.592784 12023 net.cpp:106] Creating Layer drop7
I0414 16:13:20.592806 12023 net.cpp:454] drop7 <- relu7
I0414 16:13:20.592816 12023 net.cpp:411] drop7 -> drop7
I0414 16:13:20.592857 12023 net.cpp:150] Setting up drop7
I0414 16:13:20.592864 12023 net.cpp:157] Top shape: 1 2048 (2048)
I0414 16:13:20.592869 12023 net.cpp:165] Memory required for data: 1944964
I0414 16:13:20.592874 12023 layer_factory.hpp:76] Creating layer fc8
I0414 16:13:20.592885 12023 net.cpp:106] Creating Layer fc8
I0414 16:13:20.592890 12023 net.cpp:454] fc8 <- drop7
I0414 16:13:20.592900 12023 net.cpp:411] fc8 -> fc8
I0414 16:13:20.644659 12023 net.cpp:150] Setting up fc8
I0414 16:13:20.644688 12023 net.cpp:157] Top shape: 1 1000 (1000)
I0414 16:13:20.644692 12023 net.cpp:165] Memory required for data: 1948964
I0414 16:13:20.644704 12023 layer_factory.hpp:76] Creating layer loss
I0414 16:13:20.644714 12023 net.cpp:106] Creating Layer loss
I0414 16:13:20.644721 12023 net.cpp:454] loss <- fc8
I0414 16:13:20.644727 12023 net.cpp:454] loss <- label
I0414 16:13:20.644737 12023 net.cpp:411] loss -> loss
I0414 16:13:20.644753 12023 layer_factory.hpp:76] Creating layer loss
I0414 16:13:20.645601 12023 net.cpp:150] Setting up loss
I0414 16:13:20.645612 12023 net.cpp:157] Top shape: (1)
I0414 16:13:20.645617 12023 net.cpp:160]     with loss weight 1
I0414 16:13:20.645637 12023 net.cpp:165] Memory required for data: 1948968
I0414 16:13:20.645642 12023 net.cpp:226] loss needs backward computation.
I0414 16:13:20.645648 12023 net.cpp:226] fc8 needs backward computation.
I0414 16:13:20.645653 12023 net.cpp:226] drop7 needs backward computation.
I0414 16:13:20.645656 12023 net.cpp:226] relu7 needs backward computation.
I0414 16:13:20.645661 12023 net.cpp:226] fc7 needs backward computation.
I0414 16:13:20.645665 12023 net.cpp:226] drop6 needs backward computation.
I0414 16:13:20.645673 12023 net.cpp:226] relu6 needs backward computation.
I0414 16:13:20.645679 12023 net.cpp:226] fc6 needs backward computation.
I0414 16:13:20.645684 12023 net.cpp:226] pool5 needs backward computation.
I0414 16:13:20.645689 12023 net.cpp:226] relu5 needs backward computation.
I0414 16:13:20.645692 12023 net.cpp:226] conv5 needs backward computation.
I0414 16:13:20.645696 12023 net.cpp:226] relu4 needs backward computation.
I0414 16:13:20.645701 12023 net.cpp:226] conv4 needs backward computation.
I0414 16:13:20.645705 12023 net.cpp:226] relu3 needs backward computation.
I0414 16:13:20.645710 12023 net.cpp:226] conv3 needs backward computation.
I0414 16:13:20.645715 12023 net.cpp:226] pool2 needs backward computation.
I0414 16:13:20.645720 12023 net.cpp:226] relu2 needs backward computation.
I0414 16:13:20.645723 12023 net.cpp:226] conv2 needs backward computation.
I0414 16:13:20.645728 12023 net.cpp:226] pool1 needs backward computation.
I0414 16:13:20.645732 12023 net.cpp:226] relu1 needs backward computation.
I0414 16:13:20.645737 12023 net.cpp:226] conv1 needs backward computation.
I0414 16:13:20.645742 12023 net.cpp:228] data does not need backward computation.
I0414 16:13:20.645746 12023 net.cpp:270] This network produces output loss
I0414 16:13:20.645766 12023 net.cpp:283] Network initialization done.
I0414 16:13:20.645874 12023 solver.cpp:181] Creating test net (#0) specified by net_param
I0414 16:13:20.645915 12023 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0414 16:13:20.646070 12023 net.cpp:49] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.04
    mirror: false
    crop_size: 128
    mean_value: 104
    mean_value: 117
    mean_value: 123
    force_color: true
  }
  data_param {
    source: "/home/old-ufo/storage/datasets/imagenet/imgs128/lmdb/ilsvrc12_128_val_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "relu1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "relu1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "relu2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "relu2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "relu3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "relu3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "relu4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "relu4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "relu5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "relu5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "relu6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "relu6"
  top: "drop6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "drop6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "relu7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "relu7"
  top: "drop7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "drop7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0414 16:13:20.646229 12023 layer_factory.hpp:76] Creating layer data
I0414 16:13:20.646327 12023 net.cpp:106] Creating Layer data
I0414 16:13:20.646348 12023 net.cpp:411] data -> data
I0414 16:13:20.646361 12023 net.cpp:411] data -> label
I0414 16:13:20.647136 12031 db_lmdb.cpp:38] Opened lmdb /home/old-ufo/storage/datasets/imagenet/imgs128/lmdb/ilsvrc12_128_val_lmdb
I0414 16:13:20.647735 12023 data_layer.cpp:41] output data size: 50,3,128,128
I0414 16:13:20.660248 12023 net.cpp:150] Setting up data
I0414 16:13:20.660276 12023 net.cpp:157] Top shape: 50 3 128 128 (2457600)
I0414 16:13:20.660284 12023 net.cpp:157] Top shape: 50 (50)
I0414 16:13:20.660289 12023 net.cpp:165] Memory required for data: 9830600
I0414 16:13:20.660295 12023 layer_factory.hpp:76] Creating layer label_data_1_split
I0414 16:13:20.660308 12023 net.cpp:106] Creating Layer label_data_1_split
I0414 16:13:20.660315 12023 net.cpp:454] label_data_1_split <- label
I0414 16:13:20.660325 12023 net.cpp:411] label_data_1_split -> label_data_1_split_0
I0414 16:13:20.660337 12023 net.cpp:411] label_data_1_split -> label_data_1_split_1
I0414 16:13:20.660410 12023 net.cpp:150] Setting up label_data_1_split
I0414 16:13:20.660421 12023 net.cpp:157] Top shape: 50 (50)
I0414 16:13:20.660428 12023 net.cpp:157] Top shape: 50 (50)
I0414 16:13:20.660431 12023 net.cpp:165] Memory required for data: 9831000
I0414 16:13:20.660435 12023 layer_factory.hpp:76] Creating layer conv1
I0414 16:13:20.660449 12023 net.cpp:106] Creating Layer conv1
I0414 16:13:20.660452 12023 net.cpp:454] conv1 <- data
I0414 16:13:20.660460 12023 net.cpp:411] conv1 -> conv1
I0414 16:13:20.664140 12023 net.cpp:150] Setting up conv1
I0414 16:13:20.664157 12023 net.cpp:157] Top shape: 50 96 30 30 (4320000)
I0414 16:13:20.664162 12023 net.cpp:165] Memory required for data: 27111000
I0414 16:13:20.664176 12023 layer_factory.hpp:76] Creating layer relu1
I0414 16:13:20.664186 12023 net.cpp:106] Creating Layer relu1
I0414 16:13:20.664191 12023 net.cpp:454] relu1 <- conv1
I0414 16:13:20.664197 12023 net.cpp:411] relu1 -> relu1
I0414 16:13:20.664782 12023 net.cpp:150] Setting up relu1
I0414 16:13:20.664793 12023 net.cpp:157] Top shape: 50 96 30 30 (4320000)
I0414 16:13:20.664798 12023 net.cpp:165] Memory required for data: 44391000
I0414 16:13:20.664803 12023 layer_factory.hpp:76] Creating layer pool1
I0414 16:13:20.664813 12023 net.cpp:106] Creating Layer pool1
I0414 16:13:20.664819 12023 net.cpp:454] pool1 <- relu1
I0414 16:13:20.664826 12023 net.cpp:411] pool1 -> pool1
I0414 16:13:20.665460 12023 net.cpp:150] Setting up pool1
I0414 16:13:20.665472 12023 net.cpp:157] Top shape: 50 96 15 15 (1080000)
I0414 16:13:20.665478 12023 net.cpp:165] Memory required for data: 48711000
I0414 16:13:20.665483 12023 layer_factory.hpp:76] Creating layer conv2
I0414 16:13:20.665494 12023 net.cpp:106] Creating Layer conv2
I0414 16:13:20.665498 12023 net.cpp:454] conv2 <- pool1
I0414 16:13:20.665508 12023 net.cpp:411] conv2 -> conv2
I0414 16:13:20.677129 12023 net.cpp:150] Setting up conv2
I0414 16:13:20.677152 12023 net.cpp:157] Top shape: 50 256 15 15 (2880000)
I0414 16:13:20.677156 12023 net.cpp:165] Memory required for data: 60231000
I0414 16:13:20.677175 12023 layer_factory.hpp:76] Creating layer relu2
I0414 16:13:20.677186 12023 net.cpp:106] Creating Layer relu2
I0414 16:13:20.677191 12023 net.cpp:454] relu2 <- conv2
I0414 16:13:20.677201 12023 net.cpp:411] relu2 -> relu2
I0414 16:13:20.677816 12023 net.cpp:150] Setting up relu2
I0414 16:13:20.677830 12023 net.cpp:157] Top shape: 50 256 15 15 (2880000)
I0414 16:13:20.677834 12023 net.cpp:165] Memory required for data: 71751000
I0414 16:13:20.677839 12023 layer_factory.hpp:76] Creating layer pool2
I0414 16:13:20.677848 12023 net.cpp:106] Creating Layer pool2
I0414 16:13:20.677852 12023 net.cpp:454] pool2 <- relu2
I0414 16:13:20.677861 12023 net.cpp:411] pool2 -> pool2
I0414 16:13:20.678493 12023 net.cpp:150] Setting up pool2
I0414 16:13:20.678505 12023 net.cpp:157] Top shape: 50 256 7 7 (627200)
I0414 16:13:20.678510 12023 net.cpp:165] Memory required for data: 74259800
I0414 16:13:20.678527 12023 layer_factory.hpp:76] Creating layer conv3
I0414 16:13:20.678542 12023 net.cpp:106] Creating Layer conv3
I0414 16:13:20.678549 12023 net.cpp:454] conv3 <- pool2
I0414 16:13:20.678558 12023 net.cpp:411] conv3 -> conv3
I0414 16:13:20.703135 12023 net.cpp:150] Setting up conv3
I0414 16:13:20.703160 12023 net.cpp:157] Top shape: 50 384 7 7 (940800)
I0414 16:13:20.703164 12023 net.cpp:165] Memory required for data: 78023000
I0414 16:13:20.703181 12023 layer_factory.hpp:76] Creating layer relu3
I0414 16:13:20.703192 12023 net.cpp:106] Creating Layer relu3
I0414 16:13:20.703199 12023 net.cpp:454] relu3 <- conv3
I0414 16:13:20.703209 12023 net.cpp:411] relu3 -> relu3
I0414 16:13:20.703807 12023 net.cpp:150] Setting up relu3
I0414 16:13:20.703819 12023 net.cpp:157] Top shape: 50 384 7 7 (940800)
I0414 16:13:20.703824 12023 net.cpp:165] Memory required for data: 81786200
I0414 16:13:20.703829 12023 layer_factory.hpp:76] Creating layer conv4
I0414 16:13:20.703841 12023 net.cpp:106] Creating Layer conv4
I0414 16:13:20.703847 12023 net.cpp:454] conv4 <- relu3
I0414 16:13:20.703856 12023 net.cpp:411] conv4 -> conv4
I0414 16:13:20.724380 12023 net.cpp:150] Setting up conv4
I0414 16:13:20.724405 12023 net.cpp:157] Top shape: 50 384 7 7 (940800)
I0414 16:13:20.724409 12023 net.cpp:165] Memory required for data: 85549400
I0414 16:13:20.724421 12023 layer_factory.hpp:76] Creating layer relu4
I0414 16:13:20.724431 12023 net.cpp:106] Creating Layer relu4
I0414 16:13:20.724437 12023 net.cpp:454] relu4 <- conv4
I0414 16:13:20.724447 12023 net.cpp:411] relu4 -> relu4
I0414 16:13:20.725124 12023 net.cpp:150] Setting up relu4
I0414 16:13:20.725136 12023 net.cpp:157] Top shape: 50 384 7 7 (940800)
I0414 16:13:20.725141 12023 net.cpp:165] Memory required for data: 89312600
I0414 16:13:20.725144 12023 layer_factory.hpp:76] Creating layer conv5
I0414 16:13:20.725159 12023 net.cpp:106] Creating Layer conv5
I0414 16:13:20.725164 12023 net.cpp:454] conv5 <- relu4
I0414 16:13:20.725174 12023 net.cpp:411] conv5 -> conv5
I0414 16:13:20.740221 12023 net.cpp:150] Setting up conv5
I0414 16:13:20.740245 12023 net.cpp:157] Top shape: 50 256 7 7 (627200)
I0414 16:13:20.740250 12023 net.cpp:165] Memory required for data: 91821400
I0414 16:13:20.740265 12023 layer_factory.hpp:76] Creating layer relu5
I0414 16:13:20.740277 12023 net.cpp:106] Creating Layer relu5
I0414 16:13:20.740283 12023 net.cpp:454] relu5 <- conv5
I0414 16:13:20.740293 12023 net.cpp:411] relu5 -> relu5
I0414 16:13:20.740890 12023 net.cpp:150] Setting up relu5
I0414 16:13:20.740901 12023 net.cpp:157] Top shape: 50 256 7 7 (627200)
I0414 16:13:20.740906 12023 net.cpp:165] Memory required for data: 94330200
I0414 16:13:20.740909 12023 layer_factory.hpp:76] Creating layer pool5
I0414 16:13:20.740919 12023 net.cpp:106] Creating Layer pool5
I0414 16:13:20.740924 12023 net.cpp:454] pool5 <- relu5
I0414 16:13:20.740931 12023 net.cpp:411] pool5 -> pool5
I0414 16:13:20.741549 12023 net.cpp:150] Setting up pool5
I0414 16:13:20.741560 12023 net.cpp:157] Top shape: 50 256 3 3 (115200)
I0414 16:13:20.741565 12023 net.cpp:165] Memory required for data: 94791000
I0414 16:13:20.741570 12023 layer_factory.hpp:76] Creating layer fc6
I0414 16:13:20.741580 12023 net.cpp:106] Creating Layer fc6
I0414 16:13:20.741585 12023 net.cpp:454] fc6 <- pool5
I0414 16:13:20.741595 12023 net.cpp:411] fc6 -> fc6
I0414 16:13:20.861078 12023 net.cpp:150] Setting up fc6
I0414 16:13:20.861105 12023 net.cpp:157] Top shape: 50 2048 (102400)
I0414 16:13:20.861110 12023 net.cpp:165] Memory required for data: 95200600
I0414 16:13:20.861122 12023 layer_factory.hpp:76] Creating layer relu6
I0414 16:13:20.861136 12023 net.cpp:106] Creating Layer relu6
I0414 16:13:20.861141 12023 net.cpp:454] relu6 <- fc6
I0414 16:13:20.861151 12023 net.cpp:411] relu6 -> relu6
I0414 16:13:20.861995 12023 net.cpp:150] Setting up relu6
I0414 16:13:20.862009 12023 net.cpp:157] Top shape: 50 2048 (102400)
I0414 16:13:20.862013 12023 net.cpp:165] Memory required for data: 95610200
I0414 16:13:20.862018 12023 layer_factory.hpp:76] Creating layer drop6
I0414 16:13:20.862041 12023 net.cpp:106] Creating Layer drop6
I0414 16:13:20.862046 12023 net.cpp:454] drop6 <- relu6
I0414 16:13:20.862054 12023 net.cpp:411] drop6 -> drop6
I0414 16:13:20.862104 12023 net.cpp:150] Setting up drop6
I0414 16:13:20.862112 12023 net.cpp:157] Top shape: 50 2048 (102400)
I0414 16:13:20.862117 12023 net.cpp:165] Memory required for data: 96019800
I0414 16:13:20.862121 12023 layer_factory.hpp:76] Creating layer fc7
I0414 16:13:20.862133 12023 net.cpp:106] Creating Layer fc7
I0414 16:13:20.862138 12023 net.cpp:454] fc7 <- drop6
I0414 16:13:20.862145 12023 net.cpp:411] fc7 -> fc7
I0414 16:13:20.967846 12023 net.cpp:150] Setting up fc7
I0414 16:13:20.967876 12023 net.cpp:157] Top shape: 50 2048 (102400)
I0414 16:13:20.967881 12023 net.cpp:165] Memory required for data: 96429400
I0414 16:13:20.967893 12023 layer_factory.hpp:76] Creating layer relu7
I0414 16:13:20.967905 12023 net.cpp:106] Creating Layer relu7
I0414 16:13:20.967911 12023 net.cpp:454] relu7 <- fc7
I0414 16:13:20.967919 12023 net.cpp:411] relu7 -> relu7
I0414 16:13:20.968669 12023 net.cpp:150] Setting up relu7
I0414 16:13:20.968682 12023 net.cpp:157] Top shape: 50 2048 (102400)
I0414 16:13:20.968685 12023 net.cpp:165] Memory required for data: 96839000
I0414 16:13:20.968690 12023 layer_factory.hpp:76] Creating layer drop7
I0414 16:13:20.968699 12023 net.cpp:106] Creating Layer drop7
I0414 16:13:20.968705 12023 net.cpp:454] drop7 <- relu7
I0414 16:13:20.968713 12023 net.cpp:411] drop7 -> drop7
I0414 16:13:20.968761 12023 net.cpp:150] Setting up drop7
I0414 16:13:20.968770 12023 net.cpp:157] Top shape: 50 2048 (102400)
I0414 16:13:20.968773 12023 net.cpp:165] Memory required for data: 97248600
I0414 16:13:20.968778 12023 layer_factory.hpp:76] Creating layer fc8
I0414 16:13:20.968789 12023 net.cpp:106] Creating Layer fc8
I0414 16:13:20.968794 12023 net.cpp:454] fc8 <- drop7
I0414 16:13:20.968801 12023 net.cpp:411] fc8 -> fc8
I0414 16:13:21.020666 12023 net.cpp:150] Setting up fc8
I0414 16:13:21.020696 12023 net.cpp:157] Top shape: 50 1000 (50000)
I0414 16:13:21.020700 12023 net.cpp:165] Memory required for data: 97448600
I0414 16:13:21.020712 12023 layer_factory.hpp:76] Creating layer fc8_fc8_0_split
I0414 16:13:21.020726 12023 net.cpp:106] Creating Layer fc8_fc8_0_split
I0414 16:13:21.020731 12023 net.cpp:454] fc8_fc8_0_split <- fc8
I0414 16:13:21.020741 12023 net.cpp:411] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0414 16:13:21.020752 12023 net.cpp:411] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0414 16:13:21.020804 12023 net.cpp:150] Setting up fc8_fc8_0_split
I0414 16:13:21.020812 12023 net.cpp:157] Top shape: 50 1000 (50000)
I0414 16:13:21.020817 12023 net.cpp:157] Top shape: 50 1000 (50000)
I0414 16:13:21.020823 12023 net.cpp:165] Memory required for data: 97848600
I0414 16:13:21.020826 12023 layer_factory.hpp:76] Creating layer accuracy
I0414 16:13:21.020841 12023 net.cpp:106] Creating Layer accuracy
I0414 16:13:21.020849 12023 net.cpp:454] accuracy <- fc8_fc8_0_split_0
I0414 16:13:21.020855 12023 net.cpp:454] accuracy <- label_data_1_split_0
I0414 16:13:21.020862 12023 net.cpp:411] accuracy -> accuracy
I0414 16:13:21.020876 12023 net.cpp:150] Setting up accuracy
I0414 16:13:21.020884 12023 net.cpp:157] Top shape: (1)
I0414 16:13:21.020887 12023 net.cpp:165] Memory required for data: 97848604
I0414 16:13:21.020891 12023 layer_factory.hpp:76] Creating layer loss
I0414 16:13:21.020898 12023 net.cpp:106] Creating Layer loss
I0414 16:13:21.020903 12023 net.cpp:454] loss <- fc8_fc8_0_split_1
I0414 16:13:21.020908 12023 net.cpp:454] loss <- label_data_1_split_1
I0414 16:13:21.020923 12023 net.cpp:411] loss -> loss
I0414 16:13:21.020936 12023 layer_factory.hpp:76] Creating layer loss
I0414 16:13:21.022063 12023 net.cpp:150] Setting up loss
I0414 16:13:21.022074 12023 net.cpp:157] Top shape: (1)
I0414 16:13:21.022078 12023 net.cpp:160]     with loss weight 1
I0414 16:13:21.022091 12023 net.cpp:165] Memory required for data: 97848608
I0414 16:13:21.022095 12023 net.cpp:226] loss needs backward computation.
I0414 16:13:21.022101 12023 net.cpp:228] accuracy does not need backward computation.
I0414 16:13:21.022117 12023 net.cpp:226] fc8_fc8_0_split needs backward computation.
I0414 16:13:21.022124 12023 net.cpp:226] fc8 needs backward computation.
I0414 16:13:21.022127 12023 net.cpp:226] drop7 needs backward computation.
I0414 16:13:21.022131 12023 net.cpp:226] relu7 needs backward computation.
I0414 16:13:21.022136 12023 net.cpp:226] fc7 needs backward computation.
I0414 16:13:21.022140 12023 net.cpp:226] drop6 needs backward computation.
I0414 16:13:21.022145 12023 net.cpp:226] relu6 needs backward computation.
I0414 16:13:21.022150 12023 net.cpp:226] fc6 needs backward computation.
I0414 16:13:21.022155 12023 net.cpp:226] pool5 needs backward computation.
I0414 16:13:21.022158 12023 net.cpp:226] relu5 needs backward computation.
I0414 16:13:21.022163 12023 net.cpp:226] conv5 needs backward computation.
I0414 16:13:21.022167 12023 net.cpp:226] relu4 needs backward computation.
I0414 16:13:21.022172 12023 net.cpp:226] conv4 needs backward computation.
I0414 16:13:21.022176 12023 net.cpp:226] relu3 needs backward computation.
I0414 16:13:21.022181 12023 net.cpp:226] conv3 needs backward computation.
I0414 16:13:21.022186 12023 net.cpp:226] pool2 needs backward computation.
I0414 16:13:21.022189 12023 net.cpp:226] relu2 needs backward computation.
I0414 16:13:21.022194 12023 net.cpp:226] conv2 needs backward computation.
I0414 16:13:21.022200 12023 net.cpp:226] pool1 needs backward computation.
I0414 16:13:21.022204 12023 net.cpp:226] relu1 needs backward computation.
I0414 16:13:21.022209 12023 net.cpp:226] conv1 needs backward computation.
I0414 16:13:21.022214 12023 net.cpp:228] label_data_1_split does not need backward computation.
I0414 16:13:21.022219 12023 net.cpp:228] data does not need backward computation.
I0414 16:13:21.022223 12023 net.cpp:270] This network produces output accuracy
I0414 16:13:21.022228 12023 net.cpp:270] This network produces output loss
I0414 16:13:21.022250 12023 net.cpp:283] Network initialization done.
I0414 16:13:21.022349 12023 solver.cpp:60] Solver scaffolding done.
I0414 16:13:21.022924 12023 caffe.cpp:128] Finetuning from caffenet128_lsuv_bs64.prototxt.caffemodel
I0414 16:13:21.172709 12023 caffe.cpp:212] Starting Optimization
I0414 16:13:21.172735 12023 solver.cpp:288] Solving CaffeNet
I0414 16:13:21.172739 12023 solver.cpp:289] Learning Rate Policy: step
I0414 16:13:21.173841 12023 solver.cpp:341] Iteration 0, Testing net (#0)
I0414 16:13:21.226114 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0414 16:13:47.529827 12023 solver.cpp:409]     Test net output #0: accuracy = 0.00106
I0414 16:13:47.529860 12023 solver.cpp:409]     Test net output #1: loss = 7.03386 (* 1 = 7.03386 loss)
I0414 16:13:47.538974 12023 solver.cpp:237] Iteration 0, loss = 7.35844
I0414 16:13:47.539005 12023 solver.cpp:253]     Train net output #0: loss = 7.35844 (* 1 = 7.35844 loss)
I0414 16:13:47.539018 12023 sgd_solver.cpp:106] Iteration 0, lr = 3.9063e-05
I0414 16:20:11.659548 12023 solver.cpp:237] Iteration 51200, loss = 6.91568
I0414 16:20:11.659610 12023 solver.cpp:253]     Train net output #0: loss = 6.87604 (* 1 = 6.87604 loss)
I0414 16:20:11.659616 12023 sgd_solver.cpp:106] Iteration 51200, lr = 3.9063e-05
I0414 16:26:40.519012 12023 solver.cpp:237] Iteration 102400, loss = 6.90687
I0414 16:26:40.519083 12023 solver.cpp:253]     Train net output #0: loss = 6.92996 (* 1 = 6.92996 loss)
I0414 16:26:40.519088 12023 sgd_solver.cpp:106] Iteration 102400, lr = 3.9063e-05
I0414 16:33:09.348472 12023 solver.cpp:237] Iteration 153600, loss = 6.87626
I0414 16:33:09.348533 12023 solver.cpp:253]     Train net output #0: loss = 7.09524 (* 1 = 7.09524 loss)
I0414 16:33:09.348539 12023 sgd_solver.cpp:106] Iteration 153600, lr = 3.9063e-05
I0414 16:39:38.165144 12023 solver.cpp:237] Iteration 204800, loss = 6.81407
I0414 16:39:38.165237 12023 solver.cpp:253]     Train net output #0: loss = 7.24813 (* 1 = 7.24813 loss)
I0414 16:39:38.165243 12023 sgd_solver.cpp:106] Iteration 204800, lr = 3.9063e-05
I0414 16:46:07.021471 12023 solver.cpp:341] Iteration 256000, Testing net (#0)
I0414 16:46:07.143267 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0414 16:46:33.358088 12023 solver.cpp:409]     Test net output #0: accuracy = 0.00414
I0414 16:46:33.358121 12023 solver.cpp:409]     Test net output #1: loss = 6.69954 (* 1 = 6.69954 loss)
I0414 16:46:33.361865 12023 solver.cpp:237] Iteration 256000, loss = 6.76763
I0414 16:46:33.361883 12023 solver.cpp:253]     Train net output #0: loss = 7.08336 (* 1 = 7.08336 loss)
I0414 16:46:33.361891 12023 sgd_solver.cpp:106] Iteration 256000, lr = 3.9063e-05
I0414 16:53:02.286222 12023 solver.cpp:237] Iteration 307200, loss = 6.70221
I0414 16:53:02.286294 12023 solver.cpp:253]     Train net output #0: loss = 6.85548 (* 1 = 6.85548 loss)
I0414 16:53:02.286300 12023 sgd_solver.cpp:106] Iteration 307200, lr = 3.9063e-05
I0414 16:59:31.119927 12023 solver.cpp:237] Iteration 358400, loss = 6.62895
I0414 16:59:31.119997 12023 solver.cpp:253]     Train net output #0: loss = 7.2279 (* 1 = 7.2279 loss)
I0414 16:59:31.120002 12023 sgd_solver.cpp:106] Iteration 358400, lr = 3.9063e-05
I0414 17:05:59.956754 12023 solver.cpp:237] Iteration 409600, loss = 6.51674
I0414 17:05:59.956823 12023 solver.cpp:253]     Train net output #0: loss = 6.291 (* 1 = 6.291 loss)
I0414 17:05:59.956830 12023 sgd_solver.cpp:106] Iteration 409600, lr = 3.9063e-05
I0414 17:12:28.791638 12023 solver.cpp:237] Iteration 460800, loss = 6.39925
I0414 17:12:28.791695 12023 solver.cpp:253]     Train net output #0: loss = 6.71589 (* 1 = 6.71589 loss)
I0414 17:12:28.791702 12023 sgd_solver.cpp:106] Iteration 460800, lr = 3.9063e-05
I0414 17:18:57.596912 12023 solver.cpp:341] Iteration 512000, Testing net (#0)
I0414 17:18:57.797464 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0414 17:19:23.923002 12023 solver.cpp:409]     Test net output #0: accuracy = 0.0195001
I0414 17:19:23.923038 12023 solver.cpp:409]     Test net output #1: loss = 6.10758 (* 1 = 6.10758 loss)
I0414 17:19:23.926812 12023 solver.cpp:237] Iteration 512000, loss = 6.29471
I0414 17:19:23.926832 12023 solver.cpp:253]     Train net output #0: loss = 5.28834 (* 1 = 5.28834 loss)
I0414 17:19:23.926841 12023 sgd_solver.cpp:106] Iteration 512000, lr = 3.9063e-05
I0414 17:25:52.792632 12023 solver.cpp:237] Iteration 563200, loss = 6.19712
I0414 17:25:52.792701 12023 solver.cpp:253]     Train net output #0: loss = 4.96727 (* 1 = 4.96727 loss)
I0414 17:25:52.792706 12023 sgd_solver.cpp:106] Iteration 563200, lr = 3.9063e-05
I0414 17:32:21.583204 12023 solver.cpp:237] Iteration 614400, loss = 6.11462
I0414 17:32:21.583277 12023 solver.cpp:253]     Train net output #0: loss = 5.01932 (* 1 = 5.01932 loss)
I0414 17:32:21.583283 12023 sgd_solver.cpp:106] Iteration 614400, lr = 3.9063e-05
I0414 17:38:50.381903 12023 solver.cpp:237] Iteration 665600, loss = 6.0252
I0414 17:38:50.381976 12023 solver.cpp:253]     Train net output #0: loss = 6.18752 (* 1 = 6.18752 loss)
I0414 17:38:50.381983 12023 sgd_solver.cpp:106] Iteration 665600, lr = 3.9063e-05
I0414 17:45:19.162278 12023 solver.cpp:237] Iteration 716800, loss = 5.94676
I0414 17:45:19.162348 12023 solver.cpp:253]     Train net output #0: loss = 5.9364 (* 1 = 5.9364 loss)
I0414 17:45:19.162354 12023 sgd_solver.cpp:106] Iteration 716800, lr = 3.9063e-05
I0414 17:51:48.126065 12023 solver.cpp:341] Iteration 768000, Testing net (#0)
I0414 17:51:48.407397 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0414 17:52:14.456395 12023 solver.cpp:409]     Test net output #0: accuracy = 0.0374403
I0414 17:52:14.456429 12023 solver.cpp:409]     Test net output #1: loss = 5.72923 (* 1 = 5.72923 loss)
I0414 17:52:14.460186 12023 solver.cpp:237] Iteration 768000, loss = 5.8754
I0414 17:52:14.460203 12023 solver.cpp:253]     Train net output #0: loss = 5.09303 (* 1 = 5.09303 loss)
I0414 17:52:14.460211 12023 sgd_solver.cpp:106] Iteration 768000, lr = 3.9063e-05
I0414 17:58:43.367404 12023 solver.cpp:237] Iteration 819200, loss = 5.78762
I0414 17:58:43.367481 12023 solver.cpp:253]     Train net output #0: loss = 5.06434 (* 1 = 5.06434 loss)
I0414 17:58:43.367486 12023 sgd_solver.cpp:106] Iteration 819200, lr = 3.9063e-05
I0414 18:05:12.175971 12023 solver.cpp:237] Iteration 870400, loss = 5.73233
I0414 18:05:12.176039 12023 solver.cpp:253]     Train net output #0: loss = 5.53922 (* 1 = 5.53922 loss)
I0414 18:05:12.176045 12023 sgd_solver.cpp:106] Iteration 870400, lr = 3.9063e-05
I0414 18:11:41.081135 12023 solver.cpp:237] Iteration 921600, loss = 5.65409
I0414 18:11:41.081205 12023 solver.cpp:253]     Train net output #0: loss = 5.71503 (* 1 = 5.71503 loss)
I0414 18:11:41.081210 12023 sgd_solver.cpp:106] Iteration 921600, lr = 3.9063e-05
I0414 18:18:09.886783 12023 solver.cpp:237] Iteration 972800, loss = 5.59507
I0414 18:18:09.886852 12023 solver.cpp:253]     Train net output #0: loss = 6.98226 (* 1 = 6.98226 loss)
I0414 18:18:09.886858 12023 sgd_solver.cpp:106] Iteration 972800, lr = 3.9063e-05
I0414 18:24:38.717948 12023 solver.cpp:341] Iteration 1024000, Testing net (#0)
I0414 18:24:39.078184 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0414 18:25:05.039616 12023 solver.cpp:409]     Test net output #0: accuracy = 0.0625204
I0414 18:25:05.039649 12023 solver.cpp:409]     Test net output #1: loss = 5.30763 (* 1 = 5.30763 loss)
I0414 18:25:05.043396 12023 solver.cpp:237] Iteration 1024000, loss = 5.53469
I0414 18:25:05.043416 12023 solver.cpp:253]     Train net output #0: loss = 4.65252 (* 1 = 4.65252 loss)
I0414 18:25:05.043422 12023 sgd_solver.cpp:106] Iteration 1024000, lr = 3.9063e-05
I0414 18:31:33.962121 12023 solver.cpp:237] Iteration 1075200, loss = 5.47556
I0414 18:31:33.962180 12023 solver.cpp:253]     Train net output #0: loss = 5.60202 (* 1 = 5.60202 loss)
I0414 18:31:33.962187 12023 sgd_solver.cpp:106] Iteration 1075200, lr = 3.9063e-05
I0414 18:38:03.283247 12023 solver.cpp:237] Iteration 1126400, loss = 5.42898
I0414 18:38:03.283308 12023 solver.cpp:253]     Train net output #0: loss = 6.51425 (* 1 = 6.51425 loss)
I0414 18:38:03.283315 12023 sgd_solver.cpp:106] Iteration 1126400, lr = 3.9063e-05
I0414 18:44:32.420775 12023 solver.cpp:237] Iteration 1177600, loss = 5.40232
I0414 18:44:32.420847 12023 solver.cpp:253]     Train net output #0: loss = 6.13515 (* 1 = 6.13515 loss)
I0414 18:44:32.420853 12023 sgd_solver.cpp:106] Iteration 1177600, lr = 3.9063e-05
I0414 18:51:01.290760 12023 solver.cpp:237] Iteration 1228800, loss = 5.31744
I0414 18:51:01.290832 12023 solver.cpp:253]     Train net output #0: loss = 5.24141 (* 1 = 5.24141 loss)
I0414 18:51:01.290838 12023 sgd_solver.cpp:106] Iteration 1228800, lr = 3.9063e-05
I0414 18:57:30.105952 12023 solver.cpp:341] Iteration 1280000, Testing net (#0)
I0414 18:57:30.543268 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0414 18:57:56.430028 12023 solver.cpp:409]     Test net output #0: accuracy = 0.0849602
I0414 18:57:56.430063 12023 solver.cpp:409]     Test net output #1: loss = 5.07189 (* 1 = 5.07189 loss)
I0414 18:57:56.433840 12023 solver.cpp:237] Iteration 1280000, loss = 5.29555
I0414 18:57:56.433866 12023 solver.cpp:253]     Train net output #0: loss = 6.68154 (* 1 = 6.68154 loss)
I0414 18:57:56.433873 12023 sgd_solver.cpp:106] Iteration 1280000, lr = 3.9063e-05
I0414 19:04:25.513262 12023 solver.cpp:237] Iteration 1331200, loss = 5.24935
I0414 19:04:25.513337 12023 solver.cpp:253]     Train net output #0: loss = 7.20751 (* 1 = 7.20751 loss)
I0414 19:04:25.513344 12023 sgd_solver.cpp:106] Iteration 1331200, lr = 3.9063e-05
I0414 19:10:54.282646 12023 solver.cpp:237] Iteration 1382400, loss = 5.2067
I0414 19:10:54.282704 12023 solver.cpp:253]     Train net output #0: loss = 5.17465 (* 1 = 5.17465 loss)
I0414 19:10:54.282711 12023 sgd_solver.cpp:106] Iteration 1382400, lr = 3.9063e-05
I0414 19:17:23.082370 12023 solver.cpp:237] Iteration 1433600, loss = 5.17138
I0414 19:17:23.082458 12023 solver.cpp:253]     Train net output #0: loss = 4.22794 (* 1 = 4.22794 loss)
I0414 19:17:23.082465 12023 sgd_solver.cpp:106] Iteration 1433600, lr = 3.9063e-05
I0414 19:23:51.891820 12023 solver.cpp:237] Iteration 1484800, loss = 5.13194
I0414 19:23:51.891891 12023 solver.cpp:253]     Train net output #0: loss = 5.14975 (* 1 = 5.14975 loss)
I0414 19:23:51.891896 12023 sgd_solver.cpp:106] Iteration 1484800, lr = 3.9063e-05
I0414 19:30:20.719910 12023 solver.cpp:341] Iteration 1536000, Testing net (#0)
I0414 19:30:21.215420 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0414 19:30:47.065596 12023 solver.cpp:409]     Test net output #0: accuracy = 0.10126
I0414 19:30:47.065631 12023 solver.cpp:409]     Test net output #1: loss = 4.88721 (* 1 = 4.88721 loss)
I0414 19:30:47.069421 12023 solver.cpp:237] Iteration 1536000, loss = 5.11706
I0414 19:30:47.069439 12023 solver.cpp:253]     Train net output #0: loss = 4.37711 (* 1 = 4.37711 loss)
I0414 19:30:47.069445 12023 sgd_solver.cpp:106] Iteration 1536000, lr = 3.9063e-05
I0414 19:37:16.363889 12023 solver.cpp:237] Iteration 1587200, loss = 5.06751
I0414 19:37:16.363962 12023 solver.cpp:253]     Train net output #0: loss = 3.79824 (* 1 = 3.79824 loss)
I0414 19:37:16.363968 12023 sgd_solver.cpp:106] Iteration 1587200, lr = 3.9063e-05
I0414 19:43:45.437738 12023 solver.cpp:237] Iteration 1638400, loss = 5.03735
I0414 19:43:45.437798 12023 solver.cpp:253]     Train net output #0: loss = 6.19161 (* 1 = 6.19161 loss)
I0414 19:43:45.437804 12023 sgd_solver.cpp:106] Iteration 1638400, lr = 3.9063e-05
I0414 19:50:14.711874 12023 solver.cpp:237] Iteration 1689600, loss = 5.01505
I0414 19:50:14.711951 12023 solver.cpp:253]     Train net output #0: loss = 4.72937 (* 1 = 4.72937 loss)
I0414 19:50:14.711959 12023 sgd_solver.cpp:106] Iteration 1689600, lr = 3.9063e-05
I0414 19:56:43.882349 12023 solver.cpp:237] Iteration 1740800, loss = 4.96508
I0414 19:56:43.882417 12023 solver.cpp:253]     Train net output #0: loss = 3.91279 (* 1 = 3.91279 loss)
I0414 19:56:43.882423 12023 sgd_solver.cpp:106] Iteration 1740800, lr = 3.9063e-05
I0414 20:03:13.787490 12023 solver.cpp:341] Iteration 1792000, Testing net (#0)
I0414 20:03:14.397820 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0414 20:03:40.452345 12023 solver.cpp:409]     Test net output #0: accuracy = 0.11244
I0414 20:03:40.452381 12023 solver.cpp:409]     Test net output #1: loss = 4.75918 (* 1 = 4.75918 loss)
I0414 20:03:40.456146 12023 solver.cpp:237] Iteration 1792000, loss = 4.93554
I0414 20:03:40.456166 12023 solver.cpp:253]     Train net output #0: loss = 6.91511 (* 1 = 6.91511 loss)
I0414 20:03:40.456174 12023 sgd_solver.cpp:106] Iteration 1792000, lr = 3.9063e-05
I0414 20:10:10.060309 12023 solver.cpp:237] Iteration 1843200, loss = 4.90099
I0414 20:10:10.060374 12023 solver.cpp:253]     Train net output #0: loss = 8.85323 (* 1 = 8.85323 loss)
I0414 20:10:10.060380 12023 sgd_solver.cpp:106] Iteration 1843200, lr = 3.9063e-05
I0414 20:16:39.043732 12023 solver.cpp:237] Iteration 1894400, loss = 4.89512
I0414 20:16:39.043800 12023 solver.cpp:253]     Train net output #0: loss = 7.21092 (* 1 = 7.21092 loss)
I0414 20:16:39.043807 12023 sgd_solver.cpp:106] Iteration 1894400, lr = 3.9063e-05
I0414 20:23:08.012946 12023 solver.cpp:237] Iteration 1945600, loss = 4.85886
I0414 20:23:08.013018 12023 solver.cpp:253]     Train net output #0: loss = 2.59174 (* 1 = 2.59174 loss)
I0414 20:23:08.013025 12023 sgd_solver.cpp:106] Iteration 1945600, lr = 3.9063e-05
I0414 20:29:36.900223 12023 solver.cpp:237] Iteration 1996800, loss = 4.85216
I0414 20:29:36.900280 12023 solver.cpp:253]     Train net output #0: loss = 6.53447 (* 1 = 6.53447 loss)
I0414 20:29:36.900286 12023 sgd_solver.cpp:106] Iteration 1996800, lr = 3.9063e-05
I0414 20:36:05.875406 12023 solver.cpp:341] Iteration 2048000, Testing net (#0)
I0414 20:36:06.543751 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0414 20:36:35.413885 12023 solver.cpp:409]     Test net output #0: accuracy = 0.13366
I0414 20:36:35.413923 12023 solver.cpp:409]     Test net output #1: loss = 4.55329 (* 1 = 4.55329 loss)
I0414 20:36:35.417911 12023 solver.cpp:237] Iteration 2048000, loss = 4.80867
I0414 20:36:35.417932 12023 solver.cpp:253]     Train net output #0: loss = 9.37932 (* 1 = 9.37932 loss)
I0414 20:36:35.417942 12023 sgd_solver.cpp:106] Iteration 2048000, lr = 3.9063e-05
I0414 20:43:04.360780 12023 solver.cpp:237] Iteration 2099200, loss = 4.79147
I0414 20:43:04.360870 12023 solver.cpp:253]     Train net output #0: loss = 3.70974 (* 1 = 3.70974 loss)
I0414 20:43:04.360877 12023 sgd_solver.cpp:106] Iteration 2099200, lr = 3.9063e-05
I0414 20:49:33.279767 12023 solver.cpp:237] Iteration 2150400, loss = 4.772
I0414 20:49:33.279839 12023 solver.cpp:253]     Train net output #0: loss = 4.85921 (* 1 = 4.85921 loss)
I0414 20:49:33.279844 12023 sgd_solver.cpp:106] Iteration 2150400, lr = 3.9063e-05
I0414 20:56:02.588040 12023 solver.cpp:237] Iteration 2201600, loss = 4.72865
I0414 20:56:02.588111 12023 solver.cpp:253]     Train net output #0: loss = 4.55742 (* 1 = 4.55742 loss)
I0414 20:56:02.588117 12023 sgd_solver.cpp:106] Iteration 2201600, lr = 3.9063e-05
I0414 21:02:31.821420 12023 solver.cpp:237] Iteration 2252800, loss = 4.70486
I0414 21:02:31.821490 12023 solver.cpp:253]     Train net output #0: loss = 4.81317 (* 1 = 4.81317 loss)
I0414 21:02:31.821494 12023 sgd_solver.cpp:106] Iteration 2252800, lr = 3.9063e-05
I0414 21:09:01.004245 12023 solver.cpp:341] Iteration 2304000, Testing net (#0)
I0414 21:09:01.732631 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0414 21:09:30.265187 12023 solver.cpp:409]     Test net output #0: accuracy = 0.13528
I0414 21:09:30.265223 12023 solver.cpp:409]     Test net output #1: loss = 4.54373 (* 1 = 4.54373 loss)
I0414 21:09:30.268992 12023 solver.cpp:237] Iteration 2304000, loss = 4.68021
I0414 21:09:30.269011 12023 solver.cpp:253]     Train net output #0: loss = 4.95917 (* 1 = 4.95917 loss)
I0414 21:09:30.269021 12023 sgd_solver.cpp:106] Iteration 2304000, lr = 3.9063e-05
I0414 21:15:59.372097 12023 solver.cpp:237] Iteration 2355200, loss = 4.66589
I0414 21:15:59.372169 12023 solver.cpp:253]     Train net output #0: loss = 5.51758 (* 1 = 5.51758 loss)
I0414 21:15:59.372174 12023 sgd_solver.cpp:106] Iteration 2355200, lr = 3.9063e-05
I0414 21:22:28.290030 12023 solver.cpp:237] Iteration 2406400, loss = 4.63734
I0414 21:22:28.290105 12023 solver.cpp:253]     Train net output #0: loss = 5.04498 (* 1 = 5.04498 loss)
I0414 21:22:28.290112 12023 sgd_solver.cpp:106] Iteration 2406400, lr = 3.9063e-05
I0414 21:28:57.209499 12023 solver.cpp:237] Iteration 2457600, loss = 4.64384
I0414 21:28:57.209569 12023 solver.cpp:253]     Train net output #0: loss = 5.29244 (* 1 = 5.29244 loss)
I0414 21:28:57.209575 12023 sgd_solver.cpp:106] Iteration 2457600, lr = 3.9063e-05
I0414 21:35:26.106761 12023 solver.cpp:237] Iteration 2508800, loss = 4.59812
I0414 21:35:26.106827 12023 solver.cpp:253]     Train net output #0: loss = 4.63024 (* 1 = 4.63024 loss)
I0414 21:35:26.106832 12023 sgd_solver.cpp:106] Iteration 2508800, lr = 3.9063e-05
I0414 21:41:55.033946 12023 solver.cpp:459] Snapshotting to binary proto file snapshots/caffenet128_no_lrn_lsuv_relu_bs1_iter_2560000.caffemodel
I0414 21:41:55.524621 12023 sgd_solver.cpp:269] Snapshotting solver state to binary proto file snapshots/caffenet128_no_lrn_lsuv_relu_bs1_iter_2560000.solverstate
I0414 21:41:55.585610 12023 solver.cpp:341] Iteration 2560000, Testing net (#0)
I0414 21:41:56.308279 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0414 21:42:21.930140 12023 solver.cpp:409]     Test net output #0: accuracy = 0.15876
I0414 21:42:21.930176 12023 solver.cpp:409]     Test net output #1: loss = 4.37313 (* 1 = 4.37313 loss)
I0414 21:42:21.933969 12023 solver.cpp:237] Iteration 2560000, loss = 4.59897
I0414 21:42:21.933990 12023 solver.cpp:253]     Train net output #0: loss = 5.28055 (* 1 = 5.28055 loss)
I0414 21:42:21.933998 12023 sgd_solver.cpp:106] Iteration 2560000, lr = 3.9063e-05
I0414 21:48:51.200652 12023 solver.cpp:237] Iteration 2611200, loss = 4.57386
I0414 21:48:51.200731 12023 solver.cpp:253]     Train net output #0: loss = 2.41122 (* 1 = 2.41122 loss)
I0414 21:48:51.200736 12023 sgd_solver.cpp:106] Iteration 2611200, lr = 3.9063e-05
I0414 21:55:20.133759 12023 solver.cpp:237] Iteration 2662400, loss = 4.56247
I0414 21:55:20.133832 12023 solver.cpp:253]     Train net output #0: loss = 7.45639 (* 1 = 7.45639 loss)
I0414 21:55:20.133838 12023 sgd_solver.cpp:106] Iteration 2662400, lr = 3.9063e-05
I0414 22:01:49.054157 12023 solver.cpp:237] Iteration 2713600, loss = 4.52841
I0414 22:01:49.054225 12023 solver.cpp:253]     Train net output #0: loss = 3.18865 (* 1 = 3.18865 loss)
I0414 22:01:49.054232 12023 sgd_solver.cpp:106] Iteration 2713600, lr = 3.9063e-05
I0414 22:08:18.122056 12023 solver.cpp:237] Iteration 2764800, loss = 4.51233
I0414 22:08:18.122115 12023 solver.cpp:253]     Train net output #0: loss = 6.13046 (* 1 = 6.13046 loss)
I0414 22:08:18.122122 12023 sgd_solver.cpp:106] Iteration 2764800, lr = 3.9063e-05
I0414 22:14:47.237416 12023 solver.cpp:341] Iteration 2816000, Testing net (#0)
I0414 22:14:48.084260 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0414 22:15:16.769672 12023 solver.cpp:409]     Test net output #0: accuracy = 0.16486
I0414 22:15:16.769713 12023 solver.cpp:409]     Test net output #1: loss = 4.31315 (* 1 = 4.31315 loss)
I0414 22:15:16.773689 12023 solver.cpp:237] Iteration 2816000, loss = 4.50949
I0414 22:15:16.773733 12023 solver.cpp:253]     Train net output #0: loss = 4.85207 (* 1 = 4.85207 loss)
I0414 22:15:16.773746 12023 sgd_solver.cpp:106] Iteration 2816000, lr = 3.9063e-05
I0414 22:21:45.807479 12023 solver.cpp:237] Iteration 2867200, loss = 4.47831
I0414 22:21:45.807551 12023 solver.cpp:253]     Train net output #0: loss = 3.04777 (* 1 = 3.04777 loss)
I0414 22:21:45.807557 12023 sgd_solver.cpp:106] Iteration 2867200, lr = 3.9063e-05
I0414 22:28:14.734205 12023 solver.cpp:237] Iteration 2918400, loss = 4.47385
I0414 22:28:14.734277 12023 solver.cpp:253]     Train net output #0: loss = 6.767 (* 1 = 6.767 loss)
I0414 22:28:14.734282 12023 sgd_solver.cpp:106] Iteration 2918400, lr = 3.9063e-05
I0414 22:34:43.676822 12023 solver.cpp:237] Iteration 2969600, loss = 4.45782
I0414 22:34:43.676892 12023 solver.cpp:253]     Train net output #0: loss = 3.12631 (* 1 = 3.12631 loss)
I0414 22:34:43.676898 12023 sgd_solver.cpp:106] Iteration 2969600, lr = 3.9063e-05
I0414 22:41:12.580123 12023 solver.cpp:237] Iteration 3020800, loss = 4.41649
I0414 22:41:12.580193 12023 solver.cpp:253]     Train net output #0: loss = 5.73016 (* 1 = 5.73016 loss)
I0414 22:41:12.580199 12023 sgd_solver.cpp:106] Iteration 3020800, lr = 3.9063e-05
I0414 22:47:41.469859 12023 solver.cpp:341] Iteration 3072000, Testing net (#0)
I0414 22:47:42.376371 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0414 22:48:10.853438 12023 solver.cpp:409]     Test net output #0: accuracy = 0.17896
I0414 22:48:10.853473 12023 solver.cpp:409]     Test net output #1: loss = 4.19561 (* 1 = 4.19561 loss)
I0414 22:48:10.857203 12023 solver.cpp:237] Iteration 3072000, loss = 4.40576
I0414 22:48:10.857223 12023 solver.cpp:253]     Train net output #0: loss = 2.36677 (* 1 = 2.36677 loss)
I0414 22:48:10.857231 12023 sgd_solver.cpp:106] Iteration 3072000, lr = 3.9063e-05
I0414 22:54:40.226449 12023 solver.cpp:237] Iteration 3123200, loss = 4.38771
I0414 22:54:40.226508 12023 solver.cpp:253]     Train net output #0: loss = 4.72813 (* 1 = 4.72813 loss)
I0414 22:54:40.226516 12023 sgd_solver.cpp:106] Iteration 3123200, lr = 3.9063e-05
I0414 23:01:09.017316 12023 solver.cpp:237] Iteration 3174400, loss = 4.39856
I0414 23:01:09.017371 12023 solver.cpp:253]     Train net output #0: loss = 2.36847 (* 1 = 2.36847 loss)
I0414 23:01:09.017377 12023 sgd_solver.cpp:106] Iteration 3174400, lr = 3.9063e-05
I0414 23:07:37.813280 12023 solver.cpp:237] Iteration 3225600, loss = 4.3573
I0414 23:07:37.813349 12023 solver.cpp:253]     Train net output #0: loss = 4.96247 (* 1 = 4.96247 loss)
I0414 23:07:37.813355 12023 sgd_solver.cpp:106] Iteration 3225600, lr = 3.9063e-05
I0414 23:14:06.628293 12023 solver.cpp:237] Iteration 3276800, loss = 4.37049
I0414 23:14:06.628384 12023 solver.cpp:253]     Train net output #0: loss = 2.32343 (* 1 = 2.32343 loss)
I0414 23:14:06.628391 12023 sgd_solver.cpp:106] Iteration 3276800, lr = 3.9063e-05
I0414 23:20:35.783165 12023 solver.cpp:341] Iteration 3328000, Testing net (#0)
I0414 23:20:36.682286 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0414 23:21:02.133749 12023 solver.cpp:409]     Test net output #0: accuracy = 0.18738
I0414 23:21:02.133785 12023 solver.cpp:409]     Test net output #1: loss = 4.13542 (* 1 = 4.13542 loss)
I0414 23:21:02.137557 12023 solver.cpp:237] Iteration 3328000, loss = 4.35897
I0414 23:21:02.137576 12023 solver.cpp:253]     Train net output #0: loss = 4.26872 (* 1 = 4.26872 loss)
I0414 23:21:02.137584 12023 sgd_solver.cpp:106] Iteration 3328000, lr = 3.9063e-05
I0414 23:27:31.187552 12023 solver.cpp:237] Iteration 3379200, loss = 4.33315
I0414 23:27:31.187625 12023 solver.cpp:253]     Train net output #0: loss = 6.28001 (* 1 = 6.28001 loss)
I0414 23:27:31.187634 12023 sgd_solver.cpp:106] Iteration 3379200, lr = 3.9063e-05
I0414 23:34:00.271384 12023 solver.cpp:237] Iteration 3430400, loss = 4.31989
I0414 23:34:00.271457 12023 solver.cpp:253]     Train net output #0: loss = 1.12115 (* 1 = 1.12115 loss)
I0414 23:34:00.271463 12023 sgd_solver.cpp:106] Iteration 3430400, lr = 3.9063e-05
I0414 23:40:29.194638 12023 solver.cpp:237] Iteration 3481600, loss = 4.29458
I0414 23:40:29.194707 12023 solver.cpp:253]     Train net output #0: loss = 2.30546 (* 1 = 2.30546 loss)
I0414 23:40:29.194712 12023 sgd_solver.cpp:106] Iteration 3481600, lr = 3.9063e-05
I0414 23:46:57.983598 12023 solver.cpp:237] Iteration 3532800, loss = 4.27784
I0414 23:46:57.983669 12023 solver.cpp:253]     Train net output #0: loss = 6.33232 (* 1 = 6.33232 loss)
I0414 23:46:57.983676 12023 sgd_solver.cpp:106] Iteration 3532800, lr = 3.9063e-05
I0414 23:53:27.035863 12023 solver.cpp:341] Iteration 3584000, Testing net (#0)
I0414 23:53:28.001250 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0414 23:53:53.364372 12023 solver.cpp:409]     Test net output #0: accuracy = 0.18868
I0414 23:53:53.364406 12023 solver.cpp:409]     Test net output #1: loss = 4.13627 (* 1 = 4.13627 loss)
I0414 23:53:53.368214 12023 solver.cpp:237] Iteration 3584000, loss = 4.26424
I0414 23:53:53.368237 12023 solver.cpp:253]     Train net output #0: loss = 5.69405 (* 1 = 5.69405 loss)
I0414 23:53:53.368247 12023 sgd_solver.cpp:106] Iteration 3584000, lr = 3.9063e-05
I0415 00:00:22.882697 12023 solver.cpp:237] Iteration 3635200, loss = 4.25877
I0415 00:00:22.882767 12023 solver.cpp:253]     Train net output #0: loss = 5.30542 (* 1 = 5.30542 loss)
I0415 00:00:22.882773 12023 sgd_solver.cpp:106] Iteration 3635200, lr = 3.9063e-05
I0415 00:06:52.105020 12023 solver.cpp:237] Iteration 3686400, loss = 4.22738
I0415 00:06:52.105078 12023 solver.cpp:253]     Train net output #0: loss = 4.78051 (* 1 = 4.78051 loss)
I0415 00:06:52.105083 12023 sgd_solver.cpp:106] Iteration 3686400, lr = 3.9063e-05
I0415 00:13:21.321852 12023 solver.cpp:237] Iteration 3737600, loss = 4.25138
I0415 00:13:21.321923 12023 solver.cpp:253]     Train net output #0: loss = 5.9066 (* 1 = 5.9066 loss)
I0415 00:13:21.321929 12023 sgd_solver.cpp:106] Iteration 3737600, lr = 3.9063e-05
I0415 00:19:50.507827 12023 solver.cpp:237] Iteration 3788800, loss = 4.21222
I0415 00:19:50.507889 12023 solver.cpp:253]     Train net output #0: loss = 1.15517 (* 1 = 1.15517 loss)
I0415 00:19:50.507894 12023 sgd_solver.cpp:106] Iteration 3788800, lr = 3.9063e-05
I0415 00:26:19.664249 12023 solver.cpp:341] Iteration 3840000, Testing net (#0)
I0415 00:26:20.710865 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0415 00:26:45.989833 12023 solver.cpp:409]     Test net output #0: accuracy = 0.20358
I0415 00:26:45.989868 12023 solver.cpp:409]     Test net output #1: loss = 3.99405 (* 1 = 3.99405 loss)
I0415 00:26:45.993662 12023 solver.cpp:237] Iteration 3840000, loss = 4.22913
I0415 00:26:45.993686 12023 solver.cpp:253]     Train net output #0: loss = 0.282536 (* 1 = 0.282536 loss)
I0415 00:26:45.993696 12023 sgd_solver.cpp:106] Iteration 3840000, lr = 3.9063e-05
I0415 00:33:15.435400 12023 solver.cpp:237] Iteration 3891200, loss = 4.2116
I0415 00:33:15.435479 12023 solver.cpp:253]     Train net output #0: loss = 1.93742 (* 1 = 1.93742 loss)
I0415 00:33:15.435487 12023 sgd_solver.cpp:106] Iteration 3891200, lr = 3.9063e-05
I0415 00:39:44.651732 12023 solver.cpp:237] Iteration 3942400, loss = 4.19753
I0415 00:39:44.651793 12023 solver.cpp:253]     Train net output #0: loss = 4.80122 (* 1 = 4.80122 loss)
I0415 00:39:44.651798 12023 sgd_solver.cpp:106] Iteration 3942400, lr = 3.9063e-05
I0415 00:46:13.500636 12023 solver.cpp:237] Iteration 3993600, loss = 4.19089
I0415 00:46:13.500697 12023 solver.cpp:253]     Train net output #0: loss = 1.90342 (* 1 = 1.90342 loss)
I0415 00:46:13.500704 12023 sgd_solver.cpp:106] Iteration 3993600, lr = 3.9063e-05
I0415 00:52:42.692008 12023 solver.cpp:237] Iteration 4044800, loss = 4.15996
I0415 00:52:42.692076 12023 solver.cpp:253]     Train net output #0: loss = 2.90903 (* 1 = 2.90903 loss)
I0415 00:52:42.692082 12023 sgd_solver.cpp:106] Iteration 4044800, lr = 3.9063e-05
I0415 00:59:11.948770 12023 solver.cpp:341] Iteration 4096000, Testing net (#0)
I0415 00:59:13.153432 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0415 00:59:41.484886 12023 solver.cpp:409]     Test net output #0: accuracy = 0.21246
I0415 00:59:41.484927 12023 solver.cpp:409]     Test net output #1: loss = 3.93237 (* 1 = 3.93237 loss)
I0415 00:59:41.488868 12023 solver.cpp:237] Iteration 4096000, loss = 4.16747
I0415 00:59:41.488893 12023 solver.cpp:253]     Train net output #0: loss = 2.71706 (* 1 = 2.71706 loss)
I0415 00:59:41.488903 12023 sgd_solver.cpp:106] Iteration 4096000, lr = 3.9063e-05
I0415 01:06:10.475415 12023 solver.cpp:237] Iteration 4147200, loss = 4.13563
I0415 01:06:10.475473 12023 solver.cpp:253]     Train net output #0: loss = 4.07609 (* 1 = 4.07609 loss)
I0415 01:06:10.475479 12023 sgd_solver.cpp:106] Iteration 4147200, lr = 3.9063e-05
I0415 01:12:39.302096 12023 solver.cpp:237] Iteration 4198400, loss = 4.14611
I0415 01:12:39.302157 12023 solver.cpp:253]     Train net output #0: loss = 0.000115044 (* 1 = 0.000115044 loss)
I0415 01:12:39.302165 12023 sgd_solver.cpp:106] Iteration 4198400, lr = 3.9063e-05
I0415 01:19:08.487201 12023 solver.cpp:237] Iteration 4249600, loss = 4.14193
I0415 01:19:08.487262 12023 solver.cpp:253]     Train net output #0: loss = 6.57662 (* 1 = 6.57662 loss)
I0415 01:19:08.487268 12023 sgd_solver.cpp:106] Iteration 4249600, lr = 3.9063e-05
I0415 01:25:37.630681 12023 solver.cpp:237] Iteration 4300800, loss = 4.10949
I0415 01:25:37.630750 12023 solver.cpp:253]     Train net output #0: loss = 1.81174 (* 1 = 1.81174 loss)
I0415 01:25:37.630756 12023 sgd_solver.cpp:106] Iteration 4300800, lr = 3.9063e-05
I0415 01:32:06.437073 12023 solver.cpp:341] Iteration 4352000, Testing net (#0)
I0415 01:32:07.596973 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0415 01:32:32.773921 12023 solver.cpp:409]     Test net output #0: accuracy = 0.2187
I0415 01:32:32.773953 12023 solver.cpp:409]     Test net output #1: loss = 3.88748 (* 1 = 3.88748 loss)
I0415 01:32:32.777688 12023 solver.cpp:237] Iteration 4352000, loss = 4.09597
I0415 01:32:32.777707 12023 solver.cpp:253]     Train net output #0: loss = 4.17983 (* 1 = 4.17983 loss)
I0415 01:32:32.777714 12023 sgd_solver.cpp:106] Iteration 4352000, lr = 3.9063e-05
I0415 01:39:01.632967 12023 solver.cpp:237] Iteration 4403200, loss = 4.07496
I0415 01:39:01.633038 12023 solver.cpp:253]     Train net output #0: loss = 6.26694 (* 1 = 6.26694 loss)
I0415 01:39:01.633044 12023 sgd_solver.cpp:106] Iteration 4403200, lr = 3.9063e-05
I0415 01:45:30.419339 12023 solver.cpp:237] Iteration 4454400, loss = 4.09056
I0415 01:45:30.419396 12023 solver.cpp:253]     Train net output #0: loss = 6.76232 (* 1 = 6.76232 loss)
I0415 01:45:30.419401 12023 sgd_solver.cpp:106] Iteration 4454400, lr = 3.9063e-05
I0415 01:51:59.480748 12023 solver.cpp:237] Iteration 4505600, loss = 4.06141
I0415 01:51:59.480831 12023 solver.cpp:253]     Train net output #0: loss = 4.94219 (* 1 = 4.94219 loss)
I0415 01:51:59.480842 12023 sgd_solver.cpp:106] Iteration 4505600, lr = 3.9063e-05
I0415 01:58:28.403733 12023 solver.cpp:237] Iteration 4556800, loss = 4.07915
I0415 01:58:28.403805 12023 solver.cpp:253]     Train net output #0: loss = 0.41381 (* 1 = 0.41381 loss)
I0415 01:58:28.403811 12023 sgd_solver.cpp:106] Iteration 4556800, lr = 3.9063e-05
I0415 02:04:57.241624 12023 solver.cpp:341] Iteration 4608000, Testing net (#0)
I0415 02:04:58.486992 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0415 02:05:23.604110 12023 solver.cpp:409]     Test net output #0: accuracy = 0.21886
I0415 02:05:23.604146 12023 solver.cpp:409]     Test net output #1: loss = 3.89948 (* 1 = 3.89948 loss)
I0415 02:05:23.607888 12023 solver.cpp:237] Iteration 4608000, loss = 4.06481
I0415 02:05:23.607908 12023 solver.cpp:253]     Train net output #0: loss = 2.60868 (* 1 = 2.60868 loss)
I0415 02:05:23.607915 12023 sgd_solver.cpp:106] Iteration 4608000, lr = 3.9063e-05
I0415 02:11:52.552769 12023 solver.cpp:237] Iteration 4659200, loss = 4.05891
I0415 02:11:52.552839 12023 solver.cpp:253]     Train net output #0: loss = 4.77091 (* 1 = 4.77091 loss)
I0415 02:11:52.552845 12023 sgd_solver.cpp:106] Iteration 4659200, lr = 3.9063e-05
I0415 02:18:21.348933 12023 solver.cpp:237] Iteration 4710400, loss = 4.0486
I0415 02:18:21.348984 12023 solver.cpp:253]     Train net output #0: loss = 2.58807 (* 1 = 2.58807 loss)
I0415 02:18:21.348989 12023 sgd_solver.cpp:106] Iteration 4710400, lr = 3.9063e-05
I0415 02:24:50.455948 12023 solver.cpp:237] Iteration 4761600, loss = 4.02031
I0415 02:24:50.456007 12023 solver.cpp:253]     Train net output #0: loss = 1.78522 (* 1 = 1.78522 loss)
I0415 02:24:50.456014 12023 sgd_solver.cpp:106] Iteration 4761600, lr = 3.9063e-05
I0415 02:31:19.657701 12023 solver.cpp:237] Iteration 4812800, loss = 4.01298
I0415 02:31:19.657771 12023 solver.cpp:253]     Train net output #0: loss = 3.46908 (* 1 = 3.46908 loss)
I0415 02:31:19.657776 12023 sgd_solver.cpp:106] Iteration 4812800, lr = 3.9063e-05
I0415 02:37:48.476724 12023 solver.cpp:341] Iteration 4864000, Testing net (#0)
I0415 02:37:49.918131 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0415 02:38:18.019630 12023 solver.cpp:409]     Test net output #0: accuracy = 0.23444
I0415 02:38:18.019668 12023 solver.cpp:409]     Test net output #1: loss = 3.79322 (* 1 = 3.79322 loss)
I0415 02:38:18.023591 12023 solver.cpp:237] Iteration 4864000, loss = 3.99962
I0415 02:38:18.023610 12023 solver.cpp:253]     Train net output #0: loss = 1.47399 (* 1 = 1.47399 loss)
I0415 02:38:18.023619 12023 sgd_solver.cpp:106] Iteration 4864000, lr = 3.9063e-05
I0415 02:44:46.892534 12023 solver.cpp:237] Iteration 4915200, loss = 4.00017
I0415 02:44:46.892606 12023 solver.cpp:253]     Train net output #0: loss = 0.172101 (* 1 = 0.172101 loss)
I0415 02:44:46.892611 12023 sgd_solver.cpp:106] Iteration 4915200, lr = 3.9063e-05
I0415 02:51:15.707187 12023 solver.cpp:237] Iteration 4966400, loss = 3.97433
I0415 02:51:15.707249 12023 solver.cpp:253]     Train net output #0: loss = 2.91925 (* 1 = 2.91925 loss)
I0415 02:51:15.707260 12023 sgd_solver.cpp:106] Iteration 4966400, lr = 3.9063e-05
I0415 02:57:44.551728 12023 solver.cpp:237] Iteration 5017600, loss = 3.99628
I0415 02:57:44.551800 12023 solver.cpp:253]     Train net output #0: loss = 3.46503 (* 1 = 3.46503 loss)
I0415 02:57:44.551811 12023 sgd_solver.cpp:106] Iteration 5017600, lr = 3.9063e-05
I0415 03:04:13.387086 12023 solver.cpp:237] Iteration 5068800, loss = 3.95989
I0415 03:04:13.387159 12023 solver.cpp:253]     Train net output #0: loss = 2.24154 (* 1 = 2.24154 loss)
I0415 03:04:13.387168 12023 sgd_solver.cpp:106] Iteration 5068800, lr = 3.9063e-05
I0415 03:10:42.524461 12023 solver.cpp:459] Snapshotting to binary proto file snapshots/caffenet128_no_lrn_lsuv_relu_bs1_iter_5120000.caffemodel
I0415 03:10:43.297219 12023 sgd_solver.cpp:269] Snapshotting solver state to binary proto file snapshots/caffenet128_no_lrn_lsuv_relu_bs1_iter_5120000.solverstate
I0415 03:10:43.358695 12023 solver.cpp:341] Iteration 5120000, Testing net (#0)
I0415 03:10:44.717564 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0415 03:11:09.718955 12023 solver.cpp:409]     Test net output #0: accuracy = 0.24246
I0415 03:11:09.718991 12023 solver.cpp:409]     Test net output #1: loss = 3.73196 (* 1 = 3.73196 loss)
I0415 03:11:09.722774 12023 solver.cpp:237] Iteration 5120000, loss = 3.99131
I0415 03:11:09.722792 12023 solver.cpp:253]     Train net output #0: loss = 7.99624 (* 1 = 7.99624 loss)
I0415 03:11:09.722801 12023 sgd_solver.cpp:106] Iteration 5120000, lr = 3.9063e-05
I0415 03:17:39.164810 12023 solver.cpp:237] Iteration 5171200, loss = 3.96658
I0415 03:17:39.164893 12023 solver.cpp:253]     Train net output #0: loss = 2.71289 (* 1 = 2.71289 loss)
I0415 03:17:39.164903 12023 sgd_solver.cpp:106] Iteration 5171200, lr = 3.9063e-05
I0415 03:24:08.383366 12023 solver.cpp:237] Iteration 5222400, loss = 3.96301
I0415 03:24:08.383432 12023 solver.cpp:253]     Train net output #0: loss = 7.14472 (* 1 = 7.14472 loss)
I0415 03:24:08.383442 12023 sgd_solver.cpp:106] Iteration 5222400, lr = 3.9063e-05
I0415 03:30:37.727567 12023 solver.cpp:237] Iteration 5273600, loss = 3.95095
I0415 03:30:37.727627 12023 solver.cpp:253]     Train net output #0: loss = 1.9333 (* 1 = 1.9333 loss)
I0415 03:30:37.727633 12023 sgd_solver.cpp:106] Iteration 5273600, lr = 3.9063e-05
I0415 03:37:07.018023 12023 solver.cpp:237] Iteration 5324800, loss = 3.9268
I0415 03:37:07.018081 12023 solver.cpp:253]     Train net output #0: loss = 3.62608 (* 1 = 3.62608 loss)
I0415 03:37:07.018086 12023 sgd_solver.cpp:106] Iteration 5324800, lr = 3.9063e-05
I0415 03:43:36.169397 12023 solver.cpp:341] Iteration 5376000, Testing net (#0)
I0415 03:43:37.584223 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0415 03:44:02.508172 12023 solver.cpp:409]     Test net output #0: accuracy = 0.24368
I0415 03:44:02.508208 12023 solver.cpp:409]     Test net output #1: loss = 3.72107 (* 1 = 3.72107 loss)
I0415 03:44:02.511968 12023 solver.cpp:237] Iteration 5376000, loss = 3.94009
I0415 03:44:02.511988 12023 solver.cpp:253]     Train net output #0: loss = 5.59657 (* 1 = 5.59657 loss)
I0415 03:44:02.511996 12023 sgd_solver.cpp:106] Iteration 5376000, lr = 3.9063e-05
I0415 03:50:31.862331 12023 solver.cpp:237] Iteration 5427200, loss = 3.91895
I0415 03:50:31.862403 12023 solver.cpp:253]     Train net output #0: loss = 6.63921 (* 1 = 6.63921 loss)
I0415 03:50:31.862409 12023 sgd_solver.cpp:106] Iteration 5427200, lr = 3.9063e-05
I0415 03:57:01.060655 12023 solver.cpp:237] Iteration 5478400, loss = 3.92026
I0415 03:57:01.060715 12023 solver.cpp:253]     Train net output #0: loss = 1.18395 (* 1 = 1.18395 loss)
I0415 03:57:01.060721 12023 sgd_solver.cpp:106] Iteration 5478400, lr = 3.9063e-05
I0415 04:03:30.101157 12023 solver.cpp:237] Iteration 5529600, loss = 3.922
I0415 04:03:30.101227 12023 solver.cpp:253]     Train net output #0: loss = 4.0686 (* 1 = 4.0686 loss)
I0415 04:03:30.101233 12023 sgd_solver.cpp:106] Iteration 5529600, lr = 3.9063e-05
I0415 04:09:58.877562 12023 solver.cpp:237] Iteration 5580800, loss = 3.89472
I0415 04:09:58.877631 12023 solver.cpp:253]     Train net output #0: loss = 3.47103 (* 1 = 3.47103 loss)
I0415 04:09:58.877638 12023 sgd_solver.cpp:106] Iteration 5580800, lr = 3.9063e-05
I0415 04:16:27.689366 12023 solver.cpp:341] Iteration 5632000, Testing net (#0)
I0415 04:16:29.205451 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0415 04:16:54.082077 12023 solver.cpp:409]     Test net output #0: accuracy = 0.24622
I0415 04:16:54.082111 12023 solver.cpp:409]     Test net output #1: loss = 3.6916 (* 1 = 3.6916 loss)
I0415 04:16:54.085877 12023 solver.cpp:237] Iteration 5632000, loss = 3.88634
I0415 04:16:54.085898 12023 solver.cpp:253]     Train net output #0: loss = 1.70109 (* 1 = 1.70109 loss)
I0415 04:16:54.085907 12023 sgd_solver.cpp:106] Iteration 5632000, lr = 3.9063e-05
I0415 04:23:23.006402 12023 solver.cpp:237] Iteration 5683200, loss = 3.8728
I0415 04:23:23.006497 12023 solver.cpp:253]     Train net output #0: loss = 3.27325 (* 1 = 3.27325 loss)
I0415 04:23:23.006511 12023 sgd_solver.cpp:106] Iteration 5683200, lr = 3.9063e-05
I0415 04:29:51.887177 12023 solver.cpp:237] Iteration 5734400, loss = 3.89084
I0415 04:29:51.887248 12023 solver.cpp:253]     Train net output #0: loss = 4.0836 (* 1 = 4.0836 loss)
I0415 04:29:51.887253 12023 sgd_solver.cpp:106] Iteration 5734400, lr = 3.9063e-05
I0415 04:36:20.692658 12023 solver.cpp:237] Iteration 5785600, loss = 3.86349
I0415 04:36:20.692728 12023 solver.cpp:253]     Train net output #0: loss = 5.66858 (* 1 = 5.66858 loss)
I0415 04:36:20.692734 12023 sgd_solver.cpp:106] Iteration 5785600, lr = 3.9063e-05
I0415 04:42:49.490830 12023 solver.cpp:237] Iteration 5836800, loss = 3.87337
I0415 04:42:49.490900 12023 solver.cpp:253]     Train net output #0: loss = 0.0226239 (* 1 = 0.0226239 loss)
I0415 04:42:49.490906 12023 sgd_solver.cpp:106] Iteration 5836800, lr = 3.9063e-05
I0415 04:49:18.283228 12023 solver.cpp:341] Iteration 5888000, Testing net (#0)
I0415 04:49:19.878155 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0415 04:49:44.679570 12023 solver.cpp:409]     Test net output #0: accuracy = 0.24826
I0415 04:49:44.679605 12023 solver.cpp:409]     Test net output #1: loss = 3.69016 (* 1 = 3.69016 loss)
I0415 04:49:44.683374 12023 solver.cpp:237] Iteration 5888000, loss = 3.87407
I0415 04:49:44.683393 12023 solver.cpp:253]     Train net output #0: loss = 5.39875 (* 1 = 5.39875 loss)
I0415 04:49:44.683403 12023 sgd_solver.cpp:106] Iteration 5888000, lr = 3.9063e-05
I0415 04:56:13.686554 12023 solver.cpp:237] Iteration 5939200, loss = 3.86215
I0415 04:56:13.686614 12023 solver.cpp:253]     Train net output #0: loss = 7.1238 (* 1 = 7.1238 loss)
I0415 04:56:13.686619 12023 sgd_solver.cpp:106] Iteration 5939200, lr = 3.9063e-05
I0415 05:02:42.489629 12023 solver.cpp:237] Iteration 5990400, loss = 3.85867
I0415 05:02:42.489699 12023 solver.cpp:253]     Train net output #0: loss = 2.20274 (* 1 = 2.20274 loss)
I0415 05:02:42.489706 12023 sgd_solver.cpp:106] Iteration 5990400, lr = 3.9063e-05
I0415 05:09:11.381677 12023 solver.cpp:237] Iteration 6041600, loss = 3.83032
I0415 05:09:11.381739 12023 solver.cpp:253]     Train net output #0: loss = 9.17268 (* 1 = 9.17268 loss)
I0415 05:09:11.381745 12023 sgd_solver.cpp:106] Iteration 6041600, lr = 3.9063e-05
I0415 05:15:40.643237 12023 solver.cpp:237] Iteration 6092800, loss = 3.82213
I0415 05:15:40.643307 12023 solver.cpp:253]     Train net output #0: loss = 0.147862 (* 1 = 0.147862 loss)
I0415 05:15:40.643313 12023 sgd_solver.cpp:106] Iteration 6092800, lr = 3.9063e-05
I0415 05:22:09.467242 12023 solver.cpp:341] Iteration 6144000, Testing net (#0)
I0415 05:22:11.139715 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0415 05:22:35.820996 12023 solver.cpp:409]     Test net output #0: accuracy = 0.2584
I0415 05:22:35.821032 12023 solver.cpp:409]     Test net output #1: loss = 3.62953 (* 1 = 3.62953 loss)
I0415 05:22:35.824811 12023 solver.cpp:237] Iteration 6144000, loss = 3.81633
I0415 05:22:35.824832 12023 solver.cpp:253]     Train net output #0: loss = 4.14679 (* 1 = 4.14679 loss)
I0415 05:22:35.824842 12023 sgd_solver.cpp:106] Iteration 6144000, lr = 3.9063e-05
I0415 05:29:04.756831 12023 solver.cpp:237] Iteration 6195200, loss = 3.81307
I0415 05:29:04.756893 12023 solver.cpp:253]     Train net output #0: loss = 0.0945373 (* 1 = 0.0945373 loss)
I0415 05:29:04.756901 12023 sgd_solver.cpp:106] Iteration 6195200, lr = 3.9063e-05
I0415 05:35:33.925550 12023 solver.cpp:237] Iteration 6246400, loss = 3.80588
I0415 05:35:33.925622 12023 solver.cpp:253]     Train net output #0: loss = 7.12199 (* 1 = 7.12199 loss)
I0415 05:35:33.925629 12023 sgd_solver.cpp:106] Iteration 6246400, lr = 3.9063e-05
I0415 05:42:03.113478 12023 solver.cpp:237] Iteration 6297600, loss = 3.82536
I0415 05:42:03.113539 12023 solver.cpp:253]     Train net output #0: loss = 4.1804 (* 1 = 4.1804 loss)
I0415 05:42:03.113545 12023 sgd_solver.cpp:106] Iteration 6297600, lr = 3.9063e-05
I0415 05:48:32.282287 12023 solver.cpp:237] Iteration 6348800, loss = 3.78153
I0415 05:48:32.282368 12023 solver.cpp:253]     Train net output #0: loss = 3.52549 (* 1 = 3.52549 loss)
I0415 05:48:32.282376 12023 sgd_solver.cpp:106] Iteration 6348800, lr = 3.9063e-05
I0415 05:55:01.448781 12023 solver.cpp:341] Iteration 6400000, Testing net (#0)
I0415 05:55:03.361847 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0415 05:55:30.995450 12023 solver.cpp:409]     Test net output #0: accuracy = 0.26294
I0415 05:55:30.995489 12023 solver.cpp:409]     Test net output #1: loss = 3.60265 (* 1 = 3.60265 loss)
I0415 05:55:30.999449 12023 solver.cpp:237] Iteration 6400000, loss = 3.80554
I0415 05:55:30.999469 12023 solver.cpp:253]     Train net output #0: loss = 0.905541 (* 1 = 0.905541 loss)
I0415 05:55:30.999478 12023 sgd_solver.cpp:106] Iteration 6400000, lr = 3.9063e-05
I0415 06:02:00.149044 12023 solver.cpp:237] Iteration 6451200, loss = 3.80078
I0415 06:02:00.149104 12023 solver.cpp:253]     Train net output #0: loss = 6.26564 (* 1 = 6.26564 loss)
I0415 06:02:00.149116 12023 sgd_solver.cpp:106] Iteration 6451200, lr = 3.9063e-05
I0415 06:08:29.237893 12023 solver.cpp:237] Iteration 6502400, loss = 3.79985
I0415 06:08:29.237965 12023 solver.cpp:253]     Train net output #0: loss = 6.167 (* 1 = 6.167 loss)
I0415 06:08:29.237973 12023 sgd_solver.cpp:106] Iteration 6502400, lr = 3.9063e-05
I0415 06:14:58.264955 12023 solver.cpp:237] Iteration 6553600, loss = 3.78857
I0415 06:14:58.265025 12023 solver.cpp:253]     Train net output #0: loss = 4.3645 (* 1 = 4.3645 loss)
I0415 06:14:58.265033 12023 sgd_solver.cpp:106] Iteration 6553600, lr = 3.9063e-05
I0415 06:21:27.060341 12023 solver.cpp:237] Iteration 6604800, loss = 3.76504
I0415 06:21:27.060410 12023 solver.cpp:253]     Train net output #0: loss = 2.37451 (* 1 = 2.37451 loss)
I0415 06:21:27.060416 12023 sgd_solver.cpp:106] Iteration 6604800, lr = 3.9063e-05
I0415 06:27:55.838085 12023 solver.cpp:341] Iteration 6656000, Testing net (#0)
I0415 06:27:57.780172 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0415 06:28:25.381525 12023 solver.cpp:409]     Test net output #0: accuracy = 0.26632
I0415 06:28:25.381564 12023 solver.cpp:409]     Test net output #1: loss = 3.55613 (* 1 = 3.55613 loss)
I0415 06:28:25.385517 12023 solver.cpp:237] Iteration 6656000, loss = 3.78308
I0415 06:28:25.385537 12023 solver.cpp:253]     Train net output #0: loss = 3.83989 (* 1 = 3.83989 loss)
I0415 06:28:25.385545 12023 sgd_solver.cpp:106] Iteration 6656000, lr = 3.9063e-05
I0415 06:34:54.042906 12023 solver.cpp:237] Iteration 6707200, loss = 3.76004
I0415 06:34:54.042978 12023 solver.cpp:253]     Train net output #0: loss = 5.96188 (* 1 = 5.96188 loss)
I0415 06:34:54.042984 12023 sgd_solver.cpp:106] Iteration 6707200, lr = 3.9063e-05
I0415 06:41:22.825489 12023 solver.cpp:237] Iteration 6758400, loss = 3.75875
I0415 06:41:22.825547 12023 solver.cpp:253]     Train net output #0: loss = 3.55134 (* 1 = 3.55134 loss)
I0415 06:41:22.825553 12023 sgd_solver.cpp:106] Iteration 6758400, lr = 3.9063e-05
I0415 06:47:51.803946 12023 solver.cpp:237] Iteration 6809600, loss = 3.76099
I0415 06:47:51.804016 12023 solver.cpp:253]     Train net output #0: loss = 5.59413 (* 1 = 5.59413 loss)
I0415 06:47:51.804023 12023 sgd_solver.cpp:106] Iteration 6809600, lr = 3.9063e-05
I0415 06:54:21.008170 12023 solver.cpp:237] Iteration 6860800, loss = 3.7379
I0415 06:54:21.008240 12023 solver.cpp:253]     Train net output #0: loss = 5.53627 (* 1 = 5.53627 loss)
I0415 06:54:21.008246 12023 sgd_solver.cpp:106] Iteration 6860800, lr = 3.9063e-05
I0415 07:00:49.786697 12023 solver.cpp:341] Iteration 6912000, Testing net (#0)
I0415 07:00:51.787406 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0415 07:01:19.332345 12023 solver.cpp:409]     Test net output #0: accuracy = 0.26586
I0415 07:01:19.332383 12023 solver.cpp:409]     Test net output #1: loss = 3.56244 (* 1 = 3.56244 loss)
I0415 07:01:19.336328 12023 solver.cpp:237] Iteration 6912000, loss = 3.7426
I0415 07:01:19.336349 12023 solver.cpp:253]     Train net output #0: loss = 4.79623 (* 1 = 4.79623 loss)
I0415 07:01:19.336359 12023 sgd_solver.cpp:106] Iteration 6912000, lr = 3.9063e-05
I0415 07:07:48.024418 12023 solver.cpp:237] Iteration 6963200, loss = 3.73308
I0415 07:07:48.024502 12023 solver.cpp:253]     Train net output #0: loss = 1.03426 (* 1 = 1.03426 loss)
I0415 07:07:48.024509 12023 sgd_solver.cpp:106] Iteration 6963200, lr = 3.9063e-05
I0415 07:14:17.277621 12023 solver.cpp:237] Iteration 7014400, loss = 3.73259
I0415 07:14:17.277683 12023 solver.cpp:253]     Train net output #0: loss = 0.50173 (* 1 = 0.50173 loss)
I0415 07:14:17.277689 12023 sgd_solver.cpp:106] Iteration 7014400, lr = 3.9063e-05
I0415 07:20:46.535854 12023 solver.cpp:237] Iteration 7065600, loss = 3.7254
I0415 07:20:46.535917 12023 solver.cpp:253]     Train net output #0: loss = 1.96729 (* 1 = 1.96729 loss)
I0415 07:20:46.535923 12023 sgd_solver.cpp:106] Iteration 7065600, lr = 3.9063e-05
I0415 07:27:15.639634 12023 solver.cpp:237] Iteration 7116800, loss = 3.72833
I0415 07:27:15.639695 12023 solver.cpp:253]     Train net output #0: loss = 3.33233 (* 1 = 3.33233 loss)
I0415 07:27:15.639701 12023 sgd_solver.cpp:106] Iteration 7116800, lr = 3.9063e-05
I0415 07:33:44.849715 12023 solver.cpp:341] Iteration 7168000, Testing net (#0)
I0415 07:33:46.908355 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0415 07:34:14.391850 12023 solver.cpp:409]     Test net output #0: accuracy = 0.27324
I0415 07:34:14.391891 12023 solver.cpp:409]     Test net output #1: loss = 3.5424 (* 1 = 3.5424 loss)
I0415 07:34:14.395844 12023 solver.cpp:237] Iteration 7168000, loss = 3.73665
I0415 07:34:14.395867 12023 solver.cpp:253]     Train net output #0: loss = 0.757972 (* 1 = 0.757972 loss)
I0415 07:34:14.395876 12023 sgd_solver.cpp:106] Iteration 7168000, lr = 3.9063e-05
I0415 07:40:42.939045 12023 solver.cpp:237] Iteration 7219200, loss = 3.71778
I0415 07:40:42.939116 12023 solver.cpp:253]     Train net output #0: loss = 4.90474 (* 1 = 4.90474 loss)
I0415 07:40:42.939122 12023 sgd_solver.cpp:106] Iteration 7219200, lr = 3.9063e-05
I0415 07:47:11.689620 12023 solver.cpp:237] Iteration 7270400, loss = 3.72532
I0415 07:47:11.689677 12023 solver.cpp:253]     Train net output #0: loss = 2.8863 (* 1 = 2.8863 loss)
I0415 07:47:11.689682 12023 sgd_solver.cpp:106] Iteration 7270400, lr = 3.9063e-05
I0415 07:53:40.448985 12023 solver.cpp:237] Iteration 7321600, loss = 3.70699
I0415 07:53:40.449043 12023 solver.cpp:253]     Train net output #0: loss = 7.49802 (* 1 = 7.49802 loss)
I0415 07:53:40.449048 12023 sgd_solver.cpp:106] Iteration 7321600, lr = 3.9063e-05
I0415 08:00:09.234459 12023 solver.cpp:237] Iteration 7372800, loss = 3.68224
I0415 08:00:09.234526 12023 solver.cpp:253]     Train net output #0: loss = 4.77955 (* 1 = 4.77955 loss)
I0415 08:00:09.234532 12023 sgd_solver.cpp:106] Iteration 7372800, lr = 3.9063e-05
I0415 08:06:38.380235 12023 solver.cpp:341] Iteration 7424000, Testing net (#0)
I0415 08:06:40.293356 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0415 08:07:04.707489 12023 solver.cpp:409]     Test net output #0: accuracy = 0.28018
I0415 08:07:04.707523 12023 solver.cpp:409]     Test net output #1: loss = 3.48618 (* 1 = 3.48618 loss)
I0415 08:07:04.711304 12023 solver.cpp:237] Iteration 7424000, loss = 3.68937
I0415 08:07:04.711326 12023 solver.cpp:253]     Train net output #0: loss = 3.5624 (* 1 = 3.5624 loss)
I0415 08:07:04.711336 12023 sgd_solver.cpp:106] Iteration 7424000, lr = 3.9063e-05
I0415 08:13:34.044677 12023 solver.cpp:237] Iteration 7475200, loss = 3.68854
I0415 08:13:34.044739 12023 solver.cpp:253]     Train net output #0: loss = 4.99368 (* 1 = 4.99368 loss)
I0415 08:13:34.044749 12023 sgd_solver.cpp:106] Iteration 7475200, lr = 3.9063e-05
I0415 08:20:02.840108 12023 solver.cpp:237] Iteration 7526400, loss = 3.68565
I0415 08:20:02.840168 12023 solver.cpp:253]     Train net output #0: loss = 5.68052 (* 1 = 5.68052 loss)
I0415 08:20:02.840178 12023 sgd_solver.cpp:106] Iteration 7526400, lr = 3.9063e-05
I0415 08:26:31.613415 12023 solver.cpp:237] Iteration 7577600, loss = 3.68903
I0415 08:26:31.613507 12023 solver.cpp:253]     Train net output #0: loss = 3.81297 (* 1 = 3.81297 loss)
I0415 08:26:31.613520 12023 sgd_solver.cpp:106] Iteration 7577600, lr = 3.9063e-05
I0415 08:33:00.602993 12023 solver.cpp:237] Iteration 7628800, loss = 3.6634
I0415 08:33:00.603065 12023 solver.cpp:253]     Train net output #0: loss = 1.67087 (* 1 = 1.67087 loss)
I0415 08:33:00.603071 12023 sgd_solver.cpp:106] Iteration 7628800, lr = 3.9063e-05
I0415 08:39:29.390065 12023 solver.cpp:459] Snapshotting to binary proto file snapshots/caffenet128_no_lrn_lsuv_relu_bs1_iter_7680000.caffemodel
I0415 08:39:29.971992 12023 sgd_solver.cpp:269] Snapshotting solver state to binary proto file snapshots/caffenet128_no_lrn_lsuv_relu_bs1_iter_7680000.solverstate
I0415 08:39:30.038574 12023 solver.cpp:341] Iteration 7680000, Testing net (#0)
I0415 08:39:32.038542 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0415 08:39:56.373216 12023 solver.cpp:409]     Test net output #0: accuracy = 0.27858
I0415 08:39:56.373251 12023 solver.cpp:409]     Test net output #1: loss = 3.48203 (* 1 = 3.48203 loss)
I0415 08:39:56.377055 12023 solver.cpp:237] Iteration 7680000, loss = 3.68481
I0415 08:39:56.377079 12023 solver.cpp:253]     Train net output #0: loss = 0.404217 (* 1 = 0.404217 loss)
I0415 08:39:56.377089 12023 sgd_solver.cpp:106] Iteration 7680000, lr = 3.9063e-05
I0415 08:46:25.360011 12023 solver.cpp:237] Iteration 7731200, loss = 3.68549
I0415 08:46:25.360085 12023 solver.cpp:253]     Train net output #0: loss = 0.850525 (* 1 = 0.850525 loss)
I0415 08:46:25.360092 12023 sgd_solver.cpp:106] Iteration 7731200, lr = 3.9063e-05
I0415 08:52:54.140262 12023 solver.cpp:237] Iteration 7782400, loss = 3.67074
I0415 08:52:54.140331 12023 solver.cpp:253]     Train net output #0: loss = 1.87953 (* 1 = 1.87953 loss)
I0415 08:52:54.140336 12023 sgd_solver.cpp:106] Iteration 7782400, lr = 3.9063e-05
I0415 08:59:23.212013 12023 solver.cpp:237] Iteration 7833600, loss = 3.68119
I0415 08:59:23.212082 12023 solver.cpp:253]     Train net output #0: loss = 5.21912 (* 1 = 5.21912 loss)
I0415 08:59:23.212088 12023 sgd_solver.cpp:106] Iteration 7833600, lr = 3.9063e-05
I0415 09:05:52.505532 12023 solver.cpp:237] Iteration 7884800, loss = 3.64497
I0415 09:05:52.505604 12023 solver.cpp:253]     Train net output #0: loss = 7.52287 (* 1 = 7.52287 loss)
I0415 09:05:52.505609 12023 sgd_solver.cpp:106] Iteration 7884800, lr = 3.9063e-05
I0415 09:12:21.664770 12023 solver.cpp:341] Iteration 7936000, Testing net (#0)
I0415 09:12:23.706723 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0415 09:12:47.996038 12023 solver.cpp:409]     Test net output #0: accuracy = 0.28572
I0415 09:12:47.996073 12023 solver.cpp:409]     Test net output #1: loss = 3.4433 (* 1 = 3.4433 loss)
I0415 09:12:47.999860 12023 solver.cpp:237] Iteration 7936000, loss = 3.66546
I0415 09:12:47.999881 12023 solver.cpp:253]     Train net output #0: loss = 6.72927 (* 1 = 6.72927 loss)
I0415 09:12:47.999889 12023 sgd_solver.cpp:106] Iteration 7936000, lr = 3.9063e-05
I0415 09:19:17.179225 12023 solver.cpp:237] Iteration 7987200, loss = 3.64707
I0415 09:19:17.179296 12023 solver.cpp:253]     Train net output #0: loss = 5.30699 (* 1 = 5.30699 loss)
I0415 09:19:17.179302 12023 sgd_solver.cpp:106] Iteration 7987200, lr = 3.9063e-05
I0415 09:25:46.005580 12023 solver.cpp:237] Iteration 8038400, loss = 3.66136
I0415 09:25:46.005648 12023 solver.cpp:253]     Train net output #0: loss = 1.76456 (* 1 = 1.76456 loss)
I0415 09:25:46.005655 12023 sgd_solver.cpp:106] Iteration 8038400, lr = 3.9063e-05
I0415 09:32:14.969246 12023 solver.cpp:237] Iteration 8089600, loss = 3.64878
I0415 09:32:14.969324 12023 solver.cpp:253]     Train net output #0: loss = 1.89458 (* 1 = 1.89458 loss)
I0415 09:32:14.969331 12023 sgd_solver.cpp:106] Iteration 8089600, lr = 3.9063e-05
I0415 09:38:44.298405 12023 solver.cpp:237] Iteration 8140800, loss = 3.63295
I0415 09:38:44.298477 12023 solver.cpp:253]     Train net output #0: loss = 0.413378 (* 1 = 0.413378 loss)
I0415 09:38:44.298482 12023 sgd_solver.cpp:106] Iteration 8140800, lr = 3.9063e-05
I0415 09:45:13.148795 12023 solver.cpp:341] Iteration 8192000, Testing net (#0)
I0415 09:45:15.498749 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0415 09:45:42.690599 12023 solver.cpp:409]     Test net output #0: accuracy = 0.28168
I0415 09:45:42.690639 12023 solver.cpp:409]     Test net output #1: loss = 3.46184 (* 1 = 3.46184 loss)
I0415 09:45:42.694625 12023 solver.cpp:237] Iteration 8192000, loss = 3.62464
I0415 09:45:42.694648 12023 solver.cpp:253]     Train net output #0: loss = 5.38522 (* 1 = 5.38522 loss)
I0415 09:45:42.694658 12023 sgd_solver.cpp:106] Iteration 8192000, lr = 3.9063e-05
I0415 09:52:11.530464 12023 solver.cpp:237] Iteration 8243200, loss = 3.6338
I0415 09:52:11.530536 12023 solver.cpp:253]     Train net output #0: loss = 6.99125 (* 1 = 6.99125 loss)
I0415 09:52:11.530542 12023 sgd_solver.cpp:106] Iteration 8243200, lr = 3.9063e-05
I0415 09:58:40.474756 12023 solver.cpp:237] Iteration 8294400, loss = 3.63224
I0415 09:58:40.474819 12023 solver.cpp:253]     Train net output #0: loss = 7.7952 (* 1 = 7.7952 loss)
I0415 09:58:40.474833 12023 sgd_solver.cpp:106] Iteration 8294400, lr = 3.9063e-05
I0415 10:05:09.713510 12023 solver.cpp:237] Iteration 8345600, loss = 3.62079
I0415 10:05:09.713573 12023 solver.cpp:253]     Train net output #0: loss = 6.33688 (* 1 = 6.33688 loss)
I0415 10:05:09.713582 12023 sgd_solver.cpp:106] Iteration 8345600, lr = 3.9063e-05
I0415 10:11:38.918433 12023 solver.cpp:237] Iteration 8396800, loss = 3.63434
I0415 10:11:38.918496 12023 solver.cpp:253]     Train net output #0: loss = 4.16656 (* 1 = 4.16656 loss)
I0415 10:11:38.918508 12023 sgd_solver.cpp:106] Iteration 8396800, lr = 3.9063e-05
I0415 10:18:08.175101 12023 solver.cpp:341] Iteration 8448000, Testing net (#0)
I0415 10:18:10.348203 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0415 10:18:34.501319 12023 solver.cpp:409]     Test net output #0: accuracy = 0.28832
I0415 10:18:34.501353 12023 solver.cpp:409]     Test net output #1: loss = 3.4204 (* 1 = 3.4204 loss)
I0415 10:18:34.505112 12023 solver.cpp:237] Iteration 8448000, loss = 3.63173
I0415 10:18:34.505132 12023 solver.cpp:253]     Train net output #0: loss = 6.43898 (* 1 = 6.43898 loss)
I0415 10:18:34.505141 12023 sgd_solver.cpp:106] Iteration 8448000, lr = 3.9063e-05
I0415 10:25:03.874145 12023 solver.cpp:237] Iteration 8499200, loss = 3.61488
I0415 10:25:03.874205 12023 solver.cpp:253]     Train net output #0: loss = 3.87048 (* 1 = 3.87048 loss)
I0415 10:25:03.874217 12023 sgd_solver.cpp:106] Iteration 8499200, lr = 3.9063e-05
I0415 10:31:33.123709 12023 solver.cpp:237] Iteration 8550400, loss = 3.62576
I0415 10:31:33.123771 12023 solver.cpp:253]     Train net output #0: loss = 2.84603 (* 1 = 2.84603 loss)
I0415 10:31:33.123783 12023 sgd_solver.cpp:106] Iteration 8550400, lr = 3.9063e-05
I0415 10:38:02.379267 12023 solver.cpp:237] Iteration 8601600, loss = 3.60301
I0415 10:38:02.379339 12023 solver.cpp:253]     Train net output #0: loss = 1.98703 (* 1 = 1.98703 loss)
I0415 10:38:02.379348 12023 sgd_solver.cpp:106] Iteration 8601600, lr = 3.9063e-05
I0415 10:44:31.685590 12023 solver.cpp:237] Iteration 8652800, loss = 3.59529
I0415 10:44:31.685652 12023 solver.cpp:253]     Train net output #0: loss = 3.01159 (* 1 = 3.01159 loss)
I0415 10:44:31.685664 12023 sgd_solver.cpp:106] Iteration 8652800, lr = 3.9063e-05
I0415 10:51:00.868168 12023 solver.cpp:341] Iteration 8704000, Testing net (#0)
I0415 10:51:03.119319 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0415 10:51:27.192034 12023 solver.cpp:409]     Test net output #0: accuracy = 0.28624
I0415 10:51:27.192070 12023 solver.cpp:409]     Test net output #1: loss = 3.44354 (* 1 = 3.44354 loss)
I0415 10:51:27.195865 12023 solver.cpp:237] Iteration 8704000, loss = 3.58865
I0415 10:51:27.195888 12023 solver.cpp:253]     Train net output #0: loss = 3.82483 (* 1 = 3.82483 loss)
I0415 10:51:27.195897 12023 sgd_solver.cpp:106] Iteration 8704000, lr = 3.9063e-05
I0415 10:57:56.484869 12023 solver.cpp:237] Iteration 8755200, loss = 3.58883
I0415 10:57:56.484948 12023 solver.cpp:253]     Train net output #0: loss = 4.99244 (* 1 = 4.99244 loss)
I0415 10:57:56.484959 12023 sgd_solver.cpp:106] Iteration 8755200, lr = 3.9063e-05
I0415 11:04:25.730414 12023 solver.cpp:237] Iteration 8806400, loss = 3.59387
I0415 11:04:25.730489 12023 solver.cpp:253]     Train net output #0: loss = 10.8945 (* 1 = 10.8945 loss)
I0415 11:04:25.730501 12023 sgd_solver.cpp:106] Iteration 8806400, lr = 3.9063e-05
I0415 11:10:55.086503 12023 solver.cpp:237] Iteration 8857600, loss = 3.59538
I0415 11:10:55.086565 12023 solver.cpp:253]     Train net output #0: loss = 0.998916 (* 1 = 0.998916 loss)
I0415 11:10:55.086576 12023 sgd_solver.cpp:106] Iteration 8857600, lr = 3.9063e-05
I0415 11:17:24.320487 12023 solver.cpp:237] Iteration 8908800, loss = 3.57076
I0415 11:17:24.320546 12023 solver.cpp:253]     Train net output #0: loss = 1.21218 (* 1 = 1.21218 loss)
I0415 11:17:24.320552 12023 sgd_solver.cpp:106] Iteration 8908800, lr = 3.9063e-05
I0415 11:23:53.455090 12023 solver.cpp:341] Iteration 8960000, Testing net (#0)
I0415 11:23:55.785467 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0415 11:24:19.774590 12023 solver.cpp:409]     Test net output #0: accuracy = 0.28182
I0415 11:24:19.774624 12023 solver.cpp:409]     Test net output #1: loss = 3.47455 (* 1 = 3.47455 loss)
I0415 11:24:19.778388 12023 solver.cpp:237] Iteration 8960000, loss = 3.58963
I0415 11:24:19.778409 12023 solver.cpp:253]     Train net output #0: loss = 4.43095 (* 1 = 4.43095 loss)
I0415 11:24:19.778419 12023 sgd_solver.cpp:106] Iteration 8960000, lr = 3.9063e-05
I0415 11:30:49.290805 12023 solver.cpp:237] Iteration 9011200, loss = 3.58799
I0415 11:30:49.290868 12023 solver.cpp:253]     Train net output #0: loss = 2.66489 (* 1 = 2.66489 loss)
I0415 11:30:49.290879 12023 sgd_solver.cpp:106] Iteration 9011200, lr = 3.9063e-05
I0415 11:37:18.629004 12023 solver.cpp:237] Iteration 9062400, loss = 3.58527
I0415 11:37:18.629065 12023 solver.cpp:253]     Train net output #0: loss = 5.11185 (* 1 = 5.11185 loss)
I0415 11:37:18.629076 12023 sgd_solver.cpp:106] Iteration 9062400, lr = 3.9063e-05
I0415 11:43:47.537850 12023 solver.cpp:237] Iteration 9113600, loss = 3.58231
I0415 11:43:47.537921 12023 solver.cpp:253]     Train net output #0: loss = 1.69296 (* 1 = 1.69296 loss)
I0415 11:43:47.537928 12023 sgd_solver.cpp:106] Iteration 9113600, lr = 3.9063e-05
I0415 11:50:16.400463 12023 solver.cpp:237] Iteration 9164800, loss = 3.55729
I0415 11:50:16.400532 12023 solver.cpp:253]     Train net output #0: loss = 4.96271 (* 1 = 4.96271 loss)
I0415 11:50:16.400537 12023 sgd_solver.cpp:106] Iteration 9164800, lr = 3.9063e-05
I0415 11:56:45.222203 12023 solver.cpp:341] Iteration 9216000, Testing net (#0)
I0415 11:56:47.869321 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0415 11:57:14.771116 12023 solver.cpp:409]     Test net output #0: accuracy = 0.29048
I0415 11:57:14.771154 12023 solver.cpp:409]     Test net output #1: loss = 3.40904 (* 1 = 3.40904 loss)
I0415 11:57:14.775104 12023 solver.cpp:237] Iteration 9216000, loss = 3.5776
I0415 11:57:14.775127 12023 solver.cpp:253]     Train net output #0: loss = 5.52746 (* 1 = 5.52746 loss)
I0415 11:57:14.775136 12023 sgd_solver.cpp:106] Iteration 9216000, lr = 3.9063e-05
I0415 12:03:43.818347 12023 solver.cpp:237] Iteration 9267200, loss = 3.56516
I0415 12:03:43.818403 12023 solver.cpp:253]     Train net output #0: loss = 6.01603 (* 1 = 6.01603 loss)
I0415 12:03:43.818408 12023 sgd_solver.cpp:106] Iteration 9267200, lr = 3.9063e-05
I0415 12:10:12.953109 12023 solver.cpp:237] Iteration 9318400, loss = 3.57916
I0415 12:10:12.953181 12023 solver.cpp:253]     Train net output #0: loss = 6.33765 (* 1 = 6.33765 loss)
I0415 12:10:12.953187 12023 sgd_solver.cpp:106] Iteration 9318400, lr = 3.9063e-05
I0415 12:16:42.072633 12023 solver.cpp:237] Iteration 9369600, loss = 3.56206
I0415 12:16:42.072702 12023 solver.cpp:253]     Train net output #0: loss = 3.45946 (* 1 = 3.45946 loss)
I0415 12:16:42.072710 12023 sgd_solver.cpp:106] Iteration 9369600, lr = 3.9063e-05
I0415 12:23:10.906653 12023 solver.cpp:237] Iteration 9420800, loss = 3.53889
I0415 12:23:10.906743 12023 solver.cpp:253]     Train net output #0: loss = 2.75295 (* 1 = 2.75295 loss)
I0415 12:23:10.906747 12023 sgd_solver.cpp:106] Iteration 9420800, lr = 3.9063e-05
I0415 12:29:39.715783 12023 solver.cpp:341] Iteration 9472000, Testing net (#0)
I0415 12:29:42.423676 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0415 12:30:09.255925 12023 solver.cpp:409]     Test net output #0: accuracy = 0.29782
I0415 12:30:09.255962 12023 solver.cpp:409]     Test net output #1: loss = 3.37302 (* 1 = 3.37302 loss)
I0415 12:30:09.259876 12023 solver.cpp:237] Iteration 9472000, loss = 3.548
I0415 12:30:09.259897 12023 solver.cpp:253]     Train net output #0: loss = 0.111587 (* 1 = 0.111587 loss)
I0415 12:30:09.259907 12023 sgd_solver.cpp:106] Iteration 9472000, lr = 3.9063e-05
I0415 12:36:38.014742 12023 solver.cpp:237] Iteration 9523200, loss = 3.54767
I0415 12:36:38.014811 12023 solver.cpp:253]     Train net output #0: loss = 6.20082 (* 1 = 6.20082 loss)
I0415 12:36:38.014817 12023 sgd_solver.cpp:106] Iteration 9523200, lr = 3.9063e-05
I0415 12:43:06.833935 12023 solver.cpp:237] Iteration 9574400, loss = 3.55548
I0415 12:43:06.833993 12023 solver.cpp:253]     Train net output #0: loss = 3.53357 (* 1 = 3.53357 loss)
I0415 12:43:06.833999 12023 sgd_solver.cpp:106] Iteration 9574400, lr = 3.9063e-05
I0415 12:49:36.033356 12023 solver.cpp:237] Iteration 9625600, loss = 3.54497
I0415 12:49:36.033421 12023 solver.cpp:253]     Train net output #0: loss = 2.20241 (* 1 = 2.20241 loss)
I0415 12:49:36.033430 12023 sgd_solver.cpp:106] Iteration 9625600, lr = 3.9063e-05
I0415 12:56:05.238083 12023 solver.cpp:237] Iteration 9676800, loss = 3.54598
I0415 12:56:05.238157 12023 solver.cpp:253]     Train net output #0: loss = 6.2201 (* 1 = 6.2201 loss)
I0415 12:56:05.238168 12023 sgd_solver.cpp:106] Iteration 9676800, lr = 3.9063e-05
I0415 13:02:34.505743 12023 solver.cpp:341] Iteration 9728000, Testing net (#0)
I0415 13:02:36.996923 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0415 13:03:00.833339 12023 solver.cpp:409]     Test net output #0: accuracy = 0.29906
I0415 13:03:00.833375 12023 solver.cpp:409]     Test net output #1: loss = 3.36178 (* 1 = 3.36178 loss)
I0415 13:03:00.837174 12023 solver.cpp:237] Iteration 9728000, loss = 3.55871
I0415 13:03:00.837193 12023 solver.cpp:253]     Train net output #0: loss = 2.57799 (* 1 = 2.57799 loss)
I0415 13:03:00.837203 12023 sgd_solver.cpp:106] Iteration 9728000, lr = 3.9063e-05
I0415 13:09:30.253322 12023 solver.cpp:237] Iteration 9779200, loss = 3.54723
I0415 13:09:30.253382 12023 solver.cpp:253]     Train net output #0: loss = 0.462141 (* 1 = 0.462141 loss)
I0415 13:09:30.253388 12023 sgd_solver.cpp:106] Iteration 9779200, lr = 3.9063e-05
I0415 13:15:59.443859 12023 solver.cpp:237] Iteration 9830400, loss = 3.55118
I0415 13:15:59.443922 12023 solver.cpp:253]     Train net output #0: loss = 3.94052 (* 1 = 3.94052 loss)
I0415 13:15:59.443928 12023 sgd_solver.cpp:106] Iteration 9830400, lr = 3.9063e-05
I0415 13:22:28.585477 12023 solver.cpp:237] Iteration 9881600, loss = 3.52577
I0415 13:22:28.585538 12023 solver.cpp:253]     Train net output #0: loss = 1.21181 (* 1 = 1.21181 loss)
I0415 13:22:28.585546 12023 sgd_solver.cpp:106] Iteration 9881600, lr = 3.9063e-05
I0415 13:28:57.821092 12023 solver.cpp:237] Iteration 9932800, loss = 3.51591
I0415 13:28:57.821151 12023 solver.cpp:253]     Train net output #0: loss = 2.10159 (* 1 = 2.10159 loss)
I0415 13:28:57.821157 12023 sgd_solver.cpp:106] Iteration 9932800, lr = 3.9063e-05
I0415 13:35:27.084653 12023 solver.cpp:341] Iteration 9984000, Testing net (#0)
I0415 13:35:29.685820 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0415 13:35:53.446843 12023 solver.cpp:409]     Test net output #0: accuracy = 0.30224
I0415 13:35:53.446878 12023 solver.cpp:409]     Test net output #1: loss = 3.35178 (* 1 = 3.35178 loss)
I0415 13:35:53.450646 12023 solver.cpp:237] Iteration 9984000, loss = 3.52034
I0415 13:35:53.450666 12023 solver.cpp:253]     Train net output #0: loss = 0.089636 (* 1 = 0.089636 loss)
I0415 13:35:53.450675 12023 sgd_solver.cpp:106] Iteration 9984000, lr = 3.9063e-05
I0415 13:42:22.696591 12023 solver.cpp:237] Iteration 10035200, loss = 3.51973
I0415 13:42:22.696681 12023 solver.cpp:253]     Train net output #0: loss = 6.52249 (* 1 = 6.52249 loss)
I0415 13:42:22.696689 12023 sgd_solver.cpp:106] Iteration 10035200, lr = 3.9063e-05
I0415 13:48:51.965240 12023 solver.cpp:237] Iteration 10086400, loss = 3.51794
I0415 13:48:51.965307 12023 solver.cpp:253]     Train net output #0: loss = 4.2785 (* 1 = 4.2785 loss)
I0415 13:48:51.965319 12023 sgd_solver.cpp:106] Iteration 10086400, lr = 3.9063e-05
I0415 13:55:21.193748 12023 solver.cpp:237] Iteration 10137600, loss = 3.52253
I0415 13:55:21.193811 12023 solver.cpp:253]     Train net output #0: loss = 4.09523 (* 1 = 4.09523 loss)
I0415 13:55:21.193819 12023 sgd_solver.cpp:106] Iteration 10137600, lr = 3.9063e-05
I0415 14:01:50.425118 12023 solver.cpp:237] Iteration 10188800, loss = 3.49913
I0415 14:01:50.425189 12023 solver.cpp:253]     Train net output #0: loss = 5.92403 (* 1 = 5.92403 loss)
I0415 14:01:50.425194 12023 sgd_solver.cpp:106] Iteration 10188800, lr = 3.9063e-05
I0415 14:08:19.534873 12023 solver.cpp:459] Snapshotting to binary proto file snapshots/caffenet128_no_lrn_lsuv_relu_bs1_iter_10240000.caffemodel
I0415 14:08:20.847718 12023 sgd_solver.cpp:269] Snapshotting solver state to binary proto file snapshots/caffenet128_no_lrn_lsuv_relu_bs1_iter_10240000.solverstate
I0415 14:08:20.907238 12023 solver.cpp:341] Iteration 10240000, Testing net (#0)
I0415 14:08:23.555351 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0415 14:08:47.234441 12023 solver.cpp:409]     Test net output #0: accuracy = 0.304
I0415 14:08:47.234475 12023 solver.cpp:409]     Test net output #1: loss = 3.33243 (* 1 = 3.33243 loss)
I0415 14:08:47.238258 12023 solver.cpp:237] Iteration 10240000, loss = 3.51468
I0415 14:08:47.238281 12023 solver.cpp:253]     Train net output #0: loss = 2.86824 (* 1 = 2.86824 loss)
I0415 14:08:47.238289 12023 sgd_solver.cpp:106] Iteration 10240000, lr = 3.9063e-05
I0415 14:15:16.649255 12023 solver.cpp:237] Iteration 10291200, loss = 3.52637
I0415 14:15:16.649318 12023 solver.cpp:253]     Train net output #0: loss = 2.73986 (* 1 = 2.73986 loss)
I0415 14:15:16.649324 12023 sgd_solver.cpp:106] Iteration 10291200, lr = 3.9063e-05
I0415 14:21:45.788357 12023 solver.cpp:237] Iteration 10342400, loss = 3.52032
I0415 14:21:45.788421 12023 solver.cpp:253]     Train net output #0: loss = 3.30316 (* 1 = 3.30316 loss)
I0415 14:21:45.788429 12023 sgd_solver.cpp:106] Iteration 10342400, lr = 3.9063e-05
I0415 14:28:14.972823 12023 solver.cpp:237] Iteration 10393600, loss = 3.51571
I0415 14:28:14.972890 12023 solver.cpp:253]     Train net output #0: loss = 3.53826 (* 1 = 3.53826 loss)
I0415 14:28:14.972897 12023 sgd_solver.cpp:106] Iteration 10393600, lr = 3.9063e-05
I0415 14:34:44.188819 12023 solver.cpp:237] Iteration 10444800, loss = 3.49943
I0415 14:34:44.188877 12023 solver.cpp:253]     Train net output #0: loss = 3.80369 (* 1 = 3.80369 loss)
I0415 14:34:44.188884 12023 sgd_solver.cpp:106] Iteration 10444800, lr = 3.9063e-05
I0415 14:41:13.214020 12023 solver.cpp:341] Iteration 10496000, Testing net (#0)
I0415 14:41:15.918869 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0415 14:41:39.548032 12023 solver.cpp:409]     Test net output #0: accuracy = 0.30802
I0415 14:41:39.548066 12023 solver.cpp:409]     Test net output #1: loss = 3.31078 (* 1 = 3.31078 loss)
I0415 14:41:39.551810 12023 solver.cpp:237] Iteration 10496000, loss = 3.50741
I0415 14:41:39.551831 12023 solver.cpp:253]     Train net output #0: loss = 3.14708 (* 1 = 3.14708 loss)
I0415 14:41:39.551839 12023 sgd_solver.cpp:106] Iteration 10496000, lr = 3.9063e-05
I0415 14:48:08.502128 12023 solver.cpp:237] Iteration 10547200, loss = 3.49612
I0415 14:48:08.502202 12023 solver.cpp:253]     Train net output #0: loss = 3.97884 (* 1 = 3.97884 loss)
I0415 14:48:08.502210 12023 sgd_solver.cpp:106] Iteration 10547200, lr = 3.9063e-05
I0415 14:54:37.339164 12023 solver.cpp:237] Iteration 10598400, loss = 3.50658
I0415 14:54:37.339257 12023 solver.cpp:253]     Train net output #0: loss = 5.70805 (* 1 = 5.70805 loss)
I0415 14:54:37.339264 12023 sgd_solver.cpp:106] Iteration 10598400, lr = 3.9063e-05
I0415 15:01:06.547986 12023 solver.cpp:237] Iteration 10649600, loss = 3.50158
I0415 15:01:06.548048 12023 solver.cpp:253]     Train net output #0: loss = 6.84647 (* 1 = 6.84647 loss)
I0415 15:01:06.548058 12023 sgd_solver.cpp:106] Iteration 10649600, lr = 3.9063e-05
I0415 15:07:35.812957 12023 solver.cpp:237] Iteration 10700800, loss = 3.48016
I0415 15:07:35.813030 12023 solver.cpp:253]     Train net output #0: loss = 6.28461 (* 1 = 6.28461 loss)
I0415 15:07:35.813040 12023 sgd_solver.cpp:106] Iteration 10700800, lr = 3.9063e-05
I0415 15:14:04.890913 12023 solver.cpp:341] Iteration 10752000, Testing net (#0)
I0415 15:14:07.671990 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0415 15:14:31.215131 12023 solver.cpp:409]     Test net output #0: accuracy = 0.30078
I0415 15:14:31.215167 12023 solver.cpp:409]     Test net output #1: loss = 3.32975 (* 1 = 3.32975 loss)
I0415 15:14:31.218930 12023 solver.cpp:237] Iteration 10752000, loss = 3.46955
I0415 15:14:31.218951 12023 solver.cpp:253]     Train net output #0: loss = 5.01491 (* 1 = 5.01491 loss)
I0415 15:14:31.218961 12023 sgd_solver.cpp:106] Iteration 10752000, lr = 3.9063e-05
I0415 15:21:00.467295 12023 solver.cpp:237] Iteration 10803200, loss = 3.48318
I0415 15:21:00.467366 12023 solver.cpp:253]     Train net output #0: loss = 0.611287 (* 1 = 0.611287 loss)
I0415 15:21:00.467371 12023 sgd_solver.cpp:106] Iteration 10803200, lr = 3.9063e-05
I0415 15:27:29.900002 12023 solver.cpp:237] Iteration 10854400, loss = 3.49025
I0415 15:27:29.900063 12023 solver.cpp:253]     Train net output #0: loss = 3.90124 (* 1 = 3.90124 loss)
I0415 15:27:29.900068 12023 sgd_solver.cpp:106] Iteration 10854400, lr = 3.9063e-05
I0415 15:33:59.199838 12023 solver.cpp:237] Iteration 10905600, loss = 3.47312
I0415 15:33:59.199909 12023 solver.cpp:253]     Train net output #0: loss = 1.59931 (* 1 = 1.59931 loss)
I0415 15:33:59.199918 12023 sgd_solver.cpp:106] Iteration 10905600, lr = 3.9063e-05
I0415 15:40:29.771595 12023 solver.cpp:237] Iteration 10956800, loss = 3.48592
I0415 15:40:29.771664 12023 solver.cpp:253]     Train net output #0: loss = 4.39444 (* 1 = 4.39444 loss)
I0415 15:40:29.771674 12023 sgd_solver.cpp:106] Iteration 10956800, lr = 3.9063e-05
I0415 15:47:03.803990 12023 solver.cpp:341] Iteration 11008000, Testing net (#0)
I0415 15:47:06.986248 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0415 15:47:31.059051 12023 solver.cpp:409]     Test net output #0: accuracy = 0.30604
I0415 15:47:31.059085 12023 solver.cpp:409]     Test net output #1: loss = 3.30834 (* 1 = 3.30834 loss)
I0415 15:47:31.062880 12023 solver.cpp:237] Iteration 11008000, loss = 3.49794
I0415 15:47:31.062899 12023 solver.cpp:253]     Train net output #0: loss = 0.853312 (* 1 = 0.853312 loss)
I0415 15:47:31.062907 12023 sgd_solver.cpp:106] Iteration 11008000, lr = 3.9063e-05
I0415 15:54:00.373085 12023 solver.cpp:237] Iteration 11059200, loss = 3.47977
I0415 15:54:00.373158 12023 solver.cpp:253]     Train net output #0: loss = 4.24322 (* 1 = 4.24322 loss)
I0415 15:54:00.373169 12023 sgd_solver.cpp:106] Iteration 11059200, lr = 3.9063e-05
I0415 16:00:29.668138 12023 solver.cpp:237] Iteration 11110400, loss = 3.49169
I0415 16:00:29.668208 12023 solver.cpp:253]     Train net output #0: loss = 6.55255 (* 1 = 6.55255 loss)
I0415 16:00:29.668215 12023 sgd_solver.cpp:106] Iteration 11110400, lr = 3.9063e-05
I0415 16:07:01.395354 12023 solver.cpp:237] Iteration 11161600, loss = 3.46668
I0415 16:07:01.395417 12023 solver.cpp:253]     Train net output #0: loss = 0.275138 (* 1 = 0.275138 loss)
I0415 16:07:01.395429 12023 sgd_solver.cpp:106] Iteration 11161600, lr = 3.9063e-05
I0415 16:13:30.497172 12023 solver.cpp:237] Iteration 11212800, loss = 3.45998
I0415 16:13:30.497264 12023 solver.cpp:253]     Train net output #0: loss = 4.06213 (* 1 = 4.06213 loss)
I0415 16:13:30.497280 12023 sgd_solver.cpp:106] Iteration 11212800, lr = 3.9063e-05
I0415 16:19:59.319449 12023 solver.cpp:341] Iteration 11264000, Testing net (#0)
I0415 16:20:02.242682 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0415 16:20:25.645648 12023 solver.cpp:409]     Test net output #0: accuracy = 0.31318
I0415 16:20:25.645684 12023 solver.cpp:409]     Test net output #1: loss = 3.26618 (* 1 = 3.26618 loss)
I0415 16:20:25.649482 12023 solver.cpp:237] Iteration 11264000, loss = 3.45133
I0415 16:20:25.649503 12023 solver.cpp:253]     Train net output #0: loss = 3.4477 (* 1 = 3.4477 loss)
I0415 16:20:25.649514 12023 sgd_solver.cpp:106] Iteration 11264000, lr = 3.9063e-05
I0415 16:26:54.840509 12023 solver.cpp:237] Iteration 11315200, loss = 3.43999
I0415 16:26:54.840570 12023 solver.cpp:253]     Train net output #0: loss = 4.93664 (* 1 = 4.93664 loss)
I0415 16:26:54.840576 12023 sgd_solver.cpp:106] Iteration 11315200, lr = 3.9063e-05
I0415 16:33:23.865247 12023 solver.cpp:237] Iteration 11366400, loss = 3.46456
I0415 16:33:23.865322 12023 solver.cpp:253]     Train net output #0: loss = 11.3236 (* 1 = 11.3236 loss)
I0415 16:33:23.865329 12023 sgd_solver.cpp:106] Iteration 11366400, lr = 3.9063e-05
I0415 16:39:56.897627 12023 solver.cpp:237] Iteration 11417600, loss = 3.46793
I0415 16:39:56.897707 12023 solver.cpp:253]     Train net output #0: loss = 1.61721 (* 1 = 1.61721 loss)
I0415 16:39:56.897719 12023 sgd_solver.cpp:106] Iteration 11417600, lr = 3.9063e-05
I0415 17:02:43.626109 12023 solver.cpp:237] Iteration 11468800, loss = 3.43761
I0415 17:02:43.626209 12023 solver.cpp:253]     Train net output #0: loss = 4.60863 (* 1 = 4.60863 loss)
I0415 17:02:43.626230 12023 sgd_solver.cpp:106] Iteration 11468800, lr = 3.9063e-05
I0415 17:27:33.807718 12023 solver.cpp:341] Iteration 11520000, Testing net (#0)
I0415 17:27:39.390171 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0415 17:28:12.697433 12023 solver.cpp:409]     Test net output #0: accuracy = 0.3081
I0415 17:28:12.697491 12023 solver.cpp:409]     Test net output #1: loss = 3.29855 (* 1 = 3.29855 loss)
I0415 17:28:12.715140 12023 solver.cpp:237] Iteration 11520000, loss = 3.45907
I0415 17:28:12.715195 12023 solver.cpp:253]     Train net output #0: loss = 5.2864 (* 1 = 5.2864 loss)
I0415 17:28:12.715215 12023 sgd_solver.cpp:106] Iteration 11520000, lr = 3.9063e-05
I0415 17:53:13.025542 12023 solver.cpp:237] Iteration 11571200, loss = 3.47659
I0415 17:53:13.025590 12023 solver.cpp:253]     Train net output #0: loss = 5.49676 (* 1 = 5.49676 loss)
I0415 17:53:13.025595 12023 sgd_solver.cpp:106] Iteration 11571200, lr = 3.9063e-05
I0415 18:18:10.982534 12023 solver.cpp:237] Iteration 11622400, loss = 3.45734
I0415 18:18:10.982601 12023 solver.cpp:253]     Train net output #0: loss = 0.0199681 (* 1 = 0.0199681 loss)
I0415 18:18:10.982615 12023 sgd_solver.cpp:106] Iteration 11622400, lr = 3.9063e-05
I0415 18:41:30.565500 12023 solver.cpp:237] Iteration 11673600, loss = 3.46362
I0415 18:41:30.565600 12023 solver.cpp:253]     Train net output #0: loss = 0.822938 (* 1 = 0.822938 loss)
I0415 18:41:30.565618 12023 sgd_solver.cpp:106] Iteration 11673600, lr = 3.9063e-05
I0415 19:06:24.679744 12023 solver.cpp:237] Iteration 11724800, loss = 3.44059
I0415 19:06:24.679813 12023 solver.cpp:253]     Train net output #0: loss = 6.63697 (* 1 = 6.63697 loss)
I0415 19:06:24.679821 12023 sgd_solver.cpp:106] Iteration 11724800, lr = 3.9063e-05
I0415 19:31:24.156252 12023 solver.cpp:341] Iteration 11776000, Testing net (#0)
I0415 19:31:36.605187 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0415 19:32:02.057711 12023 solver.cpp:409]     Test net output #0: accuracy = 0.30616
I0415 19:32:02.057817 12023 solver.cpp:409]     Test net output #1: loss = 3.32009 (* 1 = 3.32009 loss)
I0415 19:32:02.085400 12023 solver.cpp:237] Iteration 11776000, loss = 3.46328
I0415 19:32:02.085466 12023 solver.cpp:253]     Train net output #0: loss = 0.519735 (* 1 = 0.519735 loss)
I0415 19:32:02.085484 12023 sgd_solver.cpp:106] Iteration 11776000, lr = 3.9063e-05
I0415 19:57:00.412084 12023 solver.cpp:237] Iteration 11827200, loss = 3.44485
I0415 19:57:00.594163 12023 solver.cpp:253]     Train net output #0: loss = 6.7722 (* 1 = 6.7722 loss)
I0415 19:57:00.594180 12023 sgd_solver.cpp:106] Iteration 11827200, lr = 3.9063e-05
I0415 20:20:40.049402 12023 solver.cpp:237] Iteration 11878400, loss = 3.46165
I0415 20:20:40.215752 12023 solver.cpp:253]     Train net output #0: loss = 3.91893 (* 1 = 3.91893 loss)
I0415 20:20:40.215770 12023 sgd_solver.cpp:106] Iteration 11878400, lr = 3.9063e-05
I0415 20:45:37.646185 12023 solver.cpp:237] Iteration 11929600, loss = 3.46055
I0415 20:45:37.647527 12023 solver.cpp:253]     Train net output #0: loss = 9.29789 (* 1 = 9.29789 loss)
I0415 20:45:37.647537 12023 sgd_solver.cpp:106] Iteration 11929600, lr = 3.9063e-05
I0415 21:10:54.735783 12023 solver.cpp:237] Iteration 11980800, loss = 3.43813
I0415 21:10:54.735852 12023 solver.cpp:253]     Train net output #0: loss = 2.80625 (* 1 = 2.80625 loss)
I0415 21:10:54.735865 12023 sgd_solver.cpp:106] Iteration 11980800, lr = 3.9063e-05
I0415 21:35:55.349056 12023 solver.cpp:341] Iteration 12032000, Testing net (#0)
I0415 21:36:10.633301 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0415 21:36:31.794719 12023 solver.cpp:409]     Test net output #0: accuracy = 0.30926
I0415 21:36:31.794816 12023 solver.cpp:409]     Test net output #1: loss = 3.28832 (* 1 = 3.28832 loss)
I0415 21:36:31.814321 12023 solver.cpp:237] Iteration 12032000, loss = 3.42716
I0415 21:36:31.814383 12023 solver.cpp:253]     Train net output #0: loss = 3.93144 (* 1 = 3.93144 loss)
I0415 21:36:31.814401 12023 sgd_solver.cpp:106] Iteration 12032000, lr = 3.9063e-05
I0415 22:01:34.227512 12023 solver.cpp:237] Iteration 12083200, loss = 3.42741
I0415 22:01:34.227581 12023 solver.cpp:253]     Train net output #0: loss = 1.77105 (* 1 = 1.77105 loss)
I0415 22:01:34.227593 12023 sgd_solver.cpp:106] Iteration 12083200, lr = 3.9063e-05
I0415 22:26:14.558419 12023 solver.cpp:237] Iteration 12134400, loss = 3.43923
I0415 22:26:14.558470 12023 solver.cpp:253]     Train net output #0: loss = 7.49751 (* 1 = 7.49751 loss)
I0415 22:26:14.558476 12023 sgd_solver.cpp:106] Iteration 12134400, lr = 3.9063e-05
I0415 22:51:20.375063 12023 solver.cpp:237] Iteration 12185600, loss = 3.42765
I0415 22:51:20.555790 12023 solver.cpp:253]     Train net output #0: loss = 0.656519 (* 1 = 0.656519 loss)
I0415 22:51:20.555806 12023 sgd_solver.cpp:106] Iteration 12185600, lr = 3.9063e-05
I0415 23:16:10.697481 12023 solver.cpp:237] Iteration 12236800, loss = 3.43419
I0415 23:16:10.697531 12023 solver.cpp:253]     Train net output #0: loss = 3.43658 (* 1 = 3.43658 loss)
I0415 23:16:10.697540 12023 sgd_solver.cpp:106] Iteration 12236800, lr = 3.9063e-05
I0415 23:41:11.411588 12023 solver.cpp:341] Iteration 12288000, Testing net (#0)
I0415 23:41:37.084630 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0415 23:41:49.152757 12023 solver.cpp:409]     Test net output #0: accuracy = 0.31788
I0415 23:41:49.153609 12023 solver.cpp:409]     Test net output #1: loss = 3.24617 (* 1 = 3.24617 loss)
I0415 23:41:49.172199 12023 solver.cpp:237] Iteration 12288000, loss = 3.45121
I0415 23:41:49.172261 12023 solver.cpp:253]     Train net output #0: loss = 1.9116 (* 1 = 1.9116 loss)
I0415 23:41:49.172278 12023 sgd_solver.cpp:106] Iteration 12288000, lr = 3.9063e-05
I0416 00:05:58.338603 12023 solver.cpp:237] Iteration 12339200, loss = 3.43509
I0416 00:05:58.338676 12023 solver.cpp:253]     Train net output #0: loss = 0.000283222 (* 1 = 0.000283222 loss)
I0416 00:05:58.338685 12023 sgd_solver.cpp:106] Iteration 12339200, lr = 3.9063e-05
I0416 00:30:57.418474 12023 solver.cpp:237] Iteration 12390400, loss = 3.42821
I0416 00:30:57.418532 12023 solver.cpp:253]     Train net output #0: loss = 2.55745 (* 1 = 2.55745 loss)
I0416 00:30:57.418541 12023 sgd_solver.cpp:106] Iteration 12390400, lr = 3.9063e-05
I0416 00:47:03.615137 12023 solver.cpp:237] Iteration 12441600, loss = 3.42606
I0416 00:47:03.615229 12023 solver.cpp:253]     Train net output #0: loss = 1.32713 (* 1 = 1.32713 loss)
I0416 00:47:03.615241 12023 sgd_solver.cpp:106] Iteration 12441600, lr = 3.9063e-05
I0416 00:53:32.595367 12023 solver.cpp:237] Iteration 12492800, loss = 3.41072
I0416 00:53:32.595422 12023 solver.cpp:253]     Train net output #0: loss = 1.71302 (* 1 = 1.71302 loss)
I0416 00:53:32.595428 12023 sgd_solver.cpp:106] Iteration 12492800, lr = 3.9063e-05
I0416 01:00:01.450650 12023 solver.cpp:341] Iteration 12544000, Testing net (#0)
I0416 01:00:25.891818 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0416 01:00:30.987751 12023 solver.cpp:409]     Test net output #0: accuracy = 0.31078
I0416 01:00:30.987789 12023 solver.cpp:409]     Test net output #1: loss = 3.26268 (* 1 = 3.26268 loss)
I0416 01:00:30.991745 12023 solver.cpp:237] Iteration 12544000, loss = 3.41347
I0416 01:00:30.991767 12023 solver.cpp:253]     Train net output #0: loss = 3.34453 (* 1 = 3.34453 loss)
I0416 01:00:30.991776 12023 sgd_solver.cpp:106] Iteration 12544000, lr = 3.9063e-05
I0416 01:06:59.870743 12023 solver.cpp:237] Iteration 12595200, loss = 3.41028
I0416 01:06:59.870791 12023 solver.cpp:253]     Train net output #0: loss = 7.59268 (* 1 = 7.59268 loss)
I0416 01:06:59.870797 12023 sgd_solver.cpp:106] Iteration 12595200, lr = 3.9063e-05
I0416 01:13:29.049846 12023 solver.cpp:237] Iteration 12646400, loss = 3.41579
I0416 01:13:29.049903 12023 solver.cpp:253]     Train net output #0: loss = 0.00807082 (* 1 = 0.00807082 loss)
I0416 01:13:29.049909 12023 sgd_solver.cpp:106] Iteration 12646400, lr = 3.9063e-05
I0416 01:19:58.298678 12023 solver.cpp:237] Iteration 12697600, loss = 3.42957
I0416 01:19:58.298740 12023 solver.cpp:253]     Train net output #0: loss = 2.25821 (* 1 = 2.25821 loss)
I0416 01:19:58.298749 12023 sgd_solver.cpp:106] Iteration 12697600, lr = 3.9063e-05
I0416 01:26:27.602130 12023 solver.cpp:237] Iteration 12748800, loss = 3.39346
I0416 01:26:27.602216 12023 solver.cpp:253]     Train net output #0: loss = 4.44987 (* 1 = 4.44987 loss)
I0416 01:26:27.602227 12023 sgd_solver.cpp:106] Iteration 12748800, lr = 3.9063e-05
I0416 01:32:56.889657 12023 solver.cpp:459] Snapshotting to binary proto file snapshots/caffenet128_no_lrn_lsuv_relu_bs1_iter_12800000.caffemodel
I0416 01:32:58.272790 12023 sgd_solver.cpp:269] Snapshotting solver state to binary proto file snapshots/caffenet128_no_lrn_lsuv_relu_bs1_iter_12800000.solverstate
I0416 01:32:58.333142 12023 solver.cpp:341] Iteration 12800000, Testing net (#0)
I0416 01:33:21.849138 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0416 01:33:26.338140 12023 solver.cpp:409]     Test net output #0: accuracy = 0.31738
I0416 01:33:26.338176 12023 solver.cpp:409]     Test net output #1: loss = 3.23866 (* 1 = 3.23866 loss)
I0416 01:33:26.341980 12023 solver.cpp:237] Iteration 12800000, loss = 3.41578
I0416 01:33:26.342002 12023 solver.cpp:253]     Train net output #0: loss = 1.29397 (* 1 = 1.29397 loss)
I0416 01:33:26.342011 12023 sgd_solver.cpp:106] Iteration 12800000, lr = 3.9063e-05
I0416 01:39:55.511775 12023 solver.cpp:237] Iteration 12851200, loss = 3.43932
I0416 01:39:55.511836 12023 solver.cpp:253]     Train net output #0: loss = 2.89763 (* 1 = 2.89763 loss)
I0416 01:39:55.511842 12023 sgd_solver.cpp:106] Iteration 12851200, lr = 3.9063e-05
I0416 01:46:24.624099 12023 solver.cpp:237] Iteration 12902400, loss = 3.42224
I0416 01:46:24.624166 12023 solver.cpp:253]     Train net output #0: loss = 4.60493 (* 1 = 4.60493 loss)
I0416 01:46:24.624171 12023 sgd_solver.cpp:106] Iteration 12902400, lr = 3.9063e-05
I0416 01:52:53.494385 12023 solver.cpp:237] Iteration 12953600, loss = 3.41353
I0416 01:52:53.494452 12023 solver.cpp:253]     Train net output #0: loss = 7.64572 (* 1 = 7.64572 loss)
I0416 01:52:53.494458 12023 sgd_solver.cpp:106] Iteration 12953600, lr = 3.9063e-05
I0416 01:59:22.355108 12023 solver.cpp:237] Iteration 13004800, loss = 3.39313
I0416 01:59:22.355177 12023 solver.cpp:253]     Train net output #0: loss = 2.71707 (* 1 = 2.71707 loss)
I0416 01:59:22.355182 12023 sgd_solver.cpp:106] Iteration 13004800, lr = 3.9063e-05
I0416 02:05:51.230960 12023 solver.cpp:341] Iteration 13056000, Testing net (#0)
I0416 02:06:13.200176 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0416 02:06:13.410910 12032 blocking_queue.cpp:50] Waiting for data
I0416 02:06:17.708250 12023 solver.cpp:409]     Test net output #0: accuracy = 0.31728
I0416 02:06:17.708282 12023 solver.cpp:409]     Test net output #1: loss = 3.24923 (* 1 = 3.24923 loss)
I0416 02:06:17.712086 12023 solver.cpp:237] Iteration 13056000, loss = 3.42244
I0416 02:06:17.712105 12023 solver.cpp:253]     Train net output #0: loss = 3.97733 (* 1 = 3.97733 loss)
I0416 02:06:17.712112 12023 sgd_solver.cpp:106] Iteration 13056000, lr = 3.9063e-05
I0416 02:12:46.885543 12023 solver.cpp:237] Iteration 13107200, loss = 3.39994
I0416 02:12:46.885613 12023 solver.cpp:253]     Train net output #0: loss = 0.348769 (* 1 = 0.348769 loss)
I0416 02:12:46.885619 12023 sgd_solver.cpp:106] Iteration 13107200, lr = 3.9063e-05
I0416 02:19:15.862659 12023 solver.cpp:237] Iteration 13158400, loss = 3.42089
I0416 02:19:15.862731 12023 solver.cpp:253]     Train net output #0: loss = 6.4227 (* 1 = 6.4227 loss)
I0416 02:19:15.862738 12023 sgd_solver.cpp:106] Iteration 13158400, lr = 3.9063e-05
I0416 02:25:44.721212 12023 solver.cpp:237] Iteration 13209600, loss = 3.40576
I0416 02:25:44.721284 12023 solver.cpp:253]     Train net output #0: loss = 4.44951 (* 1 = 4.44951 loss)
I0416 02:25:44.721290 12023 sgd_solver.cpp:106] Iteration 13209600, lr = 3.9063e-05
I0416 02:32:13.704802 12023 solver.cpp:237] Iteration 13260800, loss = 3.3971
I0416 02:32:13.704864 12023 solver.cpp:253]     Train net output #0: loss = 4.2878 (* 1 = 4.2878 loss)
I0416 02:32:13.704870 12023 sgd_solver.cpp:106] Iteration 13260800, lr = 3.9063e-05
I0416 02:38:42.798835 12023 solver.cpp:341] Iteration 13312000, Testing net (#0)
I0416 02:39:04.920951 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0416 02:39:09.253839 12023 solver.cpp:409]     Test net output #0: accuracy = 0.3268
I0416 02:39:09.253875 12023 solver.cpp:409]     Test net output #1: loss = 3.20704 (* 1 = 3.20704 loss)
I0416 02:39:09.257622 12023 solver.cpp:237] Iteration 13312000, loss = 3.38495
I0416 02:39:09.257642 12023 solver.cpp:253]     Train net output #0: loss = 0.136835 (* 1 = 0.136835 loss)
I0416 02:39:09.257652 12023 sgd_solver.cpp:106] Iteration 13312000, lr = 3.9063e-05
I0416 02:45:38.229794 12023 solver.cpp:237] Iteration 13363200, loss = 3.38777
I0416 02:45:38.229854 12023 solver.cpp:253]     Train net output #0: loss = 7.71857 (* 1 = 7.71857 loss)
I0416 02:45:38.229862 12023 sgd_solver.cpp:106] Iteration 13363200, lr = 3.9063e-05
I0416 02:52:07.117435 12023 solver.cpp:237] Iteration 13414400, loss = 3.38819
I0416 02:52:07.117508 12023 solver.cpp:253]     Train net output #0: loss = 2.94366 (* 1 = 2.94366 loss)
I0416 02:52:07.117516 12023 sgd_solver.cpp:106] Iteration 13414400, lr = 3.9063e-05
I0416 02:58:36.195722 12023 solver.cpp:237] Iteration 13465600, loss = 3.38963
I0416 02:58:36.195796 12023 solver.cpp:253]     Train net output #0: loss = 1.68675 (* 1 = 1.68675 loss)
I0416 02:58:36.195803 12023 sgd_solver.cpp:106] Iteration 13465600, lr = 3.9063e-05
I0416 03:05:05.126251 12023 solver.cpp:237] Iteration 13516800, loss = 3.3821
I0416 03:05:05.126325 12023 solver.cpp:253]     Train net output #0: loss = 2.79042 (* 1 = 2.79042 loss)
I0416 03:05:05.126332 12023 sgd_solver.cpp:106] Iteration 13516800, lr = 3.9063e-05
I0416 03:11:34.392259 12023 solver.cpp:341] Iteration 13568000, Testing net (#0)
I0416 03:11:59.097066 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0416 03:12:03.929185 12023 solver.cpp:409]     Test net output #0: accuracy = 0.32482
I0416 03:12:03.929224 12023 solver.cpp:409]     Test net output #1: loss = 3.19652 (* 1 = 3.19652 loss)
I0416 03:12:03.933156 12023 solver.cpp:237] Iteration 13568000, loss = 3.41498
I0416 03:12:03.933179 12023 solver.cpp:253]     Train net output #0: loss = 0.0294696 (* 1 = 0.0294696 loss)
I0416 03:12:03.933190 12023 sgd_solver.cpp:106] Iteration 13568000, lr = 3.9063e-05
I0416 03:18:33.182561 12023 solver.cpp:237] Iteration 13619200, loss = 3.40652
I0416 03:18:33.182638 12023 solver.cpp:253]     Train net output #0: loss = 8.90599 (* 1 = 8.90599 loss)
I0416 03:18:33.182644 12023 sgd_solver.cpp:106] Iteration 13619200, lr = 3.9063e-05
I0416 03:25:04.008716 12023 solver.cpp:237] Iteration 13670400, loss = 3.39598
I0416 03:25:04.008765 12023 solver.cpp:253]     Train net output #0: loss = 2.48166 (* 1 = 2.48166 loss)
I0416 03:25:04.008771 12023 sgd_solver.cpp:106] Iteration 13670400, lr = 3.9063e-05
I0416 03:31:33.192492 12023 solver.cpp:237] Iteration 13721600, loss = 3.38146
I0416 03:31:33.192561 12023 solver.cpp:253]     Train net output #0: loss = 5.23604 (* 1 = 5.23604 loss)
I0416 03:31:33.192567 12023 sgd_solver.cpp:106] Iteration 13721600, lr = 3.9063e-05
I0416 03:38:02.237731 12023 solver.cpp:237] Iteration 13772800, loss = 3.36348
I0416 03:38:02.237787 12023 solver.cpp:253]     Train net output #0: loss = 3.41632 (* 1 = 3.41632 loss)
I0416 03:38:02.237792 12023 sgd_solver.cpp:106] Iteration 13772800, lr = 3.9063e-05
I0416 03:44:36.815716 12023 solver.cpp:341] Iteration 13824000, Testing net (#0)
I0416 03:44:57.468868 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0416 03:45:03.227773 12023 solver.cpp:409]     Test net output #0: accuracy = 0.31886
I0416 03:45:03.227808 12023 solver.cpp:409]     Test net output #1: loss = 3.22166 (* 1 = 3.22166 loss)
I0416 03:45:03.231576 12023 solver.cpp:237] Iteration 13824000, loss = 3.37175
I0416 03:45:03.231595 12023 solver.cpp:253]     Train net output #0: loss = 3.12164 (* 1 = 3.12164 loss)
I0416 03:45:03.231605 12023 sgd_solver.cpp:106] Iteration 13824000, lr = 3.9063e-05
I0416 03:51:37.564294 12023 solver.cpp:237] Iteration 13875200, loss = 3.36301
I0416 03:51:37.564355 12023 solver.cpp:253]     Train net output #0: loss = 5.07154 (* 1 = 5.07154 loss)
I0416 03:51:37.564362 12023 sgd_solver.cpp:106] Iteration 13875200, lr = 3.9063e-05
I0416 03:58:06.843628 12023 solver.cpp:237] Iteration 13926400, loss = 3.37771
I0416 03:58:06.843698 12023 solver.cpp:253]     Train net output #0: loss = 1.53336 (* 1 = 1.53336 loss)
I0416 03:58:06.843704 12023 sgd_solver.cpp:106] Iteration 13926400, lr = 3.9063e-05
I0416 04:04:35.735357 12023 solver.cpp:237] Iteration 13977600, loss = 3.37243
I0416 04:04:35.735426 12023 solver.cpp:253]     Train net output #0: loss = 2.89916 (* 1 = 2.89916 loss)
I0416 04:04:35.735432 12023 sgd_solver.cpp:106] Iteration 13977600, lr = 3.9063e-05
I0416 04:11:07.464807 12023 solver.cpp:237] Iteration 14028800, loss = 3.3659
I0416 04:11:07.464879 12023 solver.cpp:253]     Train net output #0: loss = 4.06438 (* 1 = 4.06438 loss)
I0416 04:11:07.464887 12023 sgd_solver.cpp:106] Iteration 14028800, lr = 3.9063e-05
I0416 04:17:37.344338 12023 solver.cpp:341] Iteration 14080000, Testing net (#0)
I0416 04:17:57.104262 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0416 04:18:03.859835 12023 solver.cpp:409]     Test net output #0: accuracy = 0.31932
I0416 04:18:03.859870 12023 solver.cpp:409]     Test net output #1: loss = 3.21212 (* 1 = 3.21212 loss)
I0416 04:18:03.863629 12023 solver.cpp:237] Iteration 14080000, loss = 3.37805
I0416 04:18:03.863652 12023 solver.cpp:253]     Train net output #0: loss = 0.900045 (* 1 = 0.900045 loss)
I0416 04:18:03.863662 12023 sgd_solver.cpp:106] Iteration 14080000, lr = 3.9063e-05
I0416 04:24:32.854250 12023 solver.cpp:237] Iteration 14131200, loss = 3.39211
I0416 04:24:32.854321 12023 solver.cpp:253]     Train net output #0: loss = 1.94376 (* 1 = 1.94376 loss)
I0416 04:24:32.854326 12023 sgd_solver.cpp:106] Iteration 14131200, lr = 3.9063e-05
I0416 04:31:01.727485 12023 solver.cpp:237] Iteration 14182400, loss = 3.38432
I0416 04:31:01.727555 12023 solver.cpp:253]     Train net output #0: loss = 1.02373 (* 1 = 1.02373 loss)
I0416 04:31:01.727560 12023 sgd_solver.cpp:106] Iteration 14182400, lr = 3.9063e-05
I0416 04:37:30.835080 12023 solver.cpp:237] Iteration 14233600, loss = 3.37762
I0416 04:37:30.835165 12023 solver.cpp:253]     Train net output #0: loss = 0.273122 (* 1 = 0.273122 loss)
I0416 04:37:30.835175 12023 sgd_solver.cpp:106] Iteration 14233600, lr = 3.9063e-05
I0416 04:44:00.064692 12023 solver.cpp:237] Iteration 14284800, loss = 3.3606
I0416 04:44:00.064752 12023 solver.cpp:253]     Train net output #0: loss = 2.6455 (* 1 = 2.6455 loss)
I0416 04:44:00.064760 12023 sgd_solver.cpp:106] Iteration 14284800, lr = 3.9063e-05
I0416 04:50:29.398404 12023 solver.cpp:341] Iteration 14336000, Testing net (#0)
I0416 04:50:51.229117 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0416 04:50:57.971670 12023 solver.cpp:409]     Test net output #0: accuracy = 0.332559
I0416 04:50:57.971704 12023 solver.cpp:409]     Test net output #1: loss = 3.15226 (* 1 = 3.15226 loss)
I0416 04:50:57.975458 12023 solver.cpp:237] Iteration 14336000, loss = 3.37646
I0416 04:50:57.975481 12023 solver.cpp:253]     Train net output #0: loss = 3.49736 (* 1 = 3.49736 loss)
I0416 04:50:57.975489 12023 sgd_solver.cpp:106] Iteration 14336000, lr = 3.9063e-05
I0416 04:57:27.227031 12023 solver.cpp:237] Iteration 14387200, loss = 3.37004
I0416 04:57:27.227089 12023 solver.cpp:253]     Train net output #0: loss = 2.47887 (* 1 = 2.47887 loss)
I0416 04:57:27.227097 12023 sgd_solver.cpp:106] Iteration 14387200, lr = 3.9063e-05
I0416 05:03:56.389708 12023 solver.cpp:237] Iteration 14438400, loss = 3.39275
I0416 05:03:56.389777 12023 solver.cpp:253]     Train net output #0: loss = 1.68494 (* 1 = 1.68494 loss)
I0416 05:03:56.389783 12023 sgd_solver.cpp:106] Iteration 14438400, lr = 3.9063e-05
I0416 05:10:25.603229 12023 solver.cpp:237] Iteration 14489600, loss = 3.36315
I0416 05:10:25.603297 12023 solver.cpp:253]     Train net output #0: loss = 3.23253 (* 1 = 3.23253 loss)
I0416 05:10:25.603302 12023 sgd_solver.cpp:106] Iteration 14489600, lr = 3.9063e-05
I0416 05:16:54.828930 12023 solver.cpp:237] Iteration 14540800, loss = 3.35856
I0416 05:16:54.828989 12023 solver.cpp:253]     Train net output #0: loss = 0.68345 (* 1 = 0.68345 loss)
I0416 05:16:54.828995 12023 sgd_solver.cpp:106] Iteration 14540800, lr = 3.9063e-05
I0416 05:23:23.754431 12023 solver.cpp:341] Iteration 14592000, Testing net (#0)
I0416 05:23:45.797224 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0416 05:23:53.297797 12023 solver.cpp:409]     Test net output #0: accuracy = 0.32212
I0416 05:23:53.297837 12023 solver.cpp:409]     Test net output #1: loss = 3.22353 (* 1 = 3.22353 loss)
I0416 05:23:53.301821 12023 solver.cpp:237] Iteration 14592000, loss = 3.34916
I0416 05:23:53.301842 12023 solver.cpp:253]     Train net output #0: loss = 3.58837 (* 1 = 3.58837 loss)
I0416 05:23:53.301852 12023 sgd_solver.cpp:106] Iteration 14592000, lr = 3.9063e-05
I0416 05:30:22.087425 12023 solver.cpp:237] Iteration 14643200, loss = 3.34673
I0416 05:30:22.087498 12023 solver.cpp:253]     Train net output #0: loss = 3.8167 (* 1 = 3.8167 loss)
I0416 05:30:22.087504 12023 sgd_solver.cpp:106] Iteration 14643200, lr = 3.9063e-05
I0416 05:36:51.257580 12023 solver.cpp:237] Iteration 14694400, loss = 3.35092
I0416 05:36:51.257640 12023 solver.cpp:253]     Train net output #0: loss = 3.68485 (* 1 = 3.68485 loss)
I0416 05:36:51.257647 12023 sgd_solver.cpp:106] Iteration 14694400, lr = 3.9063e-05
I0416 05:43:20.476021 12023 solver.cpp:237] Iteration 14745600, loss = 3.35524
I0416 05:43:20.476083 12023 solver.cpp:253]     Train net output #0: loss = 3.071 (* 1 = 3.071 loss)
I0416 05:43:20.476089 12023 sgd_solver.cpp:106] Iteration 14745600, lr = 3.9063e-05
I0416 05:49:49.428829 12023 solver.cpp:237] Iteration 14796800, loss = 3.35636
I0416 05:49:49.428890 12023 solver.cpp:253]     Train net output #0: loss = 3.04789 (* 1 = 3.04789 loss)
I0416 05:49:49.428900 12023 sgd_solver.cpp:106] Iteration 14796800, lr = 3.9063e-05
I0416 05:56:18.286816 12023 solver.cpp:341] Iteration 14848000, Testing net (#0)
I0416 05:56:40.355137 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0416 05:56:47.825896 12023 solver.cpp:409]     Test net output #0: accuracy = 0.32686
I0416 05:56:47.825934 12023 solver.cpp:409]     Test net output #1: loss = 3.18142 (* 1 = 3.18142 loss)
I0416 05:56:47.829862 12023 solver.cpp:237] Iteration 14848000, loss = 3.37101
I0416 05:56:47.829884 12023 solver.cpp:253]     Train net output #0: loss = 2.60471 (* 1 = 2.60471 loss)
I0416 05:56:47.829891 12023 sgd_solver.cpp:106] Iteration 14848000, lr = 3.9063e-05
I0416 06:03:17.086730 12023 solver.cpp:237] Iteration 14899200, loss = 3.36175
I0416 06:03:17.086823 12023 solver.cpp:253]     Train net output #0: loss = 2.94026 (* 1 = 2.94026 loss)
I0416 06:03:17.086830 12023 sgd_solver.cpp:106] Iteration 14899200, lr = 3.9063e-05
I0416 06:09:46.688196 12023 solver.cpp:237] Iteration 14950400, loss = 3.36895
I0416 06:09:46.688269 12023 solver.cpp:253]     Train net output #0: loss = 2.48761 (* 1 = 2.48761 loss)
I0416 06:09:46.688277 12023 sgd_solver.cpp:106] Iteration 14950400, lr = 3.9063e-05
I0416 06:16:15.804051 12023 solver.cpp:237] Iteration 15001600, loss = 3.33581
I0416 06:16:15.804101 12023 solver.cpp:253]     Train net output #0: loss = 7.74872 (* 1 = 7.74872 loss)
I0416 06:16:15.804106 12023 sgd_solver.cpp:106] Iteration 15001600, lr = 3.9063e-05
I0416 06:22:44.842326 12023 solver.cpp:237] Iteration 15052800, loss = 3.34225
I0416 06:22:44.842376 12023 solver.cpp:253]     Train net output #0: loss = 4.89416 (* 1 = 4.89416 loss)
I0416 06:22:44.842382 12023 sgd_solver.cpp:106] Iteration 15052800, lr = 3.9063e-05
I0416 06:29:19.673913 12023 solver.cpp:341] Iteration 15104000, Testing net (#0)
I0416 06:29:40.288964 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0416 06:29:49.217983 12023 solver.cpp:409]     Test net output #0: accuracy = 0.32284
I0416 06:29:49.218021 12023 solver.cpp:409]     Test net output #1: loss = 3.19157 (* 1 = 3.19157 loss)
I0416 06:29:49.221976 12023 solver.cpp:237] Iteration 15104000, loss = 3.33881
I0416 06:29:49.221997 12023 solver.cpp:253]     Train net output #0: loss = 0.928503 (* 1 = 0.928503 loss)
I0416 06:29:49.222005 12023 sgd_solver.cpp:106] Iteration 15104000, lr = 3.9063e-05
I0416 06:36:23.457000 12023 solver.cpp:237] Iteration 15155200, loss = 3.33772
I0416 06:36:23.457047 12023 solver.cpp:253]     Train net output #0: loss = 5.20622 (* 1 = 5.20622 loss)
I0416 06:36:23.457056 12023 sgd_solver.cpp:106] Iteration 15155200, lr = 3.9063e-05
I0416 06:42:52.983479 12023 solver.cpp:237] Iteration 15206400, loss = 3.34109
I0416 06:42:52.983542 12023 solver.cpp:253]     Train net output #0: loss = 5.91403 (* 1 = 5.91403 loss)
I0416 06:42:52.983548 12023 sgd_solver.cpp:106] Iteration 15206400, lr = 3.9063e-05
I0416 06:49:22.142783 12023 solver.cpp:237] Iteration 15257600, loss = 3.33585
I0416 06:49:22.142844 12023 solver.cpp:253]     Train net output #0: loss = 0.116017 (* 1 = 0.116017 loss)
I0416 06:49:22.142851 12023 sgd_solver.cpp:106] Iteration 15257600, lr = 3.9063e-05
I0416 06:55:51.359855 12023 solver.cpp:237] Iteration 15308800, loss = 3.32636
I0416 06:55:51.359925 12023 solver.cpp:253]     Train net output #0: loss = 3.63167 (* 1 = 3.63167 loss)
I0416 06:55:51.359932 12023 sgd_solver.cpp:106] Iteration 15308800, lr = 3.9063e-05
I0416 07:02:20.234119 12023 solver.cpp:459] Snapshotting to binary proto file snapshots/caffenet128_no_lrn_lsuv_relu_bs1_iter_15360000.caffemodel
I0416 07:02:21.550684 12023 sgd_solver.cpp:269] Snapshotting solver state to binary proto file snapshots/caffenet128_no_lrn_lsuv_relu_bs1_iter_15360000.solverstate
I0416 07:02:21.612161 12023 solver.cpp:341] Iteration 15360000, Testing net (#0)
I0416 07:02:39.054994 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0416 07:02:47.935323 12023 solver.cpp:409]     Test net output #0: accuracy = 0.32684
I0416 07:02:47.935359 12023 solver.cpp:409]     Test net output #1: loss = 3.19432 (* 1 = 3.19432 loss)
I0416 07:02:47.939131 12023 solver.cpp:237] Iteration 15360000, loss = 3.34539
I0416 07:02:47.939152 12023 solver.cpp:253]     Train net output #0: loss = 5.26298 (* 1 = 5.26298 loss)
I0416 07:02:47.939162 12023 sgd_solver.cpp:106] Iteration 15360000, lr = 3.9063e-05
I0416 07:09:17.144819 12023 solver.cpp:237] Iteration 15411200, loss = 3.36786
I0416 07:09:17.144902 12023 solver.cpp:253]     Train net output #0: loss = 0.55344 (* 1 = 0.55344 loss)
I0416 07:09:17.144913 12023 sgd_solver.cpp:106] Iteration 15411200, lr = 3.9063e-05
I0416 07:15:46.267572 12023 solver.cpp:237] Iteration 15462400, loss = 3.34507
I0416 07:15:46.267632 12023 solver.cpp:253]     Train net output #0: loss = 7.50756 (* 1 = 7.50756 loss)
I0416 07:15:46.267640 12023 sgd_solver.cpp:106] Iteration 15462400, lr = 3.9063e-05
I0416 07:22:15.270460 12023 solver.cpp:237] Iteration 15513600, loss = 3.34571
I0416 07:22:15.270535 12023 solver.cpp:253]     Train net output #0: loss = 0.0299589 (* 1 = 0.0299589 loss)
I0416 07:22:15.270545 12023 sgd_solver.cpp:106] Iteration 15513600, lr = 3.9063e-05
I0416 07:28:44.160862 12023 solver.cpp:237] Iteration 15564800, loss = 3.33552
I0416 07:28:44.160935 12023 solver.cpp:253]     Train net output #0: loss = 0.951117 (* 1 = 0.951117 loss)
I0416 07:28:44.160943 12023 sgd_solver.cpp:106] Iteration 15564800, lr = 3.9063e-05
I0416 07:35:13.479210 12023 solver.cpp:341] Iteration 15616000, Testing net (#0)
I0416 07:35:31.048310 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0416 07:35:39.992190 12023 solver.cpp:409]     Test net output #0: accuracy = 0.32724
I0416 07:35:39.992226 12023 solver.cpp:409]     Test net output #1: loss = 3.183 (* 1 = 3.183 loss)
I0416 07:35:39.995982 12023 solver.cpp:237] Iteration 15616000, loss = 3.35035
I0416 07:35:39.996003 12023 solver.cpp:253]     Train net output #0: loss = 4.26455 (* 1 = 4.26455 loss)
I0416 07:35:39.996012 12023 sgd_solver.cpp:106] Iteration 15616000, lr = 3.9063e-05
I0416 07:42:09.373819 12023 solver.cpp:237] Iteration 15667200, loss = 3.3295
I0416 07:42:09.373893 12023 solver.cpp:253]     Train net output #0: loss = 3.31723 (* 1 = 3.31723 loss)
I0416 07:42:09.373898 12023 sgd_solver.cpp:106] Iteration 15667200, lr = 3.9063e-05
I0416 07:48:38.609622 12023 solver.cpp:237] Iteration 15718400, loss = 3.36609
I0416 07:48:38.609683 12023 solver.cpp:253]     Train net output #0: loss = 9.37459 (* 1 = 9.37459 loss)
I0416 07:48:38.609689 12023 sgd_solver.cpp:106] Iteration 15718400, lr = 3.9063e-05
I0416 07:55:07.719161 12023 solver.cpp:237] Iteration 15769600, loss = 3.33149
I0416 07:55:07.719235 12023 solver.cpp:253]     Train net output #0: loss = 2.29809 (* 1 = 2.29809 loss)
I0416 07:55:07.719241 12023 sgd_solver.cpp:106] Iteration 15769600, lr = 3.9063e-05
I0416 08:01:36.583338 12023 solver.cpp:237] Iteration 15820800, loss = 3.32473
I0416 08:01:36.583395 12023 solver.cpp:253]     Train net output #0: loss = 6.50238 (* 1 = 6.50238 loss)
I0416 08:01:36.583400 12023 sgd_solver.cpp:106] Iteration 15820800, lr = 3.9063e-05
I0416 08:08:05.462718 12023 solver.cpp:341] Iteration 15872000, Testing net (#0)
I0416 08:08:23.111166 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0416 08:08:31.978062 12023 solver.cpp:409]     Test net output #0: accuracy = 0.33604
I0416 08:08:31.978096 12023 solver.cpp:409]     Test net output #1: loss = 3.13931 (* 1 = 3.13931 loss)
I0416 08:08:31.981827 12023 solver.cpp:237] Iteration 15872000, loss = 3.31109
I0416 08:08:31.981848 12023 solver.cpp:253]     Train net output #0: loss = 0.801568 (* 1 = 0.801568 loss)
I0416 08:08:31.981858 12023 sgd_solver.cpp:106] Iteration 15872000, lr = 3.9063e-05
I0416 08:15:01.032127 12023 solver.cpp:237] Iteration 15923200, loss = 3.31816
I0416 08:15:01.032202 12023 solver.cpp:253]     Train net output #0: loss = 2.41052 (* 1 = 2.41052 loss)
I0416 08:15:01.032217 12023 sgd_solver.cpp:106] Iteration 15923200, lr = 3.9063e-05
I0416 08:21:30.225009 12023 solver.cpp:237] Iteration 15974400, loss = 3.32755
I0416 08:21:30.225080 12023 solver.cpp:253]     Train net output #0: loss = 2.39924 (* 1 = 2.39924 loss)
I0416 08:21:30.225085 12023 sgd_solver.cpp:106] Iteration 15974400, lr = 3.9063e-05
I0416 08:27:59.085891 12023 solver.cpp:237] Iteration 16025600, loss = 3.32429
I0416 08:27:59.085958 12023 solver.cpp:253]     Train net output #0: loss = 4.1127 (* 1 = 4.1127 loss)
I0416 08:27:59.085964 12023 sgd_solver.cpp:106] Iteration 16025600, lr = 3.9063e-05
I0416 08:34:27.977645 12023 solver.cpp:237] Iteration 16076800, loss = 3.33144
I0416 08:34:27.977725 12023 solver.cpp:253]     Train net output #0: loss = 1.32539 (* 1 = 1.32539 loss)
I0416 08:34:27.977731 12023 sgd_solver.cpp:106] Iteration 16076800, lr = 3.9063e-05
I0416 08:40:56.877423 12023 solver.cpp:341] Iteration 16128000, Testing net (#0)
I0416 08:41:14.579623 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0416 08:41:23.394250 12023 solver.cpp:409]     Test net output #0: accuracy = 0.32842
I0416 08:41:23.394285 12023 solver.cpp:409]     Test net output #1: loss = 3.16847 (* 1 = 3.16847 loss)
I0416 08:41:23.398177 12023 solver.cpp:237] Iteration 16128000, loss = 3.35195
I0416 08:41:23.398226 12023 solver.cpp:253]     Train net output #0: loss = 3.02052 (* 1 = 3.02052 loss)
I0416 08:41:23.398244 12023 sgd_solver.cpp:106] Iteration 16128000, lr = 3.9063e-05
I0416 08:47:52.928761 12023 solver.cpp:237] Iteration 16179200, loss = 3.32677
I0416 08:47:52.928836 12023 solver.cpp:253]     Train net output #0: loss = 3.34495 (* 1 = 3.34495 loss)
I0416 08:47:52.928845 12023 sgd_solver.cpp:106] Iteration 16179200, lr = 3.9063e-05
I0416 08:54:22.329928 12023 solver.cpp:237] Iteration 16230400, loss = 3.34144
I0416 08:54:22.330000 12023 solver.cpp:253]     Train net output #0: loss = 5.29933 (* 1 = 5.29933 loss)
I0416 08:54:22.330006 12023 sgd_solver.cpp:106] Iteration 16230400, lr = 3.9063e-05
I0416 09:00:51.425621 12023 solver.cpp:237] Iteration 16281600, loss = 3.3164
I0416 09:00:51.425681 12023 solver.cpp:253]     Train net output #0: loss = 4.22145 (* 1 = 4.22145 loss)
I0416 09:00:51.425688 12023 sgd_solver.cpp:106] Iteration 16281600, lr = 3.9063e-05
I0416 09:07:20.550225 12023 solver.cpp:237] Iteration 16332800, loss = 3.3077
I0416 09:07:20.550285 12023 solver.cpp:253]     Train net output #0: loss = 2.91976 (* 1 = 2.91976 loss)
I0416 09:07:20.550292 12023 sgd_solver.cpp:106] Iteration 16332800, lr = 3.9063e-05
I0416 09:13:55.435070 12023 solver.cpp:341] Iteration 16384000, Testing net (#0)
I0416 09:14:11.945997 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0416 09:14:21.841168 12023 solver.cpp:409]     Test net output #0: accuracy = 0.3308
I0416 09:14:21.841202 12023 solver.cpp:409]     Test net output #1: loss = 3.17784 (* 1 = 3.17784 loss)
I0416 09:14:21.845006 12023 solver.cpp:237] Iteration 16384000, loss = 3.31306
I0416 09:14:21.845026 12023 solver.cpp:253]     Train net output #0: loss = 2.42117 (* 1 = 2.42117 loss)
I0416 09:14:21.845036 12023 sgd_solver.cpp:106] Iteration 16384000, lr = 3.9063e-05
I0416 09:20:56.066925 12023 solver.cpp:237] Iteration 16435200, loss = 3.31357
I0416 09:20:56.066980 12023 solver.cpp:253]     Train net output #0: loss = 1.68731 (* 1 = 1.68731 loss)
I0416 09:20:56.066987 12023 sgd_solver.cpp:106] Iteration 16435200, lr = 3.9063e-05
I0416 09:27:25.397996 12023 solver.cpp:237] Iteration 16486400, loss = 3.33151
I0416 09:27:25.398066 12023 solver.cpp:253]     Train net output #0: loss = 1.70214 (* 1 = 1.70214 loss)
I0416 09:27:25.398073 12023 sgd_solver.cpp:106] Iteration 16486400, lr = 3.9063e-05
I0416 09:33:54.217581 12023 solver.cpp:237] Iteration 16537600, loss = 3.31414
I0416 09:33:54.217654 12023 solver.cpp:253]     Train net output #0: loss = 4.71705 (* 1 = 4.71705 loss)
I0416 09:33:54.217660 12023 sgd_solver.cpp:106] Iteration 16537600, lr = 3.9063e-05
I0416 09:40:23.097149 12023 solver.cpp:237] Iteration 16588800, loss = 3.30029
I0416 09:40:23.097220 12023 solver.cpp:253]     Train net output #0: loss = 4.99373 (* 1 = 4.99373 loss)
I0416 09:40:23.097226 12023 sgd_solver.cpp:106] Iteration 16588800, lr = 3.9063e-05
I0416 09:46:51.939541 12023 solver.cpp:341] Iteration 16640000, Testing net (#0)
I0416 09:47:07.468916 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0416 09:47:18.351102 12023 solver.cpp:409]     Test net output #0: accuracy = 0.3201
I0416 09:47:18.351145 12023 solver.cpp:409]     Test net output #1: loss = 3.25162 (* 1 = 3.25162 loss)
I0416 09:47:18.354918 12023 solver.cpp:237] Iteration 16640000, loss = 3.31572
I0416 09:47:18.354938 12023 solver.cpp:253]     Train net output #0: loss = 4.31365 (* 1 = 4.31365 loss)
I0416 09:47:18.354948 12023 sgd_solver.cpp:106] Iteration 16640000, lr = 3.9063e-05
I0416 09:53:47.607980 12023 solver.cpp:237] Iteration 16691200, loss = 3.33111
I0416 09:53:47.608059 12023 solver.cpp:253]     Train net output #0: loss = 0.223292 (* 1 = 0.223292 loss)
I0416 09:53:47.608067 12023 sgd_solver.cpp:106] Iteration 16691200, lr = 3.9063e-05
I0416 10:00:16.588229 12023 solver.cpp:237] Iteration 16742400, loss = 3.31967
I0416 10:00:16.588299 12023 solver.cpp:253]     Train net output #0: loss = 5.18075 (* 1 = 5.18075 loss)
I0416 10:00:16.588305 12023 sgd_solver.cpp:106] Iteration 16742400, lr = 3.9063e-05
I0416 10:06:45.442077 12023 solver.cpp:237] Iteration 16793600, loss = 3.32524
I0416 10:06:45.442147 12023 solver.cpp:253]     Train net output #0: loss = 5.34398 (* 1 = 5.34398 loss)
I0416 10:06:45.442153 12023 sgd_solver.cpp:106] Iteration 16793600, lr = 3.9063e-05
I0416 10:13:14.287801 12023 solver.cpp:237] Iteration 16844800, loss = 3.30744
I0416 10:13:14.287868 12023 solver.cpp:253]     Train net output #0: loss = 2.32555 (* 1 = 2.32555 loss)
I0416 10:13:14.287880 12023 sgd_solver.cpp:106] Iteration 16844800, lr = 3.9063e-05
I0416 10:19:43.548494 12023 solver.cpp:341] Iteration 16896000, Testing net (#0)
I0416 10:20:00.879245 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0416 10:20:13.087352 12023 solver.cpp:409]     Test net output #0: accuracy = 0.336559
I0416 10:20:13.087390 12023 solver.cpp:409]     Test net output #1: loss = 3.17359 (* 1 = 3.17359 loss)
I0416 10:20:13.091375 12023 solver.cpp:237] Iteration 16896000, loss = 3.31835
I0416 10:20:13.091398 12023 solver.cpp:253]     Train net output #0: loss = 1.00947 (* 1 = 1.00947 loss)
I0416 10:20:13.091408 12023 sgd_solver.cpp:106] Iteration 16896000, lr = 3.9063e-05
I0416 10:26:42.112314 12023 solver.cpp:237] Iteration 16947200, loss = 3.31533
I0416 10:26:42.112380 12023 solver.cpp:253]     Train net output #0: loss = 3.56688 (* 1 = 3.56688 loss)
I0416 10:26:42.112385 12023 sgd_solver.cpp:106] Iteration 16947200, lr = 3.9063e-05
I0416 10:33:10.960111 12023 solver.cpp:237] Iteration 16998400, loss = 3.33793
I0416 10:33:10.960177 12023 solver.cpp:253]     Train net output #0: loss = 3.42078 (* 1 = 3.42078 loss)
I0416 10:33:10.960183 12023 sgd_solver.cpp:106] Iteration 16998400, lr = 3.9063e-05
I0416 10:39:39.811497 12023 solver.cpp:237] Iteration 17049600, loss = 3.30363
I0416 10:39:39.811566 12023 solver.cpp:253]     Train net output #0: loss = 2.25409 (* 1 = 2.25409 loss)
I0416 10:39:39.811571 12023 sgd_solver.cpp:106] Iteration 17049600, lr = 3.9063e-05
I0416 10:46:08.664086 12023 solver.cpp:237] Iteration 17100800, loss = 3.30189
I0416 10:46:08.664155 12023 solver.cpp:253]     Train net output #0: loss = 4.78897 (* 1 = 4.78897 loss)
I0416 10:46:08.664162 12023 sgd_solver.cpp:106] Iteration 17100800, lr = 3.9063e-05
I0416 10:52:39.436355 12023 solver.cpp:341] Iteration 17152000, Testing net (#0)
I0416 10:52:56.796655 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0416 10:53:08.594332 12023 solver.cpp:409]     Test net output #0: accuracy = 0.33586
I0416 10:53:08.594367 12023 solver.cpp:409]     Test net output #1: loss = 3.13677 (* 1 = 3.13677 loss)
I0416 10:53:08.598121 12023 solver.cpp:237] Iteration 17152000, loss = 3.29074
I0416 10:53:08.598142 12023 solver.cpp:253]     Train net output #0: loss = 6.47224 (* 1 = 6.47224 loss)
I0416 10:53:08.598151 12023 sgd_solver.cpp:106] Iteration 17152000, lr = 3.9063e-05
I0416 10:59:42.016284 12023 solver.cpp:237] Iteration 17203200, loss = 3.30014
I0416 10:59:42.016367 12023 solver.cpp:253]     Train net output #0: loss = 5.32444 (* 1 = 5.32444 loss)
I0416 10:59:42.016374 12023 sgd_solver.cpp:106] Iteration 17203200, lr = 3.9063e-05
I0416 11:06:15.676705 12023 solver.cpp:237] Iteration 17254400, loss = 3.30778
I0416 11:06:15.676780 12023 solver.cpp:253]     Train net output #0: loss = 0.893879 (* 1 = 0.893879 loss)
I0416 11:06:15.676790 12023 sgd_solver.cpp:106] Iteration 17254400, lr = 3.9063e-05
I0416 11:12:48.601363 12023 solver.cpp:237] Iteration 17305600, loss = 3.30122
I0416 11:12:48.601466 12023 solver.cpp:253]     Train net output #0: loss = 3.71878 (* 1 = 3.71878 loss)
I0416 11:12:48.601474 12023 sgd_solver.cpp:106] Iteration 17305600, lr = 3.9063e-05
I0416 11:19:22.279312 12023 solver.cpp:237] Iteration 17356800, loss = 3.29769
I0416 11:19:22.279381 12023 solver.cpp:253]     Train net output #0: loss = 6.57852 (* 1 = 6.57852 loss)
I0416 11:19:22.279387 12023 sgd_solver.cpp:106] Iteration 17356800, lr = 3.9063e-05
I0416 11:25:51.814931 12023 solver.cpp:341] Iteration 17408000, Testing net (#0)
I0416 11:26:07.472986 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0416 11:26:18.373308 12023 solver.cpp:409]     Test net output #0: accuracy = 0.33202
I0416 11:26:18.373342 12023 solver.cpp:409]     Test net output #1: loss = 3.15944 (* 1 = 3.15944 loss)
I0416 11:26:18.377095 12023 solver.cpp:237] Iteration 17408000, loss = 3.32129
I0416 11:26:18.377115 12023 solver.cpp:253]     Train net output #0: loss = 4.07376 (* 1 = 4.07376 loss)
I0416 11:26:18.377123 12023 sgd_solver.cpp:106] Iteration 17408000, lr = 3.9063e-05
I0416 11:32:47.971732 12023 solver.cpp:237] Iteration 17459200, loss = 3.30796
I0416 11:32:47.971803 12023 solver.cpp:253]     Train net output #0: loss = 0.387505 (* 1 = 0.387505 loss)
I0416 11:32:47.971810 12023 sgd_solver.cpp:106] Iteration 17459200, lr = 3.9063e-05
I0416 11:39:20.478143 12023 solver.cpp:237] Iteration 17510400, loss = 3.3141
I0416 11:39:20.478238 12023 solver.cpp:253]     Train net output #0: loss = 6.10822 (* 1 = 6.10822 loss)
I0416 11:39:20.478253 12023 sgd_solver.cpp:106] Iteration 17510400, lr = 3.9063e-05
I0416 11:45:51.858294 12023 solver.cpp:237] Iteration 17561600, loss = 3.292
I0416 11:45:51.858355 12023 solver.cpp:253]     Train net output #0: loss = 0.121447 (* 1 = 0.121447 loss)
I0416 11:45:51.858361 12023 sgd_solver.cpp:106] Iteration 17561600, lr = 3.9063e-05
I0416 11:52:21.571429 12023 solver.cpp:237] Iteration 17612800, loss = 3.28989
I0416 11:52:21.571491 12023 solver.cpp:253]     Train net output #0: loss = 1.4418 (* 1 = 1.4418 loss)
I0416 11:52:21.571496 12023 sgd_solver.cpp:106] Iteration 17612800, lr = 3.9063e-05
I0416 11:58:53.650046 12023 solver.cpp:341] Iteration 17664000, Testing net (#0)
I0416 11:59:08.368605 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0416 11:59:20.030797 12023 solver.cpp:409]     Test net output #0: accuracy = 0.33454
I0416 11:59:20.030833 12023 solver.cpp:409]     Test net output #1: loss = 3.13729 (* 1 = 3.13729 loss)
I0416 11:59:20.034569 12023 solver.cpp:237] Iteration 17664000, loss = 3.29303
I0416 11:59:20.034591 12023 solver.cpp:253]     Train net output #0: loss = 8.10369 (* 1 = 8.10369 loss)
I0416 11:59:20.034600 12023 sgd_solver.cpp:106] Iteration 17664000, lr = 3.9063e-05
I0416 12:05:54.056102 12023 solver.cpp:237] Iteration 17715200, loss = 3.28015
I0416 12:05:54.056172 12023 solver.cpp:253]     Train net output #0: loss = 1.61648 (* 1 = 1.61648 loss)
I0416 12:05:54.056179 12023 sgd_solver.cpp:106] Iteration 17715200, lr = 3.9063e-05
I0416 12:12:23.975342 12023 solver.cpp:237] Iteration 17766400, loss = 3.29227
I0416 12:12:23.975414 12023 solver.cpp:253]     Train net output #0: loss = 0.119123 (* 1 = 0.119123 loss)
I0416 12:12:23.975419 12023 sgd_solver.cpp:106] Iteration 17766400, lr = 3.9063e-05
I0416 12:18:53.223495 12023 solver.cpp:237] Iteration 17817600, loss = 3.29469
I0416 12:18:53.223565 12023 solver.cpp:253]     Train net output #0: loss = 1.6557 (* 1 = 1.6557 loss)
I0416 12:18:53.223572 12023 sgd_solver.cpp:106] Iteration 17817600, lr = 3.9063e-05
I0416 12:25:22.277905 12023 solver.cpp:237] Iteration 17868800, loss = 3.27443
I0416 12:25:22.277966 12023 solver.cpp:253]     Train net output #0: loss = 1.29234 (* 1 = 1.29234 loss)
I0416 12:25:22.277971 12023 sgd_solver.cpp:106] Iteration 17868800, lr = 3.9063e-05
I0416 12:31:51.343997 12023 solver.cpp:459] Snapshotting to binary proto file snapshots/caffenet128_no_lrn_lsuv_relu_bs1_iter_17920000.caffemodel
I0416 12:31:52.786095 12023 sgd_solver.cpp:269] Snapshotting solver state to binary proto file snapshots/caffenet128_no_lrn_lsuv_relu_bs1_iter_17920000.solverstate
I0416 12:31:52.847503 12023 solver.cpp:341] Iteration 17920000, Testing net (#0)
I0416 12:32:08.146253 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0416 12:32:21.203022 12023 solver.cpp:409]     Test net output #0: accuracy = 0.33438
I0416 12:32:21.203058 12023 solver.cpp:409]     Test net output #1: loss = 3.13922 (* 1 = 3.13922 loss)
I0416 12:32:21.206838 12023 solver.cpp:237] Iteration 17920000, loss = 3.29704
I0416 12:32:21.206857 12023 solver.cpp:253]     Train net output #0: loss = 2.32317 (* 1 = 2.32317 loss)
I0416 12:32:21.206866 12023 sgd_solver.cpp:106] Iteration 17920000, lr = 3.9063e-05
I0416 12:38:50.385984 12023 solver.cpp:237] Iteration 17971200, loss = 3.31611
I0416 12:38:50.386061 12023 solver.cpp:253]     Train net output #0: loss = 2.88259 (* 1 = 2.88259 loss)
I0416 12:38:50.386070 12023 sgd_solver.cpp:106] Iteration 17971200, lr = 3.9063e-05
I0416 12:45:19.629796 12023 solver.cpp:237] Iteration 18022400, loss = 3.29641
I0416 12:45:19.629864 12023 solver.cpp:253]     Train net output #0: loss = 6.43424 (* 1 = 6.43424 loss)
I0416 12:45:19.629873 12023 sgd_solver.cpp:106] Iteration 18022400, lr = 3.9063e-05
I0416 12:51:49.153944 12023 solver.cpp:237] Iteration 18073600, loss = 3.3021
I0416 12:51:49.154017 12023 solver.cpp:253]     Train net output #0: loss = 4.97334 (* 1 = 4.97334 loss)
I0416 12:51:49.154026 12023 sgd_solver.cpp:106] Iteration 18073600, lr = 3.9063e-05
I0416 12:58:18.351080 12023 solver.cpp:237] Iteration 18124800, loss = 3.28497
I0416 12:58:18.351155 12023 solver.cpp:253]     Train net output #0: loss = 6.07178 (* 1 = 6.07178 loss)
I0416 12:58:18.351163 12023 sgd_solver.cpp:106] Iteration 18124800, lr = 3.9063e-05
I0416 13:04:47.979599 12023 solver.cpp:341] Iteration 18176000, Testing net (#0)
I0416 13:05:03.248179 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0416 13:05:17.676951 12023 solver.cpp:409]     Test net output #0: accuracy = 0.3382
I0416 13:05:17.676990 12023 solver.cpp:409]     Test net output #1: loss = 3.12601 (* 1 = 3.12601 loss)
I0416 13:05:17.680927 12023 solver.cpp:237] Iteration 18176000, loss = 3.30233
I0416 13:05:17.680948 12023 solver.cpp:253]     Train net output #0: loss = 4.85008 (* 1 = 4.85008 loss)
I0416 13:05:17.680956 12023 sgd_solver.cpp:106] Iteration 18176000, lr = 3.9063e-05
I0416 13:11:46.610769 12023 solver.cpp:237] Iteration 18227200, loss = 3.28726
I0416 13:11:46.610841 12023 solver.cpp:253]     Train net output #0: loss = 0.473229 (* 1 = 0.473229 loss)
I0416 13:11:46.610848 12023 sgd_solver.cpp:106] Iteration 18227200, lr = 3.9063e-05
I0416 13:18:15.602403 12023 solver.cpp:237] Iteration 18278400, loss = 3.31702
I0416 13:18:15.602474 12023 solver.cpp:253]     Train net output #0: loss = 12.0906 (* 1 = 12.0906 loss)
I0416 13:18:15.602480 12023 sgd_solver.cpp:106] Iteration 18278400, lr = 3.9063e-05
I0416 13:24:44.613569 12023 solver.cpp:237] Iteration 18329600, loss = 3.29083
I0416 13:24:44.613629 12023 solver.cpp:253]     Train net output #0: loss = 1.38158 (* 1 = 1.38158 loss)
I0416 13:24:44.613636 12023 sgd_solver.cpp:106] Iteration 18329600, lr = 3.9063e-05
I0416 13:31:13.508754 12023 solver.cpp:237] Iteration 18380800, loss = 3.27608
I0416 13:31:13.508828 12023 solver.cpp:253]     Train net output #0: loss = 1.57331 (* 1 = 1.57331 loss)
I0416 13:31:13.508834 12023 sgd_solver.cpp:106] Iteration 18380800, lr = 3.9063e-05
I0416 13:37:42.450899 12023 solver.cpp:341] Iteration 18432000, Testing net (#0)
I0416 13:37:56.268193 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0416 13:38:08.934662 12023 solver.cpp:409]     Test net output #0: accuracy = 0.33374
I0416 13:38:08.934697 12023 solver.cpp:409]     Test net output #1: loss = 3.16707 (* 1 = 3.16707 loss)
I0416 13:38:08.938448 12023 solver.cpp:237] Iteration 18432000, loss = 3.27101
I0416 13:38:08.938469 12023 solver.cpp:253]     Train net output #0: loss = 4.97882 (* 1 = 4.97882 loss)
I0416 13:38:08.938478 12023 sgd_solver.cpp:106] Iteration 18432000, lr = 3.9063e-05
I0416 13:44:38.137069 12023 solver.cpp:237] Iteration 18483200, loss = 3.27222
I0416 13:44:38.137150 12023 solver.cpp:253]     Train net output #0: loss = 0.948078 (* 1 = 0.948078 loss)
I0416 13:44:38.137159 12023 sgd_solver.cpp:106] Iteration 18483200, lr = 3.9063e-05
I0416 13:51:07.434495 12023 solver.cpp:237] Iteration 18534400, loss = 3.28578
I0416 13:51:07.434569 12023 solver.cpp:253]     Train net output #0: loss = 2.35812 (* 1 = 2.35812 loss)
I0416 13:51:07.434578 12023 sgd_solver.cpp:106] Iteration 18534400, lr = 3.9063e-05
I0416 13:57:36.560842 12023 solver.cpp:237] Iteration 18585600, loss = 3.2885
I0416 13:57:36.560915 12023 solver.cpp:253]     Train net output #0: loss = 2.76411 (* 1 = 2.76411 loss)
I0416 13:57:36.560923 12023 sgd_solver.cpp:106] Iteration 18585600, lr = 3.9063e-05
I0416 14:04:05.482509 12023 solver.cpp:237] Iteration 18636800, loss = 3.28643
I0416 14:04:05.482584 12023 solver.cpp:253]     Train net output #0: loss = 2.8587 (* 1 = 2.8587 loss)
I0416 14:04:05.482596 12023 sgd_solver.cpp:106] Iteration 18636800, lr = 3.9063e-05
I0416 14:10:34.436735 12023 solver.cpp:341] Iteration 18688000, Testing net (#0)
I0416 14:10:48.248417 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0416 14:11:00.836988 12023 solver.cpp:409]     Test net output #0: accuracy = 0.34384
I0416 14:11:00.837021 12023 solver.cpp:409]     Test net output #1: loss = 3.11355 (* 1 = 3.11355 loss)
I0416 14:11:00.840776 12023 solver.cpp:237] Iteration 18688000, loss = 3.3006
I0416 14:11:00.840792 12023 solver.cpp:253]     Train net output #0: loss = 6.28836 (* 1 = 6.28836 loss)
I0416 14:11:00.840800 12023 sgd_solver.cpp:106] Iteration 18688000, lr = 3.9063e-05
I0416 14:17:30.204208 12023 solver.cpp:237] Iteration 18739200, loss = 3.29114
I0416 14:17:30.204282 12023 solver.cpp:253]     Train net output #0: loss = 2.57932 (* 1 = 2.57932 loss)
I0416 14:17:30.204288 12023 sgd_solver.cpp:106] Iteration 18739200, lr = 3.9063e-05
I0416 14:23:59.799881 12023 solver.cpp:237] Iteration 18790400, loss = 3.29057
I0416 14:23:59.799953 12023 solver.cpp:253]     Train net output #0: loss = 5.24034 (* 1 = 5.24034 loss)
I0416 14:23:59.799960 12023 sgd_solver.cpp:106] Iteration 18790400, lr = 3.9063e-05
I0416 14:30:31.579085 12023 solver.cpp:237] Iteration 18841600, loss = 3.26874
I0416 14:30:31.579133 12023 solver.cpp:253]     Train net output #0: loss = 2.01102 (* 1 = 2.01102 loss)
I0416 14:30:31.579139 12023 sgd_solver.cpp:106] Iteration 18841600, lr = 3.9063e-05
I0416 14:37:06.054169 12023 solver.cpp:237] Iteration 18892800, loss = 3.26931
I0416 14:37:06.054219 12023 solver.cpp:253]     Train net output #0: loss = 3.43683 (* 1 = 3.43683 loss)
I0416 14:37:06.054224 12023 sgd_solver.cpp:106] Iteration 18892800, lr = 3.9063e-05
I0416 14:43:46.377580 12023 solver.cpp:341] Iteration 18944000, Testing net (#0)
I0416 14:43:58.948876 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0416 14:44:12.947046 12023 solver.cpp:409]     Test net output #0: accuracy = 0.33668
I0416 14:44:12.947079 12023 solver.cpp:409]     Test net output #1: loss = 3.13668 (* 1 = 3.13668 loss)
I0416 14:44:12.950834 12023 solver.cpp:237] Iteration 18944000, loss = 3.26232
I0416 14:44:12.950853 12023 solver.cpp:253]     Train net output #0: loss = 2.80331 (* 1 = 2.80331 loss)
I0416 14:44:12.950862 12023 sgd_solver.cpp:106] Iteration 18944000, lr = 3.9063e-05
I0416 14:50:47.940839 12023 solver.cpp:237] Iteration 18995200, loss = 3.25905
I0416 14:50:47.940888 12023 solver.cpp:253]     Train net output #0: loss = 4.43002 (* 1 = 4.43002 loss)
I0416 14:50:47.940897 12023 sgd_solver.cpp:106] Iteration 18995200, lr = 3.9063e-05
I0416 14:57:18.108394 12023 solver.cpp:237] Iteration 19046400, loss = 3.26894
I0416 14:57:18.108465 12023 solver.cpp:253]     Train net output #0: loss = 4.19543 (* 1 = 4.19543 loss)
I0416 14:57:18.108472 12023 sgd_solver.cpp:106] Iteration 19046400, lr = 3.9063e-05
I0416 15:03:47.277400 12023 solver.cpp:237] Iteration 19097600, loss = 3.27971
I0416 15:03:47.277487 12023 solver.cpp:253]     Train net output #0: loss = 1.25115 (* 1 = 1.25115 loss)
I0416 15:03:47.277493 12023 sgd_solver.cpp:106] Iteration 19097600, lr = 3.9063e-05
I0416 15:10:16.452491 12023 solver.cpp:237] Iteration 19148800, loss = 3.25105
I0416 15:10:16.452561 12023 solver.cpp:253]     Train net output #0: loss = 3.24115 (* 1 = 3.24115 loss)
I0416 15:10:16.452567 12023 sgd_solver.cpp:106] Iteration 19148800, lr = 3.9063e-05
I0416 15:16:45.745122 12023 solver.cpp:341] Iteration 19200000, Testing net (#0)
I0416 15:16:57.475638 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0416 15:17:12.175581 12023 solver.cpp:409]     Test net output #0: accuracy = 0.3409
I0416 15:17:12.175614 12023 solver.cpp:409]     Test net output #1: loss = 3.12405 (* 1 = 3.12405 loss)
I0416 15:17:12.179396 12023 solver.cpp:237] Iteration 19200000, loss = 3.27497
I0416 15:17:12.179416 12023 solver.cpp:253]     Train net output #0: loss = 3.92631 (* 1 = 3.92631 loss)
I0416 15:17:12.179424 12023 sgd_solver.cpp:106] Iteration 19200000, lr = 3.9063e-05
I0416 15:23:41.277396 12023 solver.cpp:237] Iteration 19251200, loss = 3.28716
I0416 15:23:41.277467 12023 solver.cpp:253]     Train net output #0: loss = 2.10626 (* 1 = 2.10626 loss)
I0416 15:23:41.277472 12023 sgd_solver.cpp:106] Iteration 19251200, lr = 3.9063e-05
I0416 15:30:10.291004 12023 solver.cpp:237] Iteration 19302400, loss = 3.27499
I0416 15:30:10.291074 12023 solver.cpp:253]     Train net output #0: loss = 7.04417 (* 1 = 7.04417 loss)
I0416 15:30:10.291079 12023 sgd_solver.cpp:106] Iteration 19302400, lr = 3.9063e-05
I0416 15:36:39.473561 12023 solver.cpp:237] Iteration 19353600, loss = 3.28269
I0416 15:36:39.473631 12023 solver.cpp:253]     Train net output #0: loss = 3.37214 (* 1 = 3.37214 loss)
I0416 15:36:39.473637 12023 sgd_solver.cpp:106] Iteration 19353600, lr = 3.9063e-05
I0416 15:43:08.581153 12023 solver.cpp:237] Iteration 19404800, loss = 3.27267
I0416 15:43:08.581208 12023 solver.cpp:253]     Train net output #0: loss = 4.80382 (* 1 = 4.80382 loss)
I0416 15:43:08.581214 12023 sgd_solver.cpp:106] Iteration 19404800, lr = 3.9063e-05
I0416 15:49:38.000802 12023 solver.cpp:341] Iteration 19456000, Testing net (#0)
I0416 15:49:49.735484 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0416 15:50:04.478993 12023 solver.cpp:409]     Test net output #0: accuracy = 0.33832
I0416 15:50:04.479027 12023 solver.cpp:409]     Test net output #1: loss = 3.10386 (* 1 = 3.10386 loss)
I0416 15:50:04.482774 12023 solver.cpp:237] Iteration 19456000, loss = 3.27541
I0416 15:50:04.482791 12023 solver.cpp:253]     Train net output #0: loss = 2.33946 (* 1 = 2.33946 loss)
I0416 15:50:04.482798 12023 sgd_solver.cpp:106] Iteration 19456000, lr = 3.9063e-05
I0416 15:56:33.554364 12023 solver.cpp:237] Iteration 19507200, loss = 3.26263
I0416 15:56:33.554431 12023 solver.cpp:253]     Train net output #0: loss = 2.59489 (* 1 = 2.59489 loss)
I0416 15:56:33.554436 12023 sgd_solver.cpp:106] Iteration 19507200, lr = 3.9063e-05
I0416 16:03:02.440556 12023 solver.cpp:237] Iteration 19558400, loss = 3.29523
I0416 16:03:02.440611 12023 solver.cpp:253]     Train net output #0: loss = 0.607011 (* 1 = 0.607011 loss)
I0416 16:03:02.440618 12023 sgd_solver.cpp:106] Iteration 19558400, lr = 3.9063e-05
I0416 16:09:31.378340 12023 solver.cpp:237] Iteration 19609600, loss = 3.26498
I0416 16:09:31.378409 12023 solver.cpp:253]     Train net output #0: loss = 5.80196 (* 1 = 5.80196 loss)
I0416 16:09:31.378415 12023 sgd_solver.cpp:106] Iteration 19609600, lr = 3.9063e-05
I0416 16:16:00.352480 12023 solver.cpp:237] Iteration 19660800, loss = 3.2593
I0416 16:16:00.352552 12023 solver.cpp:253]     Train net output #0: loss = 0.554468 (* 1 = 0.554468 loss)
I0416 16:16:00.352557 12023 sgd_solver.cpp:106] Iteration 19660800, lr = 3.9063e-05
I0416 16:22:29.434473 12023 solver.cpp:341] Iteration 19712000, Testing net (#0)
I0416 16:22:41.250535 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0416 16:22:55.930750 12023 solver.cpp:409]     Test net output #0: accuracy = 0.34478
I0416 16:22:55.930783 12023 solver.cpp:409]     Test net output #1: loss = 3.09092 (* 1 = 3.09092 loss)
I0416 16:22:55.934520 12023 solver.cpp:237] Iteration 19712000, loss = 3.24068
I0416 16:22:55.934538 12023 solver.cpp:253]     Train net output #0: loss = 0.537841 (* 1 = 0.537841 loss)
I0416 16:22:55.934545 12023 sgd_solver.cpp:106] Iteration 19712000, lr = 3.9063e-05
I0416 16:29:25.079825 12023 solver.cpp:237] Iteration 19763200, loss = 3.25316
I0416 16:29:25.079919 12023 solver.cpp:253]     Train net output #0: loss = 3.384 (* 1 = 3.384 loss)
I0416 16:29:25.079931 12023 sgd_solver.cpp:106] Iteration 19763200, lr = 3.9063e-05
I0416 16:35:54.160411 12023 solver.cpp:237] Iteration 19814400, loss = 3.26099
I0416 16:35:54.160493 12023 solver.cpp:253]     Train net output #0: loss = 2.06615 (* 1 = 2.06615 loss)
I0416 16:35:54.160501 12023 sgd_solver.cpp:106] Iteration 19814400, lr = 3.9063e-05
I0416 16:42:23.368880 12023 solver.cpp:237] Iteration 19865600, loss = 3.26023
I0416 16:42:23.368939 12023 solver.cpp:253]     Train net output #0: loss = 3.54823 (* 1 = 3.54823 loss)
I0416 16:42:23.368945 12023 sgd_solver.cpp:106] Iteration 19865600, lr = 3.9063e-05
I0416 16:48:52.647511 12023 solver.cpp:237] Iteration 19916800, loss = 3.2605
I0416 16:48:52.647580 12023 solver.cpp:253]     Train net output #0: loss = 3.48258 (* 1 = 3.48258 loss)
I0416 16:48:52.647588 12023 sgd_solver.cpp:106] Iteration 19916800, lr = 3.9063e-05
I0416 16:55:21.944459 12023 solver.cpp:341] Iteration 19968000, Testing net (#0)
I0416 16:55:33.819146 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0416 16:55:48.474261 12023 solver.cpp:409]     Test net output #0: accuracy = 0.33814
I0416 16:55:48.474293 12023 solver.cpp:409]     Test net output #1: loss = 3.1198 (* 1 = 3.1198 loss)
I0416 16:55:48.478061 12023 solver.cpp:237] Iteration 19968000, loss = 3.27199
I0416 16:55:48.478082 12023 solver.cpp:253]     Train net output #0: loss = 5.14769 (* 1 = 5.14769 loss)
I0416 16:55:48.478093 12023 sgd_solver.cpp:106] Iteration 19968000, lr = 3.9063e-05
I0416 17:02:18.211072 12023 solver.cpp:237] Iteration 20019200, loss = 3.27508
I0416 17:02:18.211138 12023 solver.cpp:253]     Train net output #0: loss = 1.35385 (* 1 = 1.35385 loss)
I0416 17:02:18.211150 12023 sgd_solver.cpp:106] Iteration 20019200, lr = 3.9063e-05
I0416 17:08:48.159167 12023 solver.cpp:237] Iteration 20070400, loss = 3.26606
I0416 17:08:48.159229 12023 solver.cpp:253]     Train net output #0: loss = 0.355483 (* 1 = 0.355483 loss)
I0416 17:08:48.159236 12023 sgd_solver.cpp:106] Iteration 20070400, lr = 3.9063e-05
I0416 17:15:17.485334 12023 solver.cpp:237] Iteration 20121600, loss = 3.25292
I0416 17:15:17.485397 12023 solver.cpp:253]     Train net output #0: loss = 2.70508 (* 1 = 2.70508 loss)
I0416 17:15:17.485404 12023 sgd_solver.cpp:106] Iteration 20121600, lr = 3.9063e-05
I0416 17:21:46.555315 12023 solver.cpp:237] Iteration 20172800, loss = 3.26187
I0416 17:21:46.555376 12023 solver.cpp:253]     Train net output #0: loss = 5.92739 (* 1 = 5.92739 loss)
I0416 17:21:46.555382 12023 sgd_solver.cpp:106] Iteration 20172800, lr = 3.9063e-05
I0416 17:28:20.835472 12023 solver.cpp:341] Iteration 20224000, Testing net (#0)
I0416 17:28:31.438925 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0416 17:28:47.182274 12023 solver.cpp:409]     Test net output #0: accuracy = 0.34126
I0416 17:28:47.182308 12023 solver.cpp:409]     Test net output #1: loss = 3.09133 (* 1 = 3.09133 loss)
I0416 17:28:47.186064 12023 solver.cpp:237] Iteration 20224000, loss = 3.23915
I0416 17:28:47.186084 12023 solver.cpp:253]     Train net output #0: loss = 3.81235 (* 1 = 3.81235 loss)
I0416 17:28:47.186094 12023 sgd_solver.cpp:106] Iteration 20224000, lr = 3.9063e-05
I0416 17:35:19.700989 12023 solver.cpp:237] Iteration 20275200, loss = 3.23688
I0416 17:35:19.701041 12023 solver.cpp:253]     Train net output #0: loss = 4.63502 (* 1 = 4.63502 loss)
I0416 17:35:19.701047 12023 sgd_solver.cpp:106] Iteration 20275200, lr = 3.9063e-05
I0416 17:41:50.232786 12023 solver.cpp:237] Iteration 20326400, loss = 3.24029
I0416 17:41:50.232883 12023 solver.cpp:253]     Train net output #0: loss = 0.314754 (* 1 = 0.314754 loss)
I0416 17:41:50.232894 12023 sgd_solver.cpp:106] Iteration 20326400, lr = 3.9063e-05
I0416 17:48:19.228400 12023 solver.cpp:237] Iteration 20377600, loss = 3.24753
I0416 17:48:19.228476 12023 solver.cpp:253]     Train net output #0: loss = 0.140991 (* 1 = 0.140991 loss)
I0416 17:48:19.228488 12023 sgd_solver.cpp:106] Iteration 20377600, lr = 3.9063e-05
I0416 17:54:48.147822 12023 solver.cpp:237] Iteration 20428800, loss = 3.23709
I0416 17:54:48.147894 12023 solver.cpp:253]     Train net output #0: loss = 4.15737 (* 1 = 4.15737 loss)
I0416 17:54:48.147903 12023 sgd_solver.cpp:106] Iteration 20428800, lr = 3.9063e-05
I0416 18:01:17.169347 12023 solver.cpp:459] Snapshotting to binary proto file snapshots/caffenet128_no_lrn_lsuv_relu_bs1_iter_20480000.caffemodel
I0416 18:01:18.131244 12023 sgd_solver.cpp:269] Snapshotting solver state to binary proto file snapshots/caffenet128_no_lrn_lsuv_relu_bs1_iter_20480000.solverstate
I0416 18:01:18.190481 12023 solver.cpp:341] Iteration 20480000, Testing net (#0)
I0416 18:01:27.976649 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0416 18:01:44.568413 12023 solver.cpp:409]     Test net output #0: accuracy = 0.34498
I0416 18:01:44.568446 12023 solver.cpp:409]     Test net output #1: loss = 3.07789 (* 1 = 3.07789 loss)
I0416 18:01:44.572199 12023 solver.cpp:237] Iteration 20480000, loss = 3.25849
I0416 18:01:44.572222 12023 solver.cpp:253]     Train net output #0: loss = 0.000232545 (* 1 = 0.000232545 loss)
I0416 18:01:44.572230 12023 sgd_solver.cpp:106] Iteration 20480000, lr = 3.9063e-05
I0416 18:08:13.743757 12023 solver.cpp:237] Iteration 20531200, loss = 3.27819
I0416 18:08:13.743831 12023 solver.cpp:253]     Train net output #0: loss = 5.46057 (* 1 = 5.46057 loss)
I0416 18:08:13.743837 12023 sgd_solver.cpp:106] Iteration 20531200, lr = 3.9063e-05
I0416 18:14:42.689956 12023 solver.cpp:237] Iteration 20582400, loss = 3.24421
I0416 18:14:42.690018 12023 solver.cpp:253]     Train net output #0: loss = 3.88088 (* 1 = 3.88088 loss)
I0416 18:14:42.690032 12023 sgd_solver.cpp:106] Iteration 20582400, lr = 3.9063e-05
I0416 18:21:11.624843 12023 solver.cpp:237] Iteration 20633600, loss = 3.2558
I0416 18:21:11.624913 12023 solver.cpp:253]     Train net output #0: loss = 4.09625 (* 1 = 4.09625 loss)
I0416 18:21:11.624918 12023 sgd_solver.cpp:106] Iteration 20633600, lr = 3.9063e-05
I0416 18:27:41.191002 12023 solver.cpp:237] Iteration 20684800, loss = 3.25482
I0416 18:27:41.191057 12023 solver.cpp:253]     Train net output #0: loss = 0.162446 (* 1 = 0.162446 loss)
I0416 18:27:41.191066 12023 sgd_solver.cpp:106] Iteration 20684800, lr = 3.9063e-05
I0416 18:34:12.552767 12023 solver.cpp:341] Iteration 20736000, Testing net (#0)
I0416 18:34:22.320533 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0416 18:34:38.971001 12023 solver.cpp:409]     Test net output #0: accuracy = 0.34174
I0416 18:34:38.971037 12023 solver.cpp:409]     Test net output #1: loss = 3.09068 (* 1 = 3.09068 loss)
I0416 18:34:38.974831 12023 solver.cpp:237] Iteration 20736000, loss = 3.24872
I0416 18:34:38.974853 12023 solver.cpp:253]     Train net output #0: loss = 5.97586 (* 1 = 5.97586 loss)
I0416 18:34:38.974863 12023 sgd_solver.cpp:106] Iteration 20736000, lr = 3.9063e-05
I0416 18:41:08.349488 12023 solver.cpp:237] Iteration 20787200, loss = 3.24262
I0416 18:41:08.349548 12023 solver.cpp:253]     Train net output #0: loss = 1.498 (* 1 = 1.498 loss)
I0416 18:41:08.349556 12023 sgd_solver.cpp:106] Iteration 20787200, lr = 3.9063e-05
I0416 18:47:37.509358 12023 solver.cpp:237] Iteration 20838400, loss = 3.2794
I0416 18:47:37.509429 12023 solver.cpp:253]     Train net output #0: loss = 3.30814 (* 1 = 3.30814 loss)
I0416 18:47:37.509438 12023 sgd_solver.cpp:106] Iteration 20838400, lr = 3.9063e-05
I0416 18:54:06.637300 12023 solver.cpp:237] Iteration 20889600, loss = 3.24619
I0416 18:54:06.637373 12023 solver.cpp:253]     Train net output #0: loss = 0.921127 (* 1 = 0.921127 loss)
I0416 18:54:06.637387 12023 sgd_solver.cpp:106] Iteration 20889600, lr = 3.9063e-05
I0416 19:00:35.737102 12023 solver.cpp:237] Iteration 20940800, loss = 3.24874
I0416 19:00:35.737195 12023 solver.cpp:253]     Train net output #0: loss = 6.15403 (* 1 = 6.15403 loss)
I0416 19:00:35.737205 12023 sgd_solver.cpp:106] Iteration 20940800, lr = 3.9063e-05
I0416 19:07:04.921653 12023 solver.cpp:341] Iteration 20992000, Testing net (#0)
I0416 19:07:14.739919 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0416 19:07:31.413583 12023 solver.cpp:409]     Test net output #0: accuracy = 0.34404
I0416 19:07:31.413619 12023 solver.cpp:409]     Test net output #1: loss = 3.08782 (* 1 = 3.08782 loss)
I0416 19:07:31.417407 12023 solver.cpp:237] Iteration 20992000, loss = 3.22885
I0416 19:07:31.417428 12023 solver.cpp:253]     Train net output #0: loss = 4.27609 (* 1 = 4.27609 loss)
I0416 19:07:31.417438 12023 sgd_solver.cpp:106] Iteration 20992000, lr = 3.9063e-05
I0416 19:14:00.707384 12023 solver.cpp:237] Iteration 21043200, loss = 3.24411
I0416 19:14:00.707445 12023 solver.cpp:253]     Train net output #0: loss = 1.70722 (* 1 = 1.70722 loss)
I0416 19:14:00.707456 12023 sgd_solver.cpp:106] Iteration 21043200, lr = 3.9063e-05
I0416 19:20:30.079409 12023 solver.cpp:237] Iteration 21094400, loss = 3.24598
I0416 19:20:30.079478 12023 solver.cpp:253]     Train net output #0: loss = 5.63309 (* 1 = 5.63309 loss)
I0416 19:20:30.079485 12023 sgd_solver.cpp:106] Iteration 21094400, lr = 3.9063e-05
I0416 19:26:59.185714 12023 solver.cpp:237] Iteration 21145600, loss = 3.23936
I0416 19:26:59.185783 12023 solver.cpp:253]     Train net output #0: loss = 0.000747424 (* 1 = 0.000747424 loss)
I0416 19:26:59.185789 12023 sgd_solver.cpp:106] Iteration 21145600, lr = 3.9063e-05
I0416 19:33:28.377593 12023 solver.cpp:237] Iteration 21196800, loss = 3.24541
I0416 19:33:28.377648 12023 solver.cpp:253]     Train net output #0: loss = 4.75563 (* 1 = 4.75563 loss)
I0416 19:33:28.377655 12023 sgd_solver.cpp:106] Iteration 21196800, lr = 3.9063e-05
I0416 19:39:57.484630 12023 solver.cpp:341] Iteration 21248000, Testing net (#0)
I0416 19:40:07.402760 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0416 19:40:24.145895 12023 solver.cpp:409]     Test net output #0: accuracy = 0.339599
I0416 19:40:24.145931 12023 solver.cpp:409]     Test net output #1: loss = 3.11462 (* 1 = 3.11462 loss)
I0416 19:40:24.149723 12023 solver.cpp:237] Iteration 21248000, loss = 3.26307
I0416 19:40:24.149744 12023 solver.cpp:253]     Train net output #0: loss = 3.68875 (* 1 = 3.68875 loss)
I0416 19:40:24.149754 12023 sgd_solver.cpp:106] Iteration 21248000, lr = 3.9063e-05
I0416 19:46:54.017974 12023 solver.cpp:237] Iteration 21299200, loss = 3.25484
I0416 19:46:54.018045 12023 solver.cpp:253]     Train net output #0: loss = 0.551605 (* 1 = 0.551605 loss)
I0416 19:46:54.018051 12023 sgd_solver.cpp:106] Iteration 21299200, lr = 3.9063e-05
I0416 19:53:24.672961 12023 solver.cpp:237] Iteration 21350400, loss = 3.25326
I0416 19:53:24.673030 12023 solver.cpp:253]     Train net output #0: loss = 4.91711 (* 1 = 4.91711 loss)
I0416 19:53:24.673037 12023 sgd_solver.cpp:106] Iteration 21350400, lr = 3.9063e-05
I0416 19:59:54.533761 12023 solver.cpp:237] Iteration 21401600, loss = 3.22523
I0416 19:59:54.533812 12023 solver.cpp:253]     Train net output #0: loss = 5.18786 (* 1 = 5.18786 loss)
I0416 19:59:54.533818 12023 sgd_solver.cpp:106] Iteration 21401600, lr = 3.9063e-05
I0416 20:06:24.402323 12023 solver.cpp:237] Iteration 21452800, loss = 3.23746
I0416 20:06:24.402384 12023 solver.cpp:253]     Train net output #0: loss = 4.77902 (* 1 = 4.77902 loss)
I0416 20:06:24.402389 12023 sgd_solver.cpp:106] Iteration 21452800, lr = 3.9063e-05
I0416 20:13:00.502286 12023 solver.cpp:341] Iteration 21504000, Testing net (#0)
I0416 20:13:08.979893 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0416 20:13:26.890961 12023 solver.cpp:409]     Test net output #0: accuracy = 0.3437
I0416 20:13:26.890995 12023 solver.cpp:409]     Test net output #1: loss = 3.08749 (* 1 = 3.08749 loss)
I0416 20:13:26.894744 12023 solver.cpp:237] Iteration 21504000, loss = 3.2283
I0416 20:13:26.894765 12023 solver.cpp:253]     Train net output #0: loss = 1.87191 (* 1 = 1.87191 loss)
I0416 20:13:26.894774 12023 sgd_solver.cpp:106] Iteration 21504000, lr = 3.9063e-05
I0416 20:20:00.684293 12023 solver.cpp:237] Iteration 21555200, loss = 3.22818
I0416 20:20:00.684398 12023 solver.cpp:253]     Train net output #0: loss = 1.00048 (* 1 = 1.00048 loss)
I0416 20:20:00.684407 12023 sgd_solver.cpp:106] Iteration 21555200, lr = 3.9063e-05
I0416 20:26:31.906663 12023 solver.cpp:237] Iteration 21606400, loss = 3.22786
I0416 20:26:31.906726 12023 solver.cpp:253]     Train net output #0: loss = 3.58278 (* 1 = 3.58278 loss)
I0416 20:26:31.906733 12023 sgd_solver.cpp:106] Iteration 21606400, lr = 3.9063e-05
I0416 20:33:01.674304 12023 solver.cpp:237] Iteration 21657600, loss = 3.24034
I0416 20:33:01.674376 12023 solver.cpp:253]     Train net output #0: loss = 2.07003 (* 1 = 2.07003 loss)
I0416 20:33:01.674381 12023 sgd_solver.cpp:106] Iteration 21657600, lr = 3.9063e-05
I0416 20:39:31.386760 12023 solver.cpp:237] Iteration 21708800, loss = 3.2226
I0416 20:39:31.386832 12023 solver.cpp:253]     Train net output #0: loss = 6.12958 (* 1 = 6.12958 loss)
I0416 20:39:31.386838 12023 sgd_solver.cpp:106] Iteration 21708800, lr = 3.9063e-05
I0416 20:46:01.139302 12023 solver.cpp:341] Iteration 21760000, Testing net (#0)
I0416 20:46:08.739151 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0416 20:46:27.582852 12023 solver.cpp:409]     Test net output #0: accuracy = 0.346
I0416 20:46:27.582888 12023 solver.cpp:409]     Test net output #1: loss = 3.07095 (* 1 = 3.07095 loss)
I0416 20:46:27.586658 12023 solver.cpp:237] Iteration 21760000, loss = 3.23067
I0416 20:46:27.586699 12023 solver.cpp:253]     Train net output #0: loss = 4.51638 (* 1 = 4.51638 loss)
I0416 20:46:27.586710 12023 sgd_solver.cpp:106] Iteration 21760000, lr = 3.9063e-05
I0416 20:52:57.460132 12023 solver.cpp:237] Iteration 21811200, loss = 3.25668
I0416 20:52:57.460202 12023 solver.cpp:253]     Train net output #0: loss = 1.85478 (* 1 = 1.85478 loss)
I0416 20:52:57.460208 12023 sgd_solver.cpp:106] Iteration 21811200, lr = 3.9063e-05
I0416 20:59:27.180434 12023 solver.cpp:237] Iteration 21862400, loss = 3.23298
I0416 20:59:27.180503 12023 solver.cpp:253]     Train net output #0: loss = 5.10155 (* 1 = 5.10155 loss)
I0416 20:59:27.180510 12023 sgd_solver.cpp:106] Iteration 21862400, lr = 3.9063e-05
I0416 21:05:56.914077 12023 solver.cpp:237] Iteration 21913600, loss = 3.2399
I0416 21:05:56.914149 12023 solver.cpp:253]     Train net output #0: loss = 0.0833526 (* 1 = 0.0833526 loss)
I0416 21:05:56.914155 12023 sgd_solver.cpp:106] Iteration 21913600, lr = 3.9063e-05
I0416 21:12:26.665426 12023 solver.cpp:237] Iteration 21964800, loss = 3.23336
I0416 21:12:26.665498 12023 solver.cpp:253]     Train net output #0: loss = 2.51934 (* 1 = 2.51934 loss)
I0416 21:12:26.665503 12023 sgd_solver.cpp:106] Iteration 21964800, lr = 3.9063e-05
I0416 21:18:56.775449 12023 solver.cpp:341] Iteration 22016000, Testing net (#0)
I0416 21:19:04.396973 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0416 21:19:23.220752 12023 solver.cpp:409]     Test net output #0: accuracy = 0.34294
I0416 21:19:23.220788 12023 solver.cpp:409]     Test net output #1: loss = 3.10079 (* 1 = 3.10079 loss)
I0416 21:19:23.224565 12023 solver.cpp:237] Iteration 22016000, loss = 3.23345
I0416 21:19:23.224586 12023 solver.cpp:253]     Train net output #0: loss = 0.257643 (* 1 = 0.257643 loss)
I0416 21:19:23.224596 12023 sgd_solver.cpp:106] Iteration 22016000, lr = 3.9063e-05
I0416 21:25:56.620436 12023 solver.cpp:237] Iteration 22067200, loss = 3.23035
I0416 21:25:56.620508 12023 solver.cpp:253]     Train net output #0: loss = 7.27902 (* 1 = 7.27902 loss)
I0416 21:25:56.620515 12023 sgd_solver.cpp:106] Iteration 22067200, lr = 3.9063e-05
I0416 21:32:27.399436 12023 solver.cpp:237] Iteration 22118400, loss = 3.25882
I0416 21:32:27.399520 12023 solver.cpp:253]     Train net output #0: loss = 0.510288 (* 1 = 0.510288 loss)
I0416 21:32:27.399528 12023 sgd_solver.cpp:106] Iteration 22118400, lr = 3.9063e-05
I0416 21:38:58.349459 12023 solver.cpp:237] Iteration 22169600, loss = 3.23386
I0416 21:38:58.349522 12023 solver.cpp:253]     Train net output #0: loss = 2.76319 (* 1 = 2.76319 loss)
I0416 21:38:58.349527 12023 sgd_solver.cpp:106] Iteration 22169600, lr = 3.9063e-05
I0416 21:45:29.179298 12023 solver.cpp:237] Iteration 22220800, loss = 3.22808
I0416 21:45:29.179373 12023 solver.cpp:253]     Train net output #0: loss = 4.12258 (* 1 = 4.12258 loss)
I0416 21:45:29.179378 12023 sgd_solver.cpp:106] Iteration 22220800, lr = 3.9063e-05
I0416 21:51:59.521594 12023 solver.cpp:341] Iteration 22272000, Testing net (#0)
I0416 21:52:07.266672 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0416 21:52:26.140460 12023 solver.cpp:409]     Test net output #0: accuracy = 0.3476
I0416 21:52:26.140530 12023 solver.cpp:409]     Test net output #1: loss = 3.06862 (* 1 = 3.06862 loss)
I0416 21:52:26.144322 12023 solver.cpp:237] Iteration 22272000, loss = 3.21057
I0416 21:52:26.144345 12023 solver.cpp:253]     Train net output #0: loss = 0.522926 (* 1 = 0.522926 loss)
I0416 21:52:26.144353 12023 sgd_solver.cpp:106] Iteration 22272000, lr = 3.9063e-05
I0416 21:58:57.385954 12023 solver.cpp:237] Iteration 22323200, loss = 3.21806
I0416 21:58:57.386026 12023 solver.cpp:253]     Train net output #0: loss = 1.68156 (* 1 = 1.68156 loss)
I0416 21:58:57.386040 12023 sgd_solver.cpp:106] Iteration 22323200, lr = 3.9063e-05
I0416 22:05:29.279273 12023 solver.cpp:237] Iteration 22374400, loss = 3.23102
I0416 22:05:29.279340 12023 solver.cpp:253]     Train net output #0: loss = 4.1264 (* 1 = 4.1264 loss)
I0416 22:05:29.279347 12023 sgd_solver.cpp:106] Iteration 22374400, lr = 3.9063e-05
I0416 22:12:00.977407 12023 solver.cpp:237] Iteration 22425600, loss = 3.2235
I0416 22:12:00.977483 12023 solver.cpp:253]     Train net output #0: loss = 5.6883 (* 1 = 5.6883 loss)
I0416 22:12:00.977494 12023 sgd_solver.cpp:106] Iteration 22425600, lr = 3.9063e-05
I0416 22:18:32.737256 12023 solver.cpp:237] Iteration 22476800, loss = 3.22877
I0416 22:18:32.737318 12023 solver.cpp:253]     Train net output #0: loss = 0.498054 (* 1 = 0.498054 loss)
I0416 22:18:32.737329 12023 sgd_solver.cpp:106] Iteration 22476800, lr = 3.9063e-05
I0416 22:25:04.474586 12023 solver.cpp:341] Iteration 22528000, Testing net (#0)
I0416 22:25:12.141474 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0416 22:25:30.972196 12023 solver.cpp:409]     Test net output #0: accuracy = 0.35404
I0416 22:25:30.972232 12023 solver.cpp:409]     Test net output #1: loss = 3.03671 (* 1 = 3.03671 loss)
I0416 22:25:30.976006 12023 solver.cpp:237] Iteration 22528000, loss = 3.2498
I0416 22:25:30.976027 12023 solver.cpp:253]     Train net output #0: loss = 2.79103 (* 1 = 2.79103 loss)
I0416 22:25:30.976037 12023 sgd_solver.cpp:106] Iteration 22528000, lr = 3.9063e-05
I0416 22:32:03.330148 12023 solver.cpp:237] Iteration 22579200, loss = 3.22853
I0416 22:32:03.330227 12023 solver.cpp:253]     Train net output #0: loss = 0.769413 (* 1 = 0.769413 loss)
I0416 22:32:03.330235 12023 sgd_solver.cpp:106] Iteration 22579200, lr = 3.9063e-05
I0416 22:38:37.759758 12023 solver.cpp:237] Iteration 22630400, loss = 3.23382
I0416 22:38:37.759829 12023 solver.cpp:253]     Train net output #0: loss = 1.04544 (* 1 = 1.04544 loss)
I0416 22:38:37.759834 12023 sgd_solver.cpp:106] Iteration 22630400, lr = 3.9063e-05
I0416 22:45:09.424069 12023 solver.cpp:237] Iteration 22681600, loss = 3.22087
I0416 22:45:09.424123 12023 solver.cpp:253]     Train net output #0: loss = 3.56176 (* 1 = 3.56176 loss)
I0416 22:45:09.424129 12023 sgd_solver.cpp:106] Iteration 22681600, lr = 3.9063e-05
I0416 22:51:38.875130 12023 solver.cpp:237] Iteration 22732800, loss = 3.21966
I0416 22:51:38.875181 12023 solver.cpp:253]     Train net output #0: loss = 9.7947 (* 1 = 9.7947 loss)
I0416 22:51:38.875187 12023 sgd_solver.cpp:106] Iteration 22732800, lr = 3.9063e-05
I0416 22:58:14.211725 12023 solver.cpp:341] Iteration 22784000, Testing net (#0)
I0416 22:58:20.508040 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0416 22:58:40.633956 12023 solver.cpp:409]     Test net output #0: accuracy = 0.34578
I0416 22:58:40.633990 12023 solver.cpp:409]     Test net output #1: loss = 3.06626 (* 1 = 3.06626 loss)
I0416 22:58:40.637739 12023 solver.cpp:237] Iteration 22784000, loss = 3.21043
I0416 22:58:40.637759 12023 solver.cpp:253]     Train net output #0: loss = 0.492185 (* 1 = 0.492185 loss)
I0416 22:58:40.637766 12023 sgd_solver.cpp:106] Iteration 22784000, lr = 3.9063e-05
I0416 23:05:14.205706 12023 solver.cpp:237] Iteration 22835200, loss = 3.21601
I0416 23:05:14.205768 12023 solver.cpp:253]     Train net output #0: loss = 6.81559 (* 1 = 6.81559 loss)
I0416 23:05:14.205775 12023 sgd_solver.cpp:106] Iteration 22835200, lr = 3.9063e-05
I0416 23:11:44.871281 12023 solver.cpp:237] Iteration 22886400, loss = 3.21211
I0416 23:11:44.871342 12023 solver.cpp:253]     Train net output #0: loss = 0.573396 (* 1 = 0.573396 loss)
I0416 23:11:44.871351 12023 sgd_solver.cpp:106] Iteration 22886400, lr = 3.9063e-05
I0416 23:18:13.837851 12023 solver.cpp:237] Iteration 22937600, loss = 3.21892
I0416 23:18:13.837927 12023 solver.cpp:253]     Train net output #0: loss = 0.0294301 (* 1 = 0.0294301 loss)
I0416 23:18:13.837940 12023 sgd_solver.cpp:106] Iteration 22937600, lr = 3.9063e-05
I0416 23:24:42.786821 12023 solver.cpp:237] Iteration 22988800, loss = 3.21157
I0416 23:24:42.786896 12023 solver.cpp:253]     Train net output #0: loss = 7.68805 (* 1 = 7.68805 loss)
I0416 23:24:42.786905 12023 sgd_solver.cpp:106] Iteration 22988800, lr = 3.9063e-05
I0416 23:31:11.727756 12023 solver.cpp:459] Snapshotting to binary proto file snapshots/caffenet128_no_lrn_lsuv_relu_bs1_iter_23040000.caffemodel
I0416 23:31:13.089709 12023 sgd_solver.cpp:269] Snapshotting solver state to binary proto file snapshots/caffenet128_no_lrn_lsuv_relu_bs1_iter_23040000.solverstate
I0416 23:31:13.146853 12023 solver.cpp:341] Iteration 23040000, Testing net (#0)
I0416 23:31:18.431968 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0416 23:31:39.536124 12023 solver.cpp:409]     Test net output #0: accuracy = 0.34896
I0416 23:31:39.536160 12023 solver.cpp:409]     Test net output #1: loss = 3.06777 (* 1 = 3.06777 loss)
I0416 23:31:39.539928 12023 solver.cpp:237] Iteration 23040000, loss = 3.22552
I0416 23:31:39.539968 12023 solver.cpp:253]     Train net output #0: loss = 1.1557 (* 1 = 1.1557 loss)
I0416 23:31:39.539979 12023 sgd_solver.cpp:106] Iteration 23040000, lr = 3.9063e-05
I0416 23:38:08.647101 12023 solver.cpp:237] Iteration 23091200, loss = 3.2452
I0416 23:38:08.647176 12023 solver.cpp:253]     Train net output #0: loss = 1.92647 (* 1 = 1.92647 loss)
I0416 23:38:08.647183 12023 sgd_solver.cpp:106] Iteration 23091200, lr = 3.9063e-05
I0416 23:44:37.610213 12023 solver.cpp:237] Iteration 23142400, loss = 3.20993
I0416 23:44:37.610285 12023 solver.cpp:253]     Train net output #0: loss = 3.05759 (* 1 = 3.05759 loss)
I0416 23:44:37.610290 12023 sgd_solver.cpp:106] Iteration 23142400, lr = 3.9063e-05
I0416 23:51:06.578312 12023 solver.cpp:237] Iteration 23193600, loss = 3.21693
I0416 23:51:06.578362 12023 solver.cpp:253]     Train net output #0: loss = 0.146002 (* 1 = 0.146002 loss)
I0416 23:51:06.578368 12023 sgd_solver.cpp:106] Iteration 23193600, lr = 3.9063e-05
I0416 23:57:35.511628 12023 solver.cpp:237] Iteration 23244800, loss = 3.22164
I0416 23:57:35.511716 12023 solver.cpp:253]     Train net output #0: loss = 1.60494 (* 1 = 1.60494 loss)
I0416 23:57:35.511725 12023 sgd_solver.cpp:106] Iteration 23244800, lr = 3.9063e-05
I0417 00:04:04.879372 12023 solver.cpp:341] Iteration 23296000, Testing net (#0)
I0417 00:04:10.185149 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0417 00:04:31.336964 12023 solver.cpp:409]     Test net output #0: accuracy = 0.34562
I0417 00:04:31.337000 12023 solver.cpp:409]     Test net output #1: loss = 3.08093 (* 1 = 3.08093 loss)
I0417 00:04:31.340802 12023 solver.cpp:237] Iteration 23296000, loss = 3.21796
I0417 00:04:31.340824 12023 solver.cpp:253]     Train net output #0: loss = 8.75254 (* 1 = 8.75254 loss)
I0417 00:04:31.340834 12023 sgd_solver.cpp:106] Iteration 23296000, lr = 3.9063e-05
I0417 00:11:00.454800 12023 solver.cpp:237] Iteration 23347200, loss = 3.21435
I0417 00:11:00.454896 12023 solver.cpp:253]     Train net output #0: loss = 5.21664 (* 1 = 5.21664 loss)
I0417 00:11:00.454906 12023 sgd_solver.cpp:106] Iteration 23347200, lr = 3.9063e-05
I0417 00:17:29.512969 12023 solver.cpp:237] Iteration 23398400, loss = 3.24787
I0417 00:17:29.513044 12023 solver.cpp:253]     Train net output #0: loss = 1.06485 (* 1 = 1.06485 loss)
I0417 00:17:29.513053 12023 sgd_solver.cpp:106] Iteration 23398400, lr = 3.9063e-05
I0417 00:23:58.429844 12023 solver.cpp:237] Iteration 23449600, loss = 3.21366
I0417 00:23:58.429919 12023 solver.cpp:253]     Train net output #0: loss = 2.60987 (* 1 = 2.60987 loss)
I0417 00:23:58.429929 12023 sgd_solver.cpp:106] Iteration 23449600, lr = 3.9063e-05
I0417 00:30:27.349339 12023 solver.cpp:237] Iteration 23500800, loss = 3.21585
I0417 00:30:27.349411 12023 solver.cpp:253]     Train net output #0: loss = 4.01915 (* 1 = 4.01915 loss)
I0417 00:30:27.349416 12023 sgd_solver.cpp:106] Iteration 23500800, lr = 3.9063e-05
I0417 00:36:56.348165 12023 solver.cpp:341] Iteration 23552000, Testing net (#0)
I0417 00:37:01.734416 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0417 00:37:22.772547 12023 solver.cpp:409]     Test net output #0: accuracy = 0.34374
I0417 00:37:22.772583 12023 solver.cpp:409]     Test net output #1: loss = 3.06646 (* 1 = 3.06646 loss)
I0417 00:37:22.776330 12023 solver.cpp:237] Iteration 23552000, loss = 3.1896
I0417 00:37:22.776350 12023 solver.cpp:253]     Train net output #0: loss = 5.08483 (* 1 = 5.08483 loss)
I0417 00:37:22.776360 12023 sgd_solver.cpp:106] Iteration 23552000, lr = 3.9063e-05
I0417 00:43:51.833698 12023 solver.cpp:237] Iteration 23603200, loss = 3.2057
I0417 00:43:51.833755 12023 solver.cpp:253]     Train net output #0: loss = 1.44471 (* 1 = 1.44471 loss)
I0417 00:43:51.833761 12023 sgd_solver.cpp:106] Iteration 23603200, lr = 3.9063e-05
I0417 00:50:20.899282 12023 solver.cpp:237] Iteration 23654400, loss = 3.2119
I0417 00:50:20.899355 12023 solver.cpp:253]     Train net output #0: loss = 8.1361 (* 1 = 8.1361 loss)
I0417 00:50:20.899361 12023 sgd_solver.cpp:106] Iteration 23654400, lr = 3.9063e-05
I0417 00:56:49.850100 12023 solver.cpp:237] Iteration 23705600, loss = 3.20778
I0417 00:56:49.850157 12023 solver.cpp:253]     Train net output #0: loss = 5.08406 (* 1 = 5.08406 loss)
I0417 00:56:49.850162 12023 sgd_solver.cpp:106] Iteration 23705600, lr = 3.9063e-05
I0417 01:03:18.794069 12023 solver.cpp:237] Iteration 23756800, loss = 3.21154
I0417 01:03:18.794142 12023 solver.cpp:253]     Train net output #0: loss = 5.74899 (* 1 = 5.74899 loss)
I0417 01:03:18.794147 12023 sgd_solver.cpp:106] Iteration 23756800, lr = 3.9063e-05
I0417 01:09:47.878077 12023 solver.cpp:341] Iteration 23808000, Testing net (#0)
I0417 01:09:53.903988 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0417 01:10:16.768928 12023 solver.cpp:409]     Test net output #0: accuracy = 0.34592
I0417 01:10:16.768961 12023 solver.cpp:409]     Test net output #1: loss = 3.06622 (* 1 = 3.06622 loss)
I0417 01:10:16.772713 12023 solver.cpp:237] Iteration 23808000, loss = 3.23517
I0417 01:10:16.772733 12023 solver.cpp:253]     Train net output #0: loss = 0.785236 (* 1 = 0.785236 loss)
I0417 01:10:16.772740 12023 sgd_solver.cpp:106] Iteration 23808000, lr = 3.9063e-05
I0417 01:16:46.591786 12023 solver.cpp:237] Iteration 23859200, loss = 3.22047
I0417 01:16:46.591855 12023 solver.cpp:253]     Train net output #0: loss = 3.68521 (* 1 = 3.68521 loss)
I0417 01:16:46.591861 12023 sgd_solver.cpp:106] Iteration 23859200, lr = 3.9063e-05
I0417 01:23:16.368712 12023 solver.cpp:237] Iteration 23910400, loss = 3.21357
I0417 01:23:16.368785 12023 solver.cpp:253]     Train net output #0: loss = 0.95481 (* 1 = 0.95481 loss)
I0417 01:23:16.368793 12023 sgd_solver.cpp:106] Iteration 23910400, lr = 3.9063e-05
I0417 01:29:45.421389 12023 solver.cpp:237] Iteration 23961600, loss = 3.21286
I0417 01:29:45.421476 12023 solver.cpp:253]     Train net output #0: loss = 0.0393783 (* 1 = 0.0393783 loss)
I0417 01:29:45.421483 12023 sgd_solver.cpp:106] Iteration 23961600, lr = 3.9063e-05
I0417 01:36:14.565587 12023 solver.cpp:237] Iteration 24012800, loss = 3.21068
I0417 01:36:14.565642 12023 solver.cpp:253]     Train net output #0: loss = 3.49635 (* 1 = 3.49635 loss)
I0417 01:36:14.565649 12023 sgd_solver.cpp:106] Iteration 24012800, lr = 3.9063e-05
I0417 01:42:49.334637 12023 solver.cpp:341] Iteration 24064000, Testing net (#0)
I0417 01:42:53.440701 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0417 01:43:15.719326 12023 solver.cpp:409]     Test net output #0: accuracy = 0.35228
I0417 01:43:15.719362 12023 solver.cpp:409]     Test net output #1: loss = 3.03303 (* 1 = 3.03303 loss)
I0417 01:43:15.723136 12023 solver.cpp:237] Iteration 24064000, loss = 3.19572
I0417 01:43:15.723156 12023 solver.cpp:253]     Train net output #0: loss = 4.03099 (* 1 = 4.03099 loss)
I0417 01:43:15.723163 12023 sgd_solver.cpp:106] Iteration 24064000, lr = 3.9063e-05
I0417 01:49:48.848249 12023 solver.cpp:237] Iteration 24115200, loss = 3.19912
I0417 01:49:48.848300 12023 solver.cpp:253]     Train net output #0: loss = 2.01294 (* 1 = 2.01294 loss)
I0417 01:49:48.848306 12023 sgd_solver.cpp:106] Iteration 24115200, lr = 3.9063e-05
I0417 01:56:19.500089 12023 solver.cpp:237] Iteration 24166400, loss = 3.209
I0417 01:56:19.500162 12023 solver.cpp:253]     Train net output #0: loss = 5.81355 (* 1 = 5.81355 loss)
I0417 01:56:19.500169 12023 sgd_solver.cpp:106] Iteration 24166400, lr = 3.9063e-05
I0417 02:02:48.621194 12023 solver.cpp:237] Iteration 24217600, loss = 3.19753
I0417 02:02:48.621265 12023 solver.cpp:253]     Train net output #0: loss = 3.20553 (* 1 = 3.20553 loss)
I0417 02:02:48.621276 12023 sgd_solver.cpp:106] Iteration 24217600, lr = 3.9063e-05
I0417 02:09:17.464689 12023 solver.cpp:237] Iteration 24268800, loss = 3.19547
I0417 02:09:17.464759 12023 solver.cpp:253]     Train net output #0: loss = 4.77281 (* 1 = 4.77281 loss)
I0417 02:09:17.464766 12023 sgd_solver.cpp:106] Iteration 24268800, lr = 3.9063e-05
I0417 02:15:46.289520 12023 solver.cpp:341] Iteration 24320000, Testing net (#0)
I0417 02:15:49.386195 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0417 02:16:12.747071 12023 solver.cpp:409]     Test net output #0: accuracy = 0.35132
I0417 02:16:12.747107 12023 solver.cpp:409]     Test net output #1: loss = 3.05677 (* 1 = 3.05677 loss)
I0417 02:16:12.750929 12023 solver.cpp:237] Iteration 24320000, loss = 3.20678
I0417 02:16:12.750952 12023 solver.cpp:253]     Train net output #0: loss = 5.19796 (* 1 = 5.19796 loss)
I0417 02:16:12.750962 12023 sgd_solver.cpp:106] Iteration 24320000, lr = 3.9063e-05
I0417 02:22:41.704792 12023 solver.cpp:237] Iteration 24371200, loss = 3.23923
I0417 02:22:41.704864 12023 solver.cpp:253]     Train net output #0: loss = 3.29437 (* 1 = 3.29437 loss)
I0417 02:22:41.704870 12023 sgd_solver.cpp:106] Iteration 24371200, lr = 3.9063e-05
I0417 02:29:10.523921 12023 solver.cpp:237] Iteration 24422400, loss = 3.20747
I0417 02:29:10.523993 12023 solver.cpp:253]     Train net output #0: loss = 2.56013 (* 1 = 2.56013 loss)
I0417 02:29:10.523999 12023 sgd_solver.cpp:106] Iteration 24422400, lr = 3.9063e-05
I0417 02:35:39.363323 12023 solver.cpp:237] Iteration 24473600, loss = 3.22634
I0417 02:35:39.363394 12023 solver.cpp:253]     Train net output #0: loss = 2.38102 (* 1 = 2.38102 loss)
I0417 02:35:39.363399 12023 sgd_solver.cpp:106] Iteration 24473600, lr = 3.9063e-05
I0417 02:42:08.218852 12023 solver.cpp:237] Iteration 24524800, loss = 3.20568
I0417 02:42:08.218924 12023 solver.cpp:253]     Train net output #0: loss = 2.51242 (* 1 = 2.51242 loss)
I0417 02:42:08.218930 12023 sgd_solver.cpp:106] Iteration 24524800, lr = 3.9063e-05
I0417 02:48:37.915599 12023 solver.cpp:341] Iteration 24576000, Testing net (#0)
I0417 02:48:41.012253 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0417 02:49:04.441632 12023 solver.cpp:409]     Test net output #0: accuracy = 0.35032
I0417 02:49:04.441668 12023 solver.cpp:409]     Test net output #1: loss = 3.03861 (* 1 = 3.03861 loss)
I0417 02:49:04.445444 12023 solver.cpp:237] Iteration 24576000, loss = 3.20359
I0417 02:49:04.445466 12023 solver.cpp:253]     Train net output #0: loss = 1.67125 (* 1 = 1.67125 loss)
I0417 02:49:04.445478 12023 sgd_solver.cpp:106] Iteration 24576000, lr = 3.9063e-05
I0417 02:55:33.392097 12023 solver.cpp:237] Iteration 24627200, loss = 3.20495
I0417 02:55:33.392171 12023 solver.cpp:253]     Train net output #0: loss = 0.170409 (* 1 = 0.170409 loss)
I0417 02:55:33.392180 12023 sgd_solver.cpp:106] Iteration 24627200, lr = 3.9063e-05
I0417 03:02:02.221359 12023 solver.cpp:237] Iteration 24678400, loss = 3.22343
I0417 03:02:02.221418 12023 solver.cpp:253]     Train net output #0: loss = 3.61141 (* 1 = 3.61141 loss)
I0417 03:02:02.221426 12023 sgd_solver.cpp:106] Iteration 24678400, lr = 3.9063e-05
I0417 03:08:31.113205 12023 solver.cpp:237] Iteration 24729600, loss = 3.21064
I0417 03:08:31.113278 12023 solver.cpp:253]     Train net output #0: loss = 7.82328 (* 1 = 7.82328 loss)
I0417 03:08:31.113286 12023 sgd_solver.cpp:106] Iteration 24729600, lr = 3.9063e-05
I0417 03:14:59.913197 12023 solver.cpp:237] Iteration 24780800, loss = 3.19987
I0417 03:14:59.913266 12023 solver.cpp:253]     Train net output #0: loss = 0.685192 (* 1 = 0.685192 loss)
I0417 03:14:59.913276 12023 sgd_solver.cpp:106] Iteration 24780800, lr = 3.9063e-05
I0417 03:21:29.124092 12023 solver.cpp:341] Iteration 24832000, Testing net (#0)
I0417 03:21:32.261744 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0417 03:21:55.518985 12023 solver.cpp:409]     Test net output #0: accuracy = 0.35146
I0417 03:21:55.519021 12023 solver.cpp:409]     Test net output #1: loss = 3.02518 (* 1 = 3.02518 loss)
I0417 03:21:55.522809 12023 solver.cpp:237] Iteration 24832000, loss = 3.17591
I0417 03:21:55.522827 12023 solver.cpp:253]     Train net output #0: loss = 3.14738 (* 1 = 3.14738 loss)
I0417 03:21:55.522836 12023 sgd_solver.cpp:106] Iteration 24832000, lr = 3.9063e-05
I0417 03:28:24.548455 12023 solver.cpp:237] Iteration 24883200, loss = 3.1984
I0417 03:28:24.548527 12023 solver.cpp:253]     Train net output #0: loss = 0.234811 (* 1 = 0.234811 loss)
I0417 03:28:24.548534 12023 sgd_solver.cpp:106] Iteration 24883200, lr = 3.9063e-05
I0417 03:34:53.486145 12023 solver.cpp:237] Iteration 24934400, loss = 3.20138
I0417 03:34:53.486507 12023 solver.cpp:253]     Train net output #0: loss = 3.40003 (* 1 = 3.40003 loss)
I0417 03:34:53.486513 12023 sgd_solver.cpp:106] Iteration 24934400, lr = 3.9063e-05
I0417 03:41:22.330457 12023 solver.cpp:237] Iteration 24985600, loss = 3.19293
I0417 03:41:22.330526 12023 solver.cpp:253]     Train net output #0: loss = 6.84146 (* 1 = 6.84146 loss)
I0417 03:41:22.330533 12023 sgd_solver.cpp:106] Iteration 24985600, lr = 3.9063e-05
I0417 03:47:51.153877 12023 solver.cpp:237] Iteration 25036800, loss = 3.20216
I0417 03:47:51.153949 12023 solver.cpp:253]     Train net output #0: loss = 0.493534 (* 1 = 0.493534 loss)
I0417 03:47:51.153954 12023 sgd_solver.cpp:106] Iteration 25036800, lr = 3.9063e-05
I0417 03:54:20.264134 12023 solver.cpp:341] Iteration 25088000, Testing net (#0)
I0417 03:54:23.467335 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0417 03:54:46.783669 12023 solver.cpp:409]     Test net output #0: accuracy = 0.35164
I0417 03:54:46.783704 12023 solver.cpp:409]     Test net output #1: loss = 3.05393 (* 1 = 3.05393 loss)
I0417 03:54:46.787452 12023 solver.cpp:237] Iteration 25088000, loss = 3.22095
I0417 03:54:46.787472 12023 solver.cpp:253]     Train net output #0: loss = 5.00142 (* 1 = 5.00142 loss)
I0417 03:54:46.787480 12023 sgd_solver.cpp:106] Iteration 25088000, lr = 3.9063e-05
I0417 04:01:16.534585 12023 solver.cpp:237] Iteration 25139200, loss = 3.22668
I0417 04:01:16.534646 12023 solver.cpp:253]     Train net output #0: loss = 4.09579 (* 1 = 4.09579 loss)
I0417 04:01:16.534659 12023 sgd_solver.cpp:106] Iteration 25139200, lr = 3.9063e-05
I0417 04:07:46.436105 12023 solver.cpp:237] Iteration 25190400, loss = 3.20094
I0417 04:07:46.436189 12023 solver.cpp:253]     Train net output #0: loss = 3.28993 (* 1 = 3.28993 loss)
I0417 04:07:46.436198 12023 sgd_solver.cpp:106] Iteration 25190400, lr = 3.9063e-05
I0417 04:14:15.397716 12023 solver.cpp:237] Iteration 25241600, loss = 3.19696
I0417 04:14:15.397769 12023 solver.cpp:253]     Train net output #0: loss = 0.0572428 (* 1 = 0.0572428 loss)
I0417 04:14:15.397775 12023 sgd_solver.cpp:106] Iteration 25241600, lr = 3.9063e-05
I0417 04:20:44.461930 12023 solver.cpp:237] Iteration 25292800, loss = 3.20368
I0417 04:20:44.461977 12023 solver.cpp:253]     Train net output #0: loss = 3.91476 (* 1 = 3.91476 loss)
I0417 04:20:44.461982 12023 sgd_solver.cpp:106] Iteration 25292800, lr = 3.9063e-05
I0417 04:27:18.619333 12023 solver.cpp:341] Iteration 25344000, Testing net (#0)
I0417 04:27:20.544816 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0417 04:27:44.998394 12023 solver.cpp:409]     Test net output #0: accuracy = 0.34686
I0417 04:27:44.998427 12023 solver.cpp:409]     Test net output #1: loss = 3.06422 (* 1 = 3.06422 loss)
I0417 04:27:45.002195 12023 solver.cpp:237] Iteration 25344000, loss = 3.19008
I0417 04:27:45.002215 12023 solver.cpp:253]     Train net output #0: loss = 4.683 (* 1 = 4.683 loss)
I0417 04:27:45.002224 12023 sgd_solver.cpp:106] Iteration 25344000, lr = 3.9063e-05
I0417 04:34:18.201088 12023 solver.cpp:237] Iteration 25395200, loss = 3.18974
I0417 04:34:18.201136 12023 solver.cpp:253]     Train net output #0: loss = 3.17264 (* 1 = 3.17264 loss)
I0417 04:34:18.201143 12023 sgd_solver.cpp:106] Iteration 25395200, lr = 3.9063e-05
I0417 04:40:48.806138 12023 solver.cpp:237] Iteration 25446400, loss = 3.18772
I0417 04:40:48.806200 12023 solver.cpp:253]     Train net output #0: loss = 4.29321 (* 1 = 4.29321 loss)
I0417 04:40:48.806206 12023 sgd_solver.cpp:106] Iteration 25446400, lr = 3.9063e-05
I0417 04:47:17.650866 12023 solver.cpp:237] Iteration 25497600, loss = 3.18477
I0417 04:47:17.650936 12023 solver.cpp:253]     Train net output #0: loss = 0.121786 (* 1 = 0.121786 loss)
I0417 04:47:17.650943 12023 sgd_solver.cpp:106] Iteration 25497600, lr = 3.9063e-05
I0417 04:53:46.472864 12023 solver.cpp:237] Iteration 25548800, loss = 3.17624
I0417 04:53:46.472936 12023 solver.cpp:253]     Train net output #0: loss = 3.41573 (* 1 = 3.41573 loss)
I0417 04:53:46.472942 12023 sgd_solver.cpp:106] Iteration 25548800, lr = 3.9063e-05
I0417 05:00:15.301089 12023 solver.cpp:459] Snapshotting to binary proto file snapshots/caffenet128_no_lrn_lsuv_relu_bs1_iter_25600000.caffemodel
I0417 05:00:16.664723 12023 sgd_solver.cpp:269] Snapshotting solver state to binary proto file snapshots/caffenet128_no_lrn_lsuv_relu_bs1_iter_25600000.solverstate
I0417 05:00:16.722950 12023 solver.cpp:341] Iteration 25600000, Testing net (#0)
I0417 05:00:17.657176 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0417 05:00:45.541400 12023 solver.cpp:409]     Test net output #0: accuracy = 0.34632
I0417 05:00:45.541465 12023 solver.cpp:409]     Test net output #1: loss = 3.07507 (* 1 = 3.07507 loss)
I0417 05:00:45.545217 12023 solver.cpp:237] Iteration 25600000, loss = 3.20532
I0417 05:00:45.545239 12023 solver.cpp:253]     Train net output #0: loss = 1.21104 (* 1 = 1.21104 loss)
I0417 05:00:45.545248 12023 sgd_solver.cpp:106] Iteration 25600000, lr = 3.9063e-06
I0417 05:07:14.794644 12023 solver.cpp:237] Iteration 25651200, loss = 3.03878
I0417 05:07:14.794704 12023 solver.cpp:253]     Train net output #0: loss = 0.437053 (* 1 = 0.437053 loss)
I0417 05:07:14.794711 12023 sgd_solver.cpp:106] Iteration 25651200, lr = 3.9063e-06
I0417 05:13:43.986995 12023 solver.cpp:237] Iteration 25702400, loss = 2.93989
I0417 05:13:43.987066 12023 solver.cpp:253]     Train net output #0: loss = 8.06806 (* 1 = 8.06806 loss)
I0417 05:13:43.987071 12023 sgd_solver.cpp:106] Iteration 25702400, lr = 3.9063e-06
I0417 05:20:13.107363 12023 solver.cpp:237] Iteration 25753600, loss = 2.93094
I0417 05:20:13.107456 12023 solver.cpp:253]     Train net output #0: loss = 3.15166 (* 1 = 3.15166 loss)
I0417 05:20:13.107462 12023 sgd_solver.cpp:106] Iteration 25753600, lr = 3.9063e-06
I0417 05:26:42.279876 12023 solver.cpp:237] Iteration 25804800, loss = 2.90839
I0417 05:26:42.279937 12023 solver.cpp:253]     Train net output #0: loss = 0.534284 (* 1 = 0.534284 loss)
I0417 05:26:42.279943 12023 sgd_solver.cpp:106] Iteration 25804800, lr = 3.9063e-06
I0417 05:33:11.850433 12023 solver.cpp:341] Iteration 25856000, Testing net (#0)
I0417 05:33:12.757746 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0417 05:33:38.617733 12023 solver.cpp:409]     Test net output #0: accuracy = 0.40076
I0417 05:33:38.617769 12023 solver.cpp:409]     Test net output #1: loss = 2.75199 (* 1 = 2.75199 loss)
I0417 05:33:38.621531 12023 solver.cpp:237] Iteration 25856000, loss = 2.88589
I0417 05:33:38.621553 12023 solver.cpp:253]     Train net output #0: loss = 0.618058 (* 1 = 0.618058 loss)
I0417 05:33:38.621565 12023 sgd_solver.cpp:106] Iteration 25856000, lr = 3.9063e-06
I0417 05:40:07.538453 12023 solver.cpp:237] Iteration 25907200, loss = 2.85953
I0417 05:40:07.538522 12023 solver.cpp:253]     Train net output #0: loss = 0.677752 (* 1 = 0.677752 loss)
I0417 05:40:07.538528 12023 sgd_solver.cpp:106] Iteration 25907200, lr = 3.9063e-06
I0417 05:46:36.355088 12023 solver.cpp:237] Iteration 25958400, loss = 2.87869
I0417 05:46:36.355157 12023 solver.cpp:253]     Train net output #0: loss = 3.14356 (* 1 = 3.14356 loss)
I0417 05:46:36.355164 12023 sgd_solver.cpp:106] Iteration 25958400, lr = 3.9063e-06
I0417 05:53:05.182798 12023 solver.cpp:237] Iteration 26009600, loss = 2.84027
I0417 05:53:05.182869 12023 solver.cpp:253]     Train net output #0: loss = 0.132212 (* 1 = 0.132212 loss)
I0417 05:53:05.182876 12023 sgd_solver.cpp:106] Iteration 26009600, lr = 3.9063e-06
I0417 05:59:34.095024 12023 solver.cpp:237] Iteration 26060800, loss = 2.83329
I0417 05:59:34.095082 12023 solver.cpp:253]     Train net output #0: loss = 3.28938 (* 1 = 3.28938 loss)
I0417 05:59:34.095088 12023 sgd_solver.cpp:106] Iteration 26060800, lr = 3.9063e-06
I0417 06:06:02.916246 12023 solver.cpp:341] Iteration 26112000, Testing net (#0)
I0417 06:06:03.809864 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0417 06:06:29.436796 12023 solver.cpp:409]     Test net output #0: accuracy = 0.40704
I0417 06:06:29.436830 12023 solver.cpp:409]     Test net output #1: loss = 2.71653 (* 1 = 2.71653 loss)
I0417 06:06:29.440588 12023 solver.cpp:237] Iteration 26112000, loss = 2.81208
I0417 06:06:29.440608 12023 solver.cpp:253]     Train net output #0: loss = 5.24781 (* 1 = 5.24781 loss)
I0417 06:06:29.440615 12023 sgd_solver.cpp:106] Iteration 26112000, lr = 3.9063e-06
I0417 06:12:58.408584 12023 solver.cpp:237] Iteration 26163200, loss = 2.80989
I0417 06:12:58.408668 12023 solver.cpp:253]     Train net output #0: loss = 1.37072 (* 1 = 1.37072 loss)
I0417 06:12:58.408679 12023 sgd_solver.cpp:106] Iteration 26163200, lr = 3.9063e-06
I0417 06:19:27.699403 12023 solver.cpp:237] Iteration 26214400, loss = 2.79645
I0417 06:19:27.699483 12023 solver.cpp:253]     Train net output #0: loss = 1.44243 (* 1 = 1.44243 loss)
I0417 06:19:27.699491 12023 sgd_solver.cpp:106] Iteration 26214400, lr = 3.9063e-06
I0417 06:25:56.938421 12023 solver.cpp:237] Iteration 26265600, loss = 2.78099
I0417 06:25:56.938480 12023 solver.cpp:253]     Train net output #0: loss = 0.0553497 (* 1 = 0.0553497 loss)
I0417 06:25:56.938487 12023 sgd_solver.cpp:106] Iteration 26265600, lr = 3.9063e-06
I0417 06:32:25.808815 12023 solver.cpp:237] Iteration 26316800, loss = 2.78187
I0417 06:32:25.808883 12023 solver.cpp:253]     Train net output #0: loss = 0.290692 (* 1 = 0.290692 loss)
I0417 06:32:25.808889 12023 sgd_solver.cpp:106] Iteration 26316800, lr = 3.9063e-06
I0417 06:38:54.659104 12023 solver.cpp:341] Iteration 26368000, Testing net (#0)
I0417 06:38:55.607226 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0417 06:39:21.179653 12023 solver.cpp:409]     Test net output #0: accuracy = 0.4118
I0417 06:39:21.179688 12023 solver.cpp:409]     Test net output #1: loss = 2.69512 (* 1 = 2.69512 loss)
I0417 06:39:21.183441 12023 solver.cpp:237] Iteration 26368000, loss = 2.78959
I0417 06:39:21.183465 12023 solver.cpp:253]     Train net output #0: loss = 4.23742 (* 1 = 4.23742 loss)
I0417 06:39:21.183473 12023 sgd_solver.cpp:106] Iteration 26368000, lr = 3.9063e-06
I0417 06:45:50.818708 12023 solver.cpp:237] Iteration 26419200, loss = 2.77317
I0417 06:45:50.818789 12023 solver.cpp:253]     Train net output #0: loss = 1.12849 (* 1 = 1.12849 loss)
I0417 06:45:50.818802 12023 sgd_solver.cpp:106] Iteration 26419200, lr = 3.9063e-06
I0417 06:52:20.318907 12023 solver.cpp:237] Iteration 26470400, loss = 2.77324
I0417 06:52:20.318980 12023 solver.cpp:253]     Train net output #0: loss = 6.16964 (* 1 = 6.16964 loss)
I0417 06:52:20.318985 12023 sgd_solver.cpp:106] Iteration 26470400, lr = 3.9063e-06
I0417 06:58:49.315068 12023 solver.cpp:237] Iteration 26521600, loss = 2.73649
I0417 06:58:49.315141 12023 solver.cpp:253]     Train net output #0: loss = 5.73443 (* 1 = 5.73443 loss)
I0417 06:58:49.315147 12023 sgd_solver.cpp:106] Iteration 26521600, lr = 3.9063e-06
I0417 07:05:18.325446 12023 solver.cpp:237] Iteration 26572800, loss = 2.74267
I0417 07:05:18.325496 12023 solver.cpp:253]     Train net output #0: loss = 0.325635 (* 1 = 0.325635 loss)
I0417 07:05:18.325502 12023 sgd_solver.cpp:106] Iteration 26572800, lr = 3.9063e-06
I0417 07:10:45.360920 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0417 07:11:52.785686 12023 solver.cpp:341] Iteration 26624000, Testing net (#0)
I0417 07:12:19.094393 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0417 07:12:19.305275 12023 solver.cpp:409]     Test net output #0: accuracy = 0.4142
I0417 07:12:19.305310 12023 solver.cpp:409]     Test net output #1: loss = 2.68093 (* 1 = 2.68093 loss)
I0417 07:12:19.309051 12023 solver.cpp:237] Iteration 26624000, loss = 2.71525
I0417 07:12:19.309072 12023 solver.cpp:253]     Train net output #0: loss = 2.25674 (* 1 = 2.25674 loss)
I0417 07:12:19.309080 12023 sgd_solver.cpp:106] Iteration 26624000, lr = 3.9063e-06
I0417 07:18:52.950310 12023 solver.cpp:237] Iteration 26675200, loss = 2.69158
I0417 07:18:52.950362 12023 solver.cpp:253]     Train net output #0: loss = 1.95084 (* 1 = 1.95084 loss)
I0417 07:18:52.950371 12023 sgd_solver.cpp:106] Iteration 26675200, lr = 3.9063e-06
I0417 07:25:23.619839 12023 solver.cpp:237] Iteration 26726400, loss = 2.69004
I0417 07:25:23.619912 12023 solver.cpp:253]     Train net output #0: loss = 2.67107 (* 1 = 2.67107 loss)
I0417 07:25:23.619920 12023 sgd_solver.cpp:106] Iteration 26726400, lr = 3.9063e-06
I0417 07:31:52.510437 12023 solver.cpp:237] Iteration 26777600, loss = 2.67969
I0417 07:31:52.510507 12023 solver.cpp:253]     Train net output #0: loss = 4.42918 (* 1 = 4.42918 loss)
I0417 07:31:52.510514 12023 sgd_solver.cpp:106] Iteration 26777600, lr = 3.9063e-06
I0417 07:38:21.582948 12023 solver.cpp:237] Iteration 26828800, loss = 2.64737
I0417 07:38:21.583017 12023 solver.cpp:253]     Train net output #0: loss = 5.61364 (* 1 = 5.61364 loss)
I0417 07:38:21.583024 12023 sgd_solver.cpp:106] Iteration 26828800, lr = 3.9063e-06
I0417 07:44:50.756074 12023 solver.cpp:341] Iteration 26880000, Testing net (#0)
I0417 07:45:17.646334 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0417 07:45:19.016245 12023 solver.cpp:409]     Test net output #0: accuracy = 0.41606
I0417 07:45:19.016278 12023 solver.cpp:409]     Test net output #1: loss = 2.66486 (* 1 = 2.66486 loss)
I0417 07:45:19.020011 12023 solver.cpp:237] Iteration 26880000, loss = 2.64611
I0417 07:45:19.020030 12023 solver.cpp:253]     Train net output #0: loss = 3.33958 (* 1 = 3.33958 loss)
I0417 07:45:19.020038 12023 sgd_solver.cpp:106] Iteration 26880000, lr = 3.9063e-06
I0417 07:51:48.014048 12023 solver.cpp:237] Iteration 26931200, loss = 2.79619
I0417 07:51:48.014108 12023 solver.cpp:253]     Train net output #0: loss = 3.67346 (* 1 = 3.67346 loss)
I0417 07:51:48.014120 12023 sgd_solver.cpp:106] Iteration 26931200, lr = 3.9063e-06
I0417 07:58:17.179596 12023 solver.cpp:237] Iteration 26982400, loss = 2.76449
I0417 07:58:17.179690 12023 solver.cpp:253]     Train net output #0: loss = 0.392948 (* 1 = 0.392948 loss)
I0417 07:58:17.179700 12023 sgd_solver.cpp:106] Iteration 26982400, lr = 3.9063e-06
I0417 08:04:46.281874 12023 solver.cpp:237] Iteration 27033600, loss = 2.77824
I0417 08:04:46.281939 12023 solver.cpp:253]     Train net output #0: loss = 4.08607 (* 1 = 4.08607 loss)
I0417 08:04:46.281947 12023 sgd_solver.cpp:106] Iteration 27033600, lr = 3.9063e-06
I0417 08:11:15.535295 12023 solver.cpp:237] Iteration 27084800, loss = 2.76386
I0417 08:11:15.535378 12023 solver.cpp:253]     Train net output #0: loss = 3.87046 (* 1 = 3.87046 loss)
I0417 08:11:15.535384 12023 sgd_solver.cpp:106] Iteration 27084800, lr = 3.9063e-06
I0417 08:17:45.125891 12023 solver.cpp:341] Iteration 27136000, Testing net (#0)
I0417 08:18:10.112244 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0417 08:18:11.483135 12023 solver.cpp:409]     Test net output #0: accuracy = 0.41838
I0417 08:18:11.483170 12023 solver.cpp:409]     Test net output #1: loss = 2.65816 (* 1 = 2.65816 loss)
I0417 08:18:11.486973 12023 solver.cpp:237] Iteration 27136000, loss = 2.75638
I0417 08:18:11.486994 12023 solver.cpp:253]     Train net output #0: loss = 1.8361 (* 1 = 1.8361 loss)
I0417 08:18:11.487001 12023 sgd_solver.cpp:106] Iteration 27136000, lr = 3.9063e-06
I0417 08:24:40.689565 12023 solver.cpp:237] Iteration 27187200, loss = 2.74472
I0417 08:24:40.689627 12023 solver.cpp:253]     Train net output #0: loss = 7.16557 (* 1 = 7.16557 loss)
I0417 08:24:40.689640 12023 sgd_solver.cpp:106] Iteration 27187200, lr = 3.9063e-06
I0417 08:31:09.928196 12023 solver.cpp:237] Iteration 27238400, loss = 2.76915
I0417 08:31:09.928272 12023 solver.cpp:253]     Train net output #0: loss = 0.0593311 (* 1 = 0.0593311 loss)
I0417 08:31:09.928282 12023 sgd_solver.cpp:106] Iteration 27238400, lr = 3.9063e-06
I0417 08:37:39.046301 12023 solver.cpp:237] Iteration 27289600, loss = 2.73875
I0417 08:37:39.046363 12023 solver.cpp:253]     Train net output #0: loss = 5.31398 (* 1 = 5.31398 loss)
I0417 08:37:39.046375 12023 sgd_solver.cpp:106] Iteration 27289600, lr = 3.9063e-06
I0417 08:44:08.203359 12023 solver.cpp:237] Iteration 27340800, loss = 2.73122
I0417 08:44:08.203419 12023 solver.cpp:253]     Train net output #0: loss = 4.67085 (* 1 = 4.67085 loss)
I0417 08:44:08.203431 12023 sgd_solver.cpp:106] Iteration 27340800, lr = 3.9063e-06
I0417 08:50:37.445439 12023 solver.cpp:341] Iteration 27392000, Testing net (#0)
I0417 08:51:02.516196 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0417 08:51:03.807054 12023 solver.cpp:409]     Test net output #0: accuracy = 0.4194
I0417 08:51:03.807090 12023 solver.cpp:409]     Test net output #1: loss = 2.64548 (* 1 = 2.64548 loss)
I0417 08:51:03.810850 12023 solver.cpp:237] Iteration 27392000, loss = 2.71289
I0417 08:51:03.810871 12023 solver.cpp:253]     Train net output #0: loss = 0.0579944 (* 1 = 0.0579944 loss)
I0417 08:51:03.810883 12023 sgd_solver.cpp:106] Iteration 27392000, lr = 3.9063e-06
I0417 08:57:33.041610 12023 solver.cpp:237] Iteration 27443200, loss = 2.70745
I0417 08:57:33.041671 12023 solver.cpp:253]     Train net output #0: loss = 0.839731 (* 1 = 0.839731 loss)
I0417 08:57:33.041679 12023 sgd_solver.cpp:106] Iteration 27443200, lr = 3.9063e-06
I0417 09:04:02.437146 12023 solver.cpp:237] Iteration 27494400, loss = 2.7101
I0417 09:04:02.437206 12023 solver.cpp:253]     Train net output #0: loss = 0.229628 (* 1 = 0.229628 loss)
I0417 09:04:02.437211 12023 sgd_solver.cpp:106] Iteration 27494400, lr = 3.9063e-06
I0417 09:10:31.479486 12023 solver.cpp:237] Iteration 27545600, loss = 2.70736
I0417 09:10:31.479559 12023 solver.cpp:253]     Train net output #0: loss = 6.99054 (* 1 = 6.99054 loss)
I0417 09:10:31.479568 12023 sgd_solver.cpp:106] Iteration 27545600, lr = 3.9063e-06
I0417 09:17:00.307266 12023 solver.cpp:237] Iteration 27596800, loss = 2.69674
I0417 09:17:00.307360 12023 solver.cpp:253]     Train net output #0: loss = 4.19603 (* 1 = 4.19603 loss)
I0417 09:17:00.307370 12023 sgd_solver.cpp:106] Iteration 27596800, lr = 3.9063e-06
I0417 09:23:29.130638 12023 solver.cpp:341] Iteration 27648000, Testing net (#0)
I0417 09:23:57.245180 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0417 09:23:58.663678 12023 solver.cpp:409]     Test net output #0: accuracy = 0.42338
I0417 09:23:58.663720 12023 solver.cpp:409]     Test net output #1: loss = 2.63771 (* 1 = 2.63771 loss)
I0417 09:23:58.667646 12023 solver.cpp:237] Iteration 27648000, loss = 2.71353
I0417 09:23:58.667670 12023 solver.cpp:253]     Train net output #0: loss = 1.69813 (* 1 = 1.69813 loss)
I0417 09:23:58.667678 12023 sgd_solver.cpp:106] Iteration 27648000, lr = 3.9063e-06
I0417 09:30:28.085878 12023 solver.cpp:237] Iteration 27699200, loss = 2.71525
I0417 09:30:28.085947 12023 solver.cpp:253]     Train net output #0: loss = 2.57748 (* 1 = 2.57748 loss)
I0417 09:30:28.085952 12023 sgd_solver.cpp:106] Iteration 27699200, lr = 3.9063e-06
I0417 09:36:57.717828 12023 solver.cpp:237] Iteration 27750400, loss = 2.69176
I0417 09:36:57.717898 12023 solver.cpp:253]     Train net output #0: loss = 4.55602 (* 1 = 4.55602 loss)
I0417 09:36:57.717905 12023 sgd_solver.cpp:106] Iteration 27750400, lr = 3.9063e-06
I0417 09:43:26.785071 12023 solver.cpp:237] Iteration 27801600, loss = 2.66773
I0417 09:43:26.785141 12023 solver.cpp:253]     Train net output #0: loss = 0.121431 (* 1 = 0.121431 loss)
I0417 09:43:26.785146 12023 sgd_solver.cpp:106] Iteration 27801600, lr = 3.9063e-06
I0417 09:49:55.776022 12023 solver.cpp:237] Iteration 27852800, loss = 2.67177
I0417 09:49:55.776072 12023 solver.cpp:253]     Train net output #0: loss = 0.000196655 (* 1 = 0.000196655 loss)
I0417 09:49:55.776077 12023 sgd_solver.cpp:106] Iteration 27852800, lr = 3.9063e-06
I0417 09:56:30.320083 12023 solver.cpp:341] Iteration 27904000, Testing net (#0)
I0417 09:56:57.071380 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0417 09:56:59.857894 12023 solver.cpp:409]     Test net output #0: accuracy = 0.42474
I0417 09:56:59.857933 12023 solver.cpp:409]     Test net output #1: loss = 2.62306 (* 1 = 2.62306 loss)
I0417 09:56:59.861845 12023 solver.cpp:237] Iteration 27904000, loss = 2.65825
I0417 09:56:59.861883 12023 solver.cpp:253]     Train net output #0: loss = 0.757297 (* 1 = 0.757297 loss)
I0417 09:56:59.861899 12023 sgd_solver.cpp:106] Iteration 27904000, lr = 3.9063e-06
I0417 10:03:33.783879 12023 solver.cpp:237] Iteration 27955200, loss = 2.64295
I0417 10:03:33.783939 12023 solver.cpp:253]     Train net output #0: loss = 0.00141912 (* 1 = 0.00141912 loss)
I0417 10:03:33.783951 12023 sgd_solver.cpp:106] Iteration 27955200, lr = 3.9063e-06
I0417 10:10:04.741914 12023 solver.cpp:237] Iteration 28006400, loss = 2.6317
I0417 10:10:04.741993 12023 solver.cpp:253]     Train net output #0: loss = 0.741143 (* 1 = 0.741143 loss)
I0417 10:10:04.741999 12023 sgd_solver.cpp:106] Iteration 28006400, lr = 3.9063e-06
I0417 10:16:33.896101 12023 solver.cpp:237] Iteration 28057600, loss = 2.63135
I0417 10:16:33.896164 12023 solver.cpp:253]     Train net output #0: loss = 0.0913529 (* 1 = 0.0913529 loss)
I0417 10:16:33.896170 12023 sgd_solver.cpp:106] Iteration 28057600, lr = 3.9063e-06
I0417 10:23:03.107059 12023 solver.cpp:237] Iteration 28108800, loss = 2.61926
I0417 10:23:03.107117 12023 solver.cpp:253]     Train net output #0: loss = 2.22584 (* 1 = 2.22584 loss)
I0417 10:23:03.107123 12023 sgd_solver.cpp:106] Iteration 28108800, lr = 3.9063e-06
I0417 10:29:32.228502 12023 solver.cpp:459] Snapshotting to binary proto file snapshots/caffenet128_no_lrn_lsuv_relu_bs1_iter_28160000.caffemodel
I0417 10:29:33.342597 12023 sgd_solver.cpp:269] Snapshotting solver state to binary proto file snapshots/caffenet128_no_lrn_lsuv_relu_bs1_iter_28160000.solverstate
I0417 10:29:33.401031 12023 solver.cpp:341] Iteration 28160000, Testing net (#0)
I0417 10:29:56.184702 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0417 10:29:59.829769 12023 solver.cpp:409]     Test net output #0: accuracy = 0.42406
I0417 10:29:59.829803 12023 solver.cpp:409]     Test net output #1: loss = 2.62139 (* 1 = 2.62139 loss)
I0417 10:29:59.833549 12023 solver.cpp:237] Iteration 28160000, loss = 2.62132
I0417 10:29:59.833569 12023 solver.cpp:253]     Train net output #0: loss = 7.15173 (* 1 = 7.15173 loss)
I0417 10:29:59.833575 12023 sgd_solver.cpp:106] Iteration 28160000, lr = 3.9063e-06
I0417 10:36:29.077179 12023 solver.cpp:237] Iteration 28211200, loss = 2.7341
I0417 10:36:29.077258 12023 solver.cpp:253]     Train net output #0: loss = 6.08036 (* 1 = 6.08036 loss)
I0417 10:36:29.077266 12023 sgd_solver.cpp:106] Iteration 28211200, lr = 3.9063e-06
I0417 10:42:58.297370 12023 solver.cpp:237] Iteration 28262400, loss = 2.69786
I0417 10:42:58.297427 12023 solver.cpp:253]     Train net output #0: loss = 2.74649 (* 1 = 2.74649 loss)
I0417 10:42:58.297433 12023 sgd_solver.cpp:106] Iteration 28262400, lr = 3.9063e-06
I0417 10:49:27.330449 12023 solver.cpp:237] Iteration 28313600, loss = 2.72174
I0417 10:49:27.330512 12023 solver.cpp:253]     Train net output #0: loss = 2.62655 (* 1 = 2.62655 loss)
I0417 10:49:27.330516 12023 sgd_solver.cpp:106] Iteration 28313600, lr = 3.9063e-06
I0417 10:55:56.313639 12023 solver.cpp:237] Iteration 28364800, loss = 2.71146
I0417 10:55:56.313709 12023 solver.cpp:253]     Train net output #0: loss = 0.693399 (* 1 = 0.693399 loss)
I0417 10:55:56.313714 12023 sgd_solver.cpp:106] Iteration 28364800, lr = 3.9063e-06
I0417 11:02:25.627528 12023 solver.cpp:341] Iteration 28416000, Testing net (#0)
I0417 11:02:51.079327 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0417 11:02:55.167578 12023 solver.cpp:409]     Test net output #0: accuracy = 0.42538
I0417 11:02:55.167615 12023 solver.cpp:409]     Test net output #1: loss = 2.62792 (* 1 = 2.62792 loss)
I0417 11:02:55.171537 12023 solver.cpp:237] Iteration 28416000, loss = 2.70371
I0417 11:02:55.171557 12023 solver.cpp:253]     Train net output #0: loss = 2.35169 (* 1 = 2.35169 loss)
I0417 11:02:55.171566 12023 sgd_solver.cpp:106] Iteration 28416000, lr = 3.9063e-06
I0417 11:09:24.185528 12023 solver.cpp:237] Iteration 28467200, loss = 2.68701
I0417 11:09:24.185600 12023 solver.cpp:253]     Train net output #0: loss = 0.000423342 (* 1 = 0.000423342 loss)
I0417 11:09:24.185606 12023 sgd_solver.cpp:106] Iteration 28467200, lr = 3.9063e-06
I0417 11:15:53.083168 12023 solver.cpp:237] Iteration 28518400, loss = 2.71835
I0417 11:15:53.083240 12023 solver.cpp:253]     Train net output #0: loss = 6.31963 (* 1 = 6.31963 loss)
I0417 11:15:53.083245 12023 sgd_solver.cpp:106] Iteration 28518400, lr = 3.9063e-06
I0417 11:22:21.949810 12023 solver.cpp:237] Iteration 28569600, loss = 2.67979
I0417 11:22:21.949879 12023 solver.cpp:253]     Train net output #0: loss = 3.97784 (* 1 = 3.97784 loss)
I0417 11:22:21.949885 12023 sgd_solver.cpp:106] Iteration 28569600, lr = 3.9063e-06
I0417 11:28:50.877601 12023 solver.cpp:237] Iteration 28620800, loss = 2.67508
I0417 11:28:50.877671 12023 solver.cpp:253]     Train net output #0: loss = 0.142206 (* 1 = 0.142206 loss)
I0417 11:28:50.877677 12023 sgd_solver.cpp:106] Iteration 28620800, lr = 3.9063e-06
I0417 11:35:19.770052 12023 solver.cpp:341] Iteration 28672000, Testing net (#0)
I0417 11:35:45.273381 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0417 11:35:49.302718 12023 solver.cpp:409]     Test net output #0: accuracy = 0.42534
I0417 11:35:49.302755 12023 solver.cpp:409]     Test net output #1: loss = 2.61145 (* 1 = 2.61145 loss)
I0417 11:35:49.306676 12023 solver.cpp:237] Iteration 28672000, loss = 2.67055
I0417 11:35:49.306697 12023 solver.cpp:253]     Train net output #0: loss = 5.58001 (* 1 = 5.58001 loss)
I0417 11:35:49.306706 12023 sgd_solver.cpp:106] Iteration 28672000, lr = 3.9063e-06
I0417 11:42:18.341015 12023 solver.cpp:237] Iteration 28723200, loss = 2.66356
I0417 11:42:18.341086 12023 solver.cpp:253]     Train net output #0: loss = 0.785296 (* 1 = 0.785296 loss)
I0417 11:42:18.341092 12023 sgd_solver.cpp:106] Iteration 28723200, lr = 3.9063e-06
I0417 11:48:47.410972 12023 solver.cpp:237] Iteration 28774400, loss = 2.67272
I0417 11:48:47.411065 12023 solver.cpp:253]     Train net output #0: loss = 1.06666 (* 1 = 1.06666 loss)
I0417 11:48:47.411072 12023 sgd_solver.cpp:106] Iteration 28774400, lr = 3.9063e-06
I0417 11:55:16.712450 12023 solver.cpp:237] Iteration 28825600, loss = 2.66104
I0417 11:55:16.712525 12023 solver.cpp:253]     Train net output #0: loss = 2.89792 (* 1 = 2.89792 loss)
I0417 11:55:16.712532 12023 sgd_solver.cpp:106] Iteration 28825600, lr = 3.9063e-06
I0417 12:01:46.242831 12023 solver.cpp:237] Iteration 28876800, loss = 2.65106
I0417 12:01:46.242902 12023 solver.cpp:253]     Train net output #0: loss = 0.611018 (* 1 = 0.611018 loss)
I0417 12:01:46.242908 12023 sgd_solver.cpp:106] Iteration 28876800, lr = 3.9063e-06
I0417 12:08:15.944555 12023 solver.cpp:341] Iteration 28928000, Testing net (#0)
I0417 12:08:41.710685 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0417 12:08:45.618964 12023 solver.cpp:409]     Test net output #0: accuracy = 0.42912
I0417 12:08:45.618999 12023 solver.cpp:409]     Test net output #1: loss = 2.6048 (* 1 = 2.6048 loss)
I0417 12:08:45.622738 12023 solver.cpp:237] Iteration 28928000, loss = 2.66953
I0417 12:08:45.622758 12023 solver.cpp:253]     Train net output #0: loss = 1.12318 (* 1 = 1.12318 loss)
I0417 12:08:45.622767 12023 sgd_solver.cpp:106] Iteration 28928000, lr = 3.9063e-06
I0417 12:15:15.467211 12023 solver.cpp:237] Iteration 28979200, loss = 2.66148
I0417 12:15:15.467283 12023 solver.cpp:253]     Train net output #0: loss = 1.3391 (* 1 = 1.3391 loss)
I0417 12:15:15.467293 12023 sgd_solver.cpp:106] Iteration 28979200, lr = 3.9063e-06
I0417 12:21:45.363057 12023 solver.cpp:237] Iteration 29030400, loss = 2.65265
I0417 12:21:45.363126 12023 solver.cpp:253]     Train net output #0: loss = 4.6797 (* 1 = 4.6797 loss)
I0417 12:21:45.363134 12023 sgd_solver.cpp:106] Iteration 29030400, lr = 3.9063e-06
I0417 12:28:14.823681 12023 solver.cpp:237] Iteration 29081600, loss = 2.62734
I0417 12:28:14.823756 12023 solver.cpp:253]     Train net output #0: loss = 8.18876 (* 1 = 8.18876 loss)
I0417 12:28:14.823766 12023 sgd_solver.cpp:106] Iteration 29081600, lr = 3.9063e-06
I0417 12:34:44.043648 12023 solver.cpp:237] Iteration 29132800, loss = 2.6293
I0417 12:34:44.043702 12023 solver.cpp:253]     Train net output #0: loss = 3.58563 (* 1 = 3.58563 loss)
I0417 12:34:44.043710 12023 sgd_solver.cpp:106] Iteration 29132800, lr = 3.9063e-06
I0417 12:41:24.262002 12023 solver.cpp:341] Iteration 29184000, Testing net (#0)
I0417 12:41:45.861879 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0417 12:41:50.590538 12023 solver.cpp:409]     Test net output #0: accuracy = 0.43026
I0417 12:41:50.590572 12023 solver.cpp:409]     Test net output #1: loss = 2.59551 (* 1 = 2.59551 loss)
I0417 12:41:50.594364 12023 solver.cpp:237] Iteration 29184000, loss = 2.62046
I0417 12:41:50.594386 12023 solver.cpp:253]     Train net output #0: loss = 3.68795 (* 1 = 3.68795 loss)
I0417 12:41:50.594398 12023 sgd_solver.cpp:106] Iteration 29184000, lr = 3.9063e-06
I0417 12:48:25.452507 12023 solver.cpp:237] Iteration 29235200, loss = 2.61422
I0417 12:48:25.452551 12023 solver.cpp:253]     Train net output #0: loss = 0.467398 (* 1 = 0.467398 loss)
I0417 12:48:25.452558 12023 sgd_solver.cpp:106] Iteration 29235200, lr = 3.9063e-06
I0417 12:54:56.474431 12023 solver.cpp:237] Iteration 29286400, loss = 2.59986
I0417 12:54:56.474498 12023 solver.cpp:253]     Train net output #0: loss = 0.915521 (* 1 = 0.915521 loss)
I0417 12:54:56.474503 12023 sgd_solver.cpp:106] Iteration 29286400, lr = 3.9063e-06
I0417 13:01:25.725658 12023 solver.cpp:237] Iteration 29337600, loss = 2.60703
I0417 13:01:25.725729 12023 solver.cpp:253]     Train net output #0: loss = 3.30976 (* 1 = 3.30976 loss)
I0417 13:01:25.725735 12023 sgd_solver.cpp:106] Iteration 29337600, lr = 3.9063e-06
I0417 13:07:54.656024 12023 solver.cpp:237] Iteration 29388800, loss = 2.5958
I0417 13:07:54.656095 12023 solver.cpp:253]     Train net output #0: loss = 2.00044 (* 1 = 2.00044 loss)
I0417 13:07:54.656100 12023 sgd_solver.cpp:106] Iteration 29388800, lr = 3.9063e-06
I0417 13:14:23.545824 12023 solver.cpp:341] Iteration 29440000, Testing net (#0)
I0417 13:14:46.385812 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0417 13:14:53.085130 12023 solver.cpp:409]     Test net output #0: accuracy = 0.42858
I0417 13:14:53.085165 12023 solver.cpp:409]     Test net output #1: loss = 2.59739 (* 1 = 2.59739 loss)
I0417 13:14:53.089139 12023 solver.cpp:237] Iteration 29440000, loss = 2.59072
I0417 13:14:53.089164 12023 solver.cpp:253]     Train net output #0: loss = 1.56453 (* 1 = 1.56453 loss)
I0417 13:14:53.089174 12023 sgd_solver.cpp:106] Iteration 29440000, lr = 3.9063e-06
I0417 13:21:26.088651 12023 solver.cpp:237] Iteration 29491200, loss = 2.68691
I0417 13:21:26.088721 12023 solver.cpp:253]     Train net output #0: loss = 0.205835 (* 1 = 0.205835 loss)
I0417 13:21:26.088728 12023 sgd_solver.cpp:106] Iteration 29491200, lr = 3.9063e-06
I0417 13:27:55.529005 12023 solver.cpp:237] Iteration 29542400, loss = 2.66017
I0417 13:27:55.529059 12023 solver.cpp:253]     Train net output #0: loss = 6.47856 (* 1 = 6.47856 loss)
I0417 13:27:55.529067 12023 sgd_solver.cpp:106] Iteration 29542400, lr = 3.9063e-06
I0417 13:34:24.567680 12023 solver.cpp:237] Iteration 29593600, loss = 2.67784
I0417 13:34:24.567739 12023 solver.cpp:253]     Train net output #0: loss = 1.21179 (* 1 = 1.21179 loss)
I0417 13:34:24.567745 12023 sgd_solver.cpp:106] Iteration 29593600, lr = 3.9063e-06
I0417 13:40:53.573168 12023 solver.cpp:237] Iteration 29644800, loss = 2.67034
I0417 13:40:53.573236 12023 solver.cpp:253]     Train net output #0: loss = 0.389532 (* 1 = 0.389532 loss)
I0417 13:40:53.573242 12023 sgd_solver.cpp:106] Iteration 29644800, lr = 3.9063e-06
I0417 13:47:25.360723 12023 solver.cpp:341] Iteration 29696000, Testing net (#0)
I0417 13:47:48.503550 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0417 13:47:55.239580 12023 solver.cpp:409]     Test net output #0: accuracy = 0.43198
I0417 13:47:55.239619 12023 solver.cpp:409]     Test net output #1: loss = 2.5897 (* 1 = 2.5897 loss)
I0417 13:47:55.243542 12023 solver.cpp:237] Iteration 29696000, loss = 2.65336
I0417 13:47:55.243563 12023 solver.cpp:253]     Train net output #0: loss = 1.457 (* 1 = 1.457 loss)
I0417 13:47:55.243571 12023 sgd_solver.cpp:106] Iteration 29696000, lr = 3.9063e-06
I0417 13:54:25.828786 12023 solver.cpp:237] Iteration 29747200, loss = 2.66624
I0417 13:54:25.828855 12023 solver.cpp:253]     Train net output #0: loss = 1.91312 (* 1 = 1.91312 loss)
I0417 13:54:25.828860 12023 sgd_solver.cpp:106] Iteration 29747200, lr = 3.9063e-06
I0417 14:00:55.129020 12023 solver.cpp:237] Iteration 29798400, loss = 2.66949
I0417 14:00:55.129088 12023 solver.cpp:253]     Train net output #0: loss = 1.72978 (* 1 = 1.72978 loss)
I0417 14:00:55.129093 12023 sgd_solver.cpp:106] Iteration 29798400, lr = 3.9063e-06
I0417 14:07:24.107578 12023 solver.cpp:237] Iteration 29849600, loss = 2.65429
I0417 14:07:24.107646 12023 solver.cpp:253]     Train net output #0: loss = 0.00144676 (* 1 = 0.00144676 loss)
I0417 14:07:24.107652 12023 sgd_solver.cpp:106] Iteration 29849600, lr = 3.9063e-06
I0417 14:13:53.319556 12023 solver.cpp:237] Iteration 29900800, loss = 2.63343
I0417 14:13:53.319628 12023 solver.cpp:253]     Train net output #0: loss = 0.00817406 (* 1 = 0.00817406 loss)
I0417 14:13:53.319633 12023 sgd_solver.cpp:106] Iteration 29900800, lr = 3.9063e-06
I0417 14:20:23.799067 12023 solver.cpp:341] Iteration 29952000, Testing net (#0)
I0417 14:20:44.448747 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0417 14:20:50.368577 12023 solver.cpp:409]     Test net output #0: accuracy = 0.43114
I0417 14:20:50.368610 12023 solver.cpp:409]     Test net output #1: loss = 2.58965 (* 1 = 2.58965 loss)
I0417 14:20:50.372381 12023 solver.cpp:237] Iteration 29952000, loss = 2.63386
I0417 14:20:50.372402 12023 solver.cpp:253]     Train net output #0: loss = 1.97183 (* 1 = 1.97183 loss)
I0417 14:20:50.372411 12023 sgd_solver.cpp:106] Iteration 29952000, lr = 3.9063e-06
I0417 14:27:29.095840 12023 solver.cpp:237] Iteration 30003200, loss = 2.63207
I0417 14:27:29.095917 12023 solver.cpp:253]     Train net output #0: loss = 4.39531 (* 1 = 4.39531 loss)
I0417 14:27:29.095923 12023 sgd_solver.cpp:106] Iteration 30003200, lr = 3.9063e-06
I0417 14:33:58.913682 12023 solver.cpp:237] Iteration 30054400, loss = 2.63381
I0417 14:33:58.913751 12023 solver.cpp:253]     Train net output #0: loss = 1.16413 (* 1 = 1.16413 loss)
I0417 14:33:58.913758 12023 sgd_solver.cpp:106] Iteration 30054400, lr = 3.9063e-06
I0417 14:40:29.087857 12023 solver.cpp:237] Iteration 30105600, loss = 2.62978
I0417 14:40:29.087916 12023 solver.cpp:253]     Train net output #0: loss = 0.448802 (* 1 = 0.448802 loss)
I0417 14:40:29.087923 12023 sgd_solver.cpp:106] Iteration 30105600, lr = 3.9063e-06
I0417 14:46:58.652979 12023 solver.cpp:237] Iteration 30156800, loss = 2.61965
I0417 14:46:58.653038 12023 solver.cpp:253]     Train net output #0: loss = 3.00847 (* 1 = 3.00847 loss)
I0417 14:46:58.653044 12023 sgd_solver.cpp:106] Iteration 30156800, lr = 3.9063e-06
I0417 14:53:27.956831 12023 solver.cpp:341] Iteration 30208000, Testing net (#0)
I0417 14:53:48.409014 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0417 14:53:54.383568 12023 solver.cpp:409]     Test net output #0: accuracy = 0.43322
I0417 14:53:54.383602 12023 solver.cpp:409]     Test net output #1: loss = 2.58252 (* 1 = 2.58252 loss)
I0417 14:53:54.387357 12023 solver.cpp:237] Iteration 30208000, loss = 2.63724
I0417 14:53:54.387377 12023 solver.cpp:253]     Train net output #0: loss = 0.211662 (* 1 = 0.211662 loss)
I0417 14:53:54.387387 12023 sgd_solver.cpp:106] Iteration 30208000, lr = 3.9063e-06
I0417 15:00:24.096150 12023 solver.cpp:237] Iteration 30259200, loss = 2.63838
I0417 15:00:24.096210 12023 solver.cpp:253]     Train net output #0: loss = 1.66651 (* 1 = 1.66651 loss)
I0417 15:00:24.096215 12023 sgd_solver.cpp:106] Iteration 30259200, lr = 3.9063e-06
I0417 15:06:53.776892 12023 solver.cpp:237] Iteration 30310400, loss = 2.63538
I0417 15:06:53.776962 12023 solver.cpp:253]     Train net output #0: loss = 0.000814352 (* 1 = 0.000814352 loss)
I0417 15:06:53.776968 12023 sgd_solver.cpp:106] Iteration 30310400, lr = 3.9063e-06
I0417 15:13:22.893497 12023 solver.cpp:237] Iteration 30361600, loss = 2.59984
I0417 15:13:22.893559 12023 solver.cpp:253]     Train net output #0: loss = 4.25819 (* 1 = 4.25819 loss)
I0417 15:13:22.893565 12023 sgd_solver.cpp:106] Iteration 30361600, lr = 3.9063e-06
I0417 15:19:52.065567 12023 solver.cpp:237] Iteration 30412800, loss = 2.61192
I0417 15:19:52.065626 12023 solver.cpp:253]     Train net output #0: loss = 1.94024 (* 1 = 1.94024 loss)
I0417 15:19:52.065631 12023 sgd_solver.cpp:106] Iteration 30412800, lr = 3.9063e-06
I0417 15:26:25.702891 12023 solver.cpp:341] Iteration 30464000, Testing net (#0)
I0417 15:26:47.264889 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0417 15:26:55.236218 12023 solver.cpp:409]     Test net output #0: accuracy = 0.43324
I0417 15:26:55.236261 12023 solver.cpp:409]     Test net output #1: loss = 2.57709 (* 1 = 2.57709 loss)
I0417 15:26:55.240231 12023 solver.cpp:237] Iteration 30464000, loss = 2.60203
I0417 15:26:55.240254 12023 solver.cpp:253]     Train net output #0: loss = 5.14899 (* 1 = 5.14899 loss)
I0417 15:26:55.240264 12023 sgd_solver.cpp:106] Iteration 30464000, lr = 3.9063e-06
I0417 15:33:29.445511 12023 solver.cpp:237] Iteration 30515200, loss = 2.59089
I0417 15:33:29.445585 12023 solver.cpp:253]     Train net output #0: loss = 2.1652 (* 1 = 2.1652 loss)
I0417 15:33:29.445591 12023 sgd_solver.cpp:106] Iteration 30515200, lr = 3.9063e-06
I0417 15:40:02.184636 12023 solver.cpp:237] Iteration 30566400, loss = 2.58766
I0417 15:40:02.184696 12023 solver.cpp:253]     Train net output #0: loss = 1.485 (* 1 = 1.485 loss)
I0417 15:40:02.184702 12023 sgd_solver.cpp:106] Iteration 30566400, lr = 3.9063e-06
I0417 15:46:32.858376 12023 solver.cpp:237] Iteration 30617600, loss = 2.58813
I0417 15:46:32.858446 12023 solver.cpp:253]     Train net output #0: loss = 6.10934 (* 1 = 6.10934 loss)
I0417 15:46:32.858453 12023 sgd_solver.cpp:106] Iteration 30617600, lr = 3.9063e-06
I0417 15:53:06.762506 12023 solver.cpp:237] Iteration 30668800, loss = 2.56008
I0417 15:53:06.762590 12023 solver.cpp:253]     Train net output #0: loss = 1.71415 (* 1 = 1.71415 loss)
I0417 15:53:06.762600 12023 sgd_solver.cpp:106] Iteration 30668800, lr = 3.9063e-06
I0417 15:59:41.354794 12023 solver.cpp:459] Snapshotting to binary proto file snapshots/caffenet128_no_lrn_lsuv_relu_bs1_iter_30720000.caffemodel
I0417 15:59:41.907423 12023 sgd_solver.cpp:269] Snapshotting solver state to binary proto file snapshots/caffenet128_no_lrn_lsuv_relu_bs1_iter_30720000.solverstate
I0417 15:59:41.962266 12023 solver.cpp:341] Iteration 30720000, Testing net (#0)
I0417 16:00:02.108019 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0417 16:00:11.505918 12023 solver.cpp:409]     Test net output #0: accuracy = 0.43322
I0417 16:00:11.505997 12023 solver.cpp:409]     Test net output #1: loss = 2.58008 (* 1 = 2.58008 loss)
I0417 16:00:11.509949 12023 solver.cpp:237] Iteration 30720000, loss = 2.57264
I0417 16:00:11.509971 12023 solver.cpp:253]     Train net output #0: loss = 1.17849 (* 1 = 1.17849 loss)
I0417 16:00:11.509980 12023 sgd_solver.cpp:106] Iteration 30720000, lr = 3.9063e-06
I0417 16:06:41.013520 12023 solver.cpp:237] Iteration 30771200, loss = 2.66287
I0417 16:06:41.013582 12023 solver.cpp:253]     Train net output #0: loss = 0.00508514 (* 1 = 0.00508514 loss)
I0417 16:06:41.013593 12023 sgd_solver.cpp:106] Iteration 30771200, lr = 3.9063e-06
I0417 16:13:10.083431 12023 solver.cpp:237] Iteration 30822400, loss = 2.6355
I0417 16:13:10.083503 12023 solver.cpp:253]     Train net output #0: loss = 2.89773 (* 1 = 2.89773 loss)
I0417 16:13:10.083510 12023 sgd_solver.cpp:106] Iteration 30822400, lr = 3.9063e-06
I0417 16:19:45.646060 12023 solver.cpp:237] Iteration 30873600, loss = 2.66701
I0417 16:19:45.646133 12023 solver.cpp:253]     Train net output #0: loss = 1.47633 (* 1 = 1.47633 loss)
I0417 16:19:45.646142 12023 sgd_solver.cpp:106] Iteration 30873600, lr = 3.9063e-06
I0417 16:26:15.032703 12023 solver.cpp:237] Iteration 30924800, loss = 2.64698
I0417 16:26:15.032776 12023 solver.cpp:253]     Train net output #0: loss = 4.57842 (* 1 = 4.57842 loss)
I0417 16:26:15.032785 12023 sgd_solver.cpp:106] Iteration 30924800, lr = 3.9063e-06
I0417 16:32:44.459096 12023 solver.cpp:341] Iteration 30976000, Testing net (#0)
I0417 16:33:02.419152 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0417 16:33:10.857543 12023 solver.cpp:409]     Test net output #0: accuracy = 0.43476
I0417 16:33:10.857579 12023 solver.cpp:409]     Test net output #1: loss = 2.56839 (* 1 = 2.56839 loss)
I0417 16:33:10.861393 12023 solver.cpp:237] Iteration 30976000, loss = 2.6142
I0417 16:33:10.861416 12023 solver.cpp:253]     Train net output #0: loss = 0.922043 (* 1 = 0.922043 loss)
I0417 16:33:10.861428 12023 sgd_solver.cpp:106] Iteration 30976000, lr = 3.9063e-06
I0417 16:39:40.014549 12023 solver.cpp:237] Iteration 31027200, loss = 2.63385
I0417 16:39:40.014621 12023 solver.cpp:253]     Train net output #0: loss = 1.20789 (* 1 = 1.20789 loss)
I0417 16:39:40.014626 12023 sgd_solver.cpp:106] Iteration 31027200, lr = 3.9063e-06
I0417 16:46:13.096875 12023 solver.cpp:237] Iteration 31078400, loss = 2.63085
I0417 16:46:13.096946 12023 solver.cpp:253]     Train net output #0: loss = 1.0767 (* 1 = 1.0767 loss)
I0417 16:46:13.096953 12023 sgd_solver.cpp:106] Iteration 31078400, lr = 3.9063e-06
I0417 16:52:53.822576 12023 solver.cpp:237] Iteration 31129600, loss = 2.6303
I0417 16:52:53.822651 12023 solver.cpp:253]     Train net output #0: loss = 1.17717 (* 1 = 1.17717 loss)
I0417 16:52:53.822661 12023 sgd_solver.cpp:106] Iteration 31129600, lr = 3.9063e-06
I0417 16:59:36.513674 12023 solver.cpp:237] Iteration 31180800, loss = 2.61329
I0417 16:59:36.513749 12023 solver.cpp:253]     Train net output #0: loss = 0.162814 (* 1 = 0.162814 loss)
I0417 16:59:36.513758 12023 sgd_solver.cpp:106] Iteration 31180800, lr = 3.9063e-06
I0417 17:06:17.756456 12023 solver.cpp:341] Iteration 31232000, Testing net (#0)
I0417 17:06:35.955313 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0417 17:06:45.141098 12023 solver.cpp:409]     Test net output #0: accuracy = 0.4339
I0417 17:06:45.141131 12023 solver.cpp:409]     Test net output #1: loss = 2.5702 (* 1 = 2.5702 loss)
I0417 17:06:45.145083 12023 solver.cpp:237] Iteration 31232000, loss = 2.60612
I0417 17:06:45.145112 12023 solver.cpp:253]     Train net output #0: loss = 1.77942 (* 1 = 1.77942 loss)
I0417 17:06:45.145120 12023 sgd_solver.cpp:106] Iteration 31232000, lr = 3.9063e-06
I0417 17:13:27.420243 12023 solver.cpp:237] Iteration 31283200, loss = 2.59807
I0417 17:13:27.420315 12023 solver.cpp:253]     Train net output #0: loss = 5.02608 (* 1 = 5.02608 loss)
I0417 17:13:27.420322 12023 sgd_solver.cpp:106] Iteration 31283200, lr = 3.9063e-06
I0417 17:20:07.307528 12023 solver.cpp:237] Iteration 31334400, loss = 2.60761
I0417 17:20:07.307597 12023 solver.cpp:253]     Train net output #0: loss = 2.01914 (* 1 = 2.01914 loss)
I0417 17:20:07.307610 12023 sgd_solver.cpp:106] Iteration 31334400, lr = 3.9063e-06
I0417 17:26:37.635859 12023 solver.cpp:237] Iteration 31385600, loss = 2.60706
I0417 17:26:37.635933 12023 solver.cpp:253]     Train net output #0: loss = 0.000661771 (* 1 = 0.000661771 loss)
I0417 17:26:37.635944 12023 sgd_solver.cpp:106] Iteration 31385600, lr = 3.9063e-06
I0417 17:33:07.646106 12023 solver.cpp:237] Iteration 31436800, loss = 2.60688
I0417 17:33:07.646167 12023 solver.cpp:253]     Train net output #0: loss = 5.67955 (* 1 = 5.67955 loss)
I0417 17:33:07.646175 12023 sgd_solver.cpp:106] Iteration 31436800, lr = 3.9063e-06
I0417 17:39:37.174919 12023 solver.cpp:341] Iteration 31488000, Testing net (#0)
I0417 17:39:55.345280 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0417 17:40:03.763303 12023 solver.cpp:409]     Test net output #0: accuracy = 0.43658
I0417 17:40:03.763335 12023 solver.cpp:409]     Test net output #1: loss = 2.56269 (* 1 = 2.56269 loss)
I0417 17:40:03.767107 12023 solver.cpp:237] Iteration 31488000, loss = 2.61702
I0417 17:40:03.767132 12023 solver.cpp:253]     Train net output #0: loss = 6.61308 (* 1 = 6.61308 loss)
I0417 17:40:03.767140 12023 sgd_solver.cpp:106] Iteration 31488000, lr = 3.9063e-06
I0417 17:46:33.995592 12023 solver.cpp:237] Iteration 31539200, loss = 2.61061
I0417 17:46:33.995661 12023 solver.cpp:253]     Train net output #0: loss = 1.01685 (* 1 = 1.01685 loss)
I0417 17:46:33.995666 12023 sgd_solver.cpp:106] Iteration 31539200, lr = 3.9063e-06
I0417 17:53:04.623921 12023 solver.cpp:237] Iteration 31590400, loss = 2.60705
I0417 17:53:04.623987 12023 solver.cpp:253]     Train net output #0: loss = 3.72827 (* 1 = 3.72827 loss)
I0417 17:53:04.623996 12023 sgd_solver.cpp:106] Iteration 31590400, lr = 3.9063e-06
I0417 17:59:34.908638 12023 solver.cpp:237] Iteration 31641600, loss = 2.57595
I0417 17:59:34.908706 12023 solver.cpp:253]     Train net output #0: loss = 2.47749 (* 1 = 2.47749 loss)
I0417 17:59:34.908712 12023 sgd_solver.cpp:106] Iteration 31641600, lr = 3.9063e-06
I0417 18:06:05.150297 12023 solver.cpp:237] Iteration 31692800, loss = 2.5867
I0417 18:06:05.150357 12023 solver.cpp:253]     Train net output #0: loss = 0.739985 (* 1 = 0.739985 loss)
I0417 18:06:05.150362 12023 sgd_solver.cpp:106] Iteration 31692800, lr = 3.9063e-06
I0417 18:12:39.501646 12023 solver.cpp:341] Iteration 31744000, Testing net (#0)
I0417 18:12:58.270695 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0417 18:13:07.732372 12023 solver.cpp:409]     Test net output #0: accuracy = 0.43698
I0417 18:13:07.732403 12023 solver.cpp:409]     Test net output #1: loss = 2.55323 (* 1 = 2.55323 loss)
I0417 18:13:07.736138 12023 solver.cpp:237] Iteration 31744000, loss = 2.57283
I0417 18:13:07.736156 12023 solver.cpp:253]     Train net output #0: loss = 2.95689 (* 1 = 2.95689 loss)
I0417 18:13:07.736162 12023 sgd_solver.cpp:106] Iteration 31744000, lr = 3.9063e-06
I0417 18:19:42.729686 12023 solver.cpp:237] Iteration 31795200, loss = 2.56469
I0417 18:19:42.729786 12023 solver.cpp:253]     Train net output #0: loss = 0.466279 (* 1 = 0.466279 loss)
I0417 18:19:42.729792 12023 sgd_solver.cpp:106] Iteration 31795200, lr = 3.9063e-06
I0417 18:26:13.872490 12023 solver.cpp:237] Iteration 31846400, loss = 2.57338
I0417 18:26:13.872560 12023 solver.cpp:253]     Train net output #0: loss = 2.28694 (* 1 = 2.28694 loss)
I0417 18:26:13.872566 12023 sgd_solver.cpp:106] Iteration 31846400, lr = 3.9063e-06
I0417 18:32:42.894736 12023 solver.cpp:237] Iteration 31897600, loss = 2.5617
I0417 18:32:42.894804 12023 solver.cpp:253]     Train net output #0: loss = 2.81746 (* 1 = 2.81746 loss)
I0417 18:32:42.894811 12023 sgd_solver.cpp:106] Iteration 31897600, lr = 3.9063e-06
I0417 18:39:11.918037 12023 solver.cpp:237] Iteration 31948800, loss = 2.55459
I0417 18:39:11.918099 12023 solver.cpp:253]     Train net output #0: loss = 5.90812 (* 1 = 5.90812 loss)
I0417 18:39:11.918105 12023 sgd_solver.cpp:106] Iteration 31948800, lr = 3.9063e-06
I0417 18:45:42.121014 12023 solver.cpp:341] Iteration 32000000, Testing net (#0)
I0417 18:45:57.849084 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0417 18:46:08.574832 12023 solver.cpp:409]     Test net output #0: accuracy = 0.43532
I0417 18:46:08.574903 12023 solver.cpp:409]     Test net output #1: loss = 2.5592 (* 1 = 2.5592 loss)
I0417 18:46:08.578666 12023 solver.cpp:237] Iteration 32000000, loss = 2.55393
I0417 18:46:08.578685 12023 solver.cpp:253]     Train net output #0: loss = 2.68433 (* 1 = 2.68433 loss)
I0417 18:46:08.578694 12023 sgd_solver.cpp:106] Iteration 32000000, lr = 3.9063e-06
I0417 18:52:38.693878 12023 solver.cpp:237] Iteration 32051200, loss = 2.63092
I0417 18:52:38.693949 12023 solver.cpp:253]     Train net output #0: loss = 1.20132 (* 1 = 1.20132 loss)
I0417 18:52:38.693955 12023 sgd_solver.cpp:106] Iteration 32051200, lr = 3.9063e-06
I0417 18:59:08.802767 12023 solver.cpp:237] Iteration 32102400, loss = 2.61793
I0417 18:59:08.802837 12023 solver.cpp:253]     Train net output #0: loss = 0.398867 (* 1 = 0.398867 loss)
I0417 18:59:08.802846 12023 sgd_solver.cpp:106] Iteration 32102400, lr = 3.9063e-06
I0417 19:05:38.892356 12023 solver.cpp:237] Iteration 32153600, loss = 2.63486
I0417 19:05:38.892462 12023 solver.cpp:253]     Train net output #0: loss = 9.88725 (* 1 = 9.88725 loss)
I0417 19:05:38.892480 12023 sgd_solver.cpp:106] Iteration 32153600, lr = 3.9063e-06
I0417 19:12:08.937495 12023 solver.cpp:237] Iteration 32204800, loss = 2.61965
I0417 19:12:08.937566 12023 solver.cpp:253]     Train net output #0: loss = 0.138776 (* 1 = 0.138776 loss)
I0417 19:12:08.937575 12023 sgd_solver.cpp:106] Iteration 32204800, lr = 3.9063e-06
I0417 19:18:39.401000 12023 solver.cpp:341] Iteration 32256000, Testing net (#0)
I0417 19:18:56.946244 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0417 19:19:08.953560 12023 solver.cpp:409]     Test net output #0: accuracy = 0.43744
I0417 19:19:08.953601 12023 solver.cpp:409]     Test net output #1: loss = 2.55395 (* 1 = 2.55395 loss)
I0417 19:19:08.957545 12023 solver.cpp:237] Iteration 32256000, loss = 2.60182
I0417 19:19:08.957566 12023 solver.cpp:253]     Train net output #0: loss = 5.24255 (* 1 = 5.24255 loss)
I0417 19:19:08.957576 12023 sgd_solver.cpp:106] Iteration 32256000, lr = 3.9063e-06
I0417 19:25:39.239226 12023 solver.cpp:237] Iteration 32307200, loss = 2.61019
I0417 19:25:39.239300 12023 solver.cpp:253]     Train net output #0: loss = 1.69043 (* 1 = 1.69043 loss)
I0417 19:25:39.239305 12023 sgd_solver.cpp:106] Iteration 32307200, lr = 3.9063e-06
I0417 19:32:09.476388 12023 solver.cpp:237] Iteration 32358400, loss = 2.61589
I0417 19:32:09.476450 12023 solver.cpp:253]     Train net output #0: loss = 0.492515 (* 1 = 0.492515 loss)
I0417 19:32:09.476456 12023 sgd_solver.cpp:106] Iteration 32358400, lr = 3.9063e-06
I0417 19:38:40.148500 12023 solver.cpp:237] Iteration 32409600, loss = 2.60432
I0417 19:38:40.148576 12023 solver.cpp:253]     Train net output #0: loss = 1.63242 (* 1 = 1.63242 loss)
I0417 19:38:40.148586 12023 sgd_solver.cpp:106] Iteration 32409600, lr = 3.9063e-06
I0417 19:45:09.674296 12023 solver.cpp:237] Iteration 32460800, loss = 2.60977
I0417 19:45:09.674387 12023 solver.cpp:253]     Train net output #0: loss = 4.08026 (* 1 = 4.08026 loss)
I0417 19:45:09.674396 12023 sgd_solver.cpp:106] Iteration 32460800, lr = 3.9063e-06
I0417 19:51:38.696458 12023 solver.cpp:341] Iteration 32512000, Testing net (#0)
I0417 19:51:54.514899 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0417 19:52:05.141676 12023 solver.cpp:409]     Test net output #0: accuracy = 0.43586
I0417 19:52:05.141711 12023 solver.cpp:409]     Test net output #1: loss = 2.55559 (* 1 = 2.55559 loss)
I0417 19:52:05.145510 12023 solver.cpp:237] Iteration 32512000, loss = 2.59065
I0417 19:52:05.145529 12023 solver.cpp:253]     Train net output #0: loss = 3.01963 (* 1 = 3.01963 loss)
I0417 19:52:05.145539 12023 sgd_solver.cpp:106] Iteration 32512000, lr = 3.9063e-06
I0417 19:58:34.266072 12023 solver.cpp:237] Iteration 32563200, loss = 2.57606
I0417 19:58:34.266145 12023 solver.cpp:253]     Train net output #0: loss = 5.29603 (* 1 = 5.29603 loss)
I0417 19:58:34.266154 12023 sgd_solver.cpp:106] Iteration 32563200, lr = 3.9063e-06
I0417 20:05:03.479315 12023 solver.cpp:237] Iteration 32614400, loss = 2.59351
I0417 20:05:03.479398 12023 solver.cpp:253]     Train net output #0: loss = 0.840253 (* 1 = 0.840253 loss)
I0417 20:05:03.479408 12023 sgd_solver.cpp:106] Iteration 32614400, lr = 3.9063e-06
I0417 20:11:32.505355 12023 solver.cpp:237] Iteration 32665600, loss = 2.58605
I0417 20:11:32.505429 12023 solver.cpp:253]     Train net output #0: loss = 0.386089 (* 1 = 0.386089 loss)
I0417 20:11:32.505437 12023 sgd_solver.cpp:106] Iteration 32665600, lr = 3.9063e-06
I0417 20:18:01.516628 12023 solver.cpp:237] Iteration 32716800, loss = 2.58931
I0417 20:18:01.516700 12023 solver.cpp:253]     Train net output #0: loss = 7.76253 (* 1 = 7.76253 loss)
I0417 20:18:01.516707 12023 sgd_solver.cpp:106] Iteration 32716800, lr = 3.9063e-06
I0417 20:24:30.523139 12023 solver.cpp:341] Iteration 32768000, Testing net (#0)
I0417 20:24:46.403713 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0417 20:24:56.980118 12023 solver.cpp:409]     Test net output #0: accuracy = 0.43938
I0417 20:24:56.980152 12023 solver.cpp:409]     Test net output #1: loss = 2.54711 (* 1 = 2.54711 loss)
I0417 20:24:56.983963 12023 solver.cpp:237] Iteration 32768000, loss = 2.59637
I0417 20:24:56.983983 12023 solver.cpp:253]     Train net output #0: loss = 1.09172 (* 1 = 1.09172 loss)
I0417 20:24:56.983994 12023 sgd_solver.cpp:106] Iteration 32768000, lr = 3.9063e-06
I0417 20:31:28.143334 12023 solver.cpp:237] Iteration 32819200, loss = 2.59667
I0417 20:31:28.143394 12023 solver.cpp:253]     Train net output #0: loss = 3.29171 (* 1 = 3.29171 loss)
I0417 20:31:28.143400 12023 sgd_solver.cpp:106] Iteration 32819200, lr = 3.9063e-06
I0417 20:38:03.354297 12023 solver.cpp:237] Iteration 32870400, loss = 2.58422
I0417 20:38:03.354358 12023 solver.cpp:253]     Train net output #0: loss = 4.97751 (* 1 = 4.97751 loss)
I0417 20:38:03.354365 12023 sgd_solver.cpp:106] Iteration 32870400, lr = 3.9063e-06
I0417 20:44:34.406812 12023 solver.cpp:237] Iteration 32921600, loss = 2.56636
I0417 20:44:34.406883 12023 solver.cpp:253]     Train net output #0: loss = 1.76236 (* 1 = 1.76236 loss)
I0417 20:44:34.406889 12023 sgd_solver.cpp:106] Iteration 32921600, lr = 3.9063e-06
I0417 20:51:04.046246 12023 solver.cpp:237] Iteration 32972800, loss = 2.56923
I0417 20:51:04.046298 12023 solver.cpp:253]     Train net output #0: loss = 0.0575778 (* 1 = 0.0575778 loss)
I0417 20:51:04.046304 12023 sgd_solver.cpp:106] Iteration 32972800, lr = 3.9063e-06
I0417 20:57:37.511507 12023 solver.cpp:341] Iteration 33024000, Testing net (#0)
I0417 20:57:53.952163 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0417 20:58:07.040676 12023 solver.cpp:409]     Test net output #0: accuracy = 0.43834
I0417 20:58:07.040717 12023 solver.cpp:409]     Test net output #1: loss = 2.54316 (* 1 = 2.54316 loss)
I0417 20:58:07.044668 12023 solver.cpp:237] Iteration 33024000, loss = 2.55292
I0417 20:58:07.044716 12023 solver.cpp:253]     Train net output #0: loss = 0.0144821 (* 1 = 0.0144821 loss)
I0417 20:58:07.044728 12023 sgd_solver.cpp:106] Iteration 33024000, lr = 3.9063e-06
I0417 21:04:41.563928 12023 solver.cpp:237] Iteration 33075200, loss = 2.55189
I0417 21:04:41.564004 12023 solver.cpp:253]     Train net output #0: loss = 2.75322 (* 1 = 2.75322 loss)
I0417 21:04:41.564013 12023 sgd_solver.cpp:106] Iteration 33075200, lr = 3.9063e-06
I0417 21:11:16.220650 12023 solver.cpp:237] Iteration 33126400, loss = 2.54623
I0417 21:11:16.220726 12023 solver.cpp:253]     Train net output #0: loss = 3.52123 (* 1 = 3.52123 loss)
I0417 21:11:16.220739 12023 sgd_solver.cpp:106] Iteration 33126400, lr = 3.9063e-06
I0417 21:17:48.366449 12023 solver.cpp:237] Iteration 33177600, loss = 2.55582
I0417 21:17:48.366516 12023 solver.cpp:253]     Train net output #0: loss = 0.197885 (* 1 = 0.197885 loss)
I0417 21:17:48.366529 12023 sgd_solver.cpp:106] Iteration 33177600, lr = 3.9063e-06
I0417 21:24:18.857004 12023 solver.cpp:237] Iteration 33228800, loss = 2.53282
I0417 21:24:18.857081 12023 solver.cpp:253]     Train net output #0: loss = 1.08358 (* 1 = 1.08358 loss)
I0417 21:24:18.857094 12023 sgd_solver.cpp:106] Iteration 33228800, lr = 3.9063e-06
I0417 21:30:48.477289 12023 solver.cpp:459] Snapshotting to binary proto file snapshots/caffenet128_no_lrn_lsuv_relu_bs1_iter_33280000.caffemodel
I0417 21:30:49.232223 12023 sgd_solver.cpp:269] Snapshotting solver state to binary proto file snapshots/caffenet128_no_lrn_lsuv_relu_bs1_iter_33280000.solverstate
I0417 21:30:49.296442 12023 solver.cpp:341] Iteration 33280000, Testing net (#0)
I0417 21:31:02.619760 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0417 21:31:15.696496 12023 solver.cpp:409]     Test net output #0: accuracy = 0.43816
I0417 21:31:15.696530 12023 solver.cpp:409]     Test net output #1: loss = 2.556 (* 1 = 2.556 loss)
I0417 21:31:15.700319 12023 solver.cpp:237] Iteration 33280000, loss = 2.54583
I0417 21:31:15.700340 12023 solver.cpp:253]     Train net output #0: loss = 8.27282 (* 1 = 8.27282 loss)
I0417 21:31:15.700350 12023 sgd_solver.cpp:106] Iteration 33280000, lr = 3.9063e-06
I0417 21:37:49.074717 12023 solver.cpp:237] Iteration 33331200, loss = 2.61308
I0417 21:37:49.074790 12023 solver.cpp:253]     Train net output #0: loss = 3.13948 (* 1 = 3.13948 loss)
I0417 21:37:49.074796 12023 sgd_solver.cpp:106] Iteration 33331200, lr = 3.9063e-06
I0417 21:44:18.863277 12023 solver.cpp:237] Iteration 33382400, loss = 2.59483
I0417 21:44:18.863345 12023 solver.cpp:253]     Train net output #0: loss = 4.60123 (* 1 = 4.60123 loss)
I0417 21:44:18.863351 12023 sgd_solver.cpp:106] Iteration 33382400, lr = 3.9063e-06
I0417 21:50:48.695435 12023 solver.cpp:237] Iteration 33433600, loss = 2.61464
I0417 21:50:48.695504 12023 solver.cpp:253]     Train net output #0: loss = 1.96484 (* 1 = 1.96484 loss)
I0417 21:50:48.695509 12023 sgd_solver.cpp:106] Iteration 33433600, lr = 3.9063e-06
I0417 21:57:20.147825 12023 solver.cpp:237] Iteration 33484800, loss = 2.60309
I0417 21:57:20.147886 12023 solver.cpp:253]     Train net output #0: loss = 3.42032 (* 1 = 3.42032 loss)
I0417 21:57:20.147897 12023 sgd_solver.cpp:106] Iteration 33484800, lr = 3.9063e-06
I0417 22:03:53.431669 12023 solver.cpp:341] Iteration 33536000, Testing net (#0)
I0417 22:04:08.225877 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0417 22:04:22.968732 12023 solver.cpp:409]     Test net output #0: accuracy = 0.44064
I0417 22:04:22.968770 12023 solver.cpp:409]     Test net output #1: loss = 2.53919 (* 1 = 2.53919 loss)
I0417 22:04:22.972681 12023 solver.cpp:237] Iteration 33536000, loss = 2.58499
I0417 22:04:22.972702 12023 solver.cpp:253]     Train net output #0: loss = 1.0902 (* 1 = 1.0902 loss)
I0417 22:04:22.972709 12023 sgd_solver.cpp:106] Iteration 33536000, lr = 3.9063e-06
I0417 22:10:52.658514 12023 solver.cpp:237] Iteration 33587200, loss = 2.58374
I0417 22:10:52.658584 12023 solver.cpp:253]     Train net output #0: loss = 3.30184 (* 1 = 3.30184 loss)
I0417 22:10:52.658591 12023 sgd_solver.cpp:106] Iteration 33587200, lr = 3.9063e-06
I0417 22:17:24.024022 12023 solver.cpp:237] Iteration 33638400, loss = 2.59587
I0417 22:17:24.024119 12023 solver.cpp:253]     Train net output #0: loss = 0.0631448 (* 1 = 0.0631448 loss)
I0417 22:17:24.024129 12023 sgd_solver.cpp:106] Iteration 33638400, lr = 3.9063e-06
I0417 22:23:53.521281 12023 solver.cpp:237] Iteration 33689600, loss = 2.58298
I0417 22:23:53.521353 12023 solver.cpp:253]     Train net output #0: loss = 0.024552 (* 1 = 0.024552 loss)
I0417 22:23:53.521363 12023 sgd_solver.cpp:106] Iteration 33689600, lr = 3.9063e-06
I0417 22:30:22.713811 12023 solver.cpp:237] Iteration 33740800, loss = 2.58197
I0417 22:30:22.713874 12023 solver.cpp:253]     Train net output #0: loss = 3.50709 (* 1 = 3.50709 loss)
I0417 22:30:22.713882 12023 sgd_solver.cpp:106] Iteration 33740800, lr = 3.9063e-06
I0417 22:36:51.715127 12023 solver.cpp:341] Iteration 33792000, Testing net (#0)
I0417 22:37:04.997694 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0417 22:37:18.132310 12023 solver.cpp:409]     Test net output #0: accuracy = 0.43886
I0417 22:37:18.132385 12023 solver.cpp:409]     Test net output #1: loss = 2.53963 (* 1 = 2.53963 loss)
I0417 22:37:18.136159 12023 solver.cpp:237] Iteration 33792000, loss = 2.56345
I0417 22:37:18.136199 12023 solver.cpp:253]     Train net output #0: loss = 3.98396 (* 1 = 3.98396 loss)
I0417 22:37:18.136209 12023 sgd_solver.cpp:106] Iteration 33792000, lr = 3.9063e-06
I0417 22:43:47.237495 12023 solver.cpp:237] Iteration 33843200, loss = 2.56488
I0417 22:43:47.237571 12023 solver.cpp:253]     Train net output #0: loss = 2.92343 (* 1 = 2.92343 loss)
I0417 22:43:47.237579 12023 sgd_solver.cpp:106] Iteration 33843200, lr = 3.9063e-06
I0417 22:50:16.397403 12023 solver.cpp:237] Iteration 33894400, loss = 2.57491
I0417 22:50:16.397475 12023 solver.cpp:253]     Train net output #0: loss = 3.28546 (* 1 = 3.28546 loss)
I0417 22:50:16.397483 12023 sgd_solver.cpp:106] Iteration 33894400, lr = 3.9063e-06
I0417 22:56:45.440006 12023 solver.cpp:237] Iteration 33945600, loss = 2.56949
I0417 22:56:45.440079 12023 solver.cpp:253]     Train net output #0: loss = 1.36597 (* 1 = 1.36597 loss)
I0417 22:56:45.440086 12023 sgd_solver.cpp:106] Iteration 33945600, lr = 3.9063e-06
I0417 23:03:14.761090 12023 solver.cpp:237] Iteration 33996800, loss = 2.56722
I0417 23:03:14.761150 12023 solver.cpp:253]     Train net output #0: loss = 3.57483 (* 1 = 3.57483 loss)
I0417 23:03:14.761155 12023 sgd_solver.cpp:106] Iteration 33996800, lr = 3.9063e-06
I0417 23:09:54.249236 12023 solver.cpp:341] Iteration 34048000, Testing net (#0)
I0417 23:10:09.194558 12023 blocking_queue.cpp:50] Data layer prefetch queue empty
I0417 23:10:16.534504 12023 solver.cpp:391] Test interrupted.
I0417 23:10:16.534564 12023 solver.cpp:459] Snapshotting to binary proto file snapshots/caffenet128_no_lrn_lsuv_relu_bs1_iter_34048000.caffemodel
I0417 23:10:17.483687 12023 sgd_solver.cpp:269] Snapshotting solver state to binary proto file snapshots/caffenet128_no_lrn_lsuv_relu_bs1_iter_34048000.solverstate
I0417 23:10:17.542567 12023 solver.cpp:309] Optimization stopped early.
I0417 23:10:17.544034 12023 caffe.cpp:215] Optimization Done.
F0417 23:51:48.103909 10742 io.cpp:36] Check failed: fd != -1 (-1 vs. -1) File not found: caffenet128_lsuv_online_lr0000039063.prototxt
*** Check failure stack trace: ***
    @     0x7ffa9e0cbdaa  (unknown)
    @     0x7ffa9e0cbce4  (unknown)
    @     0x7ffa9e0cb6e6  (unknown)
    @     0x7ffa9e0ce687  (unknown)
    @     0x7ffa9e6ce4fd  caffe::ReadProtoFromTextFile()
    @     0x7ffa9e6d8034  caffe::ReadSolverParamsFromTextFileOrDie()
    @           0x407a3b  train()
    @           0x4059bc  main
    @     0x7ffa9d3d9ec5  (unknown)
    @           0x4060f1  (unknown)
    @              (nil)  (unknown)
I0417 23:53:11.311671 10752 upgrade_proto.cpp:1044] Attempting to upgrade input file specified using deprecated 'solver_type' field (enum)': done/caffenet128_lsuv_online_lr0000039063.prototxt
I0417 23:53:11.312052 10752 upgrade_proto.cpp:1051] Successfully upgraded file specified using deprecated 'solver_type' field (enum) to 'type' field (string).
W0417 23:53:11.312062 10752 upgrade_proto.cpp:1053] Note that future Caffe releases will only support 'type' field (string) for a solver's type.
I0417 23:53:11.312188 10752 caffe.cpp:185] Using GPUs 0
I0417 23:53:11.323328 10752 caffe.cpp:190] GPU 0: GeForce GTX TITAN X
I0417 23:53:11.483422 10752 solver.cpp:48] Initializing solver from parameters: 
test_iter: 1000
test_interval: 256000
base_lr: 3.9063e-05
display: 51200
max_iter: 81920000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 25600000
snapshot: 2560000
snapshot_prefix: "snapshots/caffenet128_no_lrn_lsuv_relu_bs1"
solver_mode: GPU
device_id: 0
net_param {
  name: "CaffeNet"
  layer {
    name: "data"
    type: "Data"
    top: "data"
    top: "label"
    include {
      phase: TRAIN
    }
    transform_param {
      scale: 0.04
      mirror: true
      crop_size: 128
      mean_value: 104
      mean_value: 117
      mean_value: 124
      force_color: true
    }
    data_param {
      source: "/home/old-ufo/storage/datasets/imagenet/imgs128/lmdb/ilsvrc12_128_train_lmdb"
      batch_size: 1
      backend: LMDB
    }
  }
  layer {
    name: "data"
    type: "Data"
    top: "data"
    top: "label"
    include {
      phase: TEST
    }
    transform_param {
      scale: 0.04
      mirror: false
      crop_size: 128
      mean_value: 104
      mean_value: 117
      mean_value: 123
      force_color: true
    }
    data_param {
      source: "/home/old-ufo/storage/datasets/imagenet/imgs128/lmdb/ilsvrc12_128_val_lmdb"
      batch_size: 50
      backend: LMDB
    }
  }
  layer {
    name: "conv1"
    type: "Convolution"
    bottom: "data"
    top: "conv1"
    param {
      lr_mult: 1
      decay_mult: 1
    }
    param {
      lr_mult: 2
      decay_mult: 0
    }
    convolution_param {
      num_output: 96
      kernel_size: 11
      stride: 4
      weight_filler {
        type: "gaussian"
        std: 0.01
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layer {
    name: "relu1"
    type: "ReLU"
    bottom: "conv1"
    top: "relu1"
  }
  layer {
    name: "pool1"
    type: "Pooling"
    bottom: "relu1"
    top: "pool1"
    pooling_param {
      pool: MAX
      kernel_size: 3
      stride: 2
    }
  }
  layer {
    name: "conv2"
    type: "Convolution"
    bottom: "pool1"
    top: "conv2"
    param {
      lr_mult: 1
      decay_mult: 1
    }
    param {
      lr_mult: 2
      decay_mult: 0
    }
    convolution_param {
      num_output: 256
      pad: 2
      kernel_size: 5
      group: 2
      weight_filler {
        type: "gaussian"
        std: 0.01
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layer {
    name: "relu2"
    type: "ReLU"
    bottom: "conv2"
    top: "relu2"
  }
  layer {
    name: "pool2"
    type: "Pooling"
    bottom: "relu2"
    top: "pool2"
    pooling_param {
      pool: MAX
      kernel_size: 3
      stride: 2
    }
  }
  layer {
    name: "conv3"
    type: "Convolution"
    bottom: "pool2"
    top: "conv3"
    param {
      lr_mult: 1
      decay_mult: 1
    }
    param {
      lr_mult: 2
      decay_mult: 0
    }
    convolution_param {
      num_output: 384
      pad: 1
      kernel_size: 3
      weight_filler {
        type: "gaussian"
        std: 0.01
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layer {
    name: "relu3"
    type: "ReLU"
    bottom: "conv3"
    top: "relu3"
  }
  layer {
    name: "conv4"
    type: "Convolution"
    bottom: "relu3"
    top: "conv4"
    param {
      lr_mult: 1
      decay_mult: 1
    }
    param {
      lr_mult: 2
      decay_mult: 0
    }
    convolution_param {
      num_output: 384
      pad: 1
      kernel_size: 3
      group: 2
      weight_filler {
        type: "gaussian"
        std: 0.01
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layer {
    name: "relu4"
    type: "ReLU"
    bottom: "conv4"
    top: "relu4"
  }
  layer {
    name: "conv5"
    type: "Convolution"
    bottom: "relu4"
    top: "conv5"
    param {
      lr_mult: 1
      decay_mult: 1
    }
    param {
      lr_mult: 2
      decay_mult: 0
    }
    convolution_param {
      num_output: 256
      pad: 1
      kernel_size: 3
      group: 2
      weight_filler {
        type: "gaussian"
        std: 0.01
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layer {
    name: "relu5"
    type: "ReLU"
    bottom: "conv5"
    top: "relu5"
  }
  layer {
    name: "pool5"
    type: "Pooling"
    bottom: "relu5"
    top: "pool5"
    pooling_param {
      pool: MAX
      kernel_size: 3
      stride: 2
    }
  }
  layer {
    name: "fc6"
    type: "InnerProduct"
    bottom: "pool5"
    top: "fc6"
    param {
      lr_mult: 1
      decay_mult: 1
    }
    param {
      lr_mult: 2
      decay_mult: 0
    }
    inner_product_param {
      num_output: 2048
      weight_filler {
        type: "gaussian"
        std: 0.005
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layer {
    name: "relu6"
    type: "ReLU"
    bottom: "fc6"
    top: "relu6"
  }
  layer {
    name: "drop6"
    type: "Dropout"
    bottom: "relu6"
    top: "drop6"
    dropout_param {
      dropout_ratio: 0.5
    }
  }
  layer {
    name: "fc7"
    type: "InnerProduct"
    bottom: "drop6"
    top: "fc7"
    param {
      lr_mult: 1
      decay_mult: 1
    }
    param {
      lr_mult: 2
      decay_mult: 0
    }
    inner_product_param {
      num_output: 2048
      weight_filler {
        type: "gaussian"
        std: 0.005
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layer {
    name: "relu7"
    type: "ReLU"
    bottom: "fc7"
    top: "relu7"
  }
  layer {
    name: "drop7"
    type: "Dropout"
    bottom: "relu7"
    top: "drop7"
    dropout_param {
      dropout_ratio: 0.5
    }
  }
  layer {
    name: "fc8"
    type: "InnerProduct"
    bottom: "drop7"
    top: "fc8"
    param {
      lr_mult: 1
      decay_mult: 1
    }
    param {
      lr_mult: 2
      decay_mult: 0
    }
    inner_product_param {
      num_output: 1000
      weight_filler {
        type: "gaussian"
        std: 0.01
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layer {
    name: "accuracy"
    type: "Accuracy"
    bottom: "fc8"
    bottom: "label"
    top: "accuracy"
    include {
      phase: TEST
    }
  }
  layer {
    name: "loss"
    type: "SoftmaxWithLoss"
    bottom: "fc8"
    bottom: "label"
    top: "loss"
  }
}
test_initialization: true
average_loss: 51200
iter_size: 1
type: "SGD"
I0417 23:53:11.483602 10752 solver.cpp:86] Creating training net specified in net_param.
I0417 23:53:11.483710 10752 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0417 23:53:11.483736 10752 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0417 23:53:11.483937 10752 net.cpp:49] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.04
    mirror: true
    crop_size: 128
    mean_value: 104
    mean_value: 117
    mean_value: 124
    force_color: true
  }
  data_param {
    source: "/home/old-ufo/storage/datasets/imagenet/imgs128/lmdb/ilsvrc12_128_train_lmdb"
    batch_size: 1
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "relu1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "relu1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "relu2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "relu2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "relu3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "relu3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "relu4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "relu4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "relu5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "relu5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "relu6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "relu6"
  top: "drop6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "drop6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "relu7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "relu7"
  top: "drop7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "drop7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0417 23:53:11.484043 10752 layer_factory.hpp:77] Creating layer data
I0417 23:53:11.484447 10752 net.cpp:91] Creating Layer data
I0417 23:53:11.484454 10752 net.cpp:399] data -> data
I0417 23:53:11.484475 10752 net.cpp:399] data -> label
I0417 23:53:11.679149 10758 db_lmdb.cpp:38] Opened lmdb /home/old-ufo/storage/datasets/imagenet/imgs128/lmdb/ilsvrc12_128_train_lmdb
I0417 23:53:11.687579 10752 data_layer.cpp:41] output data size: 1,3,128,128
I0417 23:53:11.688335 10752 net.cpp:141] Setting up data
I0417 23:53:11.688352 10752 net.cpp:148] Top shape: 1 3 128 128 (49152)
I0417 23:53:11.688376 10752 net.cpp:148] Top shape: 1 (1)
I0417 23:53:11.688382 10752 net.cpp:156] Memory required for data: 196612
I0417 23:53:11.688395 10752 layer_factory.hpp:77] Creating layer conv1
I0417 23:53:11.688422 10752 net.cpp:91] Creating Layer conv1
I0417 23:53:11.688431 10752 net.cpp:425] conv1 <- data
I0417 23:53:11.688449 10752 net.cpp:399] conv1 -> conv1
I0417 23:53:11.819829 10752 net.cpp:141] Setting up conv1
I0417 23:53:11.819859 10752 net.cpp:148] Top shape: 1 96 30 30 (86400)
I0417 23:53:11.819864 10752 net.cpp:156] Memory required for data: 542212
I0417 23:53:11.819882 10752 layer_factory.hpp:77] Creating layer relu1
I0417 23:53:11.819900 10752 net.cpp:91] Creating Layer relu1
I0417 23:53:11.819910 10752 net.cpp:425] relu1 <- conv1
I0417 23:53:11.819919 10752 net.cpp:399] relu1 -> relu1
I0417 23:53:11.820173 10752 net.cpp:141] Setting up relu1
I0417 23:53:11.820184 10752 net.cpp:148] Top shape: 1 96 30 30 (86400)
I0417 23:53:11.820188 10752 net.cpp:156] Memory required for data: 887812
I0417 23:53:11.820190 10752 layer_factory.hpp:77] Creating layer pool1
I0417 23:53:11.820199 10752 net.cpp:91] Creating Layer pool1
I0417 23:53:11.820201 10752 net.cpp:425] pool1 <- relu1
I0417 23:53:11.820207 10752 net.cpp:399] pool1 -> pool1
I0417 23:53:11.820260 10752 net.cpp:141] Setting up pool1
I0417 23:53:11.820266 10752 net.cpp:148] Top shape: 1 96 15 15 (21600)
I0417 23:53:11.820269 10752 net.cpp:156] Memory required for data: 974212
I0417 23:53:11.820271 10752 layer_factory.hpp:77] Creating layer conv2
I0417 23:53:11.820282 10752 net.cpp:91] Creating Layer conv2
I0417 23:53:11.820286 10752 net.cpp:425] conv2 <- pool1
I0417 23:53:11.820293 10752 net.cpp:399] conv2 -> conv2
I0417 23:53:11.829241 10752 net.cpp:141] Setting up conv2
I0417 23:53:11.829252 10752 net.cpp:148] Top shape: 1 256 15 15 (57600)
I0417 23:53:11.829255 10752 net.cpp:156] Memory required for data: 1204612
I0417 23:53:11.829263 10752 layer_factory.hpp:77] Creating layer relu2
I0417 23:53:11.829269 10752 net.cpp:91] Creating Layer relu2
I0417 23:53:11.829273 10752 net.cpp:425] relu2 <- conv2
I0417 23:53:11.829279 10752 net.cpp:399] relu2 -> relu2
I0417 23:53:11.829510 10752 net.cpp:141] Setting up relu2
I0417 23:53:11.829519 10752 net.cpp:148] Top shape: 1 256 15 15 (57600)
I0417 23:53:11.829522 10752 net.cpp:156] Memory required for data: 1435012
I0417 23:53:11.829525 10752 layer_factory.hpp:77] Creating layer pool2
I0417 23:53:11.829530 10752 net.cpp:91] Creating Layer pool2
I0417 23:53:11.829533 10752 net.cpp:425] pool2 <- relu2
I0417 23:53:11.829537 10752 net.cpp:399] pool2 -> pool2
I0417 23:53:11.829576 10752 net.cpp:141] Setting up pool2
I0417 23:53:11.829584 10752 net.cpp:148] Top shape: 1 256 7 7 (12544)
I0417 23:53:11.829587 10752 net.cpp:156] Memory required for data: 1485188
I0417 23:53:11.829589 10752 layer_factory.hpp:77] Creating layer conv3
I0417 23:53:11.829597 10752 net.cpp:91] Creating Layer conv3
I0417 23:53:11.829601 10752 net.cpp:425] conv3 <- pool2
I0417 23:53:11.829607 10752 net.cpp:399] conv3 -> conv3
I0417 23:53:11.853426 10752 net.cpp:141] Setting up conv3
I0417 23:53:11.853451 10752 net.cpp:148] Top shape: 1 384 7 7 (18816)
I0417 23:53:11.853454 10752 net.cpp:156] Memory required for data: 1560452
I0417 23:53:11.853466 10752 layer_factory.hpp:77] Creating layer relu3
I0417 23:53:11.853477 10752 net.cpp:91] Creating Layer relu3
I0417 23:53:11.853482 10752 net.cpp:425] relu3 <- conv3
I0417 23:53:11.853490 10752 net.cpp:399] relu3 -> relu3
I0417 23:53:11.853644 10752 net.cpp:141] Setting up relu3
I0417 23:53:11.853653 10752 net.cpp:148] Top shape: 1 384 7 7 (18816)
I0417 23:53:11.853655 10752 net.cpp:156] Memory required for data: 1635716
I0417 23:53:11.853658 10752 layer_factory.hpp:77] Creating layer conv4
I0417 23:53:11.853667 10752 net.cpp:91] Creating Layer conv4
I0417 23:53:11.853670 10752 net.cpp:425] conv4 <- relu3
I0417 23:53:11.853677 10752 net.cpp:399] conv4 -> conv4
I0417 23:53:11.871747 10752 net.cpp:141] Setting up conv4
I0417 23:53:11.871769 10752 net.cpp:148] Top shape: 1 384 7 7 (18816)
I0417 23:53:11.871790 10752 net.cpp:156] Memory required for data: 1710980
I0417 23:53:11.871799 10752 layer_factory.hpp:77] Creating layer relu4
I0417 23:53:11.871812 10752 net.cpp:91] Creating Layer relu4
I0417 23:53:11.871820 10752 net.cpp:425] relu4 <- conv4
I0417 23:53:11.871829 10752 net.cpp:399] relu4 -> relu4
I0417 23:53:11.871994 10752 net.cpp:141] Setting up relu4
I0417 23:53:11.872002 10752 net.cpp:148] Top shape: 1 384 7 7 (18816)
I0417 23:53:11.872004 10752 net.cpp:156] Memory required for data: 1786244
I0417 23:53:11.872007 10752 layer_factory.hpp:77] Creating layer conv5
I0417 23:53:11.872020 10752 net.cpp:91] Creating Layer conv5
I0417 23:53:11.872022 10752 net.cpp:425] conv5 <- relu4
I0417 23:53:11.872031 10752 net.cpp:399] conv5 -> conv5
I0417 23:53:11.885275 10752 net.cpp:141] Setting up conv5
I0417 23:53:11.885298 10752 net.cpp:148] Top shape: 1 256 7 7 (12544)
I0417 23:53:11.885301 10752 net.cpp:156] Memory required for data: 1836420
I0417 23:53:11.885314 10752 layer_factory.hpp:77] Creating layer relu5
I0417 23:53:11.885324 10752 net.cpp:91] Creating Layer relu5
I0417 23:53:11.885329 10752 net.cpp:425] relu5 <- conv5
I0417 23:53:11.885336 10752 net.cpp:399] relu5 -> relu5
I0417 23:53:11.885509 10752 net.cpp:141] Setting up relu5
I0417 23:53:11.885519 10752 net.cpp:148] Top shape: 1 256 7 7 (12544)
I0417 23:53:11.885521 10752 net.cpp:156] Memory required for data: 1886596
I0417 23:53:11.885524 10752 layer_factory.hpp:77] Creating layer pool5
I0417 23:53:11.885531 10752 net.cpp:91] Creating Layer pool5
I0417 23:53:11.885535 10752 net.cpp:425] pool5 <- relu5
I0417 23:53:11.885538 10752 net.cpp:399] pool5 -> pool5
I0417 23:53:11.885582 10752 net.cpp:141] Setting up pool5
I0417 23:53:11.885588 10752 net.cpp:148] Top shape: 1 256 3 3 (2304)
I0417 23:53:11.885591 10752 net.cpp:156] Memory required for data: 1895812
I0417 23:53:11.885593 10752 layer_factory.hpp:77] Creating layer fc6
I0417 23:53:11.885601 10752 net.cpp:91] Creating Layer fc6
I0417 23:53:11.885603 10752 net.cpp:425] fc6 <- pool5
I0417 23:53:11.885608 10752 net.cpp:399] fc6 -> fc6
I0417 23:53:12.006343 10752 net.cpp:141] Setting up fc6
I0417 23:53:12.006368 10752 net.cpp:148] Top shape: 1 2048 (2048)
I0417 23:53:12.006371 10752 net.cpp:156] Memory required for data: 1904004
I0417 23:53:12.006381 10752 layer_factory.hpp:77] Creating layer relu6
I0417 23:53:12.006389 10752 net.cpp:91] Creating Layer relu6
I0417 23:53:12.006393 10752 net.cpp:425] relu6 <- fc6
I0417 23:53:12.006405 10752 net.cpp:399] relu6 -> relu6
I0417 23:53:12.006714 10752 net.cpp:141] Setting up relu6
I0417 23:53:12.006724 10752 net.cpp:148] Top shape: 1 2048 (2048)
I0417 23:53:12.006727 10752 net.cpp:156] Memory required for data: 1912196
I0417 23:53:12.006731 10752 layer_factory.hpp:77] Creating layer drop6
I0417 23:53:12.006739 10752 net.cpp:91] Creating Layer drop6
I0417 23:53:12.006742 10752 net.cpp:425] drop6 <- relu6
I0417 23:53:12.006748 10752 net.cpp:399] drop6 -> drop6
I0417 23:53:12.006794 10752 net.cpp:141] Setting up drop6
I0417 23:53:12.006800 10752 net.cpp:148] Top shape: 1 2048 (2048)
I0417 23:53:12.006803 10752 net.cpp:156] Memory required for data: 1920388
I0417 23:53:12.006805 10752 layer_factory.hpp:77] Creating layer fc7
I0417 23:53:12.006813 10752 net.cpp:91] Creating Layer fc7
I0417 23:53:12.006815 10752 net.cpp:425] fc7 <- drop6
I0417 23:53:12.006819 10752 net.cpp:399] fc7 -> fc7
I0417 23:53:12.114511 10752 net.cpp:141] Setting up fc7
I0417 23:53:12.114545 10752 net.cpp:148] Top shape: 1 2048 (2048)
I0417 23:53:12.114552 10752 net.cpp:156] Memory required for data: 1928580
I0417 23:53:12.114564 10752 layer_factory.hpp:77] Creating layer relu7
I0417 23:53:12.114579 10752 net.cpp:91] Creating Layer relu7
I0417 23:53:12.114588 10752 net.cpp:425] relu7 <- fc7
I0417 23:53:12.114600 10752 net.cpp:399] relu7 -> relu7
I0417 23:53:12.114861 10752 net.cpp:141] Setting up relu7
I0417 23:53:12.114871 10752 net.cpp:148] Top shape: 1 2048 (2048)
I0417 23:53:12.114873 10752 net.cpp:156] Memory required for data: 1936772
I0417 23:53:12.114877 10752 layer_factory.hpp:77] Creating layer drop7
I0417 23:53:12.114898 10752 net.cpp:91] Creating Layer drop7
I0417 23:53:12.114902 10752 net.cpp:425] drop7 <- relu7
I0417 23:53:12.114907 10752 net.cpp:399] drop7 -> drop7
I0417 23:53:12.114941 10752 net.cpp:141] Setting up drop7
I0417 23:53:12.114948 10752 net.cpp:148] Top shape: 1 2048 (2048)
I0417 23:53:12.114950 10752 net.cpp:156] Memory required for data: 1944964
I0417 23:53:12.114953 10752 layer_factory.hpp:77] Creating layer fc8
I0417 23:53:12.114959 10752 net.cpp:91] Creating Layer fc8
I0417 23:53:12.114962 10752 net.cpp:425] fc8 <- drop7
I0417 23:53:12.114967 10752 net.cpp:399] fc8 -> fc8
I0417 23:53:12.167173 10752 net.cpp:141] Setting up fc8
I0417 23:53:12.167194 10752 net.cpp:148] Top shape: 1 1000 (1000)
I0417 23:53:12.167197 10752 net.cpp:156] Memory required for data: 1948964
I0417 23:53:12.167206 10752 layer_factory.hpp:77] Creating layer loss
I0417 23:53:12.167214 10752 net.cpp:91] Creating Layer loss
I0417 23:53:12.167218 10752 net.cpp:425] loss <- fc8
I0417 23:53:12.167223 10752 net.cpp:425] loss <- label
I0417 23:53:12.167229 10752 net.cpp:399] loss -> loss
I0417 23:53:12.167240 10752 layer_factory.hpp:77] Creating layer loss
I0417 23:53:12.167629 10752 net.cpp:141] Setting up loss
I0417 23:53:12.167639 10752 net.cpp:148] Top shape: (1)
I0417 23:53:12.167640 10752 net.cpp:151]     with loss weight 1
I0417 23:53:12.167654 10752 net.cpp:156] Memory required for data: 1948968
I0417 23:53:12.167657 10752 net.cpp:217] loss needs backward computation.
I0417 23:53:12.167660 10752 net.cpp:217] fc8 needs backward computation.
I0417 23:53:12.167662 10752 net.cpp:217] drop7 needs backward computation.
I0417 23:53:12.167665 10752 net.cpp:217] relu7 needs backward computation.
I0417 23:53:12.167667 10752 net.cpp:217] fc7 needs backward computation.
I0417 23:53:12.167670 10752 net.cpp:217] drop6 needs backward computation.
I0417 23:53:12.167673 10752 net.cpp:217] relu6 needs backward computation.
I0417 23:53:12.167675 10752 net.cpp:217] fc6 needs backward computation.
I0417 23:53:12.167678 10752 net.cpp:217] pool5 needs backward computation.
I0417 23:53:12.167680 10752 net.cpp:217] relu5 needs backward computation.
I0417 23:53:12.167683 10752 net.cpp:217] conv5 needs backward computation.
I0417 23:53:12.167685 10752 net.cpp:217] relu4 needs backward computation.
I0417 23:53:12.167688 10752 net.cpp:217] conv4 needs backward computation.
I0417 23:53:12.167691 10752 net.cpp:217] relu3 needs backward computation.
I0417 23:53:12.167693 10752 net.cpp:217] conv3 needs backward computation.
I0417 23:53:12.167696 10752 net.cpp:217] pool2 needs backward computation.
I0417 23:53:12.167698 10752 net.cpp:217] relu2 needs backward computation.
I0417 23:53:12.167701 10752 net.cpp:217] conv2 needs backward computation.
I0417 23:53:12.167703 10752 net.cpp:217] pool1 needs backward computation.
I0417 23:53:12.167706 10752 net.cpp:217] relu1 needs backward computation.
I0417 23:53:12.167709 10752 net.cpp:217] conv1 needs backward computation.
I0417 23:53:12.167711 10752 net.cpp:219] data does not need backward computation.
I0417 23:53:12.167714 10752 net.cpp:261] This network produces output loss
I0417 23:53:12.167728 10752 net.cpp:274] Network initialization done.
I0417 23:53:12.167824 10752 solver.cpp:181] Creating test net (#0) specified by net_param
I0417 23:53:12.167855 10752 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0417 23:53:12.167999 10752 net.cpp:49] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.04
    mirror: false
    crop_size: 128
    mean_value: 104
    mean_value: 117
    mean_value: 123
    force_color: true
  }
  data_param {
    source: "/home/old-ufo/storage/datasets/imagenet/imgs128/lmdb/ilsvrc12_128_val_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "relu1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "relu1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "relu2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "relu2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "relu3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "relu3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "relu4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "relu4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "relu5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "relu5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "relu6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "relu6"
  top: "drop6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "drop6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "relu7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "relu7"
  top: "drop7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "drop7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0417 23:53:12.168107 10752 layer_factory.hpp:77] Creating layer data
I0417 23:53:12.168179 10752 net.cpp:91] Creating Layer data
I0417 23:53:12.168184 10752 net.cpp:399] data -> data
I0417 23:53:12.168191 10752 net.cpp:399] data -> label
I0417 23:53:12.171448 10760 db_lmdb.cpp:38] Opened lmdb /home/old-ufo/storage/datasets/imagenet/imgs128/lmdb/ilsvrc12_128_val_lmdb
I0417 23:53:12.173038 10752 data_layer.cpp:41] output data size: 50,3,128,128
I0417 23:53:12.186106 10752 net.cpp:141] Setting up data
I0417 23:53:12.186132 10752 net.cpp:148] Top shape: 50 3 128 128 (2457600)
I0417 23:53:12.186138 10752 net.cpp:148] Top shape: 50 (50)
I0417 23:53:12.186142 10752 net.cpp:156] Memory required for data: 9830600
I0417 23:53:12.186149 10752 layer_factory.hpp:77] Creating layer label_data_1_split
I0417 23:53:12.186161 10752 net.cpp:91] Creating Layer label_data_1_split
I0417 23:53:12.186168 10752 net.cpp:425] label_data_1_split <- label
I0417 23:53:12.186177 10752 net.cpp:399] label_data_1_split -> label_data_1_split_0
I0417 23:53:12.186187 10752 net.cpp:399] label_data_1_split -> label_data_1_split_1
I0417 23:53:12.186337 10752 net.cpp:141] Setting up label_data_1_split
I0417 23:53:12.186350 10752 net.cpp:148] Top shape: 50 (50)
I0417 23:53:12.186357 10752 net.cpp:148] Top shape: 50 (50)
I0417 23:53:12.186362 10752 net.cpp:156] Memory required for data: 9831000
I0417 23:53:12.186365 10752 layer_factory.hpp:77] Creating layer conv1
I0417 23:53:12.186383 10752 net.cpp:91] Creating Layer conv1
I0417 23:53:12.186389 10752 net.cpp:425] conv1 <- data
I0417 23:53:12.186398 10752 net.cpp:399] conv1 -> conv1
I0417 23:53:12.188977 10752 net.cpp:141] Setting up conv1
I0417 23:53:12.188995 10752 net.cpp:148] Top shape: 50 96 30 30 (4320000)
I0417 23:53:12.188999 10752 net.cpp:156] Memory required for data: 27111000
I0417 23:53:12.189016 10752 layer_factory.hpp:77] Creating layer relu1
I0417 23:53:12.189028 10752 net.cpp:91] Creating Layer relu1
I0417 23:53:12.189033 10752 net.cpp:425] relu1 <- conv1
I0417 23:53:12.189040 10752 net.cpp:399] relu1 -> relu1
I0417 23:53:12.189208 10752 net.cpp:141] Setting up relu1
I0417 23:53:12.189218 10752 net.cpp:148] Top shape: 50 96 30 30 (4320000)
I0417 23:53:12.189224 10752 net.cpp:156] Memory required for data: 44391000
I0417 23:53:12.189227 10752 layer_factory.hpp:77] Creating layer pool1
I0417 23:53:12.189241 10752 net.cpp:91] Creating Layer pool1
I0417 23:53:12.189247 10752 net.cpp:425] pool1 <- relu1
I0417 23:53:12.189254 10752 net.cpp:399] pool1 -> pool1
I0417 23:53:12.189301 10752 net.cpp:141] Setting up pool1
I0417 23:53:12.189309 10752 net.cpp:148] Top shape: 50 96 15 15 (1080000)
I0417 23:53:12.189313 10752 net.cpp:156] Memory required for data: 48711000
I0417 23:53:12.189318 10752 layer_factory.hpp:77] Creating layer conv2
I0417 23:53:12.189333 10752 net.cpp:91] Creating Layer conv2
I0417 23:53:12.189338 10752 net.cpp:425] conv2 <- pool1
I0417 23:53:12.189347 10752 net.cpp:399] conv2 -> conv2
I0417 23:53:12.198676 10752 net.cpp:141] Setting up conv2
I0417 23:53:12.198698 10752 net.cpp:148] Top shape: 50 256 15 15 (2880000)
I0417 23:53:12.198703 10752 net.cpp:156] Memory required for data: 60231000
I0417 23:53:12.198717 10752 layer_factory.hpp:77] Creating layer relu2
I0417 23:53:12.198729 10752 net.cpp:91] Creating Layer relu2
I0417 23:53:12.198732 10752 net.cpp:425] relu2 <- conv2
I0417 23:53:12.198742 10752 net.cpp:399] relu2 -> relu2
I0417 23:53:12.199070 10752 net.cpp:141] Setting up relu2
I0417 23:53:12.199082 10752 net.cpp:148] Top shape: 50 256 15 15 (2880000)
I0417 23:53:12.199087 10752 net.cpp:156] Memory required for data: 71751000
I0417 23:53:12.199091 10752 layer_factory.hpp:77] Creating layer pool2
I0417 23:53:12.199101 10752 net.cpp:91] Creating Layer pool2
I0417 23:53:12.199105 10752 net.cpp:425] pool2 <- relu2
I0417 23:53:12.199113 10752 net.cpp:399] pool2 -> pool2
I0417 23:53:12.199164 10752 net.cpp:141] Setting up pool2
I0417 23:53:12.199173 10752 net.cpp:148] Top shape: 50 256 7 7 (627200)
I0417 23:53:12.199177 10752 net.cpp:156] Memory required for data: 74259800
I0417 23:53:12.199193 10752 layer_factory.hpp:77] Creating layer conv3
I0417 23:53:12.199211 10752 net.cpp:91] Creating Layer conv3
I0417 23:53:12.199216 10752 net.cpp:425] conv3 <- pool2
I0417 23:53:12.199226 10752 net.cpp:399] conv3 -> conv3
I0417 23:53:12.224117 10752 net.cpp:141] Setting up conv3
I0417 23:53:12.224148 10752 net.cpp:148] Top shape: 50 384 7 7 (940800)
I0417 23:53:12.224153 10752 net.cpp:156] Memory required for data: 78023000
I0417 23:53:12.224167 10752 layer_factory.hpp:77] Creating layer relu3
I0417 23:53:12.224180 10752 net.cpp:91] Creating Layer relu3
I0417 23:53:12.224186 10752 net.cpp:425] relu3 <- conv3
I0417 23:53:12.224195 10752 net.cpp:399] relu3 -> relu3
I0417 23:53:12.224505 10752 net.cpp:141] Setting up relu3
I0417 23:53:12.224517 10752 net.cpp:148] Top shape: 50 384 7 7 (940800)
I0417 23:53:12.224521 10752 net.cpp:156] Memory required for data: 81786200
I0417 23:53:12.224526 10752 layer_factory.hpp:77] Creating layer conv4
I0417 23:53:12.224545 10752 net.cpp:91] Creating Layer conv4
I0417 23:53:12.224551 10752 net.cpp:425] conv4 <- relu3
I0417 23:53:12.224561 10752 net.cpp:399] conv4 -> conv4
I0417 23:53:12.243758 10752 net.cpp:141] Setting up conv4
I0417 23:53:12.243782 10752 net.cpp:148] Top shape: 50 384 7 7 (940800)
I0417 23:53:12.243787 10752 net.cpp:156] Memory required for data: 85549400
I0417 23:53:12.243796 10752 layer_factory.hpp:77] Creating layer relu4
I0417 23:53:12.243809 10752 net.cpp:91] Creating Layer relu4
I0417 23:53:12.243818 10752 net.cpp:425] relu4 <- conv4
I0417 23:53:12.243825 10752 net.cpp:399] relu4 -> relu4
I0417 23:53:12.244086 10752 net.cpp:141] Setting up relu4
I0417 23:53:12.244097 10752 net.cpp:148] Top shape: 50 384 7 7 (940800)
I0417 23:53:12.244102 10752 net.cpp:156] Memory required for data: 89312600
I0417 23:53:12.244107 10752 layer_factory.hpp:77] Creating layer conv5
I0417 23:53:12.244127 10752 net.cpp:91] Creating Layer conv5
I0417 23:53:12.244134 10752 net.cpp:425] conv5 <- relu4
I0417 23:53:12.244143 10752 net.cpp:399] conv5 -> conv5
I0417 23:53:12.256952 10752 net.cpp:141] Setting up conv5
I0417 23:53:12.256975 10752 net.cpp:148] Top shape: 50 256 7 7 (627200)
I0417 23:53:12.256980 10752 net.cpp:156] Memory required for data: 91821400
I0417 23:53:12.256995 10752 layer_factory.hpp:77] Creating layer relu5
I0417 23:53:12.257009 10752 net.cpp:91] Creating Layer relu5
I0417 23:53:12.257015 10752 net.cpp:425] relu5 <- conv5
I0417 23:53:12.257024 10752 net.cpp:399] relu5 -> relu5
I0417 23:53:12.257210 10752 net.cpp:141] Setting up relu5
I0417 23:53:12.257220 10752 net.cpp:148] Top shape: 50 256 7 7 (627200)
I0417 23:53:12.257225 10752 net.cpp:156] Memory required for data: 94330200
I0417 23:53:12.257230 10752 layer_factory.hpp:77] Creating layer pool5
I0417 23:53:12.257239 10752 net.cpp:91] Creating Layer pool5
I0417 23:53:12.257246 10752 net.cpp:425] pool5 <- relu5
I0417 23:53:12.257253 10752 net.cpp:399] pool5 -> pool5
I0417 23:53:12.257304 10752 net.cpp:141] Setting up pool5
I0417 23:53:12.257313 10752 net.cpp:148] Top shape: 50 256 3 3 (115200)
I0417 23:53:12.257318 10752 net.cpp:156] Memory required for data: 94791000
I0417 23:53:12.257324 10752 layer_factory.hpp:77] Creating layer fc6
I0417 23:53:12.257335 10752 net.cpp:91] Creating Layer fc6
I0417 23:53:12.257341 10752 net.cpp:425] fc6 <- pool5
I0417 23:53:12.257351 10752 net.cpp:399] fc6 -> fc6
I0417 23:53:12.378499 10752 net.cpp:141] Setting up fc6
I0417 23:53:12.378530 10752 net.cpp:148] Top shape: 50 2048 (102400)
I0417 23:53:12.378535 10752 net.cpp:156] Memory required for data: 95200600
I0417 23:53:12.378545 10752 layer_factory.hpp:77] Creating layer relu6
I0417 23:53:12.378561 10752 net.cpp:91] Creating Layer relu6
I0417 23:53:12.378569 10752 net.cpp:425] relu6 <- fc6
I0417 23:53:12.378579 10752 net.cpp:399] relu6 -> relu6
I0417 23:53:12.378945 10752 net.cpp:141] Setting up relu6
I0417 23:53:12.378954 10752 net.cpp:148] Top shape: 50 2048 (102400)
I0417 23:53:12.378957 10752 net.cpp:156] Memory required for data: 95610200
I0417 23:53:12.378973 10752 layer_factory.hpp:77] Creating layer drop6
I0417 23:53:12.378980 10752 net.cpp:91] Creating Layer drop6
I0417 23:53:12.378983 10752 net.cpp:425] drop6 <- relu6
I0417 23:53:12.378988 10752 net.cpp:399] drop6 -> drop6
I0417 23:53:12.379024 10752 net.cpp:141] Setting up drop6
I0417 23:53:12.379029 10752 net.cpp:148] Top shape: 50 2048 (102400)
I0417 23:53:12.379031 10752 net.cpp:156] Memory required for data: 96019800
I0417 23:53:12.379034 10752 layer_factory.hpp:77] Creating layer fc7
I0417 23:53:12.379041 10752 net.cpp:91] Creating Layer fc7
I0417 23:53:12.379045 10752 net.cpp:425] fc7 <- drop6
I0417 23:53:12.379048 10752 net.cpp:399] fc7 -> fc7
I0417 23:53:12.485775 10752 net.cpp:141] Setting up fc7
I0417 23:53:12.485803 10752 net.cpp:148] Top shape: 50 2048 (102400)
I0417 23:53:12.485808 10752 net.cpp:156] Memory required for data: 96429400
I0417 23:53:12.485818 10752 layer_factory.hpp:77] Creating layer relu7
I0417 23:53:12.485829 10752 net.cpp:91] Creating Layer relu7
I0417 23:53:12.485836 10752 net.cpp:425] relu7 <- fc7
I0417 23:53:12.485851 10752 net.cpp:399] relu7 -> relu7
I0417 23:53:12.486110 10752 net.cpp:141] Setting up relu7
I0417 23:53:12.486121 10752 net.cpp:148] Top shape: 50 2048 (102400)
I0417 23:53:12.486124 10752 net.cpp:156] Memory required for data: 96839000
I0417 23:53:12.486127 10752 layer_factory.hpp:77] Creating layer drop7
I0417 23:53:12.486135 10752 net.cpp:91] Creating Layer drop7
I0417 23:53:12.486138 10752 net.cpp:425] drop7 <- relu7
I0417 23:53:12.486145 10752 net.cpp:399] drop7 -> drop7
I0417 23:53:12.486202 10752 net.cpp:141] Setting up drop7
I0417 23:53:12.486208 10752 net.cpp:148] Top shape: 50 2048 (102400)
I0417 23:53:12.486212 10752 net.cpp:156] Memory required for data: 97248600
I0417 23:53:12.486213 10752 layer_factory.hpp:77] Creating layer fc8
I0417 23:53:12.486222 10752 net.cpp:91] Creating Layer fc8
I0417 23:53:12.486224 10752 net.cpp:425] fc8 <- drop7
I0417 23:53:12.486230 10752 net.cpp:399] fc8 -> fc8
I0417 23:53:12.538841 10752 net.cpp:141] Setting up fc8
I0417 23:53:12.538866 10752 net.cpp:148] Top shape: 50 1000 (50000)
I0417 23:53:12.538871 10752 net.cpp:156] Memory required for data: 97448600
I0417 23:53:12.538882 10752 layer_factory.hpp:77] Creating layer fc8_fc8_0_split
I0417 23:53:12.538895 10752 net.cpp:91] Creating Layer fc8_fc8_0_split
I0417 23:53:12.538902 10752 net.cpp:425] fc8_fc8_0_split <- fc8
I0417 23:53:12.538913 10752 net.cpp:399] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0417 23:53:12.538924 10752 net.cpp:399] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0417 23:53:12.538990 10752 net.cpp:141] Setting up fc8_fc8_0_split
I0417 23:53:12.538997 10752 net.cpp:148] Top shape: 50 1000 (50000)
I0417 23:53:12.539000 10752 net.cpp:148] Top shape: 50 1000 (50000)
I0417 23:53:12.539003 10752 net.cpp:156] Memory required for data: 97848600
I0417 23:53:12.539005 10752 layer_factory.hpp:77] Creating layer accuracy
I0417 23:53:12.539019 10752 net.cpp:91] Creating Layer accuracy
I0417 23:53:12.539024 10752 net.cpp:425] accuracy <- fc8_fc8_0_split_0
I0417 23:53:12.539029 10752 net.cpp:425] accuracy <- label_data_1_split_0
I0417 23:53:12.539037 10752 net.cpp:399] accuracy -> accuracy
I0417 23:53:12.539048 10752 net.cpp:141] Setting up accuracy
I0417 23:53:12.539055 10752 net.cpp:148] Top shape: (1)
I0417 23:53:12.539060 10752 net.cpp:156] Memory required for data: 97848604
I0417 23:53:12.539064 10752 layer_factory.hpp:77] Creating layer loss
I0417 23:53:12.539072 10752 net.cpp:91] Creating Layer loss
I0417 23:53:12.539077 10752 net.cpp:425] loss <- fc8_fc8_0_split_1
I0417 23:53:12.539083 10752 net.cpp:425] loss <- label_data_1_split_1
I0417 23:53:12.539091 10752 net.cpp:399] loss -> loss
I0417 23:53:12.539103 10752 layer_factory.hpp:77] Creating layer loss
I0417 23:53:12.539926 10752 net.cpp:141] Setting up loss
I0417 23:53:12.539935 10752 net.cpp:148] Top shape: (1)
I0417 23:53:12.539938 10752 net.cpp:151]     with loss weight 1
I0417 23:53:12.539947 10752 net.cpp:156] Memory required for data: 97848608
I0417 23:53:12.539949 10752 net.cpp:217] loss needs backward computation.
I0417 23:53:12.539966 10752 net.cpp:219] accuracy does not need backward computation.
I0417 23:53:12.539973 10752 net.cpp:217] fc8_fc8_0_split needs backward computation.
I0417 23:53:12.539976 10752 net.cpp:217] fc8 needs backward computation.
I0417 23:53:12.539985 10752 net.cpp:217] drop7 needs backward computation.
I0417 23:53:12.539989 10752 net.cpp:217] relu7 needs backward computation.
I0417 23:53:12.539994 10752 net.cpp:217] fc7 needs backward computation.
I0417 23:53:12.539999 10752 net.cpp:217] drop6 needs backward computation.
I0417 23:53:12.540004 10752 net.cpp:217] relu6 needs backward computation.
I0417 23:53:12.540009 10752 net.cpp:217] fc6 needs backward computation.
I0417 23:53:12.540014 10752 net.cpp:217] pool5 needs backward computation.
I0417 23:53:12.540019 10752 net.cpp:217] relu5 needs backward computation.
I0417 23:53:12.540024 10752 net.cpp:217] conv5 needs backward computation.
I0417 23:53:12.540030 10752 net.cpp:217] relu4 needs backward computation.
I0417 23:53:12.540033 10752 net.cpp:217] conv4 needs backward computation.
I0417 23:53:12.540037 10752 net.cpp:217] relu3 needs backward computation.
I0417 23:53:12.540042 10752 net.cpp:217] conv3 needs backward computation.
I0417 23:53:12.540046 10752 net.cpp:217] pool2 needs backward computation.
I0417 23:53:12.540051 10752 net.cpp:217] relu2 needs backward computation.
I0417 23:53:12.540057 10752 net.cpp:217] conv2 needs backward computation.
I0417 23:53:12.540061 10752 net.cpp:217] pool1 needs backward computation.
I0417 23:53:12.540066 10752 net.cpp:217] relu1 needs backward computation.
I0417 23:53:12.540071 10752 net.cpp:217] conv1 needs backward computation.
I0417 23:53:12.540076 10752 net.cpp:219] label_data_1_split does not need backward computation.
I0417 23:53:12.540082 10752 net.cpp:219] data does not need backward computation.
I0417 23:53:12.540086 10752 net.cpp:261] This network produces output accuracy
I0417 23:53:12.540091 10752 net.cpp:261] This network produces output loss
I0417 23:53:12.540115 10752 net.cpp:274] Network initialization done.
I0417 23:53:12.540218 10752 solver.cpp:60] Solver scaffolding done.
I0417 23:53:12.540699 10752 caffe.cpp:209] Resuming from snapshots/caffenet128_no_lrn_lsuv_relu_bs1_iter_34048000.solverstate
I0417 23:53:12.846235 10752 sgd_solver.cpp:318] SGDSolver: restoring history
I0417 23:53:12.873201 10752 caffe.cpp:219] Starting Optimization
I0417 23:53:12.873224 10752 solver.cpp:279] Solving CaffeNet
I0417 23:53:12.873229 10752 solver.cpp:280] Learning Rate Policy: step
I0417 23:53:12.874238 10752 solver.cpp:337] Iteration 34048000, Testing net (#0)
I0417 23:53:12.916374 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0417 23:53:40.049444 10752 solver.cpp:404]     Test net output #0: accuracy = 0.43896
I0417 23:53:40.049487 10752 solver.cpp:404]     Test net output #1: loss = 2.54562 (* 1 = 2.54562 loss)
I0417 23:53:40.058423 10752 solver.cpp:228] Iteration 34048000, loss = 2.16574
I0417 23:53:40.058452 10752 solver.cpp:244]     Train net output #0: loss = 2.16574 (* 1 = 2.16574 loss)
I0417 23:53:40.058470 10752 sgd_solver.cpp:106] Iteration 34048000, lr = 3.9063e-06
I0417 23:58:43.863309 10752 solver.cpp:228] Iteration 34099200, loss = 2.58975
I0417 23:58:43.863373 10752 solver.cpp:244]     Train net output #0: loss = 3.5261 (* 1 = 3.5261 loss)
I0417 23:58:43.863380 10752 sgd_solver.cpp:106] Iteration 34099200, lr = 3.9063e-06
I0418 00:03:49.934242 10752 solver.cpp:228] Iteration 34150400, loss = 2.57874
I0418 00:03:49.934308 10752 solver.cpp:244]     Train net output #0: loss = 2.46217 (* 1 = 2.46217 loss)
I0418 00:03:49.934314 10752 sgd_solver.cpp:106] Iteration 34150400, lr = 3.9063e-06
I0418 00:06:36.653652 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0418 00:09:00.459873 10752 solver.cpp:228] Iteration 34201600, loss = 2.59033
I0418 00:09:00.459949 10752 solver.cpp:244]     Train net output #0: loss = 0.390861 (* 1 = 0.390861 loss)
I0418 00:09:00.459957 10752 sgd_solver.cpp:106] Iteration 34201600, lr = 3.9063e-06
I0418 00:14:07.839628 10752 solver.cpp:228] Iteration 34252800, loss = 2.55189
I0418 00:14:07.839689 10752 solver.cpp:244]     Train net output #0: loss = 4.79047 (* 1 = 4.79047 loss)
I0418 00:14:07.839696 10752 sgd_solver.cpp:106] Iteration 34252800, lr = 3.9063e-06
I0418 00:19:13.908787 10752 solver.cpp:337] Iteration 34304000, Testing net (#0)
I0418 00:19:40.265290 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0418 00:19:40.370167 10752 solver.cpp:404]     Test net output #0: accuracy = 0.44056
I0418 00:19:40.370199 10752 solver.cpp:404]     Test net output #1: loss = 2.5376 (* 1 = 2.5376 loss)
I0418 00:19:40.372751 10752 solver.cpp:228] Iteration 34304000, loss = 2.5758
I0418 00:19:40.372771 10752 solver.cpp:244]     Train net output #0: loss = 0.0759481 (* 1 = 0.0759481 loss)
I0418 00:19:40.372779 10752 sgd_solver.cpp:106] Iteration 34304000, lr = 3.9063e-06
I0418 00:24:46.498247 10752 solver.cpp:228] Iteration 34355200, loss = 2.57725
I0418 00:24:46.498311 10752 solver.cpp:244]     Train net output #0: loss = 0.0216647 (* 1 = 0.0216647 loss)
I0418 00:24:46.498317 10752 sgd_solver.cpp:106] Iteration 34355200, lr = 3.9063e-06
I0418 00:29:52.523732 10752 solver.cpp:228] Iteration 34406400, loss = 2.56904
I0418 00:29:52.523802 10752 solver.cpp:244]     Train net output #0: loss = 0.003944 (* 1 = 0.003944 loss)
I0418 00:29:52.523809 10752 sgd_solver.cpp:106] Iteration 34406400, lr = 3.9063e-06
I0418 00:34:58.530004 10752 solver.cpp:228] Iteration 34457600, loss = 2.57937
I0418 00:34:58.530076 10752 solver.cpp:244]     Train net output #0: loss = 4.16492 (* 1 = 4.16492 loss)
I0418 00:34:58.530081 10752 sgd_solver.cpp:106] Iteration 34457600, lr = 3.9063e-06
I0418 00:40:04.504812 10752 solver.cpp:228] Iteration 34508800, loss = 2.54899
I0418 00:40:04.504871 10752 solver.cpp:244]     Train net output #0: loss = 0.158084 (* 1 = 0.158084 loss)
I0418 00:40:04.504878 10752 sgd_solver.cpp:106] Iteration 34508800, lr = 3.9063e-06
I0418 00:45:10.519610 10752 solver.cpp:337] Iteration 34560000, Testing net (#0)
I0418 00:45:36.950577 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0418 00:45:37.002533 10752 solver.cpp:404]     Test net output #0: accuracy = 0.43934
I0418 00:45:37.002568 10752 solver.cpp:404]     Test net output #1: loss = 2.53702 (* 1 = 2.53702 loss)
I0418 00:45:37.005091 10752 solver.cpp:228] Iteration 34560000, loss = 2.53543
I0418 00:45:37.005110 10752 solver.cpp:244]     Train net output #0: loss = 6.60568 (* 1 = 6.60568 loss)
I0418 00:45:37.005120 10752 sgd_solver.cpp:106] Iteration 34560000, lr = 3.9063e-06
I0418 00:50:43.213351 10752 solver.cpp:228] Iteration 34611200, loss = 2.55083
I0418 00:50:43.213680 10752 solver.cpp:244]     Train net output #0: loss = 1.01442 (* 1 = 1.01442 loss)
I0418 00:50:43.213696 10752 sgd_solver.cpp:106] Iteration 34611200, lr = 3.9063e-06
I0418 00:55:49.431239 10752 solver.cpp:228] Iteration 34662400, loss = 2.56071
I0418 00:55:49.431298 10752 solver.cpp:244]     Train net output #0: loss = 2.5312 (* 1 = 2.5312 loss)
I0418 00:55:49.431304 10752 sgd_solver.cpp:106] Iteration 34662400, lr = 3.9063e-06
I0418 01:00:55.611435 10752 solver.cpp:228] Iteration 34713600, loss = 2.54303
I0418 01:00:55.611496 10752 solver.cpp:244]     Train net output #0: loss = 1.12395 (* 1 = 1.12395 loss)
I0418 01:00:55.611503 10752 sgd_solver.cpp:106] Iteration 34713600, lr = 3.9063e-06
I0418 01:06:01.636991 10752 solver.cpp:228] Iteration 34764800, loss = 2.56779
I0418 01:06:01.637064 10752 solver.cpp:244]     Train net output #0: loss = 0.0179281 (* 1 = 0.0179281 loss)
I0418 01:06:01.637071 10752 sgd_solver.cpp:106] Iteration 34764800, lr = 3.9063e-06
I0418 01:11:07.710577 10752 solver.cpp:337] Iteration 34816000, Testing net (#0)
I0418 01:11:34.492516 10752 solver.cpp:404]     Test net output #0: accuracy = 0.440481
I0418 01:11:34.492547 10752 solver.cpp:404]     Test net output #1: loss = 2.54174 (* 1 = 2.54174 loss)
I0418 01:11:34.495086 10752 solver.cpp:228] Iteration 34816000, loss = 2.58292
I0418 01:11:34.495102 10752 solver.cpp:244]     Train net output #0: loss = 5.07448 (* 1 = 5.07448 loss)
I0418 01:11:34.495110 10752 sgd_solver.cpp:106] Iteration 34816000, lr = 3.9063e-06
I0418 01:16:40.622341 10752 solver.cpp:228] Iteration 34867200, loss = 2.58264
I0418 01:16:40.622437 10752 solver.cpp:244]     Train net output #0: loss = 4.5589 (* 1 = 4.5589 loss)
I0418 01:16:40.622450 10752 sgd_solver.cpp:106] Iteration 34867200, lr = 3.9063e-06
I0418 01:21:46.660230 10752 solver.cpp:228] Iteration 34918400, loss = 2.58098
I0418 01:21:46.660305 10752 solver.cpp:244]     Train net output #0: loss = 2.65071 (* 1 = 2.65071 loss)
I0418 01:21:46.660312 10752 sgd_solver.cpp:106] Iteration 34918400, lr = 3.9063e-06
I0418 01:26:52.626269 10752 solver.cpp:228] Iteration 34969600, loss = 2.56091
I0418 01:26:52.626351 10752 solver.cpp:244]     Train net output #0: loss = 0.011378 (* 1 = 0.011378 loss)
I0418 01:26:52.626365 10752 sgd_solver.cpp:106] Iteration 34969600, lr = 3.9063e-06
I0418 01:31:58.713903 10752 solver.cpp:228] Iteration 35020800, loss = 2.54662
I0418 01:31:58.713965 10752 solver.cpp:244]     Train net output #0: loss = 3.11003 (* 1 = 3.11003 loss)
I0418 01:31:58.713978 10752 sgd_solver.cpp:106] Iteration 35020800, lr = 3.9063e-06
I0418 01:37:04.739897 10752 solver.cpp:337] Iteration 35072000, Testing net (#0)
I0418 01:37:04.769517 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0418 01:37:31.211530 10752 solver.cpp:404]     Test net output #0: accuracy = 0.4412
I0418 01:37:31.211563 10752 solver.cpp:404]     Test net output #1: loss = 2.53072 (* 1 = 2.53072 loss)
I0418 01:37:31.214073 10752 solver.cpp:228] Iteration 35072000, loss = 2.55248
I0418 01:37:31.214090 10752 solver.cpp:244]     Train net output #0: loss = 0.462701 (* 1 = 0.462701 loss)
I0418 01:37:31.214099 10752 sgd_solver.cpp:106] Iteration 35072000, lr = 3.9063e-06
I0418 01:42:37.366719 10752 solver.cpp:228] Iteration 35123200, loss = 2.54109
I0418 01:42:37.366777 10752 solver.cpp:244]     Train net output #0: loss = 0.532164 (* 1 = 0.532164 loss)
I0418 01:42:37.366783 10752 sgd_solver.cpp:106] Iteration 35123200, lr = 3.9063e-06
I0418 01:47:43.390938 10752 solver.cpp:228] Iteration 35174400, loss = 2.53808
I0418 01:47:43.391013 10752 solver.cpp:244]     Train net output #0: loss = 3.56578 (* 1 = 3.56578 loss)
I0418 01:47:43.391024 10752 sgd_solver.cpp:106] Iteration 35174400, lr = 3.9063e-06
I0418 01:52:49.440778 10752 solver.cpp:228] Iteration 35225600, loss = 2.55273
I0418 01:52:49.440837 10752 solver.cpp:244]     Train net output #0: loss = 0.0408632 (* 1 = 0.0408632 loss)
I0418 01:52:49.440846 10752 sgd_solver.cpp:106] Iteration 35225600, lr = 3.9063e-06
I0418 01:57:55.572732 10752 solver.cpp:228] Iteration 35276800, loss = 2.52668
I0418 01:57:55.572795 10752 solver.cpp:244]     Train net output #0: loss = 0.375663 (* 1 = 0.375663 loss)
I0418 01:57:55.572808 10752 sgd_solver.cpp:106] Iteration 35276800, lr = 3.9063e-06
I0418 02:03:01.751224 10752 solver.cpp:337] Iteration 35328000, Testing net (#0)
I0418 02:03:01.815978 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0418 02:03:28.213659 10752 solver.cpp:404]     Test net output #0: accuracy = 0.44292
I0418 02:03:28.213695 10752 solver.cpp:404]     Test net output #1: loss = 2.52882 (* 1 = 2.52882 loss)
I0418 02:03:28.216234 10752 solver.cpp:228] Iteration 35328000, loss = 2.57527
I0418 02:03:28.216254 10752 solver.cpp:244]     Train net output #0: loss = 9.04507 (* 1 = 9.04507 loss)
I0418 02:03:28.216265 10752 sgd_solver.cpp:106] Iteration 35328000, lr = 3.9063e-06
I0418 02:08:34.371304 10752 solver.cpp:228] Iteration 35379200, loss = 2.57667
I0418 02:08:34.371363 10752 solver.cpp:244]     Train net output #0: loss = 5.41733 (* 1 = 5.41733 loss)
I0418 02:08:34.371377 10752 sgd_solver.cpp:106] Iteration 35379200, lr = 3.9063e-06
I0418 02:13:40.491225 10752 solver.cpp:228] Iteration 35430400, loss = 2.56846
I0418 02:13:40.491298 10752 solver.cpp:244]     Train net output #0: loss = 1.03867 (* 1 = 1.03867 loss)
I0418 02:13:40.491312 10752 sgd_solver.cpp:106] Iteration 35430400, lr = 3.9063e-06
I0418 02:18:46.556807 10752 solver.cpp:228] Iteration 35481600, loss = 2.57698
I0418 02:18:46.556880 10752 solver.cpp:244]     Train net output #0: loss = 1.64363 (* 1 = 1.64363 loss)
I0418 02:18:46.556887 10752 sgd_solver.cpp:106] Iteration 35481600, lr = 3.9063e-06
I0418 02:23:52.590013 10752 solver.cpp:228] Iteration 35532800, loss = 2.55001
I0418 02:23:52.590071 10752 solver.cpp:244]     Train net output #0: loss = 0.529279 (* 1 = 0.529279 loss)
I0418 02:23:52.590078 10752 sgd_solver.cpp:106] Iteration 35532800, lr = 3.9063e-06
I0418 02:28:58.555855 10752 solver.cpp:337] Iteration 35584000, Testing net (#0)
I0418 02:28:58.692246 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0418 02:29:25.148612 10752 solver.cpp:404]     Test net output #0: accuracy = 0.44168
I0418 02:29:25.148645 10752 solver.cpp:404]     Test net output #1: loss = 2.53082 (* 1 = 2.53082 loss)
I0418 02:29:25.151185 10752 solver.cpp:228] Iteration 35584000, loss = 2.56693
I0418 02:29:25.151201 10752 solver.cpp:244]     Train net output #0: loss = 3.08784 (* 1 = 3.08784 loss)
I0418 02:29:25.151211 10752 sgd_solver.cpp:106] Iteration 35584000, lr = 3.9063e-06
I0418 02:34:31.478809 10752 solver.cpp:228] Iteration 35635200, loss = 2.54736
I0418 02:34:31.478881 10752 solver.cpp:244]     Train net output #0: loss = 1.23389 (* 1 = 1.23389 loss)
I0418 02:34:31.478888 10752 sgd_solver.cpp:106] Iteration 35635200, lr = 3.9063e-06
I0418 02:39:37.529482 10752 solver.cpp:228] Iteration 35686400, loss = 2.55651
I0418 02:39:37.529539 10752 solver.cpp:244]     Train net output #0: loss = 1.89161 (* 1 = 1.89161 loss)
I0418 02:39:37.529546 10752 sgd_solver.cpp:106] Iteration 35686400, lr = 3.9063e-06
I0418 02:44:43.671352 10752 solver.cpp:228] Iteration 35737600, loss = 2.55951
I0418 02:44:43.671423 10752 solver.cpp:244]     Train net output #0: loss = 3.36612 (* 1 = 3.36612 loss)
I0418 02:44:43.671428 10752 sgd_solver.cpp:106] Iteration 35737600, lr = 3.9063e-06
I0418 02:49:49.718703 10752 solver.cpp:228] Iteration 35788800, loss = 2.54213
I0418 02:49:49.718776 10752 solver.cpp:244]     Train net output #0: loss = 2.54419 (* 1 = 2.54419 loss)
I0418 02:49:49.718783 10752 sgd_solver.cpp:106] Iteration 35788800, lr = 3.9063e-06
I0418 02:54:55.797658 10752 solver.cpp:454] Snapshotting to binary proto file snapshots/caffenet128_no_lrn_lsuv_relu_bs1_iter_35840000.caffemodel
I0418 02:54:55.969259 10752 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/caffenet128_no_lrn_lsuv_relu_bs1_iter_35840000.solverstate
I0418 02:54:56.028785 10752 solver.cpp:337] Iteration 35840000, Testing net (#0)
I0418 02:54:56.197763 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0418 02:55:22.625259 10752 solver.cpp:404]     Test net output #0: accuracy = 0.44048
I0418 02:55:22.625293 10752 solver.cpp:404]     Test net output #1: loss = 2.53959 (* 1 = 2.53959 loss)
I0418 02:55:22.628579 10752 solver.cpp:228] Iteration 35840000, loss = 2.52868
I0418 02:55:22.628615 10752 solver.cpp:244]     Train net output #0: loss = 5.99387 (* 1 = 5.99387 loss)
I0418 02:55:22.628626 10752 sgd_solver.cpp:106] Iteration 35840000, lr = 3.9063e-06
I0418 03:00:29.968827 10752 solver.cpp:228] Iteration 35891200, loss = 2.53544
I0418 03:00:29.968883 10752 solver.cpp:244]     Train net output #0: loss = 5.97433 (* 1 = 5.97433 loss)
I0418 03:00:29.968888 10752 sgd_solver.cpp:106] Iteration 35891200, lr = 3.9063e-06
I0418 03:05:35.890504 10752 solver.cpp:228] Iteration 35942400, loss = 2.54421
I0418 03:05:35.890563 10752 solver.cpp:244]     Train net output #0: loss = 6.12439 (* 1 = 6.12439 loss)
I0418 03:05:35.890568 10752 sgd_solver.cpp:106] Iteration 35942400, lr = 3.9063e-06
I0418 03:10:42.531566 10752 solver.cpp:228] Iteration 35993600, loss = 2.54023
I0418 03:10:42.531636 10752 solver.cpp:244]     Train net output #0: loss = 0.10092 (* 1 = 0.10092 loss)
I0418 03:10:42.531642 10752 sgd_solver.cpp:106] Iteration 35993600, lr = 3.9063e-06
I0418 03:15:48.939004 10752 solver.cpp:228] Iteration 36044800, loss = 2.54187
I0418 03:15:48.939090 10752 solver.cpp:244]     Train net output #0: loss = 0.842166 (* 1 = 0.842166 loss)
I0418 03:15:48.939097 10752 sgd_solver.cpp:106] Iteration 36044800, lr = 3.9063e-06
I0418 03:20:55.447046 10752 solver.cpp:337] Iteration 36096000, Testing net (#0)
I0418 03:20:55.494809 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0418 03:21:22.748425 10752 solver.cpp:404]     Test net output #0: accuracy = 0.44066
I0418 03:21:22.748458 10752 solver.cpp:404]     Test net output #1: loss = 2.53214 (* 1 = 2.53214 loss)
I0418 03:21:22.751040 10752 solver.cpp:228] Iteration 36096000, loss = 2.56597
I0418 03:21:22.751063 10752 solver.cpp:244]     Train net output #0: loss = 5.82901 (* 1 = 5.82901 loss)
I0418 03:21:22.751075 10752 sgd_solver.cpp:106] Iteration 36096000, lr = 3.9063e-06
I0418 03:26:29.368130 10752 solver.cpp:228] Iteration 36147200, loss = 2.56799
I0418 03:26:29.368198 10752 solver.cpp:244]     Train net output #0: loss = 0.0669676 (* 1 = 0.0669676 loss)
I0418 03:26:29.368211 10752 sgd_solver.cpp:106] Iteration 36147200, lr = 3.9063e-06
I0418 03:31:35.839202 10752 solver.cpp:228] Iteration 36198400, loss = 2.56528
I0418 03:31:35.839275 10752 solver.cpp:244]     Train net output #0: loss = 2.23399 (* 1 = 2.23399 loss)
I0418 03:31:35.839284 10752 sgd_solver.cpp:106] Iteration 36198400, lr = 3.9063e-06
I0418 03:36:42.466393 10752 solver.cpp:228] Iteration 36249600, loss = 2.54016
I0418 03:36:42.466465 10752 solver.cpp:244]     Train net output #0: loss = 2.59676 (* 1 = 2.59676 loss)
I0418 03:36:42.466471 10752 sgd_solver.cpp:106] Iteration 36249600, lr = 3.9063e-06
I0418 03:41:48.925992 10752 solver.cpp:228] Iteration 36300800, loss = 2.53392
I0418 03:41:48.926064 10752 solver.cpp:244]     Train net output #0: loss = 2.6061 (* 1 = 2.6061 loss)
I0418 03:41:48.926071 10752 sgd_solver.cpp:106] Iteration 36300800, lr = 3.9063e-06
I0418 03:46:55.461204 10752 solver.cpp:337] Iteration 36352000, Testing net (#0)
I0418 03:46:55.553257 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0418 03:47:21.924765 10752 solver.cpp:404]     Test net output #0: accuracy = 0.44258
I0418 03:47:21.924796 10752 solver.cpp:404]     Test net output #1: loss = 2.53028 (* 1 = 2.53028 loss)
I0418 03:47:21.927377 10752 solver.cpp:228] Iteration 36352000, loss = 2.53509
I0418 03:47:21.927397 10752 solver.cpp:244]     Train net output #0: loss = 3.68846 (* 1 = 3.68846 loss)
I0418 03:47:21.927403 10752 sgd_solver.cpp:106] Iteration 36352000, lr = 3.9063e-06
I0418 03:52:28.636399 10752 solver.cpp:228] Iteration 36403200, loss = 2.5383
I0418 03:52:28.636461 10752 solver.cpp:244]     Train net output #0: loss = 6.74436 (* 1 = 6.74436 loss)
I0418 03:52:28.636466 10752 sgd_solver.cpp:106] Iteration 36403200, lr = 3.9063e-06
I0418 03:57:35.421726 10752 solver.cpp:228] Iteration 36454400, loss = 2.53229
I0418 03:57:35.421802 10752 solver.cpp:244]     Train net output #0: loss = 4.94649 (* 1 = 4.94649 loss)
I0418 03:57:35.421810 10752 sgd_solver.cpp:106] Iteration 36454400, lr = 3.9063e-06
I0418 04:02:41.297675 10752 solver.cpp:228] Iteration 36505600, loss = 2.52405
I0418 04:02:41.297755 10752 solver.cpp:244]     Train net output #0: loss = 4.295 (* 1 = 4.295 loss)
I0418 04:02:41.297766 10752 sgd_solver.cpp:106] Iteration 36505600, lr = 3.9063e-06
I0418 04:07:47.206347 10752 solver.cpp:228] Iteration 36556800, loss = 2.50988
I0418 04:07:47.206406 10752 solver.cpp:244]     Train net output #0: loss = 7.13648 (* 1 = 7.13648 loss)
I0418 04:07:47.206411 10752 sgd_solver.cpp:106] Iteration 36556800, lr = 3.9063e-06
I0418 04:12:53.125911 10752 solver.cpp:337] Iteration 36608000, Testing net (#0)
I0418 04:12:53.218050 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0418 04:13:19.613476 10752 solver.cpp:404]     Test net output #0: accuracy = 0.4433
I0418 04:13:19.613509 10752 solver.cpp:404]     Test net output #1: loss = 2.5234 (* 1 = 2.5234 loss)
I0418 04:13:19.616037 10752 solver.cpp:228] Iteration 36608000, loss = 2.55085
I0418 04:13:19.616055 10752 solver.cpp:244]     Train net output #0: loss = 3.92028 (* 1 = 3.92028 loss)
I0418 04:13:19.616065 10752 sgd_solver.cpp:106] Iteration 36608000, lr = 3.9063e-06
I0418 04:18:25.695801 10752 solver.cpp:228] Iteration 36659200, loss = 2.56363
I0418 04:18:25.695906 10752 solver.cpp:244]     Train net output #0: loss = 0.0759758 (* 1 = 0.0759758 loss)
I0418 04:18:25.695915 10752 sgd_solver.cpp:106] Iteration 36659200, lr = 3.9063e-06
I0418 04:23:31.592795 10752 solver.cpp:228] Iteration 36710400, loss = 2.55816
I0418 04:23:31.592855 10752 solver.cpp:244]     Train net output #0: loss = 1.23688 (* 1 = 1.23688 loss)
I0418 04:23:31.592861 10752 sgd_solver.cpp:106] Iteration 36710400, lr = 3.9063e-06
I0418 04:28:37.573067 10752 solver.cpp:228] Iteration 36761600, loss = 2.55944
I0418 04:28:37.573132 10752 solver.cpp:244]     Train net output #0: loss = 2.00576 (* 1 = 2.00576 loss)
I0418 04:28:37.573138 10752 sgd_solver.cpp:106] Iteration 36761600, lr = 3.9063e-06
I0418 04:33:43.547773 10752 solver.cpp:228] Iteration 36812800, loss = 2.54008
I0418 04:33:43.547847 10752 solver.cpp:244]     Train net output #0: loss = 0.246796 (* 1 = 0.246796 loss)
I0418 04:33:43.547852 10752 sgd_solver.cpp:106] Iteration 36812800, lr = 3.9063e-06
I0418 04:38:49.459940 10752 solver.cpp:337] Iteration 36864000, Testing net (#0)
I0418 04:38:49.604820 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0418 04:39:15.935384 10752 solver.cpp:404]     Test net output #0: accuracy = 0.43922
I0418 04:39:15.935420 10752 solver.cpp:404]     Test net output #1: loss = 2.53188 (* 1 = 2.53188 loss)
I0418 04:39:15.937996 10752 solver.cpp:228] Iteration 36864000, loss = 2.54409
I0418 04:39:15.938015 10752 solver.cpp:244]     Train net output #0: loss = 1.58021 (* 1 = 1.58021 loss)
I0418 04:39:15.938027 10752 sgd_solver.cpp:106] Iteration 36864000, lr = 3.9063e-06
I0418 04:44:22.012702 10752 solver.cpp:228] Iteration 36915200, loss = 2.54142
I0418 04:44:22.012763 10752 solver.cpp:244]     Train net output #0: loss = 3.88229 (* 1 = 3.88229 loss)
I0418 04:44:22.012768 10752 sgd_solver.cpp:106] Iteration 36915200, lr = 3.9063e-06
I0418 04:49:27.976984 10752 solver.cpp:228] Iteration 36966400, loss = 2.54924
I0418 04:49:27.977035 10752 solver.cpp:244]     Train net output #0: loss = 5.42655 (* 1 = 5.42655 loss)
I0418 04:49:27.977041 10752 sgd_solver.cpp:106] Iteration 36966400, lr = 3.9063e-06
I0418 04:54:33.911475 10752 solver.cpp:228] Iteration 37017600, loss = 2.53923
I0418 04:54:33.911545 10752 solver.cpp:244]     Train net output #0: loss = 0.470769 (* 1 = 0.470769 loss)
I0418 04:54:33.911551 10752 sgd_solver.cpp:106] Iteration 37017600, lr = 3.9063e-06
I0418 04:59:39.759124 10752 solver.cpp:228] Iteration 37068800, loss = 2.53489
I0418 04:59:39.759198 10752 solver.cpp:244]     Train net output #0: loss = 2.25212 (* 1 = 2.25212 loss)
I0418 04:59:39.759204 10752 sgd_solver.cpp:106] Iteration 37068800, lr = 3.9063e-06
I0418 05:04:45.616547 10752 solver.cpp:337] Iteration 37120000, Testing net (#0)
I0418 05:04:45.815767 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0418 05:05:12.088227 10752 solver.cpp:404]     Test net output #0: accuracy = 0.44418
I0418 05:05:12.088263 10752 solver.cpp:404]     Test net output #1: loss = 2.51028 (* 1 = 2.51028 loss)
I0418 05:05:12.090791 10752 solver.cpp:228] Iteration 37120000, loss = 2.52438
I0418 05:05:12.090812 10752 solver.cpp:244]     Train net output #0: loss = 0.923654 (* 1 = 0.923654 loss)
I0418 05:05:12.090824 10752 sgd_solver.cpp:106] Iteration 37120000, lr = 3.9063e-06
I0418 05:10:18.201097 10752 solver.cpp:228] Iteration 37171200, loss = 2.51809
I0418 05:10:18.201159 10752 solver.cpp:244]     Train net output #0: loss = 4.27072 (* 1 = 4.27072 loss)
I0418 05:10:18.201170 10752 sgd_solver.cpp:106] Iteration 37171200, lr = 3.9063e-06
I0418 05:15:24.172896 10752 solver.cpp:228] Iteration 37222400, loss = 2.53863
I0418 05:15:24.172969 10752 solver.cpp:244]     Train net output #0: loss = 0.0867662 (* 1 = 0.0867662 loss)
I0418 05:15:24.172982 10752 sgd_solver.cpp:106] Iteration 37222400, lr = 3.9063e-06
I0418 05:20:30.109351 10752 solver.cpp:228] Iteration 37273600, loss = 2.53401
I0418 05:20:30.109437 10752 solver.cpp:244]     Train net output #0: loss = 2.35189 (* 1 = 2.35189 loss)
I0418 05:20:30.109452 10752 sgd_solver.cpp:106] Iteration 37273600, lr = 3.9063e-06
I0418 05:25:35.936628 10752 solver.cpp:228] Iteration 37324800, loss = 2.53116
I0418 05:25:35.936704 10752 solver.cpp:244]     Train net output #0: loss = 0.00315884 (* 1 = 0.00315884 loss)
I0418 05:25:35.936717 10752 sgd_solver.cpp:106] Iteration 37324800, lr = 3.9063e-06
I0418 05:30:41.804612 10752 solver.cpp:337] Iteration 37376000, Testing net (#0)
I0418 05:30:42.057763 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0418 05:31:08.328035 10752 solver.cpp:404]     Test net output #0: accuracy = 0.44324
I0418 05:31:08.328069 10752 solver.cpp:404]     Test net output #1: loss = 2.51094 (* 1 = 2.51094 loss)
I0418 05:31:08.330564 10752 solver.cpp:228] Iteration 37376000, loss = 2.54529
I0418 05:31:08.330581 10752 solver.cpp:244]     Train net output #0: loss = 3.83605 (* 1 = 3.83605 loss)
I0418 05:31:08.330593 10752 sgd_solver.cpp:106] Iteration 37376000, lr = 3.9063e-06
I0418 05:36:14.390602 10752 solver.cpp:228] Iteration 37427200, loss = 2.5437
I0418 05:36:14.390666 10752 solver.cpp:244]     Train net output #0: loss = 1.14915 (* 1 = 1.14915 loss)
I0418 05:36:14.390677 10752 sgd_solver.cpp:106] Iteration 37427200, lr = 3.9063e-06
I0418 05:41:20.404129 10752 solver.cpp:228] Iteration 37478400, loss = 2.55587
I0418 05:41:20.404191 10752 solver.cpp:244]     Train net output #0: loss = 0.0286341 (* 1 = 0.0286341 loss)
I0418 05:41:20.404196 10752 sgd_solver.cpp:106] Iteration 37478400, lr = 3.9063e-06
I0418 05:46:26.406947 10752 solver.cpp:228] Iteration 37529600, loss = 2.52611
I0418 05:46:26.407007 10752 solver.cpp:244]     Train net output #0: loss = 0.00184378 (* 1 = 0.00184378 loss)
I0418 05:46:26.407016 10752 sgd_solver.cpp:106] Iteration 37529600, lr = 3.9063e-06
I0418 05:51:32.361413 10752 solver.cpp:228] Iteration 37580800, loss = 2.52927
I0418 05:51:32.361471 10752 solver.cpp:244]     Train net output #0: loss = 2.0575 (* 1 = 2.0575 loss)
I0418 05:51:32.361479 10752 sgd_solver.cpp:106] Iteration 37580800, lr = 3.9063e-06
I0418 05:56:38.316740 10752 solver.cpp:337] Iteration 37632000, Testing net (#0)
I0418 05:56:38.623697 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0418 05:57:04.769804 10752 solver.cpp:404]     Test net output #0: accuracy = 0.44206
I0418 05:57:04.769839 10752 solver.cpp:404]     Test net output #1: loss = 2.52205 (* 1 = 2.52205 loss)
I0418 05:57:04.772389 10752 solver.cpp:228] Iteration 37632000, loss = 2.51906
I0418 05:57:04.772409 10752 solver.cpp:244]     Train net output #0: loss = 0.0105517 (* 1 = 0.0105517 loss)
I0418 05:57:04.772420 10752 sgd_solver.cpp:106] Iteration 37632000, lr = 3.9063e-06
I0418 06:02:10.775429 10752 solver.cpp:228] Iteration 37683200, loss = 2.52956
I0418 06:02:10.775502 10752 solver.cpp:244]     Train net output #0: loss = 4.92291 (* 1 = 4.92291 loss)
I0418 06:02:10.775516 10752 sgd_solver.cpp:106] Iteration 37683200, lr = 3.9063e-06
I0418 06:07:16.801362 10752 solver.cpp:228] Iteration 37734400, loss = 2.51862
I0418 06:07:16.801425 10752 solver.cpp:244]     Train net output #0: loss = 3.71582 (* 1 = 3.71582 loss)
I0418 06:07:16.801440 10752 sgd_solver.cpp:106] Iteration 37734400, lr = 3.9063e-06
I0418 06:12:22.857523 10752 solver.cpp:228] Iteration 37785600, loss = 2.52017
I0418 06:12:22.857585 10752 solver.cpp:244]     Train net output #0: loss = 2.528 (* 1 = 2.528 loss)
I0418 06:12:22.857594 10752 sgd_solver.cpp:106] Iteration 37785600, lr = 3.9063e-06
I0418 06:17:28.765768 10752 solver.cpp:228] Iteration 37836800, loss = 2.5027
I0418 06:17:28.765830 10752 solver.cpp:244]     Train net output #0: loss = 1.68182 (* 1 = 1.68182 loss)
I0418 06:17:28.765841 10752 sgd_solver.cpp:106] Iteration 37836800, lr = 3.9063e-06
I0418 06:22:34.792482 10752 solver.cpp:337] Iteration 37888000, Testing net (#0)
I0418 06:22:35.151978 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0418 06:23:01.232374 10752 solver.cpp:404]     Test net output #0: accuracy = 0.44526
I0418 06:23:01.232408 10752 solver.cpp:404]     Test net output #1: loss = 2.52063 (* 1 = 2.52063 loss)
I0418 06:23:01.234967 10752 solver.cpp:228] Iteration 37888000, loss = 2.53715
I0418 06:23:01.234985 10752 solver.cpp:244]     Train net output #0: loss = 0.989423 (* 1 = 0.989423 loss)
I0418 06:23:01.234997 10752 sgd_solver.cpp:106] Iteration 37888000, lr = 3.9063e-06
I0418 06:28:07.390954 10752 solver.cpp:228] Iteration 37939200, loss = 2.54934
I0418 06:28:07.391028 10752 solver.cpp:244]     Train net output #0: loss = 2.99743 (* 1 = 2.99743 loss)
I0418 06:28:07.391036 10752 sgd_solver.cpp:106] Iteration 37939200, lr = 3.9063e-06
I0418 06:33:13.355862 10752 solver.cpp:228] Iteration 37990400, loss = 2.55284
I0418 06:33:13.355929 10752 solver.cpp:244]     Train net output #0: loss = 2.82144 (* 1 = 2.82144 loss)
I0418 06:33:13.355942 10752 sgd_solver.cpp:106] Iteration 37990400, lr = 3.9063e-06
I0418 06:38:19.186034 10752 solver.cpp:228] Iteration 38041600, loss = 2.56532
I0418 06:38:19.186108 10752 solver.cpp:244]     Train net output #0: loss = 0.942571 (* 1 = 0.942571 loss)
I0418 06:38:19.186120 10752 sgd_solver.cpp:106] Iteration 38041600, lr = 3.9063e-06
I0418 06:43:25.110630 10752 solver.cpp:228] Iteration 38092800, loss = 2.53196
I0418 06:43:25.110692 10752 solver.cpp:244]     Train net output #0: loss = 0.113517 (* 1 = 0.113517 loss)
I0418 06:43:25.110700 10752 sgd_solver.cpp:106] Iteration 38092800, lr = 3.9063e-06
I0418 06:48:31.082867 10752 solver.cpp:337] Iteration 38144000, Testing net (#0)
I0418 06:48:31.496043 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0418 06:48:57.591400 10752 solver.cpp:404]     Test net output #0: accuracy = 0.44424
I0418 06:48:57.591434 10752 solver.cpp:404]     Test net output #1: loss = 2.51589 (* 1 = 2.51589 loss)
I0418 06:48:57.593991 10752 solver.cpp:228] Iteration 38144000, loss = 2.55031
I0418 06:48:57.594009 10752 solver.cpp:244]     Train net output #0: loss = 0.279541 (* 1 = 0.279541 loss)
I0418 06:48:57.594019 10752 sgd_solver.cpp:106] Iteration 38144000, lr = 3.9063e-06
I0418 06:54:03.751099 10752 solver.cpp:228] Iteration 38195200, loss = 2.53172
I0418 06:54:03.751160 10752 solver.cpp:244]     Train net output #0: loss = 0.804536 (* 1 = 0.804536 loss)
I0418 06:54:03.751166 10752 sgd_solver.cpp:106] Iteration 38195200, lr = 3.9063e-06
I0418 06:59:09.745043 10752 solver.cpp:228] Iteration 38246400, loss = 2.54054
I0418 06:59:09.745103 10752 solver.cpp:244]     Train net output #0: loss = 0.00310109 (* 1 = 0.00310109 loss)
I0418 06:59:09.745111 10752 sgd_solver.cpp:106] Iteration 38246400, lr = 3.9063e-06
I0418 07:04:15.768218 10752 solver.cpp:228] Iteration 38297600, loss = 2.53468
I0418 07:04:15.768277 10752 solver.cpp:244]     Train net output #0: loss = 7.17726 (* 1 = 7.17726 loss)
I0418 07:04:15.768283 10752 sgd_solver.cpp:106] Iteration 38297600, lr = 3.9063e-06
I0418 07:09:21.812679 10752 solver.cpp:228] Iteration 38348800, loss = 2.52289
I0418 07:09:21.812753 10752 solver.cpp:244]     Train net output #0: loss = 0.118459 (* 1 = 0.118459 loss)
I0418 07:09:21.812763 10752 sgd_solver.cpp:106] Iteration 38348800, lr = 3.9063e-06
I0418 07:14:27.925894 10752 solver.cpp:454] Snapshotting to binary proto file snapshots/caffenet128_no_lrn_lsuv_relu_bs1_iter_38400000.caffemodel
I0418 07:14:28.101683 10752 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/caffenet128_no_lrn_lsuv_relu_bs1_iter_38400000.solverstate
I0418 07:14:28.158983 10752 solver.cpp:337] Iteration 38400000, Testing net (#0)
I0418 07:14:28.676197 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0418 07:14:54.970461 10752 solver.cpp:404]     Test net output #0: accuracy = 0.44568
I0418 07:14:54.970495 10752 solver.cpp:404]     Test net output #1: loss = 2.50884 (* 1 = 2.50884 loss)
I0418 07:14:54.973068 10752 solver.cpp:228] Iteration 38400000, loss = 2.51476
I0418 07:14:54.973086 10752 solver.cpp:244]     Train net output #0: loss = 3.9378 (* 1 = 3.9378 loss)
I0418 07:14:54.973098 10752 sgd_solver.cpp:106] Iteration 38400000, lr = 3.9063e-06
I0418 07:20:01.085199 10752 solver.cpp:228] Iteration 38451200, loss = 2.51703
I0418 07:20:01.085294 10752 solver.cpp:244]     Train net output #0: loss = 3.6596 (* 1 = 3.6596 loss)
I0418 07:20:01.085309 10752 sgd_solver.cpp:106] Iteration 38451200, lr = 3.9063e-06
I0418 07:25:06.936393 10752 solver.cpp:228] Iteration 38502400, loss = 2.53017
I0418 07:25:06.936470 10752 solver.cpp:244]     Train net output #0: loss = 3.42267 (* 1 = 3.42267 loss)
I0418 07:25:06.936483 10752 sgd_solver.cpp:106] Iteration 38502400, lr = 3.9063e-06
I0418 07:30:13.035481 10752 solver.cpp:228] Iteration 38553600, loss = 2.50403
I0418 07:30:13.035554 10752 solver.cpp:244]     Train net output #0: loss = 1.64809 (* 1 = 1.64809 loss)
I0418 07:30:13.035562 10752 sgd_solver.cpp:106] Iteration 38553600, lr = 3.9063e-06
I0418 07:35:19.065291 10752 solver.cpp:228] Iteration 38604800, loss = 2.52911
I0418 07:35:19.065361 10752 solver.cpp:244]     Train net output #0: loss = 0.614659 (* 1 = 0.614659 loss)
I0418 07:35:19.065367 10752 sgd_solver.cpp:106] Iteration 38604800, lr = 3.9063e-06
I0418 07:40:25.172938 10752 solver.cpp:337] Iteration 38656000, Testing net (#0)
I0418 07:40:25.689635 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0418 07:40:51.608497 10752 solver.cpp:404]     Test net output #0: accuracy = 0.4453
I0418 07:40:51.608530 10752 solver.cpp:404]     Test net output #1: loss = 2.50879 (* 1 = 2.50879 loss)
I0418 07:40:51.611088 10752 solver.cpp:228] Iteration 38656000, loss = 2.54478
I0418 07:40:51.611104 10752 solver.cpp:244]     Train net output #0: loss = 1.64328 (* 1 = 1.64328 loss)
I0418 07:40:51.611116 10752 sgd_solver.cpp:106] Iteration 38656000, lr = 3.9063e-06
I0418 07:45:57.838137 10752 solver.cpp:228] Iteration 38707200, loss = 2.54385
I0418 07:45:57.838191 10752 solver.cpp:244]     Train net output #0: loss = 2.82717 (* 1 = 2.82717 loss)
I0418 07:45:57.838206 10752 sgd_solver.cpp:106] Iteration 38707200, lr = 3.9063e-06
I0418 07:51:04.063338 10752 solver.cpp:228] Iteration 38758400, loss = 2.53427
I0418 07:51:04.063400 10752 solver.cpp:244]     Train net output #0: loss = 1.70823 (* 1 = 1.70823 loss)
I0418 07:51:04.063410 10752 sgd_solver.cpp:106] Iteration 38758400, lr = 3.9063e-06
I0418 07:56:10.301394 10752 solver.cpp:228] Iteration 38809600, loss = 2.51277
I0418 07:56:10.301468 10752 solver.cpp:244]     Train net output #0: loss = 0.2963 (* 1 = 0.2963 loss)
I0418 07:56:10.301476 10752 sgd_solver.cpp:106] Iteration 38809600, lr = 3.9063e-06
I0418 08:01:16.575625 10752 solver.cpp:228] Iteration 38860800, loss = 2.50907
I0418 08:01:16.575696 10752 solver.cpp:244]     Train net output #0: loss = 3.42576 (* 1 = 3.42576 loss)
I0418 08:01:16.575702 10752 sgd_solver.cpp:106] Iteration 38860800, lr = 3.9063e-06
I0418 08:06:22.764205 10752 solver.cpp:337] Iteration 38912000, Testing net (#0)
I0418 08:06:23.304165 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0418 08:06:49.281044 10752 solver.cpp:404]     Test net output #0: accuracy = 0.44634
I0418 08:06:49.281076 10752 solver.cpp:404]     Test net output #1: loss = 2.50505 (* 1 = 2.50505 loss)
I0418 08:06:49.283603 10752 solver.cpp:228] Iteration 38912000, loss = 2.50831
I0418 08:06:49.283622 10752 solver.cpp:244]     Train net output #0: loss = 0.394939 (* 1 = 0.394939 loss)
I0418 08:06:49.283632 10752 sgd_solver.cpp:106] Iteration 38912000, lr = 3.9063e-06
I0418 08:11:55.562922 10752 solver.cpp:228] Iteration 38963200, loss = 2.51068
I0418 08:11:55.562995 10752 solver.cpp:244]     Train net output #0: loss = 0.456838 (* 1 = 0.456838 loss)
I0418 08:11:55.563002 10752 sgd_solver.cpp:106] Iteration 38963200, lr = 3.9063e-06
I0418 08:17:01.643899 10752 solver.cpp:228] Iteration 39014400, loss = 2.51651
I0418 08:17:01.643962 10752 solver.cpp:244]     Train net output #0: loss = 0.160198 (* 1 = 0.160198 loss)
I0418 08:17:01.643968 10752 sgd_solver.cpp:106] Iteration 39014400, lr = 3.9063e-06
I0418 08:22:07.804240 10752 solver.cpp:228] Iteration 39065600, loss = 2.51237
I0418 08:22:07.804321 10752 solver.cpp:244]     Train net output #0: loss = 0.453579 (* 1 = 0.453579 loss)
I0418 08:22:07.804328 10752 sgd_solver.cpp:106] Iteration 39065600, lr = 3.9063e-06
I0418 08:27:13.899981 10752 solver.cpp:228] Iteration 39116800, loss = 2.49628
I0418 08:27:13.900053 10752 solver.cpp:244]     Train net output #0: loss = 4.68135 (* 1 = 4.68135 loss)
I0418 08:27:13.900059 10752 sgd_solver.cpp:106] Iteration 39116800, lr = 3.9063e-06
I0418 08:32:19.995746 10752 solver.cpp:337] Iteration 39168000, Testing net (#0)
I0418 08:32:20.663064 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0418 08:32:46.930543 10752 solver.cpp:404]     Test net output #0: accuracy = 0.4472
I0418 08:32:46.930577 10752 solver.cpp:404]     Test net output #1: loss = 2.50259 (* 1 = 2.50259 loss)
I0418 08:32:46.933102 10752 solver.cpp:228] Iteration 39168000, loss = 2.52924
I0418 08:32:46.933120 10752 solver.cpp:244]     Train net output #0: loss = 4.2268 (* 1 = 4.2268 loss)
I0418 08:32:46.933130 10752 sgd_solver.cpp:106] Iteration 39168000, lr = 3.9063e-06
I0418 08:37:53.075135 10752 solver.cpp:228] Iteration 39219200, loss = 2.54445
I0418 08:37:53.075191 10752 solver.cpp:244]     Train net output #0: loss = 1.28328 (* 1 = 1.28328 loss)
I0418 08:37:53.075201 10752 sgd_solver.cpp:106] Iteration 39219200, lr = 3.9063e-06
I0418 08:42:59.220666 10752 solver.cpp:228] Iteration 39270400, loss = 2.53924
I0418 08:42:59.220741 10752 solver.cpp:244]     Train net output #0: loss = 5.92829 (* 1 = 5.92829 loss)
I0418 08:42:59.220749 10752 sgd_solver.cpp:106] Iteration 39270400, lr = 3.9063e-06
I0418 08:48:05.297186 10752 solver.cpp:228] Iteration 39321600, loss = 2.5384
I0418 08:48:05.297240 10752 solver.cpp:244]     Train net output #0: loss = 0.263899 (* 1 = 0.263899 loss)
I0418 08:48:05.297246 10752 sgd_solver.cpp:106] Iteration 39321600, lr = 3.9063e-06
I0418 08:53:11.358461 10752 solver.cpp:228] Iteration 39372800, loss = 2.52462
I0418 08:53:11.358521 10752 solver.cpp:244]     Train net output #0: loss = 0.214892 (* 1 = 0.214892 loss)
I0418 08:53:11.358528 10752 sgd_solver.cpp:106] Iteration 39372800, lr = 3.9063e-06
I0418 08:58:17.389997 10752 solver.cpp:337] Iteration 39424000, Testing net (#0)
I0418 08:58:18.037088 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0418 08:58:43.879148 10752 solver.cpp:404]     Test net output #0: accuracy = 0.4455
I0418 08:58:43.879184 10752 solver.cpp:404]     Test net output #1: loss = 2.50655 (* 1 = 2.50655 loss)
I0418 08:58:43.881727 10752 solver.cpp:228] Iteration 39424000, loss = 2.53853
I0418 08:58:43.881748 10752 solver.cpp:244]     Train net output #0: loss = 6.6344 (* 1 = 6.6344 loss)
I0418 08:58:43.881759 10752 sgd_solver.cpp:106] Iteration 39424000, lr = 3.9063e-06
I0418 09:03:49.969539 10752 solver.cpp:228] Iteration 39475200, loss = 2.52487
I0418 09:03:49.969614 10752 solver.cpp:244]     Train net output #0: loss = 0.985 (* 1 = 0.985 loss)
I0418 09:03:49.969625 10752 sgd_solver.cpp:106] Iteration 39475200, lr = 3.9063e-06
I0418 09:08:55.926182 10752 solver.cpp:228] Iteration 39526400, loss = 2.5388
I0418 09:08:55.926249 10752 solver.cpp:244]     Train net output #0: loss = 0.254862 (* 1 = 0.254862 loss)
I0418 09:08:55.926259 10752 sgd_solver.cpp:106] Iteration 39526400, lr = 3.9063e-06
I0418 09:14:02.054677 10752 solver.cpp:228] Iteration 39577600, loss = 2.53208
I0418 09:14:02.054738 10752 solver.cpp:244]     Train net output #0: loss = 2.42812 (* 1 = 2.42812 loss)
I0418 09:14:02.054750 10752 sgd_solver.cpp:106] Iteration 39577600, lr = 3.9063e-06
I0418 09:19:12.113591 10752 solver.cpp:228] Iteration 39628800, loss = 2.5097
I0418 09:19:12.113648 10752 solver.cpp:244]     Train net output #0: loss = 1.76165 (* 1 = 1.76165 loss)
I0418 09:19:12.113654 10752 sgd_solver.cpp:106] Iteration 39628800, lr = 3.9063e-06
I0418 09:24:18.404716 10752 solver.cpp:337] Iteration 39680000, Testing net (#0)
I0418 09:24:19.013576 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0418 09:24:45.334610 10752 solver.cpp:404]     Test net output #0: accuracy = 0.44442
I0418 09:24:45.334646 10752 solver.cpp:404]     Test net output #1: loss = 2.50908 (* 1 = 2.50908 loss)
I0418 09:24:45.337178 10752 solver.cpp:228] Iteration 39680000, loss = 2.4965
I0418 09:24:45.337198 10752 solver.cpp:244]     Train net output #0: loss = 0.0633052 (* 1 = 0.0633052 loss)
I0418 09:24:45.337208 10752 sgd_solver.cpp:106] Iteration 39680000, lr = 3.9063e-06
I0418 09:29:52.415993 10752 solver.cpp:228] Iteration 39731200, loss = 2.51209
I0418 09:29:52.416080 10752 solver.cpp:244]     Train net output #0: loss = 2.48783 (* 1 = 2.48783 loss)
I0418 09:29:52.416086 10752 sgd_solver.cpp:106] Iteration 39731200, lr = 3.9063e-06
I0418 09:34:59.183586 10752 solver.cpp:228] Iteration 39782400, loss = 2.52014
I0418 09:34:59.183648 10752 solver.cpp:244]     Train net output #0: loss = 0.374791 (* 1 = 0.374791 loss)
I0418 09:34:59.183655 10752 sgd_solver.cpp:106] Iteration 39782400, lr = 3.9063e-06
I0418 09:40:05.853991 10752 solver.cpp:228] Iteration 39833600, loss = 2.51552
I0418 09:40:05.854056 10752 solver.cpp:244]     Train net output #0: loss = 4.21787 (* 1 = 4.21787 loss)
I0418 09:40:05.854068 10752 sgd_solver.cpp:106] Iteration 39833600, lr = 3.9063e-06
I0418 09:45:13.453786 10752 solver.cpp:228] Iteration 39884800, loss = 2.51373
I0418 09:45:13.453862 10752 solver.cpp:244]     Train net output #0: loss = 0.00510653 (* 1 = 0.00510653 loss)
I0418 09:45:13.453871 10752 sgd_solver.cpp:106] Iteration 39884800, lr = 3.9063e-06
I0418 09:50:20.182493 10752 solver.cpp:337] Iteration 39936000, Testing net (#0)
I0418 09:50:20.595485 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0418 09:50:46.641724 10752 solver.cpp:404]     Test net output #0: accuracy = 0.44642
I0418 09:50:46.641757 10752 solver.cpp:404]     Test net output #1: loss = 2.49807 (* 1 = 2.49807 loss)
I0418 09:50:46.644273 10752 solver.cpp:228] Iteration 39936000, loss = 2.54014
I0418 09:50:46.644290 10752 solver.cpp:244]     Train net output #0: loss = 3.4197 (* 1 = 3.4197 loss)
I0418 09:50:46.644299 10752 sgd_solver.cpp:106] Iteration 39936000, lr = 3.9063e-06
I0418 09:55:53.839861 10752 solver.cpp:228] Iteration 39987200, loss = 2.53072
I0418 09:55:53.839937 10752 solver.cpp:244]     Train net output #0: loss = 7.46531 (* 1 = 7.46531 loss)
I0418 09:55:53.839943 10752 sgd_solver.cpp:106] Iteration 39987200, lr = 3.9063e-06
I0418 10:01:00.697382 10752 solver.cpp:228] Iteration 40038400, loss = 2.52862
I0418 10:01:00.697456 10752 solver.cpp:244]     Train net output #0: loss = 2.17765 (* 1 = 2.17765 loss)
I0418 10:01:00.697463 10752 sgd_solver.cpp:106] Iteration 40038400, lr = 3.9063e-06
I0418 10:06:08.662721 10752 solver.cpp:228] Iteration 40089600, loss = 2.51172
I0418 10:06:08.662781 10752 solver.cpp:244]     Train net output #0: loss = 6.08686 (* 1 = 6.08686 loss)
I0418 10:06:08.662787 10752 sgd_solver.cpp:106] Iteration 40089600, lr = 3.9063e-06
I0418 10:11:18.225389 10752 solver.cpp:228] Iteration 40140800, loss = 2.51312
I0418 10:11:18.225462 10752 solver.cpp:244]     Train net output #0: loss = 0.0113061 (* 1 = 0.0113061 loss)
I0418 10:11:18.225468 10752 sgd_solver.cpp:106] Iteration 40140800, lr = 3.9063e-06
I0418 10:16:25.986876 10752 solver.cpp:337] Iteration 40192000, Testing net (#0)
I0418 10:16:26.106662 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0418 10:16:52.512671 10752 solver.cpp:404]     Test net output #0: accuracy = 0.44698
I0418 10:16:52.512707 10752 solver.cpp:404]     Test net output #1: loss = 2.49968 (* 1 = 2.49968 loss)
I0418 10:16:52.515259 10752 solver.cpp:228] Iteration 40192000, loss = 2.48733
I0418 10:16:52.515280 10752 solver.cpp:244]     Train net output #0: loss = 5.08407 (* 1 = 5.08407 loss)
I0418 10:16:52.515290 10752 sgd_solver.cpp:106] Iteration 40192000, lr = 3.9063e-06
I0418 10:22:03.135071 10752 solver.cpp:228] Iteration 40243200, loss = 2.50944
I0418 10:22:03.135139 10752 solver.cpp:244]     Train net output #0: loss = 0.00796526 (* 1 = 0.00796526 loss)
I0418 10:22:03.135145 10752 sgd_solver.cpp:106] Iteration 40243200, lr = 3.9063e-06
I0418 10:22:31.930693 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0418 10:27:12.886925 10752 solver.cpp:228] Iteration 40294400, loss = 2.51099
I0418 10:27:12.887011 10752 solver.cpp:244]     Train net output #0: loss = 5.4379 (* 1 = 5.4379 loss)
I0418 10:27:12.887020 10752 sgd_solver.cpp:106] Iteration 40294400, lr = 3.9063e-06
I0418 10:32:19.560968 10752 solver.cpp:228] Iteration 40345600, loss = 2.5062
I0418 10:32:19.561044 10752 solver.cpp:244]     Train net output #0: loss = 6.1214 (* 1 = 6.1214 loss)
I0418 10:32:19.561053 10752 sgd_solver.cpp:106] Iteration 40345600, lr = 3.9063e-06
I0418 10:37:27.150609 10752 solver.cpp:228] Iteration 40396800, loss = 2.48519
I0418 10:37:27.150686 10752 solver.cpp:244]     Train net output #0: loss = 0.124116 (* 1 = 0.124116 loss)
I0418 10:37:27.150696 10752 sgd_solver.cpp:106] Iteration 40396800, lr = 3.9063e-06
I0418 10:42:33.775302 10752 solver.cpp:337] Iteration 40448000, Testing net (#0)
I0418 10:43:00.179484 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0418 10:43:00.258508 10752 solver.cpp:404]     Test net output #0: accuracy = 0.4461
I0418 10:43:00.258543 10752 solver.cpp:404]     Test net output #1: loss = 2.50551 (* 1 = 2.50551 loss)
I0418 10:43:00.261198 10752 solver.cpp:228] Iteration 40448000, loss = 2.52858
I0418 10:43:00.261219 10752 solver.cpp:244]     Train net output #0: loss = 0.311815 (* 1 = 0.311815 loss)
I0418 10:43:00.261275 10752 sgd_solver.cpp:106] Iteration 40448000, lr = 3.9063e-06
I0418 10:48:07.579120 10752 solver.cpp:228] Iteration 40499200, loss = 2.54093
I0418 10:48:07.579192 10752 solver.cpp:244]     Train net output #0: loss = 1.26852 (* 1 = 1.26852 loss)
I0418 10:48:07.579200 10752 sgd_solver.cpp:106] Iteration 40499200, lr = 3.9063e-06
I0418 10:53:15.811542 10752 solver.cpp:228] Iteration 40550400, loss = 2.52993
I0418 10:53:15.811606 10752 solver.cpp:244]     Train net output #0: loss = 5.36864 (* 1 = 5.36864 loss)
I0418 10:53:15.811616 10752 sgd_solver.cpp:106] Iteration 40550400, lr = 3.9063e-06
I0418 10:58:23.330191 10752 solver.cpp:228] Iteration 40601600, loss = 2.54016
I0418 10:58:23.330250 10752 solver.cpp:244]     Train net output #0: loss = 5.08306 (* 1 = 5.08306 loss)
I0418 10:58:23.330255 10752 sgd_solver.cpp:106] Iteration 40601600, lr = 3.9063e-06
I0418 11:03:30.224580 10752 solver.cpp:228] Iteration 40652800, loss = 2.50929
I0418 11:03:30.224645 10752 solver.cpp:244]     Train net output #0: loss = 0.37429 (* 1 = 0.37429 loss)
I0418 11:03:30.224653 10752 sgd_solver.cpp:106] Iteration 40652800, lr = 3.9063e-06
I0418 11:08:38.092268 10752 solver.cpp:337] Iteration 40704000, Testing net (#0)
I0418 11:09:05.650205 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0418 11:09:05.933349 10752 solver.cpp:404]     Test net output #0: accuracy = 0.44714
I0418 11:09:05.933413 10752 solver.cpp:404]     Test net output #1: loss = 2.49833 (* 1 = 2.49833 loss)
I0418 11:09:05.935972 10752 solver.cpp:228] Iteration 40704000, loss = 2.52394
I0418 11:09:05.935992 10752 solver.cpp:244]     Train net output #0: loss = 3.17655 (* 1 = 3.17655 loss)
I0418 11:09:05.936000 10752 sgd_solver.cpp:106] Iteration 40704000, lr = 3.9063e-06
I0418 11:14:14.078725 10752 solver.cpp:228] Iteration 40755200, loss = 2.5223
I0418 11:14:14.078800 10752 solver.cpp:244]     Train net output #0: loss = 5.21888 (* 1 = 5.21888 loss)
I0418 11:14:14.078809 10752 sgd_solver.cpp:106] Iteration 40755200, lr = 3.9063e-06
I0418 11:19:20.142704 10752 solver.cpp:228] Iteration 40806400, loss = 2.53156
I0418 11:19:20.142767 10752 solver.cpp:244]     Train net output #0: loss = 2.94685 (* 1 = 2.94685 loss)
I0418 11:19:20.142777 10752 sgd_solver.cpp:106] Iteration 40806400, lr = 3.9063e-06
I0418 11:24:28.832028 10752 solver.cpp:228] Iteration 40857600, loss = 2.52371
I0418 11:24:28.832092 10752 solver.cpp:244]     Train net output #0: loss = 4.05182 (* 1 = 4.05182 loss)
I0418 11:24:28.832101 10752 sgd_solver.cpp:106] Iteration 40857600, lr = 3.9063e-06
I0418 11:29:34.847811 10752 solver.cpp:228] Iteration 40908800, loss = 2.50643
I0418 11:29:34.847900 10752 solver.cpp:244]     Train net output #0: loss = 2.71797 (* 1 = 2.71797 loss)
I0418 11:29:34.847914 10752 sgd_solver.cpp:106] Iteration 40908800, lr = 3.9063e-06
I0418 11:34:40.791456 10752 solver.cpp:454] Snapshotting to binary proto file snapshots/caffenet128_no_lrn_lsuv_relu_bs1_iter_40960000.caffemodel
I0418 11:34:41.020167 10752 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/caffenet128_no_lrn_lsuv_relu_bs1_iter_40960000.solverstate
I0418 11:34:41.080376 10752 solver.cpp:337] Iteration 40960000, Testing net (#0)
I0418 11:35:07.224022 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0418 11:35:07.566985 10752 solver.cpp:404]     Test net output #0: accuracy = 0.44684
I0418 11:35:07.567019 10752 solver.cpp:404]     Test net output #1: loss = 2.49347 (* 1 = 2.49347 loss)
I0418 11:35:07.569545 10752 solver.cpp:228] Iteration 40960000, loss = 2.49854
I0418 11:35:07.569561 10752 solver.cpp:244]     Train net output #0: loss = 2.25443 (* 1 = 2.25443 loss)
I0418 11:35:07.569571 10752 sgd_solver.cpp:106] Iteration 40960000, lr = 3.9063e-06
I0418 11:40:13.719393 10752 solver.cpp:228] Iteration 41011200, loss = 2.49637
I0418 11:40:13.719457 10752 solver.cpp:244]     Train net output #0: loss = 0.493115 (* 1 = 0.493115 loss)
I0418 11:40:13.719465 10752 sgd_solver.cpp:106] Iteration 41011200, lr = 3.9063e-06
I0418 11:45:19.743525 10752 solver.cpp:228] Iteration 41062400, loss = 2.50494
I0418 11:45:19.743595 10752 solver.cpp:244]     Train net output #0: loss = 1.18463 (* 1 = 1.18463 loss)
I0418 11:45:19.743602 10752 sgd_solver.cpp:106] Iteration 41062400, lr = 3.9063e-06
I0418 11:50:25.755806 10752 solver.cpp:228] Iteration 41113600, loss = 2.49596
I0418 11:50:25.755878 10752 solver.cpp:244]     Train net output #0: loss = 0.00820585 (* 1 = 0.00820585 loss)
I0418 11:50:25.755884 10752 sgd_solver.cpp:106] Iteration 41113600, lr = 3.9063e-06
I0418 11:55:31.690615 10752 solver.cpp:228] Iteration 41164800, loss = 2.50293
I0418 11:55:31.690675 10752 solver.cpp:244]     Train net output #0: loss = 0.870024 (* 1 = 0.870024 loss)
I0418 11:55:31.690685 10752 sgd_solver.cpp:106] Iteration 41164800, lr = 3.9063e-06
I0418 12:00:37.760596 10752 solver.cpp:337] Iteration 41216000, Testing net (#0)
I0418 12:01:03.931215 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0418 12:01:04.220496 10752 solver.cpp:404]     Test net output #0: accuracy = 0.44356
I0418 12:01:04.220530 10752 solver.cpp:404]     Test net output #1: loss = 2.50507 (* 1 = 2.50507 loss)
I0418 12:01:04.223104 10752 solver.cpp:228] Iteration 41216000, loss = 2.54731
I0418 12:01:04.223124 10752 solver.cpp:244]     Train net output #0: loss = 0.0260941 (* 1 = 0.0260941 loss)
I0418 12:01:04.223135 10752 sgd_solver.cpp:106] Iteration 41216000, lr = 3.9063e-06
I0418 12:06:10.482731 10752 solver.cpp:228] Iteration 41267200, loss = 2.52302
I0418 12:06:10.482806 10752 solver.cpp:244]     Train net output #0: loss = 3.27508 (* 1 = 3.27508 loss)
I0418 12:06:10.482813 10752 sgd_solver.cpp:106] Iteration 41267200, lr = 3.9063e-06
I0418 12:11:16.659869 10752 solver.cpp:228] Iteration 41318400, loss = 2.52349
I0418 12:11:16.659941 10752 solver.cpp:244]     Train net output #0: loss = 3.78943 (* 1 = 3.78943 loss)
I0418 12:11:16.659948 10752 sgd_solver.cpp:106] Iteration 41318400, lr = 3.9063e-06
I0418 12:16:22.767088 10752 solver.cpp:228] Iteration 41369600, loss = 2.50344
I0418 12:16:22.767163 10752 solver.cpp:244]     Train net output #0: loss = 6.88455 (* 1 = 6.88455 loss)
I0418 12:16:22.767170 10752 sgd_solver.cpp:106] Iteration 41369600, lr = 3.9063e-06
I0418 12:21:29.062744 10752 solver.cpp:228] Iteration 41420800, loss = 2.49162
I0418 12:21:29.062801 10752 solver.cpp:244]     Train net output #0: loss = 1.03633 (* 1 = 1.03633 loss)
I0418 12:21:29.062808 10752 sgd_solver.cpp:106] Iteration 41420800, lr = 3.9063e-06
I0418 12:26:35.371786 10752 solver.cpp:337] Iteration 41472000, Testing net (#0)
I0418 12:27:01.571257 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0418 12:27:01.808956 10752 solver.cpp:404]     Test net output #0: accuracy = 0.4464
I0418 12:27:01.808995 10752 solver.cpp:404]     Test net output #1: loss = 2.49451 (* 1 = 2.49451 loss)
I0418 12:27:01.811491 10752 solver.cpp:228] Iteration 41472000, loss = 2.48726
I0418 12:27:01.811507 10752 solver.cpp:244]     Train net output #0: loss = 1.08418 (* 1 = 1.08418 loss)
I0418 12:27:01.811513 10752 sgd_solver.cpp:106] Iteration 41472000, lr = 3.9063e-06
I0418 12:32:08.143458 10752 solver.cpp:228] Iteration 41523200, loss = 2.49918
I0418 12:32:08.143831 10752 solver.cpp:244]     Train net output #0: loss = 1.54355 (* 1 = 1.54355 loss)
I0418 12:32:08.143837 10752 sgd_solver.cpp:106] Iteration 41523200, lr = 3.9063e-06
I0418 12:37:14.283536 10752 solver.cpp:228] Iteration 41574400, loss = 2.48965
I0418 12:37:14.283612 10752 solver.cpp:244]     Train net output #0: loss = 3.92127 (* 1 = 3.92127 loss)
I0418 12:37:14.283620 10752 sgd_solver.cpp:106] Iteration 41574400, lr = 3.9063e-06
I0418 12:42:20.528249 10752 solver.cpp:228] Iteration 41625600, loss = 2.49956
I0418 12:42:20.528324 10752 solver.cpp:244]     Train net output #0: loss = 0.304119 (* 1 = 0.304119 loss)
I0418 12:42:20.528337 10752 sgd_solver.cpp:106] Iteration 41625600, lr = 3.9063e-06
I0418 12:47:26.639426 10752 solver.cpp:228] Iteration 41676800, loss = 2.477
I0418 12:47:26.639490 10752 solver.cpp:244]     Train net output #0: loss = 0.11903 (* 1 = 0.11903 loss)
I0418 12:47:26.639503 10752 sgd_solver.cpp:106] Iteration 41676800, lr = 3.9063e-06
I0418 12:52:32.744810 10752 solver.cpp:337] Iteration 41728000, Testing net (#0)
I0418 12:52:58.990010 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0418 12:52:59.174120 10752 solver.cpp:404]     Test net output #0: accuracy = 0.44584
I0418 12:52:59.174154 10752 solver.cpp:404]     Test net output #1: loss = 2.50279 (* 1 = 2.50279 loss)
I0418 12:52:59.176656 10752 solver.cpp:228] Iteration 41728000, loss = 2.51221
I0418 12:52:59.176672 10752 solver.cpp:244]     Train net output #0: loss = 0.0388103 (* 1 = 0.0388103 loss)
I0418 12:52:59.176681 10752 sgd_solver.cpp:106] Iteration 41728000, lr = 3.9063e-06
I0418 12:58:05.302219 10752 solver.cpp:228] Iteration 41779200, loss = 2.53263
I0418 12:58:05.302297 10752 solver.cpp:244]     Train net output #0: loss = 0.107815 (* 1 = 0.107815 loss)
I0418 12:58:05.302310 10752 sgd_solver.cpp:106] Iteration 41779200, lr = 3.9063e-06
I0418 13:03:11.309190 10752 solver.cpp:228] Iteration 41830400, loss = 2.53077
I0418 13:03:11.309263 10752 solver.cpp:244]     Train net output #0: loss = 0.743137 (* 1 = 0.743137 loss)
I0418 13:03:11.309276 10752 sgd_solver.cpp:106] Iteration 41830400, lr = 3.9063e-06
I0418 13:08:17.259744 10752 solver.cpp:228] Iteration 41881600, loss = 2.52978
I0418 13:08:17.259809 10752 solver.cpp:244]     Train net output #0: loss = 4.08676 (* 1 = 4.08676 loss)
I0418 13:08:17.259824 10752 sgd_solver.cpp:106] Iteration 41881600, lr = 3.9063e-06
I0418 13:13:23.318905 10752 solver.cpp:228] Iteration 41932800, loss = 2.50785
I0418 13:13:23.319185 10752 solver.cpp:244]     Train net output #0: loss = 4.80263 (* 1 = 4.80263 loss)
I0418 13:13:23.319200 10752 sgd_solver.cpp:106] Iteration 41932800, lr = 3.9063e-06
I0418 13:18:29.474742 10752 solver.cpp:337] Iteration 41984000, Testing net (#0)
I0418 13:18:56.532682 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0418 13:18:56.664583 10752 solver.cpp:404]     Test net output #0: accuracy = 0.44902
I0418 13:18:56.664616 10752 solver.cpp:404]     Test net output #1: loss = 2.49218 (* 1 = 2.49218 loss)
I0418 13:18:56.667135 10752 solver.cpp:228] Iteration 41984000, loss = 2.52362
I0418 13:18:56.667152 10752 solver.cpp:244]     Train net output #0: loss = 1.16636 (* 1 = 1.16636 loss)
I0418 13:18:56.667162 10752 sgd_solver.cpp:106] Iteration 41984000, lr = 3.9063e-06
I0418 13:24:02.846037 10752 solver.cpp:228] Iteration 42035200, loss = 2.50866
I0418 13:24:02.846098 10752 solver.cpp:244]     Train net output #0: loss = 3.83804 (* 1 = 3.83804 loss)
I0418 13:24:02.846106 10752 sgd_solver.cpp:106] Iteration 42035200, lr = 3.9063e-06
I0418 13:29:08.840298 10752 solver.cpp:228] Iteration 42086400, loss = 2.52091
I0418 13:29:08.840386 10752 solver.cpp:244]     Train net output #0: loss = 0.727665 (* 1 = 0.727665 loss)
I0418 13:29:08.840394 10752 sgd_solver.cpp:106] Iteration 42086400, lr = 3.9063e-06
I0418 13:34:14.913525 10752 solver.cpp:228] Iteration 42137600, loss = 2.51951
I0418 13:34:14.913596 10752 solver.cpp:244]     Train net output #0: loss = 0.56655 (* 1 = 0.56655 loss)
I0418 13:34:14.913610 10752 sgd_solver.cpp:106] Iteration 42137600, lr = 3.9063e-06
I0418 13:39:20.994480 10752 solver.cpp:228] Iteration 42188800, loss = 2.49579
I0418 13:39:20.994542 10752 solver.cpp:244]     Train net output #0: loss = 0.174102 (* 1 = 0.174102 loss)
I0418 13:39:20.994555 10752 sgd_solver.cpp:106] Iteration 42188800, lr = 3.9063e-06
I0418 13:44:27.127221 10752 solver.cpp:337] Iteration 42240000, Testing net (#0)
I0418 13:44:53.574035 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0418 13:44:53.653115 10752 solver.cpp:404]     Test net output #0: accuracy = 0.44666
I0418 13:44:53.653149 10752 solver.cpp:404]     Test net output #1: loss = 2.49359 (* 1 = 2.49359 loss)
I0418 13:44:53.655675 10752 solver.cpp:228] Iteration 42240000, loss = 2.48769
I0418 13:44:53.655694 10752 solver.cpp:244]     Train net output #0: loss = 3.732 (* 1 = 3.732 loss)
I0418 13:44:53.655704 10752 sgd_solver.cpp:106] Iteration 42240000, lr = 3.9063e-06
I0418 13:50:00.047688 10752 solver.cpp:228] Iteration 42291200, loss = 2.48869
I0418 13:50:00.047763 10752 solver.cpp:244]     Train net output #0: loss = 3.11589 (* 1 = 3.11589 loss)
I0418 13:50:00.047777 10752 sgd_solver.cpp:106] Iteration 42291200, lr = 3.9063e-06
I0418 13:55:06.183281 10752 solver.cpp:228] Iteration 42342400, loss = 2.49961
I0418 13:55:06.183354 10752 solver.cpp:244]     Train net output #0: loss = 2.78788 (* 1 = 2.78788 loss)
I0418 13:55:06.183367 10752 sgd_solver.cpp:106] Iteration 42342400, lr = 3.9063e-06
I0418 14:00:12.258170 10752 solver.cpp:228] Iteration 42393600, loss = 2.49346
I0418 14:00:12.258232 10752 solver.cpp:244]     Train net output #0: loss = 3.47959 (* 1 = 3.47959 loss)
I0418 14:00:12.258240 10752 sgd_solver.cpp:106] Iteration 42393600, lr = 3.9063e-06
I0418 14:05:18.307230 10752 solver.cpp:228] Iteration 42444800, loss = 2.49523
I0418 14:05:18.307303 10752 solver.cpp:244]     Train net output #0: loss = 0.000407361 (* 1 = 0.000407361 loss)
I0418 14:05:18.307315 10752 sgd_solver.cpp:106] Iteration 42444800, lr = 3.9063e-06
I0418 14:10:24.338209 10752 solver.cpp:337] Iteration 42496000, Testing net (#0)
I0418 14:10:50.751338 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0418 14:10:50.778269 10752 solver.cpp:404]     Test net output #0: accuracy = 0.45148
I0418 14:10:50.778304 10752 solver.cpp:404]     Test net output #1: loss = 2.48197 (* 1 = 2.48197 loss)
I0418 14:10:50.780855 10752 solver.cpp:228] Iteration 42496000, loss = 2.51795
I0418 14:10:50.780871 10752 solver.cpp:244]     Train net output #0: loss = 0.1308 (* 1 = 0.1308 loss)
I0418 14:10:50.780880 10752 sgd_solver.cpp:106] Iteration 42496000, lr = 3.9063e-06
I0418 14:15:56.964429 10752 solver.cpp:228] Iteration 42547200, loss = 2.52079
I0418 14:15:56.964489 10752 solver.cpp:244]     Train net output #0: loss = 5.39136 (* 1 = 5.39136 loss)
I0418 14:15:56.964495 10752 sgd_solver.cpp:106] Iteration 42547200, lr = 3.9063e-06
I0418 14:21:03.025988 10752 solver.cpp:228] Iteration 42598400, loss = 2.51679
I0418 14:21:03.026051 10752 solver.cpp:244]     Train net output #0: loss = 1.6447 (* 1 = 1.6447 loss)
I0418 14:21:03.026057 10752 sgd_solver.cpp:106] Iteration 42598400, lr = 3.9063e-06
I0418 14:26:09.180363 10752 solver.cpp:228] Iteration 42649600, loss = 2.4928
I0418 14:26:09.180426 10752 solver.cpp:244]     Train net output #0: loss = 1.47407 (* 1 = 1.47407 loss)
I0418 14:26:09.180433 10752 sgd_solver.cpp:106] Iteration 42649600, lr = 3.9063e-06
I0418 14:31:15.310070 10752 solver.cpp:228] Iteration 42700800, loss = 2.49369
I0418 14:31:15.310169 10752 solver.cpp:244]     Train net output #0: loss = 1.69296 (* 1 = 1.69296 loss)
I0418 14:31:15.310176 10752 sgd_solver.cpp:106] Iteration 42700800, lr = 3.9063e-06
I0418 14:36:21.551467 10752 solver.cpp:337] Iteration 42752000, Testing net (#0)
I0418 14:36:48.117112 10752 solver.cpp:404]     Test net output #0: accuracy = 0.45016
I0418 14:36:48.117180 10752 solver.cpp:404]     Test net output #1: loss = 2.48126 (* 1 = 2.48126 loss)
I0418 14:36:48.120254 10752 solver.cpp:228] Iteration 42752000, loss = 2.48042
I0418 14:36:48.120282 10752 solver.cpp:244]     Train net output #0: loss = 2.72019 (* 1 = 2.72019 loss)
I0418 14:36:48.120293 10752 sgd_solver.cpp:106] Iteration 42752000, lr = 3.9063e-06
I0418 14:41:54.295066 10752 solver.cpp:228] Iteration 42803200, loss = 2.48268
I0418 14:41:54.295127 10752 solver.cpp:244]     Train net output #0: loss = 2.12359 (* 1 = 2.12359 loss)
I0418 14:41:54.295140 10752 sgd_solver.cpp:106] Iteration 42803200, lr = 3.9063e-06
I0418 14:47:00.278751 10752 solver.cpp:228] Iteration 42854400, loss = 2.49674
I0418 14:47:00.278815 10752 solver.cpp:244]     Train net output #0: loss = 1.49348 (* 1 = 1.49348 loss)
I0418 14:47:00.278830 10752 sgd_solver.cpp:106] Iteration 42854400, lr = 3.9063e-06
I0418 14:52:06.476236 10752 solver.cpp:228] Iteration 42905600, loss = 2.4921
I0418 14:52:06.476296 10752 solver.cpp:244]     Train net output #0: loss = 0.326432 (* 1 = 0.326432 loss)
I0418 14:52:06.476303 10752 sgd_solver.cpp:106] Iteration 42905600, lr = 3.9063e-06
I0418 14:57:12.622457 10752 solver.cpp:228] Iteration 42956800, loss = 2.47007
I0418 14:57:12.622516 10752 solver.cpp:244]     Train net output #0: loss = 0.312393 (* 1 = 0.312393 loss)
I0418 14:57:12.622522 10752 sgd_solver.cpp:106] Iteration 42956800, lr = 3.9063e-06
I0418 15:02:18.731426 10752 solver.cpp:337] Iteration 43008000, Testing net (#0)
I0418 15:02:18.761932 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0418 15:02:45.239352 10752 solver.cpp:404]     Test net output #0: accuracy = 0.44826
I0418 15:02:45.239385 10752 solver.cpp:404]     Test net output #1: loss = 2.4949 (* 1 = 2.4949 loss)
I0418 15:02:45.241925 10752 solver.cpp:228] Iteration 43008000, loss = 2.5107
I0418 15:02:45.241941 10752 solver.cpp:244]     Train net output #0: loss = 2.45889 (* 1 = 2.45889 loss)
I0418 15:02:45.241950 10752 sgd_solver.cpp:106] Iteration 43008000, lr = 3.9063e-06
I0418 15:07:51.391907 10752 solver.cpp:228] Iteration 43059200, loss = 2.52906
I0418 15:07:51.391968 10752 solver.cpp:244]     Train net output #0: loss = 4.03757 (* 1 = 4.03757 loss)
I0418 15:07:51.391973 10752 sgd_solver.cpp:106] Iteration 43059200, lr = 3.9063e-06
I0418 15:12:57.505241 10752 solver.cpp:228] Iteration 43110400, loss = 2.51818
I0418 15:12:57.505301 10752 solver.cpp:244]     Train net output #0: loss = 4.05171 (* 1 = 4.05171 loss)
I0418 15:12:57.505308 10752 sgd_solver.cpp:106] Iteration 43110400, lr = 3.9063e-06
I0418 15:18:03.567227 10752 solver.cpp:228] Iteration 43161600, loss = 2.52822
I0418 15:18:03.567306 10752 solver.cpp:244]     Train net output #0: loss = 1.05754 (* 1 = 1.05754 loss)
I0418 15:18:03.567320 10752 sgd_solver.cpp:106] Iteration 43161600, lr = 3.9063e-06
I0418 15:23:09.549542 10752 solver.cpp:228] Iteration 43212800, loss = 2.49854
I0418 15:23:09.549615 10752 solver.cpp:244]     Train net output #0: loss = 4.46754 (* 1 = 4.46754 loss)
I0418 15:23:09.549623 10752 sgd_solver.cpp:106] Iteration 43212800, lr = 3.9063e-06
I0418 15:28:15.528828 10752 solver.cpp:337] Iteration 43264000, Testing net (#0)
I0418 15:28:15.595628 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0418 15:28:42.053445 10752 solver.cpp:404]     Test net output #0: accuracy = 0.44952
I0418 15:28:42.053479 10752 solver.cpp:404]     Test net output #1: loss = 2.49107 (* 1 = 2.49107 loss)
I0418 15:28:42.056023 10752 solver.cpp:228] Iteration 43264000, loss = 2.50722
I0418 15:28:42.056056 10752 solver.cpp:244]     Train net output #0: loss = 4.94324 (* 1 = 4.94324 loss)
I0418 15:28:42.056066 10752 sgd_solver.cpp:106] Iteration 43264000, lr = 3.9063e-06
I0418 15:33:48.278110 10752 solver.cpp:228] Iteration 43315200, loss = 2.50439
I0418 15:33:48.278188 10752 solver.cpp:244]     Train net output #0: loss = 5.26716 (* 1 = 5.26716 loss)
I0418 15:33:48.278194 10752 sgd_solver.cpp:106] Iteration 43315200, lr = 3.9063e-06
I0418 15:38:54.533810 10752 solver.cpp:228] Iteration 43366400, loss = 2.50451
I0418 15:38:54.533885 10752 solver.cpp:244]     Train net output #0: loss = 4.55323 (* 1 = 4.55323 loss)
I0418 15:38:54.533891 10752 sgd_solver.cpp:106] Iteration 43366400, lr = 3.9063e-06
I0418 15:44:00.511521 10752 solver.cpp:228] Iteration 43417600, loss = 2.50252
I0418 15:44:00.511585 10752 solver.cpp:244]     Train net output #0: loss = 1.43289 (* 1 = 1.43289 loss)
I0418 15:44:00.511592 10752 sgd_solver.cpp:106] Iteration 43417600, lr = 3.9063e-06
I0418 15:49:06.530484 10752 solver.cpp:228] Iteration 43468800, loss = 2.48744
I0418 15:49:06.530547 10752 solver.cpp:244]     Train net output #0: loss = 2.88482 (* 1 = 2.88482 loss)
I0418 15:49:06.530553 10752 sgd_solver.cpp:106] Iteration 43468800, lr = 3.9063e-06
I0418 15:54:12.624078 10752 solver.cpp:454] Snapshotting to binary proto file snapshots/caffenet128_no_lrn_lsuv_relu_bs1_iter_43520000.caffemodel
I0418 15:54:12.865952 10752 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/caffenet128_no_lrn_lsuv_relu_bs1_iter_43520000.solverstate
I0418 15:54:12.922593 10752 solver.cpp:337] Iteration 43520000, Testing net (#0)
I0418 15:54:13.038769 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0418 15:54:39.389861 10752 solver.cpp:404]     Test net output #0: accuracy = 0.448
I0418 15:54:39.389894 10752 solver.cpp:404]     Test net output #1: loss = 2.49234 (* 1 = 2.49234 loss)
I0418 15:54:39.392380 10752 solver.cpp:228] Iteration 43520000, loss = 2.48647
I0418 15:54:39.392396 10752 solver.cpp:244]     Train net output #0: loss = 1.53266 (* 1 = 1.53266 loss)
I0418 15:54:39.392403 10752 sgd_solver.cpp:106] Iteration 43520000, lr = 3.9063e-06
I0418 15:59:45.683195 10752 solver.cpp:228] Iteration 43571200, loss = 2.48059
I0418 15:59:45.683269 10752 solver.cpp:244]     Train net output #0: loss = 7.4757 (* 1 = 7.4757 loss)
I0418 15:59:45.683275 10752 sgd_solver.cpp:106] Iteration 43571200, lr = 3.9063e-06
I0418 16:04:51.705451 10752 solver.cpp:228] Iteration 43622400, loss = 2.4941
I0418 16:04:51.705514 10752 solver.cpp:244]     Train net output #0: loss = 2.13798 (* 1 = 2.13798 loss)
I0418 16:04:51.705521 10752 sgd_solver.cpp:106] Iteration 43622400, lr = 3.9063e-06
I0418 16:09:57.883404 10752 solver.cpp:228] Iteration 43673600, loss = 2.48828
I0418 16:09:57.883462 10752 solver.cpp:244]     Train net output #0: loss = 4.00513 (* 1 = 4.00513 loss)
I0418 16:09:57.883468 10752 sgd_solver.cpp:106] Iteration 43673600, lr = 3.9063e-06
I0418 16:15:04.066112 10752 solver.cpp:228] Iteration 43724800, loss = 2.49144
I0418 16:15:04.066182 10752 solver.cpp:244]     Train net output #0: loss = 7.67053 (* 1 = 7.67053 loss)
I0418 16:15:04.066189 10752 sgd_solver.cpp:106] Iteration 43724800, lr = 3.9063e-06
I0418 16:20:10.239724 10752 solver.cpp:337] Iteration 43776000, Testing net (#0)
I0418 16:20:10.410709 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0418 16:20:36.707348 10752 solver.cpp:404]     Test net output #0: accuracy = 0.449119
I0418 16:20:36.707382 10752 solver.cpp:404]     Test net output #1: loss = 2.48888 (* 1 = 2.48888 loss)
I0418 16:20:36.709910 10752 solver.cpp:228] Iteration 43776000, loss = 2.51542
I0418 16:20:36.709928 10752 solver.cpp:244]     Train net output #0: loss = 2.27158 (* 1 = 2.27158 loss)
I0418 16:20:36.709939 10752 sgd_solver.cpp:106] Iteration 43776000, lr = 3.9063e-06
I0418 16:25:43.131842 10752 solver.cpp:228] Iteration 43827200, loss = 2.50199
I0418 16:25:43.131916 10752 solver.cpp:244]     Train net output #0: loss = 0.0206728 (* 1 = 0.0206728 loss)
I0418 16:25:43.131922 10752 sgd_solver.cpp:106] Iteration 43827200, lr = 3.9063e-06
I0418 16:30:49.449460 10752 solver.cpp:228] Iteration 43878400, loss = 2.51103
I0418 16:30:49.449530 10752 solver.cpp:244]     Train net output #0: loss = 3.69314 (* 1 = 3.69314 loss)
I0418 16:30:49.449537 10752 sgd_solver.cpp:106] Iteration 43878400, lr = 3.9063e-06
I0418 16:35:55.689705 10752 solver.cpp:228] Iteration 43929600, loss = 2.49082
I0418 16:35:55.689800 10752 solver.cpp:244]     Train net output #0: loss = 1.11005 (* 1 = 1.11005 loss)
I0418 16:35:55.689807 10752 sgd_solver.cpp:106] Iteration 43929600, lr = 3.9063e-06
I0418 16:41:02.063412 10752 solver.cpp:228] Iteration 43980800, loss = 2.4857
I0418 16:41:02.063473 10752 solver.cpp:244]     Train net output #0: loss = 2.55818 (* 1 = 2.55818 loss)
I0418 16:41:02.063479 10752 sgd_solver.cpp:106] Iteration 43980800, lr = 3.9063e-06
I0418 16:46:08.338788 10752 solver.cpp:337] Iteration 44032000, Testing net (#0)
I0418 16:46:08.565232 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0418 16:46:34.806408 10752 solver.cpp:404]     Test net output #0: accuracy = 0.45062
I0418 16:46:34.806440 10752 solver.cpp:404]     Test net output #1: loss = 2.48097 (* 1 = 2.48097 loss)
I0418 16:46:34.808990 10752 solver.cpp:228] Iteration 44032000, loss = 2.48442
I0418 16:46:34.809007 10752 solver.cpp:244]     Train net output #0: loss = 0.00040116 (* 1 = 0.00040116 loss)
I0418 16:46:34.809015 10752 sgd_solver.cpp:106] Iteration 44032000, lr = 3.9063e-06
I0418 16:51:41.313283 10752 solver.cpp:228] Iteration 44083200, loss = 2.47422
I0418 16:51:41.313341 10752 solver.cpp:244]     Train net output #0: loss = 5.63158 (* 1 = 5.63158 loss)
I0418 16:51:41.313347 10752 sgd_solver.cpp:106] Iteration 44083200, lr = 3.9063e-06
I0418 16:56:47.629441 10752 solver.cpp:228] Iteration 44134400, loss = 2.47978
I0418 16:56:47.629514 10752 solver.cpp:244]     Train net output #0: loss = 3.68565 (* 1 = 3.68565 loss)
I0418 16:56:47.629519 10752 sgd_solver.cpp:106] Iteration 44134400, lr = 3.9063e-06
I0418 17:01:53.875077 10752 solver.cpp:228] Iteration 44185600, loss = 2.48559
I0418 17:01:53.875149 10752 solver.cpp:244]     Train net output #0: loss = 1.49593 (* 1 = 1.49593 loss)
I0418 17:01:53.875155 10752 sgd_solver.cpp:106] Iteration 44185600, lr = 3.9063e-06
I0418 17:07:00.234421 10752 solver.cpp:228] Iteration 44236800, loss = 2.4666
I0418 17:07:00.234478 10752 solver.cpp:244]     Train net output #0: loss = 2.63936 (* 1 = 2.63936 loss)
I0418 17:07:00.234484 10752 sgd_solver.cpp:106] Iteration 44236800, lr = 3.9063e-06
I0418 17:12:06.612722 10752 solver.cpp:337] Iteration 44288000, Testing net (#0)
I0418 17:12:06.891501 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0418 17:12:33.105201 10752 solver.cpp:404]     Test net output #0: accuracy = 0.44828
I0418 17:12:33.105234 10752 solver.cpp:404]     Test net output #1: loss = 2.48455 (* 1 = 2.48455 loss)
I0418 17:12:33.107743 10752 solver.cpp:228] Iteration 44288000, loss = 2.49065
I0418 17:12:33.107760 10752 solver.cpp:244]     Train net output #0: loss = 1.86411 (* 1 = 1.86411 loss)
I0418 17:12:33.107769 10752 sgd_solver.cpp:106] Iteration 44288000, lr = 3.9063e-06
I0418 17:17:39.589721 10752 solver.cpp:228] Iteration 44339200, loss = 2.5179
I0418 17:17:39.589797 10752 solver.cpp:244]     Train net output #0: loss = 2.12972 (* 1 = 2.12972 loss)
I0418 17:17:39.589805 10752 sgd_solver.cpp:106] Iteration 44339200, lr = 3.9063e-06
I0418 17:22:45.869444 10752 solver.cpp:228] Iteration 44390400, loss = 2.51674
I0418 17:22:45.869515 10752 solver.cpp:244]     Train net output #0: loss = 3.3165 (* 1 = 3.3165 loss)
I0418 17:22:45.869521 10752 sgd_solver.cpp:106] Iteration 44390400, lr = 3.9063e-06
I0418 17:27:52.210057 10752 solver.cpp:228] Iteration 44441600, loss = 2.52095
I0418 17:27:52.210115 10752 solver.cpp:244]     Train net output #0: loss = 0.765171 (* 1 = 0.765171 loss)
I0418 17:27:52.210121 10752 sgd_solver.cpp:106] Iteration 44441600, lr = 3.9063e-06
I0418 17:32:58.539552 10752 solver.cpp:228] Iteration 44492800, loss = 2.49352
I0418 17:32:58.539621 10752 solver.cpp:244]     Train net output #0: loss = 0.929246 (* 1 = 0.929246 loss)
I0418 17:32:58.539628 10752 sgd_solver.cpp:106] Iteration 44492800, lr = 3.9063e-06
I0418 17:38:04.973701 10752 solver.cpp:337] Iteration 44544000, Testing net (#0)
I0418 17:38:05.333348 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0418 17:38:31.476320 10752 solver.cpp:404]     Test net output #0: accuracy = 0.44652
I0418 17:38:31.476352 10752 solver.cpp:404]     Test net output #1: loss = 2.49604 (* 1 = 2.49604 loss)
I0418 17:38:31.478934 10752 solver.cpp:228] Iteration 44544000, loss = 2.50446
I0418 17:38:31.478950 10752 solver.cpp:244]     Train net output #0: loss = 0.573263 (* 1 = 0.573263 loss)
I0418 17:38:31.478957 10752 sgd_solver.cpp:106] Iteration 44544000, lr = 3.9063e-06
I0418 17:43:37.923152 10752 solver.cpp:228] Iteration 44595200, loss = 2.49227
I0418 17:43:37.923215 10752 solver.cpp:244]     Train net output #0: loss = 1.95389 (* 1 = 1.95389 loss)
I0418 17:43:37.923221 10752 sgd_solver.cpp:106] Iteration 44595200, lr = 3.9063e-06
I0418 17:48:44.297224 10752 solver.cpp:228] Iteration 44646400, loss = 2.51405
I0418 17:48:44.297286 10752 solver.cpp:244]     Train net output #0: loss = 8.05915 (* 1 = 8.05915 loss)
I0418 17:48:44.297291 10752 sgd_solver.cpp:106] Iteration 44646400, lr = 3.9063e-06
I0418 17:53:50.572028 10752 solver.cpp:228] Iteration 44697600, loss = 2.50363
I0418 17:53:50.572088 10752 solver.cpp:244]     Train net output #0: loss = 5.29738 (* 1 = 5.29738 loss)
I0418 17:53:50.572094 10752 sgd_solver.cpp:106] Iteration 44697600, lr = 3.9063e-06
I0418 17:58:56.840296 10752 solver.cpp:228] Iteration 44748800, loss = 2.48837
I0418 17:58:56.840360 10752 solver.cpp:244]     Train net output #0: loss = 2.49791 (* 1 = 2.49791 loss)
I0418 17:58:56.840374 10752 sgd_solver.cpp:106] Iteration 44748800, lr = 3.9063e-06
I0418 18:04:02.908481 10752 solver.cpp:337] Iteration 44800000, Testing net (#0)
I0418 18:04:03.323498 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0418 18:04:29.401629 10752 solver.cpp:404]     Test net output #0: accuracy = 0.44968
I0418 18:04:29.401664 10752 solver.cpp:404]     Test net output #1: loss = 2.47641 (* 1 = 2.47641 loss)
I0418 18:04:29.404227 10752 solver.cpp:228] Iteration 44800000, loss = 2.47142
I0418 18:04:29.404248 10752 solver.cpp:244]     Train net output #0: loss = 5.68175 (* 1 = 5.68175 loss)
I0418 18:04:29.404260 10752 sgd_solver.cpp:106] Iteration 44800000, lr = 3.9063e-06
I0418 18:09:35.516127 10752 solver.cpp:228] Iteration 44851200, loss = 2.47382
I0418 18:09:35.516201 10752 solver.cpp:244]     Train net output #0: loss = 1.47224 (* 1 = 1.47224 loss)
I0418 18:09:35.516208 10752 sgd_solver.cpp:106] Iteration 44851200, lr = 3.9063e-06
I0418 18:14:41.520798 10752 solver.cpp:228] Iteration 44902400, loss = 2.49
I0418 18:14:41.520861 10752 solver.cpp:244]     Train net output #0: loss = 2.84209 (* 1 = 2.84209 loss)
I0418 18:14:41.520869 10752 sgd_solver.cpp:106] Iteration 44902400, lr = 3.9063e-06
I0418 18:19:47.850438 10752 solver.cpp:228] Iteration 44953600, loss = 2.48465
I0418 18:19:47.850505 10752 solver.cpp:244]     Train net output #0: loss = 0.00586102 (* 1 = 0.00586102 loss)
I0418 18:19:47.850513 10752 sgd_solver.cpp:106] Iteration 44953600, lr = 3.9063e-06
I0418 18:24:54.053165 10752 solver.cpp:228] Iteration 45004800, loss = 2.48398
I0418 18:24:54.053239 10752 solver.cpp:244]     Train net output #0: loss = 3.17152 (* 1 = 3.17152 loss)
I0418 18:24:54.053246 10752 sgd_solver.cpp:106] Iteration 45004800, lr = 3.9063e-06
I0418 18:30:00.308650 10752 solver.cpp:337] Iteration 45056000, Testing net (#0)
I0418 18:30:00.828927 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0418 18:30:27.092656 10752 solver.cpp:404]     Test net output #0: accuracy = 0.45024
I0418 18:30:27.092687 10752 solver.cpp:404]     Test net output #1: loss = 2.48436 (* 1 = 2.48436 loss)
I0418 18:30:27.095662 10752 solver.cpp:228] Iteration 45056000, loss = 2.51113
I0418 18:30:27.095690 10752 solver.cpp:244]     Train net output #0: loss = 1.89955 (* 1 = 1.89955 loss)
I0418 18:30:27.095700 10752 sgd_solver.cpp:106] Iteration 45056000, lr = 3.9063e-06
I0418 18:35:33.322674 10752 solver.cpp:228] Iteration 45107200, loss = 2.4929
I0418 18:35:33.322768 10752 solver.cpp:244]     Train net output #0: loss = 0.817266 (* 1 = 0.817266 loss)
I0418 18:35:33.322775 10752 sgd_solver.cpp:106] Iteration 45107200, lr = 3.9063e-06
I0418 18:40:39.361935 10752 solver.cpp:228] Iteration 45158400, loss = 2.49741
I0418 18:40:39.361991 10752 solver.cpp:244]     Train net output #0: loss = 6.95688 (* 1 = 6.95688 loss)
I0418 18:40:39.361999 10752 sgd_solver.cpp:106] Iteration 45158400, lr = 3.9063e-06
I0418 18:45:45.468556 10752 solver.cpp:228] Iteration 45209600, loss = 2.49321
I0418 18:45:45.468628 10752 solver.cpp:244]     Train net output #0: loss = 0.00228403 (* 1 = 0.00228403 loss)
I0418 18:45:45.468634 10752 sgd_solver.cpp:106] Iteration 45209600, lr = 3.9063e-06
I0418 18:50:51.556181 10752 solver.cpp:228] Iteration 45260800, loss = 2.47788
I0418 18:50:51.556241 10752 solver.cpp:244]     Train net output #0: loss = 1.70409 (* 1 = 1.70409 loss)
I0418 18:50:51.556247 10752 sgd_solver.cpp:106] Iteration 45260800, lr = 3.9063e-06
I0418 18:55:57.547372 10752 solver.cpp:337] Iteration 45312000, Testing net (#0)
I0418 18:55:58.064522 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0418 18:56:23.996784 10752 solver.cpp:404]     Test net output #0: accuracy = 0.451
I0418 18:56:23.996817 10752 solver.cpp:404]     Test net output #1: loss = 2.4739 (* 1 = 2.4739 loss)
I0418 18:56:23.999392 10752 solver.cpp:228] Iteration 45312000, loss = 2.4724
I0418 18:56:23.999410 10752 solver.cpp:244]     Train net output #0: loss = 1.1749 (* 1 = 1.1749 loss)
I0418 18:56:23.999419 10752 sgd_solver.cpp:106] Iteration 45312000, lr = 3.9063e-06
I0418 19:01:30.171497 10752 solver.cpp:228] Iteration 45363200, loss = 2.46164
I0418 19:01:30.171560 10752 solver.cpp:244]     Train net output #0: loss = 3.85767 (* 1 = 3.85767 loss)
I0418 19:01:30.171573 10752 sgd_solver.cpp:106] Iteration 45363200, lr = 3.9063e-06
I0418 19:06:36.109709 10752 solver.cpp:228] Iteration 45414400, loss = 2.48121
I0418 19:06:36.109771 10752 solver.cpp:244]     Train net output #0: loss = 8.81579 (* 1 = 8.81579 loss)
I0418 19:06:36.109786 10752 sgd_solver.cpp:106] Iteration 45414400, lr = 3.9063e-06
I0418 19:11:42.123054 10752 solver.cpp:228] Iteration 45465600, loss = 2.48101
I0418 19:11:42.123128 10752 solver.cpp:244]     Train net output #0: loss = 0.40097 (* 1 = 0.40097 loss)
I0418 19:11:42.123141 10752 sgd_solver.cpp:106] Iteration 45465600, lr = 3.9063e-06
I0418 19:16:48.141729 10752 solver.cpp:228] Iteration 45516800, loss = 2.45962
I0418 19:16:48.141800 10752 solver.cpp:244]     Train net output #0: loss = 0.0569734 (* 1 = 0.0569734 loss)
I0418 19:16:48.141813 10752 sgd_solver.cpp:106] Iteration 45516800, lr = 3.9063e-06
I0418 19:21:54.146258 10752 solver.cpp:337] Iteration 45568000, Testing net (#0)
I0418 19:21:54.782920 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0418 19:22:21.189249 10752 solver.cpp:404]     Test net output #0: accuracy = 0.44922
I0418 19:22:21.189321 10752 solver.cpp:404]     Test net output #1: loss = 2.48699 (* 1 = 2.48699 loss)
I0418 19:22:21.194010 10752 solver.cpp:228] Iteration 45568000, loss = 2.4876
I0418 19:22:21.194066 10752 solver.cpp:244]     Train net output #0: loss = 4.58594 (* 1 = 4.58594 loss)
I0418 19:22:21.194075 10752 sgd_solver.cpp:106] Iteration 45568000, lr = 3.9063e-06
I0418 19:27:27.560104 10752 solver.cpp:228] Iteration 45619200, loss = 2.52055
I0418 19:27:27.560173 10752 solver.cpp:244]     Train net output #0: loss = 2.88401 (* 1 = 2.88401 loss)
I0418 19:27:27.560178 10752 sgd_solver.cpp:106] Iteration 45619200, lr = 3.9063e-06
I0418 19:32:33.646107 10752 solver.cpp:228] Iteration 45670400, loss = 2.50395
I0418 19:32:33.646181 10752 solver.cpp:244]     Train net output #0: loss = 0.217926 (* 1 = 0.217926 loss)
I0418 19:32:33.646189 10752 sgd_solver.cpp:106] Iteration 45670400, lr = 3.9063e-06
I0418 19:37:39.806591 10752 solver.cpp:228] Iteration 45721600, loss = 2.51803
I0418 19:37:39.806648 10752 solver.cpp:244]     Train net output #0: loss = 0.207354 (* 1 = 0.207354 loss)
I0418 19:37:39.806653 10752 sgd_solver.cpp:106] Iteration 45721600, lr = 3.9063e-06
I0418 19:42:45.972491 10752 solver.cpp:228] Iteration 45772800, loss = 2.47891
I0418 19:42:45.972599 10752 solver.cpp:244]     Train net output #0: loss = 5.20055 (* 1 = 5.20055 loss)
I0418 19:42:45.972612 10752 sgd_solver.cpp:106] Iteration 45772800, lr = 3.9063e-06
I0418 19:47:52.019556 10752 solver.cpp:337] Iteration 45824000, Testing net (#0)
I0418 19:47:52.716022 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0418 19:48:19.026728 10752 solver.cpp:404]     Test net output #0: accuracy = 0.44806
I0418 19:48:19.026762 10752 solver.cpp:404]     Test net output #1: loss = 2.49763 (* 1 = 2.49763 loss)
I0418 19:48:19.029249 10752 solver.cpp:228] Iteration 45824000, loss = 2.49996
I0418 19:48:19.029268 10752 solver.cpp:244]     Train net output #0: loss = 0.0720998 (* 1 = 0.0720998 loss)
I0418 19:48:19.029279 10752 sgd_solver.cpp:106] Iteration 45824000, lr = 3.9063e-06
I0418 19:53:25.342355 10752 solver.cpp:228] Iteration 45875200, loss = 2.49211
I0418 19:53:25.342418 10752 solver.cpp:244]     Train net output #0: loss = 3.16637 (* 1 = 3.16637 loss)
I0418 19:53:25.342430 10752 sgd_solver.cpp:106] Iteration 45875200, lr = 3.9063e-06
I0418 19:58:31.566007 10752 solver.cpp:228] Iteration 45926400, loss = 2.50717
I0418 19:58:31.566068 10752 solver.cpp:244]     Train net output #0: loss = 1.50144 (* 1 = 1.50144 loss)
I0418 19:58:31.566077 10752 sgd_solver.cpp:106] Iteration 45926400, lr = 3.9063e-06
I0418 20:03:37.584348 10752 solver.cpp:228] Iteration 45977600, loss = 2.49572
I0418 20:03:37.584424 10752 solver.cpp:244]     Train net output #0: loss = 0.242268 (* 1 = 0.242268 loss)
I0418 20:03:37.584437 10752 sgd_solver.cpp:106] Iteration 45977600, lr = 3.9063e-06
I0418 20:08:43.676865 10752 solver.cpp:228] Iteration 46028800, loss = 2.47406
I0418 20:08:43.676925 10752 solver.cpp:244]     Train net output #0: loss = 2.15192 (* 1 = 2.15192 loss)
I0418 20:08:43.676931 10752 sgd_solver.cpp:106] Iteration 46028800, lr = 3.9063e-06
I0418 20:13:49.864739 10752 solver.cpp:454] Snapshotting to binary proto file snapshots/caffenet128_no_lrn_lsuv_relu_bs1_iter_46080000.caffemodel
I0418 20:13:50.104792 10752 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/caffenet128_no_lrn_lsuv_relu_bs1_iter_46080000.solverstate
I0418 20:13:50.163882 10752 solver.cpp:337] Iteration 46080000, Testing net (#0)
I0418 20:13:50.834836 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0418 20:14:16.628201 10752 solver.cpp:404]     Test net output #0: accuracy = 0.4477
I0418 20:14:16.628235 10752 solver.cpp:404]     Test net output #1: loss = 2.48906 (* 1 = 2.48906 loss)
I0418 20:14:16.630781 10752 solver.cpp:228] Iteration 46080000, loss = 2.47135
I0418 20:14:16.630800 10752 solver.cpp:244]     Train net output #0: loss = 0.5384 (* 1 = 0.5384 loss)
I0418 20:14:16.630810 10752 sgd_solver.cpp:106] Iteration 46080000, lr = 3.9063e-06
I0418 20:19:23.278996 10752 solver.cpp:228] Iteration 46131200, loss = 2.46936
I0418 20:19:23.279055 10752 solver.cpp:244]     Train net output #0: loss = 2.7328 (* 1 = 2.7328 loss)
I0418 20:19:23.279064 10752 sgd_solver.cpp:106] Iteration 46131200, lr = 3.9063e-06
I0418 20:24:30.140710 10752 solver.cpp:228] Iteration 46182400, loss = 2.49006
I0418 20:24:30.140772 10752 solver.cpp:244]     Train net output #0: loss = 5.42788 (* 1 = 5.42788 loss)
I0418 20:24:30.140781 10752 sgd_solver.cpp:106] Iteration 46182400, lr = 3.9063e-06
I0418 20:29:37.500939 10752 solver.cpp:228] Iteration 46233600, loss = 2.4711
I0418 20:29:37.501006 10752 solver.cpp:244]     Train net output #0: loss = 2.33244 (* 1 = 2.33244 loss)
I0418 20:29:37.501018 10752 sgd_solver.cpp:106] Iteration 46233600, lr = 3.9063e-06
I0418 20:34:44.899305 10752 solver.cpp:228] Iteration 46284800, loss = 2.47553
I0418 20:34:44.899371 10752 solver.cpp:244]     Train net output #0: loss = 3.08201 (* 1 = 3.08201 loss)
I0418 20:34:44.899385 10752 sgd_solver.cpp:106] Iteration 46284800, lr = 3.9063e-06
I0418 20:39:51.367022 10752 solver.cpp:337] Iteration 46336000, Testing net (#0)
I0418 20:39:51.946676 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0418 20:40:18.161767 10752 solver.cpp:404]     Test net output #0: accuracy = 0.45152
I0418 20:40:18.161799 10752 solver.cpp:404]     Test net output #1: loss = 2.47874 (* 1 = 2.47874 loss)
I0418 20:40:18.164436 10752 solver.cpp:228] Iteration 46336000, loss = 2.50516
I0418 20:40:18.164453 10752 solver.cpp:244]     Train net output #0: loss = 1.21317 (* 1 = 1.21317 loss)
I0418 20:40:18.164461 10752 sgd_solver.cpp:106] Iteration 46336000, lr = 3.9063e-06
I0418 20:45:25.102367 10752 solver.cpp:228] Iteration 46387200, loss = 2.50563
I0418 20:45:25.102453 10752 solver.cpp:244]     Train net output #0: loss = 0.00039794 (* 1 = 0.00039794 loss)
I0418 20:45:25.102463 10752 sgd_solver.cpp:106] Iteration 46387200, lr = 3.9063e-06
I0418 20:50:31.730819 10752 solver.cpp:228] Iteration 46438400, loss = 2.49526
I0418 20:50:31.730880 10752 solver.cpp:244]     Train net output #0: loss = 0.437549 (* 1 = 0.437549 loss)
I0418 20:50:31.730885 10752 sgd_solver.cpp:106] Iteration 46438400, lr = 3.9063e-06
I0418 20:55:42.292275 10752 solver.cpp:228] Iteration 46489600, loss = 2.47182
I0418 20:55:42.292348 10752 solver.cpp:244]     Train net output #0: loss = 0.100123 (* 1 = 0.100123 loss)
I0418 20:55:42.292361 10752 sgd_solver.cpp:106] Iteration 46489600, lr = 3.9063e-06
I0418 21:00:51.447846 10752 solver.cpp:228] Iteration 46540800, loss = 2.47126
I0418 21:00:51.447919 10752 solver.cpp:244]     Train net output #0: loss = 2.06859 (* 1 = 2.06859 loss)
I0418 21:00:51.447926 10752 sgd_solver.cpp:106] Iteration 46540800, lr = 3.9063e-06
I0418 21:05:59.814023 10752 solver.cpp:337] Iteration 46592000, Testing net (#0)
I0418 21:06:00.124423 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0418 21:06:26.618566 10752 solver.cpp:404]     Test net output #0: accuracy = 0.45144
I0418 21:06:26.618598 10752 solver.cpp:404]     Test net output #1: loss = 2.47225 (* 1 = 2.47225 loss)
I0418 21:06:26.621086 10752 solver.cpp:228] Iteration 46592000, loss = 2.46794
I0418 21:06:26.621104 10752 solver.cpp:244]     Train net output #0: loss = 3.04839 (* 1 = 3.04839 loss)
I0418 21:06:26.621110 10752 sgd_solver.cpp:106] Iteration 46592000, lr = 3.9063e-06
I0418 21:11:35.864506 10752 solver.cpp:228] Iteration 46643200, loss = 2.4654
I0418 21:11:35.864579 10752 solver.cpp:244]     Train net output #0: loss = 1.34848 (* 1 = 1.34848 loss)
I0418 21:11:35.864586 10752 sgd_solver.cpp:106] Iteration 46643200, lr = 3.9063e-06
I0418 21:16:42.868587 10752 solver.cpp:228] Iteration 46694400, loss = 2.48351
I0418 21:16:42.868660 10752 solver.cpp:244]     Train net output #0: loss = 0.0157634 (* 1 = 0.0157634 loss)
I0418 21:16:42.868666 10752 sgd_solver.cpp:106] Iteration 46694400, lr = 3.9063e-06
I0418 21:21:49.774325 10752 solver.cpp:228] Iteration 46745600, loss = 2.46577
I0418 21:21:49.774394 10752 solver.cpp:244]     Train net output #0: loss = 1.41826 (* 1 = 1.41826 loss)
I0418 21:21:49.774400 10752 sgd_solver.cpp:106] Iteration 46745600, lr = 3.9063e-06
I0418 21:26:57.122841 10752 solver.cpp:228] Iteration 46796800, loss = 2.45189
I0418 21:26:57.122912 10752 solver.cpp:244]     Train net output #0: loss = 3.87531 (* 1 = 3.87531 loss)
I0418 21:26:57.122920 10752 sgd_solver.cpp:106] Iteration 46796800, lr = 3.9063e-06
I0418 21:32:03.634219 10752 solver.cpp:337] Iteration 46848000, Testing net (#0)
I0418 21:32:03.889075 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0418 21:32:31.076040 10752 solver.cpp:404]     Test net output #0: accuracy = 0.45278
I0418 21:32:31.076073 10752 solver.cpp:404]     Test net output #1: loss = 2.47764 (* 1 = 2.47764 loss)
I0418 21:32:31.078591 10752 solver.cpp:228] Iteration 46848000, loss = 2.47453
I0418 21:32:31.078610 10752 solver.cpp:244]     Train net output #0: loss = 3.48658 (* 1 = 3.48658 loss)
I0418 21:32:31.078620 10752 sgd_solver.cpp:106] Iteration 46848000, lr = 3.9063e-06
I0418 21:37:38.181452 10752 solver.cpp:228] Iteration 46899200, loss = 2.50921
I0418 21:37:38.181512 10752 solver.cpp:244]     Train net output #0: loss = 3.17036 (* 1 = 3.17036 loss)
I0418 21:37:38.181519 10752 sgd_solver.cpp:106] Iteration 46899200, lr = 3.9063e-06
I0418 21:42:45.099400 10752 solver.cpp:228] Iteration 46950400, loss = 2.50176
I0418 21:42:45.099481 10752 solver.cpp:244]     Train net output #0: loss = 0.366961 (* 1 = 0.366961 loss)
I0418 21:42:45.099490 10752 sgd_solver.cpp:106] Iteration 46950400, lr = 3.9063e-06
I0418 21:47:51.995681 10752 solver.cpp:228] Iteration 47001600, loss = 2.49293
I0418 21:47:51.995730 10752 solver.cpp:244]     Train net output #0: loss = 7.06724 (* 1 = 7.06724 loss)
I0418 21:47:51.995736 10752 sgd_solver.cpp:106] Iteration 47001600, lr = 3.9063e-06
I0418 21:52:58.811259 10752 solver.cpp:228] Iteration 47052800, loss = 2.47738
I0418 21:52:58.811321 10752 solver.cpp:244]     Train net output #0: loss = 1.25182 (* 1 = 1.25182 loss)
I0418 21:52:58.811327 10752 sgd_solver.cpp:106] Iteration 47052800, lr = 3.9063e-06
I0418 21:58:05.778921 10752 solver.cpp:337] Iteration 47104000, Testing net (#0)
I0418 21:58:06.005312 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0418 21:58:32.274039 10752 solver.cpp:404]     Test net output #0: accuracy = 0.45252
I0418 21:58:32.274071 10752 solver.cpp:404]     Test net output #1: loss = 2.47051 (* 1 = 2.47051 loss)
I0418 21:58:32.276604 10752 solver.cpp:228] Iteration 47104000, loss = 2.48626
I0418 21:58:32.276621 10752 solver.cpp:244]     Train net output #0: loss = 4.88587 (* 1 = 4.88587 loss)
I0418 21:58:32.276630 10752 sgd_solver.cpp:106] Iteration 47104000, lr = 3.9063e-06
I0418 22:03:39.351657 10752 solver.cpp:228] Iteration 47155200, loss = 2.4803
I0418 22:03:39.351732 10752 solver.cpp:244]     Train net output #0: loss = 0.254396 (* 1 = 0.254396 loss)
I0418 22:03:39.351739 10752 sgd_solver.cpp:106] Iteration 47155200, lr = 3.9063e-06
I0418 22:08:46.189414 10752 solver.cpp:228] Iteration 47206400, loss = 2.49748
I0418 22:08:46.189473 10752 solver.cpp:244]     Train net output #0: loss = 8.85245 (* 1 = 8.85245 loss)
I0418 22:08:46.189479 10752 sgd_solver.cpp:106] Iteration 47206400, lr = 3.9063e-06
I0418 22:13:53.214328 10752 solver.cpp:228] Iteration 47257600, loss = 2.48122
I0418 22:13:53.214387 10752 solver.cpp:244]     Train net output #0: loss = 4.65622 (* 1 = 4.65622 loss)
I0418 22:13:53.214395 10752 sgd_solver.cpp:106] Iteration 47257600, lr = 3.9063e-06
I0418 22:19:00.098579 10752 solver.cpp:228] Iteration 47308800, loss = 2.47251
I0418 22:19:00.098631 10752 solver.cpp:244]     Train net output #0: loss = 4.14228 (* 1 = 4.14228 loss)
I0418 22:19:00.098639 10752 sgd_solver.cpp:106] Iteration 47308800, lr = 3.9063e-06
I0418 22:24:07.207777 10752 solver.cpp:337] Iteration 47360000, Testing net (#0)
I0418 22:24:07.461424 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0418 22:24:33.703301 10752 solver.cpp:404]     Test net output #0: accuracy = 0.4512
I0418 22:24:33.703336 10752 solver.cpp:404]     Test net output #1: loss = 2.47018 (* 1 = 2.47018 loss)
I0418 22:24:33.705875 10752 solver.cpp:228] Iteration 47360000, loss = 2.45582
I0418 22:24:33.705893 10752 solver.cpp:244]     Train net output #0: loss = 0.192676 (* 1 = 0.192676 loss)
I0418 22:24:33.705902 10752 sgd_solver.cpp:106] Iteration 47360000, lr = 3.9063e-06
I0418 22:29:40.958187 10752 solver.cpp:228] Iteration 47411200, loss = 2.47217
I0418 22:29:40.958259 10752 solver.cpp:244]     Train net output #0: loss = 9.55904 (* 1 = 9.55904 loss)
I0418 22:29:40.958266 10752 sgd_solver.cpp:106] Iteration 47411200, lr = 3.9063e-06
I0418 22:34:47.985177 10752 solver.cpp:228] Iteration 47462400, loss = 2.46666
I0418 22:34:47.985250 10752 solver.cpp:244]     Train net output #0: loss = 2.28851 (* 1 = 2.28851 loss)
I0418 22:34:47.985257 10752 sgd_solver.cpp:106] Iteration 47462400, lr = 3.9063e-06
I0418 22:39:54.932250 10752 solver.cpp:228] Iteration 47513600, loss = 2.47721
I0418 22:39:54.932322 10752 solver.cpp:244]     Train net output #0: loss = 0.62594 (* 1 = 0.62594 loss)
I0418 22:39:54.932327 10752 sgd_solver.cpp:106] Iteration 47513600, lr = 3.9063e-06
I0418 22:45:02.893818 10752 solver.cpp:228] Iteration 47564800, loss = 2.46894
I0418 22:45:02.893916 10752 solver.cpp:244]     Train net output #0: loss = 3.60737 (* 1 = 3.60737 loss)
I0418 22:45:02.893929 10752 sgd_solver.cpp:106] Iteration 47564800, lr = 3.9063e-06
I0418 22:50:10.188068 10752 solver.cpp:337] Iteration 47616000, Testing net (#0)
I0418 22:50:10.217486 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0418 22:50:36.696296 10752 solver.cpp:404]     Test net output #0: accuracy = 0.45242
I0418 22:50:36.696331 10752 solver.cpp:404]     Test net output #1: loss = 2.47413 (* 1 = 2.47413 loss)
I0418 22:50:36.698861 10752 solver.cpp:228] Iteration 47616000, loss = 2.49521
I0418 22:50:36.698879 10752 solver.cpp:244]     Train net output #0: loss = 0.126174 (* 1 = 0.126174 loss)
I0418 22:50:36.698889 10752 sgd_solver.cpp:106] Iteration 47616000, lr = 3.9063e-06
I0418 22:55:43.744542 10752 solver.cpp:228] Iteration 47667200, loss = 2.49238
I0418 22:55:43.744614 10752 solver.cpp:244]     Train net output #0: loss = 5.07682 (* 1 = 5.07682 loss)
I0418 22:55:43.744621 10752 sgd_solver.cpp:106] Iteration 47667200, lr = 3.9063e-06
I0418 23:00:50.234328 10752 solver.cpp:228] Iteration 47718400, loss = 2.49286
I0418 23:00:50.234388 10752 solver.cpp:244]     Train net output #0: loss = 2.31152 (* 1 = 2.31152 loss)
I0418 23:00:50.234395 10752 sgd_solver.cpp:106] Iteration 47718400, lr = 3.9063e-06
I0418 23:05:56.679615 10752 solver.cpp:228] Iteration 47769600, loss = 2.47312
I0418 23:05:56.679687 10752 solver.cpp:244]     Train net output #0: loss = 0.237181 (* 1 = 0.237181 loss)
I0418 23:05:56.679692 10752 sgd_solver.cpp:106] Iteration 47769600, lr = 3.9063e-06
I0418 23:09:59.802162 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0418 23:11:04.844279 10752 solver.cpp:228] Iteration 47820800, loss = 2.46231
I0418 23:11:04.844354 10752 solver.cpp:244]     Train net output #0: loss = 6.84676 (* 1 = 6.84676 loss)
I0418 23:11:04.844362 10752 sgd_solver.cpp:106] Iteration 47820800, lr = 3.9063e-06
I0418 23:16:15.354593 10752 solver.cpp:337] Iteration 47872000, Testing net (#0)
I0418 23:16:41.542151 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0418 23:16:41.805976 10752 solver.cpp:404]     Test net output #0: accuracy = 0.4511
I0418 23:16:41.806010 10752 solver.cpp:404]     Test net output #1: loss = 2.4746 (* 1 = 2.4746 loss)
I0418 23:16:41.808555 10752 solver.cpp:228] Iteration 47872000, loss = 2.45985
I0418 23:16:41.808574 10752 solver.cpp:244]     Train net output #0: loss = 2.6674 (* 1 = 2.6674 loss)
I0418 23:16:41.808585 10752 sgd_solver.cpp:106] Iteration 47872000, lr = 3.9063e-06
I0418 23:21:48.207101 10752 solver.cpp:228] Iteration 47923200, loss = 2.45485
I0418 23:21:48.207162 10752 solver.cpp:244]     Train net output #0: loss = 1.53709 (* 1 = 1.53709 loss)
I0418 23:21:48.207170 10752 sgd_solver.cpp:106] Iteration 47923200, lr = 3.9063e-06
I0418 23:26:54.368636 10752 solver.cpp:228] Iteration 47974400, loss = 2.4742
I0418 23:26:54.368711 10752 solver.cpp:244]     Train net output #0: loss = 0.122652 (* 1 = 0.122652 loss)
I0418 23:26:54.368721 10752 sgd_solver.cpp:106] Iteration 47974400, lr = 3.9063e-06
I0418 23:32:00.639454 10752 solver.cpp:228] Iteration 48025600, loss = 2.46023
I0418 23:32:00.639528 10752 solver.cpp:244]     Train net output #0: loss = 2.22574 (* 1 = 2.22574 loss)
I0418 23:32:00.639535 10752 sgd_solver.cpp:106] Iteration 48025600, lr = 3.9063e-06
I0418 23:37:06.856817 10752 solver.cpp:228] Iteration 48076800, loss = 2.45554
I0418 23:37:06.856881 10752 solver.cpp:244]     Train net output #0: loss = 4.44247 (* 1 = 4.44247 loss)
I0418 23:37:06.856889 10752 sgd_solver.cpp:106] Iteration 48076800, lr = 3.9063e-06
I0418 23:42:13.071007 10752 solver.cpp:337] Iteration 48128000, Testing net (#0)
I0418 23:42:39.351233 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0418 23:42:39.560593 10752 solver.cpp:404]     Test net output #0: accuracy = 0.4551
I0418 23:42:39.560626 10752 solver.cpp:404]     Test net output #1: loss = 2.46581 (* 1 = 2.46581 loss)
I0418 23:42:39.563132 10752 solver.cpp:228] Iteration 48128000, loss = 2.4676
I0418 23:42:39.563149 10752 solver.cpp:244]     Train net output #0: loss = 0.680664 (* 1 = 0.680664 loss)
I0418 23:42:39.563158 10752 sgd_solver.cpp:106] Iteration 48128000, lr = 3.9063e-06
I0418 23:47:46.233719 10752 solver.cpp:228] Iteration 48179200, loss = 2.50059
I0418 23:47:46.233799 10752 solver.cpp:244]     Train net output #0: loss = 0.901186 (* 1 = 0.901186 loss)
I0418 23:47:46.233808 10752 sgd_solver.cpp:106] Iteration 48179200, lr = 3.9063e-06
I0418 23:52:52.437507 10752 solver.cpp:228] Iteration 48230400, loss = 2.49357
I0418 23:52:52.437571 10752 solver.cpp:244]     Train net output #0: loss = 0.19501 (* 1 = 0.19501 loss)
I0418 23:52:52.437579 10752 sgd_solver.cpp:106] Iteration 48230400, lr = 3.9063e-06
I0418 23:57:58.511719 10752 solver.cpp:228] Iteration 48281600, loss = 2.48563
I0418 23:57:58.511795 10752 solver.cpp:244]     Train net output #0: loss = 0.640549 (* 1 = 0.640549 loss)
I0418 23:57:58.511803 10752 sgd_solver.cpp:106] Iteration 48281600, lr = 3.9063e-06
I0419 00:03:04.453287 10752 solver.cpp:228] Iteration 48332800, loss = 2.48144
I0419 00:03:04.453359 10752 solver.cpp:244]     Train net output #0: loss = 0.452529 (* 1 = 0.452529 loss)
I0419 00:03:04.453368 10752 sgd_solver.cpp:106] Iteration 48332800, lr = 3.9063e-06
I0419 00:08:10.560200 10752 solver.cpp:337] Iteration 48384000, Testing net (#0)
I0419 00:08:36.874117 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0419 00:08:37.032299 10752 solver.cpp:404]     Test net output #0: accuracy = 0.45004
I0419 00:08:37.032332 10752 solver.cpp:404]     Test net output #1: loss = 2.47853 (* 1 = 2.47853 loss)
I0419 00:08:37.034850 10752 solver.cpp:228] Iteration 48384000, loss = 2.49087
I0419 00:08:37.034868 10752 solver.cpp:244]     Train net output #0: loss = 3.22731 (* 1 = 3.22731 loss)
I0419 00:08:37.034880 10752 sgd_solver.cpp:106] Iteration 48384000, lr = 3.9063e-06
I0419 00:13:43.223239 10752 solver.cpp:228] Iteration 48435200, loss = 2.48046
I0419 00:13:43.223310 10752 solver.cpp:244]     Train net output #0: loss = 1.33035 (* 1 = 1.33035 loss)
I0419 00:13:43.223316 10752 sgd_solver.cpp:106] Iteration 48435200, lr = 3.9063e-06
I0419 00:18:49.215659 10752 solver.cpp:228] Iteration 48486400, loss = 2.49881
I0419 00:18:49.215733 10752 solver.cpp:244]     Train net output #0: loss = 5.55999 (* 1 = 5.55999 loss)
I0419 00:18:49.215739 10752 sgd_solver.cpp:106] Iteration 48486400, lr = 3.9063e-06
I0419 00:23:55.284613 10752 solver.cpp:228] Iteration 48537600, loss = 2.46653
I0419 00:23:55.284685 10752 solver.cpp:244]     Train net output #0: loss = 2.27613 (* 1 = 2.27613 loss)
I0419 00:23:55.284692 10752 sgd_solver.cpp:106] Iteration 48537600, lr = 3.9063e-06
I0419 00:29:01.303009 10752 solver.cpp:228] Iteration 48588800, loss = 2.46695
I0419 00:29:01.303082 10752 solver.cpp:244]     Train net output #0: loss = 6.79495e-06 (* 1 = 6.79495e-06 loss)
I0419 00:29:01.303088 10752 sgd_solver.cpp:106] Iteration 48588800, lr = 3.9063e-06
I0419 00:34:07.275496 10752 solver.cpp:454] Snapshotting to binary proto file snapshots/caffenet128_no_lrn_lsuv_relu_bs1_iter_48640000.caffemodel
I0419 00:34:07.512461 10752 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/caffenet128_no_lrn_lsuv_relu_bs1_iter_48640000.solverstate
I0419 00:34:07.571223 10752 solver.cpp:337] Iteration 48640000, Testing net (#0)
I0419 00:34:34.001919 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0419 00:34:34.106077 10752 solver.cpp:404]     Test net output #0: accuracy = 0.45248
I0419 00:34:34.106113 10752 solver.cpp:404]     Test net output #1: loss = 2.47143 (* 1 = 2.47143 loss)
I0419 00:34:34.108641 10752 solver.cpp:228] Iteration 48640000, loss = 2.45979
I0419 00:34:34.108664 10752 solver.cpp:244]     Train net output #0: loss = 2.22047 (* 1 = 2.22047 loss)
I0419 00:34:34.108675 10752 sgd_solver.cpp:106] Iteration 48640000, lr = 3.9063e-06
I0419 00:39:40.296320 10752 solver.cpp:228] Iteration 48691200, loss = 2.45802
I0419 00:39:40.296382 10752 solver.cpp:244]     Train net output #0: loss = 4.76886 (* 1 = 4.76886 loss)
I0419 00:39:40.296388 10752 sgd_solver.cpp:106] Iteration 48691200, lr = 3.9063e-06
I0419 00:44:46.371405 10752 solver.cpp:228] Iteration 48742400, loss = 2.47333
I0419 00:44:46.371503 10752 solver.cpp:244]     Train net output #0: loss = 0.0269341 (* 1 = 0.0269341 loss)
I0419 00:44:46.371516 10752 sgd_solver.cpp:106] Iteration 48742400, lr = 3.9063e-06
I0419 00:49:52.371122 10752 solver.cpp:228] Iteration 48793600, loss = 2.46283
I0419 00:49:52.371196 10752 solver.cpp:244]     Train net output #0: loss = 1.10313 (* 1 = 1.10313 loss)
I0419 00:49:52.371209 10752 sgd_solver.cpp:106] Iteration 48793600, lr = 3.9063e-06
I0419 00:54:58.389168 10752 solver.cpp:228] Iteration 48844800, loss = 2.45693
I0419 00:54:58.389230 10752 solver.cpp:244]     Train net output #0: loss = 1.18668 (* 1 = 1.18668 loss)
I0419 00:54:58.389243 10752 sgd_solver.cpp:106] Iteration 48844800, lr = 3.9063e-06
I0419 01:00:04.340541 10752 solver.cpp:337] Iteration 48896000, Testing net (#0)
I0419 01:00:31.436902 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0419 01:00:31.489737 10752 solver.cpp:404]     Test net output #0: accuracy = 0.45058
I0419 01:00:31.489768 10752 solver.cpp:404]     Test net output #1: loss = 2.48241 (* 1 = 2.48241 loss)
I0419 01:00:31.492764 10752 solver.cpp:228] Iteration 48896000, loss = 2.49686
I0419 01:00:31.492789 10752 solver.cpp:244]     Train net output #0: loss = 2.07927 (* 1 = 2.07927 loss)
I0419 01:00:31.492795 10752 sgd_solver.cpp:106] Iteration 48896000, lr = 3.9063e-06
I0419 01:05:37.720046 10752 solver.cpp:228] Iteration 48947200, loss = 2.4893
I0419 01:05:37.720120 10752 solver.cpp:244]     Train net output #0: loss = 5.04565 (* 1 = 5.04565 loss)
I0419 01:05:37.720126 10752 sgd_solver.cpp:106] Iteration 48947200, lr = 3.9063e-06
I0419 01:10:43.722259 10752 solver.cpp:228] Iteration 48998400, loss = 2.48462
I0419 01:10:43.722342 10752 solver.cpp:244]     Train net output #0: loss = 2.46217 (* 1 = 2.46217 loss)
I0419 01:10:43.722352 10752 sgd_solver.cpp:106] Iteration 48998400, lr = 3.9063e-06
I0419 01:15:49.772569 10752 solver.cpp:228] Iteration 49049600, loss = 2.46572
I0419 01:15:49.772640 10752 solver.cpp:244]     Train net output #0: loss = 9.76073 (* 1 = 9.76073 loss)
I0419 01:15:49.772650 10752 sgd_solver.cpp:106] Iteration 49049600, lr = 3.9063e-06
I0419 01:20:55.792758 10752 solver.cpp:228] Iteration 49100800, loss = 2.46421
I0419 01:20:55.792832 10752 solver.cpp:244]     Train net output #0: loss = 0.468632 (* 1 = 0.468632 loss)
I0419 01:20:55.792839 10752 sgd_solver.cpp:106] Iteration 49100800, lr = 3.9063e-06
I0419 01:26:01.858333 10752 solver.cpp:337] Iteration 49152000, Testing net (#0)
I0419 01:26:28.281970 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0419 01:26:28.308435 10752 solver.cpp:404]     Test net output #0: accuracy = 0.45194
I0419 01:26:28.308468 10752 solver.cpp:404]     Test net output #1: loss = 2.47122 (* 1 = 2.47122 loss)
I0419 01:26:28.311013 10752 solver.cpp:228] Iteration 49152000, loss = 2.44617
I0419 01:26:28.311030 10752 solver.cpp:244]     Train net output #0: loss = 0.839069 (* 1 = 0.839069 loss)
I0419 01:26:28.311040 10752 sgd_solver.cpp:106] Iteration 49152000, lr = 3.9063e-06
I0419 01:31:34.548815 10752 solver.cpp:228] Iteration 49203200, loss = 2.45118
I0419 01:31:34.548888 10752 solver.cpp:244]     Train net output #0: loss = 2.73727 (* 1 = 2.73727 loss)
I0419 01:31:34.548902 10752 sgd_solver.cpp:106] Iteration 49203200, lr = 3.9063e-06
I0419 01:36:40.560062 10752 solver.cpp:228] Iteration 49254400, loss = 2.46797
I0419 01:36:40.560134 10752 solver.cpp:244]     Train net output #0: loss = 4.61642 (* 1 = 4.61642 loss)
I0419 01:36:40.560145 10752 sgd_solver.cpp:106] Iteration 49254400, lr = 3.9063e-06
I0419 01:41:46.637760 10752 solver.cpp:228] Iteration 49305600, loss = 2.45991
I0419 01:41:46.637835 10752 solver.cpp:244]     Train net output #0: loss = 0.103557 (* 1 = 0.103557 loss)
I0419 01:41:46.637847 10752 sgd_solver.cpp:106] Iteration 49305600, lr = 3.9063e-06
I0419 01:46:52.597895 10752 solver.cpp:228] Iteration 49356800, loss = 2.44622
I0419 01:46:52.597977 10752 solver.cpp:244]     Train net output #0: loss = 5.38495 (* 1 = 5.38495 loss)
I0419 01:46:52.597990 10752 sgd_solver.cpp:106] Iteration 49356800, lr = 3.9063e-06
I0419 01:51:58.668915 10752 solver.cpp:337] Iteration 49408000, Testing net (#0)
I0419 01:52:25.124717 10752 solver.cpp:404]     Test net output #0: accuracy = 0.45064
I0419 01:52:25.124752 10752 solver.cpp:404]     Test net output #1: loss = 2.47313 (* 1 = 2.47313 loss)
I0419 01:52:25.127313 10752 solver.cpp:228] Iteration 49408000, loss = 2.46502
I0419 01:52:25.127353 10752 solver.cpp:244]     Train net output #0: loss = 0.567025 (* 1 = 0.567025 loss)
I0419 01:52:25.127373 10752 sgd_solver.cpp:106] Iteration 49408000, lr = 3.9063e-06
I0419 01:57:31.407557 10752 solver.cpp:228] Iteration 49459200, loss = 2.48441
I0419 01:57:31.407610 10752 solver.cpp:244]     Train net output #0: loss = 0.258362 (* 1 = 0.258362 loss)
I0419 01:57:31.407624 10752 sgd_solver.cpp:106] Iteration 49459200, lr = 3.9063e-06
I0419 02:02:37.459491 10752 solver.cpp:228] Iteration 49510400, loss = 2.48828
I0419 02:02:37.459553 10752 solver.cpp:244]     Train net output #0: loss = 6.27909 (* 1 = 6.27909 loss)
I0419 02:02:37.459566 10752 sgd_solver.cpp:106] Iteration 49510400, lr = 3.9063e-06
I0419 02:07:43.509901 10752 solver.cpp:228] Iteration 49561600, loss = 2.4917
I0419 02:07:43.509960 10752 solver.cpp:244]     Train net output #0: loss = 0.319351 (* 1 = 0.319351 loss)
I0419 02:07:43.509966 10752 sgd_solver.cpp:106] Iteration 49561600, lr = 3.9063e-06
I0419 02:12:49.548768 10752 solver.cpp:228] Iteration 49612800, loss = 2.4685
I0419 02:12:49.548838 10752 solver.cpp:244]     Train net output #0: loss = 1.42234 (* 1 = 1.42234 loss)
I0419 02:12:49.548846 10752 sgd_solver.cpp:106] Iteration 49612800, lr = 3.9063e-06
I0419 02:17:55.594957 10752 solver.cpp:337] Iteration 49664000, Testing net (#0)
I0419 02:17:55.624825 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0419 02:18:22.192720 10752 solver.cpp:404]     Test net output #0: accuracy = 0.45
I0419 02:18:22.192754 10752 solver.cpp:404]     Test net output #1: loss = 2.47291 (* 1 = 2.47291 loss)
I0419 02:18:22.195339 10752 solver.cpp:228] Iteration 49664000, loss = 2.47633
I0419 02:18:22.195379 10752 solver.cpp:244]     Train net output #0: loss = 4.63107 (* 1 = 4.63107 loss)
I0419 02:18:22.195397 10752 sgd_solver.cpp:106] Iteration 49664000, lr = 3.9063e-06
I0419 02:23:28.343384 10752 solver.cpp:228] Iteration 49715200, loss = 2.46317
I0419 02:23:28.343461 10752 solver.cpp:244]     Train net output #0: loss = 0.792034 (* 1 = 0.792034 loss)
I0419 02:23:28.343473 10752 sgd_solver.cpp:106] Iteration 49715200, lr = 3.9063e-06
I0419 02:28:34.401772 10752 solver.cpp:228] Iteration 49766400, loss = 2.48933
I0419 02:28:34.401839 10752 solver.cpp:244]     Train net output #0: loss = 6.65978 (* 1 = 6.65978 loss)
I0419 02:28:34.401859 10752 sgd_solver.cpp:106] Iteration 49766400, lr = 3.9063e-06
I0419 02:33:40.420083 10752 solver.cpp:228] Iteration 49817600, loss = 2.46516
I0419 02:33:40.420155 10752 solver.cpp:244]     Train net output #0: loss = 1.0796 (* 1 = 1.0796 loss)
I0419 02:33:40.420162 10752 sgd_solver.cpp:106] Iteration 49817600, lr = 3.9063e-06
I0419 02:38:46.405864 10752 solver.cpp:228] Iteration 49868800, loss = 2.45263
I0419 02:38:46.405936 10752 solver.cpp:244]     Train net output #0: loss = 5.51654 (* 1 = 5.51654 loss)
I0419 02:38:46.405946 10752 sgd_solver.cpp:106] Iteration 49868800, lr = 3.9063e-06
I0419 02:43:52.369335 10752 solver.cpp:337] Iteration 49920000, Testing net (#0)
I0419 02:43:52.461575 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0419 02:44:18.866857 10752 solver.cpp:404]     Test net output #0: accuracy = 0.45158
I0419 02:44:18.866889 10752 solver.cpp:404]     Test net output #1: loss = 2.46893 (* 1 = 2.46893 loss)
I0419 02:44:18.869426 10752 solver.cpp:228] Iteration 49920000, loss = 2.44514
I0419 02:44:18.869443 10752 solver.cpp:244]     Train net output #0: loss = 0.356605 (* 1 = 0.356605 loss)
I0419 02:44:18.869452 10752 sgd_solver.cpp:106] Iteration 49920000, lr = 3.9063e-06
I0419 02:49:24.950651 10752 solver.cpp:228] Iteration 49971200, loss = 2.46266
I0419 02:49:24.950736 10752 solver.cpp:244]     Train net output #0: loss = 0.74158 (* 1 = 0.74158 loss)
I0419 02:49:24.950747 10752 sgd_solver.cpp:106] Iteration 49971200, lr = 3.9063e-06
I0419 02:54:31.019829 10752 solver.cpp:228] Iteration 50022400, loss = 2.46339
I0419 02:54:31.019891 10752 solver.cpp:244]     Train net output #0: loss = 0.382883 (* 1 = 0.382883 loss)
I0419 02:54:31.019906 10752 sgd_solver.cpp:106] Iteration 50022400, lr = 3.9063e-06
I0419 02:59:37.114917 10752 solver.cpp:228] Iteration 50073600, loss = 2.46276
I0419 02:59:37.114989 10752 solver.cpp:244]     Train net output #0: loss = 1.63889 (* 1 = 1.63889 loss)
I0419 02:59:37.114998 10752 sgd_solver.cpp:106] Iteration 50073600, lr = 3.9063e-06
I0419 03:04:43.138044 10752 solver.cpp:228] Iteration 50124800, loss = 2.46057
I0419 03:04:43.138118 10752 solver.cpp:244]     Train net output #0: loss = 1.96701 (* 1 = 1.96701 loss)
I0419 03:04:43.138133 10752 sgd_solver.cpp:106] Iteration 50124800, lr = 3.9063e-06
I0419 03:09:49.089831 10752 solver.cpp:337] Iteration 50176000, Testing net (#0)
I0419 03:09:49.237277 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0419 03:10:15.560160 10752 solver.cpp:404]     Test net output #0: accuracy = 0.45302
I0419 03:10:15.560194 10752 solver.cpp:404]     Test net output #1: loss = 2.47177 (* 1 = 2.47177 loss)
I0419 03:10:15.562700 10752 solver.cpp:228] Iteration 50176000, loss = 2.49707
I0419 03:10:15.562716 10752 solver.cpp:244]     Train net output #0: loss = 1.28289 (* 1 = 1.28289 loss)
I0419 03:10:15.562727 10752 sgd_solver.cpp:106] Iteration 50176000, lr = 3.9063e-06
I0419 03:15:21.707851 10752 solver.cpp:228] Iteration 50227200, loss = 2.47939
I0419 03:15:21.707921 10752 solver.cpp:244]     Train net output #0: loss = 1.96867 (* 1 = 1.96867 loss)
I0419 03:15:21.707931 10752 sgd_solver.cpp:106] Iteration 50227200, lr = 3.9063e-06
I0419 03:20:27.802490 10752 solver.cpp:228] Iteration 50278400, loss = 2.47483
I0419 03:20:27.802567 10752 solver.cpp:244]     Train net output #0: loss = 2.18432 (* 1 = 2.18432 loss)
I0419 03:20:27.802582 10752 sgd_solver.cpp:106] Iteration 50278400, lr = 3.9063e-06
I0419 03:25:33.866299 10752 solver.cpp:228] Iteration 50329600, loss = 2.46004
I0419 03:25:33.866365 10752 solver.cpp:244]     Train net output #0: loss = 4.57033 (* 1 = 4.57033 loss)
I0419 03:25:33.866371 10752 sgd_solver.cpp:106] Iteration 50329600, lr = 3.9063e-06
I0419 03:30:39.943197 10752 solver.cpp:228] Iteration 50380800, loss = 2.46503
I0419 03:30:39.943256 10752 solver.cpp:244]     Train net output #0: loss = 1.04545 (* 1 = 1.04545 loss)
I0419 03:30:39.943261 10752 sgd_solver.cpp:106] Iteration 50380800, lr = 3.9063e-06
I0419 03:35:45.933264 10752 solver.cpp:337] Iteration 50432000, Testing net (#0)
I0419 03:35:46.131242 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0419 03:36:12.369034 10752 solver.cpp:404]     Test net output #0: accuracy = 0.45358
I0419 03:36:12.369074 10752 solver.cpp:404]     Test net output #1: loss = 2.46732 (* 1 = 2.46732 loss)
I0419 03:36:12.371623 10752 solver.cpp:228] Iteration 50432000, loss = 2.45103
I0419 03:36:12.371645 10752 solver.cpp:244]     Train net output #0: loss = 0.218702 (* 1 = 0.218702 loss)
I0419 03:36:12.371657 10752 sgd_solver.cpp:106] Iteration 50432000, lr = 3.9063e-06
I0419 03:41:18.606114 10752 solver.cpp:228] Iteration 50483200, loss = 2.44629
I0419 03:41:18.606175 10752 solver.cpp:244]     Train net output #0: loss = 1.75734 (* 1 = 1.75734 loss)
I0419 03:41:18.606189 10752 sgd_solver.cpp:106] Iteration 50483200, lr = 3.9063e-06
I0419 03:46:24.631752 10752 solver.cpp:228] Iteration 50534400, loss = 2.46708
I0419 03:46:24.631819 10752 solver.cpp:244]     Train net output #0: loss = 0.222281 (* 1 = 0.222281 loss)
I0419 03:46:24.631834 10752 sgd_solver.cpp:106] Iteration 50534400, lr = 3.9063e-06
I0419 03:51:30.743850 10752 solver.cpp:228] Iteration 50585600, loss = 2.44631
I0419 03:51:30.743911 10752 solver.cpp:244]     Train net output #0: loss = 4.19423 (* 1 = 4.19423 loss)
I0419 03:51:30.743921 10752 sgd_solver.cpp:106] Iteration 50585600, lr = 3.9063e-06
I0419 03:56:36.809598 10752 solver.cpp:228] Iteration 50636800, loss = 2.44367
I0419 03:56:36.809690 10752 solver.cpp:244]     Train net output #0: loss = 4.02505 (* 1 = 4.02505 loss)
I0419 03:56:36.809700 10752 sgd_solver.cpp:106] Iteration 50636800, lr = 3.9063e-06
I0419 04:01:42.904592 10752 solver.cpp:337] Iteration 50688000, Testing net (#0)
I0419 04:01:43.157016 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0419 04:02:09.356967 10752 solver.cpp:404]     Test net output #0: accuracy = 0.45234
I0419 04:02:09.357002 10752 solver.cpp:404]     Test net output #1: loss = 2.47175 (* 1 = 2.47175 loss)
I0419 04:02:09.359474 10752 solver.cpp:228] Iteration 50688000, loss = 2.45461
I0419 04:02:09.359493 10752 solver.cpp:244]     Train net output #0: loss = 4.08215 (* 1 = 4.08215 loss)
I0419 04:02:09.359515 10752 sgd_solver.cpp:106] Iteration 50688000, lr = 3.9063e-06
I0419 04:07:15.683781 10752 solver.cpp:228] Iteration 50739200, loss = 2.48733
I0419 04:07:15.683851 10752 solver.cpp:244]     Train net output #0: loss = 0.0384039 (* 1 = 0.0384039 loss)
I0419 04:07:15.683862 10752 sgd_solver.cpp:106] Iteration 50739200, lr = 3.9063e-06
I0419 04:12:21.799284 10752 solver.cpp:228] Iteration 50790400, loss = 2.49058
I0419 04:12:21.799358 10752 solver.cpp:244]     Train net output #0: loss = 2.88072 (* 1 = 2.88072 loss)
I0419 04:12:21.799371 10752 sgd_solver.cpp:106] Iteration 50790400, lr = 3.9063e-06
I0419 04:17:27.822666 10752 solver.cpp:228] Iteration 50841600, loss = 2.48775
I0419 04:17:27.822739 10752 solver.cpp:244]     Train net output #0: loss = 1.9449 (* 1 = 1.9449 loss)
I0419 04:17:27.822747 10752 sgd_solver.cpp:106] Iteration 50841600, lr = 3.9063e-06
I0419 04:22:33.893628 10752 solver.cpp:228] Iteration 50892800, loss = 2.46143
I0419 04:22:33.893703 10752 solver.cpp:244]     Train net output #0: loss = 0.269543 (* 1 = 0.269543 loss)
I0419 04:22:33.893717 10752 sgd_solver.cpp:106] Iteration 50892800, lr = 3.9063e-06
I0419 04:27:39.961848 10752 solver.cpp:337] Iteration 50944000, Testing net (#0)
I0419 04:27:40.266913 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0419 04:28:06.406782 10752 solver.cpp:404]     Test net output #0: accuracy = 0.45358
I0419 04:28:06.406816 10752 solver.cpp:404]     Test net output #1: loss = 2.46257 (* 1 = 2.46257 loss)
I0419 04:28:06.409320 10752 solver.cpp:228] Iteration 50944000, loss = 2.46998
I0419 04:28:06.409337 10752 solver.cpp:244]     Train net output #0: loss = 1.60874 (* 1 = 1.60874 loss)
I0419 04:28:06.409348 10752 sgd_solver.cpp:106] Iteration 50944000, lr = 3.9063e-06
I0419 04:33:12.637590 10752 solver.cpp:228] Iteration 50995200, loss = 2.45878
I0419 04:33:12.637663 10752 solver.cpp:244]     Train net output #0: loss = 2.02787 (* 1 = 2.02787 loss)
I0419 04:33:12.637678 10752 sgd_solver.cpp:106] Iteration 50995200, lr = 3.9063e-06
I0419 04:38:18.711519 10752 solver.cpp:228] Iteration 51046400, loss = 2.48495
I0419 04:38:18.711613 10752 solver.cpp:244]     Train net output #0: loss = 5.52057 (* 1 = 5.52057 loss)
I0419 04:38:18.711629 10752 sgd_solver.cpp:106] Iteration 51046400, lr = 3.9063e-06
I0419 04:43:24.813334 10752 solver.cpp:228] Iteration 51097600, loss = 2.4565
I0419 04:43:24.813407 10752 solver.cpp:244]     Train net output #0: loss = 0.429263 (* 1 = 0.429263 loss)
I0419 04:43:24.813413 10752 sgd_solver.cpp:106] Iteration 51097600, lr = 3.9063e-06
I0419 04:48:30.821683 10752 solver.cpp:228] Iteration 51148800, loss = 2.45027
I0419 04:48:30.821753 10752 solver.cpp:244]     Train net output #0: loss = 1.81877 (* 1 = 1.81877 loss)
I0419 04:48:30.821763 10752 sgd_solver.cpp:106] Iteration 51148800, lr = 3.9063e-06
I0419 04:53:41.865345 10752 solver.cpp:454] Snapshotting to binary proto file snapshots/caffenet128_no_lrn_lsuv_relu_bs1_iter_51200000.caffemodel
I0419 04:53:42.030308 10752 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/caffenet128_no_lrn_lsuv_relu_bs1_iter_51200000.solverstate
I0419 04:53:42.091459 10752 solver.cpp:337] Iteration 51200000, Testing net (#0)
I0419 04:53:42.264976 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0419 04:54:08.719017 10752 solver.cpp:404]     Test net output #0: accuracy = 0.4514
I0419 04:54:08.719051 10752 solver.cpp:404]     Test net output #1: loss = 2.46302 (* 1 = 2.46302 loss)
I0419 04:54:08.721622 10752 solver.cpp:228] Iteration 51200000, loss = 2.4523
I0419 04:54:08.721655 10752 solver.cpp:244]     Train net output #0: loss = 5.59558 (* 1 = 5.59558 loss)
I0419 04:54:08.721665 10752 sgd_solver.cpp:106] Iteration 51200000, lr = 3.9063e-07
I0419 04:59:16.781424 10752 solver.cpp:228] Iteration 51251200, loss = 2.41324
I0419 04:59:16.781502 10752 solver.cpp:244]     Train net output #0: loss = 3.4421 (* 1 = 3.4421 loss)
I0419 04:59:16.781517 10752 sgd_solver.cpp:106] Iteration 51251200, lr = 3.9063e-07
I0419 05:04:26.080032 10752 solver.cpp:228] Iteration 51302400, loss = 2.4158
I0419 05:04:26.080096 10752 solver.cpp:244]     Train net output #0: loss = 1.57379 (* 1 = 1.57379 loss)
I0419 05:04:26.080103 10752 sgd_solver.cpp:106] Iteration 51302400, lr = 3.9063e-07
I0419 05:09:33.458366 10752 solver.cpp:228] Iteration 51353600, loss = 2.40131
I0419 05:09:33.458425 10752 solver.cpp:244]     Train net output #0: loss = 4.51257 (* 1 = 4.51257 loss)
I0419 05:09:33.458431 10752 sgd_solver.cpp:106] Iteration 51353600, lr = 3.9063e-07
I0419 05:14:39.947340 10752 solver.cpp:228] Iteration 51404800, loss = 2.39782
I0419 05:14:39.947410 10752 solver.cpp:244]     Train net output #0: loss = 3.94303 (* 1 = 3.94303 loss)
I0419 05:14:39.947417 10752 sgd_solver.cpp:106] Iteration 51404800, lr = 3.9063e-07
I0419 05:19:46.334659 10752 solver.cpp:337] Iteration 51456000, Testing net (#0)
I0419 05:19:46.401463 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0419 05:20:12.826527 10752 solver.cpp:404]     Test net output #0: accuracy = 0.46366
I0419 05:20:12.826561 10752 solver.cpp:404]     Test net output #1: loss = 2.4071 (* 1 = 2.4071 loss)
I0419 05:20:12.829110 10752 solver.cpp:228] Iteration 51456000, loss = 2.42165
I0419 05:20:12.829128 10752 solver.cpp:244]     Train net output #0: loss = 1.5642 (* 1 = 1.5642 loss)
I0419 05:20:12.829138 10752 sgd_solver.cpp:106] Iteration 51456000, lr = 3.9063e-07
I0419 05:25:19.477195 10752 solver.cpp:228] Iteration 51507200, loss = 2.40717
I0419 05:25:19.477270 10752 solver.cpp:244]     Train net output #0: loss = 0.0338341 (* 1 = 0.0338341 loss)
I0419 05:25:19.477277 10752 sgd_solver.cpp:106] Iteration 51507200, lr = 3.9063e-07
I0419 05:30:26.105506 10752 solver.cpp:228] Iteration 51558400, loss = 2.40338
I0419 05:30:26.105563 10752 solver.cpp:244]     Train net output #0: loss = 2.66462 (* 1 = 2.66462 loss)
I0419 05:30:26.105569 10752 sgd_solver.cpp:106] Iteration 51558400, lr = 3.9063e-07
I0419 05:35:32.685016 10752 solver.cpp:228] Iteration 51609600, loss = 2.37588
I0419 05:35:32.685087 10752 solver.cpp:244]     Train net output #0: loss = 0.405259 (* 1 = 0.405259 loss)
I0419 05:35:32.685094 10752 sgd_solver.cpp:106] Iteration 51609600, lr = 3.9063e-07
I0419 05:40:39.195289 10752 solver.cpp:228] Iteration 51660800, loss = 2.38494
I0419 05:40:39.195353 10752 solver.cpp:244]     Train net output #0: loss = 0.210212 (* 1 = 0.210212 loss)
I0419 05:40:39.195363 10752 sgd_solver.cpp:106] Iteration 51660800, lr = 3.9063e-07
I0419 05:45:45.673820 10752 solver.cpp:337] Iteration 51712000, Testing net (#0)
I0419 05:45:45.810925 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0419 05:46:12.340083 10752 solver.cpp:404]     Test net output #0: accuracy = 0.4658
I0419 05:46:12.340114 10752 solver.cpp:404]     Test net output #1: loss = 2.40132 (* 1 = 2.40132 loss)
I0419 05:46:12.343113 10752 solver.cpp:228] Iteration 51712000, loss = 2.36905
I0419 05:46:12.343142 10752 solver.cpp:244]     Train net output #0: loss = 4.53374 (* 1 = 4.53374 loss)
I0419 05:46:12.343150 10752 sgd_solver.cpp:106] Iteration 51712000, lr = 3.9063e-07
I0419 05:51:19.063324 10752 solver.cpp:228] Iteration 51763200, loss = 2.36953
I0419 05:51:19.063410 10752 solver.cpp:244]     Train net output #0: loss = 0.578049 (* 1 = 0.578049 loss)
I0419 05:51:19.063418 10752 sgd_solver.cpp:106] Iteration 51763200, lr = 3.9063e-07
I0419 05:56:25.454869 10752 solver.cpp:228] Iteration 51814400, loss = 2.37963
I0419 05:56:25.454946 10752 solver.cpp:244]     Train net output #0: loss = 0.041191 (* 1 = 0.041191 loss)
I0419 05:56:25.454952 10752 sgd_solver.cpp:106] Iteration 51814400, lr = 3.9063e-07
I0419 06:01:31.978246 10752 solver.cpp:228] Iteration 51865600, loss = 2.37212
I0419 06:01:31.978312 10752 solver.cpp:244]     Train net output #0: loss = 2.20495 (* 1 = 2.20495 loss)
I0419 06:01:31.978318 10752 sgd_solver.cpp:106] Iteration 51865600, lr = 3.9063e-07
I0419 06:06:38.403005 10752 solver.cpp:228] Iteration 51916800, loss = 2.35152
I0419 06:06:38.403069 10752 solver.cpp:244]     Train net output #0: loss = 0.00609325 (* 1 = 0.00609325 loss)
I0419 06:06:38.403075 10752 sgd_solver.cpp:106] Iteration 51916800, lr = 3.9063e-07
I0419 06:11:44.714148 10752 solver.cpp:337] Iteration 51968000, Testing net (#0)
I0419 06:11:44.909721 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0419 06:12:11.264235 10752 solver.cpp:404]     Test net output #0: accuracy = 0.465401
I0419 06:12:11.264266 10752 solver.cpp:404]     Test net output #1: loss = 2.40092 (* 1 = 2.40092 loss)
I0419 06:12:11.266798 10752 solver.cpp:228] Iteration 51968000, loss = 2.36652
I0419 06:12:11.266815 10752 solver.cpp:244]     Train net output #0: loss = 0.924143 (* 1 = 0.924143 loss)
I0419 06:12:11.266825 10752 sgd_solver.cpp:106] Iteration 51968000, lr = 3.9063e-07
I0419 06:17:18.013947 10752 solver.cpp:228] Iteration 52019200, loss = 2.39667
I0419 06:17:18.014013 10752 solver.cpp:244]     Train net output #0: loss = 5.47181 (* 1 = 5.47181 loss)
I0419 06:17:18.014019 10752 sgd_solver.cpp:106] Iteration 52019200, lr = 3.9063e-07
I0419 06:22:24.385807 10752 solver.cpp:228] Iteration 52070400, loss = 2.38212
I0419 06:22:24.385871 10752 solver.cpp:244]     Train net output #0: loss = 5.4323 (* 1 = 5.4323 loss)
I0419 06:22:24.385879 10752 sgd_solver.cpp:106] Iteration 52070400, lr = 3.9063e-07
I0419 06:27:30.901147 10752 solver.cpp:228] Iteration 52121600, loss = 2.39334
I0419 06:27:30.901207 10752 solver.cpp:244]     Train net output #0: loss = 3.63603 (* 1 = 3.63603 loss)
I0419 06:27:30.901214 10752 sgd_solver.cpp:106] Iteration 52121600, lr = 3.9063e-07
I0419 06:32:37.358927 10752 solver.cpp:228] Iteration 52172800, loss = 2.36466
I0419 06:32:37.358997 10752 solver.cpp:244]     Train net output #0: loss = 3.66897 (* 1 = 3.66897 loss)
I0419 06:32:37.359004 10752 sgd_solver.cpp:106] Iteration 52172800, lr = 3.9063e-07
I0419 06:37:43.774878 10752 solver.cpp:337] Iteration 52224000, Testing net (#0)
I0419 06:37:44.030803 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0419 06:38:10.623502 10752 solver.cpp:404]     Test net output #0: accuracy = 0.4661
I0419 06:38:10.623533 10752 solver.cpp:404]     Test net output #1: loss = 2.39724 (* 1 = 2.39724 loss)
I0419 06:38:10.626566 10752 solver.cpp:228] Iteration 52224000, loss = 2.35184
I0419 06:38:10.626596 10752 solver.cpp:244]     Train net output #0: loss = 0.0626408 (* 1 = 0.0626408 loss)
I0419 06:38:10.626605 10752 sgd_solver.cpp:106] Iteration 52224000, lr = 3.9063e-07
I0419 06:43:16.939743 10752 solver.cpp:228] Iteration 52275200, loss = 2.35952
I0419 06:43:16.939805 10752 solver.cpp:244]     Train net output #0: loss = 0.252317 (* 1 = 0.252317 loss)
I0419 06:43:16.939812 10752 sgd_solver.cpp:106] Iteration 52275200, lr = 3.9063e-07
I0419 06:48:23.543015 10752 solver.cpp:228] Iteration 52326400, loss = 2.37982
I0419 06:48:23.543076 10752 solver.cpp:244]     Train net output #0: loss = 2.14891 (* 1 = 2.14891 loss)
I0419 06:48:23.543084 10752 sgd_solver.cpp:106] Iteration 52326400, lr = 3.9063e-07
I0419 06:53:29.938796 10752 solver.cpp:228] Iteration 52377600, loss = 2.35481
I0419 06:53:29.938855 10752 solver.cpp:244]     Train net output #0: loss = 1.52389 (* 1 = 1.52389 loss)
I0419 06:53:29.938863 10752 sgd_solver.cpp:106] Iteration 52377600, lr = 3.9063e-07
I0419 06:58:36.558876 10752 solver.cpp:228] Iteration 52428800, loss = 2.33921
I0419 06:58:36.558969 10752 solver.cpp:244]     Train net output #0: loss = 2.75354 (* 1 = 2.75354 loss)
I0419 06:58:36.558976 10752 sgd_solver.cpp:106] Iteration 52428800, lr = 3.9063e-07
I0419 07:03:43.055158 10752 solver.cpp:337] Iteration 52480000, Testing net (#0)
I0419 07:03:43.335469 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0419 07:04:09.645961 10752 solver.cpp:404]     Test net output #0: accuracy = 0.4655
I0419 07:04:09.645997 10752 solver.cpp:404]     Test net output #1: loss = 2.39573 (* 1 = 2.39573 loss)
I0419 07:04:09.648512 10752 solver.cpp:228] Iteration 52480000, loss = 2.3305
I0419 07:04:09.648533 10752 solver.cpp:244]     Train net output #0: loss = 8.37822 (* 1 = 8.37822 loss)
I0419 07:04:09.648542 10752 sgd_solver.cpp:106] Iteration 52480000, lr = 3.9063e-07
I0419 07:09:16.238473 10752 solver.cpp:228] Iteration 52531200, loss = 2.3805
I0419 07:09:16.238534 10752 solver.cpp:244]     Train net output #0: loss = 1.66883 (* 1 = 1.66883 loss)
I0419 07:09:16.238548 10752 sgd_solver.cpp:106] Iteration 52531200, lr = 3.9063e-07
I0419 07:14:22.757928 10752 solver.cpp:228] Iteration 52582400, loss = 2.3779
I0419 07:14:22.757990 10752 solver.cpp:244]     Train net output #0: loss = 2.07362 (* 1 = 2.07362 loss)
I0419 07:14:22.757998 10752 sgd_solver.cpp:106] Iteration 52582400, lr = 3.9063e-07
I0419 07:19:30.404183 10752 solver.cpp:228] Iteration 52633600, loss = 2.37188
I0419 07:19:30.404299 10752 solver.cpp:244]     Train net output #0: loss = 2.46124 (* 1 = 2.46124 loss)
I0419 07:19:30.404323 10752 sgd_solver.cpp:106] Iteration 52633600, lr = 3.9063e-07
I0419 07:24:38.450590 10752 solver.cpp:228] Iteration 52684800, loss = 2.37594
I0419 07:24:38.450649 10752 solver.cpp:244]     Train net output #0: loss = 2.40564 (* 1 = 2.40564 loss)
I0419 07:24:38.450654 10752 sgd_solver.cpp:106] Iteration 52684800, lr = 3.9063e-07
I0419 07:29:44.734041 10752 solver.cpp:337] Iteration 52736000, Testing net (#0)
I0419 07:29:44.934670 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0419 07:30:11.252012 10752 solver.cpp:404]     Test net output #0: accuracy = 0.46658
I0419 07:30:11.252044 10752 solver.cpp:404]     Test net output #1: loss = 2.39348 (* 1 = 2.39348 loss)
I0419 07:30:11.254576 10752 solver.cpp:228] Iteration 52736000, loss = 2.39709
I0419 07:30:11.254592 10752 solver.cpp:244]     Train net output #0: loss = 6.95798 (* 1 = 6.95798 loss)
I0419 07:30:11.254600 10752 sgd_solver.cpp:106] Iteration 52736000, lr = 3.9063e-07
I0419 07:35:20.697095 10752 solver.cpp:228] Iteration 52787200, loss = 2.39166
I0419 07:35:20.697160 10752 solver.cpp:244]     Train net output #0: loss = 0.0427736 (* 1 = 0.0427736 loss)
I0419 07:35:20.697168 10752 sgd_solver.cpp:106] Iteration 52787200, lr = 3.9063e-07
I0419 07:40:31.087422 10752 solver.cpp:228] Iteration 52838400, loss = 2.38675
I0419 07:40:31.087482 10752 solver.cpp:244]     Train net output #0: loss = 2.96051 (* 1 = 2.96051 loss)
I0419 07:40:31.087488 10752 sgd_solver.cpp:106] Iteration 52838400, lr = 3.9063e-07
I0419 07:45:37.438375 10752 solver.cpp:228] Iteration 52889600, loss = 2.36461
I0419 07:45:37.438434 10752 solver.cpp:244]     Train net output #0: loss = 4.35685 (* 1 = 4.35685 loss)
I0419 07:45:37.438441 10752 sgd_solver.cpp:106] Iteration 52889600, lr = 3.9063e-07
I0419 07:50:44.425842 10752 solver.cpp:228] Iteration 52940800, loss = 2.36784
I0419 07:50:44.425901 10752 solver.cpp:244]     Train net output #0: loss = 2.68148 (* 1 = 2.68148 loss)
I0419 07:50:44.425906 10752 sgd_solver.cpp:106] Iteration 52940800, lr = 3.9063e-07
I0419 07:55:51.229454 10752 solver.cpp:337] Iteration 52992000, Testing net (#0)
I0419 07:55:51.277685 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0419 07:56:17.942935 10752 solver.cpp:404]     Test net output #0: accuracy = 0.46648
I0419 07:56:17.942968 10752 solver.cpp:404]     Test net output #1: loss = 2.39287 (* 1 = 2.39287 loss)
I0419 07:56:17.945485 10752 solver.cpp:228] Iteration 52992000, loss = 2.35883
I0419 07:56:17.945503 10752 solver.cpp:244]     Train net output #0: loss = 1.39939 (* 1 = 1.39939 loss)
I0419 07:56:17.945513 10752 sgd_solver.cpp:106] Iteration 52992000, lr = 3.9063e-07
I0419 08:01:27.490854 10752 solver.cpp:228] Iteration 53043200, loss = 2.36452
I0419 08:01:27.490948 10752 solver.cpp:244]     Train net output #0: loss = 5.0282 (* 1 = 5.0282 loss)
I0419 08:01:27.490955 10752 sgd_solver.cpp:106] Iteration 53043200, lr = 3.9063e-07
I0419 08:06:34.395136 10752 solver.cpp:228] Iteration 53094400, loss = 2.365
I0419 08:06:34.395212 10752 solver.cpp:244]     Train net output #0: loss = 1.15667 (* 1 = 1.15667 loss)
I0419 08:06:34.395220 10752 sgd_solver.cpp:106] Iteration 53094400, lr = 3.9063e-07
I0419 08:11:41.140054 10752 solver.cpp:228] Iteration 53145600, loss = 2.35254
I0419 08:11:41.140118 10752 solver.cpp:244]     Train net output #0: loss = 1.64927 (* 1 = 1.64927 loss)
I0419 08:11:41.140125 10752 sgd_solver.cpp:106] Iteration 53145600, lr = 3.9063e-07
I0419 08:16:47.600965 10752 solver.cpp:228] Iteration 53196800, loss = 2.34543
I0419 08:16:47.601037 10752 solver.cpp:244]     Train net output #0: loss = 6.04459 (* 1 = 6.04459 loss)
I0419 08:16:47.601043 10752 sgd_solver.cpp:106] Iteration 53196800, lr = 3.9063e-07
I0419 08:21:54.047523 10752 solver.cpp:337] Iteration 53248000, Testing net (#0)
I0419 08:21:54.096096 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0419 08:22:20.598567 10752 solver.cpp:404]     Test net output #0: accuracy = 0.46724
I0419 08:22:20.598599 10752 solver.cpp:404]     Test net output #1: loss = 2.39383 (* 1 = 2.39383 loss)
I0419 08:22:20.601110 10752 solver.cpp:228] Iteration 53248000, loss = 2.36237
I0419 08:22:20.601128 10752 solver.cpp:244]     Train net output #0: loss = 4.32638 (* 1 = 4.32638 loss)
I0419 08:22:20.601140 10752 sgd_solver.cpp:106] Iteration 53248000, lr = 3.9063e-07
I0419 08:27:27.194699 10752 solver.cpp:228] Iteration 53299200, loss = 2.39711
I0419 08:27:27.194763 10752 solver.cpp:244]     Train net output #0: loss = 9.06347 (* 1 = 9.06347 loss)
I0419 08:27:27.194777 10752 sgd_solver.cpp:106] Iteration 53299200, lr = 3.9063e-07
I0419 08:32:33.601248 10752 solver.cpp:228] Iteration 53350400, loss = 2.36808
I0419 08:32:33.601322 10752 solver.cpp:244]     Train net output #0: loss = 7.15583 (* 1 = 7.15583 loss)
I0419 08:32:33.601328 10752 sgd_solver.cpp:106] Iteration 53350400, lr = 3.9063e-07
I0419 08:37:39.955893 10752 solver.cpp:228] Iteration 53401600, loss = 2.39195
I0419 08:37:39.955963 10752 solver.cpp:244]     Train net output #0: loss = 1.97119 (* 1 = 1.97119 loss)
I0419 08:37:39.955970 10752 sgd_solver.cpp:106] Iteration 53401600, lr = 3.9063e-07
I0419 08:42:46.342631 10752 solver.cpp:228] Iteration 53452800, loss = 2.3566
I0419 08:42:46.342702 10752 solver.cpp:244]     Train net output #0: loss = 3.24937 (* 1 = 3.24937 loss)
I0419 08:42:46.342708 10752 sgd_solver.cpp:106] Iteration 53452800, lr = 3.9063e-07
I0419 08:47:52.724719 10752 solver.cpp:337] Iteration 53504000, Testing net (#0)
I0419 08:47:52.817478 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0419 08:48:19.230882 10752 solver.cpp:404]     Test net output #0: accuracy = 0.46694
I0419 08:48:19.230914 10752 solver.cpp:404]     Test net output #1: loss = 2.39066 (* 1 = 2.39066 loss)
I0419 08:48:19.233465 10752 solver.cpp:228] Iteration 53504000, loss = 2.3603
I0419 08:48:19.233482 10752 solver.cpp:244]     Train net output #0: loss = 2.29793 (* 1 = 2.29793 loss)
I0419 08:48:19.233492 10752 sgd_solver.cpp:106] Iteration 53504000, lr = 3.9063e-07
I0419 08:53:25.850342 10752 solver.cpp:228] Iteration 53555200, loss = 2.35156
I0419 08:53:25.850402 10752 solver.cpp:244]     Train net output #0: loss = 1.55369 (* 1 = 1.55369 loss)
I0419 08:53:25.850409 10752 sgd_solver.cpp:106] Iteration 53555200, lr = 3.9063e-07
I0419 08:58:32.359587 10752 solver.cpp:228] Iteration 53606400, loss = 2.37101
I0419 08:58:32.359647 10752 solver.cpp:244]     Train net output #0: loss = 0.131071 (* 1 = 0.131071 loss)
I0419 08:58:32.359652 10752 sgd_solver.cpp:106] Iteration 53606400, lr = 3.9063e-07
I0419 09:03:38.776513 10752 solver.cpp:228] Iteration 53657600, loss = 2.34861
I0419 09:03:38.776594 10752 solver.cpp:244]     Train net output #0: loss = 1.10451 (* 1 = 1.10451 loss)
I0419 09:03:38.776602 10752 sgd_solver.cpp:106] Iteration 53657600, lr = 3.9063e-07
I0419 09:08:45.283252 10752 solver.cpp:228] Iteration 53708800, loss = 2.3303
I0419 09:08:45.283313 10752 solver.cpp:244]     Train net output #0: loss = 0.000909503 (* 1 = 0.000909503 loss)
I0419 09:08:45.283319 10752 sgd_solver.cpp:106] Iteration 53708800, lr = 3.9063e-07
I0419 09:13:51.761060 10752 solver.cpp:454] Snapshotting to binary proto file snapshots/caffenet128_no_lrn_lsuv_relu_bs1_iter_53760000.caffemodel
I0419 09:13:51.981403 10752 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/caffenet128_no_lrn_lsuv_relu_bs1_iter_53760000.solverstate
I0419 09:13:52.040463 10752 solver.cpp:337] Iteration 53760000, Testing net (#0)
I0419 09:13:52.181056 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0419 09:14:18.544551 10752 solver.cpp:404]     Test net output #0: accuracy = 0.46722
I0419 09:14:18.544585 10752 solver.cpp:404]     Test net output #1: loss = 2.38789 (* 1 = 2.38789 loss)
I0419 09:14:18.547142 10752 solver.cpp:228] Iteration 53760000, loss = 2.32027
I0419 09:14:18.547161 10752 solver.cpp:244]     Train net output #0: loss = 0.0859262 (* 1 = 0.0859262 loss)
I0419 09:14:18.547169 10752 sgd_solver.cpp:106] Iteration 53760000, lr = 3.9063e-07
I0419 09:19:25.167263 10752 solver.cpp:228] Iteration 53811200, loss = 2.37058
I0419 09:19:25.167326 10752 solver.cpp:244]     Train net output #0: loss = 4.21204 (* 1 = 4.21204 loss)
I0419 09:19:25.167335 10752 sgd_solver.cpp:106] Iteration 53811200, lr = 3.9063e-07
I0419 09:24:33.008957 10752 solver.cpp:228] Iteration 53862400, loss = 2.3748
I0419 09:24:33.009022 10752 solver.cpp:244]     Train net output #0: loss = 2.69811 (* 1 = 2.69811 loss)
I0419 09:24:33.009030 10752 sgd_solver.cpp:106] Iteration 53862400, lr = 3.9063e-07
I0419 09:24:57.108783 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0419 09:29:42.163552 10752 solver.cpp:228] Iteration 53913600, loss = 2.36882
I0419 09:29:42.163620 10752 solver.cpp:244]     Train net output #0: loss = 4.11993 (* 1 = 4.11993 loss)
I0419 09:29:42.163627 10752 sgd_solver.cpp:106] Iteration 53913600, lr = 3.9063e-07
I0419 09:34:48.369729 10752 solver.cpp:228] Iteration 53964800, loss = 2.37006
I0419 09:34:48.369799 10752 solver.cpp:244]     Train net output #0: loss = 0.522516 (* 1 = 0.522516 loss)
I0419 09:34:48.369806 10752 sgd_solver.cpp:106] Iteration 53964800, lr = 3.9063e-07
I0419 09:39:54.502794 10752 solver.cpp:337] Iteration 54016000, Testing net (#0)
I0419 09:40:20.915148 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0419 09:40:20.967787 10752 solver.cpp:404]     Test net output #0: accuracy = 0.468401
I0419 09:40:20.967821 10752 solver.cpp:404]     Test net output #1: loss = 2.38857 (* 1 = 2.38857 loss)
I0419 09:40:20.970348 10752 solver.cpp:228] Iteration 54016000, loss = 2.38913
I0419 09:40:20.970369 10752 solver.cpp:244]     Train net output #0: loss = 4.05518 (* 1 = 4.05518 loss)
I0419 09:40:20.970381 10752 sgd_solver.cpp:106] Iteration 54016000, lr = 3.9063e-07
I0419 09:45:27.296489 10752 solver.cpp:228] Iteration 54067200, loss = 2.39131
I0419 09:45:27.296566 10752 solver.cpp:244]     Train net output #0: loss = 2.52985 (* 1 = 2.52985 loss)
I0419 09:45:27.296579 10752 sgd_solver.cpp:106] Iteration 54067200, lr = 3.9063e-07
I0419 09:50:33.567829 10752 solver.cpp:228] Iteration 54118400, loss = 2.37624
I0419 09:50:33.567903 10752 solver.cpp:244]     Train net output #0: loss = 1.00625 (* 1 = 1.00625 loss)
I0419 09:50:33.567909 10752 sgd_solver.cpp:106] Iteration 54118400, lr = 3.9063e-07
I0419 09:55:39.780933 10752 solver.cpp:228] Iteration 54169600, loss = 2.35018
I0419 09:55:39.780994 10752 solver.cpp:244]     Train net output #0: loss = 1.61524 (* 1 = 1.61524 loss)
I0419 09:55:39.781000 10752 sgd_solver.cpp:106] Iteration 54169600, lr = 3.9063e-07
I0419 10:00:45.978530 10752 solver.cpp:228] Iteration 54220800, loss = 2.36602
I0419 10:00:45.978618 10752 solver.cpp:244]     Train net output #0: loss = 5.75605 (* 1 = 5.75605 loss)
I0419 10:00:45.978626 10752 sgd_solver.cpp:106] Iteration 54220800, lr = 3.9063e-07
I0419 10:05:52.163738 10752 solver.cpp:337] Iteration 54272000, Testing net (#0)
I0419 10:06:18.619182 10752 solver.cpp:404]     Test net output #0: accuracy = 0.46796
I0419 10:06:18.619216 10752 solver.cpp:404]     Test net output #1: loss = 2.38842 (* 1 = 2.38842 loss)
I0419 10:06:18.621742 10752 solver.cpp:228] Iteration 54272000, loss = 2.35905
I0419 10:06:18.621775 10752 solver.cpp:244]     Train net output #0: loss = 8.6709 (* 1 = 8.6709 loss)
I0419 10:06:18.621786 10752 sgd_solver.cpp:106] Iteration 54272000, lr = 3.9063e-07
I0419 10:06:18.712461 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0419 10:11:24.956187 10752 solver.cpp:228] Iteration 54323200, loss = 2.35318
I0419 10:11:24.956236 10752 solver.cpp:244]     Train net output #0: loss = 0.319693 (* 1 = 0.319693 loss)
I0419 10:11:24.956241 10752 sgd_solver.cpp:106] Iteration 54323200, lr = 3.9063e-07
I0419 10:16:30.963024 10752 solver.cpp:228] Iteration 54374400, loss = 2.36777
I0419 10:16:30.963099 10752 solver.cpp:244]     Train net output #0: loss = 0.0893384 (* 1 = 0.0893384 loss)
I0419 10:16:30.963109 10752 sgd_solver.cpp:106] Iteration 54374400, lr = 3.9063e-07
I0419 10:21:37.086894 10752 solver.cpp:228] Iteration 54425600, loss = 2.35262
I0419 10:21:37.086953 10752 solver.cpp:244]     Train net output #0: loss = 0.143403 (* 1 = 0.143403 loss)
I0419 10:21:37.086959 10752 sgd_solver.cpp:106] Iteration 54425600, lr = 3.9063e-07
I0419 10:26:43.071523 10752 solver.cpp:228] Iteration 54476800, loss = 2.33447
I0419 10:26:43.071590 10752 solver.cpp:244]     Train net output #0: loss = 6.04118 (* 1 = 6.04118 loss)
I0419 10:26:43.071596 10752 sgd_solver.cpp:106] Iteration 54476800, lr = 3.9063e-07
I0419 10:31:49.180476 10752 solver.cpp:337] Iteration 54528000, Testing net (#0)
I0419 10:32:15.672138 10752 solver.cpp:404]     Test net output #0: accuracy = 0.46768
I0419 10:32:15.672173 10752 solver.cpp:404]     Test net output #1: loss = 2.39129 (* 1 = 2.39129 loss)
I0419 10:32:15.674741 10752 solver.cpp:228] Iteration 54528000, loss = 2.35081
I0419 10:32:15.674759 10752 solver.cpp:244]     Train net output #0: loss = 2.01466e-05 (* 1 = 2.01466e-05 loss)
I0419 10:32:15.674768 10752 sgd_solver.cpp:106] Iteration 54528000, lr = 3.9063e-07
I0419 10:37:21.949110 10752 solver.cpp:228] Iteration 54579200, loss = 2.38898
I0419 10:37:21.949172 10752 solver.cpp:244]     Train net output #0: loss = 4.45281 (* 1 = 4.45281 loss)
I0419 10:37:21.949178 10752 sgd_solver.cpp:106] Iteration 54579200, lr = 3.9063e-07
I0419 10:42:28.187760 10752 solver.cpp:228] Iteration 54630400, loss = 2.36018
I0419 10:42:28.187819 10752 solver.cpp:244]     Train net output #0: loss = 0.162564 (* 1 = 0.162564 loss)
I0419 10:42:28.187827 10752 sgd_solver.cpp:106] Iteration 54630400, lr = 3.9063e-07
I0419 10:47:34.313249 10752 solver.cpp:228] Iteration 54681600, loss = 2.37361
I0419 10:47:34.313321 10752 solver.cpp:244]     Train net output #0: loss = 2.10023 (* 1 = 2.10023 loss)
I0419 10:47:34.313326 10752 sgd_solver.cpp:106] Iteration 54681600, lr = 3.9063e-07
I0419 10:52:40.505782 10752 solver.cpp:228] Iteration 54732800, loss = 2.3496
I0419 10:52:40.505851 10752 solver.cpp:244]     Train net output #0: loss = 0.00992083 (* 1 = 0.00992083 loss)
I0419 10:52:40.505862 10752 sgd_solver.cpp:106] Iteration 54732800, lr = 3.9063e-07
I0419 10:57:46.625536 10752 solver.cpp:337] Iteration 54784000, Testing net (#0)
I0419 10:57:46.673576 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0419 10:58:13.114318 10752 solver.cpp:404]     Test net output #0: accuracy = 0.46782
I0419 10:58:13.114351 10752 solver.cpp:404]     Test net output #1: loss = 2.38606 (* 1 = 2.38606 loss)
I0419 10:58:13.116888 10752 solver.cpp:228] Iteration 54784000, loss = 2.35629
I0419 10:58:13.116904 10752 solver.cpp:244]     Train net output #0: loss = 6.05135 (* 1 = 6.05135 loss)
I0419 10:58:13.116915 10752 sgd_solver.cpp:106] Iteration 54784000, lr = 3.9063e-07
I0419 11:03:19.466482 10752 solver.cpp:228] Iteration 54835200, loss = 2.34308
I0419 11:03:19.466565 10752 solver.cpp:244]     Train net output #0: loss = 1.44095 (* 1 = 1.44095 loss)
I0419 11:03:19.466573 10752 sgd_solver.cpp:106] Iteration 54835200, lr = 3.9063e-07
I0419 11:08:25.788179 10752 solver.cpp:228] Iteration 54886400, loss = 2.37197
I0419 11:08:25.788252 10752 solver.cpp:244]     Train net output #0: loss = 2.62365 (* 1 = 2.62365 loss)
I0419 11:08:25.788257 10752 sgd_solver.cpp:106] Iteration 54886400, lr = 3.9063e-07
I0419 11:13:32.045873 10752 solver.cpp:228] Iteration 54937600, loss = 2.34048
I0419 11:13:32.045948 10752 solver.cpp:244]     Train net output #0: loss = 0.00823421 (* 1 = 0.00823421 loss)
I0419 11:13:32.045954 10752 sgd_solver.cpp:106] Iteration 54937600, lr = 3.9063e-07
I0419 11:18:38.323343 10752 solver.cpp:228] Iteration 54988800, loss = 2.33682
I0419 11:18:38.323400 10752 solver.cpp:244]     Train net output #0: loss = 2.72871 (* 1 = 2.72871 loss)
I0419 11:18:38.323405 10752 sgd_solver.cpp:106] Iteration 54988800, lr = 3.9063e-07
I0419 11:23:44.570922 10752 solver.cpp:337] Iteration 55040000, Testing net (#0)
I0419 11:23:44.663288 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0419 11:24:11.036541 10752 solver.cpp:404]     Test net output #0: accuracy = 0.46802
I0419 11:24:11.036573 10752 solver.cpp:404]     Test net output #1: loss = 2.384 (* 1 = 2.384 loss)
I0419 11:24:11.039101 10752 solver.cpp:228] Iteration 55040000, loss = 2.32492
I0419 11:24:11.039119 10752 solver.cpp:244]     Train net output #0: loss = 3.03313 (* 1 = 3.03313 loss)
I0419 11:24:11.039129 10752 sgd_solver.cpp:106] Iteration 55040000, lr = 3.9063e-07
I0419 11:29:17.476052 10752 solver.cpp:228] Iteration 55091200, loss = 2.35868
I0419 11:29:17.476124 10752 solver.cpp:244]     Train net output #0: loss = 0.385142 (* 1 = 0.385142 loss)
I0419 11:29:17.476130 10752 sgd_solver.cpp:106] Iteration 55091200, lr = 3.9063e-07
I0419 11:34:23.766680 10752 solver.cpp:228] Iteration 55142400, loss = 2.37749
I0419 11:34:23.766770 10752 solver.cpp:244]     Train net output #0: loss = 6.2778 (* 1 = 6.2778 loss)
I0419 11:34:23.766777 10752 sgd_solver.cpp:106] Iteration 55142400, lr = 3.9063e-07
I0419 11:39:30.091675 10752 solver.cpp:228] Iteration 55193600, loss = 2.3697
I0419 11:39:30.091747 10752 solver.cpp:244]     Train net output #0: loss = 0.015248 (* 1 = 0.015248 loss)
I0419 11:39:30.091753 10752 sgd_solver.cpp:106] Iteration 55193600, lr = 3.9063e-07
I0419 11:44:36.281312 10752 solver.cpp:228] Iteration 55244800, loss = 2.35812
I0419 11:44:36.281371 10752 solver.cpp:244]     Train net output #0: loss = 3.74588 (* 1 = 3.74588 loss)
I0419 11:44:36.281378 10752 sgd_solver.cpp:106] Iteration 55244800, lr = 3.9063e-07
I0419 11:49:42.461916 10752 solver.cpp:337] Iteration 55296000, Testing net (#0)
I0419 11:49:42.608664 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0419 11:50:09.019625 10752 solver.cpp:404]     Test net output #0: accuracy = 0.468521
I0419 11:50:09.019659 10752 solver.cpp:404]     Test net output #1: loss = 2.38572 (* 1 = 2.38572 loss)
I0419 11:50:09.022174 10752 solver.cpp:228] Iteration 55296000, loss = 2.37889
I0419 11:50:09.022192 10752 solver.cpp:244]     Train net output #0: loss = 0.597939 (* 1 = 0.597939 loss)
I0419 11:50:09.022204 10752 sgd_solver.cpp:106] Iteration 55296000, lr = 3.9063e-07
I0419 11:55:15.395967 10752 solver.cpp:228] Iteration 55347200, loss = 2.38551
I0419 11:55:15.396020 10752 solver.cpp:244]     Train net output #0: loss = 0.498061 (* 1 = 0.498061 loss)
I0419 11:55:15.396026 10752 sgd_solver.cpp:106] Iteration 55347200, lr = 3.9063e-07
I0419 12:00:21.612620 10752 solver.cpp:228] Iteration 55398400, loss = 2.37365
I0419 12:00:21.612689 10752 solver.cpp:244]     Train net output #0: loss = 2.20417 (* 1 = 2.20417 loss)
I0419 12:00:21.612694 10752 sgd_solver.cpp:106] Iteration 55398400, lr = 3.9063e-07
I0419 12:05:27.755533 10752 solver.cpp:228] Iteration 55449600, loss = 2.35692
I0419 12:05:27.755623 10752 solver.cpp:244]     Train net output #0: loss = 1.41045 (* 1 = 1.41045 loss)
I0419 12:05:27.755632 10752 sgd_solver.cpp:106] Iteration 55449600, lr = 3.9063e-07
I0419 12:10:33.922706 10752 solver.cpp:228] Iteration 55500800, loss = 2.37301
I0419 12:10:33.922797 10752 solver.cpp:244]     Train net output #0: loss = 3.35413 (* 1 = 3.35413 loss)
I0419 12:10:33.922808 10752 sgd_solver.cpp:106] Iteration 55500800, lr = 3.9063e-07
I0419 12:15:40.040498 10752 solver.cpp:337] Iteration 55552000, Testing net (#0)
I0419 12:15:40.243870 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0419 12:16:06.498008 10752 solver.cpp:404]     Test net output #0: accuracy = 0.46806
I0419 12:16:06.498044 10752 solver.cpp:404]     Test net output #1: loss = 2.38594 (* 1 = 2.38594 loss)
I0419 12:16:06.500548 10752 solver.cpp:228] Iteration 55552000, loss = 2.3411
I0419 12:16:06.500566 10752 solver.cpp:244]     Train net output #0: loss = 0.0825761 (* 1 = 0.0825761 loss)
I0419 12:16:06.500574 10752 sgd_solver.cpp:106] Iteration 55552000, lr = 3.9063e-07
I0419 12:21:12.865969 10752 solver.cpp:228] Iteration 55603200, loss = 2.35399
I0419 12:21:12.866022 10752 solver.cpp:244]     Train net output #0: loss = 0.281148 (* 1 = 0.281148 loss)
I0419 12:21:12.866030 10752 sgd_solver.cpp:106] Iteration 55603200, lr = 3.9063e-07
I0419 12:26:19.094264 10752 solver.cpp:228] Iteration 55654400, loss = 2.34794
I0419 12:26:19.094327 10752 solver.cpp:244]     Train net output #0: loss = 1.25906 (* 1 = 1.25906 loss)
I0419 12:26:19.094336 10752 sgd_solver.cpp:106] Iteration 55654400, lr = 3.9063e-07
I0419 12:31:25.414211 10752 solver.cpp:228] Iteration 55705600, loss = 2.34859
I0419 12:31:25.414283 10752 solver.cpp:244]     Train net output #0: loss = 0.801284 (* 1 = 0.801284 loss)
I0419 12:31:25.414290 10752 sgd_solver.cpp:106] Iteration 55705600, lr = 3.9063e-07
I0419 12:36:31.598655 10752 solver.cpp:228] Iteration 55756800, loss = 2.32719
I0419 12:36:31.598713 10752 solver.cpp:244]     Train net output #0: loss = 4.00459 (* 1 = 4.00459 loss)
I0419 12:36:31.598719 10752 sgd_solver.cpp:106] Iteration 55756800, lr = 3.9063e-07
I0419 12:41:37.679915 10752 solver.cpp:337] Iteration 55808000, Testing net (#0)
I0419 12:41:37.931977 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0419 12:42:04.141609 10752 solver.cpp:404]     Test net output #0: accuracy = 0.466801
I0419 12:42:04.141644 10752 solver.cpp:404]     Test net output #1: loss = 2.3874 (* 1 = 2.3874 loss)
I0419 12:42:04.144595 10752 solver.cpp:228] Iteration 55808000, loss = 2.35291
I0419 12:42:04.144619 10752 solver.cpp:244]     Train net output #0: loss = 4.17756 (* 1 = 4.17756 loss)
I0419 12:42:04.144629 10752 sgd_solver.cpp:106] Iteration 55808000, lr = 3.9063e-07
I0419 12:47:10.401170 10752 solver.cpp:228] Iteration 55859200, loss = 2.39493
I0419 12:47:10.401237 10752 solver.cpp:244]     Train net output #0: loss = 0.996889 (* 1 = 0.996889 loss)
I0419 12:47:10.401247 10752 sgd_solver.cpp:106] Iteration 55859200, lr = 3.9063e-07
I0419 12:52:16.446959 10752 solver.cpp:228] Iteration 55910400, loss = 2.35925
I0419 12:52:16.447038 10752 solver.cpp:244]     Train net output #0: loss = 2.36914 (* 1 = 2.36914 loss)
I0419 12:52:16.447052 10752 sgd_solver.cpp:106] Iteration 55910400, lr = 3.9063e-07
I0419 12:57:22.510962 10752 solver.cpp:228] Iteration 55961600, loss = 2.37354
I0419 12:57:22.511026 10752 solver.cpp:244]     Train net output #0: loss = 0.387948 (* 1 = 0.387948 loss)
I0419 12:57:22.511039 10752 sgd_solver.cpp:106] Iteration 55961600, lr = 3.9063e-07
I0419 13:02:28.685551 10752 solver.cpp:228] Iteration 56012800, loss = 2.35217
I0419 13:02:28.685614 10752 solver.cpp:244]     Train net output #0: loss = 2.04348 (* 1 = 2.04348 loss)
I0419 13:02:28.685624 10752 sgd_solver.cpp:106] Iteration 56012800, lr = 3.9063e-07
I0419 13:07:34.917033 10752 solver.cpp:337] Iteration 56064000, Testing net (#0)
I0419 13:07:35.223026 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0419 13:08:01.373394 10752 solver.cpp:404]     Test net output #0: accuracy = 0.4684
I0419 13:08:01.373426 10752 solver.cpp:404]     Test net output #1: loss = 2.38489 (* 1 = 2.38489 loss)
I0419 13:08:01.375917 10752 solver.cpp:228] Iteration 56064000, loss = 2.34775
I0419 13:08:01.375933 10752 solver.cpp:244]     Train net output #0: loss = 0.0945558 (* 1 = 0.0945558 loss)
I0419 13:08:01.375941 10752 sgd_solver.cpp:106] Iteration 56064000, lr = 3.9063e-07
I0419 13:13:07.667376 10752 solver.cpp:228] Iteration 56115200, loss = 2.35376
I0419 13:13:07.667462 10752 solver.cpp:244]     Train net output #0: loss = 4.32466 (* 1 = 4.32466 loss)
I0419 13:13:07.667469 10752 sgd_solver.cpp:106] Iteration 56115200, lr = 3.9063e-07
I0419 13:18:13.828470 10752 solver.cpp:228] Iteration 56166400, loss = 2.37513
I0419 13:18:13.828529 10752 solver.cpp:244]     Train net output #0: loss = 2.57061 (* 1 = 2.57061 loss)
I0419 13:18:13.828534 10752 sgd_solver.cpp:106] Iteration 56166400, lr = 3.9063e-07
I0419 13:23:19.936688 10752 solver.cpp:228] Iteration 56217600, loss = 2.34511
I0419 13:23:19.936759 10752 solver.cpp:244]     Train net output #0: loss = 2.18055 (* 1 = 2.18055 loss)
I0419 13:23:19.936764 10752 sgd_solver.cpp:106] Iteration 56217600, lr = 3.9063e-07
I0419 13:28:26.170886 10752 solver.cpp:228] Iteration 56268800, loss = 2.33787
I0419 13:28:26.170958 10752 solver.cpp:244]     Train net output #0: loss = 5.01756 (* 1 = 5.01756 loss)
I0419 13:28:26.170965 10752 sgd_solver.cpp:106] Iteration 56268800, lr = 3.9063e-07
I0419 13:33:32.474140 10752 solver.cpp:454] Snapshotting to binary proto file snapshots/caffenet128_no_lrn_lsuv_relu_bs1_iter_56320000.caffemodel
I0419 13:33:32.666215 10752 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/caffenet128_no_lrn_lsuv_relu_bs1_iter_56320000.solverstate
I0419 13:33:32.725338 10752 solver.cpp:337] Iteration 56320000, Testing net (#0)
I0419 13:33:33.080718 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0419 13:33:59.189411 10752 solver.cpp:404]     Test net output #0: accuracy = 0.46864
I0419 13:33:59.189445 10752 solver.cpp:404]     Test net output #1: loss = 2.38141 (* 1 = 2.38141 loss)
I0419 13:33:59.191978 10752 solver.cpp:228] Iteration 56320000, loss = 2.33514
I0419 13:33:59.191997 10752 solver.cpp:244]     Train net output #0: loss = 0.520059 (* 1 = 0.520059 loss)
I0419 13:33:59.192003 10752 sgd_solver.cpp:106] Iteration 56320000, lr = 3.9063e-07
I0419 13:39:05.421411 10752 solver.cpp:228] Iteration 56371200, loss = 2.35189
I0419 13:39:05.421478 10752 solver.cpp:244]     Train net output #0: loss = 0.06949 (* 1 = 0.06949 loss)
I0419 13:39:05.421485 10752 sgd_solver.cpp:106] Iteration 56371200, lr = 3.9063e-07
I0419 13:44:11.436785 10752 solver.cpp:228] Iteration 56422400, loss = 2.37054
I0419 13:44:11.436856 10752 solver.cpp:244]     Train net output #0: loss = 3.31638 (* 1 = 3.31638 loss)
I0419 13:44:11.436861 10752 sgd_solver.cpp:106] Iteration 56422400, lr = 3.9063e-07
I0419 13:49:17.417145 10752 solver.cpp:228] Iteration 56473600, loss = 2.3538
I0419 13:49:17.417210 10752 solver.cpp:244]     Train net output #0: loss = 1.97127 (* 1 = 1.97127 loss)
I0419 13:49:17.417219 10752 sgd_solver.cpp:106] Iteration 56473600, lr = 3.9063e-07
I0419 13:54:23.375334 10752 solver.cpp:228] Iteration 56524800, loss = 2.36226
I0419 13:54:23.375406 10752 solver.cpp:244]     Train net output #0: loss = 0.532009 (* 1 = 0.532009 loss)
I0419 13:54:23.375411 10752 sgd_solver.cpp:106] Iteration 56524800, lr = 3.9063e-07
I0419 13:59:29.458528 10752 solver.cpp:337] Iteration 56576000, Testing net (#0)
I0419 13:59:29.874794 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0419 13:59:55.911778 10752 solver.cpp:404]     Test net output #0: accuracy = 0.468801
I0419 13:59:55.911813 10752 solver.cpp:404]     Test net output #1: loss = 2.38237 (* 1 = 2.38237 loss)
I0419 13:59:55.914330 10752 solver.cpp:228] Iteration 56576000, loss = 2.38036
I0419 13:59:55.914348 10752 solver.cpp:244]     Train net output #0: loss = 0.308908 (* 1 = 0.308908 loss)
I0419 13:59:55.914357 10752 sgd_solver.cpp:106] Iteration 56576000, lr = 3.9063e-07
I0419 14:05:02.025873 10752 solver.cpp:228] Iteration 56627200, loss = 2.37907
I0419 14:05:02.025948 10752 solver.cpp:244]     Train net output #0: loss = 0.0383338 (* 1 = 0.0383338 loss)
I0419 14:05:02.025956 10752 sgd_solver.cpp:106] Iteration 56627200, lr = 3.9063e-07
I0419 14:10:08.052526 10752 solver.cpp:228] Iteration 56678400, loss = 2.36781
I0419 14:10:08.052599 10752 solver.cpp:244]     Train net output #0: loss = 0.465782 (* 1 = 0.465782 loss)
I0419 14:10:08.052606 10752 sgd_solver.cpp:106] Iteration 56678400, lr = 3.9063e-07
I0419 14:15:14.185137 10752 solver.cpp:228] Iteration 56729600, loss = 2.35179
I0419 14:15:14.185189 10752 solver.cpp:244]     Train net output #0: loss = 0.830067 (* 1 = 0.830067 loss)
I0419 14:15:14.185194 10752 sgd_solver.cpp:106] Iteration 56729600, lr = 3.9063e-07
I0419 14:20:20.220531 10752 solver.cpp:228] Iteration 56780800, loss = 2.35067
I0419 14:20:20.220592 10752 solver.cpp:244]     Train net output #0: loss = 8.62844 (* 1 = 8.62844 loss)
I0419 14:20:20.220598 10752 sgd_solver.cpp:106] Iteration 56780800, lr = 3.9063e-07
I0419 14:25:26.309662 10752 solver.cpp:337] Iteration 56832000, Testing net (#0)
I0419 14:25:26.774659 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0419 14:25:52.770318 10752 solver.cpp:404]     Test net output #0: accuracy = 0.468521
I0419 14:25:52.770352 10752 solver.cpp:404]     Test net output #1: loss = 2.38245 (* 1 = 2.38245 loss)
I0419 14:25:52.772919 10752 solver.cpp:228] Iteration 56832000, loss = 2.34194
I0419 14:25:52.772936 10752 solver.cpp:244]     Train net output #0: loss = 0.886048 (* 1 = 0.886048 loss)
I0419 14:25:52.772944 10752 sgd_solver.cpp:106] Iteration 56832000, lr = 3.9063e-07
I0419 14:30:58.997987 10752 solver.cpp:228] Iteration 56883200, loss = 2.34793
I0419 14:30:58.998044 10752 solver.cpp:244]     Train net output #0: loss = 4.61088 (* 1 = 4.61088 loss)
I0419 14:30:58.998050 10752 sgd_solver.cpp:106] Iteration 56883200, lr = 3.9063e-07
I0419 14:36:05.027930 10752 solver.cpp:228] Iteration 56934400, loss = 2.35337
I0419 14:36:05.028005 10752 solver.cpp:244]     Train net output #0: loss = 1.2541 (* 1 = 1.2541 loss)
I0419 14:36:05.028014 10752 sgd_solver.cpp:106] Iteration 56934400, lr = 3.9063e-07
I0419 14:41:11.112152 10752 solver.cpp:228] Iteration 56985600, loss = 2.34297
I0419 14:41:11.112217 10752 solver.cpp:244]     Train net output #0: loss = 0.000179009 (* 1 = 0.000179009 loss)
I0419 14:41:11.112231 10752 sgd_solver.cpp:106] Iteration 56985600, lr = 3.9063e-07
I0419 14:46:17.213616 10752 solver.cpp:228] Iteration 57036800, loss = 2.33811
I0419 14:46:17.213690 10752 solver.cpp:244]     Train net output #0: loss = 3.93766 (* 1 = 3.93766 loss)
I0419 14:46:17.213695 10752 sgd_solver.cpp:106] Iteration 57036800, lr = 3.9063e-07
I0419 14:51:23.187221 10752 solver.cpp:337] Iteration 57088000, Testing net (#0)
I0419 14:51:23.703130 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0419 14:51:49.650193 10752 solver.cpp:404]     Test net output #0: accuracy = 0.467641
I0419 14:51:49.650228 10752 solver.cpp:404]     Test net output #1: loss = 2.38315 (* 1 = 2.38315 loss)
I0419 14:51:49.652787 10752 solver.cpp:228] Iteration 57088000, loss = 2.35147
I0419 14:51:49.652806 10752 solver.cpp:244]     Train net output #0: loss = 1.28539 (* 1 = 1.28539 loss)
I0419 14:51:49.652815 10752 sgd_solver.cpp:106] Iteration 57088000, lr = 3.9063e-07
I0419 14:56:55.789782 10752 solver.cpp:228] Iteration 57139200, loss = 2.38523
I0419 14:56:55.789855 10752 solver.cpp:244]     Train net output #0: loss = 0.578215 (* 1 = 0.578215 loss)
I0419 14:56:55.789863 10752 sgd_solver.cpp:106] Iteration 57139200, lr = 3.9063e-07
I0419 15:02:01.779145 10752 solver.cpp:228] Iteration 57190400, loss = 2.35726
I0419 15:02:01.779201 10752 solver.cpp:244]     Train net output #0: loss = 1.89225 (* 1 = 1.89225 loss)
I0419 15:02:01.779209 10752 sgd_solver.cpp:106] Iteration 57190400, lr = 3.9063e-07
I0419 15:07:07.882432 10752 solver.cpp:228] Iteration 57241600, loss = 2.37314
I0419 15:07:07.882505 10752 solver.cpp:244]     Train net output #0: loss = 0.00784504 (* 1 = 0.00784504 loss)
I0419 15:07:07.882518 10752 sgd_solver.cpp:106] Iteration 57241600, lr = 3.9063e-07
I0419 15:12:14.002928 10752 solver.cpp:228] Iteration 57292800, loss = 2.34516
I0419 15:12:14.003032 10752 solver.cpp:244]     Train net output #0: loss = 3.46555 (* 1 = 3.46555 loss)
I0419 15:12:14.003051 10752 sgd_solver.cpp:106] Iteration 57292800, lr = 3.9063e-07
I0419 15:17:20.126134 10752 solver.cpp:337] Iteration 57344000, Testing net (#0)
I0419 15:17:20.692821 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0419 15:17:46.547322 10752 solver.cpp:404]     Test net output #0: accuracy = 0.46914
I0419 15:17:46.547353 10752 solver.cpp:404]     Test net output #1: loss = 2.38447 (* 1 = 2.38447 loss)
I0419 15:17:46.550494 10752 solver.cpp:228] Iteration 57344000, loss = 2.36403
I0419 15:17:46.550521 10752 solver.cpp:244]     Train net output #0: loss = 7.16581 (* 1 = 7.16581 loss)
I0419 15:17:46.550529 10752 sgd_solver.cpp:106] Iteration 57344000, lr = 3.9063e-07
I0419 15:22:52.871181 10752 solver.cpp:228] Iteration 57395200, loss = 2.34443
I0419 15:22:52.871254 10752 solver.cpp:244]     Train net output #0: loss = 4.36311 (* 1 = 4.36311 loss)
I0419 15:22:52.871261 10752 sgd_solver.cpp:106] Iteration 57395200, lr = 3.9063e-07
I0419 15:27:59.019227 10752 solver.cpp:228] Iteration 57446400, loss = 2.36234
I0419 15:27:59.019273 10752 solver.cpp:244]     Train net output #0: loss = 0.319556 (* 1 = 0.319556 loss)
I0419 15:27:59.019278 10752 sgd_solver.cpp:106] Iteration 57446400, lr = 3.9063e-07
I0419 15:33:05.099035 10752 solver.cpp:228] Iteration 57497600, loss = 2.33948
I0419 15:33:05.099097 10752 solver.cpp:244]     Train net output #0: loss = 3.58243 (* 1 = 3.58243 loss)
I0419 15:33:05.099103 10752 sgd_solver.cpp:106] Iteration 57497600, lr = 3.9063e-07
I0419 15:38:11.139706 10752 solver.cpp:228] Iteration 57548800, loss = 2.33428
I0419 15:38:11.139765 10752 solver.cpp:244]     Train net output #0: loss = 1.89464 (* 1 = 1.89464 loss)
I0419 15:38:11.139770 10752 sgd_solver.cpp:106] Iteration 57548800, lr = 3.9063e-07
I0419 15:43:17.212038 10752 solver.cpp:337] Iteration 57600000, Testing net (#0)
I0419 15:43:17.909081 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0419 15:43:43.773932 10752 solver.cpp:404]     Test net output #0: accuracy = 0.46844
I0419 15:43:43.773967 10752 solver.cpp:404]     Test net output #1: loss = 2.38121 (* 1 = 2.38121 loss)
I0419 15:43:43.776504 10752 solver.cpp:228] Iteration 57600000, loss = 2.31148
I0419 15:43:43.776521 10752 solver.cpp:244]     Train net output #0: loss = 5.76597 (* 1 = 5.76597 loss)
I0419 15:43:43.776531 10752 sgd_solver.cpp:106] Iteration 57600000, lr = 3.9063e-07
I0419 15:48:50.149637 10752 solver.cpp:228] Iteration 57651200, loss = 2.3526
I0419 15:48:50.149700 10752 solver.cpp:244]     Train net output #0: loss = 0.371236 (* 1 = 0.371236 loss)
I0419 15:48:50.149713 10752 sgd_solver.cpp:106] Iteration 57651200, lr = 3.9063e-07
I0419 15:53:56.362124 10752 solver.cpp:228] Iteration 57702400, loss = 2.36224
I0419 15:53:56.362185 10752 solver.cpp:244]     Train net output #0: loss = 7.32418 (* 1 = 7.32418 loss)
I0419 15:53:56.362192 10752 sgd_solver.cpp:106] Iteration 57702400, lr = 3.9063e-07
I0419 15:59:02.515668 10752 solver.cpp:228] Iteration 57753600, loss = 2.35108
I0419 15:59:02.515728 10752 solver.cpp:244]     Train net output #0: loss = 4.30182 (* 1 = 4.30182 loss)
I0419 15:59:02.515738 10752 sgd_solver.cpp:106] Iteration 57753600, lr = 3.9063e-07
I0419 16:04:08.818470 10752 solver.cpp:228] Iteration 57804800, loss = 2.36247
I0419 16:04:08.818531 10752 solver.cpp:244]     Train net output #0: loss = 4.591 (* 1 = 4.591 loss)
I0419 16:04:08.818538 10752 sgd_solver.cpp:106] Iteration 57804800, lr = 3.9063e-07
I0419 16:09:15.067374 10752 solver.cpp:337] Iteration 57856000, Testing net (#0)
I0419 16:09:15.740082 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0419 16:09:41.514536 10752 solver.cpp:404]     Test net output #0: accuracy = 0.47054
I0419 16:09:41.514565 10752 solver.cpp:404]     Test net output #1: loss = 2.37962 (* 1 = 2.37962 loss)
I0419 16:09:41.517554 10752 solver.cpp:228] Iteration 57856000, loss = 2.37007
I0419 16:09:41.517580 10752 solver.cpp:244]     Train net output #0: loss = 0.126218 (* 1 = 0.126218 loss)
I0419 16:09:41.517587 10752 sgd_solver.cpp:106] Iteration 57856000, lr = 3.9063e-07
I0419 16:14:47.989807 10752 solver.cpp:228] Iteration 57907200, loss = 2.38184
I0419 16:14:47.989884 10752 solver.cpp:244]     Train net output #0: loss = 4.07261 (* 1 = 4.07261 loss)
I0419 16:14:47.989891 10752 sgd_solver.cpp:106] Iteration 57907200, lr = 3.9063e-07
I0419 16:19:54.339166 10752 solver.cpp:228] Iteration 57958400, loss = 2.36654
I0419 16:19:54.339237 10752 solver.cpp:244]     Train net output #0: loss = 0.201126 (* 1 = 0.201126 loss)
I0419 16:19:54.339243 10752 sgd_solver.cpp:106] Iteration 57958400, lr = 3.9063e-07
I0419 16:25:00.589980 10752 solver.cpp:228] Iteration 58009600, loss = 2.34623
I0419 16:25:00.590039 10752 solver.cpp:244]     Train net output #0: loss = 0.0151757 (* 1 = 0.0151757 loss)
I0419 16:25:00.590045 10752 sgd_solver.cpp:106] Iteration 58009600, lr = 3.9063e-07
I0419 16:30:06.831552 10752 solver.cpp:228] Iteration 58060800, loss = 2.35502
I0419 16:30:06.831611 10752 solver.cpp:244]     Train net output #0: loss = 1.81386 (* 1 = 1.81386 loss)
I0419 16:30:06.831616 10752 sgd_solver.cpp:106] Iteration 58060800, lr = 3.9063e-07
I0419 16:35:13.107131 10752 solver.cpp:337] Iteration 58112000, Testing net (#0)
I0419 16:35:13.832326 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0419 16:35:39.569856 10752 solver.cpp:404]     Test net output #0: accuracy = 0.46958
I0419 16:35:39.569887 10752 solver.cpp:404]     Test net output #1: loss = 2.38061 (* 1 = 2.38061 loss)
I0419 16:35:39.572398 10752 solver.cpp:228] Iteration 58112000, loss = 2.34373
I0419 16:35:39.572415 10752 solver.cpp:244]     Train net output #0: loss = 5.24988 (* 1 = 5.24988 loss)
I0419 16:35:39.572422 10752 sgd_solver.cpp:106] Iteration 58112000, lr = 3.9063e-07
I0419 16:40:45.914407 10752 solver.cpp:228] Iteration 58163200, loss = 2.34221
I0419 16:40:45.914471 10752 solver.cpp:244]     Train net output #0: loss = 0.99543 (* 1 = 0.99543 loss)
I0419 16:40:45.914479 10752 sgd_solver.cpp:106] Iteration 58163200, lr = 3.9063e-07
I0419 16:45:52.224165 10752 solver.cpp:228] Iteration 58214400, loss = 2.3461
I0419 16:45:52.224225 10752 solver.cpp:244]     Train net output #0: loss = 5.14737 (* 1 = 5.14737 loss)
I0419 16:45:52.224231 10752 sgd_solver.cpp:106] Iteration 58214400, lr = 3.9063e-07
I0419 16:50:58.445557 10752 solver.cpp:228] Iteration 58265600, loss = 2.33893
I0419 16:50:58.445631 10752 solver.cpp:244]     Train net output #0: loss = 0.0861972 (* 1 = 0.0861972 loss)
I0419 16:50:58.445638 10752 sgd_solver.cpp:106] Iteration 58265600, lr = 3.9063e-07
I0419 16:56:04.658200 10752 solver.cpp:228] Iteration 58316800, loss = 2.32511
I0419 16:56:04.658270 10752 solver.cpp:244]     Train net output #0: loss = 4.57241 (* 1 = 4.57241 loss)
I0419 16:56:04.658280 10752 sgd_solver.cpp:106] Iteration 58316800, lr = 3.9063e-07
I0419 17:01:10.956750 10752 solver.cpp:337] Iteration 58368000, Testing net (#0)
I0419 17:01:11.736728 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0419 17:01:37.420801 10752 solver.cpp:404]     Test net output #0: accuracy = 0.46888
I0419 17:01:37.420833 10752 solver.cpp:404]     Test net output #1: loss = 2.38148 (* 1 = 2.38148 loss)
I0419 17:01:37.423355 10752 solver.cpp:228] Iteration 58368000, loss = 2.35015
I0419 17:01:37.423372 10752 solver.cpp:244]     Train net output #0: loss = 4.69647 (* 1 = 4.69647 loss)
I0419 17:01:37.423379 10752 sgd_solver.cpp:106] Iteration 58368000, lr = 3.9063e-07
I0419 17:06:43.883785 10752 solver.cpp:228] Iteration 58419200, loss = 2.38247
I0419 17:06:43.883852 10752 solver.cpp:244]     Train net output #0: loss = 5.94274 (* 1 = 5.94274 loss)
I0419 17:06:43.883858 10752 sgd_solver.cpp:106] Iteration 58419200, lr = 3.9063e-07
I0419 17:11:50.234187 10752 solver.cpp:228] Iteration 58470400, loss = 2.35174
I0419 17:11:50.234267 10752 solver.cpp:244]     Train net output #0: loss = 0.0822383 (* 1 = 0.0822383 loss)
I0419 17:11:50.234278 10752 sgd_solver.cpp:106] Iteration 58470400, lr = 3.9063e-07
I0419 17:16:56.416460 10752 solver.cpp:228] Iteration 58521600, loss = 2.36793
I0419 17:16:56.416519 10752 solver.cpp:244]     Train net output #0: loss = 8.39096 (* 1 = 8.39096 loss)
I0419 17:16:56.416525 10752 sgd_solver.cpp:106] Iteration 58521600, lr = 3.9063e-07
I0419 17:22:02.620127 10752 solver.cpp:228] Iteration 58572800, loss = 2.35283
I0419 17:22:02.620198 10752 solver.cpp:244]     Train net output #0: loss = 3.31827 (* 1 = 3.31827 loss)
I0419 17:22:02.620203 10752 sgd_solver.cpp:106] Iteration 58572800, lr = 3.9063e-07
I0419 17:27:08.857744 10752 solver.cpp:337] Iteration 58624000, Testing net (#0)
I0419 17:27:09.695341 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0419 17:27:35.371793 10752 solver.cpp:404]     Test net output #0: accuracy = 0.46936
I0419 17:27:35.371824 10752 solver.cpp:404]     Test net output #1: loss = 2.38064 (* 1 = 2.38064 loss)
I0419 17:27:35.374343 10752 solver.cpp:228] Iteration 58624000, loss = 2.34711
I0419 17:27:35.374358 10752 solver.cpp:244]     Train net output #0: loss = 2.40882 (* 1 = 2.40882 loss)
I0419 17:27:35.374366 10752 sgd_solver.cpp:106] Iteration 58624000, lr = 3.9063e-07
I0419 17:32:41.799746 10752 solver.cpp:228] Iteration 58675200, loss = 2.33243
I0419 17:32:41.799823 10752 solver.cpp:244]     Train net output #0: loss = 0.0580042 (* 1 = 0.0580042 loss)
I0419 17:32:41.799832 10752 sgd_solver.cpp:106] Iteration 58675200, lr = 3.9063e-07
I0419 17:37:47.965144 10752 solver.cpp:228] Iteration 58726400, loss = 2.36432
I0419 17:37:47.965204 10752 solver.cpp:244]     Train net output #0: loss = 2.40529 (* 1 = 2.40529 loss)
I0419 17:37:47.965209 10752 sgd_solver.cpp:106] Iteration 58726400, lr = 3.9063e-07
I0419 17:42:54.271340 10752 solver.cpp:228] Iteration 58777600, loss = 2.33456
I0419 17:42:54.271399 10752 solver.cpp:244]     Train net output #0: loss = 4.90996 (* 1 = 4.90996 loss)
I0419 17:42:54.271404 10752 sgd_solver.cpp:106] Iteration 58777600, lr = 3.9063e-07
I0419 17:48:00.583340 10752 solver.cpp:228] Iteration 58828800, loss = 2.32981
I0419 17:48:00.583410 10752 solver.cpp:244]     Train net output #0: loss = 0.304263 (* 1 = 0.304263 loss)
I0419 17:48:00.583415 10752 sgd_solver.cpp:106] Iteration 58828800, lr = 3.9063e-07
I0419 17:53:06.917376 10752 solver.cpp:454] Snapshotting to binary proto file snapshots/caffenet128_no_lrn_lsuv_relu_bs1_iter_58880000.caffemodel
I0419 17:53:07.120182 10752 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/caffenet128_no_lrn_lsuv_relu_bs1_iter_58880000.solverstate
I0419 17:53:07.180796 10752 solver.cpp:337] Iteration 58880000, Testing net (#0)
I0419 17:53:08.065417 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0419 17:53:33.643889 10752 solver.cpp:404]     Test net output #0: accuracy = 0.4686
I0419 17:53:33.643923 10752 solver.cpp:404]     Test net output #1: loss = 2.38025 (* 1 = 2.38025 loss)
I0419 17:53:33.646603 10752 solver.cpp:228] Iteration 58880000, loss = 2.3261
I0419 17:53:33.646620 10752 solver.cpp:244]     Train net output #0: loss = 1.98803 (* 1 = 1.98803 loss)
I0419 17:53:33.646631 10752 sgd_solver.cpp:106] Iteration 58880000, lr = 3.9063e-07
I0419 17:58:40.026331 10752 solver.cpp:228] Iteration 58931200, loss = 2.3558
I0419 17:58:40.026409 10752 solver.cpp:244]     Train net output #0: loss = 0.0735006 (* 1 = 0.0735006 loss)
I0419 17:58:40.026423 10752 sgd_solver.cpp:106] Iteration 58931200, lr = 3.9063e-07
I0419 18:03:46.372827 10752 solver.cpp:228] Iteration 58982400, loss = 2.35402
I0419 18:03:46.372907 10752 solver.cpp:244]     Train net output #0: loss = 0.341151 (* 1 = 0.341151 loss)
I0419 18:03:46.372920 10752 sgd_solver.cpp:106] Iteration 58982400, lr = 3.9063e-07
I0419 18:08:52.760025 10752 solver.cpp:228] Iteration 59033600, loss = 2.33915
I0419 18:08:52.760082 10752 solver.cpp:244]     Train net output #0: loss = 5.11787 (* 1 = 5.11787 loss)
I0419 18:08:52.760087 10752 sgd_solver.cpp:106] Iteration 59033600, lr = 3.9063e-07
I0419 18:13:58.934671 10752 solver.cpp:228] Iteration 59084800, loss = 2.35484
I0419 18:13:58.934754 10752 solver.cpp:244]     Train net output #0: loss = 0.0189002 (* 1 = 0.0189002 loss)
I0419 18:13:58.934767 10752 sgd_solver.cpp:106] Iteration 59084800, lr = 3.9063e-07
I0419 18:19:04.999258 10752 solver.cpp:337] Iteration 59136000, Testing net (#0)
I0419 18:19:06.034380 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0419 18:19:31.531942 10752 solver.cpp:404]     Test net output #0: accuracy = 0.47006
I0419 18:19:31.531975 10752 solver.cpp:404]     Test net output #1: loss = 2.38055 (* 1 = 2.38055 loss)
I0419 18:19:31.534524 10752 solver.cpp:228] Iteration 59136000, loss = 2.37738
I0419 18:19:31.534543 10752 solver.cpp:244]     Train net output #0: loss = 3.32304 (* 1 = 3.32304 loss)
I0419 18:19:31.534551 10752 sgd_solver.cpp:106] Iteration 59136000, lr = 3.9063e-07
I0419 18:24:37.894796 10752 solver.cpp:228] Iteration 59187200, loss = 2.37527
I0419 18:24:37.894860 10752 solver.cpp:244]     Train net output #0: loss = 1.30353 (* 1 = 1.30353 loss)
I0419 18:24:37.894876 10752 sgd_solver.cpp:106] Iteration 59187200, lr = 3.9063e-07
I0419 18:29:44.137362 10752 solver.cpp:228] Iteration 59238400, loss = 2.36619
I0419 18:29:44.137439 10752 solver.cpp:244]     Train net output #0: loss = 1.53318 (* 1 = 1.53318 loss)
I0419 18:29:44.137444 10752 sgd_solver.cpp:106] Iteration 59238400, lr = 3.9063e-07
I0419 18:34:50.287139 10752 solver.cpp:228] Iteration 59289600, loss = 2.35079
I0419 18:34:50.287201 10752 solver.cpp:244]     Train net output #0: loss = 0.0512791 (* 1 = 0.0512791 loss)
I0419 18:34:50.287209 10752 sgd_solver.cpp:106] Iteration 59289600, lr = 3.9063e-07
I0419 18:39:56.787111 10752 solver.cpp:228] Iteration 59340800, loss = 2.34983
I0419 18:39:56.787189 10752 solver.cpp:244]     Train net output #0: loss = 1.81704 (* 1 = 1.81704 loss)
I0419 18:39:56.787202 10752 sgd_solver.cpp:106] Iteration 59340800, lr = 3.9063e-07
I0419 18:45:03.017974 10752 solver.cpp:337] Iteration 59392000, Testing net (#0)
I0419 18:45:03.986783 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0419 18:45:29.519399 10752 solver.cpp:404]     Test net output #0: accuracy = 0.46902
I0419 18:45:29.519433 10752 solver.cpp:404]     Test net output #1: loss = 2.37927 (* 1 = 2.37927 loss)
I0419 18:45:29.521971 10752 solver.cpp:228] Iteration 59392000, loss = 2.34996
I0419 18:45:29.521988 10752 solver.cpp:244]     Train net output #0: loss = 2.37128 (* 1 = 2.37128 loss)
I0419 18:45:29.521998 10752 sgd_solver.cpp:106] Iteration 59392000, lr = 3.9063e-07
I0419 18:50:35.783437 10752 solver.cpp:228] Iteration 59443200, loss = 2.3488
I0419 18:50:35.783499 10752 solver.cpp:244]     Train net output #0: loss = 2.69157 (* 1 = 2.69157 loss)
I0419 18:50:35.783512 10752 sgd_solver.cpp:106] Iteration 59443200, lr = 3.9063e-07
I0419 18:55:41.966819 10752 solver.cpp:228] Iteration 59494400, loss = 2.34422
I0419 18:55:41.966894 10752 solver.cpp:244]     Train net output #0: loss = 5.32978 (* 1 = 5.32978 loss)
I0419 18:55:41.966904 10752 sgd_solver.cpp:106] Iteration 59494400, lr = 3.9063e-07
I0419 19:00:48.098693 10752 solver.cpp:228] Iteration 59545600, loss = 2.32623
I0419 19:00:48.098767 10752 solver.cpp:244]     Train net output #0: loss = 0.306199 (* 1 = 0.306199 loss)
I0419 19:00:48.098778 10752 sgd_solver.cpp:106] Iteration 59545600, lr = 3.9063e-07
I0419 19:05:54.237145 10752 solver.cpp:228] Iteration 59596800, loss = 2.32048
I0419 19:05:54.237218 10752 solver.cpp:244]     Train net output #0: loss = 6.0457 (* 1 = 6.0457 loss)
I0419 19:05:54.237226 10752 sgd_solver.cpp:106] Iteration 59596800, lr = 3.9063e-07
I0419 19:11:00.381202 10752 solver.cpp:337] Iteration 59648000, Testing net (#0)
I0419 19:11:01.407737 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0419 19:11:26.888864 10752 solver.cpp:404]     Test net output #0: accuracy = 0.46864
I0419 19:11:26.888900 10752 solver.cpp:404]     Test net output #1: loss = 2.38066 (* 1 = 2.38066 loss)
I0419 19:11:26.891458 10752 solver.cpp:228] Iteration 59648000, loss = 2.34976
I0419 19:11:26.891479 10752 solver.cpp:244]     Train net output #0: loss = 2.33796 (* 1 = 2.33796 loss)
I0419 19:11:26.891489 10752 sgd_solver.cpp:106] Iteration 59648000, lr = 3.9063e-07
I0419 19:16:33.108009 10752 solver.cpp:228] Iteration 59699200, loss = 2.37105
I0419 19:16:33.108104 10752 solver.cpp:244]     Train net output #0: loss = 0.0401398 (* 1 = 0.0401398 loss)
I0419 19:16:33.108119 10752 sgd_solver.cpp:106] Iteration 59699200, lr = 3.9063e-07
I0419 19:21:39.141938 10752 solver.cpp:228] Iteration 59750400, loss = 2.35682
I0419 19:21:39.142012 10752 solver.cpp:244]     Train net output #0: loss = 4.8225 (* 1 = 4.8225 loss)
I0419 19:21:39.142019 10752 sgd_solver.cpp:106] Iteration 59750400, lr = 3.9063e-07
I0419 19:26:45.205082 10752 solver.cpp:228] Iteration 59801600, loss = 2.36771
I0419 19:26:45.205144 10752 solver.cpp:244]     Train net output #0: loss = 2.262 (* 1 = 2.262 loss)
I0419 19:26:45.205150 10752 sgd_solver.cpp:106] Iteration 59801600, lr = 3.9063e-07
I0419 19:31:51.350278 10752 solver.cpp:228] Iteration 59852800, loss = 2.34623
I0419 19:31:51.350343 10752 solver.cpp:244]     Train net output #0: loss = 0.932467 (* 1 = 0.932467 loss)
I0419 19:31:51.350353 10752 sgd_solver.cpp:106] Iteration 59852800, lr = 3.9063e-07
I0419 19:36:57.475949 10752 solver.cpp:337] Iteration 59904000, Testing net (#0)
I0419 19:36:58.549949 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0419 19:37:23.921254 10752 solver.cpp:404]     Test net output #0: accuracy = 0.4698
I0419 19:37:23.921289 10752 solver.cpp:404]     Test net output #1: loss = 2.37957 (* 1 = 2.37957 loss)
I0419 19:37:23.923822 10752 solver.cpp:228] Iteration 59904000, loss = 2.33727
I0419 19:37:23.923841 10752 solver.cpp:244]     Train net output #0: loss = 0.917572 (* 1 = 0.917572 loss)
I0419 19:37:23.923851 10752 sgd_solver.cpp:106] Iteration 59904000, lr = 3.9063e-07
I0419 19:42:30.104840 10752 solver.cpp:228] Iteration 59955200, loss = 2.33421
I0419 19:42:30.104897 10752 solver.cpp:244]     Train net output #0: loss = 0.750149 (* 1 = 0.750149 loss)
I0419 19:42:30.104902 10752 sgd_solver.cpp:106] Iteration 59955200, lr = 3.9063e-07
I0419 19:47:36.272775 10752 solver.cpp:228] Iteration 60006400, loss = 2.35736
I0419 19:47:36.272836 10752 solver.cpp:244]     Train net output #0: loss = 0.590002 (* 1 = 0.590002 loss)
I0419 19:47:36.272842 10752 sgd_solver.cpp:106] Iteration 60006400, lr = 3.9063e-07
I0419 19:52:42.291244 10752 solver.cpp:228] Iteration 60057600, loss = 2.33337
I0419 19:52:42.291307 10752 solver.cpp:244]     Train net output #0: loss = 0.497092 (* 1 = 0.497092 loss)
I0419 19:52:42.291314 10752 sgd_solver.cpp:106] Iteration 60057600, lr = 3.9063e-07
I0419 19:57:48.426455 10752 solver.cpp:228] Iteration 60108800, loss = 2.32338
I0419 19:57:48.426518 10752 solver.cpp:244]     Train net output #0: loss = 2.90463 (* 1 = 2.90463 loss)
I0419 19:57:48.426525 10752 sgd_solver.cpp:106] Iteration 60108800, lr = 3.9063e-07
I0419 20:02:54.544258 10752 solver.cpp:337] Iteration 60160000, Testing net (#0)
I0419 20:02:55.675675 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0419 20:03:21.006779 10752 solver.cpp:404]     Test net output #0: accuracy = 0.46892
I0419 20:03:21.006810 10752 solver.cpp:404]     Test net output #1: loss = 2.37663 (* 1 = 2.37663 loss)
I0419 20:03:21.009773 10752 solver.cpp:228] Iteration 60160000, loss = 2.32708
I0419 20:03:21.009799 10752 solver.cpp:244]     Train net output #0: loss = 2.28746 (* 1 = 2.28746 loss)
I0419 20:03:21.009809 10752 sgd_solver.cpp:106] Iteration 60160000, lr = 3.9063e-07
I0419 20:08:27.199265 10752 solver.cpp:228] Iteration 60211200, loss = 2.3451
I0419 20:08:27.199337 10752 solver.cpp:244]     Train net output #0: loss = 2.03185 (* 1 = 2.03185 loss)
I0419 20:08:27.199342 10752 sgd_solver.cpp:106] Iteration 60211200, lr = 3.9063e-07
I0419 20:13:33.296464 10752 solver.cpp:228] Iteration 60262400, loss = 2.35639
I0419 20:13:33.296526 10752 solver.cpp:244]     Train net output #0: loss = 0.400508 (* 1 = 0.400508 loss)
I0419 20:13:33.296531 10752 sgd_solver.cpp:106] Iteration 60262400, lr = 3.9063e-07
I0419 20:18:39.284798 10752 solver.cpp:228] Iteration 60313600, loss = 2.35039
I0419 20:18:39.284896 10752 solver.cpp:244]     Train net output #0: loss = 0.122452 (* 1 = 0.122452 loss)
I0419 20:18:39.284907 10752 sgd_solver.cpp:106] Iteration 60313600, lr = 3.9063e-07
I0419 20:23:45.277549 10752 solver.cpp:228] Iteration 60364800, loss = 2.36146
I0419 20:23:45.277608 10752 solver.cpp:244]     Train net output #0: loss = 0.523204 (* 1 = 0.523204 loss)
I0419 20:23:45.277616 10752 sgd_solver.cpp:106] Iteration 60364800, lr = 3.9063e-07
I0419 20:28:51.255646 10752 solver.cpp:337] Iteration 60416000, Testing net (#0)
I0419 20:28:52.576824 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0419 20:29:18.000079 10752 solver.cpp:404]     Test net output #0: accuracy = 0.46918
I0419 20:29:18.000113 10752 solver.cpp:404]     Test net output #1: loss = 2.378 (* 1 = 2.378 loss)
I0419 20:29:18.002686 10752 solver.cpp:228] Iteration 60416000, loss = 2.3729
I0419 20:29:18.002708 10752 solver.cpp:244]     Train net output #0: loss = 5.97028 (* 1 = 5.97028 loss)
I0419 20:29:18.002720 10752 sgd_solver.cpp:106] Iteration 60416000, lr = 3.9063e-07
I0419 20:34:24.249557 10752 solver.cpp:228] Iteration 60467200, loss = 2.37307
I0419 20:34:24.249619 10752 solver.cpp:244]     Train net output #0: loss = 0.201451 (* 1 = 0.201451 loss)
I0419 20:34:24.249629 10752 sgd_solver.cpp:106] Iteration 60467200, lr = 3.9063e-07
I0419 20:39:30.577726 10752 solver.cpp:228] Iteration 60518400, loss = 2.37126
I0419 20:39:30.577792 10752 solver.cpp:244]     Train net output #0: loss = 9.50683 (* 1 = 9.50683 loss)
I0419 20:39:30.577802 10752 sgd_solver.cpp:106] Iteration 60518400, lr = 3.9063e-07
I0419 20:44:37.700311 10752 solver.cpp:228] Iteration 60569600, loss = 2.34477
I0419 20:44:37.700384 10752 solver.cpp:244]     Train net output #0: loss = 5.3382 (* 1 = 5.3382 loss)
I0419 20:44:37.700392 10752 sgd_solver.cpp:106] Iteration 60569600, lr = 3.9063e-07
I0419 20:49:44.262780 10752 solver.cpp:228] Iteration 60620800, loss = 2.34785
I0419 20:49:44.262841 10752 solver.cpp:244]     Train net output #0: loss = 1.53488 (* 1 = 1.53488 loss)
I0419 20:49:44.262848 10752 sgd_solver.cpp:106] Iteration 60620800, lr = 3.9063e-07
I0419 20:54:50.866291 10752 solver.cpp:337] Iteration 60672000, Testing net (#0)
I0419 20:54:52.097338 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0419 20:55:17.380970 10752 solver.cpp:404]     Test net output #0: accuracy = 0.46938
I0419 20:55:17.381003 10752 solver.cpp:404]     Test net output #1: loss = 2.37754 (* 1 = 2.37754 loss)
I0419 20:55:17.383553 10752 solver.cpp:228] Iteration 60672000, loss = 2.33213
I0419 20:55:17.383571 10752 solver.cpp:244]     Train net output #0: loss = 0.260504 (* 1 = 0.260504 loss)
I0419 20:55:17.383582 10752 sgd_solver.cpp:106] Iteration 60672000, lr = 3.9063e-07
I0419 21:00:24.100283 10752 solver.cpp:228] Iteration 60723200, loss = 2.33482
I0419 21:00:24.100356 10752 solver.cpp:244]     Train net output #0: loss = 1.22898 (* 1 = 1.22898 loss)
I0419 21:00:24.100366 10752 sgd_solver.cpp:106] Iteration 60723200, lr = 3.9063e-07
I0419 21:05:30.741705 10752 solver.cpp:228] Iteration 60774400, loss = 2.33729
I0419 21:05:30.741767 10752 solver.cpp:244]     Train net output #0: loss = 1.06729 (* 1 = 1.06729 loss)
I0419 21:05:30.741776 10752 sgd_solver.cpp:106] Iteration 60774400, lr = 3.9063e-07
I0419 21:10:37.351805 10752 solver.cpp:228] Iteration 60825600, loss = 2.33428
I0419 21:10:37.351879 10752 solver.cpp:244]     Train net output #0: loss = 3.44305 (* 1 = 3.44305 loss)
I0419 21:10:37.351887 10752 sgd_solver.cpp:106] Iteration 60825600, lr = 3.9063e-07
I0419 21:15:44.014408 10752 solver.cpp:228] Iteration 60876800, loss = 2.32411
I0419 21:15:44.014482 10752 solver.cpp:244]     Train net output #0: loss = 4.00532 (* 1 = 4.00532 loss)
I0419 21:15:44.014497 10752 sgd_solver.cpp:106] Iteration 60876800, lr = 3.9063e-07
I0419 21:20:50.110344 10752 solver.cpp:337] Iteration 60928000, Testing net (#0)
I0419 21:20:51.373349 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0419 21:21:16.569561 10752 solver.cpp:404]     Test net output #0: accuracy = 0.46996
I0419 21:21:16.569594 10752 solver.cpp:404]     Test net output #1: loss = 2.37673 (* 1 = 2.37673 loss)
I0419 21:21:16.572091 10752 solver.cpp:228] Iteration 60928000, loss = 2.34598
I0419 21:21:16.572108 10752 solver.cpp:244]     Train net output #0: loss = 1.07892 (* 1 = 1.07892 loss)
I0419 21:21:16.572118 10752 sgd_solver.cpp:106] Iteration 60928000, lr = 3.9063e-07
I0419 21:26:23.059538 10752 solver.cpp:228] Iteration 60979200, loss = 2.37302
I0419 21:26:23.059612 10752 solver.cpp:244]     Train net output #0: loss = 3.49053 (* 1 = 3.49053 loss)
I0419 21:26:23.059618 10752 sgd_solver.cpp:106] Iteration 60979200, lr = 3.9063e-07
I0419 21:31:29.476141 10752 solver.cpp:228] Iteration 61030400, loss = 2.35323
I0419 21:31:29.476235 10752 solver.cpp:244]     Train net output #0: loss = 0.0382834 (* 1 = 0.0382834 loss)
I0419 21:31:29.476249 10752 sgd_solver.cpp:106] Iteration 61030400, lr = 3.9063e-07
I0419 21:36:35.823230 10752 solver.cpp:228] Iteration 61081600, loss = 2.36024
I0419 21:36:35.823289 10752 solver.cpp:244]     Train net output #0: loss = 5.87981 (* 1 = 5.87981 loss)
I0419 21:36:35.823295 10752 sgd_solver.cpp:106] Iteration 61081600, lr = 3.9063e-07
I0419 21:41:47.359503 10752 solver.cpp:228] Iteration 61132800, loss = 2.34979
I0419 21:41:47.359570 10752 solver.cpp:244]     Train net output #0: loss = 2.90602 (* 1 = 2.90602 loss)
I0419 21:41:47.359577 10752 sgd_solver.cpp:106] Iteration 61132800, lr = 3.9063e-07
I0419 21:46:59.199244 10752 solver.cpp:337] Iteration 61184000, Testing net (#0)
I0419 21:47:00.217871 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0419 21:47:27.460253 10752 solver.cpp:404]     Test net output #0: accuracy = 0.47012
I0419 21:47:27.460280 10752 solver.cpp:404]     Test net output #1: loss = 2.37875 (* 1 = 2.37875 loss)
I0419 21:47:27.462816 10752 solver.cpp:228] Iteration 61184000, loss = 2.34082
I0419 21:47:27.462832 10752 solver.cpp:244]     Train net output #0: loss = 0.373549 (* 1 = 0.373549 loss)
I0419 21:47:27.462838 10752 sgd_solver.cpp:106] Iteration 61184000, lr = 3.9063e-07
I0419 21:52:36.740259 10752 solver.cpp:228] Iteration 61235200, loss = 2.32405
I0419 21:52:36.740324 10752 solver.cpp:244]     Train net output #0: loss = 5.05631 (* 1 = 5.05631 loss)
I0419 21:52:36.740331 10752 sgd_solver.cpp:106] Iteration 61235200, lr = 3.9063e-07
I0419 21:57:43.783699 10752 solver.cpp:228] Iteration 61286400, loss = 2.35658
I0419 21:57:43.783771 10752 solver.cpp:244]     Train net output #0: loss = 0.000975966 (* 1 = 0.000975966 loss)
I0419 21:57:43.783776 10752 sgd_solver.cpp:106] Iteration 61286400, lr = 3.9063e-07
I0419 22:02:51.728699 10752 solver.cpp:228] Iteration 61337600, loss = 2.33389
I0419 22:02:51.728775 10752 solver.cpp:244]     Train net output #0: loss = 1.34162 (* 1 = 1.34162 loss)
I0419 22:02:51.728786 10752 sgd_solver.cpp:106] Iteration 61337600, lr = 3.9063e-07
I0419 22:08:05.379972 10752 solver.cpp:228] Iteration 61388800, loss = 2.32327
I0419 22:08:05.380034 10752 solver.cpp:244]     Train net output #0: loss = 1.4603 (* 1 = 1.4603 loss)
I0419 22:08:05.380043 10752 sgd_solver.cpp:106] Iteration 61388800, lr = 3.9063e-07
I0419 22:13:11.646005 10752 solver.cpp:454] Snapshotting to binary proto file snapshots/caffenet128_no_lrn_lsuv_relu_bs1_iter_61440000.caffemodel
I0419 22:13:11.899718 10752 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/caffenet128_no_lrn_lsuv_relu_bs1_iter_61440000.solverstate
I0419 22:13:11.961805 10752 solver.cpp:337] Iteration 61440000, Testing net (#0)
I0419 22:13:12.656043 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0419 22:13:39.112390 10752 solver.cpp:404]     Test net output #0: accuracy = 0.46942
I0419 22:13:39.112421 10752 solver.cpp:404]     Test net output #1: loss = 2.37766 (* 1 = 2.37766 loss)
I0419 22:13:39.114958 10752 solver.cpp:228] Iteration 61440000, loss = 2.32996
I0419 22:13:39.114979 10752 solver.cpp:244]     Train net output #0: loss = 0.00935825 (* 1 = 0.00935825 loss)
I0419 22:13:39.114990 10752 sgd_solver.cpp:106] Iteration 61440000, lr = 3.9063e-07
I0419 22:18:46.467234 10752 solver.cpp:228] Iteration 61491200, loss = 2.34838
I0419 22:18:46.467314 10752 solver.cpp:244]     Train net output #0: loss = 0.78321 (* 1 = 0.78321 loss)
I0419 22:18:46.467322 10752 sgd_solver.cpp:106] Iteration 61491200, lr = 3.9063e-07
I0419 22:23:53.935796 10752 solver.cpp:228] Iteration 61542400, loss = 2.35248
I0419 22:23:53.935869 10752 solver.cpp:244]     Train net output #0: loss = 0.204805 (* 1 = 0.204805 loss)
I0419 22:23:53.935879 10752 sgd_solver.cpp:106] Iteration 61542400, lr = 3.9063e-07
I0419 22:29:01.473105 10752 solver.cpp:228] Iteration 61593600, loss = 2.35098
I0419 22:29:01.473176 10752 solver.cpp:244]     Train net output #0: loss = 5.74207 (* 1 = 5.74207 loss)
I0419 22:29:01.473182 10752 sgd_solver.cpp:106] Iteration 61593600, lr = 3.9063e-07
I0419 22:34:09.211513 10752 solver.cpp:228] Iteration 61644800, loss = 2.34754
I0419 22:34:09.211573 10752 solver.cpp:244]     Train net output #0: loss = 4.07601 (* 1 = 4.07601 loss)
I0419 22:34:09.211580 10752 sgd_solver.cpp:106] Iteration 61644800, lr = 3.9063e-07
I0419 22:39:16.503151 10752 solver.cpp:337] Iteration 61696000, Testing net (#0)
I0419 22:39:17.155298 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0419 22:39:43.068114 10752 solver.cpp:404]     Test net output #0: accuracy = 0.46946
I0419 22:39:43.068145 10752 solver.cpp:404]     Test net output #1: loss = 2.37669 (* 1 = 2.37669 loss)
I0419 22:39:43.070721 10752 solver.cpp:228] Iteration 61696000, loss = 2.36643
I0419 22:39:43.070742 10752 solver.cpp:244]     Train net output #0: loss = 0.380689 (* 1 = 0.380689 loss)
I0419 22:39:43.070752 10752 sgd_solver.cpp:106] Iteration 61696000, lr = 3.9063e-07
I0419 22:44:50.638520 10752 solver.cpp:228] Iteration 61747200, loss = 2.36838
I0419 22:44:50.638578 10752 solver.cpp:244]     Train net output #0: loss = 2.82817 (* 1 = 2.82817 loss)
I0419 22:44:50.638584 10752 sgd_solver.cpp:106] Iteration 61747200, lr = 3.9063e-07
I0419 22:49:58.139868 10752 solver.cpp:228] Iteration 61798400, loss = 2.37122
I0419 22:49:58.139930 10752 solver.cpp:244]     Train net output #0: loss = 3.79398 (* 1 = 3.79398 loss)
I0419 22:49:58.139936 10752 sgd_solver.cpp:106] Iteration 61798400, lr = 3.9063e-07
I0419 22:55:06.587985 10752 solver.cpp:228] Iteration 61849600, loss = 2.3364
I0419 22:55:06.588052 10752 solver.cpp:244]     Train net output #0: loss = 0.0715292 (* 1 = 0.0715292 loss)
I0419 22:55:06.588059 10752 sgd_solver.cpp:106] Iteration 61849600, lr = 3.9063e-07
I0419 23:00:15.673606 10752 solver.cpp:228] Iteration 61900800, loss = 2.34918
I0419 23:00:15.673666 10752 solver.cpp:244]     Train net output #0: loss = 0.000752434 (* 1 = 0.000752434 loss)
I0419 23:00:15.673679 10752 sgd_solver.cpp:106] Iteration 61900800, lr = 3.9063e-07
I0419 23:05:23.241885 10752 solver.cpp:337] Iteration 61952000, Testing net (#0)
I0419 23:05:23.602383 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0419 23:05:49.726917 10752 solver.cpp:404]     Test net output #0: accuracy = 0.47036
I0419 23:05:49.726950 10752 solver.cpp:404]     Test net output #1: loss = 2.37668 (* 1 = 2.37668 loss)
I0419 23:05:49.729497 10752 solver.cpp:228] Iteration 61952000, loss = 2.33865
I0419 23:05:49.729516 10752 solver.cpp:244]     Train net output #0: loss = 0.107366 (* 1 = 0.107366 loss)
I0419 23:05:49.729526 10752 sgd_solver.cpp:106] Iteration 61952000, lr = 3.9063e-07
I0419 23:10:56.580615 10752 solver.cpp:228] Iteration 62003200, loss = 2.3344
I0419 23:10:56.580680 10752 solver.cpp:244]     Train net output #0: loss = 0.0585487 (* 1 = 0.0585487 loss)
I0419 23:10:56.580690 10752 sgd_solver.cpp:106] Iteration 62003200, lr = 3.9063e-07
I0419 23:16:08.189533 10752 solver.cpp:228] Iteration 62054400, loss = 2.33865
I0419 23:16:08.189592 10752 solver.cpp:244]     Train net output #0: loss = 1.3323 (* 1 = 1.3323 loss)
I0419 23:16:08.189610 10752 sgd_solver.cpp:106] Iteration 62054400, lr = 3.9063e-07
I0419 23:21:17.501085 10752 solver.cpp:228] Iteration 62105600, loss = 2.33917
I0419 23:21:17.501179 10752 solver.cpp:244]     Train net output #0: loss = 0.0188911 (* 1 = 0.0188911 loss)
I0419 23:21:17.501188 10752 sgd_solver.cpp:106] Iteration 62105600, lr = 3.9063e-07
I0419 23:26:24.044417 10752 solver.cpp:228] Iteration 62156800, loss = 2.31603
I0419 23:26:24.044481 10752 solver.cpp:244]     Train net output #0: loss = 1.97841 (* 1 = 1.97841 loss)
I0419 23:26:24.044488 10752 sgd_solver.cpp:106] Iteration 62156800, lr = 3.9063e-07
I0419 23:31:33.702585 10752 solver.cpp:337] Iteration 62208000, Testing net (#0)
I0419 23:31:33.797837 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0419 23:32:02.362498 10752 solver.cpp:404]     Test net output #0: accuracy = 0.47018
I0419 23:32:02.362534 10752 solver.cpp:404]     Test net output #1: loss = 2.37542 (* 1 = 2.37542 loss)
I0419 23:32:02.365087 10752 solver.cpp:228] Iteration 62208000, loss = 2.33962
I0419 23:32:02.365106 10752 solver.cpp:244]     Train net output #0: loss = 3.3439 (* 1 = 3.3439 loss)
I0419 23:32:02.365118 10752 sgd_solver.cpp:106] Iteration 62208000, lr = 3.9063e-07
I0419 23:37:11.414474 10752 solver.cpp:228] Iteration 62259200, loss = 2.35614
I0419 23:37:11.414546 10752 solver.cpp:244]     Train net output #0: loss = 1.08521 (* 1 = 1.08521 loss)
I0419 23:37:11.414553 10752 sgd_solver.cpp:106] Iteration 62259200, lr = 3.9063e-07
I0419 23:42:18.024760 10752 solver.cpp:228] Iteration 62310400, loss = 2.33811
I0419 23:42:18.024834 10752 solver.cpp:244]     Train net output #0: loss = 0.99447 (* 1 = 0.99447 loss)
I0419 23:42:18.024840 10752 sgd_solver.cpp:106] Iteration 62310400, lr = 3.9063e-07
I0419 23:47:24.845767 10752 solver.cpp:228] Iteration 62361600, loss = 2.36227
I0419 23:47:24.845839 10752 solver.cpp:244]     Train net output #0: loss = 0.612207 (* 1 = 0.612207 loss)
I0419 23:47:24.845845 10752 sgd_solver.cpp:106] Iteration 62361600, lr = 3.9063e-07
I0419 23:52:31.648645 10752 solver.cpp:228] Iteration 62412800, loss = 2.35485
I0419 23:52:31.648711 10752 solver.cpp:244]     Train net output #0: loss = 1.54593 (* 1 = 1.54593 loss)
I0419 23:52:31.648718 10752 sgd_solver.cpp:106] Iteration 62412800, lr = 3.9063e-07
I0419 23:57:38.463460 10752 solver.cpp:337] Iteration 62464000, Testing net (#0)
I0419 23:57:38.556015 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0419 23:58:04.927711 10752 solver.cpp:404]     Test net output #0: accuracy = 0.47086
I0419 23:58:04.927745 10752 solver.cpp:404]     Test net output #1: loss = 2.37627 (* 1 = 2.37627 loss)
I0419 23:58:04.930308 10752 solver.cpp:228] Iteration 62464000, loss = 2.34223
I0419 23:58:04.930330 10752 solver.cpp:244]     Train net output #0: loss = 1.98222 (* 1 = 1.98222 loss)
I0419 23:58:04.930341 10752 sgd_solver.cpp:106] Iteration 62464000, lr = 3.9063e-07
I0420 00:03:11.952508 10752 solver.cpp:228] Iteration 62515200, loss = 2.32727
I0420 00:03:11.952574 10752 solver.cpp:244]     Train net output #0: loss = 0.0248832 (* 1 = 0.0248832 loss)
I0420 00:03:11.952586 10752 sgd_solver.cpp:106] Iteration 62515200, lr = 3.9063e-07
I0420 00:08:18.735349 10752 solver.cpp:228] Iteration 62566400, loss = 2.36221
I0420 00:08:18.735438 10752 solver.cpp:244]     Train net output #0: loss = 4.54505 (* 1 = 4.54505 loss)
I0420 00:08:18.735450 10752 sgd_solver.cpp:106] Iteration 62566400, lr = 3.9063e-07
I0420 00:13:25.513715 10752 solver.cpp:228] Iteration 62617600, loss = 2.33937
I0420 00:13:25.513780 10752 solver.cpp:244]     Train net output #0: loss = 3.33578 (* 1 = 3.33578 loss)
I0420 00:13:25.513792 10752 sgd_solver.cpp:106] Iteration 62617600, lr = 3.9063e-07
I0420 00:18:32.216547 10752 solver.cpp:228] Iteration 62668800, loss = 2.33014
I0420 00:18:32.216611 10752 solver.cpp:244]     Train net output #0: loss = 0.104819 (* 1 = 0.104819 loss)
I0420 00:18:32.216624 10752 sgd_solver.cpp:106] Iteration 62668800, lr = 3.9063e-07
I0420 00:23:41.986459 10752 solver.cpp:337] Iteration 62720000, Testing net (#0)
I0420 00:23:42.088609 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0420 00:24:10.885818 10752 solver.cpp:404]     Test net output #0: accuracy = 0.4693
I0420 00:24:10.885851 10752 solver.cpp:404]     Test net output #1: loss = 2.37651 (* 1 = 2.37651 loss)
I0420 00:24:10.888370 10752 solver.cpp:228] Iteration 62720000, loss = 2.32361
I0420 00:24:10.888391 10752 solver.cpp:244]     Train net output #0: loss = 4.56889 (* 1 = 4.56889 loss)
I0420 00:24:10.888397 10752 sgd_solver.cpp:106] Iteration 62720000, lr = 3.9063e-07
I0420 00:29:23.062263 10752 solver.cpp:228] Iteration 62771200, loss = 2.33591
I0420 00:29:23.062355 10752 solver.cpp:244]     Train net output #0: loss = 0.804281 (* 1 = 0.804281 loss)
I0420 00:29:23.062361 10752 sgd_solver.cpp:106] Iteration 62771200, lr = 3.9063e-07
I0420 00:34:29.493628 10752 solver.cpp:228] Iteration 62822400, loss = 2.35198
I0420 00:34:29.493695 10752 solver.cpp:244]     Train net output #0: loss = 0.376547 (* 1 = 0.376547 loss)
I0420 00:34:29.493700 10752 sgd_solver.cpp:106] Iteration 62822400, lr = 3.9063e-07
I0420 00:39:36.228188 10752 solver.cpp:228] Iteration 62873600, loss = 2.3465
I0420 00:39:36.228250 10752 solver.cpp:244]     Train net output #0: loss = 3.31688 (* 1 = 3.31688 loss)
I0420 00:39:36.228256 10752 sgd_solver.cpp:106] Iteration 62873600, lr = 3.9063e-07
I0420 00:44:42.948957 10752 solver.cpp:228] Iteration 62924800, loss = 2.34702
I0420 00:44:42.949015 10752 solver.cpp:244]     Train net output #0: loss = 0.881434 (* 1 = 0.881434 loss)
I0420 00:44:42.949023 10752 sgd_solver.cpp:106] Iteration 62924800, lr = 3.9063e-07
I0420 00:46:01.513015 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0420 00:49:52.448259 10752 solver.cpp:337] Iteration 62976000, Testing net (#0)
I0420 00:50:19.023504 10752 solver.cpp:404]     Test net output #0: accuracy = 0.47058
I0420 00:50:19.023540 10752 solver.cpp:404]     Test net output #1: loss = 2.3759 (* 1 = 2.3759 loss)
I0420 00:50:19.026113 10752 solver.cpp:228] Iteration 62976000, loss = 2.36444
I0420 00:50:19.026132 10752 solver.cpp:244]     Train net output #0: loss = 0.221894 (* 1 = 0.221894 loss)
I0420 00:50:19.026144 10752 sgd_solver.cpp:106] Iteration 62976000, lr = 3.9063e-07
I0420 00:54:25.654407 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0420 00:55:29.850225 10752 solver.cpp:228] Iteration 63027200, loss = 2.36556
I0420 00:55:29.850288 10752 solver.cpp:244]     Train net output #0: loss = 1.88181 (* 1 = 1.88181 loss)
I0420 00:55:29.850296 10752 sgd_solver.cpp:106] Iteration 63027200, lr = 3.9063e-07
I0420 01:00:38.369735 10752 solver.cpp:228] Iteration 63078400, loss = 2.36403
I0420 01:00:38.369803 10752 solver.cpp:244]     Train net output #0: loss = 4.51578 (* 1 = 4.51578 loss)
I0420 01:00:38.369812 10752 sgd_solver.cpp:106] Iteration 63078400, lr = 3.9063e-07
I0420 01:05:45.161511 10752 solver.cpp:228] Iteration 63129600, loss = 2.34397
I0420 01:05:45.161572 10752 solver.cpp:244]     Train net output #0: loss = 3.55716 (* 1 = 3.55716 loss)
I0420 01:05:45.161578 10752 sgd_solver.cpp:106] Iteration 63129600, lr = 3.9063e-07
I0420 01:10:52.190032 10752 solver.cpp:228] Iteration 63180800, loss = 2.33741
I0420 01:10:52.190104 10752 solver.cpp:244]     Train net output #0: loss = 1.35653 (* 1 = 1.35653 loss)
I0420 01:10:52.190109 10752 sgd_solver.cpp:106] Iteration 63180800, lr = 3.9063e-07
I0420 01:15:59.019712 10752 solver.cpp:337] Iteration 63232000, Testing net (#0)
I0420 01:16:25.526465 10752 solver.cpp:404]     Test net output #0: accuracy = 0.46908
I0420 01:16:25.526496 10752 solver.cpp:404]     Test net output #1: loss = 2.37478 (* 1 = 2.37478 loss)
I0420 01:16:25.529323 10752 solver.cpp:228] Iteration 63232000, loss = 2.33029
I0420 01:16:25.529347 10752 solver.cpp:244]     Train net output #0: loss = 0.137033 (* 1 = 0.137033 loss)
I0420 01:16:25.529357 10752 sgd_solver.cpp:106] Iteration 63232000, lr = 3.9063e-07
I0420 01:16:25.607797 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0420 01:21:32.494669 10752 solver.cpp:228] Iteration 63283200, loss = 2.33437
I0420 01:21:32.494746 10752 solver.cpp:244]     Train net output #0: loss = 0.974328 (* 1 = 0.974328 loss)
I0420 01:21:32.494758 10752 sgd_solver.cpp:106] Iteration 63283200, lr = 3.9063e-07
I0420 01:26:39.688712 10752 solver.cpp:228] Iteration 63334400, loss = 2.33069
I0420 01:26:39.688804 10752 solver.cpp:244]     Train net output #0: loss = 0.771329 (* 1 = 0.771329 loss)
I0420 01:26:39.688818 10752 sgd_solver.cpp:106] Iteration 63334400, lr = 3.9063e-07
I0420 01:31:49.335093 10752 solver.cpp:228] Iteration 63385600, loss = 2.33675
I0420 01:31:49.335166 10752 solver.cpp:244]     Train net output #0: loss = 0.789913 (* 1 = 0.789913 loss)
I0420 01:31:49.335173 10752 sgd_solver.cpp:106] Iteration 63385600, lr = 3.9063e-07
I0420 01:36:56.330111 10752 solver.cpp:228] Iteration 63436800, loss = 2.32491
I0420 01:36:56.330170 10752 solver.cpp:244]     Train net output #0: loss = 3.46201 (* 1 = 3.46201 loss)
I0420 01:36:56.330176 10752 sgd_solver.cpp:106] Iteration 63436800, lr = 3.9063e-07
I0420 01:42:02.683018 10752 solver.cpp:337] Iteration 63488000, Testing net (#0)
I0420 01:42:29.612169 10752 solver.cpp:404]     Test net output #0: accuracy = 0.47014
I0420 01:42:29.612236 10752 solver.cpp:404]     Test net output #1: loss = 2.37563 (* 1 = 2.37563 loss)
I0420 01:42:29.615883 10752 solver.cpp:228] Iteration 63488000, loss = 2.34686
I0420 01:42:29.615911 10752 solver.cpp:244]     Train net output #0: loss = 0.574685 (* 1 = 0.574685 loss)
I0420 01:42:29.615921 10752 sgd_solver.cpp:106] Iteration 63488000, lr = 3.9063e-07
I0420 01:42:29.693543 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0420 01:47:36.244806 10752 solver.cpp:228] Iteration 63539200, loss = 2.3644
I0420 01:47:36.244875 10752 solver.cpp:244]     Train net output #0: loss = 0.317751 (* 1 = 0.317751 loss)
I0420 01:47:36.244881 10752 sgd_solver.cpp:106] Iteration 63539200, lr = 3.9063e-07
I0420 01:52:42.884472 10752 solver.cpp:228] Iteration 63590400, loss = 2.34153
I0420 01:52:42.884534 10752 solver.cpp:244]     Train net output #0: loss = 6.57535 (* 1 = 6.57535 loss)
I0420 01:52:42.884541 10752 sgd_solver.cpp:106] Iteration 63590400, lr = 3.9063e-07
I0420 01:57:49.310576 10752 solver.cpp:228] Iteration 63641600, loss = 2.36098
I0420 01:57:49.310639 10752 solver.cpp:244]     Train net output #0: loss = 0.906244 (* 1 = 0.906244 loss)
I0420 01:57:49.310645 10752 sgd_solver.cpp:106] Iteration 63641600, lr = 3.9063e-07
I0420 02:02:55.709136 10752 solver.cpp:228] Iteration 63692800, loss = 2.35145
I0420 02:02:55.709215 10752 solver.cpp:244]     Train net output #0: loss = 1.04972 (* 1 = 1.04972 loss)
I0420 02:02:55.709221 10752 sgd_solver.cpp:106] Iteration 63692800, lr = 3.9063e-07
I0420 02:08:05.162286 10752 solver.cpp:337] Iteration 63744000, Testing net (#0)
I0420 02:08:32.426268 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0420 02:08:32.795164 10752 solver.cpp:404]     Test net output #0: accuracy = 0.4705
I0420 02:08:32.795197 10752 solver.cpp:404]     Test net output #1: loss = 2.37554 (* 1 = 2.37554 loss)
I0420 02:08:32.798602 10752 solver.cpp:228] Iteration 63744000, loss = 2.34153
I0420 02:08:32.798621 10752 solver.cpp:244]     Train net output #0: loss = 0.686295 (* 1 = 0.686295 loss)
I0420 02:08:32.798631 10752 sgd_solver.cpp:106] Iteration 63744000, lr = 3.9063e-07
I0420 02:13:42.368955 10752 solver.cpp:228] Iteration 63795200, loss = 2.33739
I0420 02:13:42.369020 10752 solver.cpp:244]     Train net output #0: loss = 3.48975 (* 1 = 3.48975 loss)
I0420 02:13:42.369029 10752 sgd_solver.cpp:106] Iteration 63795200, lr = 3.9063e-07
I0420 02:18:50.901923 10752 solver.cpp:228] Iteration 63846400, loss = 2.34944
I0420 02:18:50.901998 10752 solver.cpp:244]     Train net output #0: loss = 3.03078 (* 1 = 3.03078 loss)
I0420 02:18:50.902004 10752 sgd_solver.cpp:106] Iteration 63846400, lr = 3.9063e-07
I0420 02:24:00.447963 10752 solver.cpp:228] Iteration 63897600, loss = 2.33037
I0420 02:24:00.448035 10752 solver.cpp:244]     Train net output #0: loss = 0.00394932 (* 1 = 0.00394932 loss)
I0420 02:24:00.448046 10752 sgd_solver.cpp:106] Iteration 63897600, lr = 3.9063e-07
I0420 02:29:13.243335 10752 solver.cpp:228] Iteration 63948800, loss = 2.32616
I0420 02:29:13.243422 10752 solver.cpp:244]     Train net output #0: loss = 0.00407392 (* 1 = 0.00407392 loss)
I0420 02:29:13.243428 10752 sgd_solver.cpp:106] Iteration 63948800, lr = 3.9063e-07
I0420 02:34:29.698668 10752 solver.cpp:454] Snapshotting to binary proto file snapshots/caffenet128_no_lrn_lsuv_relu_bs1_iter_64000000.caffemodel
I0420 02:34:29.878983 10752 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/caffenet128_no_lrn_lsuv_relu_bs1_iter_64000000.solverstate
I0420 02:34:29.942528 10752 solver.cpp:337] Iteration 64000000, Testing net (#0)
I0420 02:34:52.245364 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0420 02:34:57.826959 10752 solver.cpp:404]     Test net output #0: accuracy = 0.46916
I0420 02:34:57.826990 10752 solver.cpp:404]     Test net output #1: loss = 2.37411 (* 1 = 2.37411 loss)
I0420 02:34:57.829699 10752 solver.cpp:228] Iteration 64000000, loss = 2.32472
I0420 02:34:57.829720 10752 solver.cpp:244]     Train net output #0: loss = 1.60133 (* 1 = 1.60133 loss)
I0420 02:34:57.829726 10752 sgd_solver.cpp:106] Iteration 64000000, lr = 3.9063e-07
I0420 02:40:09.813237 10752 solver.cpp:228] Iteration 64051200, loss = 2.33515
I0420 02:40:09.813303 10752 solver.cpp:244]     Train net output #0: loss = 2.86001 (* 1 = 2.86001 loss)
I0420 02:40:09.813311 10752 sgd_solver.cpp:106] Iteration 64051200, lr = 3.9063e-07
I0420 02:45:16.545140 10752 solver.cpp:228] Iteration 64102400, loss = 2.35012
I0420 02:45:16.545217 10752 solver.cpp:244]     Train net output #0: loss = 0.0415201 (* 1 = 0.0415201 loss)
I0420 02:45:16.545224 10752 sgd_solver.cpp:106] Iteration 64102400, lr = 3.9063e-07
I0420 02:50:26.715417 10752 solver.cpp:228] Iteration 64153600, loss = 2.34411
I0420 02:50:26.715482 10752 solver.cpp:244]     Train net output #0: loss = 2.14814 (* 1 = 2.14814 loss)
I0420 02:50:26.715493 10752 sgd_solver.cpp:106] Iteration 64153600, lr = 3.9063e-07
I0420 02:55:38.826683 10752 solver.cpp:228] Iteration 64204800, loss = 2.34297
I0420 02:55:38.826746 10752 solver.cpp:244]     Train net output #0: loss = 1.84345 (* 1 = 1.84345 loss)
I0420 02:55:38.826753 10752 sgd_solver.cpp:106] Iteration 64204800, lr = 3.9063e-07
I0420 03:00:52.425806 10752 solver.cpp:337] Iteration 64256000, Testing net (#0)
I0420 03:01:13.268051 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0420 03:01:21.634328 10752 solver.cpp:404]     Test net output #0: accuracy = 0.4705
I0420 03:01:21.634474 10752 solver.cpp:404]     Test net output #1: loss = 2.37298 (* 1 = 2.37298 loss)
I0420 03:01:21.638263 10752 solver.cpp:228] Iteration 64256000, loss = 2.36239
I0420 03:01:21.638305 10752 solver.cpp:244]     Train net output #0: loss = 2.43297 (* 1 = 2.43297 loss)
I0420 03:01:21.638316 10752 sgd_solver.cpp:106] Iteration 64256000, lr = 3.9063e-07
I0420 03:06:31.945183 10752 solver.cpp:228] Iteration 64307200, loss = 2.3625
I0420 03:06:31.945255 10752 solver.cpp:244]     Train net output #0: loss = 0.18027 (* 1 = 0.18027 loss)
I0420 03:06:31.945271 10752 sgd_solver.cpp:106] Iteration 64307200, lr = 3.9063e-07
I0420 03:11:39.879215 10752 solver.cpp:228] Iteration 64358400, loss = 2.36241
I0420 03:11:39.879292 10752 solver.cpp:244]     Train net output #0: loss = 0.00287074 (* 1 = 0.00287074 loss)
I0420 03:11:39.879303 10752 sgd_solver.cpp:106] Iteration 64358400, lr = 3.9063e-07
I0420 03:16:47.276084 10752 solver.cpp:228] Iteration 64409600, loss = 2.33303
I0420 03:16:47.276145 10752 solver.cpp:244]     Train net output #0: loss = 2.4013 (* 1 = 2.4013 loss)
I0420 03:16:47.276152 10752 sgd_solver.cpp:106] Iteration 64409600, lr = 3.9063e-07
I0420 03:21:55.598224 10752 solver.cpp:228] Iteration 64460800, loss = 2.34457
I0420 03:21:55.598290 10752 solver.cpp:244]     Train net output #0: loss = 3.51434 (* 1 = 3.51434 loss)
I0420 03:21:55.598302 10752 sgd_solver.cpp:106] Iteration 64460800, lr = 3.9063e-07
I0420 03:27:04.887177 10752 solver.cpp:337] Iteration 64512000, Testing net (#0)
I0420 03:27:22.827842 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0420 03:27:31.326584 10752 solver.cpp:404]     Test net output #0: accuracy = 0.4703
I0420 03:27:31.326617 10752 solver.cpp:404]     Test net output #1: loss = 2.3721 (* 1 = 2.3721 loss)
I0420 03:27:31.329167 10752 solver.cpp:228] Iteration 64512000, loss = 2.33061
I0420 03:27:31.329185 10752 solver.cpp:244]     Train net output #0: loss = 5.1157 (* 1 = 5.1157 loss)
I0420 03:27:31.329195 10752 sgd_solver.cpp:106] Iteration 64512000, lr = 3.9063e-07
I0420 03:32:37.524358 10752 solver.cpp:228] Iteration 64563200, loss = 2.32977
I0420 03:32:37.524467 10752 solver.cpp:244]     Train net output #0: loss = 0.21682 (* 1 = 0.21682 loss)
I0420 03:32:37.524482 10752 sgd_solver.cpp:106] Iteration 64563200, lr = 3.9063e-07
I0420 03:37:43.492975 10752 solver.cpp:228] Iteration 64614400, loss = 2.33739
I0420 03:37:43.493055 10752 solver.cpp:244]     Train net output #0: loss = 2.0191 (* 1 = 2.0191 loss)
I0420 03:37:43.493068 10752 sgd_solver.cpp:106] Iteration 64614400, lr = 3.9063e-07
I0420 03:42:49.499400 10752 solver.cpp:228] Iteration 64665600, loss = 2.3338
I0420 03:42:49.499476 10752 solver.cpp:244]     Train net output #0: loss = 5.65432 (* 1 = 5.65432 loss)
I0420 03:42:49.499490 10752 sgd_solver.cpp:106] Iteration 64665600, lr = 3.9063e-07
I0420 03:47:55.400486 10752 solver.cpp:228] Iteration 64716800, loss = 2.31985
I0420 03:47:55.400562 10752 solver.cpp:244]     Train net output #0: loss = 1.72812 (* 1 = 1.72812 loss)
I0420 03:47:55.400574 10752 sgd_solver.cpp:106] Iteration 64716800, lr = 3.9063e-07
I0420 03:53:01.602591 10752 solver.cpp:337] Iteration 64768000, Testing net (#0)
I0420 03:53:19.942571 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0420 03:53:28.410468 10752 solver.cpp:404]     Test net output #0: accuracy = 0.4702
I0420 03:53:28.410502 10752 solver.cpp:404]     Test net output #1: loss = 2.37305 (* 1 = 2.37305 loss)
I0420 03:53:28.413008 10752 solver.cpp:228] Iteration 64768000, loss = 2.32764
I0420 03:53:28.413027 10752 solver.cpp:244]     Train net output #0: loss = 1.84098 (* 1 = 1.84098 loss)
I0420 03:53:28.413038 10752 sgd_solver.cpp:106] Iteration 64768000, lr = 3.9063e-07
I0420 03:58:34.591963 10752 solver.cpp:228] Iteration 64819200, loss = 2.36797
I0420 03:58:34.592039 10752 solver.cpp:244]     Train net output #0: loss = 0.00618249 (* 1 = 0.00618249 loss)
I0420 03:58:34.592053 10752 sgd_solver.cpp:106] Iteration 64819200, lr = 3.9063e-07
I0420 04:03:40.555181 10752 solver.cpp:228] Iteration 64870400, loss = 2.33773
I0420 04:03:40.555258 10752 solver.cpp:244]     Train net output #0: loss = 3.56559 (* 1 = 3.56559 loss)
I0420 04:03:40.555268 10752 sgd_solver.cpp:106] Iteration 64870400, lr = 3.9063e-07
I0420 04:08:46.520562 10752 solver.cpp:228] Iteration 64921600, loss = 2.36808
I0420 04:08:46.520633 10752 solver.cpp:244]     Train net output #0: loss = 0.61941 (* 1 = 0.61941 loss)
I0420 04:08:46.520639 10752 sgd_solver.cpp:106] Iteration 64921600, lr = 3.9063e-07
I0420 04:13:52.495591 10752 solver.cpp:228] Iteration 64972800, loss = 2.34899
I0420 04:13:52.495651 10752 solver.cpp:244]     Train net output #0: loss = 3.91013 (* 1 = 3.91013 loss)
I0420 04:13:52.495656 10752 sgd_solver.cpp:106] Iteration 64972800, lr = 3.9063e-07
I0420 04:18:58.491966 10752 solver.cpp:337] Iteration 65024000, Testing net (#0)
I0420 04:19:16.566382 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0420 04:19:24.961540 10752 solver.cpp:404]     Test net output #0: accuracy = 0.47124
I0420 04:19:24.961572 10752 solver.cpp:404]     Test net output #1: loss = 2.37025 (* 1 = 2.37025 loss)
I0420 04:19:24.964108 10752 solver.cpp:228] Iteration 65024000, loss = 2.33474
I0420 04:19:24.964126 10752 solver.cpp:244]     Train net output #0: loss = 0.884663 (* 1 = 0.884663 loss)
I0420 04:19:24.964133 10752 sgd_solver.cpp:106] Iteration 65024000, lr = 3.9063e-07
I0420 04:24:31.039588 10752 solver.cpp:228] Iteration 65075200, loss = 2.33775
I0420 04:24:31.039649 10752 solver.cpp:244]     Train net output #0: loss = 0.835723 (* 1 = 0.835723 loss)
I0420 04:24:31.039654 10752 sgd_solver.cpp:106] Iteration 65075200, lr = 3.9063e-07
I0420 04:29:37.067383 10752 solver.cpp:228] Iteration 65126400, loss = 2.34438
I0420 04:29:37.067473 10752 solver.cpp:244]     Train net output #0: loss = 0.499252 (* 1 = 0.499252 loss)
I0420 04:29:37.067482 10752 sgd_solver.cpp:106] Iteration 65126400, lr = 3.9063e-07
I0420 04:34:43.025223 10752 solver.cpp:228] Iteration 65177600, loss = 2.34705
I0420 04:34:43.025297 10752 solver.cpp:244]     Train net output #0: loss = 0.231318 (* 1 = 0.231318 loss)
I0420 04:34:43.025305 10752 sgd_solver.cpp:106] Iteration 65177600, lr = 3.9063e-07
I0420 04:39:49.040740 10752 solver.cpp:228] Iteration 65228800, loss = 2.32444
I0420 04:39:49.040801 10752 solver.cpp:244]     Train net output #0: loss = 0.21898 (* 1 = 0.21898 loss)
I0420 04:39:49.040807 10752 sgd_solver.cpp:106] Iteration 65228800, lr = 3.9063e-07
I0420 04:44:55.096887 10752 solver.cpp:337] Iteration 65280000, Testing net (#0)
I0420 04:45:13.200404 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0420 04:45:21.530707 10752 solver.cpp:404]     Test net output #0: accuracy = 0.47066
I0420 04:45:21.530740 10752 solver.cpp:404]     Test net output #1: loss = 2.37055 (* 1 = 2.37055 loss)
I0420 04:45:21.533280 10752 solver.cpp:228] Iteration 65280000, loss = 2.32133
I0420 04:45:21.533296 10752 solver.cpp:244]     Train net output #0: loss = 1.78855 (* 1 = 1.78855 loss)
I0420 04:45:21.533308 10752 sgd_solver.cpp:106] Iteration 65280000, lr = 3.9063e-07
I0420 04:50:27.718533 10752 solver.cpp:228] Iteration 65331200, loss = 2.33448
I0420 04:50:27.718605 10752 solver.cpp:244]     Train net output #0: loss = 2.2705 (* 1 = 2.2705 loss)
I0420 04:50:27.718611 10752 sgd_solver.cpp:106] Iteration 65331200, lr = 3.9063e-07
I0420 04:55:33.734871 10752 solver.cpp:228] Iteration 65382400, loss = 2.34968
I0420 04:55:33.734941 10752 solver.cpp:244]     Train net output #0: loss = 2.28909 (* 1 = 2.28909 loss)
I0420 04:55:33.734947 10752 sgd_solver.cpp:106] Iteration 65382400, lr = 3.9063e-07
I0420 05:00:39.761953 10752 solver.cpp:228] Iteration 65433600, loss = 2.34165
I0420 05:00:39.762022 10752 solver.cpp:244]     Train net output #0: loss = 0.0453837 (* 1 = 0.0453837 loss)
I0420 05:00:39.762029 10752 sgd_solver.cpp:106] Iteration 65433600, lr = 3.9063e-07
I0420 05:05:45.763025 10752 solver.cpp:228] Iteration 65484800, loss = 2.33159
I0420 05:05:45.763087 10752 solver.cpp:244]     Train net output #0: loss = 5.02103 (* 1 = 5.02103 loss)
I0420 05:05:45.763092 10752 sgd_solver.cpp:106] Iteration 65484800, lr = 3.9063e-07
I0420 05:10:51.786871 10752 solver.cpp:337] Iteration 65536000, Testing net (#0)
I0420 05:11:10.000248 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0420 05:11:18.285567 10752 solver.cpp:404]     Test net output #0: accuracy = 0.4714
I0420 05:11:18.285611 10752 solver.cpp:404]     Test net output #1: loss = 2.37226 (* 1 = 2.37226 loss)
I0420 05:11:18.288910 10752 solver.cpp:228] Iteration 65536000, loss = 2.35845
I0420 05:11:18.288935 10752 solver.cpp:244]     Train net output #0: loss = 2.90174 (* 1 = 2.90174 loss)
I0420 05:11:18.288941 10752 sgd_solver.cpp:106] Iteration 65536000, lr = 3.9063e-07
I0420 05:16:24.727998 10752 solver.cpp:228] Iteration 65587200, loss = 2.35762
I0420 05:16:24.728068 10752 solver.cpp:244]     Train net output #0: loss = 0.776084 (* 1 = 0.776084 loss)
I0420 05:16:24.728075 10752 sgd_solver.cpp:106] Iteration 65587200, lr = 3.9063e-07
I0420 05:21:30.922663 10752 solver.cpp:228] Iteration 65638400, loss = 2.35298
I0420 05:21:30.922724 10752 solver.cpp:244]     Train net output #0: loss = 3.25169 (* 1 = 3.25169 loss)
I0420 05:21:30.922731 10752 sgd_solver.cpp:106] Iteration 65638400, lr = 3.9063e-07
I0420 05:26:37.134129 10752 solver.cpp:228] Iteration 65689600, loss = 2.33515
I0420 05:26:37.134204 10752 solver.cpp:244]     Train net output #0: loss = 2.24517 (* 1 = 2.24517 loss)
I0420 05:26:37.134217 10752 sgd_solver.cpp:106] Iteration 65689600, lr = 3.9063e-07
I0420 05:31:43.165097 10752 solver.cpp:228] Iteration 65740800, loss = 2.34501
I0420 05:31:43.165172 10752 solver.cpp:244]     Train net output #0: loss = 2.45002 (* 1 = 2.45002 loss)
I0420 05:31:43.165187 10752 sgd_solver.cpp:106] Iteration 65740800, lr = 3.9063e-07
I0420 05:36:49.111696 10752 solver.cpp:337] Iteration 65792000, Testing net (#0)
I0420 05:37:07.329818 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0420 05:37:15.568506 10752 solver.cpp:404]     Test net output #0: accuracy = 0.47064
I0420 05:37:15.568539 10752 solver.cpp:404]     Test net output #1: loss = 2.37324 (* 1 = 2.37324 loss)
I0420 05:37:15.571084 10752 solver.cpp:228] Iteration 65792000, loss = 2.33053
I0420 05:37:15.571102 10752 solver.cpp:244]     Train net output #0: loss = 4.3481 (* 1 = 4.3481 loss)
I0420 05:37:15.571115 10752 sgd_solver.cpp:106] Iteration 65792000, lr = 3.9063e-07
I0420 05:42:21.704808 10752 solver.cpp:228] Iteration 65843200, loss = 2.33651
I0420 05:42:21.704869 10752 solver.cpp:244]     Train net output #0: loss = 0.412553 (* 1 = 0.412553 loss)
I0420 05:42:21.704874 10752 sgd_solver.cpp:106] Iteration 65843200, lr = 3.9063e-07
I0420 05:47:27.682266 10752 solver.cpp:228] Iteration 65894400, loss = 2.33348
I0420 05:47:27.682346 10752 solver.cpp:244]     Train net output #0: loss = 1.75892 (* 1 = 1.75892 loss)
I0420 05:47:27.682353 10752 sgd_solver.cpp:106] Iteration 65894400, lr = 3.9063e-07
I0420 05:52:33.668588 10752 solver.cpp:228] Iteration 65945600, loss = 2.32468
I0420 05:52:33.668659 10752 solver.cpp:244]     Train net output #0: loss = 1.90194 (* 1 = 1.90194 loss)
I0420 05:52:33.668668 10752 sgd_solver.cpp:106] Iteration 65945600, lr = 3.9063e-07
I0420 05:57:39.690043 10752 solver.cpp:228] Iteration 65996800, loss = 2.32206
I0420 05:57:39.690115 10752 solver.cpp:244]     Train net output #0: loss = 4.95146 (* 1 = 4.95146 loss)
I0420 05:57:39.690122 10752 sgd_solver.cpp:106] Iteration 65996800, lr = 3.9063e-07
I0420 06:02:45.684911 10752 solver.cpp:337] Iteration 66048000, Testing net (#0)
I0420 06:03:03.975102 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0420 06:03:12.155778 10752 solver.cpp:404]     Test net output #0: accuracy = 0.46974
I0420 06:03:12.155812 10752 solver.cpp:404]     Test net output #1: loss = 2.37306 (* 1 = 2.37306 loss)
I0420 06:03:12.158357 10752 solver.cpp:228] Iteration 66048000, loss = 2.32424
I0420 06:03:12.158376 10752 solver.cpp:244]     Train net output #0: loss = 1.51422 (* 1 = 1.51422 loss)
I0420 06:03:12.158386 10752 sgd_solver.cpp:106] Iteration 66048000, lr = 3.9063e-07
I0420 06:08:18.383375 10752 solver.cpp:228] Iteration 66099200, loss = 2.3719
I0420 06:08:18.383450 10752 solver.cpp:244]     Train net output #0: loss = 1.14702 (* 1 = 1.14702 loss)
I0420 06:08:18.383460 10752 sgd_solver.cpp:106] Iteration 66099200, lr = 3.9063e-07
I0420 06:13:24.468051 10752 solver.cpp:228] Iteration 66150400, loss = 2.34009
I0420 06:13:24.468128 10752 solver.cpp:244]     Train net output #0: loss = 0.557144 (* 1 = 0.557144 loss)
I0420 06:13:24.468143 10752 sgd_solver.cpp:106] Iteration 66150400, lr = 3.9063e-07
I0420 06:18:30.501984 10752 solver.cpp:228] Iteration 66201600, loss = 2.35092
I0420 06:18:30.502048 10752 solver.cpp:244]     Train net output #0: loss = 8.36086 (* 1 = 8.36086 loss)
I0420 06:18:30.502063 10752 sgd_solver.cpp:106] Iteration 66201600, lr = 3.9063e-07
I0420 06:23:36.565088 10752 solver.cpp:228] Iteration 66252800, loss = 2.34933
I0420 06:23:36.565153 10752 solver.cpp:244]     Train net output #0: loss = 0.0628337 (* 1 = 0.0628337 loss)
I0420 06:23:36.565167 10752 sgd_solver.cpp:106] Iteration 66252800, lr = 3.9063e-07
I0420 06:28:42.623862 10752 solver.cpp:337] Iteration 66304000, Testing net (#0)
I0420 06:29:00.971508 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0420 06:29:09.106000 10752 solver.cpp:404]     Test net output #0: accuracy = 0.47126
I0420 06:29:09.106034 10752 solver.cpp:404]     Test net output #1: loss = 2.37152 (* 1 = 2.37152 loss)
I0420 06:29:09.108538 10752 solver.cpp:228] Iteration 66304000, loss = 2.3349
I0420 06:29:09.108556 10752 solver.cpp:244]     Train net output #0: loss = 2.40692 (* 1 = 2.40692 loss)
I0420 06:29:09.108564 10752 sgd_solver.cpp:106] Iteration 66304000, lr = 3.9063e-07
I0420 06:34:15.374193 10752 solver.cpp:228] Iteration 66355200, loss = 2.33963
I0420 06:34:15.374287 10752 solver.cpp:244]     Train net output #0: loss = 0.688533 (* 1 = 0.688533 loss)
I0420 06:34:15.374294 10752 sgd_solver.cpp:106] Iteration 66355200, lr = 3.9063e-07
I0420 06:39:21.495458 10752 solver.cpp:228] Iteration 66406400, loss = 2.34523
I0420 06:39:21.495537 10752 solver.cpp:244]     Train net output #0: loss = 3.14507 (* 1 = 3.14507 loss)
I0420 06:39:21.495543 10752 sgd_solver.cpp:106] Iteration 66406400, lr = 3.9063e-07
I0420 06:44:27.661115 10752 solver.cpp:228] Iteration 66457600, loss = 2.33325
I0420 06:44:27.661176 10752 solver.cpp:244]     Train net output #0: loss = 0.198361 (* 1 = 0.198361 loss)
I0420 06:44:27.661181 10752 sgd_solver.cpp:106] Iteration 66457600, lr = 3.9063e-07
I0420 06:49:33.797611 10752 solver.cpp:228] Iteration 66508800, loss = 2.33026
I0420 06:49:33.797674 10752 solver.cpp:244]     Train net output #0: loss = 8.82307 (* 1 = 8.82307 loss)
I0420 06:49:33.797682 10752 sgd_solver.cpp:106] Iteration 66508800, lr = 3.9063e-07
I0420 06:54:39.860656 10752 solver.cpp:454] Snapshotting to binary proto file snapshots/caffenet128_no_lrn_lsuv_relu_bs1_iter_66560000.caffemodel
I0420 06:54:40.062765 10752 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/caffenet128_no_lrn_lsuv_relu_bs1_iter_66560000.solverstate
I0420 06:54:40.129947 10752 solver.cpp:337] Iteration 66560000, Testing net (#0)
I0420 06:54:58.513679 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0420 06:55:06.590061 10752 solver.cpp:404]     Test net output #0: accuracy = 0.47084
I0420 06:55:06.590095 10752 solver.cpp:404]     Test net output #1: loss = 2.37037 (* 1 = 2.37037 loss)
I0420 06:55:06.592623 10752 solver.cpp:228] Iteration 66560000, loss = 2.31909
I0420 06:55:06.592640 10752 solver.cpp:244]     Train net output #0: loss = 3.24601 (* 1 = 3.24601 loss)
I0420 06:55:06.592650 10752 sgd_solver.cpp:106] Iteration 66560000, lr = 3.9063e-07
I0420 07:00:12.811936 10752 solver.cpp:228] Iteration 66611200, loss = 2.32646
I0420 07:00:12.812010 10752 solver.cpp:244]     Train net output #0: loss = 2.93076 (* 1 = 2.93076 loss)
I0420 07:00:12.812016 10752 sgd_solver.cpp:106] Iteration 66611200, lr = 3.9063e-07
I0420 07:05:18.946430 10752 solver.cpp:228] Iteration 66662400, loss = 2.35118
I0420 07:05:18.946502 10752 solver.cpp:244]     Train net output #0: loss = 0.0224279 (* 1 = 0.0224279 loss)
I0420 07:05:18.946508 10752 sgd_solver.cpp:106] Iteration 66662400, lr = 3.9063e-07
I0420 07:10:25.019546 10752 solver.cpp:228] Iteration 66713600, loss = 2.33742
I0420 07:10:25.019608 10752 solver.cpp:244]     Train net output #0: loss = 3.23245 (* 1 = 3.23245 loss)
I0420 07:10:25.019614 10752 sgd_solver.cpp:106] Iteration 66713600, lr = 3.9063e-07
I0420 07:15:31.188571 10752 solver.cpp:228] Iteration 66764800, loss = 2.34311
I0420 07:15:31.188642 10752 solver.cpp:244]     Train net output #0: loss = 7.87169 (* 1 = 7.87169 loss)
I0420 07:15:31.188647 10752 sgd_solver.cpp:106] Iteration 66764800, lr = 3.9063e-07
I0420 07:20:37.241904 10752 solver.cpp:337] Iteration 66816000, Testing net (#0)
I0420 07:20:56.825878 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0420 07:21:04.854957 10752 solver.cpp:404]     Test net output #0: accuracy = 0.47132
I0420 07:21:04.854992 10752 solver.cpp:404]     Test net output #1: loss = 2.37443 (* 1 = 2.37443 loss)
I0420 07:21:04.857542 10752 solver.cpp:228] Iteration 66816000, loss = 2.35754
I0420 07:21:04.857561 10752 solver.cpp:244]     Train net output #0: loss = 2.30713 (* 1 = 2.30713 loss)
I0420 07:21:04.857573 10752 sgd_solver.cpp:106] Iteration 66816000, lr = 3.9063e-07
I0420 07:26:11.173355 10752 solver.cpp:228] Iteration 66867200, loss = 2.36105
I0420 07:26:11.173421 10752 solver.cpp:244]     Train net output #0: loss = 3.3972 (* 1 = 3.3972 loss)
I0420 07:26:11.173429 10752 sgd_solver.cpp:106] Iteration 66867200, lr = 3.9063e-07
I0420 07:31:17.491552 10752 solver.cpp:228] Iteration 66918400, loss = 2.35908
I0420 07:31:17.491662 10752 solver.cpp:244]     Train net output #0: loss = 5.2079 (* 1 = 5.2079 loss)
I0420 07:31:17.491670 10752 sgd_solver.cpp:106] Iteration 66918400, lr = 3.9063e-07
I0420 07:36:23.606936 10752 solver.cpp:228] Iteration 66969600, loss = 2.33606
I0420 07:36:23.607000 10752 solver.cpp:244]     Train net output #0: loss = 0.804816 (* 1 = 0.804816 loss)
I0420 07:36:23.607009 10752 sgd_solver.cpp:106] Iteration 66969600, lr = 3.9063e-07
I0420 07:41:29.868458 10752 solver.cpp:228] Iteration 67020800, loss = 2.34118
I0420 07:41:29.868520 10752 solver.cpp:244]     Train net output #0: loss = 0.0291165 (* 1 = 0.0291165 loss)
I0420 07:41:29.868527 10752 sgd_solver.cpp:106] Iteration 67020800, lr = 3.9063e-07
I0420 07:46:36.024605 10752 solver.cpp:337] Iteration 67072000, Testing net (#0)
I0420 07:46:54.397164 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0420 07:47:02.548563 10752 solver.cpp:404]     Test net output #0: accuracy = 0.471821
I0420 07:47:02.548595 10752 solver.cpp:404]     Test net output #1: loss = 2.37107 (* 1 = 2.37107 loss)
I0420 07:47:02.551120 10752 solver.cpp:228] Iteration 67072000, loss = 2.3323
I0420 07:47:02.551136 10752 solver.cpp:244]     Train net output #0: loss = 0.0293503 (* 1 = 0.0293503 loss)
I0420 07:47:02.551143 10752 sgd_solver.cpp:106] Iteration 67072000, lr = 3.9063e-07
I0420 07:52:08.837731 10752 solver.cpp:228] Iteration 67123200, loss = 2.33499
I0420 07:52:08.837805 10752 solver.cpp:244]     Train net output #0: loss = 1.73681 (* 1 = 1.73681 loss)
I0420 07:52:08.837810 10752 sgd_solver.cpp:106] Iteration 67123200, lr = 3.9063e-07
I0420 07:57:15.002475 10752 solver.cpp:228] Iteration 67174400, loss = 2.32548
I0420 07:57:15.002537 10752 solver.cpp:244]     Train net output #0: loss = 0.168868 (* 1 = 0.168868 loss)
I0420 07:57:15.002542 10752 sgd_solver.cpp:106] Iteration 67174400, lr = 3.9063e-07
I0420 08:02:21.224256 10752 solver.cpp:228] Iteration 67225600, loss = 2.33277
I0420 08:02:21.224318 10752 solver.cpp:244]     Train net output #0: loss = 0.0669135 (* 1 = 0.0669135 loss)
I0420 08:02:21.224323 10752 sgd_solver.cpp:106] Iteration 67225600, lr = 3.9063e-07
I0420 08:07:27.520913 10752 solver.cpp:228] Iteration 67276800, loss = 2.32045
I0420 08:07:27.520980 10752 solver.cpp:244]     Train net output #0: loss = 1.97675 (* 1 = 1.97675 loss)
I0420 08:07:27.520987 10752 sgd_solver.cpp:106] Iteration 67276800, lr = 3.9063e-07
I0420 08:12:33.743989 10752 solver.cpp:337] Iteration 67328000, Testing net (#0)
I0420 08:12:52.184201 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0420 08:13:00.257601 10752 solver.cpp:404]     Test net output #0: accuracy = 0.47004
I0420 08:13:00.257632 10752 solver.cpp:404]     Test net output #1: loss = 2.37125 (* 1 = 2.37125 loss)
I0420 08:13:00.260583 10752 solver.cpp:228] Iteration 67328000, loss = 2.32417
I0420 08:13:00.260612 10752 solver.cpp:244]     Train net output #0: loss = 7.5622 (* 1 = 7.5622 loss)
I0420 08:13:00.260620 10752 sgd_solver.cpp:106] Iteration 67328000, lr = 3.9063e-07
I0420 08:18:06.416822 10752 solver.cpp:228] Iteration 67379200, loss = 2.36622
I0420 08:18:06.416890 10752 solver.cpp:244]     Train net output #0: loss = 1.54948 (* 1 = 1.54948 loss)
I0420 08:18:06.416898 10752 sgd_solver.cpp:106] Iteration 67379200, lr = 3.9063e-07
I0420 08:23:12.412974 10752 solver.cpp:228] Iteration 67430400, loss = 2.34462
I0420 08:23:12.413050 10752 solver.cpp:244]     Train net output #0: loss = 3.82471 (* 1 = 3.82471 loss)
I0420 08:23:12.413058 10752 sgd_solver.cpp:106] Iteration 67430400, lr = 3.9063e-07
I0420 08:28:18.545384 10752 solver.cpp:228] Iteration 67481600, loss = 2.36062
I0420 08:28:18.545455 10752 solver.cpp:244]     Train net output #0: loss = 1.22502 (* 1 = 1.22502 loss)
I0420 08:28:18.545466 10752 sgd_solver.cpp:106] Iteration 67481600, lr = 3.9063e-07
I0420 08:33:24.601866 10752 solver.cpp:228] Iteration 67532800, loss = 2.34028
I0420 08:33:24.601923 10752 solver.cpp:244]     Train net output #0: loss = 2.50558 (* 1 = 2.50558 loss)
I0420 08:33:24.601933 10752 sgd_solver.cpp:106] Iteration 67532800, lr = 3.9063e-07
I0420 08:38:30.654592 10752 solver.cpp:337] Iteration 67584000, Testing net (#0)
I0420 08:38:49.188824 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0420 08:38:57.187060 10752 solver.cpp:404]     Test net output #0: accuracy = 0.47174
I0420 08:38:57.187093 10752 solver.cpp:404]     Test net output #1: loss = 2.36949 (* 1 = 2.36949 loss)
I0420 08:38:57.190112 10752 solver.cpp:228] Iteration 67584000, loss = 2.335
I0420 08:38:57.190140 10752 solver.cpp:244]     Train net output #0: loss = 0.704593 (* 1 = 0.704593 loss)
I0420 08:38:57.190150 10752 sgd_solver.cpp:106] Iteration 67584000, lr = 3.9063e-07
I0420 08:44:03.305913 10752 solver.cpp:228] Iteration 67635200, loss = 2.33179
I0420 08:44:03.305980 10752 solver.cpp:244]     Train net output #0: loss = 4.38843 (* 1 = 4.38843 loss)
I0420 08:44:03.305991 10752 sgd_solver.cpp:106] Iteration 67635200, lr = 3.9063e-07
I0420 08:49:09.362133 10752 solver.cpp:228] Iteration 67686400, loss = 2.33979
I0420 08:49:09.362196 10752 solver.cpp:244]     Train net output #0: loss = 0.00615796 (* 1 = 0.00615796 loss)
I0420 08:49:09.362207 10752 sgd_solver.cpp:106] Iteration 67686400, lr = 3.9063e-07
I0420 08:54:15.438598 10752 solver.cpp:228] Iteration 67737600, loss = 2.33174
I0420 08:54:15.438702 10752 solver.cpp:244]     Train net output #0: loss = 0.05705 (* 1 = 0.05705 loss)
I0420 08:54:15.438720 10752 sgd_solver.cpp:106] Iteration 67737600, lr = 3.9063e-07
I0420 08:59:21.584985 10752 solver.cpp:228] Iteration 67788800, loss = 2.32867
I0420 08:59:21.585059 10752 solver.cpp:244]     Train net output #0: loss = 3.33063 (* 1 = 3.33063 loss)
I0420 08:59:21.585072 10752 sgd_solver.cpp:106] Iteration 67788800, lr = 3.9063e-07
I0420 09:04:27.797322 10752 solver.cpp:337] Iteration 67840000, Testing net (#0)
I0420 09:04:46.318465 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0420 09:04:54.282450 10752 solver.cpp:404]     Test net output #0: accuracy = 0.47084
I0420 09:04:54.282483 10752 solver.cpp:404]     Test net output #1: loss = 2.3701 (* 1 = 2.3701 loss)
I0420 09:04:54.285043 10752 solver.cpp:228] Iteration 67840000, loss = 2.31738
I0420 09:04:54.285060 10752 solver.cpp:244]     Train net output #0: loss = 1.47904 (* 1 = 1.47904 loss)
I0420 09:04:54.285071 10752 sgd_solver.cpp:106] Iteration 67840000, lr = 3.9063e-07
I0420 09:10:00.476445 10752 solver.cpp:228] Iteration 67891200, loss = 2.3258
I0420 09:10:00.476521 10752 solver.cpp:244]     Train net output #0: loss = 5.19543 (* 1 = 5.19543 loss)
I0420 09:10:00.476534 10752 sgd_solver.cpp:106] Iteration 67891200, lr = 3.9063e-07
I0420 09:15:06.677135 10752 solver.cpp:228] Iteration 67942400, loss = 2.34583
I0420 09:15:06.677211 10752 solver.cpp:244]     Train net output #0: loss = 5.53276 (* 1 = 5.53276 loss)
I0420 09:15:06.677217 10752 sgd_solver.cpp:106] Iteration 67942400, lr = 3.9063e-07
I0420 09:20:12.915411 10752 solver.cpp:228] Iteration 67993600, loss = 2.34632
I0420 09:20:12.915472 10752 solver.cpp:244]     Train net output #0: loss = 1.73948 (* 1 = 1.73948 loss)
I0420 09:20:12.915478 10752 sgd_solver.cpp:106] Iteration 67993600, lr = 3.9063e-07
I0420 09:25:19.116261 10752 solver.cpp:228] Iteration 68044800, loss = 2.34078
I0420 09:25:19.116336 10752 solver.cpp:244]     Train net output #0: loss = 4.07272 (* 1 = 4.07272 loss)
I0420 09:25:19.116346 10752 sgd_solver.cpp:106] Iteration 68044800, lr = 3.9063e-07
I0420 09:30:31.139272 10752 solver.cpp:337] Iteration 68096000, Testing net (#0)
I0420 09:30:49.807214 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0420 09:30:58.396102 10752 solver.cpp:404]     Test net output #0: accuracy = 0.47114
I0420 09:30:58.396136 10752 solver.cpp:404]     Test net output #1: loss = 2.37397 (* 1 = 2.37397 loss)
I0420 09:30:58.398663 10752 solver.cpp:228] Iteration 68096000, loss = 2.34689
I0420 09:30:58.398682 10752 solver.cpp:244]     Train net output #0: loss = 5.57037 (* 1 = 5.57037 loss)
I0420 09:30:58.398691 10752 sgd_solver.cpp:106] Iteration 68096000, lr = 3.9063e-07
I0420 09:36:06.011117 10752 solver.cpp:228] Iteration 68147200, loss = 2.35867
I0420 09:36:06.011209 10752 solver.cpp:244]     Train net output #0: loss = 0.0106393 (* 1 = 0.0106393 loss)
I0420 09:36:06.011219 10752 sgd_solver.cpp:106] Iteration 68147200, lr = 3.9063e-07
I0420 09:41:14.684319 10752 solver.cpp:228] Iteration 68198400, loss = 2.3566
I0420 09:41:14.684391 10752 solver.cpp:244]     Train net output #0: loss = 1.67521 (* 1 = 1.67521 loss)
I0420 09:41:14.684397 10752 sgd_solver.cpp:106] Iteration 68198400, lr = 3.9063e-07
I0420 09:46:25.070386 10752 solver.cpp:228] Iteration 68249600, loss = 2.33722
I0420 09:46:25.070461 10752 solver.cpp:244]     Train net output #0: loss = 5.02631 (* 1 = 5.02631 loss)
I0420 09:46:25.070466 10752 sgd_solver.cpp:106] Iteration 68249600, lr = 3.9063e-07
I0420 09:51:31.742039 10752 solver.cpp:228] Iteration 68300800, loss = 2.33985
I0420 09:51:31.742106 10752 solver.cpp:244]     Train net output #0: loss = 3.68828 (* 1 = 3.68828 loss)
I0420 09:51:31.742117 10752 sgd_solver.cpp:106] Iteration 68300800, lr = 3.9063e-07
I0420 09:56:42.047611 10752 solver.cpp:337] Iteration 68352000, Testing net (#0)
I0420 09:57:00.687667 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0420 09:57:09.677952 10752 solver.cpp:404]     Test net output #0: accuracy = 0.47072
I0420 09:57:09.678017 10752 solver.cpp:404]     Test net output #1: loss = 2.37301 (* 1 = 2.37301 loss)
I0420 09:57:09.683045 10752 solver.cpp:228] Iteration 68352000, loss = 2.33395
I0420 09:57:09.683110 10752 solver.cpp:244]     Train net output #0: loss = 0.0235877 (* 1 = 0.0235877 loss)
I0420 09:57:09.683127 10752 sgd_solver.cpp:106] Iteration 68352000, lr = 3.9063e-07
I0420 10:02:20.276906 10752 solver.cpp:228] Iteration 68403200, loss = 2.33168
I0420 10:02:20.276968 10752 solver.cpp:244]     Train net output #0: loss = 0.100667 (* 1 = 0.100667 loss)
I0420 10:02:20.276974 10752 sgd_solver.cpp:106] Iteration 68403200, lr = 3.9063e-07
I0420 10:07:26.986585 10752 solver.cpp:228] Iteration 68454400, loss = 2.3283
I0420 10:07:26.986659 10752 solver.cpp:244]     Train net output #0: loss = 0.753555 (* 1 = 0.753555 loss)
I0420 10:07:26.986665 10752 sgd_solver.cpp:106] Iteration 68454400, lr = 3.9063e-07
I0420 10:12:34.055178 10752 solver.cpp:228] Iteration 68505600, loss = 2.33292
I0420 10:12:34.055250 10752 solver.cpp:244]     Train net output #0: loss = 4.75759 (* 1 = 4.75759 loss)
I0420 10:12:34.055258 10752 sgd_solver.cpp:106] Iteration 68505600, lr = 3.9063e-07
I0420 10:17:45.526463 10752 solver.cpp:228] Iteration 68556800, loss = 2.32396
I0420 10:17:45.526532 10752 solver.cpp:244]     Train net output #0: loss = 5.56816 (* 1 = 5.56816 loss)
I0420 10:17:45.526542 10752 sgd_solver.cpp:106] Iteration 68556800, lr = 3.9063e-07
I0420 10:22:54.268690 10752 solver.cpp:337] Iteration 68608000, Testing net (#0)
I0420 10:23:12.287911 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0420 10:23:21.119451 10752 solver.cpp:404]     Test net output #0: accuracy = 0.4708
I0420 10:23:21.119482 10752 solver.cpp:404]     Test net output #1: loss = 2.37046 (* 1 = 2.37046 loss)
I0420 10:23:21.122493 10752 solver.cpp:228] Iteration 68608000, loss = 2.32973
I0420 10:23:21.122521 10752 solver.cpp:244]     Train net output #0: loss = 1.912 (* 1 = 1.912 loss)
I0420 10:23:21.122530 10752 sgd_solver.cpp:106] Iteration 68608000, lr = 3.9063e-07
I0420 10:28:30.895537 10752 solver.cpp:228] Iteration 68659200, loss = 2.37775
I0420 10:28:30.895607 10752 solver.cpp:244]     Train net output #0: loss = 2.08083 (* 1 = 2.08083 loss)
I0420 10:28:30.895614 10752 sgd_solver.cpp:106] Iteration 68659200, lr = 3.9063e-07
I0420 10:33:40.760879 10752 solver.cpp:228] Iteration 68710400, loss = 2.35127
I0420 10:33:40.760956 10752 solver.cpp:244]     Train net output #0: loss = 0.0171154 (* 1 = 0.0171154 loss)
I0420 10:33:40.760965 10752 sgd_solver.cpp:106] Iteration 68710400, lr = 3.9063e-07
I0420 10:38:53.292320 10752 solver.cpp:228] Iteration 68761600, loss = 2.35479
I0420 10:38:53.292384 10752 solver.cpp:244]     Train net output #0: loss = 1.16786 (* 1 = 1.16786 loss)
I0420 10:38:53.292398 10752 sgd_solver.cpp:106] Iteration 68761600, lr = 3.9063e-07
I0420 10:44:01.505019 10752 solver.cpp:228] Iteration 68812800, loss = 2.34745
I0420 10:44:01.505113 10752 solver.cpp:244]     Train net output #0: loss = 2.93236 (* 1 = 2.93236 loss)
I0420 10:44:01.505120 10752 sgd_solver.cpp:106] Iteration 68812800, lr = 3.9063e-07
I0420 10:49:08.221923 10752 solver.cpp:337] Iteration 68864000, Testing net (#0)
I0420 10:49:25.745611 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0420 10:49:34.665688 10752 solver.cpp:404]     Test net output #0: accuracy = 0.47134
I0420 10:49:34.665722 10752 solver.cpp:404]     Test net output #1: loss = 2.36904 (* 1 = 2.36904 loss)
I0420 10:49:34.668253 10752 solver.cpp:228] Iteration 68864000, loss = 2.33404
I0420 10:49:34.668272 10752 solver.cpp:244]     Train net output #0: loss = 0.0160882 (* 1 = 0.0160882 loss)
I0420 10:49:34.668282 10752 sgd_solver.cpp:106] Iteration 68864000, lr = 3.9063e-07
I0420 10:54:41.410917 10752 solver.cpp:228] Iteration 68915200, loss = 2.33572
I0420 10:54:41.411002 10752 solver.cpp:244]     Train net output #0: loss = 1.98514 (* 1 = 1.98514 loss)
I0420 10:54:41.411015 10752 sgd_solver.cpp:106] Iteration 68915200, lr = 3.9063e-07
I0420 10:59:48.418251 10752 solver.cpp:228] Iteration 68966400, loss = 2.33727
I0420 10:59:48.418323 10752 solver.cpp:244]     Train net output #0: loss = 0.200815 (* 1 = 0.200815 loss)
I0420 10:59:48.418329 10752 sgd_solver.cpp:106] Iteration 68966400, lr = 3.9063e-07
I0420 11:04:55.543804 10752 solver.cpp:228] Iteration 69017600, loss = 2.33949
I0420 11:04:55.543877 10752 solver.cpp:244]     Train net output #0: loss = 0.402331 (* 1 = 0.402331 loss)
I0420 11:04:55.543884 10752 sgd_solver.cpp:106] Iteration 69017600, lr = 3.9063e-07
I0420 11:10:02.766347 10752 solver.cpp:228] Iteration 69068800, loss = 2.32879
I0420 11:10:02.766423 10752 solver.cpp:244]     Train net output #0: loss = 9.35286 (* 1 = 9.35286 loss)
I0420 11:10:02.766430 10752 sgd_solver.cpp:106] Iteration 69068800, lr = 3.9063e-07
I0420 11:15:10.195161 10752 solver.cpp:454] Snapshotting to binary proto file snapshots/caffenet128_no_lrn_lsuv_relu_bs1_iter_69120000.caffemodel
I0420 11:15:10.409162 10752 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/caffenet128_no_lrn_lsuv_relu_bs1_iter_69120000.solverstate
I0420 11:15:10.479074 10752 solver.cpp:337] Iteration 69120000, Testing net (#0)
I0420 11:15:28.034142 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0420 11:15:37.023556 10752 solver.cpp:404]     Test net output #0: accuracy = 0.47132
I0420 11:15:37.023591 10752 solver.cpp:404]     Test net output #1: loss = 2.36766 (* 1 = 2.36766 loss)
I0420 11:15:37.026149 10752 solver.cpp:228] Iteration 69120000, loss = 2.31788
I0420 11:15:37.026170 10752 solver.cpp:244]     Train net output #0: loss = 0.0318614 (* 1 = 0.0318614 loss)
I0420 11:15:37.026181 10752 sgd_solver.cpp:106] Iteration 69120000, lr = 3.9063e-07
I0420 11:20:44.188659 10752 solver.cpp:228] Iteration 69171200, loss = 2.32436
I0420 11:20:44.188745 10752 solver.cpp:244]     Train net output #0: loss = 2.24874 (* 1 = 2.24874 loss)
I0420 11:20:44.188753 10752 sgd_solver.cpp:106] Iteration 69171200, lr = 3.9063e-07
I0420 11:25:51.646411 10752 solver.cpp:228] Iteration 69222400, loss = 2.34633
I0420 11:25:51.646474 10752 solver.cpp:244]     Train net output #0: loss = 0.0138246 (* 1 = 0.0138246 loss)
I0420 11:25:51.646481 10752 sgd_solver.cpp:106] Iteration 69222400, lr = 3.9063e-07
I0420 11:30:58.916940 10752 solver.cpp:228] Iteration 69273600, loss = 2.32965
I0420 11:30:58.917016 10752 solver.cpp:244]     Train net output #0: loss = 6.2524 (* 1 = 6.2524 loss)
I0420 11:30:58.917026 10752 sgd_solver.cpp:106] Iteration 69273600, lr = 3.9063e-07
I0420 11:36:05.843269 10752 solver.cpp:228] Iteration 69324800, loss = 2.33575
I0420 11:36:05.843348 10752 solver.cpp:244]     Train net output #0: loss = 0.818297 (* 1 = 0.818297 loss)
I0420 11:36:05.843354 10752 sgd_solver.cpp:106] Iteration 69324800, lr = 3.9063e-07
I0420 11:41:13.416493 10752 solver.cpp:337] Iteration 69376000, Testing net (#0)
I0420 11:41:31.042641 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0420 11:41:39.996738 10752 solver.cpp:404]     Test net output #0: accuracy = 0.4709
I0420 11:41:39.996768 10752 solver.cpp:404]     Test net output #1: loss = 2.37127 (* 1 = 2.37127 loss)
I0420 11:41:39.999285 10752 solver.cpp:228] Iteration 69376000, loss = 2.35448
I0420 11:41:39.999302 10752 solver.cpp:244]     Train net output #0: loss = 1.26569 (* 1 = 1.26569 loss)
I0420 11:41:39.999312 10752 sgd_solver.cpp:106] Iteration 69376000, lr = 3.9063e-07
I0420 11:46:51.364840 10752 solver.cpp:228] Iteration 69427200, loss = 2.34402
I0420 11:46:51.364923 10752 solver.cpp:244]     Train net output #0: loss = 3.66764 (* 1 = 3.66764 loss)
I0420 11:46:51.364938 10752 sgd_solver.cpp:106] Iteration 69427200, lr = 3.9063e-07
I0420 11:52:01.807003 10752 solver.cpp:228] Iteration 69478400, loss = 2.35519
I0420 11:52:01.807080 10752 solver.cpp:244]     Train net output #0: loss = 7.94869 (* 1 = 7.94869 loss)
I0420 11:52:01.807087 10752 sgd_solver.cpp:106] Iteration 69478400, lr = 3.9063e-07
I0420 11:57:15.090972 10752 solver.cpp:228] Iteration 69529600, loss = 2.33157
I0420 11:57:15.091043 10752 solver.cpp:244]     Train net output #0: loss = 2.31634 (* 1 = 2.31634 loss)
I0420 11:57:15.091054 10752 sgd_solver.cpp:106] Iteration 69529600, lr = 3.9063e-07
I0420 12:02:25.802831 10752 solver.cpp:228] Iteration 69580800, loss = 2.33496
I0420 12:02:25.802899 10752 solver.cpp:244]     Train net output #0: loss = 1.74588 (* 1 = 1.74588 loss)
I0420 12:02:25.802907 10752 sgd_solver.cpp:106] Iteration 69580800, lr = 3.9063e-07
I0420 12:07:35.904605 10752 solver.cpp:337] Iteration 69632000, Testing net (#0)
I0420 12:07:53.036340 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0420 12:08:02.944682 10752 solver.cpp:404]     Test net output #0: accuracy = 0.47126
I0420 12:08:02.944741 10752 solver.cpp:404]     Test net output #1: loss = 2.36926 (* 1 = 2.36926 loss)
I0420 12:08:02.949477 10752 solver.cpp:228] Iteration 69632000, loss = 2.33194
I0420 12:08:02.949543 10752 solver.cpp:244]     Train net output #0: loss = 3.64024 (* 1 = 3.64024 loss)
I0420 12:08:02.949565 10752 sgd_solver.cpp:106] Iteration 69632000, lr = 3.9063e-07
I0420 12:13:10.487452 10752 solver.cpp:228] Iteration 69683200, loss = 2.33191
I0420 12:13:10.487517 10752 solver.cpp:244]     Train net output #0: loss = 4.80578 (* 1 = 4.80578 loss)
I0420 12:13:10.487526 10752 sgd_solver.cpp:106] Iteration 69683200, lr = 3.9063e-07
I0420 12:18:16.779696 10752 solver.cpp:228] Iteration 69734400, loss = 2.31904
I0420 12:18:16.779760 10752 solver.cpp:244]     Train net output #0: loss = 9.14014 (* 1 = 9.14014 loss)
I0420 12:18:16.779767 10752 sgd_solver.cpp:106] Iteration 69734400, lr = 3.9063e-07
I0420 12:23:24.790666 10752 solver.cpp:228] Iteration 69785600, loss = 2.32846
I0420 12:23:24.790730 10752 solver.cpp:244]     Train net output #0: loss = 1.24556 (* 1 = 1.24556 loss)
I0420 12:23:24.790737 10752 sgd_solver.cpp:106] Iteration 69785600, lr = 3.9063e-07
I0420 12:28:30.877671 10752 solver.cpp:228] Iteration 69836800, loss = 2.32031
I0420 12:28:30.877743 10752 solver.cpp:244]     Train net output #0: loss = 0.565916 (* 1 = 0.565916 loss)
I0420 12:28:30.877749 10752 sgd_solver.cpp:106] Iteration 69836800, lr = 3.9063e-07
I0420 12:33:36.922225 10752 solver.cpp:337] Iteration 69888000, Testing net (#0)
I0420 12:33:53.754910 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0420 12:34:03.456452 10752 solver.cpp:404]     Test net output #0: accuracy = 0.4715
I0420 12:34:03.456480 10752 solver.cpp:404]     Test net output #1: loss = 2.36669 (* 1 = 2.36669 loss)
I0420 12:34:03.458972 10752 solver.cpp:228] Iteration 69888000, loss = 2.32232
I0420 12:34:03.458994 10752 solver.cpp:244]     Train net output #0: loss = 0.00495162 (* 1 = 0.00495162 loss)
I0420 12:34:03.459003 10752 sgd_solver.cpp:106] Iteration 69888000, lr = 3.9063e-07
I0420 12:39:09.618610 10752 solver.cpp:228] Iteration 69939200, loss = 2.35531
I0420 12:39:09.618706 10752 solver.cpp:244]     Train net output #0: loss = 1.46499 (* 1 = 1.46499 loss)
I0420 12:39:09.618713 10752 sgd_solver.cpp:106] Iteration 69939200, lr = 3.9063e-07
I0420 12:44:15.766966 10752 solver.cpp:228] Iteration 69990400, loss = 2.34798
I0420 12:44:15.767043 10752 solver.cpp:244]     Train net output #0: loss = 1.54787 (* 1 = 1.54787 loss)
I0420 12:44:15.767058 10752 sgd_solver.cpp:106] Iteration 69990400, lr = 3.9063e-07
I0420 12:49:21.754987 10752 solver.cpp:228] Iteration 70041600, loss = 2.35215
I0420 12:49:21.755060 10752 solver.cpp:244]     Train net output #0: loss = 2.43448 (* 1 = 2.43448 loss)
I0420 12:49:21.755069 10752 sgd_solver.cpp:106] Iteration 70041600, lr = 3.9063e-07
I0420 12:54:27.705839 10752 solver.cpp:228] Iteration 70092800, loss = 2.34059
I0420 12:54:27.705917 10752 solver.cpp:244]     Train net output #0: loss = 1.63441 (* 1 = 1.63441 loss)
I0420 12:54:27.705931 10752 sgd_solver.cpp:106] Iteration 70092800, lr = 3.9063e-07
I0420 12:59:33.688058 10752 solver.cpp:337] Iteration 70144000, Testing net (#0)
I0420 12:59:51.299196 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0420 13:00:00.936236 10752 solver.cpp:404]     Test net output #0: accuracy = 0.4719
I0420 13:00:00.936270 10752 solver.cpp:404]     Test net output #1: loss = 2.3693 (* 1 = 2.3693 loss)
I0420 13:00:00.938876 10752 solver.cpp:228] Iteration 70144000, loss = 2.32721
I0420 13:00:00.938897 10752 solver.cpp:244]     Train net output #0: loss = 0.402303 (* 1 = 0.402303 loss)
I0420 13:00:00.938908 10752 sgd_solver.cpp:106] Iteration 70144000, lr = 3.9063e-07
I0420 13:05:07.161963 10752 solver.cpp:228] Iteration 70195200, loss = 2.32922
I0420 13:05:07.162030 10752 solver.cpp:244]     Train net output #0: loss = 1.98402 (* 1 = 1.98402 loss)
I0420 13:05:07.162042 10752 sgd_solver.cpp:106] Iteration 70195200, lr = 3.9063e-07
I0420 13:10:13.302541 10752 solver.cpp:228] Iteration 70246400, loss = 2.34065
I0420 13:10:13.302608 10752 solver.cpp:244]     Train net output #0: loss = 2.43806 (* 1 = 2.43806 loss)
I0420 13:10:13.302619 10752 sgd_solver.cpp:106] Iteration 70246400, lr = 3.9063e-07
I0420 13:15:19.330621 10752 solver.cpp:228] Iteration 70297600, loss = 2.34302
I0420 13:15:19.330685 10752 solver.cpp:244]     Train net output #0: loss = 1.73531 (* 1 = 1.73531 loss)
I0420 13:15:19.330698 10752 sgd_solver.cpp:106] Iteration 70297600, lr = 3.9063e-07
I0420 13:20:25.422475 10752 solver.cpp:228] Iteration 70348800, loss = 2.32977
I0420 13:20:25.422543 10752 solver.cpp:244]     Train net output #0: loss = 0.799008 (* 1 = 0.799008 loss)
I0420 13:20:25.422556 10752 sgd_solver.cpp:106] Iteration 70348800, lr = 3.9063e-07
I0420 13:25:31.648079 10752 solver.cpp:337] Iteration 70400000, Testing net (#0)
I0420 13:25:48.561229 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0420 13:25:58.153877 10752 solver.cpp:404]     Test net output #0: accuracy = 0.47114
I0420 13:25:58.153909 10752 solver.cpp:404]     Test net output #1: loss = 2.36717 (* 1 = 2.36717 loss)
I0420 13:25:58.156455 10752 solver.cpp:228] Iteration 70400000, loss = 2.31256
I0420 13:25:58.156473 10752 solver.cpp:244]     Train net output #0: loss = 0.00304058 (* 1 = 0.00304058 loss)
I0420 13:25:58.156486 10752 sgd_solver.cpp:106] Iteration 70400000, lr = 3.9063e-07
I0420 13:31:04.474906 10752 solver.cpp:228] Iteration 70451200, loss = 2.31869
I0420 13:31:04.474967 10752 solver.cpp:244]     Train net output #0: loss = 2.02869 (* 1 = 2.02869 loss)
I0420 13:31:04.474973 10752 sgd_solver.cpp:106] Iteration 70451200, lr = 3.9063e-07
I0420 13:36:10.744263 10752 solver.cpp:228] Iteration 70502400, loss = 2.34568
I0420 13:36:10.744333 10752 solver.cpp:244]     Train net output #0: loss = 2.25723 (* 1 = 2.25723 loss)
I0420 13:36:10.744339 10752 sgd_solver.cpp:106] Iteration 70502400, lr = 3.9063e-07
I0420 13:41:17.206044 10752 solver.cpp:228] Iteration 70553600, loss = 2.33442
I0420 13:41:17.206118 10752 solver.cpp:244]     Train net output #0: loss = 1.62991 (* 1 = 1.62991 loss)
I0420 13:41:17.206125 10752 sgd_solver.cpp:106] Iteration 70553600, lr = 3.9063e-07
I0420 13:46:23.528743 10752 solver.cpp:228] Iteration 70604800, loss = 2.34598
I0420 13:46:23.528826 10752 solver.cpp:244]     Train net output #0: loss = 2.63909 (* 1 = 2.63909 loss)
I0420 13:46:23.528833 10752 sgd_solver.cpp:106] Iteration 70604800, lr = 3.9063e-07
I0420 13:51:29.872953 10752 solver.cpp:337] Iteration 70656000, Testing net (#0)
I0420 13:51:48.153586 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0420 13:51:57.662912 10752 solver.cpp:404]     Test net output #0: accuracy = 0.4711
I0420 13:51:57.662947 10752 solver.cpp:404]     Test net output #1: loss = 2.36778 (* 1 = 2.36778 loss)
I0420 13:51:57.665488 10752 solver.cpp:228] Iteration 70656000, loss = 2.35424
I0420 13:51:57.665508 10752 solver.cpp:244]     Train net output #0: loss = 4.17177 (* 1 = 4.17177 loss)
I0420 13:51:57.665519 10752 sgd_solver.cpp:106] Iteration 70656000, lr = 3.9063e-07
I0420 13:57:04.191920 10752 solver.cpp:228] Iteration 70707200, loss = 2.35288
I0420 13:57:04.191994 10752 solver.cpp:244]     Train net output #0: loss = 2.01874 (* 1 = 2.01874 loss)
I0420 13:57:04.192003 10752 sgd_solver.cpp:106] Iteration 70707200, lr = 3.9063e-07
I0420 14:08:50.991930 10752 solver.cpp:228] Iteration 70758400, loss = 2.35166
I0420 14:08:50.992012 10752 solver.cpp:244]     Train net output #0: loss = 0.418732 (* 1 = 0.418732 loss)
I0420 14:08:50.992027 10752 sgd_solver.cpp:106] Iteration 70758400, lr = 3.9063e-07
I0420 14:23:21.992033 10752 solver.cpp:228] Iteration 70809600, loss = 2.33236
I0420 14:23:21.992105 10752 solver.cpp:244]     Train net output #0: loss = 5.56307 (* 1 = 5.56307 loss)
I0420 14:23:21.992117 10752 sgd_solver.cpp:106] Iteration 70809600, lr = 3.9063e-07
I0420 14:38:18.119735 10752 solver.cpp:228] Iteration 70860800, loss = 2.33162
I0420 14:38:18.119869 10752 solver.cpp:244]     Train net output #0: loss = 5.86686 (* 1 = 5.86686 loss)
I0420 14:38:18.119900 10752 sgd_solver.cpp:106] Iteration 70860800, lr = 3.9063e-07
I0420 14:52:38.885898 10752 solver.cpp:337] Iteration 70912000, Testing net (#0)
I0420 14:53:11.059027 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0420 14:53:15.527737 10752 solver.cpp:404]     Test net output #0: accuracy = 0.47184
I0420 14:53:15.527776 10752 solver.cpp:404]     Test net output #1: loss = 2.36665 (* 1 = 2.36665 loss)
I0420 14:53:15.530345 10752 solver.cpp:228] Iteration 70912000, loss = 2.31979
I0420 14:53:15.530364 10752 solver.cpp:244]     Train net output #0: loss = 0.803008 (* 1 = 0.803008 loss)
I0420 14:53:15.530375 10752 sgd_solver.cpp:106] Iteration 70912000, lr = 3.9063e-07
I0420 15:08:08.924073 10752 solver.cpp:228] Iteration 70963200, loss = 2.33703
I0420 15:08:09.095384 10752 solver.cpp:244]     Train net output #0: loss = 0.0430997 (* 1 = 0.0430997 loss)
I0420 15:08:09.095403 10752 sgd_solver.cpp:106] Iteration 70963200, lr = 3.9063e-07
I0420 15:22:37.479610 10752 solver.cpp:228] Iteration 71014400, loss = 2.31332
I0420 15:22:37.655961 10752 solver.cpp:244]     Train net output #0: loss = 5.18359 (* 1 = 5.18359 loss)
I0420 15:22:37.655978 10752 sgd_solver.cpp:106] Iteration 71014400, lr = 3.9063e-07
I0420 15:36:52.616412 10752 solver.cpp:228] Iteration 71065600, loss = 2.33146
I0420 15:36:52.617800 10752 solver.cpp:244]     Train net output #0: loss = 2.44572 (* 1 = 2.44572 loss)
I0420 15:36:52.617815 10752 sgd_solver.cpp:106] Iteration 71065600, lr = 3.9063e-07
I0420 15:51:49.293678 10752 solver.cpp:228] Iteration 71116800, loss = 2.31749
I0420 15:51:49.478531 10752 solver.cpp:244]     Train net output #0: loss = 0.0343063 (* 1 = 0.0343063 loss)
I0420 15:51:49.478549 10752 sgd_solver.cpp:106] Iteration 71116800, lr = 3.9063e-07
I0420 16:06:20.772703 10752 solver.cpp:337] Iteration 71168000, Testing net (#0)
I0420 16:06:57.698040 10752 solver.cpp:404]     Test net output #0: accuracy = 0.472
I0420 16:06:57.698140 10752 solver.cpp:404]     Test net output #1: loss = 2.36607 (* 1 = 2.36607 loss)
I0420 16:06:57.700948 10752 solver.cpp:228] Iteration 71168000, loss = 2.31587
I0420 16:06:57.700991 10752 solver.cpp:244]     Train net output #0: loss = 2.474 (* 1 = 2.474 loss)
I0420 16:06:57.701009 10752 sgd_solver.cpp:106] Iteration 71168000, lr = 3.9063e-07
I0420 16:21:51.203855 10752 solver.cpp:228] Iteration 71219200, loss = 2.35442
I0420 16:21:51.203975 10752 solver.cpp:244]     Train net output #0: loss = 3.92638 (* 1 = 3.92638 loss)
I0420 16:21:51.203987 10752 sgd_solver.cpp:106] Iteration 71219200, lr = 3.9063e-07
I0420 16:36:09.024225 10752 solver.cpp:228] Iteration 71270400, loss = 2.33659
I0420 16:36:09.028085 10752 solver.cpp:244]     Train net output #0: loss = 0.00167719 (* 1 = 0.00167719 loss)
I0420 16:36:09.028103 10752 sgd_solver.cpp:106] Iteration 71270400, lr = 3.9063e-07
I0420 16:49:31.331125 10752 solver.cpp:228] Iteration 71321600, loss = 2.34926
I0420 16:49:31.332506 10752 solver.cpp:244]     Train net output #0: loss = 0.00440116 (* 1 = 0.00440116 loss)
I0420 16:49:31.332521 10752 sgd_solver.cpp:106] Iteration 71321600, lr = 3.9063e-07
I0420 17:04:53.298522 10752 solver.cpp:228] Iteration 71372800, loss = 2.35533
I0420 17:04:53.467389 10752 solver.cpp:244]     Train net output #0: loss = 0.169548 (* 1 = 0.169548 loss)
I0420 17:04:53.467411 10752 sgd_solver.cpp:106] Iteration 71372800, lr = 3.9063e-07
I0420 17:19:13.328451 10752 solver.cpp:337] Iteration 71424000, Testing net (#0)
I0420 17:19:20.678513 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0420 17:19:50.661497 10752 solver.cpp:404]     Test net output #0: accuracy = 0.47158
I0420 17:19:50.661593 10752 solver.cpp:404]     Test net output #1: loss = 2.36898 (* 1 = 2.36898 loss)
I0420 17:19:50.665045 10752 solver.cpp:228] Iteration 71424000, loss = 2.32268
I0420 17:19:50.665076 10752 solver.cpp:244]     Train net output #0: loss = 1.36015 (* 1 = 1.36015 loss)
I0420 17:19:50.665086 10752 sgd_solver.cpp:106] Iteration 71424000, lr = 3.9063e-07
I0420 17:34:58.527331 10752 solver.cpp:228] Iteration 71475200, loss = 2.33228
I0420 17:34:58.527425 10752 solver.cpp:244]     Train net output #0: loss = 0.324429 (* 1 = 0.324429 loss)
I0420 17:34:58.527434 10752 sgd_solver.cpp:106] Iteration 71475200, lr = 3.9063e-07
I0420 17:49:45.920193 10752 solver.cpp:228] Iteration 71526400, loss = 2.3338
I0420 17:49:45.920289 10752 solver.cpp:244]     Train net output #0: loss = 2.8625 (* 1 = 2.8625 loss)
I0420 17:49:45.920302 10752 sgd_solver.cpp:106] Iteration 71526400, lr = 3.9063e-07
I0420 18:03:00.494158 10752 solver.cpp:228] Iteration 71577600, loss = 2.32796
I0420 18:03:00.494231 10752 solver.cpp:244]     Train net output #0: loss = 2.06977 (* 1 = 2.06977 loss)
I0420 18:03:00.494243 10752 sgd_solver.cpp:106] Iteration 71577600, lr = 3.9063e-07
I0420 18:17:39.220315 10752 solver.cpp:228] Iteration 71628800, loss = 2.32817
I0420 18:17:39.220393 10752 solver.cpp:244]     Train net output #0: loss = 5.86509 (* 1 = 5.86509 loss)
I0420 18:17:39.220404 10752 sgd_solver.cpp:106] Iteration 71628800, lr = 3.9063e-07
I0420 18:32:21.361280 10752 solver.cpp:454] Snapshotting to binary proto file snapshots/caffenet128_no_lrn_lsuv_relu_bs1_iter_71680000.caffemodel
I0420 18:32:21.759996 10752 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/caffenet128_no_lrn_lsuv_relu_bs1_iter_71680000.solverstate
I0420 18:32:21.859745 10752 solver.cpp:337] Iteration 71680000, Testing net (#0)
I0420 18:32:33.605496 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0420 18:32:55.451315 10752 solver.cpp:404]     Test net output #0: accuracy = 0.47156
I0420 18:32:55.451414 10752 solver.cpp:404]     Test net output #1: loss = 2.36678 (* 1 = 2.36678 loss)
I0420 18:32:55.467185 10752 solver.cpp:228] Iteration 71680000, loss = 2.30853
I0420 18:32:55.467284 10752 solver.cpp:244]     Train net output #0: loss = 4.47771 (* 1 = 4.47771 loss)
I0420 18:32:55.467303 10752 sgd_solver.cpp:106] Iteration 71680000, lr = 3.9063e-07
I0420 18:47:30.835814 10752 solver.cpp:228] Iteration 71731200, loss = 2.32669
I0420 18:47:30.835896 10752 solver.cpp:244]     Train net output #0: loss = 1.38054 (* 1 = 1.38054 loss)
I0420 18:47:30.835909 10752 sgd_solver.cpp:106] Iteration 71731200, lr = 3.9063e-07
I0420 19:02:19.690421 10752 solver.cpp:228] Iteration 71782400, loss = 2.34375
I0420 19:02:19.692265 10752 solver.cpp:244]     Train net output #0: loss = 0.029731 (* 1 = 0.029731 loss)
I0420 19:02:19.692276 10752 sgd_solver.cpp:106] Iteration 71782400, lr = 3.9063e-07
I0420 19:16:03.800019 10752 solver.cpp:228] Iteration 71833600, loss = 2.33193
I0420 19:16:03.970996 10752 solver.cpp:244]     Train net output #0: loss = 0.0505366 (* 1 = 0.0505366 loss)
I0420 19:16:03.971017 10752 sgd_solver.cpp:106] Iteration 71833600, lr = 3.9063e-07
I0420 19:31:21.365604 10752 solver.cpp:228] Iteration 71884800, loss = 2.33913
I0420 19:31:21.542080 10752 solver.cpp:244]     Train net output #0: loss = 2.43879 (* 1 = 2.43879 loss)
I0420 19:31:21.542094 10752 sgd_solver.cpp:106] Iteration 71884800, lr = 3.9063e-07
I0420 19:46:02.430862 10752 solver.cpp:337] Iteration 71936000, Testing net (#0)
I0420 19:46:16.283205 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0420 19:46:37.379703 10752 solver.cpp:404]     Test net output #0: accuracy = 0.47222
I0420 19:46:37.379794 10752 solver.cpp:404]     Test net output #1: loss = 2.36771 (* 1 = 2.36771 loss)
I0420 19:46:37.397636 10752 solver.cpp:228] Iteration 71936000, loss = 2.34169
I0420 19:46:37.397699 10752 solver.cpp:244]     Train net output #0: loss = 0.206628 (* 1 = 0.206628 loss)
I0420 19:46:37.397716 10752 sgd_solver.cpp:106] Iteration 71936000, lr = 3.9063e-07
I0420 20:01:08.802044 10752 solver.cpp:228] Iteration 71987200, loss = 2.3482
I0420 20:01:08.802156 10752 solver.cpp:244]     Train net output #0: loss = 0.448153 (* 1 = 0.448153 loss)
I0420 20:01:08.802178 10752 sgd_solver.cpp:106] Iteration 71987200, lr = 3.9063e-07
I0420 20:15:52.446766 10752 solver.cpp:228] Iteration 72038400, loss = 2.35021
I0420 20:15:52.448595 10752 solver.cpp:244]     Train net output #0: loss = 3.68828 (* 1 = 3.68828 loss)
I0420 20:15:52.448608 10752 sgd_solver.cpp:106] Iteration 72038400, lr = 3.9063e-07
I0420 20:30:17.161255 10752 solver.cpp:228] Iteration 72089600, loss = 2.33615
I0420 20:30:17.162688 10752 solver.cpp:244]     Train net output #0: loss = 2.06243 (* 1 = 2.06243 loss)
I0420 20:30:17.162700 10752 sgd_solver.cpp:106] Iteration 72089600, lr = 3.9063e-07
I0420 20:44:31.386512 10752 solver.cpp:228] Iteration 72140800, loss = 2.32427
I0420 20:44:31.387346 10752 solver.cpp:244]     Train net output #0: loss = 5.57204 (* 1 = 5.57204 loss)
I0420 20:44:31.387357 10752 sgd_solver.cpp:106] Iteration 72140800, lr = 3.9063e-07
I0420 20:58:16.052736 10752 solver.cpp:337] Iteration 72192000, Testing net (#0)
I0420 20:58:42.656900 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0420 20:58:54.336113 10752 solver.cpp:404]     Test net output #0: accuracy = 0.472
I0420 20:58:54.336326 10752 solver.cpp:404]     Test net output #1: loss = 2.36532 (* 1 = 2.36532 loss)
I0420 20:58:54.342445 10752 solver.cpp:228] Iteration 72192000, loss = 2.32287
I0420 20:58:54.342506 10752 solver.cpp:244]     Train net output #0: loss = 4.24323 (* 1 = 4.24323 loss)
I0420 20:58:54.342525 10752 sgd_solver.cpp:106] Iteration 72192000, lr = 3.9063e-07
I0420 21:12:26.160462 10752 solver.cpp:228] Iteration 72243200, loss = 2.34327
I0420 21:12:26.160552 10752 solver.cpp:244]     Train net output #0: loss = 0.176422 (* 1 = 0.176422 loss)
I0420 21:12:26.160562 10752 sgd_solver.cpp:106] Iteration 72243200, lr = 3.9063e-07
I0420 21:26:41.660315 10752 solver.cpp:228] Iteration 72294400, loss = 2.31771
I0420 21:26:41.662174 10752 solver.cpp:244]     Train net output #0: loss = 0.108084 (* 1 = 0.108084 loss)
I0420 21:26:41.662191 10752 sgd_solver.cpp:106] Iteration 72294400, lr = 3.9063e-07
I0420 21:40:27.665253 10752 solver.cpp:228] Iteration 72345600, loss = 2.32125
I0420 21:40:27.666375 10752 solver.cpp:244]     Train net output #0: loss = 2.06935 (* 1 = 2.06935 loss)
I0420 21:40:27.666393 10752 sgd_solver.cpp:106] Iteration 72345600, lr = 3.9063e-07
I0420 21:54:15.433092 10752 solver.cpp:228] Iteration 72396800, loss = 2.31972
I0420 21:54:15.602823 10752 solver.cpp:244]     Train net output #0: loss = 3.23465 (* 1 = 3.23465 loss)
I0420 21:54:15.602841 10752 sgd_solver.cpp:106] Iteration 72396800, lr = 3.9063e-07
I0420 22:07:33.858314 10752 solver.cpp:337] Iteration 72448000, Testing net (#0)
I0420 22:08:09.392282 10752 blocking_queue.cpp:50] Data layer prefetch queue empty
I0420 22:08:13.811234 10752 solver.cpp:404]     Test net output #0: accuracy = 0.47212
I0420 22:08:13.811269 10752 solver.cpp:404]     Test net output #1: loss = 2.3661 (* 1 = 2.3661 loss)
I0420 22:08:13.831656 10752 solver.cpp:228] Iteration 72448000, loss = 2.31487
I0420 22:08:13.831764 10752 solver.cpp:244]     Train net output #0: loss = 4.52547 (* 1 = 4.52547 loss)
I0420 22:08:13.831784 10752 sgd_solver.cpp:106] Iteration 72448000, lr = 3.9063e-07
I0420 22:23:14.100292 10752 solver.cpp:228] Iteration 72499200, loss = 2.36202
I0420 22:23:14.100363 10752 solver.cpp:244]     Train net output #0: loss = 5.55417 (* 1 = 5.55417 loss)
I0420 22:23:14.100375 10752 sgd_solver.cpp:106] Iteration 72499200, lr = 3.9063e-07
I0420 22:37:50.409329 10752 solver.cpp:228] Iteration 72550400, loss = 2.34251
I0420 22:37:50.409399 10752 solver.cpp:244]     Train net output #0: loss = 0.73955 (* 1 = 0.73955 loss)
I0420 22:37:50.409414 10752 sgd_solver.cpp:106] Iteration 72550400, lr = 3.9063e-07
I0420 22:51:18.174854 10752 solver.cpp:228] Iteration 72601600, loss = 2.35044
I0420 22:51:18.174923 10752 solver.cpp:244]     Train net output #0: loss = 1.57167 (* 1 = 1.57167 loss)
I0420 22:51:18.174934 10752 sgd_solver.cpp:106] Iteration 72601600, lr = 3.9063e-07
I0420 23:03:56.888872 10752 solver.cpp:454] Snapshotting to binary proto file snapshots/caffenet128_no_lrn_lsuv_relu_bs1_iter_72648645.caffemodel
I0420 23:03:57.733610 10752 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/caffenet128_no_lrn_lsuv_relu_bs1_iter_72648645.solverstate
I0420 23:03:57.812480 10752 solver.cpp:301] Optimization stopped early.
I0420 23:03:57.814319 10752 caffe.cpp:222] Optimization Done.
I0421 00:09:36.453300 16809 upgrade_proto.cpp:1044] Attempting to upgrade input file specified using deprecated 'solver_type' field (enum)': done/caffenet128_lsuv_online_lr0000039063.prototxt
I0421 00:09:36.454037 16809 upgrade_proto.cpp:1051] Successfully upgraded file specified using deprecated 'solver_type' field (enum) to 'type' field (string).
W0421 00:09:36.454046 16809 upgrade_proto.cpp:1053] Note that future Caffe releases will only support 'type' field (string) for a solver's type.
I0421 00:09:36.454180 16809 caffe.cpp:185] Using GPUs 0
I0421 00:09:36.478476 16809 caffe.cpp:190] GPU 0: GeForce GTX TITAN X
I0421 00:09:36.840945 16809 solver.cpp:48] Initializing solver from parameters: 
test_iter: 1000
test_interval: 256000
base_lr: 3.9063e-05
display: 51200
max_iter: 81920000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 25600000
snapshot: 2560000
snapshot_prefix: "snapshots/caffenet128_no_lrn_lsuv_relu_bs1"
solver_mode: GPU
device_id: 0
net_param {
  name: "CaffeNet"
  layer {
    name: "data"
    type: "Data"
    top: "data"
    top: "label"
    include {
      phase: TRAIN
    }
    transform_param {
      scale: 0.04
      mirror: true
      crop_size: 128
      mean_value: 104
      mean_value: 117
      mean_value: 124
      force_color: true
    }
    data_param {
      source: "/home/old-ufo/storage/datasets/imagenet/imgs128/lmdb/ilsvrc12_128_train_lmdb"
      batch_size: 1
      backend: LMDB
    }
  }
  layer {
    name: "data"
    type: "Data"
    top: "data"
    top: "label"
    include {
      phase: TEST
    }
    transform_param {
      scale: 0.04
      mirror: false
      crop_size: 128
      mean_value: 104
      mean_value: 117
      mean_value: 123
      force_color: true
    }
    data_param {
      source: "/home/old-ufo/storage/datasets/imagenet/imgs128/lmdb/ilsvrc12_128_val_lmdb"
      batch_size: 50
      backend: LMDB
    }
  }
  layer {
    name: "conv1"
    type: "Convolution"
    bottom: "data"
    top: "conv1"
    param {
      lr_mult: 1
      decay_mult: 1
    }
    param {
      lr_mult: 2
      decay_mult: 0
    }
    convolution_param {
      num_output: 96
      kernel_size: 11
      stride: 4
      weight_filler {
        type: "gaussian"
        std: 0.01
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layer {
    name: "relu1"
    type: "ReLU"
    bottom: "conv1"
    top: "relu1"
  }
  layer {
    name: "pool1"
    type: "Pooling"
    bottom: "relu1"
    top: "pool1"
    pooling_param {
      pool: MAX
      kernel_size: 3
      stride: 2
    }
  }
  layer {
    name: "conv2"
    type: "Convolution"
    bottom: "pool1"
    top: "conv2"
    param {
      lr_mult: 1
      decay_mult: 1
    }
    param {
      lr_mult: 2
      decay_mult: 0
    }
    convolution_param {
      num_output: 256
      pad: 2
      kernel_size: 5
      group: 2
      weight_filler {
        type: "gaussian"
        std: 0.01
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layer {
    name: "relu2"
    type: "ReLU"
    bottom: "conv2"
    top: "relu2"
  }
  layer {
    name: "pool2"
    type: "Pooling"
    bottom: "relu2"
    top: "pool2"
    pooling_param {
      pool: MAX
      kernel_size: 3
      stride: 2
    }
  }
  layer {
    name: "conv3"
    type: "Convolution"
    bottom: "pool2"
    top: "conv3"
    param {
      lr_mult: 1
      decay_mult: 1
    }
    param {
      lr_mult: 2
      decay_mult: 0
    }
    convolution_param {
      num_output: 384
      pad: 1
      kernel_size: 3
      weight_filler {
        type: "gaussian"
        std: 0.01
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layer {
    name: "relu3"
    type: "ReLU"
    bottom: "conv3"
    top: "relu3"
  }
  layer {
    name: "conv4"
    type: "Convolution"
    bottom: "relu3"
    top: "conv4"
    param {
      lr_mult: 1
      decay_mult: 1
    }
    param {
      lr_mult: 2
      decay_mult: 0
    }
    convolution_param {
      num_output: 384
      pad: 1
      kernel_size: 3
      group: 2
      weight_filler {
        type: "gaussian"
        std: 0.01
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layer {
    name: "relu4"
    type: "ReLU"
    bottom: "conv4"
    top: "relu4"
  }
  layer {
    name: "conv5"
    type: "Convolution"
    bottom: "relu4"
    top: "conv5"
    param {
      lr_mult: 1
      decay_mult: 1
    }
    param {
      lr_mult: 2
      decay_mult: 0
    }
    convolution_param {
      num_output: 256
      pad: 1
      kernel_size: 3
      group: 2
      weight_filler {
        type: "gaussian"
        std: 0.01
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layer {
    name: "relu5"
    type: "ReLU"
    bottom: "conv5"
    top: "relu5"
  }
  layer {
    name: "pool5"
    type: "Pooling"
    bottom: "relu5"
    top: "pool5"
    pooling_param {
      pool: MAX
      kernel_size: 3
      stride: 2
    }
  }
  layer {
    name: "fc6"
    type: "InnerProduct"
    bottom: "pool5"
    top: "fc6"
    param {
      lr_mult: 1
      decay_mult: 1
    }
    param {
      lr_mult: 2
      decay_mult: 0
    }
    inner_product_param {
      num_output: 2048
      weight_filler {
        type: "gaussian"
        std: 0.005
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layer {
    name: "relu6"
    type: "ReLU"
    bottom: "fc6"
    top: "relu6"
  }
  layer {
    name: "drop6"
    type: "Dropout"
    bottom: "relu6"
    top: "drop6"
    dropout_param {
      dropout_ratio: 0.5
    }
  }
  layer {
    name: "fc7"
    type: "InnerProduct"
    bottom: "drop6"
    top: "fc7"
    param {
      lr_mult: 1
      decay_mult: 1
    }
    param {
      lr_mult: 2
      decay_mult: 0
    }
    inner_product_param {
      num_output: 2048
      weight_filler {
        type: "gaussian"
        std: 0.005
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layer {
    name: "relu7"
    type: "ReLU"
    bottom: "fc7"
    top: "relu7"
  }
  layer {
    name: "drop7"
    type: "Dropout"
    bottom: "relu7"
    top: "drop7"
    dropout_param {
      dropout_ratio: 0.5
    }
  }
  layer {
    name: "fc8"
    type: "InnerProduct"
    bottom: "drop7"
    top: "fc8"
    param {
      lr_mult: 1
      decay_mult: 1
    }
    param {
      lr_mult: 2
      decay_mult: 0
    }
    inner_product_param {
      num_output: 1000
      weight_filler {
        type: "gaussian"
        std: 0.01
      }
      bias_filler {
        type: "constant"
      }
    }
  }
  layer {
    name: "accuracy"
    type: "Accuracy"
    bottom: "fc8"
    bottom: "label"
    top: "accuracy"
    include {
      phase: TEST
    }
  }
  layer {
    name: "loss"
    type: "SoftmaxWithLoss"
    bottom: "fc8"
    bottom: "label"
    top: "loss"
  }
}
test_initialization: true
average_loss: 51200
iter_size: 1
type: "SGD"
I0421 00:09:36.841744 16809 solver.cpp:86] Creating training net specified in net_param.
I0421 00:09:36.841830 16809 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0421 00:09:36.841857 16809 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0421 00:09:36.842003 16809 net.cpp:49] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.04
    mirror: true
    crop_size: 128
    mean_value: 104
    mean_value: 117
    mean_value: 124
    force_color: true
  }
  data_param {
    source: "/home/old-ufo/storage/datasets/imagenet/imgs128/lmdb/ilsvrc12_128_train_lmdb"
    batch_size: 1
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "relu1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "relu1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "relu2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "relu2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "relu3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "relu3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "relu4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "relu4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "relu5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "relu5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "relu6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "relu6"
  top: "drop6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "drop6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "relu7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "relu7"
  top: "drop7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "drop7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0421 00:09:36.842511 16809 layer_factory.hpp:77] Creating layer data
I0421 00:09:36.843171 16809 net.cpp:91] Creating Layer data
I0421 00:09:36.843189 16809 net.cpp:399] data -> data
I0421 00:09:36.843224 16809 net.cpp:399] data -> label
I0421 00:09:36.844000 16815 db_lmdb.cpp:38] Opened lmdb /home/old-ufo/storage/datasets/imagenet/imgs128/lmdb/ilsvrc12_128_train_lmdb
I0421 00:09:36.853693 16809 data_layer.cpp:41] output data size: 1,3,128,128
I0421 00:09:36.854452 16809 net.cpp:141] Setting up data
I0421 00:09:36.854473 16809 net.cpp:148] Top shape: 1 3 128 128 (49152)
I0421 00:09:36.854499 16809 net.cpp:148] Top shape: 1 (1)
I0421 00:09:36.854506 16809 net.cpp:156] Memory required for data: 196612
I0421 00:09:36.854517 16809 layer_factory.hpp:77] Creating layer conv1
I0421 00:09:36.854544 16809 net.cpp:91] Creating Layer conv1
I0421 00:09:36.854553 16809 net.cpp:425] conv1 <- data
I0421 00:09:36.854569 16809 net.cpp:399] conv1 -> conv1
I0421 00:09:37.710556 16809 net.cpp:141] Setting up conv1
I0421 00:09:37.710588 16809 net.cpp:148] Top shape: 1 96 30 30 (86400)
I0421 00:09:37.710595 16809 net.cpp:156] Memory required for data: 542212
I0421 00:09:37.710682 16809 layer_factory.hpp:77] Creating layer relu1
I0421 00:09:37.711094 16809 net.cpp:91] Creating Layer relu1
I0421 00:09:37.711158 16809 net.cpp:425] relu1 <- conv1
I0421 00:09:37.711215 16809 net.cpp:399] relu1 -> relu1
I0421 00:09:37.711596 16809 net.cpp:141] Setting up relu1
I0421 00:09:37.711665 16809 net.cpp:148] Top shape: 1 96 30 30 (86400)
I0421 00:09:37.711716 16809 net.cpp:156] Memory required for data: 887812
I0421 00:09:37.711766 16809 layer_factory.hpp:77] Creating layer pool1
I0421 00:09:37.711820 16809 net.cpp:91] Creating Layer pool1
I0421 00:09:37.711870 16809 net.cpp:425] pool1 <- relu1
I0421 00:09:37.711923 16809 net.cpp:399] pool1 -> pool1
I0421 00:09:37.712031 16809 net.cpp:141] Setting up pool1
I0421 00:09:37.712090 16809 net.cpp:148] Top shape: 1 96 15 15 (21600)
I0421 00:09:37.712138 16809 net.cpp:156] Memory required for data: 974212
I0421 00:09:37.712187 16809 layer_factory.hpp:77] Creating layer conv2
I0421 00:09:37.712246 16809 net.cpp:91] Creating Layer conv2
I0421 00:09:37.712297 16809 net.cpp:425] conv2 <- pool1
I0421 00:09:37.712350 16809 net.cpp:399] conv2 -> conv2
I0421 00:09:37.726060 16809 net.cpp:141] Setting up conv2
I0421 00:09:37.726202 16809 net.cpp:148] Top shape: 1 256 15 15 (57600)
I0421 00:09:37.726265 16809 net.cpp:156] Memory required for data: 1204612
I0421 00:09:37.726347 16809 layer_factory.hpp:77] Creating layer relu2
I0421 00:09:37.726409 16809 net.cpp:91] Creating Layer relu2
I0421 00:09:37.726462 16809 net.cpp:425] relu2 <- conv2
I0421 00:09:37.726518 16809 net.cpp:399] relu2 -> relu2
I0421 00:09:37.726898 16809 net.cpp:141] Setting up relu2
I0421 00:09:37.726968 16809 net.cpp:148] Top shape: 1 256 15 15 (57600)
I0421 00:09:37.727018 16809 net.cpp:156] Memory required for data: 1435012
I0421 00:09:37.727079 16809 layer_factory.hpp:77] Creating layer pool2
I0421 00:09:37.727134 16809 net.cpp:91] Creating Layer pool2
I0421 00:09:37.727185 16809 net.cpp:425] pool2 <- relu2
I0421 00:09:37.727237 16809 net.cpp:399] pool2 -> pool2
I0421 00:09:37.727331 16809 net.cpp:141] Setting up pool2
I0421 00:09:37.727388 16809 net.cpp:148] Top shape: 1 256 7 7 (12544)
I0421 00:09:37.727437 16809 net.cpp:156] Memory required for data: 1485188
I0421 00:09:37.727485 16809 layer_factory.hpp:77] Creating layer conv3
I0421 00:09:37.727545 16809 net.cpp:91] Creating Layer conv3
I0421 00:09:37.727594 16809 net.cpp:425] conv3 <- pool2
I0421 00:09:37.727648 16809 net.cpp:399] conv3 -> conv3
I0421 00:09:37.763543 16809 net.cpp:141] Setting up conv3
I0421 00:09:37.763628 16809 net.cpp:148] Top shape: 1 384 7 7 (18816)
I0421 00:09:37.763658 16809 net.cpp:156] Memory required for data: 1560452
I0421 00:09:37.763691 16809 layer_factory.hpp:77] Creating layer relu3
I0421 00:09:37.763722 16809 net.cpp:91] Creating Layer relu3
I0421 00:09:37.763743 16809 net.cpp:425] relu3 <- conv3
I0421 00:09:37.763767 16809 net.cpp:399] relu3 -> relu3
I0421 00:09:37.764930 16809 net.cpp:141] Setting up relu3
I0421 00:09:37.764961 16809 net.cpp:148] Top shape: 1 384 7 7 (18816)
I0421 00:09:37.764979 16809 net.cpp:156] Memory required for data: 1635716
I0421 00:09:37.764998 16809 layer_factory.hpp:77] Creating layer conv4
I0421 00:09:37.765027 16809 net.cpp:91] Creating Layer conv4
I0421 00:09:37.765046 16809 net.cpp:425] conv4 <- relu3
I0421 00:09:37.765067 16809 net.cpp:399] conv4 -> conv4
I0421 00:09:37.797369 16809 net.cpp:141] Setting up conv4
I0421 00:09:37.797456 16809 net.cpp:148] Top shape: 1 384 7 7 (18816)
I0421 00:09:37.797503 16809 net.cpp:156] Memory required for data: 1710980
I0421 00:09:37.797533 16809 layer_factory.hpp:77] Creating layer relu4
I0421 00:09:37.797559 16809 net.cpp:91] Creating Layer relu4
I0421 00:09:37.797580 16809 net.cpp:425] relu4 <- conv4
I0421 00:09:37.797603 16809 net.cpp:399] relu4 -> relu4
I0421 00:09:37.799665 16809 net.cpp:141] Setting up relu4
I0421 00:09:37.799697 16809 net.cpp:148] Top shape: 1 384 7 7 (18816)
I0421 00:09:37.799717 16809 net.cpp:156] Memory required for data: 1786244
I0421 00:09:37.799736 16809 layer_factory.hpp:77] Creating layer conv5
I0421 00:09:37.799765 16809 net.cpp:91] Creating Layer conv5
I0421 00:09:37.799784 16809 net.cpp:425] conv5 <- relu4
I0421 00:09:37.799806 16809 net.cpp:399] conv5 -> conv5
I0421 00:09:37.824810 16809 net.cpp:141] Setting up conv5
I0421 00:09:37.824883 16809 net.cpp:148] Top shape: 1 256 7 7 (12544)
I0421 00:09:37.824909 16809 net.cpp:156] Memory required for data: 1836420
I0421 00:09:37.824945 16809 layer_factory.hpp:77] Creating layer relu5
I0421 00:09:37.824973 16809 net.cpp:91] Creating Layer relu5
I0421 00:09:37.824993 16809 net.cpp:425] relu5 <- conv5
I0421 00:09:37.825016 16809 net.cpp:399] relu5 -> relu5
I0421 00:09:37.825842 16809 net.cpp:141] Setting up relu5
I0421 00:09:37.825876 16809 net.cpp:148] Top shape: 1 256 7 7 (12544)
I0421 00:09:37.825893 16809 net.cpp:156] Memory required for data: 1886596
I0421 00:09:37.825911 16809 layer_factory.hpp:77] Creating layer pool5
I0421 00:09:37.825933 16809 net.cpp:91] Creating Layer pool5
I0421 00:09:37.825954 16809 net.cpp:425] pool5 <- relu5
I0421 00:09:37.825978 16809 net.cpp:399] pool5 -> pool5
I0421 00:09:37.826043 16809 net.cpp:141] Setting up pool5
I0421 00:09:37.826066 16809 net.cpp:148] Top shape: 1 256 3 3 (2304)
I0421 00:09:37.826084 16809 net.cpp:156] Memory required for data: 1895812
I0421 00:09:37.826102 16809 layer_factory.hpp:77] Creating layer fc6
I0421 00:09:37.827574 16809 net.cpp:91] Creating Layer fc6
I0421 00:09:37.827606 16809 net.cpp:425] fc6 <- pool5
I0421 00:09:37.827630 16809 net.cpp:399] fc6 -> fc6
I0421 00:09:37.962023 16809 net.cpp:141] Setting up fc6
I0421 00:09:37.962051 16809 net.cpp:148] Top shape: 1 2048 (2048)
I0421 00:09:37.962055 16809 net.cpp:156] Memory required for data: 1904004
I0421 00:09:37.962067 16809 layer_factory.hpp:77] Creating layer relu6
I0421 00:09:37.962079 16809 net.cpp:91] Creating Layer relu6
I0421 00:09:37.962085 16809 net.cpp:425] relu6 <- fc6
I0421 00:09:37.962095 16809 net.cpp:399] relu6 -> relu6
I0421 00:09:37.962424 16809 net.cpp:141] Setting up relu6
I0421 00:09:37.962436 16809 net.cpp:148] Top shape: 1 2048 (2048)
I0421 00:09:37.962441 16809 net.cpp:156] Memory required for data: 1912196
I0421 00:09:37.962446 16809 layer_factory.hpp:77] Creating layer drop6
I0421 00:09:37.962486 16809 net.cpp:91] Creating Layer drop6
I0421 00:09:37.962493 16809 net.cpp:425] drop6 <- relu6
I0421 00:09:37.962502 16809 net.cpp:399] drop6 -> drop6
I0421 00:09:37.962545 16809 net.cpp:141] Setting up drop6
I0421 00:09:37.962554 16809 net.cpp:148] Top shape: 1 2048 (2048)
I0421 00:09:37.962558 16809 net.cpp:156] Memory required for data: 1920388
I0421 00:09:37.962564 16809 layer_factory.hpp:77] Creating layer fc7
I0421 00:09:37.962574 16809 net.cpp:91] Creating Layer fc7
I0421 00:09:37.962579 16809 net.cpp:425] fc7 <- drop6
I0421 00:09:37.962587 16809 net.cpp:399] fc7 -> fc7
I0421 00:09:38.080420 16809 net.cpp:141] Setting up fc7
I0421 00:09:38.080453 16809 net.cpp:148] Top shape: 1 2048 (2048)
I0421 00:09:38.080459 16809 net.cpp:156] Memory required for data: 1928580
I0421 00:09:38.080474 16809 layer_factory.hpp:77] Creating layer relu7
I0421 00:09:38.080490 16809 net.cpp:91] Creating Layer relu7
I0421 00:09:38.080497 16809 net.cpp:425] relu7 <- fc7
I0421 00:09:38.080507 16809 net.cpp:399] relu7 -> relu7
I0421 00:09:38.080765 16809 net.cpp:141] Setting up relu7
I0421 00:09:38.080778 16809 net.cpp:148] Top shape: 1 2048 (2048)
I0421 00:09:38.080783 16809 net.cpp:156] Memory required for data: 1936772
I0421 00:09:38.080790 16809 layer_factory.hpp:77] Creating layer drop7
I0421 00:09:38.080821 16809 net.cpp:91] Creating Layer drop7
I0421 00:09:38.080829 16809 net.cpp:425] drop7 <- relu7
I0421 00:09:38.080837 16809 net.cpp:399] drop7 -> drop7
I0421 00:09:38.080884 16809 net.cpp:141] Setting up drop7
I0421 00:09:38.080893 16809 net.cpp:148] Top shape: 1 2048 (2048)
I0421 00:09:38.080898 16809 net.cpp:156] Memory required for data: 1944964
I0421 00:09:38.080902 16809 layer_factory.hpp:77] Creating layer fc8
I0421 00:09:38.080914 16809 net.cpp:91] Creating Layer fc8
I0421 00:09:38.080919 16809 net.cpp:425] fc8 <- drop7
I0421 00:09:38.080927 16809 net.cpp:399] fc8 -> fc8
I0421 00:09:38.145464 16809 net.cpp:141] Setting up fc8
I0421 00:09:38.145493 16809 net.cpp:148] Top shape: 1 1000 (1000)
I0421 00:09:38.145498 16809 net.cpp:156] Memory required for data: 1948964
I0421 00:09:38.145509 16809 layer_factory.hpp:77] Creating layer loss
I0421 00:09:38.145520 16809 net.cpp:91] Creating Layer loss
I0421 00:09:38.145529 16809 net.cpp:425] loss <- fc8
I0421 00:09:38.145535 16809 net.cpp:425] loss <- label
I0421 00:09:38.145544 16809 net.cpp:399] loss -> loss
I0421 00:09:38.145565 16809 layer_factory.hpp:77] Creating layer loss
I0421 00:09:38.145985 16809 net.cpp:141] Setting up loss
I0421 00:09:38.145998 16809 net.cpp:148] Top shape: (1)
I0421 00:09:38.146003 16809 net.cpp:151]     with loss weight 1
I0421 00:09:38.146021 16809 net.cpp:156] Memory required for data: 1948968
I0421 00:09:38.146025 16809 net.cpp:217] loss needs backward computation.
I0421 00:09:38.146030 16809 net.cpp:217] fc8 needs backward computation.
I0421 00:09:38.146034 16809 net.cpp:217] drop7 needs backward computation.
I0421 00:09:38.146039 16809 net.cpp:217] relu7 needs backward computation.
I0421 00:09:38.146042 16809 net.cpp:217] fc7 needs backward computation.
I0421 00:09:38.146046 16809 net.cpp:217] drop6 needs backward computation.
I0421 00:09:38.146050 16809 net.cpp:217] relu6 needs backward computation.
I0421 00:09:38.146054 16809 net.cpp:217] fc6 needs backward computation.
I0421 00:09:38.146059 16809 net.cpp:217] pool5 needs backward computation.
I0421 00:09:38.146062 16809 net.cpp:217] relu5 needs backward computation.
I0421 00:09:38.146066 16809 net.cpp:217] conv5 needs backward computation.
I0421 00:09:38.146070 16809 net.cpp:217] relu4 needs backward computation.
I0421 00:09:38.146075 16809 net.cpp:217] conv4 needs backward computation.
I0421 00:09:38.146078 16809 net.cpp:217] relu3 needs backward computation.
I0421 00:09:38.146082 16809 net.cpp:217] conv3 needs backward computation.
I0421 00:09:38.146086 16809 net.cpp:217] pool2 needs backward computation.
I0421 00:09:38.146090 16809 net.cpp:217] relu2 needs backward computation.
I0421 00:09:38.146095 16809 net.cpp:217] conv2 needs backward computation.
I0421 00:09:38.146098 16809 net.cpp:217] pool1 needs backward computation.
I0421 00:09:38.146102 16809 net.cpp:217] relu1 needs backward computation.
I0421 00:09:38.146106 16809 net.cpp:217] conv1 needs backward computation.
I0421 00:09:38.146111 16809 net.cpp:219] data does not need backward computation.
I0421 00:09:38.146116 16809 net.cpp:261] This network produces output loss
I0421 00:09:38.146134 16809 net.cpp:274] Network initialization done.
I0421 00:09:38.146265 16809 solver.cpp:181] Creating test net (#0) specified by net_param
I0421 00:09:38.146319 16809 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0421 00:09:38.146482 16809 net.cpp:49] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.04
    mirror: false
    crop_size: 128
    mean_value: 104
    mean_value: 117
    mean_value: 123
    force_color: true
  }
  data_param {
    source: "/home/old-ufo/storage/datasets/imagenet/imgs128/lmdb/ilsvrc12_128_val_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "relu1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "relu1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "relu2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "relu2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "relu3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "relu3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "relu4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "relu4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "relu5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "relu5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "relu6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "relu6"
  top: "drop6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "drop6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "relu7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "relu7"
  top: "drop7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "drop7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0421 00:09:38.146631 16809 layer_factory.hpp:77] Creating layer data
I0421 00:09:38.146719 16809 net.cpp:91] Creating Layer data
I0421 00:09:38.146728 16809 net.cpp:399] data -> data
I0421 00:09:38.146741 16809 net.cpp:399] data -> label
I0421 00:09:38.147811 16818 db_lmdb.cpp:38] Opened lmdb /home/old-ufo/storage/datasets/imagenet/imgs128/lmdb/ilsvrc12_128_val_lmdb
I0421 00:09:38.148607 16809 data_layer.cpp:41] output data size: 50,3,128,128
I0421 00:09:38.165020 16809 net.cpp:141] Setting up data
I0421 00:09:38.165093 16809 net.cpp:148] Top shape: 50 3 128 128 (2457600)
I0421 00:09:38.165114 16809 net.cpp:148] Top shape: 50 (50)
I0421 00:09:38.165132 16809 net.cpp:156] Memory required for data: 9830600
I0421 00:09:38.165153 16809 layer_factory.hpp:77] Creating layer label_data_1_split
I0421 00:09:38.165179 16809 net.cpp:91] Creating Layer label_data_1_split
I0421 00:09:38.165199 16809 net.cpp:425] label_data_1_split <- label
I0421 00:09:38.165223 16809 net.cpp:399] label_data_1_split -> label_data_1_split_0
I0421 00:09:38.165249 16809 net.cpp:399] label_data_1_split -> label_data_1_split_1
I0421 00:09:38.165336 16809 net.cpp:141] Setting up label_data_1_split
I0421 00:09:38.165362 16809 net.cpp:148] Top shape: 50 (50)
I0421 00:09:38.165383 16809 net.cpp:148] Top shape: 50 (50)
I0421 00:09:38.165400 16809 net.cpp:156] Memory required for data: 9831000
I0421 00:09:38.165416 16809 layer_factory.hpp:77] Creating layer conv1
I0421 00:09:38.165444 16809 net.cpp:91] Creating Layer conv1
I0421 00:09:38.165463 16809 net.cpp:425] conv1 <- data
I0421 00:09:38.165484 16809 net.cpp:399] conv1 -> conv1
I0421 00:09:38.168627 16809 net.cpp:141] Setting up conv1
I0421 00:09:38.168666 16809 net.cpp:148] Top shape: 50 96 30 30 (4320000)
I0421 00:09:38.168684 16809 net.cpp:156] Memory required for data: 27111000
I0421 00:09:38.168714 16809 layer_factory.hpp:77] Creating layer relu1
I0421 00:09:38.168735 16809 net.cpp:91] Creating Layer relu1
I0421 00:09:38.168753 16809 net.cpp:425] relu1 <- conv1
I0421 00:09:38.168776 16809 net.cpp:399] relu1 -> relu1
I0421 00:09:38.168992 16809 net.cpp:141] Setting up relu1
I0421 00:09:38.169019 16809 net.cpp:148] Top shape: 50 96 30 30 (4320000)
I0421 00:09:38.169039 16809 net.cpp:156] Memory required for data: 44391000
I0421 00:09:38.169065 16809 layer_factory.hpp:77] Creating layer pool1
I0421 00:09:38.169090 16809 net.cpp:91] Creating Layer pool1
I0421 00:09:38.169108 16809 net.cpp:425] pool1 <- relu1
I0421 00:09:38.169129 16809 net.cpp:399] pool1 -> pool1
I0421 00:09:38.169191 16809 net.cpp:141] Setting up pool1
I0421 00:09:38.169214 16809 net.cpp:148] Top shape: 50 96 15 15 (1080000)
I0421 00:09:38.169231 16809 net.cpp:156] Memory required for data: 48711000
I0421 00:09:38.169248 16809 layer_factory.hpp:77] Creating layer conv2
I0421 00:09:38.169272 16809 net.cpp:91] Creating Layer conv2
I0421 00:09:38.169291 16809 net.cpp:425] conv2 <- pool1
I0421 00:09:38.169312 16809 net.cpp:399] conv2 -> conv2
I0421 00:09:38.182297 16809 net.cpp:141] Setting up conv2
I0421 00:09:38.182364 16809 net.cpp:148] Top shape: 50 256 15 15 (2880000)
I0421 00:09:38.182381 16809 net.cpp:156] Memory required for data: 60231000
I0421 00:09:38.182413 16809 layer_factory.hpp:77] Creating layer relu2
I0421 00:09:38.182438 16809 net.cpp:91] Creating Layer relu2
I0421 00:09:38.182454 16809 net.cpp:425] relu2 <- conv2
I0421 00:09:38.182473 16809 net.cpp:399] relu2 -> relu2
I0421 00:09:38.182817 16809 net.cpp:141] Setting up relu2
I0421 00:09:38.182844 16809 net.cpp:148] Top shape: 50 256 15 15 (2880000)
I0421 00:09:38.182859 16809 net.cpp:156] Memory required for data: 71751000
I0421 00:09:38.182874 16809 layer_factory.hpp:77] Creating layer pool2
I0421 00:09:38.182893 16809 net.cpp:91] Creating Layer pool2
I0421 00:09:38.182907 16809 net.cpp:425] pool2 <- relu2
I0421 00:09:38.182924 16809 net.cpp:399] pool2 -> pool2
I0421 00:09:38.182982 16809 net.cpp:141] Setting up pool2
I0421 00:09:38.183003 16809 net.cpp:148] Top shape: 50 256 7 7 (627200)
I0421 00:09:38.183017 16809 net.cpp:156] Memory required for data: 74259800
I0421 00:09:38.183048 16809 layer_factory.hpp:77] Creating layer conv3
I0421 00:09:38.183073 16809 net.cpp:91] Creating Layer conv3
I0421 00:09:38.183089 16809 net.cpp:425] conv3 <- pool2
I0421 00:09:38.183107 16809 net.cpp:399] conv3 -> conv3
I0421 00:09:38.216503 16809 net.cpp:141] Setting up conv3
I0421 00:09:38.216572 16809 net.cpp:148] Top shape: 50 384 7 7 (940800)
I0421 00:09:38.216593 16809 net.cpp:156] Memory required for data: 78023000
I0421 00:09:38.216622 16809 layer_factory.hpp:77] Creating layer relu3
I0421 00:09:38.216648 16809 net.cpp:91] Creating Layer relu3
I0421 00:09:38.216670 16809 net.cpp:425] relu3 <- conv3
I0421 00:09:38.216706 16809 net.cpp:399] relu3 -> relu3
I0421 00:09:38.217118 16809 net.cpp:141] Setting up relu3
I0421 00:09:38.217147 16809 net.cpp:148] Top shape: 50 384 7 7 (940800)
I0421 00:09:38.217164 16809 net.cpp:156] Memory required for data: 81786200
I0421 00:09:38.217178 16809 layer_factory.hpp:77] Creating layer conv4
I0421 00:09:38.217202 16809 net.cpp:91] Creating Layer conv4
I0421 00:09:38.217221 16809 net.cpp:425] conv4 <- relu3
I0421 00:09:38.217241 16809 net.cpp:399] conv4 -> conv4
I0421 00:09:38.242949 16809 net.cpp:141] Setting up conv4
I0421 00:09:38.243017 16809 net.cpp:148] Top shape: 50 384 7 7 (940800)
I0421 00:09:38.243037 16809 net.cpp:156] Memory required for data: 85549400
I0421 00:09:38.243059 16809 layer_factory.hpp:77] Creating layer relu4
I0421 00:09:38.243083 16809 net.cpp:91] Creating Layer relu4
I0421 00:09:38.243099 16809 net.cpp:425] relu4 <- conv4
I0421 00:09:38.243119 16809 net.cpp:399] relu4 -> relu4
I0421 00:09:38.243480 16809 net.cpp:141] Setting up relu4
I0421 00:09:38.243508 16809 net.cpp:148] Top shape: 50 384 7 7 (940800)
I0421 00:09:38.243523 16809 net.cpp:156] Memory required for data: 89312600
I0421 00:09:38.243537 16809 layer_factory.hpp:77] Creating layer conv5
I0421 00:09:38.243566 16809 net.cpp:91] Creating Layer conv5
I0421 00:09:38.243580 16809 net.cpp:425] conv5 <- relu4
I0421 00:09:38.243599 16809 net.cpp:399] conv5 -> conv5
I0421 00:09:38.262115 16809 net.cpp:141] Setting up conv5
I0421 00:09:38.262202 16809 net.cpp:148] Top shape: 50 256 7 7 (627200)
I0421 00:09:38.262224 16809 net.cpp:156] Memory required for data: 91821400
I0421 00:09:38.262259 16809 layer_factory.hpp:77] Creating layer relu5
I0421 00:09:38.262303 16809 net.cpp:91] Creating Layer relu5
I0421 00:09:38.262326 16809 net.cpp:425] relu5 <- conv5
I0421 00:09:38.262347 16809 net.cpp:399] relu5 -> relu5
I0421 00:09:38.262609 16809 net.cpp:141] Setting up relu5
I0421 00:09:38.262639 16809 net.cpp:148] Top shape: 50 256 7 7 (627200)
I0421 00:09:38.262656 16809 net.cpp:156] Memory required for data: 94330200
I0421 00:09:38.262673 16809 layer_factory.hpp:77] Creating layer pool5
I0421 00:09:38.262694 16809 net.cpp:91] Creating Layer pool5
I0421 00:09:38.262711 16809 net.cpp:425] pool5 <- relu5
I0421 00:09:38.262732 16809 net.cpp:399] pool5 -> pool5
I0421 00:09:38.262814 16809 net.cpp:141] Setting up pool5
I0421 00:09:38.262838 16809 net.cpp:148] Top shape: 50 256 3 3 (115200)
I0421 00:09:38.262855 16809 net.cpp:156] Memory required for data: 94791000
I0421 00:09:38.262868 16809 layer_factory.hpp:77] Creating layer fc6
I0421 00:09:38.262889 16809 net.cpp:91] Creating Layer fc6
I0421 00:09:38.262905 16809 net.cpp:425] fc6 <- pool5
I0421 00:09:38.262925 16809 net.cpp:399] fc6 -> fc6
I0421 00:09:38.396595 16809 net.cpp:141] Setting up fc6
I0421 00:09:38.396625 16809 net.cpp:148] Top shape: 50 2048 (102400)
I0421 00:09:38.396630 16809 net.cpp:156] Memory required for data: 95200600
I0421 00:09:38.396641 16809 layer_factory.hpp:77] Creating layer relu6
I0421 00:09:38.396657 16809 net.cpp:91] Creating Layer relu6
I0421 00:09:38.396663 16809 net.cpp:425] relu6 <- fc6
I0421 00:09:38.396672 16809 net.cpp:399] relu6 -> relu6
I0421 00:09:38.397097 16809 net.cpp:141] Setting up relu6
I0421 00:09:38.397109 16809 net.cpp:148] Top shape: 50 2048 (102400)
I0421 00:09:38.397114 16809 net.cpp:156] Memory required for data: 95610200
I0421 00:09:38.397135 16809 layer_factory.hpp:77] Creating layer drop6
I0421 00:09:38.397147 16809 net.cpp:91] Creating Layer drop6
I0421 00:09:38.397152 16809 net.cpp:425] drop6 <- relu6
I0421 00:09:38.397161 16809 net.cpp:399] drop6 -> drop6
I0421 00:09:38.397217 16809 net.cpp:141] Setting up drop6
I0421 00:09:38.397225 16809 net.cpp:148] Top shape: 50 2048 (102400)
I0421 00:09:38.397229 16809 net.cpp:156] Memory required for data: 96019800
I0421 00:09:38.397233 16809 layer_factory.hpp:77] Creating layer fc7
I0421 00:09:38.397245 16809 net.cpp:91] Creating Layer fc7
I0421 00:09:38.397250 16809 net.cpp:425] fc7 <- drop6
I0421 00:09:38.397258 16809 net.cpp:399] fc7 -> fc7
I0421 00:09:38.512459 16809 net.cpp:141] Setting up fc7
I0421 00:09:38.512490 16809 net.cpp:148] Top shape: 50 2048 (102400)
I0421 00:09:38.512495 16809 net.cpp:156] Memory required for data: 96429400
I0421 00:09:38.512506 16809 layer_factory.hpp:77] Creating layer relu7
I0421 00:09:38.512517 16809 net.cpp:91] Creating Layer relu7
I0421 00:09:38.512526 16809 net.cpp:425] relu7 <- fc7
I0421 00:09:38.512537 16809 net.cpp:399] relu7 -> relu7
I0421 00:09:38.512841 16809 net.cpp:141] Setting up relu7
I0421 00:09:38.512852 16809 net.cpp:148] Top shape: 50 2048 (102400)
I0421 00:09:38.512856 16809 net.cpp:156] Memory required for data: 96839000
I0421 00:09:38.512861 16809 layer_factory.hpp:77] Creating layer drop7
I0421 00:09:38.512871 16809 net.cpp:91] Creating Layer drop7
I0421 00:09:38.512877 16809 net.cpp:425] drop7 <- relu7
I0421 00:09:38.512884 16809 net.cpp:399] drop7 -> drop7
I0421 00:09:38.512935 16809 net.cpp:141] Setting up drop7
I0421 00:09:38.512943 16809 net.cpp:148] Top shape: 50 2048 (102400)
I0421 00:09:38.512948 16809 net.cpp:156] Memory required for data: 97248600
I0421 00:09:38.512953 16809 layer_factory.hpp:77] Creating layer fc8
I0421 00:09:38.512965 16809 net.cpp:91] Creating Layer fc8
I0421 00:09:38.512971 16809 net.cpp:425] fc8 <- drop7
I0421 00:09:38.512979 16809 net.cpp:399] fc8 -> fc8
I0421 00:09:38.572022 16809 net.cpp:141] Setting up fc8
I0421 00:09:38.572048 16809 net.cpp:148] Top shape: 50 1000 (50000)
I0421 00:09:38.572053 16809 net.cpp:156] Memory required for data: 97448600
I0421 00:09:38.572067 16809 layer_factory.hpp:77] Creating layer fc8_fc8_0_split
I0421 00:09:38.572080 16809 net.cpp:91] Creating Layer fc8_fc8_0_split
I0421 00:09:38.572089 16809 net.cpp:425] fc8_fc8_0_split <- fc8
I0421 00:09:38.572098 16809 net.cpp:399] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0421 00:09:38.572108 16809 net.cpp:399] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0421 00:09:38.572165 16809 net.cpp:141] Setting up fc8_fc8_0_split
I0421 00:09:38.572177 16809 net.cpp:148] Top shape: 50 1000 (50000)
I0421 00:09:38.572183 16809 net.cpp:148] Top shape: 50 1000 (50000)
I0421 00:09:38.572187 16809 net.cpp:156] Memory required for data: 97848600
I0421 00:09:38.572192 16809 layer_factory.hpp:77] Creating layer accuracy
I0421 00:09:38.573664 16809 net.cpp:91] Creating Layer accuracy
I0421 00:09:38.573685 16809 net.cpp:425] accuracy <- fc8_fc8_0_split_0
I0421 00:09:38.573691 16809 net.cpp:425] accuracy <- label_data_1_split_0
I0421 00:09:38.573719 16809 net.cpp:399] accuracy -> accuracy
I0421 00:09:38.573734 16809 net.cpp:141] Setting up accuracy
I0421 00:09:38.573740 16809 net.cpp:148] Top shape: (1)
I0421 00:09:38.573745 16809 net.cpp:156] Memory required for data: 97848604
I0421 00:09:38.573748 16809 layer_factory.hpp:77] Creating layer loss
I0421 00:09:38.573756 16809 net.cpp:91] Creating Layer loss
I0421 00:09:38.573761 16809 net.cpp:425] loss <- fc8_fc8_0_split_1
I0421 00:09:38.573766 16809 net.cpp:425] loss <- label_data_1_split_1
I0421 00:09:38.573777 16809 net.cpp:399] loss -> loss
I0421 00:09:38.573787 16809 layer_factory.hpp:77] Creating layer loss
I0421 00:09:38.574909 16809 net.cpp:141] Setting up loss
I0421 00:09:38.574928 16809 net.cpp:148] Top shape: (1)
I0421 00:09:38.574934 16809 net.cpp:151]     with loss weight 1
I0421 00:09:38.574945 16809 net.cpp:156] Memory required for data: 97848608
I0421 00:09:38.574952 16809 net.cpp:217] loss needs backward computation.
I0421 00:09:38.574975 16809 net.cpp:219] accuracy does not need backward computation.
I0421 00:09:38.574985 16809 net.cpp:217] fc8_fc8_0_split needs backward computation.
I0421 00:09:38.574990 16809 net.cpp:217] fc8 needs backward computation.
I0421 00:09:38.574996 16809 net.cpp:217] drop7 needs backward computation.
I0421 00:09:38.575002 16809 net.cpp:217] relu7 needs backward computation.
I0421 00:09:38.575008 16809 net.cpp:217] fc7 needs backward computation.
I0421 00:09:38.575013 16809 net.cpp:217] drop6 needs backward computation.
I0421 00:09:38.575019 16809 net.cpp:217] relu6 needs backward computation.
I0421 00:09:38.575026 16809 net.cpp:217] fc6 needs backward computation.
I0421 00:09:38.575031 16809 net.cpp:217] pool5 needs backward computation.
I0421 00:09:38.575037 16809 net.cpp:217] relu5 needs backward computation.
I0421 00:09:38.575042 16809 net.cpp:217] conv5 needs backward computation.
I0421 00:09:38.575047 16809 net.cpp:217] relu4 needs backward computation.
I0421 00:09:38.575052 16809 net.cpp:217] conv4 needs backward computation.
I0421 00:09:38.575058 16809 net.cpp:217] relu3 needs backward computation.
I0421 00:09:38.575064 16809 net.cpp:217] conv3 needs backward computation.
I0421 00:09:38.575069 16809 net.cpp:217] pool2 needs backward computation.
I0421 00:09:38.575075 16809 net.cpp:217] relu2 needs backward computation.
I0421 00:09:38.575081 16809 net.cpp:217] conv2 needs backward computation.
I0421 00:09:38.575086 16809 net.cpp:217] pool1 needs backward computation.
I0421 00:09:38.575093 16809 net.cpp:217] relu1 needs backward computation.
I0421 00:09:38.575098 16809 net.cpp:217] conv1 needs backward computation.
I0421 00:09:38.575104 16809 net.cpp:219] label_data_1_split does not need backward computation.
I0421 00:09:38.575110 16809 net.cpp:219] data does not need backward computation.
I0421 00:09:38.575116 16809 net.cpp:261] This network produces output accuracy
I0421 00:09:38.575121 16809 net.cpp:261] This network produces output loss
I0421 00:09:38.575146 16809 net.cpp:274] Network initialization done.
I0421 00:09:38.575345 16809 solver.cpp:60] Solver scaffolding done.
I0421 00:09:38.575981 16809 caffe.cpp:209] Resuming from snapshots/caffenet128_no_lrn_lsuv_relu_bs1_iter_72648645.solverstate
I0421 00:09:41.758291 16809 sgd_solver.cpp:318] SGDSolver: restoring history
I0421 00:09:41.793057 16809 caffe.cpp:219] Starting Optimization
I0421 00:09:41.793083 16809 solver.cpp:279] Solving CaffeNet
I0421 00:09:41.793088 16809 solver.cpp:280] Learning Rate Policy: step
I0421 00:10:57.804534 16809 solver.cpp:228] Iteration 72652800, loss = 2.33076
I0421 00:10:57.988286 16809 solver.cpp:244]     Train net output #0: loss = 2.70257 (* 1 = 2.70257 loss)
I0421 00:10:57.988302 16809 sgd_solver.cpp:106] Iteration 72652800, lr = 3.9063e-07
I0421 00:13:23.241050 16809 blocking_queue.cpp:50] Data layer prefetch queue empty
I0421 00:25:02.816356 16809 solver.cpp:337] Iteration 72704000, Testing net (#0)
I0421 00:25:42.635717 16809 solver.cpp:404]     Test net output #0: accuracy = 0.47258
I0421 00:25:42.635782 16809 solver.cpp:404]     Test net output #1: loss = 2.36662 (* 1 = 2.36662 loss)
I0421 00:25:42.638361 16809 solver.cpp:228] Iteration 72704000, loss = 2.33108
I0421 00:25:42.638382 16809 solver.cpp:244]     Train net output #0: loss = 0.758946 (* 1 = 0.758946 loss)
I0421 00:25:42.638391 16809 sgd_solver.cpp:106] Iteration 72704000, lr = 3.9063e-07
I0421 00:39:56.499495 16809 solver.cpp:228] Iteration 72755200, loss = 2.32851
I0421 00:39:56.499593 16809 solver.cpp:244]     Train net output #0: loss = 1.94711 (* 1 = 1.94711 loss)
I0421 00:39:56.499609 16809 sgd_solver.cpp:106] Iteration 72755200, lr = 3.9063e-07
I0421 00:53:53.781905 16809 solver.cpp:228] Iteration 72806400, loss = 2.3376
I0421 00:53:53.782004 16809 solver.cpp:244]     Train net output #0: loss = 1.15546 (* 1 = 1.15546 loss)
I0421 00:53:53.782016 16809 sgd_solver.cpp:106] Iteration 72806400, lr = 3.9063e-07
I0421 01:08:47.565954 16809 solver.cpp:228] Iteration 72857600, loss = 2.32108
I0421 01:08:47.567314 16809 solver.cpp:244]     Train net output #0: loss = 1.93274 (* 1 = 1.93274 loss)
I0421 01:08:47.567330 16809 sgd_solver.cpp:106] Iteration 72857600, lr = 3.9063e-07
I0421 01:22:43.198035 16809 solver.cpp:228] Iteration 72908800, loss = 2.34813
I0421 01:22:43.212095 16809 solver.cpp:244]     Train net output #0: loss = 0.773341 (* 1 = 0.773341 loss)
I0421 01:22:43.212110 16809 sgd_solver.cpp:106] Iteration 72908800, lr = 3.9063e-07
I0421 01:36:26.434281 16809 solver.cpp:337] Iteration 72960000, Testing net (#0)
I0421 01:36:38.725626 16809 blocking_queue.cpp:50] Data layer prefetch queue empty
I0421 01:37:03.101732 16809 solver.cpp:404]     Test net output #0: accuracy = 0.4728
I0421 01:37:03.101840 16809 solver.cpp:404]     Test net output #1: loss = 2.36636 (* 1 = 2.36636 loss)
I0421 01:37:03.117774 16809 solver.cpp:228] Iteration 72960000, loss = 2.32151
I0421 01:37:03.117842 16809 solver.cpp:244]     Train net output #0: loss = 0.00436105 (* 1 = 0.00436105 loss)
I0421 01:37:03.117859 16809 sgd_solver.cpp:106] Iteration 72960000, lr = 3.9063e-07
I0421 01:51:23.932132 16809 solver.cpp:228] Iteration 73011200, loss = 2.32799
I0421 01:51:23.932260 16809 solver.cpp:244]     Train net output #0: loss = 1.34587 (* 1 = 1.34587 loss)
I0421 01:51:23.932276 16809 sgd_solver.cpp:106] Iteration 73011200, lr = 3.9063e-07
I0421 02:05:52.088642 16809 solver.cpp:228] Iteration 73062400, loss = 2.33312
I0421 02:05:52.090023 16809 solver.cpp:244]     Train net output #0: loss = 1.20412 (* 1 = 1.20412 loss)
I0421 02:05:52.090037 16809 sgd_solver.cpp:106] Iteration 73062400, lr = 3.9063e-07
I0421 02:20:11.893764 16809 solver.cpp:228] Iteration 73113600, loss = 2.30586
I0421 02:20:11.893841 16809 solver.cpp:244]     Train net output #0: loss = 0.224355 (* 1 = 0.224355 loss)
I0421 02:20:11.893851 16809 sgd_solver.cpp:106] Iteration 73113600, lr = 3.9063e-07
I0421 02:34:40.531148 16809 solver.cpp:228] Iteration 73164800, loss = 2.31063
I0421 02:34:40.531260 16809 solver.cpp:244]     Train net output #0: loss = 0.0306206 (* 1 = 0.0306206 loss)
I0421 02:34:40.531282 16809 sgd_solver.cpp:106] Iteration 73164800, lr = 3.9063e-07
I0421 02:48:26.208389 16809 solver.cpp:337] Iteration 73216000, Testing net (#0)
I0421 02:48:42.185679 16809 blocking_queue.cpp:50] Data layer prefetch queue empty
I0421 02:48:59.871400 16809 solver.cpp:404]     Test net output #0: accuracy = 0.47098
I0421 02:48:59.871505 16809 solver.cpp:404]     Test net output #1: loss = 2.37001 (* 1 = 2.37001 loss)
I0421 02:48:59.874253 16809 solver.cpp:228] Iteration 73216000, loss = 2.33899
I0421 02:48:59.874307 16809 solver.cpp:244]     Train net output #0: loss = 0.00102775 (* 1 = 0.00102775 loss)
I0421 02:48:59.874325 16809 sgd_solver.cpp:106] Iteration 73216000, lr = 3.9063e-07
I0421 03:03:51.902802 16809 solver.cpp:228] Iteration 73267200, loss = 2.34735
I0421 03:03:51.902873 16809 solver.cpp:244]     Train net output #0: loss = 2.10123 (* 1 = 2.10123 loss)
I0421 03:03:51.902886 16809 sgd_solver.cpp:106] Iteration 73267200, lr = 3.9063e-07
I0421 03:18:49.488600 16809 solver.cpp:228] Iteration 73318400, loss = 2.32233
I0421 03:18:49.488679 16809 solver.cpp:244]     Train net output #0: loss = 1.05133 (* 1 = 1.05133 loss)
I0421 03:18:49.488693 16809 sgd_solver.cpp:106] Iteration 73318400, lr = 3.9063e-07
I0421 03:33:29.613000 16809 solver.cpp:228] Iteration 73369600, loss = 2.35035
I0421 03:33:29.613072 16809 solver.cpp:244]     Train net output #0: loss = 4.29187 (* 1 = 4.29187 loss)
I0421 03:33:29.613085 16809 sgd_solver.cpp:106] Iteration 73369600, lr = 3.9063e-07
I0421 03:47:55.955770 16809 solver.cpp:228] Iteration 73420800, loss = 2.34889
I0421 03:47:55.955847 16809 solver.cpp:244]     Train net output #0: loss = 0.0902388 (* 1 = 0.0902388 loss)
I0421 03:47:55.955860 16809 sgd_solver.cpp:106] Iteration 73420800, lr = 3.9063e-07
I0421 04:02:02.994392 16809 solver.cpp:337] Iteration 73472000, Testing net (#0)
I0421 04:02:21.756225 16809 blocking_queue.cpp:50] Data layer prefetch queue empty
I0421 04:02:35.204123 16809 solver.cpp:404]     Test net output #0: accuracy = 0.47176
I0421 04:02:35.204198 16809 solver.cpp:404]     Test net output #1: loss = 2.36539 (* 1 = 2.36539 loss)
I0421 04:02:35.207021 16809 solver.cpp:228] Iteration 73472000, loss = 2.35478
I0421 04:02:35.207052 16809 solver.cpp:244]     Train net output #0: loss = 2.84651 (* 1 = 2.84651 loss)
I0421 04:02:35.207062 16809 sgd_solver.cpp:106] Iteration 73472000, lr = 3.9063e-07
I0421 04:07:38.967929 16809 solver.cpp:228] Iteration 73523200, loss = 2.33335
I0421 04:07:38.967983 16809 solver.cpp:244]     Train net output #0: loss = 0.00283984 (* 1 = 0.00283984 loss)
I0421 04:07:38.967990 16809 sgd_solver.cpp:106] Iteration 73523200, lr = 3.9063e-07
I0421 04:12:44.886492 16809 solver.cpp:228] Iteration 73574400, loss = 2.32165
I0421 04:12:44.886556 16809 solver.cpp:244]     Train net output #0: loss = 0.0937575 (* 1 = 0.0937575 loss)
I0421 04:12:44.886566 16809 sgd_solver.cpp:106] Iteration 73574400, lr = 3.9063e-07
I0421 04:17:50.827631 16809 solver.cpp:228] Iteration 73625600, loss = 2.32326
I0421 04:17:50.827682 16809 solver.cpp:244]     Train net output #0: loss = 2.98169 (* 1 = 2.98169 loss)
I0421 04:17:50.827687 16809 sgd_solver.cpp:106] Iteration 73625600, lr = 3.9063e-07
I0421 04:22:56.640425 16809 solver.cpp:228] Iteration 73676800, loss = 2.31974
I0421 04:22:56.640492 16809 solver.cpp:244]     Train net output #0: loss = 1.31402 (* 1 = 1.31402 loss)
I0421 04:22:56.640498 16809 sgd_solver.cpp:106] Iteration 73676800, lr = 3.9063e-07
I0421 04:28:02.867008 16809 solver.cpp:337] Iteration 73728000, Testing net (#0)
I0421 04:28:18.155279 16809 blocking_queue.cpp:50] Data layer prefetch queue empty
I0421 04:28:29.338196 16809 solver.cpp:404]     Test net output #0: accuracy = 0.47232
I0421 04:28:29.338232 16809 solver.cpp:404]     Test net output #1: loss = 2.36628 (* 1 = 2.36628 loss)
I0421 04:28:29.340792 16809 solver.cpp:228] Iteration 73728000, loss = 2.32706
I0421 04:28:29.340816 16809 solver.cpp:244]     Train net output #0: loss = 0.00011564 (* 1 = 0.00011564 loss)
I0421 04:28:29.340826 16809 sgd_solver.cpp:106] Iteration 73728000, lr = 3.9063e-07
I0421 04:33:35.474114 16809 solver.cpp:228] Iteration 73779200, loss = 2.31194
I0421 04:33:35.474164 16809 solver.cpp:244]     Train net output #0: loss = 0.116638 (* 1 = 0.116638 loss)
I0421 04:33:35.474169 16809 sgd_solver.cpp:106] Iteration 73779200, lr = 3.9063e-07
I0421 04:38:42.972761 16809 solver.cpp:228] Iteration 73830400, loss = 2.31975
I0421 04:38:42.972827 16809 solver.cpp:244]     Train net output #0: loss = 1.08153 (* 1 = 1.08153 loss)
I0421 04:38:42.972834 16809 sgd_solver.cpp:106] Iteration 73830400, lr = 3.9063e-07
I0421 04:43:49.080979 16809 solver.cpp:228] Iteration 73881600, loss = 2.32047
I0421 04:43:49.081053 16809 solver.cpp:244]     Train net output #0: loss = 6.52031 (* 1 = 6.52031 loss)
I0421 04:43:49.081064 16809 sgd_solver.cpp:106] Iteration 73881600, lr = 3.9063e-07
I0421 04:48:55.007943 16809 solver.cpp:228] Iteration 73932800, loss = 2.34607
I0421 04:48:55.008014 16809 solver.cpp:244]     Train net output #0: loss = 1.24703 (* 1 = 1.24703 loss)
I0421 04:48:55.008023 16809 sgd_solver.cpp:106] Iteration 73932800, lr = 3.9063e-07
I0421 04:54:00.864665 16809 solver.cpp:337] Iteration 73984000, Testing net (#0)
I0421 04:54:10.267060 16819 blocking_queue.cpp:50] Waiting for data
I0421 04:54:16.139423 16809 blocking_queue.cpp:50] Data layer prefetch queue empty
I0421 04:54:27.546644 16809 solver.cpp:404]     Test net output #0: accuracy = 0.4716
I0421 04:54:27.546679 16809 solver.cpp:404]     Test net output #1: loss = 2.36994 (* 1 = 2.36994 loss)
I0421 04:54:27.549223 16809 solver.cpp:228] Iteration 73984000, loss = 2.34134
I0421 04:54:27.549242 16809 solver.cpp:244]     Train net output #0: loss = 0.0061134 (* 1 = 0.0061134 loss)
I0421 04:54:27.549253 16809 sgd_solver.cpp:106] Iteration 73984000, lr = 3.9063e-07
I0421 04:59:33.667378 16809 solver.cpp:228] Iteration 74035200, loss = 2.32535
I0421 04:59:33.667464 16809 solver.cpp:244]     Train net output #0: loss = 0.914995 (* 1 = 0.914995 loss)
I0421 04:59:33.667470 16809 sgd_solver.cpp:106] Iteration 74035200, lr = 3.9063e-07
I0421 05:04:39.741127 16809 solver.cpp:228] Iteration 74086400, loss = 2.33782
I0421 05:04:39.741185 16809 solver.cpp:244]     Train net output #0: loss = 1.93223 (* 1 = 1.93223 loss)
I0421 05:04:39.741191 16809 sgd_solver.cpp:106] Iteration 74086400, lr = 3.9063e-07
I0421 05:09:45.760440 16809 solver.cpp:228] Iteration 74137600, loss = 2.32955
I0421 05:09:45.760500 16809 solver.cpp:244]     Train net output #0: loss = 0.0160082 (* 1 = 0.0160082 loss)
I0421 05:09:45.760507 16809 sgd_solver.cpp:106] Iteration 74137600, lr = 3.9063e-07
I0421 05:14:51.782438 16809 solver.cpp:228] Iteration 74188800, loss = 2.34504
I0421 05:14:51.782507 16809 solver.cpp:244]     Train net output #0: loss = 5.61863 (* 1 = 5.61863 loss)
I0421 05:14:51.782513 16809 sgd_solver.cpp:106] Iteration 74188800, lr = 3.9063e-07
I0421 05:19:57.992565 16809 solver.cpp:454] Snapshotting to binary proto file snapshots/caffenet128_no_lrn_lsuv_relu_bs1_iter_74240000.caffemodel
I0421 05:19:58.330348 16809 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/caffenet128_no_lrn_lsuv_relu_bs1_iter_74240000.solverstate
I0421 05:19:58.390208 16809 solver.cpp:337] Iteration 74240000, Testing net (#0)
I0421 05:20:13.645782 16809 blocking_queue.cpp:50] Data layer prefetch queue empty
I0421 05:20:25.003968 16809 solver.cpp:404]     Test net output #0: accuracy = 0.47232
I0421 05:20:25.003998 16809 solver.cpp:404]     Test net output #1: loss = 2.3642 (* 1 = 2.3642 loss)
I0421 05:20:25.006531 16809 solver.cpp:228] Iteration 74240000, loss = 2.32705
I0421 05:20:25.006549 16809 solver.cpp:244]     Train net output #0: loss = 0.874622 (* 1 = 0.874622 loss)
I0421 05:20:25.006556 16809 sgd_solver.cpp:106] Iteration 74240000, lr = 3.9063e-07
I0421 05:25:31.010797 16809 solver.cpp:228] Iteration 74291200, loss = 2.33855
I0421 05:25:31.010854 16809 solver.cpp:244]     Train net output #0: loss = 2.64746 (* 1 = 2.64746 loss)
I0421 05:25:31.010860 16809 sgd_solver.cpp:106] Iteration 74291200, lr = 3.9063e-07
I0421 05:30:36.943519 16809 solver.cpp:228] Iteration 74342400, loss = 2.3265
I0421 05:30:36.943578 16809 solver.cpp:244]     Train net output #0: loss = 7.19296 (* 1 = 7.19296 loss)
I0421 05:30:36.943583 16809 sgd_solver.cpp:106] Iteration 74342400, lr = 3.9063e-07
I0421 05:35:42.908677 16809 solver.cpp:228] Iteration 74393600, loss = 2.30962
I0421 05:35:42.908752 16809 solver.cpp:244]     Train net output #0: loss = 3.86097 (* 1 = 3.86097 loss)
I0421 05:35:42.908759 16809 sgd_solver.cpp:106] Iteration 74393600, lr = 3.9063e-07
I0421 05:40:48.992149 16809 solver.cpp:228] Iteration 74444800, loss = 2.29093
I0421 05:40:48.992208 16809 solver.cpp:244]     Train net output #0: loss = 7.70776 (* 1 = 7.70776 loss)
I0421 05:40:48.992214 16809 sgd_solver.cpp:106] Iteration 74444800, lr = 3.9063e-07
I0421 05:45:55.108881 16809 solver.cpp:337] Iteration 74496000, Testing net (#0)
I0421 05:46:10.354409 16809 blocking_queue.cpp:50] Data layer prefetch queue empty
I0421 05:46:21.584656 16809 solver.cpp:404]     Test net output #0: accuracy = 0.47152
I0421 05:46:21.584687 16809 solver.cpp:404]     Test net output #1: loss = 2.3649 (* 1 = 2.3649 loss)
I0421 05:46:21.587236 16809 solver.cpp:228] Iteration 74496000, loss = 2.33135
I0421 05:46:21.587256 16809 solver.cpp:244]     Train net output #0: loss = 0.257803 (* 1 = 0.257803 loss)
I0421 05:46:21.587265 16809 sgd_solver.cpp:106] Iteration 74496000, lr = 3.9063e-07
I0421 05:51:27.773772 16809 solver.cpp:228] Iteration 74547200, loss = 2.34216
I0421 05:51:27.773847 16809 solver.cpp:244]     Train net output #0: loss = 1.24262 (* 1 = 1.24262 loss)
I0421 05:51:27.773861 16809 sgd_solver.cpp:106] Iteration 74547200, lr = 3.9063e-07
I0421 05:56:33.790172 16809 solver.cpp:228] Iteration 74598400, loss = 2.32377
I0421 05:56:33.790256 16809 solver.cpp:244]     Train net output #0: loss = 2.45539 (* 1 = 2.45539 loss)
I0421 05:56:33.790262 16809 sgd_solver.cpp:106] Iteration 74598400, lr = 3.9063e-07
I0421 06:01:39.871250 16809 solver.cpp:228] Iteration 74649600, loss = 2.34602
I0421 06:01:39.871336 16809 solver.cpp:244]     Train net output #0: loss = 1.85284 (* 1 = 1.85284 loss)
I0421 06:01:39.871342 16809 sgd_solver.cpp:106] Iteration 74649600, lr = 3.9063e-07
I0421 06:06:45.948051 16809 solver.cpp:228] Iteration 74700800, loss = 2.34746
I0421 06:06:45.948120 16809 solver.cpp:244]     Train net output #0: loss = 1.6037 (* 1 = 1.6037 loss)
I0421 06:06:45.948127 16809 sgd_solver.cpp:106] Iteration 74700800, lr = 3.9063e-07
I0421 06:11:51.923887 16809 solver.cpp:337] Iteration 74752000, Testing net (#0)
I0421 06:12:07.213971 16809 blocking_queue.cpp:50] Data layer prefetch queue empty
I0421 06:12:18.422503 16809 solver.cpp:404]     Test net output #0: accuracy = 0.47196
I0421 06:12:18.422535 16809 solver.cpp:404]     Test net output #1: loss = 2.36639 (* 1 = 2.36639 loss)
I0421 06:12:18.425006 16809 solver.cpp:228] Iteration 74752000, loss = 2.35
I0421 06:12:18.425022 16809 solver.cpp:244]     Train net output #0: loss = 3.98441 (* 1 = 3.98441 loss)
I0421 06:12:18.425029 16809 sgd_solver.cpp:106] Iteration 74752000, lr = 3.9063e-07
I0421 06:17:24.524982 16809 solver.cpp:228] Iteration 74803200, loss = 2.34411
I0421 06:17:24.525054 16809 solver.cpp:244]     Train net output #0: loss = 5.55621 (* 1 = 5.55621 loss)
I0421 06:17:24.525061 16809 sgd_solver.cpp:106] Iteration 74803200, lr = 3.9063e-07
I0421 06:22:30.646777 16809 solver.cpp:228] Iteration 74854400, loss = 2.31665
I0421 06:22:30.646836 16809 solver.cpp:244]     Train net output #0: loss = 9.05003 (* 1 = 9.05003 loss)
I0421 06:22:30.646842 16809 sgd_solver.cpp:106] Iteration 74854400, lr = 3.9063e-07
I0421 06:27:36.581876 16809 solver.cpp:228] Iteration 74905600, loss = 2.32006
I0421 06:27:36.581925 16809 solver.cpp:244]     Train net output #0: loss = 4.22956 (* 1 = 4.22956 loss)
I0421 06:27:36.581933 16809 sgd_solver.cpp:106] Iteration 74905600, lr = 3.9063e-07
I0421 06:32:42.825163 16809 solver.cpp:228] Iteration 74956800, loss = 2.32008
I0421 06:32:42.825212 16809 solver.cpp:244]     Train net output #0: loss = 0.150097 (* 1 = 0.150097 loss)
I0421 06:32:42.825217 16809 sgd_solver.cpp:106] Iteration 74956800, lr = 3.9063e-07
I0421 06:37:49.473280 16809 solver.cpp:337] Iteration 75008000, Testing net (#0)
I0421 06:38:04.707705 16809 blocking_queue.cpp:50] Data layer prefetch queue empty
I0421 06:38:16.010654 16809 solver.cpp:404]     Test net output #0: accuracy = 0.47286
I0421 06:38:16.010687 16809 solver.cpp:404]     Test net output #1: loss = 2.36619 (* 1 = 2.36619 loss)
I0421 06:38:16.013211 16809 solver.cpp:228] Iteration 75008000, loss = 2.32727
I0421 06:38:16.013232 16809 solver.cpp:244]     Train net output #0: loss = 0.141326 (* 1 = 0.141326 loss)
I0421 06:38:16.013242 16809 sgd_solver.cpp:106] Iteration 75008000, lr = 3.9063e-07
I0421 06:43:30.004652 16809 solver.cpp:228] Iteration 75059200, loss = 2.31381
I0421 06:43:30.004714 16809 solver.cpp:244]     Train net output #0: loss = 1.90303 (* 1 = 1.90303 loss)
I0421 06:43:30.004722 16809 sgd_solver.cpp:106] Iteration 75059200, lr = 3.9063e-07
I0421 06:48:41.405222 16809 solver.cpp:228] Iteration 75110400, loss = 2.32642
I0421 06:48:41.405268 16809 solver.cpp:244]     Train net output #0: loss = 0.00191896 (* 1 = 0.00191896 loss)
I0421 06:48:41.405274 16809 sgd_solver.cpp:106] Iteration 75110400, lr = 3.9063e-07
I0421 06:53:49.584594 16809 solver.cpp:228] Iteration 75161600, loss = 2.30888
I0421 06:53:49.584663 16809 solver.cpp:244]     Train net output #0: loss = 3.84762 (* 1 = 3.84762 loss)
I0421 06:53:49.584669 16809 sgd_solver.cpp:106] Iteration 75161600, lr = 3.9063e-07
I0421 06:58:55.614716 16809 solver.cpp:228] Iteration 75212800, loss = 2.34795
I0421 06:58:55.614784 16809 solver.cpp:244]     Train net output #0: loss = 1.20988 (* 1 = 1.20988 loss)
I0421 06:58:55.614790 16809 sgd_solver.cpp:106] Iteration 75212800, lr = 3.9063e-07
I0421 07:04:01.818117 16809 solver.cpp:337] Iteration 75264000, Testing net (#0)
I0421 07:04:14.321883 16809 blocking_queue.cpp:50] Data layer prefetch queue empty
I0421 07:04:28.392204 16809 solver.cpp:404]     Test net output #0: accuracy = 0.47204
I0421 07:04:28.392236 16809 solver.cpp:404]     Test net output #1: loss = 2.36796 (* 1 = 2.36796 loss)
I0421 07:04:28.394747 16809 solver.cpp:228] Iteration 75264000, loss = 2.34362
I0421 07:04:28.394767 16809 solver.cpp:244]     Train net output #0: loss = 0.466471 (* 1 = 0.466471 loss)
I0421 07:04:28.394775 16809 sgd_solver.cpp:106] Iteration 75264000, lr = 3.9063e-07
I0421 07:09:34.481235 16809 solver.cpp:228] Iteration 75315200, loss = 2.33168
I0421 07:09:34.481308 16809 solver.cpp:244]     Train net output #0: loss = 0.162563 (* 1 = 0.162563 loss)
I0421 07:09:34.481314 16809 sgd_solver.cpp:106] Iteration 75315200, lr = 3.9063e-07
I0421 07:14:40.362145 16809 solver.cpp:228] Iteration 75366400, loss = 2.33813
I0421 07:14:40.362216 16809 solver.cpp:244]     Train net output #0: loss = 0.847122 (* 1 = 0.847122 loss)
I0421 07:14:40.362222 16809 sgd_solver.cpp:106] Iteration 75366400, lr = 3.9063e-07
I0421 07:19:46.262034 16809 solver.cpp:228] Iteration 75417600, loss = 2.32388
I0421 07:19:46.262092 16809 solver.cpp:244]     Train net output #0: loss = 1.48418 (* 1 = 1.48418 loss)
I0421 07:19:46.262099 16809 sgd_solver.cpp:106] Iteration 75417600, lr = 3.9063e-07
I0421 07:24:52.170845 16809 solver.cpp:228] Iteration 75468800, loss = 2.33515
I0421 07:24:52.170902 16809 solver.cpp:244]     Train net output #0: loss = 4.46273 (* 1 = 4.46273 loss)
I0421 07:24:52.170907 16809 sgd_solver.cpp:106] Iteration 75468800, lr = 3.9063e-07
I0421 07:29:58.126405 16809 solver.cpp:337] Iteration 75520000, Testing net (#0)
I0421 07:30:10.598197 16809 blocking_queue.cpp:50] Data layer prefetch queue empty
I0421 07:30:24.614014 16809 solver.cpp:404]     Test net output #0: accuracy = 0.47294
I0421 07:30:24.614048 16809 solver.cpp:404]     Test net output #1: loss = 2.36158 (* 1 = 2.36158 loss)
I0421 07:30:24.616791 16809 solver.cpp:228] Iteration 75520000, loss = 2.3184
I0421 07:30:24.616837 16809 solver.cpp:244]     Train net output #0: loss = 1.09029 (* 1 = 1.09029 loss)
I0421 07:30:24.616855 16809 sgd_solver.cpp:106] Iteration 75520000, lr = 3.9063e-07
I0421 07:35:30.908542 16809 solver.cpp:228] Iteration 75571200, loss = 2.33533
I0421 07:35:30.908601 16809 solver.cpp:244]     Train net output #0: loss = 2.5461 (* 1 = 2.5461 loss)
I0421 07:35:30.908607 16809 sgd_solver.cpp:106] Iteration 75571200, lr = 3.9063e-07
I0421 07:40:37.125983 16809 solver.cpp:228] Iteration 75622400, loss = 2.33406
I0421 07:40:37.126049 16809 solver.cpp:244]     Train net output #0: loss = 3.26107 (* 1 = 3.26107 loss)
I0421 07:40:37.126055 16809 sgd_solver.cpp:106] Iteration 75622400, lr = 3.9063e-07
I0421 07:45:43.324883 16809 solver.cpp:228] Iteration 75673600, loss = 2.31051
I0421 07:45:43.324945 16809 solver.cpp:244]     Train net output #0: loss = 6.33021e-05 (* 1 = 6.33021e-05 loss)
I0421 07:45:43.324951 16809 sgd_solver.cpp:106] Iteration 75673600, lr = 3.9063e-07
I0421 07:50:49.365794 16809 solver.cpp:228] Iteration 75724800, loss = 2.31028
I0421 07:50:49.365866 16809 solver.cpp:244]     Train net output #0: loss = 0.121024 (* 1 = 0.121024 loss)
I0421 07:50:49.365874 16809 sgd_solver.cpp:106] Iteration 75724800, lr = 3.9063e-07
I0421 07:55:55.645537 16809 solver.cpp:337] Iteration 75776000, Testing net (#0)
I0421 07:56:08.129878 16809 blocking_queue.cpp:50] Data layer prefetch queue empty
I0421 07:56:22.152679 16809 solver.cpp:404]     Test net output #0: accuracy = 0.47192
I0421 07:56:22.152711 16809 solver.cpp:404]     Test net output #1: loss = 2.36193 (* 1 = 2.36193 loss)
I0421 07:56:22.155263 16809 solver.cpp:228] Iteration 75776000, loss = 2.32706
I0421 07:56:22.155282 16809 solver.cpp:244]     Train net output #0: loss = 1.94413 (* 1 = 1.94413 loss)
I0421 07:56:22.155290 16809 sgd_solver.cpp:106] Iteration 75776000, lr = 3.9063e-07
I0421 08:01:28.323552 16809 solver.cpp:228] Iteration 75827200, loss = 2.33626
I0421 08:01:28.323643 16809 solver.cpp:244]     Train net output #0: loss = 2.01213 (* 1 = 2.01213 loss)
I0421 08:01:28.323655 16809 sgd_solver.cpp:106] Iteration 75827200, lr = 3.9063e-07
I0421 08:06:34.285096 16809 solver.cpp:228] Iteration 75878400, loss = 2.32401
I0421 08:06:34.285168 16809 solver.cpp:244]     Train net output #0: loss = 5.57482 (* 1 = 5.57482 loss)
I0421 08:06:34.285174 16809 sgd_solver.cpp:106] Iteration 75878400, lr = 3.9063e-07
I0421 08:11:40.216689 16809 solver.cpp:228] Iteration 75929600, loss = 2.34496
I0421 08:11:40.216907 16809 solver.cpp:244]     Train net output #0: loss = 1.80251 (* 1 = 1.80251 loss)
I0421 08:11:40.216917 16809 sgd_solver.cpp:106] Iteration 75929600, lr = 3.9063e-07
I0421 08:16:46.128916 16809 solver.cpp:228] Iteration 75980800, loss = 2.34786
I0421 08:16:46.128983 16809 solver.cpp:244]     Train net output #0: loss = 1.95438 (* 1 = 1.95438 loss)
I0421 08:16:46.128990 16809 sgd_solver.cpp:106] Iteration 75980800, lr = 3.9063e-07
I0421 08:21:52.113977 16809 solver.cpp:337] Iteration 76032000, Testing net (#0)
I0421 08:22:04.662647 16809 blocking_queue.cpp:50] Data layer prefetch queue empty
I0421 08:22:18.691558 16809 solver.cpp:404]     Test net output #0: accuracy = 0.47144
I0421 08:22:18.691591 16809 solver.cpp:404]     Test net output #1: loss = 2.36635 (* 1 = 2.36635 loss)
I0421 08:22:18.694126 16809 solver.cpp:228] Iteration 76032000, loss = 2.34869
I0421 08:22:18.694145 16809 solver.cpp:244]     Train net output #0: loss = 0.807524 (* 1 = 0.807524 loss)
I0421 08:22:18.694154 16809 sgd_solver.cpp:106] Iteration 76032000, lr = 3.9063e-07
I0421 08:27:24.794180 16809 solver.cpp:228] Iteration 76083200, loss = 2.34818
I0421 08:27:24.794239 16809 solver.cpp:244]     Train net output #0: loss = 3.67996 (* 1 = 3.67996 loss)
I0421 08:27:24.794245 16809 sgd_solver.cpp:106] Iteration 76083200, lr = 3.9063e-07
I0421 08:32:30.785120 16809 solver.cpp:228] Iteration 76134400, loss = 2.31844
I0421 08:32:30.785181 16809 solver.cpp:244]     Train net output #0: loss = 8.49196 (* 1 = 8.49196 loss)
I0421 08:32:30.785187 16809 sgd_solver.cpp:106] Iteration 76134400, lr = 3.9063e-07
I0421 08:37:36.716192 16809 solver.cpp:228] Iteration 76185600, loss = 2.3235
I0421 08:37:36.716253 16809 solver.cpp:244]     Train net output #0: loss = 1.91144 (* 1 = 1.91144 loss)
I0421 08:37:36.716259 16809 sgd_solver.cpp:106] Iteration 76185600, lr = 3.9063e-07
I0421 08:42:43.460574 16809 solver.cpp:228] Iteration 76236800, loss = 2.31856
I0421 08:42:43.460629 16809 solver.cpp:244]     Train net output #0: loss = 5.80877 (* 1 = 5.80877 loss)
I0421 08:42:43.460636 16809 sgd_solver.cpp:106] Iteration 76236800, lr = 3.9063e-07
I0421 08:47:50.158277 16809 solver.cpp:337] Iteration 76288000, Testing net (#0)
I0421 08:48:02.594693 16809 blocking_queue.cpp:50] Data layer prefetch queue empty
I0421 08:48:16.710906 16809 solver.cpp:404]     Test net output #0: accuracy = 0.47186
I0421 08:48:16.710942 16809 solver.cpp:404]     Test net output #1: loss = 2.36604 (* 1 = 2.36604 loss)
I0421 08:48:16.713482 16809 solver.cpp:228] Iteration 76288000, loss = 2.31798
I0421 08:48:16.713500 16809 solver.cpp:244]     Train net output #0: loss = 3.79224 (* 1 = 3.79224 loss)
I0421 08:48:16.713510 16809 sgd_solver.cpp:106] Iteration 76288000, lr = 3.9063e-07
I0421 08:53:31.243530 16809 solver.cpp:228] Iteration 76339200, loss = 2.3117
I0421 08:53:31.243582 16809 solver.cpp:244]     Train net output #0: loss = 0.303235 (* 1 = 0.303235 loss)
I0421 08:53:31.243587 16809 sgd_solver.cpp:106] Iteration 76339200, lr = 3.9063e-07
I0421 08:58:43.039893 16809 solver.cpp:228] Iteration 76390400, loss = 2.31868
I0421 08:58:43.039942 16809 solver.cpp:244]     Train net output #0: loss = 0.291924 (* 1 = 0.291924 loss)
I0421 08:58:43.039947 16809 sgd_solver.cpp:106] Iteration 76390400, lr = 3.9063e-07
I0421 09:03:51.367547 16809 solver.cpp:228] Iteration 76441600, loss = 2.31077
I0421 09:03:51.367609 16809 solver.cpp:244]     Train net output #0: loss = 2.00038 (* 1 = 2.00038 loss)
I0421 09:03:51.367615 16809 sgd_solver.cpp:106] Iteration 76441600, lr = 3.9063e-07
I0421 09:08:57.252286 16809 solver.cpp:228] Iteration 76492800, loss = 2.34366
I0421 09:08:57.252374 16809 solver.cpp:244]     Train net output #0: loss = 1.10174 (* 1 = 1.10174 loss)
I0421 09:08:57.252380 16809 sgd_solver.cpp:106] Iteration 76492800, lr = 3.9063e-07
I0421 09:14:03.107851 16809 solver.cpp:337] Iteration 76544000, Testing net (#0)
I0421 09:14:12.652250 16809 blocking_queue.cpp:50] Data layer prefetch queue empty
I0421 09:14:29.693785 16809 solver.cpp:404]     Test net output #0: accuracy = 0.4721
I0421 09:14:29.693817 16809 solver.cpp:404]     Test net output #1: loss = 2.36672 (* 1 = 2.36672 loss)
I0421 09:14:29.696347 16809 solver.cpp:228] Iteration 76544000, loss = 2.33798
I0421 09:14:29.696364 16809 solver.cpp:244]     Train net output #0: loss = 2.74216 (* 1 = 2.74216 loss)
I0421 09:14:29.696370 16809 sgd_solver.cpp:106] Iteration 76544000, lr = 3.9063e-07
I0421 09:19:35.917142 16809 solver.cpp:228] Iteration 76595200, loss = 2.33629
I0421 09:19:35.917199 16809 solver.cpp:244]     Train net output #0: loss = 1.25517 (* 1 = 1.25517 loss)
I0421 09:19:35.917206 16809 sgd_solver.cpp:106] Iteration 76595200, lr = 3.9063e-07
I0421 09:24:41.871778 16809 solver.cpp:228] Iteration 76646400, loss = 2.34288
I0421 09:24:41.871842 16809 solver.cpp:244]     Train net output #0: loss = 4.73235 (* 1 = 4.73235 loss)
I0421 09:24:41.871848 16809 sgd_solver.cpp:106] Iteration 76646400, lr = 3.9063e-07
I0421 09:29:47.826781 16809 solver.cpp:228] Iteration 76697600, loss = 2.32442
I0421 09:29:47.826848 16809 solver.cpp:244]     Train net output #0: loss = 2.78133 (* 1 = 2.78133 loss)
I0421 09:29:47.826855 16809 sgd_solver.cpp:106] Iteration 76697600, lr = 3.9063e-07
I0421 09:34:53.783098 16809 solver.cpp:228] Iteration 76748800, loss = 2.32983
I0421 09:34:53.783148 16809 solver.cpp:244]     Train net output #0: loss = 4.07522 (* 1 = 4.07522 loss)
I0421 09:34:53.783152 16809 sgd_solver.cpp:106] Iteration 76748800, lr = 3.9063e-07
I0421 09:39:59.672680 16809 solver.cpp:454] Snapshotting to binary proto file snapshots/caffenet128_no_lrn_lsuv_relu_bs1_iter_76800000.caffemodel
I0421 09:40:00.190645 16809 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/caffenet128_no_lrn_lsuv_relu_bs1_iter_76800000.solverstate
I0421 09:40:00.253890 16809 solver.cpp:337] Iteration 76800000, Testing net (#0)
I0421 09:40:09.846653 16809 blocking_queue.cpp:50] Data layer prefetch queue empty
I0421 09:40:26.764621 16809 solver.cpp:404]     Test net output #0: accuracy = 0.47362
I0421 09:40:26.764653 16809 solver.cpp:404]     Test net output #1: loss = 2.36188 (* 1 = 2.36188 loss)
I0421 09:40:26.767184 16809 solver.cpp:228] Iteration 76800000, loss = 2.31472
I0421 09:40:26.767202 16809 solver.cpp:244]     Train net output #0: loss = 6.38829 (* 1 = 6.38829 loss)
I0421 09:40:26.767218 16809 sgd_solver.cpp:106] Iteration 76800000, lr = 3.9063e-08
I0421 09:45:32.987252 16809 solver.cpp:228] Iteration 76851200, loss = 2.32308
I0421 09:45:32.987310 16809 solver.cpp:244]     Train net output #0: loss = 0.000600399 (* 1 = 0.000600399 loss)
I0421 09:45:32.987316 16809 sgd_solver.cpp:106] Iteration 76851200, lr = 3.9063e-08
I0421 09:50:39.048521 16809 solver.cpp:228] Iteration 76902400, loss = 2.31926
I0421 09:50:39.048589 16809 solver.cpp:244]     Train net output #0: loss = 0.281008 (* 1 = 0.281008 loss)
I0421 09:50:39.048596 16809 sgd_solver.cpp:106] Iteration 76902400, lr = 3.9063e-08
I0421 09:55:51.229172 16809 solver.cpp:228] Iteration 76953600, loss = 2.30502
I0421 09:55:51.229240 16809 solver.cpp:244]     Train net output #0: loss = 3.50424 (* 1 = 3.50424 loss)
I0421 09:55:51.229249 16809 sgd_solver.cpp:106] Iteration 76953600, lr = 3.9063e-08
I0421 10:01:02.056942 16809 solver.cpp:228] Iteration 77004800, loss = 2.30682
I0421 10:01:02.057016 16809 solver.cpp:244]     Train net output #0: loss = 3.56207 (* 1 = 3.56207 loss)
I0421 10:01:02.057027 16809 sgd_solver.cpp:106] Iteration 77004800, lr = 3.9063e-08
I0421 10:06:09.093749 16809 solver.cpp:337] Iteration 77056000, Testing net (#0)
I0421 10:06:18.372217 16809 blocking_queue.cpp:50] Data layer prefetch queue empty
I0421 10:06:35.589033 16809 solver.cpp:404]     Test net output #0: accuracy = 0.4734
I0421 10:06:35.589068 16809 solver.cpp:404]     Test net output #1: loss = 2.35743 (* 1 = 2.35743 loss)
I0421 10:06:35.591647 16809 solver.cpp:228] Iteration 77056000, loss = 2.32581
I0421 10:06:35.591668 16809 solver.cpp:244]     Train net output #0: loss = 2.74104 (* 1 = 2.74104 loss)
I0421 10:06:35.591680 16809 sgd_solver.cpp:106] Iteration 77056000, lr = 3.9063e-08
I0421 10:11:44.284807 16809 solver.cpp:228] Iteration 77107200, loss = 2.32749
I0421 10:11:44.284868 16809 solver.cpp:244]     Train net output #0: loss = 0.436099 (* 1 = 0.436099 loss)
I0421 10:11:44.284876 16809 sgd_solver.cpp:106] Iteration 77107200, lr = 3.9063e-08
I0421 10:16:56.000445 16809 solver.cpp:228] Iteration 77158400, loss = 2.31329
I0421 10:16:56.000525 16809 solver.cpp:244]     Train net output #0: loss = 10.5243 (* 1 = 10.5243 loss)
I0421 10:16:56.000545 16809 sgd_solver.cpp:106] Iteration 77158400, lr = 3.9063e-08
I0421 10:22:05.680723 16809 solver.cpp:228] Iteration 77209600, loss = 2.32505
I0421 10:22:05.680786 16809 solver.cpp:244]     Train net output #0: loss = 0.0782485 (* 1 = 0.0782485 loss)
I0421 10:22:05.680793 16809 sgd_solver.cpp:106] Iteration 77209600, lr = 3.9063e-08
I0421 10:27:13.583412 16809 solver.cpp:228] Iteration 77260800, loss = 2.33643
I0421 10:27:13.583483 16809 solver.cpp:244]     Train net output #0: loss = 5.63623 (* 1 = 5.63623 loss)
I0421 10:27:13.583492 16809 sgd_solver.cpp:106] Iteration 77260800, lr = 3.9063e-08
I0421 10:32:20.473206 16809 solver.cpp:337] Iteration 77312000, Testing net (#0)
I0421 10:32:29.975052 16809 blocking_queue.cpp:50] Data layer prefetch queue empty
I0421 10:32:47.797814 16809 solver.cpp:404]     Test net output #0: accuracy = 0.4734
I0421 10:32:47.797847 16809 solver.cpp:404]     Test net output #1: loss = 2.35715 (* 1 = 2.35715 loss)
I0421 10:32:47.800397 16809 solver.cpp:228] Iteration 77312000, loss = 2.33168
I0421 10:32:47.800415 16809 solver.cpp:244]     Train net output #0: loss = 2.79687 (* 1 = 2.79687 loss)
I0421 10:32:47.800425 16809 sgd_solver.cpp:106] Iteration 77312000, lr = 3.9063e-08
I0421 10:37:58.122311 16809 solver.cpp:228] Iteration 77363200, loss = 2.33779
I0421 10:37:58.122371 16809 solver.cpp:244]     Train net output #0: loss = 0.0947633 (* 1 = 0.0947633 loss)
I0421 10:37:58.122380 16809 sgd_solver.cpp:106] Iteration 77363200, lr = 3.9063e-08
I0421 10:43:04.637344 16809 solver.cpp:228] Iteration 77414400, loss = 2.31266
I0421 10:43:04.637408 16809 solver.cpp:244]     Train net output #0: loss = 0.0119916 (* 1 = 0.0119916 loss)
I0421 10:43:04.637415 16809 sgd_solver.cpp:106] Iteration 77414400, lr = 3.9063e-08
I0421 10:48:11.855598 16809 solver.cpp:228] Iteration 77465600, loss = 2.30447
I0421 10:48:11.855671 16809 solver.cpp:244]     Train net output #0: loss = 0.081288 (* 1 = 0.081288 loss)
I0421 10:48:11.855679 16809 sgd_solver.cpp:106] Iteration 77465600, lr = 3.9063e-08
I0421 10:53:19.429520 16809 solver.cpp:228] Iteration 77516800, loss = 2.304
I0421 10:53:19.429582 16809 solver.cpp:244]     Train net output #0: loss = 0.171195 (* 1 = 0.171195 loss)
I0421 10:53:19.429589 16809 sgd_solver.cpp:106] Iteration 77516800, lr = 3.9063e-08
I0421 10:58:27.317000 16809 solver.cpp:337] Iteration 77568000, Testing net (#0)
I0421 10:58:36.189918 16809 blocking_queue.cpp:50] Data layer prefetch queue empty
I0421 10:58:53.947058 16809 solver.cpp:404]     Test net output #0: accuracy = 0.47356
I0421 10:58:53.947090 16809 solver.cpp:404]     Test net output #1: loss = 2.3573 (* 1 = 2.3573 loss)
I0421 10:58:53.949630 16809 solver.cpp:228] Iteration 77568000, loss = 2.30906
I0421 10:58:53.949647 16809 solver.cpp:244]     Train net output #0: loss = 5.72695 (* 1 = 5.72695 loss)
I0421 10:58:53.949657 16809 sgd_solver.cpp:106] Iteration 77568000, lr = 3.9063e-08
I0421 11:04:09.946789 16809 solver.cpp:228] Iteration 77619200, loss = 2.31242
I0421 11:04:09.946836 16809 solver.cpp:244]     Train net output #0: loss = 0.428201 (* 1 = 0.428201 loss)
I0421 11:04:09.946841 16809 sgd_solver.cpp:106] Iteration 77619200, lr = 3.9063e-08
I0421 11:09:20.155664 16809 solver.cpp:228] Iteration 77670400, loss = 2.30932
I0421 11:09:20.155756 16809 solver.cpp:244]     Train net output #0: loss = 1.07673 (* 1 = 1.07673 loss)
I0421 11:09:20.155766 16809 sgd_solver.cpp:106] Iteration 77670400, lr = 3.9063e-08
I0421 11:14:28.901036 16809 solver.cpp:228] Iteration 77721600, loss = 2.29908
I0421 11:14:28.901105 16809 solver.cpp:244]     Train net output #0: loss = 3.66956 (* 1 = 3.66956 loss)
I0421 11:14:28.901113 16809 sgd_solver.cpp:106] Iteration 77721600, lr = 3.9063e-08
I0421 11:19:36.355717 16809 solver.cpp:228] Iteration 77772800, loss = 2.33468
I0421 11:19:36.355788 16809 solver.cpp:244]     Train net output #0: loss = 4.28965 (* 1 = 4.28965 loss)
I0421 11:19:36.355797 16809 sgd_solver.cpp:106] Iteration 77772800, lr = 3.9063e-08
I0421 11:24:43.884279 16809 solver.cpp:337] Iteration 77824000, Testing net (#0)
I0421 11:24:50.580222 16809 blocking_queue.cpp:50] Data layer prefetch queue empty
I0421 11:25:10.487375 16809 solver.cpp:404]     Test net output #0: accuracy = 0.4735
I0421 11:25:10.487408 16809 solver.cpp:404]     Test net output #1: loss = 2.35753 (* 1 = 2.35753 loss)
I0421 11:25:10.490046 16809 solver.cpp:228] Iteration 77824000, loss = 2.32611
I0421 11:25:10.490080 16809 solver.cpp:244]     Train net output #0: loss = 1.96922 (* 1 = 1.96922 loss)
I0421 11:25:10.490099 16809 sgd_solver.cpp:106] Iteration 77824000, lr = 3.9063e-08
I0421 11:30:22.962256 16809 solver.cpp:228] Iteration 77875200, loss = 2.31597
I0421 11:30:22.962319 16809 solver.cpp:244]     Train net output #0: loss = 0.534138 (* 1 = 0.534138 loss)
I0421 11:30:22.962327 16809 sgd_solver.cpp:106] Iteration 77875200, lr = 3.9063e-08
I0421 11:35:35.178246 16809 solver.cpp:228] Iteration 77926400, loss = 2.32831
I0421 11:35:35.178383 16809 solver.cpp:244]     Train net output #0: loss = 2.77527 (* 1 = 2.77527 loss)
I0421 11:35:35.178413 16809 sgd_solver.cpp:106] Iteration 77926400, lr = 3.9063e-08
I0421 11:40:44.287662 16809 solver.cpp:228] Iteration 77977600, loss = 2.30432
I0421 11:40:44.287721 16809 solver.cpp:244]     Train net output #0: loss = 1.79343 (* 1 = 1.79343 loss)
I0421 11:40:44.287729 16809 sgd_solver.cpp:106] Iteration 77977600, lr = 3.9063e-08
I0421 11:45:53.534060 16809 solver.cpp:228] Iteration 78028800, loss = 2.31304
I0421 11:45:53.534118 16809 solver.cpp:244]     Train net output #0: loss = 0.837678 (* 1 = 0.837678 loss)
I0421 11:45:53.534124 16809 sgd_solver.cpp:106] Iteration 78028800, lr = 3.9063e-08
I0421 11:51:00.015070 16809 solver.cpp:337] Iteration 78080000, Testing net (#0)
I0421 11:51:06.394346 16809 blocking_queue.cpp:50] Data layer prefetch queue empty
I0421 11:51:26.564751 16809 solver.cpp:404]     Test net output #0: accuracy = 0.47416
I0421 11:51:26.564785 16809 solver.cpp:404]     Test net output #1: loss = 2.3565 (* 1 = 2.3565 loss)
I0421 11:51:26.567348 16809 solver.cpp:228] Iteration 78080000, loss = 2.30728
I0421 11:51:26.567368 16809 solver.cpp:244]     Train net output #0: loss = 2.74307 (* 1 = 2.74307 loss)
I0421 11:51:26.567378 16809 sgd_solver.cpp:106] Iteration 78080000, lr = 3.9063e-08
I0421 11:56:32.623474 16809 solver.cpp:228] Iteration 78131200, loss = 2.31562
I0421 11:56:32.623534 16809 solver.cpp:244]     Train net output #0: loss = 2.04589 (* 1 = 2.04589 loss)
I0421 11:56:32.623541 16809 sgd_solver.cpp:106] Iteration 78131200, lr = 3.9063e-08
I0421 12:01:38.483675 16809 solver.cpp:228] Iteration 78182400, loss = 2.32284
I0421 12:01:38.483727 16809 solver.cpp:244]     Train net output #0: loss = 0.91098 (* 1 = 0.91098 loss)
I0421 12:01:38.483736 16809 sgd_solver.cpp:106] Iteration 78182400, lr = 3.9063e-08
I0421 12:06:44.414690 16809 solver.cpp:228] Iteration 78233600, loss = 2.3102
I0421 12:06:44.414763 16809 solver.cpp:244]     Train net output #0: loss = 0.0955981 (* 1 = 0.0955981 loss)
I0421 12:06:44.414770 16809 sgd_solver.cpp:106] Iteration 78233600, lr = 3.9063e-08
I0421 12:11:50.395855 16809 solver.cpp:228] Iteration 78284800, loss = 2.29721
I0421 12:11:50.395942 16809 solver.cpp:244]     Train net output #0: loss = 2.63508 (* 1 = 2.63508 loss)
I0421 12:11:50.395949 16809 sgd_solver.cpp:106] Iteration 78284800, lr = 3.9063e-08
I0421 12:16:56.306061 16809 solver.cpp:337] Iteration 78336000, Testing net (#0)
I0421 12:17:02.680661 16809 blocking_queue.cpp:50] Data layer prefetch queue empty
I0421 12:17:22.796594 16809 solver.cpp:404]     Test net output #0: accuracy = 0.4737
I0421 12:17:22.796627 16809 solver.cpp:404]     Test net output #1: loss = 2.35692 (* 1 = 2.35692 loss)
I0421 12:17:22.799168 16809 solver.cpp:228] Iteration 78336000, loss = 2.31437
I0421 12:17:22.799187 16809 solver.cpp:244]     Train net output #0: loss = 2.54363 (* 1 = 2.54363 loss)
I0421 12:17:22.799197 16809 sgd_solver.cpp:106] Iteration 78336000, lr = 3.9063e-08
I0421 12:22:28.847077 16809 solver.cpp:228] Iteration 78387200, loss = 2.3282
I0421 12:22:28.847153 16809 solver.cpp:244]     Train net output #0: loss = 2.5034e-06 (* 1 = 2.5034e-06 loss)
I0421 12:22:28.847159 16809 sgd_solver.cpp:106] Iteration 78387200, lr = 3.9063e-08
I0421 12:27:34.824456 16809 solver.cpp:228] Iteration 78438400, loss = 2.31075
I0421 12:27:34.824527 16809 solver.cpp:244]     Train net output #0: loss = 0.168928 (* 1 = 0.168928 loss)
I0421 12:27:34.824533 16809 sgd_solver.cpp:106] Iteration 78438400, lr = 3.9063e-08
I0421 12:32:40.945953 16809 solver.cpp:228] Iteration 78489600, loss = 2.33215
I0421 12:32:40.946010 16809 solver.cpp:244]     Train net output #0: loss = 0.0518121 (* 1 = 0.0518121 loss)
I0421 12:32:40.946017 16809 sgd_solver.cpp:106] Iteration 78489600, lr = 3.9063e-08
I0421 12:37:46.946486 16809 solver.cpp:228] Iteration 78540800, loss = 2.33715
I0421 12:37:46.946550 16809 solver.cpp:244]     Train net output #0: loss = 3.93149 (* 1 = 3.93149 loss)
I0421 12:37:46.946565 16809 sgd_solver.cpp:106] Iteration 78540800, lr = 3.9063e-08
I0421 12:42:52.940512 16809 solver.cpp:337] Iteration 78592000, Testing net (#0)
I0421 12:42:59.353849 16809 blocking_queue.cpp:50] Data layer prefetch queue empty
I0421 12:43:19.400187 16809 solver.cpp:404]     Test net output #0: accuracy = 0.47366
I0421 12:43:19.400221 16809 solver.cpp:404]     Test net output #1: loss = 2.35655 (* 1 = 2.35655 loss)
I0421 12:43:19.402770 16809 solver.cpp:228] Iteration 78592000, loss = 2.33882
I0421 12:43:19.402791 16809 solver.cpp:244]     Train net output #0: loss = 9.6239 (* 1 = 9.6239 loss)
I0421 12:43:19.402803 16809 sgd_solver.cpp:106] Iteration 78592000, lr = 3.9063e-08
I0421 12:48:25.707732 16809 solver.cpp:228] Iteration 78643200, loss = 2.33089
I0421 12:48:25.707794 16809 solver.cpp:244]     Train net output #0: loss = 0.667494 (* 1 = 0.667494 loss)
I0421 12:48:25.707800 16809 sgd_solver.cpp:106] Iteration 78643200, lr = 3.9063e-08
I0421 12:53:31.762373 16809 solver.cpp:228] Iteration 78694400, loss = 2.30455
I0421 12:53:31.762445 16809 solver.cpp:244]     Train net output #0: loss = 2.75688 (* 1 = 2.75688 loss)
I0421 12:53:31.762452 16809 sgd_solver.cpp:106] Iteration 78694400, lr = 3.9063e-08
I0421 12:58:38.038195 16809 solver.cpp:228] Iteration 78745600, loss = 2.3072
I0421 12:58:38.038256 16809 solver.cpp:244]     Train net output #0: loss = 0.398383 (* 1 = 0.398383 loss)
I0421 12:58:38.038265 16809 sgd_solver.cpp:106] Iteration 78745600, lr = 3.9063e-08
I0421 13:03:54.951613 16809 solver.cpp:228] Iteration 78796800, loss = 2.30901
I0421 13:03:54.951673 16809 solver.cpp:244]     Train net output #0: loss = 3.27864 (* 1 = 3.27864 loss)
I0421 13:03:54.951683 16809 sgd_solver.cpp:106] Iteration 78796800, lr = 3.9063e-08
I0421 13:18:41.557878 16809 solver.cpp:337] Iteration 78848000, Testing net (#0)
I0421 13:18:51.932579 16809 blocking_queue.cpp:50] Data layer prefetch queue empty
I0421 13:19:16.315253 16809 solver.cpp:404]     Test net output #0: accuracy = 0.47368
I0421 13:19:16.315351 16809 solver.cpp:404]     Test net output #1: loss = 2.35735 (* 1 = 2.35735 loss)
I0421 13:19:16.319406 16809 solver.cpp:228] Iteration 78848000, loss = 2.3125
I0421 13:19:16.319454 16809 solver.cpp:244]     Train net output #0: loss = 0.318055 (* 1 = 0.318055 loss)
I0421 13:19:16.319471 16809 sgd_solver.cpp:106] Iteration 78848000, lr = 3.9063e-08
I0421 13:33:15.959065 16809 solver.cpp:228] Iteration 78899200, loss = 2.30792
I0421 13:33:15.959154 16809 solver.cpp:244]     Train net output #0: loss = 0.165944 (* 1 = 0.165944 loss)
I0421 13:33:15.959167 16809 sgd_solver.cpp:106] Iteration 78899200, lr = 3.9063e-08
I0421 13:47:52.366921 16809 solver.cpp:228] Iteration 78950400, loss = 2.31513
I0421 13:47:52.540827 16809 solver.cpp:244]     Train net output #0: loss = 0.722305 (* 1 = 0.722305 loss)
I0421 13:47:52.540853 16809 sgd_solver.cpp:106] Iteration 78950400, lr = 3.9063e-08
I0421 14:01:55.285233 16809 solver.cpp:228] Iteration 79001600, loss = 2.28401
I0421 14:01:55.466573 16809 solver.cpp:244]     Train net output #0: loss = 2.82148 (* 1 = 2.82148 loss)
I0421 14:01:55.466594 16809 sgd_solver.cpp:106] Iteration 79001600, lr = 3.9063e-08
I0421 14:16:22.774920 16809 solver.cpp:228] Iteration 79052800, loss = 2.32874
I0421 14:16:22.942199 16809 solver.cpp:244]     Train net output #0: loss = 0.994918 (* 1 = 0.994918 loss)
I0421 14:16:22.942219 16809 sgd_solver.cpp:106] Iteration 79052800, lr = 3.9063e-08
I0421 14:31:29.465344 16809 solver.cpp:337] Iteration 79104000, Testing net (#0)
I0421 14:31:47.989686 16809 blocking_queue.cpp:50] Data layer prefetch queue empty
I0421 14:32:03.288633 16809 solver.cpp:404]     Test net output #0: accuracy = 0.47428
I0421 14:32:03.288750 16809 solver.cpp:404]     Test net output #1: loss = 2.35703 (* 1 = 2.35703 loss)
I0421 14:32:03.291646 16809 solver.cpp:228] Iteration 79104000, loss = 2.32024
I0421 14:32:03.291688 16809 solver.cpp:244]     Train net output #0: loss = 0.00101564 (* 1 = 0.00101564 loss)
I0421 14:32:03.291707 16809 sgd_solver.cpp:106] Iteration 79104000, lr = 3.9063e-08
I0421 14:46:07.611739 16809 solver.cpp:228] Iteration 79155200, loss = 2.32388
I0421 14:46:07.611986 16809 solver.cpp:244]     Train net output #0: loss = 1.4001 (* 1 = 1.4001 loss)
I0421 14:46:07.612002 16809 sgd_solver.cpp:106] Iteration 79155200, lr = 3.9063e-08
I0421 15:00:27.005067 16809 solver.cpp:228] Iteration 79206400, loss = 2.3265
I0421 15:00:27.005147 16809 solver.cpp:244]     Train net output #0: loss = 0.898984 (* 1 = 0.898984 loss)
I0421 15:00:27.005161 16809 sgd_solver.cpp:106] Iteration 79206400, lr = 3.9063e-08
I0421 15:14:41.454147 16809 solver.cpp:228] Iteration 79257600, loss = 2.31056
I0421 15:14:41.454252 16809 solver.cpp:244]     Train net output #0: loss = 0.185381 (* 1 = 0.185381 loss)
I0421 15:14:41.454270 16809 sgd_solver.cpp:106] Iteration 79257600, lr = 3.9063e-08
I0421 15:29:05.159605 16809 solver.cpp:228] Iteration 79308800, loss = 2.33156
I0421 15:29:05.337390 16809 solver.cpp:244]     Train net output #0: loss = 2.03342 (* 1 = 2.03342 loss)
I0421 15:29:05.337409 16809 sgd_solver.cpp:106] Iteration 79308800, lr = 3.9063e-08
I0421 15:43:49.016808 16809 solver.cpp:454] Snapshotting to binary proto file snapshots/caffenet128_no_lrn_lsuv_relu_bs1_iter_79360000.caffemodel
I0421 15:43:50.856214 16809 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/caffenet128_no_lrn_lsuv_relu_bs1_iter_79360000.solverstate
I0421 15:43:50.918690 16809 solver.cpp:337] Iteration 79360000, Testing net (#0)
I0421 15:44:09.028024 16809 blocking_queue.cpp:50] Data layer prefetch queue empty
I0421 15:44:23.482197 16809 solver.cpp:404]     Test net output #0: accuracy = 0.4734
I0421 15:44:23.482287 16809 solver.cpp:404]     Test net output #1: loss = 2.35645 (* 1 = 2.35645 loss)
I0421 15:44:23.486191 16809 solver.cpp:228] Iteration 79360000, loss = 2.30695
I0421 15:44:23.486217 16809 solver.cpp:244]     Train net output #0: loss = 3.84955 (* 1 = 3.84955 loss)
I0421 15:44:23.486228 16809 sgd_solver.cpp:106] Iteration 79360000, lr = 3.9063e-08
I0421 15:59:23.388124 16809 solver.cpp:228] Iteration 79411200, loss = 2.32533
I0421 15:59:23.388195 16809 solver.cpp:244]     Train net output #0: loss = 6.40344 (* 1 = 6.40344 loss)
I0421 15:59:23.388206 16809 sgd_solver.cpp:106] Iteration 79411200, lr = 3.9063e-08
I0421 16:13:15.623112 16809 solver.cpp:228] Iteration 79462400, loss = 2.32132
I0421 16:13:15.623205 16809 solver.cpp:244]     Train net output #0: loss = 0.126884 (* 1 = 0.126884 loss)
I0421 16:13:15.623217 16809 sgd_solver.cpp:106] Iteration 79462400, lr = 3.9063e-08
I0421 16:28:08.444056 16809 solver.cpp:228] Iteration 79513600, loss = 2.29709
I0421 16:28:08.445503 16809 solver.cpp:244]     Train net output #0: loss = 5.3329 (* 1 = 5.3329 loss)
I0421 16:28:08.445521 16809 sgd_solver.cpp:106] Iteration 79513600, lr = 3.9063e-08
I0421 16:42:31.425398 16809 solver.cpp:228] Iteration 79564800, loss = 2.30571
I0421 16:42:31.619032 16809 solver.cpp:244]     Train net output #0: loss = 3.78201 (* 1 = 3.78201 loss)
I0421 16:42:31.619053 16809 sgd_solver.cpp:106] Iteration 79564800, lr = 3.9063e-08
I0421 16:56:46.278939 16809 solver.cpp:337] Iteration 79616000, Testing net (#0)
I0421 16:57:10.389572 16809 blocking_queue.cpp:50] Data layer prefetch queue empty
I0421 16:57:21.751672 16809 solver.cpp:404]     Test net output #0: accuracy = 0.47388
I0421 16:57:21.751773 16809 solver.cpp:404]     Test net output #1: loss = 2.35611 (* 1 = 2.35611 loss)
I0421 16:57:21.779606 16809 solver.cpp:228] Iteration 79616000, loss = 2.31804
I0421 16:57:21.779693 16809 solver.cpp:244]     Train net output #0: loss = 0.96953 (* 1 = 0.96953 loss)
I0421 16:57:21.779729 16809 sgd_solver.cpp:106] Iteration 79616000, lr = 3.9063e-08
I0421 17:11:27.965553 16809 solver.cpp:228] Iteration 79667200, loss = 2.3307
I0421 17:11:27.965625 16809 solver.cpp:244]     Train net output #0: loss = 1.86775 (* 1 = 1.86775 loss)
I0421 17:11:27.965637 16809 sgd_solver.cpp:106] Iteration 79667200, lr = 3.9063e-08
I0421 17:25:45.683079 16809 solver.cpp:228] Iteration 79718400, loss = 2.30698
I0421 17:25:45.683179 16809 solver.cpp:244]     Train net output #0: loss = 3.48689 (* 1 = 3.48689 loss)
I0421 17:25:45.683192 16809 sgd_solver.cpp:106] Iteration 79718400, lr = 3.9063e-08
I0421 17:40:20.801436 16809 solver.cpp:228] Iteration 79769600, loss = 2.3343
I0421 17:40:20.801542 16809 solver.cpp:244]     Train net output #0: loss = 4.7647 (* 1 = 4.7647 loss)
I0421 17:40:20.801563 16809 sgd_solver.cpp:106] Iteration 79769600, lr = 3.9063e-08
I0421 17:54:02.182078 16809 solver.cpp:228] Iteration 79820800, loss = 2.33306
I0421 17:54:02.186300 16809 solver.cpp:244]     Train net output #0: loss = 6.97408 (* 1 = 6.97408 loss)
I0421 17:54:02.186316 16809 sgd_solver.cpp:106] Iteration 79820800, lr = 3.9063e-08
I0421 18:08:18.599735 16809 solver.cpp:337] Iteration 79872000, Testing net (#0)
I0421 18:08:47.178369 16809 blocking_queue.cpp:50] Data layer prefetch queue empty
I0421 18:08:53.047930 16809 solver.cpp:404]     Test net output #0: accuracy = 0.47422
I0421 18:08:53.048030 16809 solver.cpp:404]     Test net output #1: loss = 2.35643 (* 1 = 2.35643 loss)
I0421 18:08:53.066886 16809 solver.cpp:228] Iteration 79872000, loss = 2.33276
I0421 18:08:53.066956 16809 solver.cpp:244]     Train net output #0: loss = 5.89863 (* 1 = 5.89863 loss)
I0421 18:08:53.066979 16809 sgd_solver.cpp:106] Iteration 79872000, lr = 3.9063e-08
I0421 18:23:40.834372 16809 solver.cpp:228] Iteration 79923200, loss = 2.3314
I0421 18:23:40.834455 16809 solver.cpp:244]     Train net output #0: loss = 2.15284 (* 1 = 2.15284 loss)
I0421 18:23:40.834465 16809 sgd_solver.cpp:106] Iteration 79923200, lr = 3.9063e-08
I0421 18:37:29.827488 16809 solver.cpp:228] Iteration 79974400, loss = 2.30717
I0421 18:37:29.828063 16809 solver.cpp:244]     Train net output #0: loss = 2.65151 (* 1 = 2.65151 loss)
I0421 18:37:29.828075 16809 sgd_solver.cpp:106] Iteration 79974400, lr = 3.9063e-08
I0421 18:52:29.618460 16809 solver.cpp:228] Iteration 80025600, loss = 2.30996
I0421 18:52:29.618540 16809 solver.cpp:244]     Train net output #0: loss = 0.345266 (* 1 = 0.345266 loss)
I0421 18:52:29.618551 16809 sgd_solver.cpp:106] Iteration 80025600, lr = 3.9063e-08
I0421 19:07:15.909025 16809 solver.cpp:228] Iteration 80076800, loss = 2.31052
I0421 19:07:16.080216 16809 solver.cpp:244]     Train net output #0: loss = 2.60924 (* 1 = 2.60924 loss)
I0421 19:07:16.080236 16809 sgd_solver.cpp:106] Iteration 80076800, lr = 3.9063e-08
I0421 19:21:32.553716 16809 solver.cpp:337] Iteration 80128000, Testing net (#0)
I0421 19:22:07.485389 16809 solver.cpp:404]     Test net output #0: accuracy = 0.47378
I0421 19:22:07.485491 16809 solver.cpp:404]     Test net output #1: loss = 2.35675 (* 1 = 2.35675 loss)
I0421 19:22:07.499320 16809 solver.cpp:228] Iteration 80128000, loss = 2.30832
I0421 19:22:07.499382 16809 solver.cpp:244]     Train net output #0: loss = 2.14167 (* 1 = 2.14167 loss)
I0421 19:22:07.499398 16809 sgd_solver.cpp:106] Iteration 80128000, lr = 3.9063e-08
I0421 19:36:45.263571 16809 solver.cpp:228] Iteration 80179200, loss = 2.30137
I0421 19:36:45.263640 16809 solver.cpp:244]     Train net output #0: loss = 1.74257 (* 1 = 1.74257 loss)
I0421 19:36:45.263658 16809 sgd_solver.cpp:106] Iteration 80179200, lr = 3.9063e-08
I0421 19:51:31.551746 16809 solver.cpp:228] Iteration 80230400, loss = 2.31261
I0421 19:51:31.551815 16809 solver.cpp:244]     Train net output #0: loss = 0.144031 (* 1 = 0.144031 loss)
I0421 19:51:31.551823 16809 sgd_solver.cpp:106] Iteration 80230400, lr = 3.9063e-08
I0421 20:05:36.724341 16809 solver.cpp:228] Iteration 80281600, loss = 2.28808
I0421 20:05:36.724417 16809 solver.cpp:244]     Train net output #0: loss = 1.01678 (* 1 = 1.01678 loss)
I0421 20:05:36.724431 16809 sgd_solver.cpp:106] Iteration 80281600, lr = 3.9063e-08
I0421 20:20:19.324858 16809 solver.cpp:228] Iteration 80332800, loss = 2.32352
I0421 20:20:19.324923 16809 solver.cpp:244]     Train net output #0: loss = 1.71266 (* 1 = 1.71266 loss)
I0421 20:20:19.324934 16809 sgd_solver.cpp:106] Iteration 80332800, lr = 3.9063e-08
I0421 20:34:07.413115 16809 solver.cpp:337] Iteration 80384000, Testing net (#0)
I0421 20:34:09.693825 16809 blocking_queue.cpp:50] Data layer prefetch queue empty
I0421 20:34:42.546428 16809 solver.cpp:404]     Test net output #0: accuracy = 0.47402
I0421 20:34:42.546540 16809 solver.cpp:404]     Test net output #1: loss = 2.35644 (* 1 = 2.35644 loss)
I0421 20:34:42.564993 16809 solver.cpp:228] Iteration 80384000, loss = 2.32545
I0421 20:34:42.565080 16809 solver.cpp:244]     Train net output #0: loss = 0.0959747 (* 1 = 0.0959747 loss)
I0421 20:34:42.565100 16809 sgd_solver.cpp:106] Iteration 80384000, lr = 3.9063e-08
I0421 20:48:35.731978 16809 solver.cpp:228] Iteration 80435200, loss = 2.32587
I0421 20:48:35.732048 16809 solver.cpp:244]     Train net output #0: loss = 0.202827 (* 1 = 0.202827 loss)
I0421 20:48:35.732064 16809 sgd_solver.cpp:106] Iteration 80435200, lr = 3.9063e-08
I0421 21:02:25.918859 16809 solver.cpp:228] Iteration 80486400, loss = 2.32411
I0421 21:02:25.918962 16809 solver.cpp:244]     Train net output #0: loss = 2.6527 (* 1 = 2.6527 loss)
I0421 21:02:25.918979 16809 sgd_solver.cpp:106] Iteration 80486400, lr = 3.9063e-08
I0421 21:16:45.918408 16809 solver.cpp:228] Iteration 80537600, loss = 2.30817
I0421 21:16:45.918479 16809 solver.cpp:244]     Train net output #0: loss = 2.28075 (* 1 = 2.28075 loss)
I0421 21:16:45.918493 16809 sgd_solver.cpp:106] Iteration 80537600, lr = 3.9063e-08
I0421 21:31:13.294030 16809 solver.cpp:228] Iteration 80588800, loss = 2.31554
I0421 21:31:13.465941 16809 solver.cpp:244]     Train net output #0: loss = 1.60356 (* 1 = 1.60356 loss)
I0421 21:31:13.465965 16809 sgd_solver.cpp:106] Iteration 80588800, lr = 3.9063e-08
I0421 21:44:51.248451 16809 solver.cpp:337] Iteration 80640000, Testing net (#0)
I0421 21:44:59.834758 16809 blocking_queue.cpp:50] Data layer prefetch queue empty
I0421 21:45:26.998561 16809 solver.cpp:404]     Test net output #0: accuracy = 0.47388
I0421 21:45:26.998656 16809 solver.cpp:404]     Test net output #1: loss = 2.35564 (* 1 = 2.35564 loss)
I0421 21:45:27.019992 16809 solver.cpp:228] Iteration 80640000, loss = 2.3061
I0421 21:45:27.020066 16809 solver.cpp:244]     Train net output #0: loss = 3.07038 (* 1 = 3.07038 loss)
I0421 21:45:27.020089 16809 sgd_solver.cpp:106] Iteration 80640000, lr = 3.9063e-08
I0421 21:59:24.430200 16809 solver.cpp:228] Iteration 80691200, loss = 2.31963
I0421 21:59:24.434334 16809 solver.cpp:244]     Train net output #0: loss = 6.65076 (* 1 = 6.65076 loss)
I0421 21:59:24.434351 16809 sgd_solver.cpp:106] Iteration 80691200, lr = 3.9063e-08
I0421 22:12:25.512822 16809 solver.cpp:228] Iteration 80742400, loss = 2.31595
I0421 22:12:25.514209 16809 solver.cpp:244]     Train net output #0: loss = 3.66664 (* 1 = 3.66664 loss)
I0421 22:12:25.514225 16809 sgd_solver.cpp:106] Iteration 80742400, lr = 3.9063e-08
I0421 22:25:31.438693 16809 solver.cpp:228] Iteration 80793600, loss = 2.29777
I0421 22:25:31.442597 16809 solver.cpp:244]     Train net output #0: loss = 6.33478 (* 1 = 6.33478 loss)
I0421 22:25:31.442611 16809 sgd_solver.cpp:106] Iteration 80793600, lr = 3.9063e-08
I0421 22:38:23.691426 16809 solver.cpp:228] Iteration 80844800, loss = 2.30545
I0421 22:38:23.695391 16809 solver.cpp:244]     Train net output #0: loss = 0.406285 (* 1 = 0.406285 loss)
I0421 22:38:23.695425 16809 sgd_solver.cpp:106] Iteration 80844800, lr = 3.9063e-08
I0421 22:51:52.254874 16809 solver.cpp:337] Iteration 80896000, Testing net (#0)
I0421 22:52:08.864617 16809 blocking_queue.cpp:50] Data layer prefetch queue empty
I0421 22:52:29.686954 16809 solver.cpp:404]     Test net output #0: accuracy = 0.47398
I0421 22:52:29.687660 16809 solver.cpp:404]     Test net output #1: loss = 2.35565 (* 1 = 2.35565 loss)
I0421 22:52:29.705868 16809 solver.cpp:228] Iteration 80896000, loss = 2.3188
I0421 22:52:29.705938 16809 solver.cpp:244]     Train net output #0: loss = 5.0156 (* 1 = 5.0156 loss)
I0421 22:52:29.705960 16809 sgd_solver.cpp:106] Iteration 80896000, lr = 3.9063e-08
I0421 23:06:14.106480 16809 solver.cpp:228] Iteration 80947200, loss = 2.32729
I0421 23:06:14.106819 16809 solver.cpp:244]     Train net output #0: loss = 5.00973 (* 1 = 5.00973 loss)
I0421 23:06:14.106837 16809 sgd_solver.cpp:106] Iteration 80947200, lr = 3.9063e-08
I0421 23:20:58.368026 16809 solver.cpp:228] Iteration 80998400, loss = 2.31554
I0421 23:20:58.368120 16809 solver.cpp:244]     Train net output #0: loss = 1.23999 (* 1 = 1.23999 loss)
I0421 23:20:58.368132 16809 sgd_solver.cpp:106] Iteration 80998400, lr = 3.9063e-08
I0421 23:34:53.259245 16809 solver.cpp:228] Iteration 81049600, loss = 2.32714
I0421 23:34:53.259323 16809 solver.cpp:244]     Train net output #0: loss = 0.178026 (* 1 = 0.178026 loss)
I0421 23:34:53.259338 16809 sgd_solver.cpp:106] Iteration 81049600, lr = 3.9063e-08
I0421 23:49:34.234361 16809 solver.cpp:228] Iteration 81100800, loss = 2.33673
I0421 23:49:34.234443 16809 solver.cpp:244]     Train net output #0: loss = 1.34335 (* 1 = 1.34335 loss)
I0421 23:49:34.234455 16809 sgd_solver.cpp:106] Iteration 81100800, lr = 3.9063e-08
I0421 23:56:00.337031 16809 solver.cpp:337] Iteration 81152000, Testing net (#0)
I0421 23:56:13.710604 16809 blocking_queue.cpp:50] Data layer prefetch queue empty
I0421 23:56:26.804474 16809 solver.cpp:404]     Test net output #0: accuracy = 0.47392
I0421 23:56:26.804505 16809 solver.cpp:404]     Test net output #1: loss = 2.35598 (* 1 = 2.35598 loss)
I0421 23:56:26.807047 16809 solver.cpp:228] Iteration 81152000, loss = 2.33339
I0421 23:56:26.807065 16809 solver.cpp:244]     Train net output #0: loss = 0.674563 (* 1 = 0.674563 loss)
I0421 23:56:26.807071 16809 sgd_solver.cpp:106] Iteration 81152000, lr = 3.9063e-08
I0422 00:01:28.952271 16809 solver.cpp:228] Iteration 81203200, loss = 2.33632
I0422 00:01:28.952343 16809 solver.cpp:244]     Train net output #0: loss = 3.72394 (* 1 = 3.72394 loss)
I0422 00:01:28.952353 16809 sgd_solver.cpp:106] Iteration 81203200, lr = 3.9063e-08
I0422 00:06:30.692865 16809 solver.cpp:228] Iteration 81254400, loss = 2.30556
I0422 00:06:30.692924 16809 solver.cpp:244]     Train net output #0: loss = 2.35646 (* 1 = 2.35646 loss)
I0422 00:06:30.692934 16809 sgd_solver.cpp:106] Iteration 81254400, lr = 3.9063e-08
I0422 00:11:32.474383 16809 solver.cpp:228] Iteration 81305600, loss = 2.31441
I0422 00:11:32.474455 16809 solver.cpp:244]     Train net output #0: loss = 0.340718 (* 1 = 0.340718 loss)
I0422 00:11:32.474462 16809 sgd_solver.cpp:106] Iteration 81305600, lr = 3.9063e-08
I0422 00:16:34.220278 16809 solver.cpp:228] Iteration 81356800, loss = 2.30006
I0422 00:16:34.399387 16809 solver.cpp:244]     Train net output #0: loss = 0.0452002 (* 1 = 0.0452002 loss)
I0422 00:16:34.399402 16809 sgd_solver.cpp:106] Iteration 81356800, lr = 3.9063e-08
I0422 00:21:36.160120 16809 solver.cpp:337] Iteration 81408000, Testing net (#0)
I0422 00:21:49.557760 16809 blocking_queue.cpp:50] Data layer prefetch queue empty
I0422 00:22:02.583341 16809 solver.cpp:404]     Test net output #0: accuracy = 0.47418
I0422 00:22:02.583374 16809 solver.cpp:404]     Test net output #1: loss = 2.35622 (* 1 = 2.35622 loss)
I0422 00:22:02.585927 16809 solver.cpp:228] Iteration 81408000, loss = 2.30213
I0422 00:22:02.585947 16809 solver.cpp:244]     Train net output #0: loss = 0.000207386 (* 1 = 0.000207386 loss)
I0422 00:22:02.585954 16809 sgd_solver.cpp:106] Iteration 81408000, lr = 3.9063e-08
I0422 00:27:04.527292 16809 solver.cpp:228] Iteration 81459200, loss = 2.30808
I0422 00:27:04.527353 16809 solver.cpp:244]     Train net output #0: loss = 2.61872 (* 1 = 2.61872 loss)
I0422 00:27:04.527359 16809 sgd_solver.cpp:106] Iteration 81459200, lr = 3.9063e-08
I0422 00:32:06.252115 16809 solver.cpp:228] Iteration 81510400, loss = 2.30812
I0422 00:32:06.252174 16809 solver.cpp:244]     Train net output #0: loss = 2.62461 (* 1 = 2.62461 loss)
I0422 00:32:06.252179 16809 sgd_solver.cpp:106] Iteration 81510400, lr = 3.9063e-08
I0422 00:37:08.015506 16809 solver.cpp:228] Iteration 81561600, loss = 2.29521
I0422 00:37:08.015563 16809 solver.cpp:244]     Train net output #0: loss = 6.89655 (* 1 = 6.89655 loss)
I0422 00:37:08.015568 16809 sgd_solver.cpp:106] Iteration 81561600, lr = 3.9063e-08
I0422 00:42:09.798421 16809 solver.cpp:228] Iteration 81612800, loss = 2.3237
I0422 00:42:09.798501 16809 solver.cpp:244]     Train net output #0: loss = 0.267103 (* 1 = 0.267103 loss)
I0422 00:42:09.798508 16809 sgd_solver.cpp:106] Iteration 81612800, lr = 3.9063e-08
I0422 00:47:11.561034 16809 solver.cpp:337] Iteration 81664000, Testing net (#0)
I0422 00:47:25.042227 16809 blocking_queue.cpp:50] Data layer prefetch queue empty
I0422 00:47:38.387704 16809 solver.cpp:404]     Test net output #0: accuracy = 0.47386
I0422 00:47:38.387742 16809 solver.cpp:404]     Test net output #1: loss = 2.35646 (* 1 = 2.35646 loss)
I0422 00:47:38.390455 16809 solver.cpp:228] Iteration 81664000, loss = 2.33201
I0422 00:47:38.390475 16809 solver.cpp:244]     Train net output #0: loss = 0.84665 (* 1 = 0.84665 loss)
I0422 00:47:38.390486 16809 sgd_solver.cpp:106] Iteration 81664000, lr = 3.9063e-08
I0422 00:52:40.273027 16809 solver.cpp:228] Iteration 81715200, loss = 2.3244
I0422 00:52:40.273079 16809 solver.cpp:244]     Train net output #0: loss = 0.24097 (* 1 = 0.24097 loss)
I0422 00:52:40.273087 16809 sgd_solver.cpp:106] Iteration 81715200, lr = 3.9063e-08
I0422 00:57:42.007158 16809 solver.cpp:228] Iteration 81766400, loss = 2.32322
I0422 00:57:42.007230 16809 solver.cpp:244]     Train net output #0: loss = 4.8445 (* 1 = 4.8445 loss)
I0422 00:57:42.007236 16809 sgd_solver.cpp:106] Iteration 81766400, lr = 3.9063e-08
I0422 01:02:43.723009 16809 solver.cpp:228] Iteration 81817600, loss = 2.29925
I0422 01:02:43.723079 16809 solver.cpp:244]     Train net output #0: loss = 4.92957 (* 1 = 4.92957 loss)
I0422 01:02:43.723085 16809 sgd_solver.cpp:106] Iteration 81817600, lr = 3.9063e-08
I0422 01:07:45.449311 16809 solver.cpp:228] Iteration 81868800, loss = 2.32435
I0422 01:07:45.449381 16809 solver.cpp:244]     Train net output #0: loss = 1.26794 (* 1 = 1.26794 loss)
I0422 01:07:45.449388 16809 sgd_solver.cpp:106] Iteration 81868800, lr = 3.9063e-08
I0422 01:12:47.167176 16809 solver.cpp:454] Snapshotting to binary proto file snapshots/caffenet128_no_lrn_lsuv_relu_bs1_iter_81920000.caffemodel
I0422 01:12:47.626559 16809 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/caffenet128_no_lrn_lsuv_relu_bs1_iter_81920000.solverstate
I0422 01:12:47.689580 16809 solver.cpp:317] Iteration 81920000, loss = 2.30725
I0422 01:12:47.689612 16809 solver.cpp:337] Iteration 81920000, Testing net (#0)
I0422 01:13:01.224014 16809 blocking_queue.cpp:50] Data layer prefetch queue empty
I0422 01:13:14.210644 16809 solver.cpp:404]     Test net output #0: accuracy = 0.47406
I0422 01:13:14.210678 16809 solver.cpp:404]     Test net output #1: loss = 2.3554 (* 1 = 2.3554 loss)
I0422 01:13:14.210687 16809 solver.cpp:322] Optimization Done.
I0422 01:13:14.378592 16809 caffe.cpp:222] Optimization Done.
