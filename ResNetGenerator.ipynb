{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/old-ufo/dev/caffe/python/caffe/pycaffe.py:13: RuntimeWarning: to-Python converter for boost::shared_ptr<caffe::Net<float> > already registered; second conversion method ignored.\n",
      "  from ._caffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, \\\n",
      "/home/old-ufo/dev/caffe/python/caffe/pycaffe.py:13: RuntimeWarning: to-Python converter for boost::shared_ptr<caffe::Blob<float> > already registered; second conversion method ignored.\n",
      "  from ._caffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, \\\n",
      "/home/old-ufo/dev/caffe/python/caffe/pycaffe.py:13: RuntimeWarning: to-Python converter for boost::shared_ptr<caffe::Solver<float> > already registered; second conversion method ignored.\n",
      "  from ._caffe import Net, SGDSolver, NesterovSolver, AdaGradSolver, \\\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, '/home/old-ufo/dev/caffe/python')\n",
    "import caffe\n",
    "\n",
    "from pylab import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from caffe import layers as L\n",
    "from caffe import params as P\n",
    "\n",
    "                                            #Orthogonalization\n",
    "import numpy as np\n",
    "\n",
    "net = caffe.NetSpec()\n",
    "namePerfix = \"\"\n",
    "layersArray = []\n",
    "n = caffe.NetSpec()\n",
    "n.data, n.label = L.Data(batch_size=256, backend=P.Data.LMDB, source=\"\",\n",
    "                              ntop=2)\n",
    "n.tops\n",
    "\n",
    "imagenettraindb=\"/home/old-ufo/datasets/imagenet/ilsvrc12_train_shuffle_lmdb\"\n",
    "imagenetvaldb=\"/home/old-ufo/datasets/imagenet/ilsvrc12_val_lmdb\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be running the provided LeNet example (make sure you've downloaded the data and created the databases, as below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def addConvLayer(net,namePrefix,layersArray,channels=0,padding=0,kernel_size=0,\n",
    "                 stride=1,group=1,explicit_name=None,weight_filler=dict(type='xavier'),bias_init=0):\n",
    "    thisLayerName = namePrefix+\"_conv\"+str(len(layersArray))\n",
    "    if(explicit_name != None):\n",
    "        thisLayerName = explicit_name\n",
    "    net.tops[thisLayerName] = L.Convolution(net.tops[layersArray[-1]], \n",
    "                                       kernel_size=kernel_size, \n",
    "                                       num_output=channels,\n",
    "                                       pad=padding,\n",
    "                                       stride=stride,\n",
    "                                       group=group,\n",
    "                                       param=[dict(decay_mult=1),dict(decay_mult=0)],\n",
    "                                       weight_filler=weight_filler,\n",
    "                                       bias_filler=dict(value=bias_init))\n",
    "    layersArray.append(thisLayerName)\n",
    "    return thisLayerName\n",
    "def addEluLayer(net,namePrefix,layersArray,negative_slope=0, in_place=False, explicit_name=None):    \n",
    "    thisLayerName = namePrefix+\"_elu\"+str(len(layersArray)-1)\n",
    "    if(explicit_name != None):\n",
    "        thisLayerName = explicit_name\n",
    "    net.tops[thisLayerName] = L.ELU(net.tops[layersArray[-1]], in_place=in_place,\n",
    "                                     elu_param=dict(alpha=negative_slope))\n",
    "    if(not in_place):\n",
    "        layersArray.append(thisLayerName)\n",
    "    return thisLayerName    \n",
    "def addReluLayer(net,namePrefix,layersArray,negative_slope=0, in_place=False, explicit_name=None):    \n",
    "    thisLayerName = namePrefix+\"_relu\"+str(len(layersArray)-1)\n",
    "    if(explicit_name != None):\n",
    "        thisLayerName = explicit_name\n",
    "    net.tops[thisLayerName] = L.ReLU(net.tops[layersArray[-1]], in_place=in_place,\n",
    "                                     relu_param=dict(negative_slope=negative_slope))\n",
    "    if(not in_place):\n",
    "        layersArray.append(thisLayerName)\n",
    "    return thisLayerName\n",
    "def addConvRelu(net,namePrefix,layersArray,negative_slope=0.2,relu_in_place=False,\n",
    "                channels=0,padding=0,kernel_size=0,stride=1,explicit_name=None):\n",
    "    conv_explicit_name = None\n",
    "    relu_explicit_name = None\n",
    "    if(relu_in_place):\n",
    "        conv_explicit_name = explicit_name\n",
    "    else:\n",
    "        relu_explicit_name = explicit_name\n",
    "        \n",
    "    addConvLayer(net,namePrefix,layersArray,channels=channels,padding=padding,\n",
    "                 kernel_size=kernel_size,stride=stride,explicit_name=conv_explicit_name)\n",
    "    return addReluLayer(net,namePrefix,layersArray,negative_slope=negative_slope,\n",
    "                        in_place=relu_in_place,explicit_name=relu_explicit_name)\n",
    "    \n",
    "def addInnerProductLayer(net,namePrefix,layersArray,num_output = 0,explicit_name=None,bias_init = 0.0):\n",
    "    thisLayerName = namePrefix+\"_ip\"+str(len(layersArray))\n",
    "    if(explicit_name != None):\n",
    "        thisLayerName = explicit_name\n",
    "    net.tops[thisLayerName] = L.InnerProduct(net.tops[layersArray[-1]],\n",
    "                                             num_output = num_output,\n",
    "                                             param=[dict(decay_mult=1),\n",
    "                                                    dict(decay_mult=BIAS_DECAY_MUL)],\n",
    "                                            weight_filler=dict(type='gaussian', std=0.02),\n",
    "                                            bias_filler=dict(value=bias_init))\n",
    "    layersArray.append(thisLayerName)\n",
    "    return thisLayerName\n",
    "def addIPRelu(net,namePrefix,layersArray,negative_slope=0.2,\n",
    "              relu_in_place=False,num_output=0,explicit_name=None):\n",
    "    ip_explicit_name = None\n",
    "    relu_explicit_name = None\n",
    "    if(relu_in_place):\n",
    "        ip_explicit_name = explicit_name\n",
    "    else:\n",
    "        relu_explicit_name = explicit_name\n",
    "        \n",
    "    addInnerProductLayer(net,namePrefix,layersArray,num_output=num_output,explicit_name=ip_explicit_name)\n",
    "    return addReluLayer(net,namePrefix,layersArray,negative_slope=negative_slope,in_place=relu_in_place,explicit_name=relu_explicit_name)\n",
    " \n",
    "def addSoftmaxWithLossLayer(net,namePrefix,layersArray,explicit_name=None,loss_weight=1):\n",
    "    thisLayerName = namePrefix+\"_loss\"+str(len(layersArray))\n",
    "    if(explicit_name != None):\n",
    "        thisLayerName = explicit_name    \n",
    "    net.tops[thisLayerName] = L.SoftmaxWithLoss(net.tops[layersArray[-2]],net.tops[layersArray[-1]],loss_weight=loss_weight)\n",
    "    layersArray.append(thisLayerName)\n",
    "    return thisLayerName\n",
    "def addAccuracyLayer(net,namePrefix,layersArray,explicit_name=None):\n",
    "    thisLayerName = namePrefix+\"_accuracy\"+str(len(layersArray))\n",
    "    if(explicit_name != None):\n",
    "        thisLayerName = explicit_name    \n",
    "    net.tops[thisLayerName] = L.Accuracy(net.tops[layersArray[-2]],net.tops[layersArray[-1]])\n",
    "    layersArray.append(thisLayerName)\n",
    "    return thisLayerName\n",
    "\n",
    "    \n",
    "\n",
    "\"\"\"layer {\n",
    "  name: \"conv1_BN\"\n",
    "  type: \"BatchNorm\" include { phase: TRAIN}\n",
    "  bottom: \"conv1\"\n",
    "  top: \"conv1_BN\"\n",
    "  param {\n",
    "    lr_mult: 0\n",
    "    decay_mult: 0\n",
    "  }\n",
    "  param {\n",
    "    lr_mult: 0\n",
    "    decay_mult: 0\n",
    "  }\n",
    "  param {\n",
    "    lr_mult: 0\n",
    "    decay_mult: 0\n",
    "  }\n",
    "  batch_norm_param {\n",
    "    use_global_stats: false\n",
    "    moving_average_fraction: 0.95\n",
    "  }\n",
    "}\"\"\"    \n",
    "    \n",
    "    \n",
    "def addBatchNormLayer(net,namePrefix,layersArray,moving_average_fraction=0.95,\n",
    "                      use_global_stats=False,explicit_name=None,in_place=False):\n",
    "    thisLayerName = layersArray[-1]+\"_BN\"\n",
    "    if(explicit_name != None):\n",
    "        thisLayerName = explicit_name\n",
    "    net.tops[thisLayerName] = L.BatchNorm(net.tops[layersArray[-1]],\n",
    "                                          param = [dict(lr_mult=0,decay_mult=0)]*3,\n",
    "                                          use_global_stats = use_global_stats,\n",
    "                                          moving_average_fraction = moving_average_fraction\n",
    "                                         )\n",
    "    if(not in_place):\n",
    "        layersArray.append(thisLayerName)\n",
    "    return thisLayerName\n",
    "    \n",
    "\n",
    "def addScaleBiasLayer(net,namePrefix,layersArray,explicit_name=None,scale_init = 1.0,bias_init = 0.0,num_axes=1):\n",
    "    thisLayerName = layersArray[-1]+\"_scaled_biased\"\n",
    "    if(explicit_name != None):\n",
    "        thisLayerName = explicit_name\n",
    "    net.tops[thisLayerName] = L.Scale(net.tops[layersArray[-1]],\n",
    "                                          bias_term=True,\n",
    "                                          filler=dict(value=scale_init),\n",
    "                                          bias_filler=dict(value=bias_init),\n",
    "                                          num_axes=num_axes\n",
    "                                         )\n",
    "    layersArray.append(thisLayerName)    \n",
    "    return thisLayerName\n",
    "    \n",
    "def addBiasLayer(net,namePrefix,layersArray,explicit_name=None,bias_init = 0.0,num_axes=1):\n",
    "    thisLayerName = layersArray[-1]+\"_biased\"\n",
    "    if(explicit_name != None):\n",
    "        thisLayerName = explicit_name\n",
    "    net.tops[thisLayerName] = L.Bias(net.tops[layersArray[-1]],\n",
    "                                          filler=dict(value=bias_init),\n",
    "                                          num_axes=num_axes\n",
    "                                         )\n",
    "    layersArray.append(thisLayerName)    \n",
    "    return thisLayerName\n",
    "    \n",
    "\n",
    "def addDroupoutLayer(net,namePrefix,layersArray,dropout_ratio=0.5,explicit_name=None):\n",
    "    thisLayerName = layersArray[-1]+\"_dropout\"\n",
    "    if(explicit_name != None):\n",
    "        thisLayerName = explicit_name\n",
    "    net.tops[thisLayerName] = L.Dropout(net.tops[layersArray[-1]],\n",
    "                                          dropout_ratio=dropout_ratio\n",
    "                                         )\n",
    "    layersArray.append(thisLayerName)    \n",
    "    return thisLayerName\n",
    "\n",
    "def addEltwiseLayer(net,namePrefix,layersArray,opeation=1,inputlayer1=None,inputlayer2=None, explicit_name=None):\n",
    "    thisLayerName = layersArray[-1]+\"_eltwise\"\n",
    "    if(explicit_name != None):\n",
    "        thisLayerName = explicit_name\n",
    "    net.tops[thisLayerName] = L.Eltwise(net.tops[layersArray[-1]],\n",
    "                                          operation=1, bottom=[inputlayer1])\n",
    "    layersArray.append(thisLayerName)    \n",
    "    return thisLayerName\n",
    "def addEALayer(net,namePrefix,layersArray,opeation=1,inputlayer1=None,inputlayer2=None, explicit_name=None):\n",
    "    thisLayerName = layersArray[-1]+\"_EA\"\n",
    "    if(explicit_name != None):\n",
    "        thisLayerName = explicit_name\n",
    "    net.tops[thisLayerName] = L.EltwiseAffine(net.tops[layersArray[-1]],\n",
    "                                          slope_filler=dict(value=1.0),\n",
    "                                          bias_filler=dict(value=0))\n",
    "    layersArray.append(thisLayerName)    \n",
    "    return thisLayerName\n",
    "def addGlobalAvePoolingLayer(net,namePrefix,layersArray,explicit_name=None):\n",
    "    thisLayerName = layersArray[-1]+\"_global_ave\"\n",
    "    if(explicit_name != None):\n",
    "        thisLayerName = explicit_name\n",
    "        \n",
    "    net.tops[thisLayerName] = L.Pooling(net.tops[layersArray[-1]],\n",
    "                                          pooling_param = dict (\n",
    "            pool = 1,global_pooling = True\n",
    "        )\n",
    "                                         )\n",
    "    layersArray.append(thisLayerName)\n",
    "    return thisLayerName\n",
    "\n",
    "def addAvePoolingLayer(net,namePrefix,layersArray,kernel_size=1,stride=1,explicit_name=None):\n",
    "    thisLayerName = layersArray[-1]+\"_ave\"\n",
    "    if(explicit_name != None):\n",
    "        thisLayerName = explicit_name\n",
    "        \n",
    "    net.tops[thisLayerName] = L.Pooling(net.tops[layersArray[-1]],\n",
    "                                          pooling_param = dict (\n",
    "            pool = 1,kernel_size = kernel_size,stride=stride\n",
    "        )\n",
    "                                         )\n",
    "    layersArray.append(thisLayerName)\n",
    "    return thisLayerName\n",
    "def addMaxPoolingLayer(net,namePrefix,layersArray,kernel_size=1,stride=1,padding=0,explicit_name=None):\n",
    "    thisLayerName = layersArray[-1]+\"_max\"\n",
    "    if(explicit_name != None):\n",
    "        thisLayerName = explicit_name\n",
    "        \n",
    "    net.tops[thisLayerName] = L.Pooling(net.tops[layersArray[-1]],\n",
    "                                          pooling_param = dict (pool = 0,kernel_size = kernel_size,stride=stride,\n",
    "                                                                pad=padding))\n",
    "    layersArray.append(thisLayerName)\n",
    "    return thisLayerName\n",
    "def addFlatResBlock(net,namePrefix,layersArray,negative_slope=0.2,relu_in_place=False,\n",
    "                channels=0,padding=0,kernel_size=0,stride=1,explicit_name=None):\n",
    "    thisLayerName = namePrefix+\"_FlatResBlock\"+str(len(layersArray))\n",
    "    conv1_name=layersArray[-1]\n",
    "    conv_explicit_name = None\n",
    "    relu_explicit_name = None\n",
    "    if(relu_in_place):\n",
    "        conv_explicit_name = explicit_name\n",
    "    else:\n",
    "        relu_explicit_name = explicit_name\n",
    "        \n",
    "    addConvLayer(net,namePrefix,layersArray,channels=channels,padding=padding,\n",
    "                 kernel_size=kernel_size,stride=stride,explicit_name=conv_explicit_name)\n",
    "    addBatchNormLayer(net,namePrefix,layersArray,moving_average_fraction=0.95,\n",
    "                      use_global_stats=False,explicit_name=None)\n",
    "    addReluLayer(net,namePrefix,layersArray,negative_slope=negative_slope,\n",
    "                        in_place=relu_in_place,explicit_name=relu_explicit_name)\n",
    "    \n",
    "    addConvLayer(net,namePrefix,layersArray,channels=channels,padding=padding,\n",
    "                 kernel_size=kernel_size,stride=1,explicit_name=conv_explicit_name)\n",
    "    conv2_name=addBatchNormLayer(net,namePrefix,layersArray,moving_average_fraction=0.95,\n",
    "                      use_global_stats=False,explicit_name=None)\n",
    "    addEltwiseLayer(net,namePrefix,layersArray,opeation=1,inputlayer1=conv1_name,\n",
    "                    inputlayer2=conv2_name, explicit_name=None)\n",
    "    \n",
    "    return addReluLayer(net,namePrefix,layersArray,negative_slope=negative_slope,\n",
    "                        in_place=relu_in_place,explicit_name=relu_explicit_name)\n",
    "\n",
    "def addBottleNeckResBlock(net,namePrefix,layersArray,negative_slope=0.2,relu_in_place=False,\n",
    "                channels_wide=0,channels_narrow=0,padding=0,kernel_size=0,stride=1,explicit_name=None):\n",
    "    thisLayerName = namePrefix+\"_BottleNeckResBlock\"+str(len(layersArray))\n",
    "    conv1_name=layersArray[-1]\n",
    "    conv_explicit_name = None\n",
    "    relu_explicit_name = None\n",
    "    if(relu_in_place):\n",
    "        conv_explicit_name = explicit_name\n",
    "    else:\n",
    "        relu_explicit_name = explicit_name\n",
    "        \n",
    "    addConvLayer(net,namePrefix,layersArray,channels=channels_narrow,padding=0,\n",
    "                 kernel_size=1,stride=stride,explicit_name=conv_explicit_name)\n",
    "    addBatchNormLayer(net,namePrefix,layersArray,moving_average_fraction=0.95,\n",
    "                      use_global_stats=False,explicit_name=None)\n",
    "    addReluLayer(net,namePrefix,layersArray,negative_slope=negative_slope,\n",
    "                        in_place=relu_in_place,explicit_name=relu_explicit_name)\n",
    "    \n",
    "    addConvLayer(net,namePrefix,layersArray,channels=channels_narrow,padding=padding,\n",
    "                 kernel_size=kernel_size,stride=1,explicit_name=conv_explicit_name)\n",
    "    addBatchNormLayer(net,namePrefix,layersArray,moving_average_fraction=0.95,\n",
    "                      use_global_stats=False,explicit_name=None)\n",
    "    addReluLayer(net,namePrefix,layersArray,negative_slope=negative_slope,\n",
    "                        in_place=relu_in_place,explicit_name=relu_explicit_name)\n",
    "    \n",
    "    addConvLayer(net,namePrefix,layersArray,channels=channels_wide,padding=0,\n",
    "                 kernel_size=1,stride=1,explicit_name=conv_explicit_name)\n",
    "    conv2_name=addBatchNormLayer(net,namePrefix,layersArray,moving_average_fraction=0.95,\n",
    "                      use_global_stats=False,explicit_name=None)\n",
    "    \n",
    "    addEltwiseLayer(net,namePrefix,layersArray,opeation=1,\n",
    "                    inputlayer1=str(conv1_name), explicit_name=None)\n",
    "    return addReluLayer(net,namePrefix,layersArray,negative_slope=negative_slope,\n",
    "                        in_place=False,explicit_name=relu_explicit_name)\n",
    "def addBottleNeckResBlockELUnoBN(net,namePrefix,layersArray,negative_slope=0.2,relu_in_place=False,\n",
    "                channels_wide=0,channels_narrow=0,padding=0,kernel_size=0,stride=1,explicit_name=None):\n",
    "    thisLayerName = namePrefix+\"_BottleNeckResBlock\"+str(len(layersArray))\n",
    "    conv1_name=layersArray[-1]\n",
    "    conv_explicit_name = None\n",
    "    relu_explicit_name = None\n",
    "    if(relu_in_place):\n",
    "        conv_explicit_name = explicit_name\n",
    "    else:\n",
    "        relu_explicit_name = explicit_name\n",
    "    alpha=1    \n",
    "    addConvLayer(net,namePrefix,layersArray,channels=channels_narrow,padding=0,\n",
    "                 kernel_size=1,stride=stride,explicit_name=conv_explicit_name)\n",
    "    addEluLayer(net,namePrefix,layersArray,negative_slope=alpha,\n",
    "                        in_place=relu_in_place,explicit_name=relu_explicit_name)\n",
    "    \n",
    "    addConvLayer(net,namePrefix,layersArray,channels=channels_narrow,padding=padding,\n",
    "                 kernel_size=kernel_size,stride=1,explicit_name=conv_explicit_name)\n",
    "    addEluLayer(net,namePrefix,layersArray,negative_slope=alpha,\n",
    "                        in_place=relu_in_place,explicit_name=relu_explicit_name)\n",
    "    \n",
    "    conv2_name=addConvLayer(net,namePrefix,layersArray,channels=channels_wide,padding=0,\n",
    "                 kernel_size=1,stride=1,explicit_name=conv_explicit_name)\n",
    "    addEltwiseLayer(net,namePrefix,layersArray,opeation=1,\n",
    "                    inputlayer1=str(conv1_name), explicit_name=None)\n",
    "    return  addEluLayer(net,namePrefix,layersArray,negative_slope=alpha,\n",
    "                        in_place=relu_in_place,explicit_name=relu_explicit_name)\n",
    "\n",
    "def addBottleNeckResBlockNoBN(net,namePrefix,layersArray,negative_slope=0.2,relu_in_place=False,\n",
    "                channels_wide=0,channels_narrow=0,padding=0,kernel_size=0,stride=1,explicit_name=None):\n",
    "    thisLayerName = namePrefix+\"_BottleNeckResBlock\"+str(len(layersArray))\n",
    "    conv1_name=layersArray[-1]\n",
    "    conv_explicit_name = None\n",
    "    relu_explicit_name = None\n",
    "    if(relu_in_place):\n",
    "        conv_explicit_name = explicit_name\n",
    "    else:\n",
    "        relu_explicit_name = explicit_name\n",
    "        \n",
    "    addConvLayer(net,namePrefix,layersArray,channels=channels_narrow,padding=0,\n",
    "                 kernel_size=1,stride=stride,explicit_name=conv_explicit_name)\n",
    "    #addBatchNormLayer(net,namePrefix,layersArray,moving_average_fraction=0.95,\n",
    "    #                  use_global_stats=False,explicit_name=None)\n",
    "    addReluLayer(net,namePrefix,layersArray,negative_slope=negative_slope,\n",
    "                        in_place=relu_in_place,explicit_name=relu_explicit_name)\n",
    "    \n",
    "    addConvLayer(net,namePrefix,layersArray,channels=channels_narrow,padding=padding,\n",
    "                 kernel_size=kernel_size,stride=1,explicit_name=conv_explicit_name)\n",
    "    #addBatchNormLayer(net,namePrefix,layersArray,moving_average_fraction=0.95,\n",
    "    #                  use_global_stats=False,explicit_name=None)\n",
    "    addReluLayer(net,namePrefix,layersArray,negative_slope=negative_slope,\n",
    "                        in_place=relu_in_place,explicit_name=relu_explicit_name)\n",
    "    \n",
    "    addConvLayer(net,namePrefix,layersArray,channels=channels_wide,padding=0,\n",
    "                 kernel_size=1,stride=1,explicit_name=conv_explicit_name)\n",
    "    #conv2_name=addBatchNormLayer(net,namePrefix,layersArray,moving_average_fraction=0.95,\n",
    "    #                  use_global_stats=False,explicit_name=None)\n",
    "    \n",
    "    addEltwiseLayer(net,namePrefix,layersArray,opeation=1,\n",
    "                    inputlayer1=str(conv1_name), explicit_name=None)\n",
    "    return addReluLayer(net,namePrefix,layersArray,negative_slope=negative_slope,\n",
    "                        in_place=False,explicit_name=relu_explicit_name)\n",
    "def addBottleNeckResBlockBNEA(net,namePrefix,layersArray,negative_slope=0.2,relu_in_place=False,\n",
    "                channels_wide=0,channels_narrow=0,padding=0,kernel_size=0,stride=1,explicit_name=None):\n",
    "    thisLayerName = namePrefix+\"_BottleNeckResBlock\"+str(len(layersArray))\n",
    "    conv1_name=layersArray[-1]\n",
    "    conv_explicit_name = None\n",
    "    relu_explicit_name = None\n",
    "    if(relu_in_place):\n",
    "        conv_explicit_name = explicit_name\n",
    "    else:\n",
    "        relu_explicit_name = explicit_name\n",
    "        \n",
    "    addConvLayer(net,namePrefix,layersArray,channels=channels_narrow,padding=0,\n",
    "                 kernel_size=1,stride=stride,explicit_name=conv_explicit_name)\n",
    "    addBatchNormLayer(net,namePrefix,layersArray,moving_average_fraction=0.95,\n",
    "                      use_global_stats=False,explicit_name=None)\n",
    "    addEALayer(net,namePrefix,layersArray,explicit_name=None)\n",
    "    addReluLayer(net,namePrefix,layersArray,negative_slope=negative_slope,\n",
    "                        in_place=relu_in_place,explicit_name=relu_explicit_name)\n",
    "    \n",
    "    addConvLayer(net,namePrefix,layersArray,channels=channels_narrow,padding=padding,\n",
    "                 kernel_size=kernel_size,stride=1,explicit_name=conv_explicit_name)\n",
    "    addBatchNormLayer(net,namePrefix,layersArray,moving_average_fraction=0.95,\n",
    "                      use_global_stats=False,explicit_name=None)\n",
    "    addEALayer(net,namePrefix,layersArray,explicit_name=None)\n",
    "    addReluLayer(net,namePrefix,layersArray,negative_slope=negative_slope,\n",
    "                        in_place=relu_in_place,explicit_name=relu_explicit_name)\n",
    "    \n",
    "    addConvLayer(net,namePrefix,layersArray,channels=channels_wide,padding=0,\n",
    "                 kernel_size=1,stride=1,explicit_name=conv_explicit_name)\n",
    "    addBatchNormLayer(net,namePrefix,layersArray,moving_average_fraction=0.95,\n",
    "                      use_global_stats=False,explicit_name=None)\n",
    "    addEALayer(net,namePrefix,layersArray,explicit_name=None)\n",
    "    addEltwiseLayer(net,namePrefix,layersArray,opeation=1,\n",
    "                    inputlayer1=str(conv1_name), explicit_name=None)\n",
    "    return addReluLayer(net,namePrefix,layersArray,negative_slope=negative_slope,\n",
    "                        in_place=False,explicit_name=relu_explicit_name)\n",
    "def addBottleNeckResBlockBNScaleBias(net,namePrefix,layersArray,negative_slope=0.2,relu_in_place=False,\n",
    "                channels_wide=0,channels_narrow=0,padding=0,kernel_size=0,stride=1,explicit_name=None):\n",
    "    thisLayerName = namePrefix+\"_BottleNeckResBlock\"+str(len(layersArray))\n",
    "    conv1_name=layersArray[-1]\n",
    "    conv_explicit_name = None\n",
    "    relu_explicit_name = None\n",
    "    if(relu_in_place):\n",
    "        conv_explicit_name = explicit_name\n",
    "    else:\n",
    "        relu_explicit_name = explicit_name\n",
    "        \n",
    "    addConvLayer(net,namePrefix,layersArray,channels=channels_narrow,padding=0,\n",
    "                 kernel_size=1,stride=stride,explicit_name=conv_explicit_name)\n",
    "    addBatchNormLayer(net,namePrefix,layersArray,moving_average_fraction=0.95,\n",
    "                      use_global_stats=False,explicit_name=None)\n",
    "    addScaleBiasLayer(net,namePrefix,layersArray,explicit_name=None,scale_init = 1.0,bias_init = 0.0,num_axes=1)\n",
    "    addReluLayer(net,namePrefix,layersArray,negative_slope=negative_slope,\n",
    "                        in_place=relu_in_place,explicit_name=relu_explicit_name)\n",
    "    \n",
    "    addConvLayer(net,namePrefix,layersArray,channels=channels_narrow,padding=padding,\n",
    "                 kernel_size=kernel_size,stride=1,explicit_name=conv_explicit_name)\n",
    "    addBatchNormLayer(net,namePrefix,layersArray,moving_average_fraction=0.95,\n",
    "                      use_global_stats=False,explicit_name=None)\n",
    "    addScaleBiasLayer(net,namePrefix,layersArray,explicit_name=None,scale_init = 1.0,bias_init = 0.0,num_axes=1)\n",
    "    addReluLayer(net,namePrefix,layersArray,negative_slope=negative_slope,\n",
    "                        in_place=relu_in_place,explicit_name=relu_explicit_name)\n",
    "    \n",
    "    addConvLayer(net,namePrefix,layersArray,channels=channels_wide,padding=0,\n",
    "                 kernel_size=1,stride=1,explicit_name=conv_explicit_name)\n",
    "    addBatchNormLayer(net,namePrefix,layersArray,moving_average_fraction=0.95,\n",
    "                      use_global_stats=False,explicit_name=None)\n",
    "    addScaleBiasLayer(net,namePrefix,layersArray,explicit_name=None,scale_init = 1.0,bias_init = 0.0,num_axes=1)\n",
    "    addEltwiseLayer(net,namePrefix,layersArray,opeation=1,\n",
    "                    inputlayer1=str(conv1_name), explicit_name=None)\n",
    "    return addReluLayer(net,namePrefix,layersArray,negative_slope=negative_slope,\n",
    "                        in_place=False,explicit_name=relu_explicit_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ThinResNetNoBN(bs=256, db='db1'):\n",
    "    net = caffe.NetSpec()\n",
    "    layersArray=[];\n",
    "    namePrefix='block1'\n",
    "    \n",
    "    net.tops[\"data\"],net.tops[\"label\"] = L.Data(batch_size=256, backend=P.Data.LMDB, source=db,  ntop=2)  \n",
    "    layersArray=['data']\n",
    " #   net.tops[\"RandomDescriptor\"] = L.DummyData(dummy_data_param = dict(\n",
    " #           shape = dict(dim=[bs,256]),\n",
    " #                        data_filler=dict(type=\"gaussian\")))\n",
    " #   layersArray=[\"RandomDescriptor\"]\n",
    "    addConvLayer(net,namePrefix,layersArray,channels=64,padding=0,\n",
    "                 kernel_size=7,stride=2)\n",
    " #   addBatchNormLayer(net,namePrefix,layersArray,moving_average_fraction=0.95,\n",
    " #                     use_global_stats=False,explicit_name=None)\n",
    "    addReluLayer(net,namePrefix,layersArray,negative_slope=0,\n",
    "                        in_place=True,explicit_name=None)\n",
    "    addMaxPoolingLayer(net,namePrefix,layersArray,kernel_size=3,stride=2,explicit_name=None)\n",
    "        #Block2\n",
    "    namePrefix='block2'\n",
    "\n",
    "    addConvLayer(net,namePrefix,layersArray,channels=256,padding=0,\n",
    "             kernel_size=1,stride=2)\n",
    "    addReluLayer(net,namePrefix,layersArray,negative_slope=0,\n",
    "                        in_place=True,explicit_name=None)\n",
    "    for i in range(3):\n",
    "        addBottleNeckResBlock(net,namePrefix,layersArray,negative_slope=0,relu_in_place=True,\n",
    "                              channels_wide=256,channels_narrow=64,padding=1,\n",
    "                              kernel_size=3,stride=1,explicit_name=None);         \n",
    "    namePrefix='block3'\n",
    "    addConvLayer(net,namePrefix,layersArray,channels=512,padding=0,\n",
    "             kernel_size=1,stride=2)\n",
    "    addReluLayer(net,namePrefix,layersArray,negative_slope=0,\n",
    "                        in_place=True,explicit_name=None)\n",
    "    for i in range(2):\n",
    "        addBottleNeckResBlock(net,namePrefix,layersArray,negative_slope=0,relu_in_place=True,\n",
    "                              channels_wide=512,channels_narrow=128,padding=1,\n",
    "                              kernel_size=3,stride=1,explicit_name=None);\n",
    "    namePrefix='block4'\n",
    "    addConvLayer(net,namePrefix,layersArray,channels=1024,padding=0,\n",
    "             kernel_size=1,stride=2)\n",
    "    addReluLayer(net,namePrefix,layersArray,negative_slope=0,\n",
    "                        in_place=True,explicit_name=None)\n",
    "    for i in range(23):\n",
    "        addBottleNeckResBlock(net,namePrefix,layersArray,negative_slope=0,relu_in_place=True,\n",
    "                              channels_wide=1024,channels_narrow=256,padding=1,\n",
    "                              kernel_size=3,stride=1,explicit_name=None);\n",
    "\n",
    "  #  addConvLayer(net,namePrefix,layersArray,channels=2048,padding=0,\n",
    "  #           kernel_size=1,stride=2)\n",
    "  #  addReluLayer(net,namePrefix,layersArray,negative_slope=0,\n",
    "  #                      in_place=True,explicit_name=None)\n",
    "\n",
    "    \n",
    "  #  namePrefix='block5'\n",
    "  #  for i in range(3):\n",
    "  #      addBottleNeckResBlock(net,namePrefix,layersArray,negative_slope=0,relu_in_place=True,\n",
    "  #                            channels_wide=2048,channels_narrow=512,padding=1,\n",
    "  #                            kernel_size=3,stride=1,explicit_name=None);\n",
    "\n",
    "    namePrefix='final'\n",
    "    addConvLayer(net,namePrefix,layersArray,channels=1024,padding=0,\n",
    "             kernel_size=1,stride=1)\n",
    "  #  addBatchNormLayer(net,namePrefix,layersArray,moving_average_fraction=0.95,\n",
    "  #                    use_global_stats=False,explicit_name=None)\n",
    "  \n",
    "    addReluLayer(net,namePrefix,layersArray,negative_slope=0,\n",
    "                        in_place=True,explicit_name=None)\n",
    "    addGlobalAvePoolingLayer(net,namePrefix,layersArray,explicit_name=None)\n",
    "    addConvLayer(net,namePrefix,layersArray,channels=1000,padding=0,kernel_size=1,\n",
    "                 stride=1,group=1,explicit_name=None,weight_filler=dict(type='xavier'),bias_init=0)\n",
    "    clf_name=layersArray[-1];\n",
    "    net.tops['loss'] = L.SoftmaxWithLoss(net.tops[clf_name],net.tops['label'],loss_weight=1)\n",
    "    net.tops['acc'] =  L.Accuracy(net.tops[clf_name],net.tops['label'])\n",
    "    \n",
    "    return net.to_proto()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ThinResNet(bs=256, db='db1'):\n",
    "    net = caffe.NetSpec()\n",
    "    layersArray=[];\n",
    "    namePrefix='block1'\n",
    "    \n",
    "    net.tops[\"data\"],net.tops[\"label\"] = L.Data(batch_size=256, backend=P.Data.LMDB, source=db,  ntop=2)  \n",
    "    layersArray=['data']\n",
    " #   net.tops[\"RandomDescriptor\"] = L.DummyData(dummy_data_param = dict(\n",
    " #           shape = dict(dim=[bs,256]),\n",
    " #                        data_filler=dict(type=\"gaussian\")))\n",
    " #   layersArray=[\"RandomDescriptor\"]\n",
    "    addConvLayer(net,namePrefix,layersArray,channels=64,padding=0,\n",
    "                 kernel_size=7,stride=2)\n",
    "    addBatchNormLayer(net,namePrefix,layersArray,moving_average_fraction=0.95,\n",
    "                      use_global_stats=False,explicit_name=None)\n",
    "    addReluLayer(net,namePrefix,layersArray,negative_slope=0,\n",
    "                        in_place=True,explicit_name=None)\n",
    "    addMaxPoolingLayer(net,namePrefix,layersArray,kernel_size=3,stride=2,explicit_name=None)\n",
    "        #Block2\n",
    "    namePrefix='block2'\n",
    "\n",
    "    addConvLayer(net,namePrefix,layersArray,channels=256,padding=0,\n",
    "             kernel_size=1,stride=2)\n",
    "    addBatchNormLayer(net,namePrefix,layersArray,moving_average_fraction=0.95,\n",
    "                      use_global_stats=False,explicit_name=None)\n",
    "    addReluLayer(net,namePrefix,layersArray,negative_slope=0,\n",
    "                        in_place=True,explicit_name=None)\n",
    "    for i in range(3):\n",
    "        addBottleNeckResBlock(net,namePrefix,layersArray,negative_slope=0,relu_in_place=True,\n",
    "                              channels_wide=256,channels_narrow=64,padding=1,\n",
    "                              kernel_size=3,stride=1,explicit_name=None);         \n",
    "    namePrefix='block3'\n",
    "    addConvLayer(net,namePrefix,layersArray,channels=512,padding=0,\n",
    "             kernel_size=1,stride=2)\n",
    "    addReluLayer(net,namePrefix,layersArray,negative_slope=0,\n",
    "                        in_place=True,explicit_name=None)\n",
    "    for i in range(2):\n",
    "        addBottleNeckResBlock(net,namePrefix,layersArray,negative_slope=0,relu_in_place=True,\n",
    "                              channels_wide=512,channels_narrow=128,padding=1,\n",
    "                              kernel_size=3,stride=1,explicit_name=None);\n",
    "    namePrefix='block4'\n",
    "    addConvLayer(net,namePrefix,layersArray,channels=1024,padding=0,\n",
    "             kernel_size=1,stride=2)\n",
    "    addReluLayer(net,namePrefix,layersArray,negative_slope=0,\n",
    "                        in_place=True,explicit_name=None)\n",
    "    for i in range(23):\n",
    "        addBottleNeckResBlock(net,namePrefix,layersArray,negative_slope=0,relu_in_place=True,\n",
    "                              channels_wide=1024,channels_narrow=256,padding=1,\n",
    "                              kernel_size=3,stride=1,explicit_name=None);\n",
    "\n",
    "  #  addConvLayer(net,namePrefix,layersArray,channels=2048,padding=0,\n",
    "  #           kernel_size=1,stride=2)\n",
    "  #  addReluLayer(net,namePrefix,layersArray,negative_slope=0,\n",
    "  #                      in_place=True,explicit_name=None)\n",
    "\n",
    "    \n",
    "  #  namePrefix='block5'\n",
    "  #  for i in range(3):\n",
    "  #      addBottleNeckResBlock(net,namePrefix,layersArray,negative_slope=0,relu_in_place=True,\n",
    "  #                            channels_wide=2048,channels_narrow=512,padding=1,\n",
    "  #                            kernel_size=3,stride=1,explicit_name=None);\n",
    "\n",
    "    namePrefix='final'\n",
    "    addConvLayer(net,namePrefix,layersArray,channels=1024,padding=0,\n",
    "             kernel_size=1,stride=1)\n",
    "    addBatchNormLayer(net,namePrefix,layersArray,moving_average_fraction=0.95,\n",
    "                      use_global_stats=False,explicit_name=None)\n",
    "  \n",
    "    addReluLayer(net,namePrefix,layersArray,negative_slope=0,\n",
    "                        in_place=True,explicit_name=None)\n",
    "    addGlobalAvePoolingLayer(net,namePrefix,layersArray,explicit_name=None)\n",
    "    addConvLayer(net,namePrefix,layersArray,channels=1000,padding=0,kernel_size=1,\n",
    "                 stride=1,group=1,explicit_name=None,weight_filler=dict(type='xavier'),bias_init=0)\n",
    "    clf_name=layersArray[-1];\n",
    "    net.tops['loss'] = L.SoftmaxWithLoss(net.tops[clf_name],net.tops['label'],loss_weight=1)\n",
    "    net.tops['acc'] =  L.Accuracy(net.tops[clf_name],net.tops['label'])\n",
    "    \n",
    "    return net.to_proto()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ThinResNetBNEA(bs=256, db='db1'):\n",
    "    net = caffe.NetSpec()\n",
    "    layersArray=[];\n",
    "    namePrefix='block1'\n",
    "    \n",
    "    net.tops[\"data\"],net.tops[\"label\"] = L.Data(batch_size=256, backend=P.Data.LMDB, source=db,  ntop=2)  \n",
    "    layersArray=['data']\n",
    " #   net.tops[\"RandomDescriptor\"] = L.DummyData(dummy_data_param = dict(\n",
    " #           shape = dict(dim=[bs,256]),\n",
    " #                        data_filler=dict(type=\"gaussian\")))\n",
    " #   layersArray=[\"RandomDescriptor\"]\n",
    "    addConvLayer(net,namePrefix,layersArray,channels=64,padding=0,\n",
    "                 kernel_size=7,stride=2)\n",
    "    addBatchNormLayer(net,namePrefix,layersArray,moving_average_fraction=0.95,\n",
    "                      use_global_stats=False,explicit_name=None)\n",
    "    addEALayer(net,namePrefix,layersArray,explicit_name=None)\n",
    "    addReluLayer(net,namePrefix,layersArray,negative_slope=0,\n",
    "                        in_place=True,explicit_name=None)\n",
    "    addMaxPoolingLayer(net,namePrefix,layersArray,kernel_size=3,stride=2,explicit_name=None)\n",
    "        #Block2\n",
    "    namePrefix='block2'\n",
    "\n",
    "    addConvLayer(net,namePrefix,layersArray,channels=256,padding=0,\n",
    "             kernel_size=1,stride=2)\n",
    "    addBatchNormLayer(net,namePrefix,layersArray,moving_average_fraction=0.95,\n",
    "                      use_global_stats=False,explicit_name=None)\n",
    "    \n",
    "    addEALayer(net,namePrefix,layersArray,explicit_name=None)\n",
    "    addReluLayer(net,namePrefix,layersArray,negative_slope=0,\n",
    "                        in_place=True,explicit_name=None)\n",
    "    for i in range(3):\n",
    "        addBottleNeckResBlockBNEA(net,namePrefix,layersArray,negative_slope=0,relu_in_place=True,\n",
    "                              channels_wide=256,channels_narrow=64,padding=1,\n",
    "                              kernel_size=3,stride=1,explicit_name=None);         \n",
    "    namePrefix='block3'\n",
    "    addConvLayer(net,namePrefix,layersArray,channels=512,padding=0,\n",
    "             kernel_size=1,stride=2)\n",
    "    addReluLayer(net,namePrefix,layersArray,negative_slope=0,\n",
    "                        in_place=True,explicit_name=None)\n",
    "    for i in range(2):\n",
    "        addBottleNeckResBlockBNEA(net,namePrefix,layersArray,negative_slope=0,relu_in_place=True,\n",
    "                              channels_wide=512,channels_narrow=128,padding=1,\n",
    "                              kernel_size=3,stride=1,explicit_name=None);\n",
    "    namePrefix='block4'\n",
    "    addConvLayer(net,namePrefix,layersArray,channels=1024,padding=0,\n",
    "             kernel_size=1,stride=2)\n",
    "    addReluLayer(net,namePrefix,layersArray,negative_slope=0,\n",
    "                        in_place=True,explicit_name=None)\n",
    "    addBatchNormLayer(net,namePrefix,layersArray,moving_average_fraction=0.95,\n",
    "                      use_global_stats=False,explicit_name=None)\n",
    "    \n",
    "    addEALayer(net,namePrefix,layersArray,explicit_name=None)\n",
    "    for i in range(23):\n",
    "        addBottleNeckResBlockBNEA(net,namePrefix,layersArray,negative_slope=0,relu_in_place=True,\n",
    "                              channels_wide=1024,channels_narrow=256,padding=1,\n",
    "                              kernel_size=3,stride=1,explicit_name=None);\n",
    "\n",
    "  #  addConvLayer(net,namePrefix,layersArray,channels=2048,padding=0,\n",
    "  #           kernel_size=1,stride=2)\n",
    "  #  addReluLayer(net,namePrefix,layersArray,negative_slope=0,\n",
    "  #                      in_place=True,explicit_name=None)\n",
    "\n",
    "    \n",
    "  #  namePrefix='block5'\n",
    "  #  for i in range(3):\n",
    "  #      addBottleNeckResBlock(net,namePrefix,layersArray,negative_slope=0,relu_in_place=True,\n",
    "  #                            channels_wide=2048,channels_narrow=512,padding=1,\n",
    "  #                            kernel_size=3,stride=1,explicit_name=None);\n",
    "\n",
    "    namePrefix='final'\n",
    "    addConvLayer(net,namePrefix,layersArray,channels=1024,padding=0,\n",
    "             kernel_size=1,stride=1)\n",
    "    addBatchNormLayer(net,namePrefix,layersArray,moving_average_fraction=0.95,\n",
    "                      use_global_stats=False,explicit_name=None)\n",
    "  \n",
    "    addEALayer(net,namePrefix,layersArray,explicit_name=None)\n",
    "    addReluLayer(net,namePrefix,layersArray,negative_slope=0,\n",
    "                        in_place=True,explicit_name=None)\n",
    "    addGlobalAvePoolingLayer(net,namePrefix,layersArray,explicit_name=None)\n",
    "    addConvLayer(net,namePrefix,layersArray,channels=1000,padding=0,kernel_size=1,\n",
    "                 stride=1,group=1,explicit_name=None,weight_filler=dict(type='xavier'),bias_init=0)\n",
    "    clf_name=layersArray[-1];\n",
    "    net.tops['loss'] = L.SoftmaxWithLoss(net.tops[clf_name],net.tops['label'],loss_weight=1)\n",
    "    net.tops['acc'] =  L.Accuracy(net.tops[clf_name],net.tops['label'])\n",
    "    \n",
    "    return net.to_proto()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ThinResNet50(bs=256, db='db1'):\n",
    "    net = caffe.NetSpec()\n",
    "    layersArray=[];\n",
    "    namePrefix='block1'\n",
    "    \n",
    "    net.tops[\"data\"],net.tops[\"label\"] = L.Data(batch_size=256, backend=P.Data.LMDB, source=db,  ntop=2)  \n",
    "    layersArray=['data']\n",
    " #   net.tops[\"RandomDescriptor\"] = L.DummyData(dummy_data_param = dict(\n",
    " #           shape = dict(dim=[bs,256]),\n",
    " #                        data_filler=dict(type=\"gaussian\")))\n",
    " #   layersArray=[\"RandomDescriptor\"]\n",
    "    addConvLayer(net,namePrefix,layersArray,channels=64,padding=0,\n",
    "                 kernel_size=7,stride=2)\n",
    "    addBatchNormLayer(net,namePrefix,layersArray,moving_average_fraction=0.98,\n",
    "                      use_global_stats=False,explicit_name=None,in_place=True)\n",
    "    addReluLayer(net,namePrefix,layersArray,negative_slope=0,\n",
    "                        in_place=True,explicit_name=None)\n",
    "    addMaxPoolingLayer(net,namePrefix,layersArray,kernel_size=3,stride=2,explicit_name=None)\n",
    "    \n",
    "    addConvLayer(net,namePrefix,layersArray,channels=256,padding=0,\n",
    "                 kernel_size=1,stride=2)\n",
    "        #Block2\n",
    "    namePrefix='block2'\n",
    "    for i in range(3):\n",
    "        addBottleNeckResBlock(net,namePrefix,layersArray,negative_slope=0,relu_in_place=True,\n",
    "                              channels_wide=256,channels_narrow=64,padding=1,\n",
    "                              kernel_size=3,stride=1,explicit_name=None,bn_in_place=True); \n",
    "    addConvLayer(net,namePrefix,layersArray,channels=512,padding=0,\n",
    "                 kernel_size=1,stride=2)\n",
    "    \n",
    "    namePrefix='block3'\n",
    "#    addConvLayer(net,namePrefix,layersArray,channels=512,padding=0,\n",
    "#             kernel_size=1,stride=2)\n",
    "#    addReluLayer(net,namePrefix,layersArray,negative_slope=0,\n",
    "#                        in_place=True,explicit_name=None)\n",
    "    for i in range(4):\n",
    "        addBottleNeckResBlock(net,namePrefix,layersArray,negative_slope=0,relu_in_place=True,\n",
    "                              channels_wide=512,channels_narrow=128,padding=1,\n",
    "                              kernel_size=3,stride=1,explicit_name=None,bn_in_place=True);\n",
    "    addConvLayer(net,namePrefix,layersArray,channels=1024,padding=0,\n",
    "                 kernel_size=1,stride=2)\n",
    "    \n",
    "    namePrefix='block4'\n",
    "#    addConvLayer(net,namePrefix,layersArray,channels=1024,padding=0,\n",
    "#             kernel_size=1,stride=2)\n",
    "#    addReluLayer(net,namePrefix,layersArray,negative_slope=0,\n",
    "#                        in_place=True,explicit_name=None)\n",
    "\n",
    "    for i in range(6):\n",
    "        addBottleNeckResBlock(net,namePrefix,layersArray,negative_slope=0,relu_in_place=True,\n",
    "                              channels_wide=1024,channels_narrow=256,padding=1,\n",
    "                              kernel_size=3,stride=1,explicit_name=None,bn_in_place=True);\n",
    "    addConvLayer(net,namePrefix,layersArray,channels=2048,padding=0,\n",
    "                 kernel_size=1,stride=2)\n",
    "    \n",
    "  #  addConvLayer(net,namePrefix,layersArray,channels=2048,padding=0,\n",
    "  #           kernel_size=1,stride=2)\n",
    "  #  addReluLayer(net,namePrefix,layersArray,negative_slope=0,\n",
    "  #                      in_place=True,explicit_name=None)\n",
    "\n",
    "    \n",
    "    namePrefix='block5'\n",
    "    for i in range(3):\n",
    "        addBottleNeckResBlock(net,namePrefix,layersArray,negative_slope=0,relu_in_place=True,\n",
    "                              channels_wide=2048,channels_narrow=512,padding=1,\n",
    "                             kernel_size=3,stride=1,explicit_name=None,bn_in_place=True);\n",
    "\n",
    "    namePrefix='final'\n",
    "    addGlobalAvePoolingLayer(net,namePrefix,layersArray,explicit_name=None)\n",
    "    addConvLayer(net,namePrefix,layersArray,channels=1000,padding=0,kernel_size=1,\n",
    "                 stride=1,group=1,explicit_name=None,weight_filler=dict(type='xavier'),bias_init=0)\n",
    "    clf_name=layersArray[-1];\n",
    "    net.tops['loss'] = L.SoftmaxWithLoss(net.tops[clf_name],net.tops['label'],loss_weight=1)\n",
    "    net.tops['acc'] =  L.Accuracy(net.tops[clf_name],net.tops['label'])\n",
    "    \n",
    "    return net.to_proto()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ThinResNet50BNAfter(bs=256, db='db1'):\n",
    "    net = caffe.NetSpec()\n",
    "    layersArray=[];\n",
    "    namePrefix='block1'\n",
    "    \n",
    "    net.tops[\"data\"],net.tops[\"label\"] = L.Data(batch_size=256, backend=P.Data.LMDB, source=db,  ntop=2)  \n",
    "    layersArray=['data']\n",
    " #   net.tops[\"RandomDescriptor\"] = L.DummyData(dummy_data_param = dict(\n",
    " #           shape = dict(dim=[bs,256]),\n",
    " #                        data_filler=dict(type=\"gaussian\")))\n",
    " #   layersArray=[\"RandomDescriptor\"]\n",
    "    addConvLayer(net,namePrefix,layersArray,channels=64,padding=0,\n",
    "                 kernel_size=7,stride=2)\n",
    "    addReluLayer(net,namePrefix,layersArray,negative_slope=0,\n",
    "                        in_place=True,explicit_name=None)\n",
    "    addBatchNormLayer(net,namePrefix,layersArray,moving_average_fraction=0.98,\n",
    "                      use_global_stats=False,explicit_name=None,in_place=True)\n",
    "    addMaxPoolingLayer(net,namePrefix,layersArray,kernel_size=3,stride=2,explicit_name=None)\n",
    "    \n",
    "    addConvLayer(net,namePrefix,layersArray,channels=256,padding=0,\n",
    "                 kernel_size=1,stride=1)\n",
    "        #Block2\n",
    "    namePrefix='block2'\n",
    "    for i in range(3):\n",
    "        addBottleNeckResBlockBNAfter1(net,namePrefix,layersArray,negative_slope=0,relu_in_place=True,\n",
    "                              channels_wide=256,channels_narrow=64,padding=1,\n",
    "                              kernel_size=3,stride=1,explicit_name=None,bn_in_place=True); \n",
    "    addConvLayer(net,namePrefix,layersArray,channels=512,padding=0,\n",
    "                 kernel_size=1,stride=2)\n",
    "    \n",
    "    namePrefix='block3'\n",
    "#    addConvLayer(net,namePrefix,layersArray,channels=512,padding=0,\n",
    "#             kernel_size=1,stride=2)\n",
    "#    addReluLayer(net,namePrefix,layersArray,negative_slope=0,\n",
    "#                        in_place=True,explicit_name=None)\n",
    "    for i in range(4):\n",
    "        addBottleNeckResBlockBNAfter1(net,namePrefix,layersArray,negative_slope=0,relu_in_place=True,\n",
    "                              channels_wide=512,channels_narrow=128,padding=1,\n",
    "                              kernel_size=3,stride=1,explicit_name=None,bn_in_place=True);\n",
    "    addConvLayer(net,namePrefix,layersArray,channels=1024,padding=0,\n",
    "                 kernel_size=1,stride=2)\n",
    "    \n",
    "    namePrefix='block4'\n",
    "#    addConvLayer(net,namePrefix,layersArray,channels=1024,padding=0,\n",
    "#             kernel_size=1,stride=2)\n",
    "#    addReluLayer(net,namePrefix,layersArray,negative_slope=0,\n",
    "#                        in_place=True,explicit_name=None)\n",
    "\n",
    "    for i in range(6):\n",
    "        addBottleNeckResBlockBNAfter1(net,namePrefix,layersArray,negative_slope=0,relu_in_place=True,\n",
    "                              channels_wide=1024,channels_narrow=256,padding=1,\n",
    "                              kernel_size=3,stride=1,explicit_name=None,bn_in_place=True);\n",
    "    addConvLayer(net,namePrefix,layersArray,channels=2048,padding=0,\n",
    "                 kernel_size=1,stride=2)\n",
    "    \n",
    "  #  addConvLayer(net,namePrefix,layersArray,channels=2048,padding=0,\n",
    "  #           kernel_size=1,stride=2)\n",
    "  #  addReluLayer(net,namePrefix,layersArray,negative_slope=0,\n",
    "  #                      in_place=True,explicit_name=None)\n",
    "\n",
    "    \n",
    "    namePrefix='block5'\n",
    "    for i in range(3):\n",
    "        addBottleNeckResBlockBNAfter1(net,namePrefix,layersArray,negative_slope=0,relu_in_place=True,\n",
    "                              channels_wide=2048,channels_narrow=512,padding=1,\n",
    "                             kernel_size=3,stride=1,explicit_name=None,bn_in_place=True);\n",
    "\n",
    "    namePrefix='final'\n",
    "    addGlobalAvePoolingLayer(net,namePrefix,layersArray,explicit_name=None)\n",
    "    addConvLayer(net,namePrefix,layersArray,channels=1000,padding=0,kernel_size=1,\n",
    "                 stride=1,group=1,explicit_name=None,weight_filler=dict(type='xavier'),bias_init=0)\n",
    "    clf_name=layersArray[-1];\n",
    "    net.tops['loss'] = L.SoftmaxWithLoss(net.tops[clf_name],net.tops['label'],loss_weight=1)\n",
    "    net.tops['acc'] =  L.Accuracy(net.tops[clf_name],net.tops['label'])\n",
    "    \n",
    "    return net.to_proto()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ThinResNet50BNAfter2(bs=256, db='db1'):\n",
    "    net = caffe.NetSpec()\n",
    "    layersArray=[];\n",
    "    namePrefix='block1'\n",
    "    \n",
    "    net.tops[\"data\"],net.tops[\"label\"] = L.Data(batch_size=256, backend=P.Data.LMDB, source=db,  ntop=2)  \n",
    "    layersArray=['data']\n",
    " #   net.tops[\"RandomDescriptor\"] = L.DummyData(dummy_data_param = dict(\n",
    " #           shape = dict(dim=[bs,256]),\n",
    " #                        data_filler=dict(type=\"gaussian\")))\n",
    " #   layersArray=[\"RandomDescriptor\"]\n",
    "    addConvLayer(net,namePrefix,layersArray,channels=64,padding=0,\n",
    "                 kernel_size=7,stride=2)\n",
    "    addReluLayer(net,namePrefix,layersArray,negative_slope=0,\n",
    "                        in_place=True,explicit_name=None)\n",
    "    addBatchNormLayer(net,namePrefix,layersArray,moving_average_fraction=0.98,\n",
    "                      use_global_stats=False,explicit_name=None,in_place=True)\n",
    "    addMaxPoolingLayer(net,namePrefix,layersArray,kernel_size=3,stride=2,explicit_name=None)\n",
    "    \n",
    "    addConvLayer(net,namePrefix,layersArray,channels=256,padding=0,\n",
    "                 kernel_size=1,stride=2)\n",
    "        #Block2\n",
    "    namePrefix='block2'\n",
    "    for i in range(3):\n",
    "        addBottleNeckResBlockBNAfter2(net,namePrefix,layersArray,negative_slope=0,relu_in_place=True,\n",
    "                              channels_wide=256,channels_narrow=64,padding=1,\n",
    "                              kernel_size=3,stride=1,explicit_name=None,bn_in_place=True); \n",
    "    addConvLayer(net,namePrefix,layersArray,channels=512,padding=0,\n",
    "                 kernel_size=1,stride=2)\n",
    "    \n",
    "    namePrefix='block3'\n",
    "#    addConvLayer(net,namePrefix,layersArray,channels=512,padding=0,\n",
    "#             kernel_size=1,stride=2)\n",
    "#    addReluLayer(net,namePrefix,layersArray,negative_slope=0,\n",
    "#                        in_place=True,explicit_name=None)\n",
    "    for i in range(4):\n",
    "        addBottleNeckResBlockBNAfter2(net,namePrefix,layersArray,negative_slope=0,relu_in_place=True,\n",
    "                              channels_wide=512,channels_narrow=128,padding=1,\n",
    "                              kernel_size=3,stride=1,explicit_name=None,bn_in_place=True);\n",
    "    addConvLayer(net,namePrefix,layersArray,channels=1024,padding=0,\n",
    "                 kernel_size=1,stride=2)\n",
    "    \n",
    "    namePrefix='block4'\n",
    "#    addConvLayer(net,namePrefix,layersArray,channels=1024,padding=0,\n",
    "#             kernel_size=1,stride=2)\n",
    "#    addReluLayer(net,namePrefix,layersArray,negative_slope=0,\n",
    "#                        in_place=True,explicit_name=None)\n",
    "\n",
    "    for i in range(6):\n",
    "        addBottleNeckResBlockBNAfter2(net,namePrefix,layersArray,negative_slope=0,relu_in_place=True,\n",
    "                              channels_wide=1024,channels_narrow=256,padding=1,\n",
    "                              kernel_size=3,stride=1,explicit_name=None,bn_in_place=True);\n",
    "    addConvLayer(net,namePrefix,layersArray,channels=2048,padding=0,\n",
    "                 kernel_size=1,stride=2)\n",
    "    \n",
    "  #  addConvLayer(net,namePrefix,layersArray,channels=2048,padding=0,\n",
    "  #           kernel_size=1,stride=2)\n",
    "  #  addReluLayer(net,namePrefix,layersArray,negative_slope=0,\n",
    "  #                      in_place=True,explicit_name=None)\n",
    "\n",
    "    \n",
    "    namePrefix='block5'\n",
    "    for i in range(3):\n",
    "        addBottleNeckResBlockBNAfter2(net,namePrefix,layersArray,negative_slope=0,relu_in_place=True,\n",
    "                              channels_wide=2048,channels_narrow=512,padding=1,\n",
    "                             kernel_size=3,stride=1,explicit_name=None,bn_in_place=True);\n",
    "\n",
    "    namePrefix='final'\n",
    "    addGlobalAvePoolingLayer(net,namePrefix,layersArray,explicit_name=None)\n",
    "    addConvLayer(net,namePrefix,layersArray,channels=1000,padding=0,kernel_size=1,\n",
    "                 stride=1,group=1,explicit_name=None,weight_filler=dict(type='xavier'),bias_init=0)\n",
    "    clf_name=layersArray[-1];\n",
    "    net.tops['loss'] = L.SoftmaxWithLoss(net.tops[clf_name],net.tops['label'],loss_weight=1)\n",
    "    net.tops['acc'] =  L.Accuracy(net.tops[clf_name],net.tops['label'])\n",
    "    \n",
    "    return net.to_proto()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ThinResNet50ELUnoBN(bs=256, db='db1'):\n",
    "    net = caffe.NetSpec()\n",
    "    layersArray=[];\n",
    "    namePrefix='block1'\n",
    "    \n",
    "    net.tops[\"data\"],net.tops[\"label\"] = L.Data(batch_size=256, backend=P.Data.LMDB, source=db,  ntop=2)  \n",
    "    layersArray=['data']\n",
    " #   net.tops[\"RandomDescriptor\"] = L.DummyData(dummy_data_param = dict(\n",
    " #           shape = dict(dim=[bs,256]),\n",
    " #                        data_filler=dict(type=\"gaussian\")))\n",
    " #   layersArray=[\"RandomDescriptor\"]\n",
    "    addConvLayer(net,namePrefix,layersArray,channels=64,padding=0,\n",
    "                 kernel_size=7,stride=2)\n",
    "    addEluLayer(net,namePrefix,layersArray,negative_slope=1,\n",
    "                        in_place=True,explicit_name=None)\n",
    "    addMaxPoolingLayer(net,namePrefix,layersArray,kernel_size=3,stride=2, padding=1, explicit_name=None)\n",
    "    addConvLayer(net,namePrefix,layersArray,channels=256,padding=0,\n",
    "             kernel_size=1,stride=2)\n",
    "        #Block2\n",
    "    namePrefix='block2'\n",
    "    for i in range(3):\n",
    "        addBottleNeckResBlockELUnoBN(net,namePrefix,layersArray,negative_slope=0,relu_in_place=True,\n",
    "                              channels_wide=256,channels_narrow=64,padding=1,\n",
    "                              kernel_size=3,stride=1,explicit_name=None); \n",
    "    addConvLayer(net,namePrefix,layersArray,channels=512,padding=0,\n",
    "                 kernel_size=1,stride=2)\n",
    "    \n",
    "    namePrefix='block3'\n",
    "#    addConvLayer(net,namePrefix,layersArray,channels=512,padding=0,\n",
    "#             kernel_size=1,stride=2)\n",
    "#    addReluLayer(net,namePrefix,layersArray,negative_slope=0,\n",
    "#                        in_place=True,explicit_name=None)\n",
    "    for i in range(4):\n",
    "        addBottleNeckResBlockELUnoBN(net,namePrefix,layersArray,negative_slope=0,relu_in_place=True,\n",
    "                              channels_wide=512,channels_narrow=128,padding=1,\n",
    "                              kernel_size=3,stride=1,explicit_name=None);\n",
    "    addConvLayer(net,namePrefix,layersArray,channels=1024,padding=0,\n",
    "                 kernel_size=1,stride=2)\n",
    "    \n",
    "    namePrefix='block4'\n",
    "    \n",
    "    for i in range(6):\n",
    "        addBottleNeckResBlockELUnoBN(net,namePrefix,layersArray,negative_slope=0,relu_in_place=True,\n",
    "                              channels_wide=1024,channels_narrow=256,padding=1,\n",
    "                              kernel_size=3,stride=1,explicit_name=None);\n",
    "    addConvLayer(net,namePrefix,layersArray,channels=2048,padding=0,\n",
    "                 kernel_size=1,stride=2)\n",
    "    \n",
    "    namePrefix='block5'\n",
    "    for i in range(3):\n",
    "        addBottleNeckResBlockELUnoBN(net,namePrefix,layersArray,negative_slope=0,relu_in_place=True,\n",
    "                              channels_wide=2048,channels_narrow=512,padding=1,\n",
    "                             kernel_size=3,stride=1,explicit_name=None);\n",
    "\n",
    "    namePrefix='final'\n",
    "    addGlobalAvePoolingLayer(net,namePrefix,layersArray,explicit_name=None)\n",
    "    addConvLayer(net,namePrefix,layersArray,channels=1000,padding=0,kernel_size=1,\n",
    "                 stride=1,group=1,explicit_name=None,weight_filler=dict(type='xavier'),bias_init=0)\n",
    "    clf_name=layersArray[-1];\n",
    "    net.tops['loss'] = L.SoftmaxWithLoss(net.tops[clf_name],net.tops['label'],loss_weight=1)\n",
    "    net.tops['acc'] =  L.Accuracy(net.tops[clf_name],net.tops['label'])\n",
    "    \n",
    "    return net.to_proto()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ThinResNet50ReLUBN(bs=256, db='db1'):\n",
    "    net = caffe.NetSpec()\n",
    "    layersArray=[];\n",
    "    namePrefix='block1'\n",
    "    \n",
    "    net.tops[\"data\"],net.tops[\"label\"] = L.Data(batch_size=256, backend=P.Data.LMDB, source=db,  ntop=2)  \n",
    "    layersArray=['data']\n",
    " #   net.tops[\"RandomDescriptor\"] = L.DummyData(dummy_data_param = dict(\n",
    " #           shape = dict(dim=[bs,256]),\n",
    " #                        data_filler=dict(type=\"gaussian\")))\n",
    " #   layersArray=[\"RandomDescriptor\"]\n",
    "    addConvLayer(net,namePrefix,layersArray,channels=64,padding=0,\n",
    "                 kernel_size=7,stride=2)\n",
    "    addBatchNormLayer(net,namePrefix,layersArray,moving_average_fraction=0.98,\n",
    "                      use_global_stats=False,explicit_name=None,in_place=True)\n",
    "    addScaleBiasLayer(net,namePrefix,layersArray,explicit_name=None,scale_init = 1.0,bias_init = 0.0,num_axes=1)\n",
    "    addReluLayer(net,namePrefix,layersArray,negative_slope=0,\n",
    "                        in_place=True,explicit_name=None)\n",
    "    addMaxPoolingLayer(net,namePrefix,layersArray,kernel_size=3,stride=2, padding=1, explicit_name=None)\n",
    "    addConvLayer(net,namePrefix,layersArray,channels=256,padding=0,\n",
    "             kernel_size=1,stride=2)\n",
    "       #Block2\n",
    "    namePrefix='block2'\n",
    "    for i in range(3):\n",
    "        addBottleNeckResBlockBNScaleBias(net,namePrefix,layersArray,negative_slope=0,relu_in_place=True,\n",
    "                              channels_wide=256,channels_narrow=64,padding=1,\n",
    "                              kernel_size=3,stride=1,explicit_name=None); \n",
    "    addConvLayer(net,namePrefix,layersArray,channels=512,padding=0,\n",
    "                 kernel_size=1,stride=2)\n",
    "    \n",
    "    namePrefix='block3'\n",
    "#    addConvLayer(net,namePrefix,layersArray,channels=512,padding=0,\n",
    "#             kernel_size=1,stride=2)\n",
    "#    addReluLayer(net,namePrefix,layersArray,negative_slope=0,\n",
    "#                        in_place=True,explicit_name=None)\n",
    "    for i in range(4):\n",
    "        addBottleNeckResBlockBNScaleBias(net,namePrefix,layersArray,negative_slope=0,relu_in_place=True,\n",
    "                              channels_wide=512,channels_narrow=128,padding=1,\n",
    "                              kernel_size=3,stride=1,explicit_name=None);\n",
    "    addConvLayer(net,namePrefix,layersArray,channels=1024,padding=0,\n",
    "                 kernel_size=1,stride=2)\n",
    "    \n",
    "    namePrefix='block4'\n",
    "    \n",
    "    for i in range(6):\n",
    "        addBottleNeckResBlockBNScaleBias(net,namePrefix,layersArray,negative_slope=0,relu_in_place=True,\n",
    "                              channels_wide=1024,channels_narrow=256,padding=1,\n",
    "                              kernel_size=3,stride=1,explicit_name=None);\n",
    "    addConvLayer(net,namePrefix,layersArray,channels=2048,padding=0,\n",
    "                 kernel_size=1,stride=2)\n",
    "    \n",
    "    namePrefix='block5'\n",
    "    for i in range(3):\n",
    "        addBottleNeckResBlockBNScaleBias(net,namePrefix,layersArray,negative_slope=0,relu_in_place=True,\n",
    "                              channels_wide=2048,channels_narrow=512,padding=1,\n",
    "                             kernel_size=3,stride=1,explicit_name=None);\n",
    "\n",
    "    namePrefix='final'\n",
    "    addGlobalAvePoolingLayer(net,namePrefix,layersArray,explicit_name=None)\n",
    "    addConvLayer(net,namePrefix,layersArray,channels=1000,padding=0,kernel_size=1,\n",
    "                 stride=1,group=1,explicit_name=None,weight_filler=dict(type='xavier'),bias_init=0)\n",
    "    clf_name=layersArray[-1];\n",
    "    net.tops['loss'] = L.SoftmaxWithLoss(net.tops[clf_name],net.tops['label'],loss_weight=1)\n",
    "    net.tops['acc'] =  L.Accuracy(net.tops[clf_name],net.tops['label'])\n",
    "    \n",
    "    return net.to_proto()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "with open('resnetbn_50_bn_after_sb1.prototxt', 'w') as f:\n",
    "    f.write(str( ThinResNet50ReLUBN(256,imagenettraindb)))\n",
    "#nn=ThinResNet(256,imagenettraindb)"
   ]
  }
 ],
 "metadata": {
  "description": "Define, train, and test the classic LeNet with the Python interface.",
  "example_name": "Learning LeNet",
  "include_in_docs": true,
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "priority": 2
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
